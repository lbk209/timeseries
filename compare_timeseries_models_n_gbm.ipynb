{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403b7c49-b1e4-4567-b300-d0cf4343f1ef",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589d964f-db11-4ee9-b31e-43a56aa2ed1c",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4c83acee-3f1c-4594-883d-7c9aa7615e83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(quantmod)\n",
    "library(forecast)\n",
    "library(rugarch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f76fd154-b6aa-4ba4-aac9-d547d3227669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Rcpp\n",
      "\n",
      "Loading required package: rlang\n",
      "\n",
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:xts’:\n",
      "\n",
      "    first, last\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Loading required package: BoomSpikeSlab\n",
      "\n",
      "Loading required package: Boom\n",
      "\n",
      "Loading required package: MASS\n",
      "\n",
      "\n",
      "Attaching package: ‘MASS’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    select\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘Boom’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    rWishart\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘BoomSpikeSlab’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    knots\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘bsts’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:BoomSpikeSlab’:\n",
      "\n",
      "    SuggestBurn\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘xgboost’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    slice\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(prophet)\n",
    "library(dplyr)\n",
    "\n",
    "library(bsts)\n",
    "\n",
    "library(xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a36dd52-ad96-4245-9985-ef4ee04f7323",
   "metadata": {},
   "source": [
    "### user's defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7c1cae5f-cb19-423f-9f75-23355f2b58d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path <- '~/works/utils/r'\n",
    "source(paste(path, \"myutils.r\", sep='/'))\n",
    "source(paste(path, \"myarimagarch.r\", sep='/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1ca76d8-f191-41d9-b2f7-320cad9fd35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new.get_result <- function(x, group, group.col='Models',\n",
    "                          errors=c('rmse','mape') # unconditional forecast\n",
    "                          #errors=c('rmse.mean','mape.mean') # daily forecast\n",
    "                          ) {\n",
    "    y <- my.get_result(x, group, errors=errors, group.col=group.col)\n",
    "    colnames(y) <- c('rmse','mape',group.col)\n",
    "    return(y)\n",
    "}\n",
    "\n",
    "\n",
    "new.plot_errors <- function(x, group.col='Models', ...) {\n",
    "    my.plot_errors(x, metrics=c('rmse'), group.col=group.col, ...)\n",
    "}\n",
    "\n",
    "# forecast only at h\n",
    "new.forecast <- function(x, h, forecastfunction, ...) {\n",
    "    fc <- forecastfunction(x, h, ...)\n",
    "    fc <- list(method = paste(\"Forecasting on\", h, sep=' '), mean=fc$mean[h])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81965efe-0310-4a8f-bab8-f7d92d9d839f",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b7c1c3-673b-420b-9e3c-c94ac7936b24",
   "metadata": {},
   "source": [
    "### S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae10fdf1-3592-4ea5-8ae2-d5917a507e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start <- '1991-01-01'\n",
    "train_end <- '2019-12-31'\n",
    "\n",
    "test_start <- '2020-01-01'\n",
    "test_end <- '2020-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee333ae3-056f-4986-aef5-64e8a03fcc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'^GSPC'"
      ],
      "text/latex": [
       "'\\textasciicircum{}GSPC'"
      ],
      "text/markdown": [
       "'^GSPC'"
      ],
      "text/plain": [
       "[1] \"^GSPC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from <- train_start\n",
    "to <- test_end\n",
    "getSymbols(\"^GSPC\", from=from, to=to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "214a3960-5dd7-47be-90ef-2e258d043250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spx <- GSPC\n",
    "colnames(spx) <- c('o','h','l','c','v','a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019dcc7f-aabe-4e1a-bced-ba8dcc21036b",
   "metadata": {},
   "source": [
    "### Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8becee7d-33dc-4db2-bab9-71e87158d6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookahead <- 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afb9af71-95b5-4285-93a0-0e5913510963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               logret\n",
       "1991-01-31 0.05216129\n",
       "1991-02-01 0.06360416\n",
       "1991-02-04 0.08173788\n",
       "1991-02-05 0.10755822\n",
       "1991-02-06 0.12847341\n",
       "1991-02-07 0.13502311"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spx.ret <- diff(log(spx$a), lookahead)\n",
    "spx.ret <- na.omit(spx.ret)\n",
    "colnames(spx.ret) <- 'logret'\n",
    "head(spx.ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "651c6501-6ff3-4d97-a129-65e3ee317cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train <- window(spx.ret, end=as.Date(train_end))\n",
    "test <- window(spx.ret, start=as.Date(test_start), end=as.Date(test_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf7c574-fcaf-41e8-a22e-97b2caadd84a",
   "metadata": {},
   "source": [
    "## CV Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ad305fe-7f89-4186-a651-1873d64ef6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR <- 252\n",
    "\n",
    "#hori <- floor(YEAR/2)\n",
    "#hori <- floor(YEAR/6)\n",
    "hori <- floor(YEAR/12)\n",
    "\n",
    "#peri <- floor(hori/2)\n",
    "#peri <- hori*2\n",
    "peri <- hori\n",
    "\n",
    "#wind <- 5*YEAR\n",
    "#wind <- 7*YEAR\n",
    "wind <- 9*YEAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f16cf2d-16cb-45ad-adb3-4dfc8bcfda22",
   "metadata": {},
   "source": [
    "### testing\n",
    "- rerun Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6af023f6-9782-43de-ad8a-60f12ef422a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing <- FALSE\n",
    "\n",
    "if (testing) {\n",
    "    train_start <- '1991-01-01'\n",
    "\n",
    "    #train_end <- '2000-12-31'\n",
    "    train_end <- '2000-07-01'\n",
    "    #train_end <- '1997-12-31'\n",
    "    \n",
    "    train <- window(spx.ret, start=as.Date(train_start), end=as.Date(train_end))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "493d63b9-0a03-4771-9aa1-53e0d58166f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"number of iterations: 238\"\n"
     ]
    }
   ],
   "source": [
    "n <- (nrow(train) - wind - hori)/floor(peri)\n",
    "print(paste('number of iterations: ', round(n), sep=''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a0b3d6-8fa4-4911-9127-b372ec88ba57",
   "metadata": {},
   "source": [
    "## Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f87d6209-3593-4659-b754-eef50734902f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x <- RSI(spx$a)\n",
    "trainx <- merge(train, x, join='left', fill=NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "063c43c3-688b-49ac-a6e2-89690219b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use close instead of adjusted to make consistent with \"un-adjusted\" high & low\n",
    "x <- BBands(spx[,c('h','l','c')])\n",
    "x <- x$pctB\n",
    "trainx <- merge(trainx, x, join='left', fill=NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff082501-d546-4510-bf61-43cfec923f72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x <- MACD(spx$a)\n",
    "x <- x$macd - x$signal\n",
    "trainx <- merge(trainx, x, join='left', fill=NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "befa6d49-0a1c-4bc7-8083-45ac91a02823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    y      rsi    bbands        macd\n",
       "1991-02-19 0.10602550 72.59254 0.8419486 -0.03641515\n",
       "1991-02-20 0.09798126 66.25313 0.7706927 -0.18551057\n",
       "1991-02-21 0.10585688 66.00481 0.7330987 -0.30953562\n",
       "1991-02-22 0.10194779 66.54491 0.7402938 -0.39546732\n",
       "1991-02-25 0.09259647 67.84742 0.7305630 -0.43573971\n",
       "1991-02-26 0.07655978 60.80133 0.6379610 -0.55105032"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                    y      rsi    bbands       macd\n",
       "2019-12-23 0.03808252 76.15462 0.9680588 0.15430304\n",
       "2019-12-24 0.03571448 75.83204 0.9028770 0.14089335\n",
       "2019-12-26 0.03335029 78.41506 0.9189083 0.14916039\n",
       "2019-12-27 0.03119111 78.43159 0.8946206 0.13732115\n",
       "2019-12-30 0.02122778 68.77901 0.7837726 0.07574999\n",
       "2019-12-31 0.02818876 70.74366 0.7500170 0.04243151"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colnames(trainx) <- c('y','rsi','bbands','macd')\n",
    "trainx <- na.omit(trainx)\n",
    "head(trainx)\n",
    "tail(trainx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5049d74b-5700-4b0c-af48-c2d74dc6d9cd",
   "metadata": {},
   "source": [
    "# Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9653be84-20b9-4aad-b230-55cfa4fc581c",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2842860f-ca3a-4757-9d7e-a0f608b8b9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast <- function(x, h, xreg=NULL, xreg.msize=NULL) {\n",
    "    \n",
    "    check.ds <- function(x) {\n",
    "        d <- try(as.POSIXct(x$ds, format = \"%Y-%m-%d\"), silent=T)\n",
    "        if ((sum(is.na(d))>0) | (is.element(\"try-error\", class(d))))  {\n",
    "            #print(\"That wasn't correct!\")\n",
    "            x$ds <- seq(as.Date('1901-01-01'), length.out=length(x$ds), by=1)\n",
    "        }\n",
    "        return(x)\n",
    "    }\n",
    "    \n",
    "    model <- prophet()\n",
    "\n",
    "    if (!is.null(xreg)) {\n",
    "        ### convert data for prophet\n",
    "        #x <- ifelse(is.null(dim(x)), data.frame(x), x) # not works\n",
    "        if (is.null(dim(x))) {x <- data.frame(x)}\n",
    "        colnames(x) <- 'y'\n",
    "        x.train <- cbind(x, xreg)\n",
    "        x.train <- as.data.frame(x.train)\n",
    "        x.train <- cbind(ds=rownames(x.train), x.train)\n",
    "        rownames(x.train) <- NULL\n",
    "        x.train <- check.ds(x.train)\n",
    "\n",
    "        ### add regressors before fitting\n",
    "        for (c in colnames(xreg)) {\n",
    "            model <- add_regressor(model, c)\n",
    "        }\n",
    "\n",
    "        ### fit: must run after add_regressor and before make_future_dataframe\n",
    "        model <- fit.prophet(model, x.train)\n",
    "\n",
    "        ### prepare future ds\n",
    "        future <- make_future_dataframe(model, periods=h)\n",
    "\n",
    "        # regessor assumption for future\n",
    "        if (is.null(xreg.msize)) {\n",
    "            xreg.m <- xreg # calc mean for future with all the xreg\n",
    "        } else {\n",
    "            # calc mean for future with xreg of length xreg.mszie\n",
    "            xreg.m <- tail(xreg, n=xreg.msize)\n",
    "        }\n",
    "        \n",
    "        if (is.null(dim(xreg))) {\n",
    "            xreg.h <- mean(xreg.m)\n",
    "        } else {\n",
    "            xreg.h <- colMeans(xreg.m)  \n",
    "        }\n",
    "\n",
    "        # rbind history & future of xreg\n",
    "        xreg.all <- data.frame(xreg)\n",
    "        xreg.coln <- colnames(xreg.all) # save name for the case of single xreg\n",
    "\n",
    "        xreg.h <- data.frame(xreg.h)\n",
    "        colnames(xreg.h) <- colnames(NA)\n",
    "        xreg.h <- t(xreg.h)\n",
    "        xreg.h <- as.ts(xreg.h[rep(seq_len(nrow(xreg.h)), h), ])\n",
    "        xreg.h <- data.frame(xreg.h) # convert to frame for the case of single xreg\n",
    "        \n",
    "        # update future\n",
    "        if ((dim(xreg.h)[2]==1) & (dim(xreg.h)[1]==length(xreg.coln))) {\n",
    "            xreg.h <- t(xreg.h) # the case of h==1\n",
    "        }\n",
    "        colnames(xreg.h) <- xreg.coln # match name to rbind\n",
    "        #xreg.all <- rbind(xreg.all, xreg.h)\n",
    "        xreg.all <- rbind(as.matrix(xreg.all), xreg.h) \n",
    "        xreg.all <- data.frame(xreg.all, row.names = NULL) \n",
    "        xreg.all$ds <- future$ds\n",
    "        future <- xreg.all\n",
    "\n",
    "    } else {\n",
    "        x.train <- data.frame(ds=index(x), y=as.numeric(x))\n",
    "        x.train <- check.ds(x.train)\n",
    "        model <- fit.prophet(model, x.train)\n",
    "        future <- make_future_dataframe(model, periods=h)\n",
    "    }\n",
    "\n",
    "    fc <- predict(model, future)\n",
    "    fc <- list(method = \"Prophet Forecasting\", mean=tail(fc$yhat, h),\n",
    "               model=model, pred=fc) # save model & pred result as well\n",
    "    return(fc)\n",
    "} \n",
    "\n",
    "prophet.forecast <- cv.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58748625-2a70-41e8-8e78-59a2a1b18b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast.2 <- function(x, h, ...) {\n",
    "    new.forecast(x, h, cv.forecast, ...)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e0fb38-d451-44d8-8834-ba4d69d19781",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dd96713-bac0-45e7-acee-91b3db181205",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "10 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "20 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "30 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "40 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "50 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "60 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "70 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "80 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "90 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m01.1 <- my.tsCV(train, cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                        silent=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ac8981d-15bf-408c-9638-7b4754cbf984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-01-24\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m01.1\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c1ddd0-be96-456c-878f-5386005d6092",
   "metadata": {},
   "source": [
    "## Additional regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5003bce6-1677-46e3-a84f-18b57b7872bc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "10 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "20 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "30 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "40 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "50 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "60 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "70 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "80 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "90 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m01.2 <- my.tsCV(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          xreg=trainx[,2:4],\n",
    "                          silent=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2d5fe22-e405-4131-96d3-1cf18723f552",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "10 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "20 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "30 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "40 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "50 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "60 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "70 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "80 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "90 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m01.3 <- my.tsCV(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          xreg=trainx[,3], \n",
    "                          silent=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ba326e3-2a59-4a52-ab62-c7b71ccb9ea8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "10 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "20 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "30 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "40 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "50 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "60 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "70 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "80 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "90 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m01.4 <- my.tsCV(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                         xreg=trainx[,2:4],\n",
    "                         xreg.msize=hori)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfe1cb3-5728-4fd8-a0ef-2593535940f5",
   "metadata": {},
   "source": [
    "## Compare Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "729703b7-0e13-4ac8-9014-dbab6d2d5acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my.figsize(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88224355-62cb-4480-b79c-b2791413a8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94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\nrkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- new.get_result(result.m01.1, '1.Prophet')\n",
    "errors.2 <- new.get_result(result.m01.2, '2.Prophet with Regressors')\n",
    "errors.3 <- new.get_result(result.m01.3, '3.Prophet with 1 Regressor')\n",
    "errors.4 <- new.get_result(result.m01.4, '4.Prophet with Regressor (2)')\n",
    "\n",
    "x <- errors.1\n",
    "x <- rbind(x, errors.2)\n",
    "x <- rbind(x, errors.3)\n",
    "x <- rbind(x, errors.4)\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8351dcbc-33db-44ea-a47d-550e48cc6e6c",
   "metadata": {},
   "source": [
    "### save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b27ae32-b956-4e94-9aec-d07bfd72a72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- result.m01.1\n",
    "write.csv(x, file = \"prophet_result_m0101.csv\")\n",
    "x <- result.m01.2\n",
    "write.csv(x, file = \"prophet_result_m0102.csv\")\n",
    "x <- result.m01.3\n",
    "write.csv(x, file = \"prophet_result_m0103.csv\")\n",
    "x <- result.m01.4\n",
    "write.csv(x, file = \"prophet_result_m0104.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c5f45-45d6-4303-82e4-1a2f9d7fbd8c",
   "metadata": {},
   "source": [
    "### load result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2e2b68b-2e54-484a-9d72-6d74422bd9c6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.m01.1 <- read.csv(file = 'prophet_result_m0101.csv')\n",
    "result.m01.2 <- read.csv(file = 'prophet_result_m0102.csv')\n",
    "result.m01.3 <- read.csv(file = 'prophet_result_m0103.csv')\n",
    "result.m01.4 <- read.csv(file = 'prophet_result_m0104.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7cb8d98e-9491-400a-abd5-6a4694dfe9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m01 <- result.m01.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d38357-ca19-4a00-a9f3-88f56e5a4726",
   "metadata": {},
   "source": [
    "# BSTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b1a082-dca7-457f-a151-90f7518efe7a",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "92d8cf60-d4b2-4d74-b586-01285de500da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast <- function(x, h, xreg=NULL, xreg.msize=NULL, expected.model.size=0,\n",
    "                        model=NULL, niter=1000, ...) \n",
    "{\n",
    "    if (!is.null(xreg)) {\n",
    "        ### set params for fitting\n",
    "        # organize data for fitting\n",
    "        if (is.null(dim(x))) {x <- data.frame(x)}\n",
    "        colnames(x) <- 'y'\n",
    "        x.train <- cbind(x, xreg)\n",
    "        x.train <- as.data.frame(x.train)\n",
    "        \n",
    "        if (is.null(model)) {\n",
    "            n <- ncol(x.train)\n",
    "            if ((expected.model.size < 1) | (expected.model.size > n)) {\n",
    "                expected.model.size <- n\n",
    "            }\n",
    "            ss <- AddSemilocalLinearTrend(list(), x.train$y)\n",
    "            model <- bsts(y ~ .,\n",
    "                          state.specification = ss,\n",
    "                          niter = niter,\n",
    "                          data = x.train,\n",
    "                          expected.model.size = expected.model.size)  # Passed to SpikeSlabPrior.\n",
    "            olddata <- NULL\n",
    "        } else {\n",
    "            olddata <- x.train\n",
    "        }\n",
    "        \n",
    "        ### set params for prediction\n",
    "        # regessor assumption for future\n",
    "        if (is.null(xreg.msize)) {\n",
    "            xreg.m <- xreg # calc mean for future with all the xreg\n",
    "        } else {\n",
    "            # calc mean for future with xreg of length xreg.mszie\n",
    "            xreg.m <- tail(xreg, n=xreg.msize)\n",
    "        }\n",
    "\n",
    "        if (is.null(dim(xreg))) {\n",
    "            xreg.h <- mean(xreg.m)\n",
    "        } else {\n",
    "            xreg.h <- colMeans(xreg.m)  \n",
    "        }\n",
    "\n",
    "        xreg.all <- data.frame(xreg)\n",
    "        xreg.coln <- colnames(xreg.all) # save name for the case of single xreg\n",
    "        xreg.h <- data.frame(xreg.h)\n",
    "        colnames(xreg.h) <- colnames(NA)\n",
    "        xreg.h <- t(xreg.h)\n",
    "        xreg.h <- as.ts(xreg.h[rep(seq_len(nrow(xreg.h)), h), ])\n",
    "        xreg.h <- data.frame(xreg.h) # convert to frame for the case of single xreg\n",
    "        \n",
    "        if ((dim(xreg.h)[2]==1) & (dim(xreg.h)[1]==length(xreg.coln))) {\n",
    "            xreg.h <- t(xreg.h) # the case of h==1\n",
    "        } else {\n",
    "            xreg.h <- as.ts(xreg.h) # convert to ts as xreg is ts\n",
    "        }\n",
    "        \n",
    "        colnames(xreg.h) <- xreg.coln # match name to rbind\n",
    "        \n",
    "    } else {\n",
    "        if (is.null(model)) {\n",
    "            ss <- AddSemilocalLinearTrend(list(), x)\n",
    "            model <- bsts(x, state.specification = ss, niter=niter, ...)\n",
    "            olddata <- NULL\n",
    "        } else {\n",
    "            olddata <- x\n",
    "        }\n",
    "        xreg.h <- NULL\n",
    "    }\n",
    "    # predict\n",
    "    fc <- predict(model, horizon=h, newdata=xreg.h, olddata=olddata)\n",
    "    fc$model <- model\n",
    "    return(fc)\n",
    "}\n",
    "\n",
    "bsts.forecast <- cv.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55107914-5b42-493c-b20b-c6b5d0d9b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast.2 <- function(x, h, ...) {\n",
    "    new.forecast(x, h, cv.forecast, ping=0, ...)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d8fc5f-8e48-4ea2-b707-e1f062d6b634",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0bae75e-ad34-40a9-aceb-7542fa7c13fd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n",
      "20 % done.\n",
      "\n",
      "30 % done.\n",
      "\n",
      "40 % done.\n",
      "\n",
      "50 % done.\n",
      "\n",
      "60 % done.\n",
      "\n",
      "70 % done.\n",
      "\n",
      "80 % done.\n",
      "\n",
      "90 % done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m02.1 <- my.tsCV(train, cv.forecast.2, h=hori, window=wind, step=peri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "602a90d7-2081-46eb-8cf8-ca09307501bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-01-24\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m02.1\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b296acaf-74d0-4185-b130-b6512bbf03be",
   "metadata": {},
   "source": [
    "## Regression with spike and slab priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ecce414-f5fc-4f70-9f89-4908c5fe4e9a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:50:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:50:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:50:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:50:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:51:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:51:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:51:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:51:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:51:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:51:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:51:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:51:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:51:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:51:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:51:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:51:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:51:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:51:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:51:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:51:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:52:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:52:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:52:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:52:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:52:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:52:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:52:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:52:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:52:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:52:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:52:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:52:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:52:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:52:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:52:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:52:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:52:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:53:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:53:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:53:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:53:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:53:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:53:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:53:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:53:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:53:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:53:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:53:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:53:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:53:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:53:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:53:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:53:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:54:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:54:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:54:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:54:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:54:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:54:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:54:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:54:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:54:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:54:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:54:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:54:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:54:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:54:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:54:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:54:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:54:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:55:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:55:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:55:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:55:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:55:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:55:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:55:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:55:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:55:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:55:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:55:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:55:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:55:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:55:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:55:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:55:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:55:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:56:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:56:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:56:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:56:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:56:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:56:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:56:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:56:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:56:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:56:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:56:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:56:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:56:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:56:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:56:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:56:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:57:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:57:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:57:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:57:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:57:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:57:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:57:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:57:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:57:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:57:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:57:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:57:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:57:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:57:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:57:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:57:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:57:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:58:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:58:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:58:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:58:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:58:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:58:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:58:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:58:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:58:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:58:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:58:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:58:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:58:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:58:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:58:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:58:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:59:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:59:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:59:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:59:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:59:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:59:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:59:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:59:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:59:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:59:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:59:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:59:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:59:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:59:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:59:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:59:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:59:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:00:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:00:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:00:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:00:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:00:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:00:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:00:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:00:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:00:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:00:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:00:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:00:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:00:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:00:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:00:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:00:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:01:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:01:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:01:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:01:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:01:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:01:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:01:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:01:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:01:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:01:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:01:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:01:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:01:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:01:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:01:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:01:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:01:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:02:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:02:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:02:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:02:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:02:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:02:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:02:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:02:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:02:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:02:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:02:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:02:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:02:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:02:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:02:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:02:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:03:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:03:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:03:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:03:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:03:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:03:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:03:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:03:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:03:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:03:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:03:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:03:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:03:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:03:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:03:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:03:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:03:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:04:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:04:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:04:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:04:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:04:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:04:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:04:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:04:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:04:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:04:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:04:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:04:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:04:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:04:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:04:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:04:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:05:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:05:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:05:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:05:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:05:15 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:05:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:05:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:05:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:05:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:05:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:05:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:05:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:05:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:05:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:05:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:05:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:05:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:06:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:06:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:06:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:06:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:06:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:06:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:06:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:06:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:06:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:06:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:06:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:06:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:06:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:06:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:06:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:06:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:06:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:07:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:07:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:07:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:07:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:07:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:07:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:07:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:07:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:07:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:07:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:07:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:07:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:07:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:07:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:07:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:07:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:08:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:08:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:08:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:08:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:08:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:08:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:08:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:08:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:08:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:08:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:08:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:08:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:08:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:08:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:08:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:08:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:09:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:09:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:09:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:09:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:09:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:09:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:09:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:09:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:09:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:09:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:09:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:09:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:09:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:09:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:09:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:09:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:09:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:10:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:10:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:10:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:10:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:10:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:10:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:10:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:10:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:10:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:10:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:10:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:10:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:10:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:10:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:10:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:10:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:10:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:11:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:11:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:11:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:11:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:11:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:11:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:11:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:11:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:11:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:11:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:11:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:11:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:11:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:11:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:11:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:11:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:12:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:12:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:12:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:12:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:12:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:12:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:12:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:12:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:12:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:12:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:12:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:12:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:12:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:12:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:12:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:12:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:12:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:13:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:13:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:13:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:13:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:13:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:13:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:13:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:13:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:13:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:13:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:13:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:13:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:13:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:13:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:13:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:13:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:14:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:14:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:14:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:14:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:14:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:14:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:14:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:14:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:14:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:14:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:14:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:14:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:14:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:14:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:14:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:14:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:14:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:15:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:15:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:15:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:15:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:15:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:15:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:15:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:15:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:15:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:15:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:15:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:15:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:15:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:15:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:15:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:15:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:15:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:16:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:16:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:16:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:16:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:16:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:16:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:16:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:16:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:16:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:16:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:16:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:16:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:16:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:16:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:16:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:16:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:17:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:17:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:17:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:17:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:17:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:17:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:17:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:17:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:17:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:17:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:17:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:17:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:17:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:17:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:17:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:17:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:17:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:18:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:18:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:18:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:18:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:18:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:18:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:18:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:18:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:18:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:18:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:18:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:18:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:18:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:18:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:18:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:18:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:19:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:19:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:19:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:19:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:19:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:19:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:19:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:19:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:19:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:19:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:19:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:19:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:19:43 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:19:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:19:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:19:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:19:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:20:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:20:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:20:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:20:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:20:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:20:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:20:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:20:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:20:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:20:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:20:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:20:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:20:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:20:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:20:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:20:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:20:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:21:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:21:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:21:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:21:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:21:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:21:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:21:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:21:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:21:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:21:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:21:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:21:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:21:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:21:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:21:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:21:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:22:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:22:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:22:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:22:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:22:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:22:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:22:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:22:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:22:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:22:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:22:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:22:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:22:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:22:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:22:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:22:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:22:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:23:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:23:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:23:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:23:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:23:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:23:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:23:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:23:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:23:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:23:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:23:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:23:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:23:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:23:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:23:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:23:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:23:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:24:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:24:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:24:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:24:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:24:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:24:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:24:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:24:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:24:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:24:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:24:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:24:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:24:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:24:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:24:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:24:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:25:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:25:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:25:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:25:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:25:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:25:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:25:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:25:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:25:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:25:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:25:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:25:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:25:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:25:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:25:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:25:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:25:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:26:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:26:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:26:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:26:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:26:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:26:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:26:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:26:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:26:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:26:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:26:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:26:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:26:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:26:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:26:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:26:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:27:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:27:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:27:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:27:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:27:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:27:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:27:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:27:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:27:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:27:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:27:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:27:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:27:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:27:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:27:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:27:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:27:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:28:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:28:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:28:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:28:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:28:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:28:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:28:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:28:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:28:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:28:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:28:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:28:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:28:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:28:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:28:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:28:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:28:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:29:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:29:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:29:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:29:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:29:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:29:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:29:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:29:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:29:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:29:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:29:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:29:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:29:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:29:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:29:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:29:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:30:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:30:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:30:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:30:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:30:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:30:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:30:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:30:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:30:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:30:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:30:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:30:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:30:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:30:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:30:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:30:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:31:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:31:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:31:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:31:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:31:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:31:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:31:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:31:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:31:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:31:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:31:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:31:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:31:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:31:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:31:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:31:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:31:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:32:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:32:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:32:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:32:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:32:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:32:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:32:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:32:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:32:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:32:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:32:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:32:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:32:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:32:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:32:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:32:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:32:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:33:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:33:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:33:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:33:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:33:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:33:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:33:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:33:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:33:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:33:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:33:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:33:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:33:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:33:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:33:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:33:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:34:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:34:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:34:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:34:11 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:34:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:34:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:34:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:34:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:34:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:34:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:34:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:34:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:34:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:34:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:34:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:34:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:34:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:35:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:35:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:35:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:35:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:35:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:35:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:35:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:35:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:35:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:35:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:35:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:35:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:35:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:35:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:35:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:35:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:36:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:36:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:36:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:36:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:36:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:36:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:36:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:36:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:36:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:36:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:36:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:36:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:36:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:36:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:36:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:36:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:36:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:37:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:37:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:37:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:37:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:37:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:37:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:37:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:37:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:37:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:37:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:37:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:37:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:37:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:37:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:37:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:37:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:37:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:38:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:38:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:38:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:38:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:38:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:38:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:38:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:38:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:38:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:38:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:38:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:38:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:38:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:38:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:38:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:38:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:39:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:39:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:39:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:39:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:39:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:39:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:39:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:39:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:39:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:39:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:39:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:39:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:39:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:39:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:39:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:39:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:39:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:40:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:40:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:40:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:40:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:40:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:40:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:40:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:40:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:40:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:40:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:40:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:40:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:40:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:40:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:40:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:40:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:41:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:41:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:41:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:41:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:41:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:41:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:41:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:41:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:41:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:41:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:41:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:41:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:41:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:41:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:41:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:41:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:41:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:42:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:42:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:42:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:42:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:42:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:42:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:42:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:42:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:42:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:42:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:42:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:42:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:42:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:42:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:42:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:42:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:42:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:43:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:43:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:43:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:43:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:43:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:43:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:43:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:43:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:43:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:43:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:43:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:43:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:43:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:43:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:43:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:43:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:44:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:44:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:44:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:44:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:44:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:44:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:44:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:44:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:44:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:44:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:44:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:44:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:44:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:44:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:44:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:44:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:44:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:45:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:45:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:45:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:45:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:45:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:45:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:45:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:45:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:45:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:45:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:45:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:45:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:45:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:45:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:45:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:45:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:45:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:46:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:46:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:46:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:46:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:46:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:46:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:46:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:46:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:46:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:46:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:46:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:46:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:46:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:46:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:46:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:46:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:47:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:47:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:47:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:47:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:47:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:47:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:47:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:47:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:47:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:47:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:47:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:47:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:47:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:47:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:47:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:47:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:47:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:48:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:48:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:48:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:48:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:48:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:48:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:48:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:48:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:48:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:48:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:48:38 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:48:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:48:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:48:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:48:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:48:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:48:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:49:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:49:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:49:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:49:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:49:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:49:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:49:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:49:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:49:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:49:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:49:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:49:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:49:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:49:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:49:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:49:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:50:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:50:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:50:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:50:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:50:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:50:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:50:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:50:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:50:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:50:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:50:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:50:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:50:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:50:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:50:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:50:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:50:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:51:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:51:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:51:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:51:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:51:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:51:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:51:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:51:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:51:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:51:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:51:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:51:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:51:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:51:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:51:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:51:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:52:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:52:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:52:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:52:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:52:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:52:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:52:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:52:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:52:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:52:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:52:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:52:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:52:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:52:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:52:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:52:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:52:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:53:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:53:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:53:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:53:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:53:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:53:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:53:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:53:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:53:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:53:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:53:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:53:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:53:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:53:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:53:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:53:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:54:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:54:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:54:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:54:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:54:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:54:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:54:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:54:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:54:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:54:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:54:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:54:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:54:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:54:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:54:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:54:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:54:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:55:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:55:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:55:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:55:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:55:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:55:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:55:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:55:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:55:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:55:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:55:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:55:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:55:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:55:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:55:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:55:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:55:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:56:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:56:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:56:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:56:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:56:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:56:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:56:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:56:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:56:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:56:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:56:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:56:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:56:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:56:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:56:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:56:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:57:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:57:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:57:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:57:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:57:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:57:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:57:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:57:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:57:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:57:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:57:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:57:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:57:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:57:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:57:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:57:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:57:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:58:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:58:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:58:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:58:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:58:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:58:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:58:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:58:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:58:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:58:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:58:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:58:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:58:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:58:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:58:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:58:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:59:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:59:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:59:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:59:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:59:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:59:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:59:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:59:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:59:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:59:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:59:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:59:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:59:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:59:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:59:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:59:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:59:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:00:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:00:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:00:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:00:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:00:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:00:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:00:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:00:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:00:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:00:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:00:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:00:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:00:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:00:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:00:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:00:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:00:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:01:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:01:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:01:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:01:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:01:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:01:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:01:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:01:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:01:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:01:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:01:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:01:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:01:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:01:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:01:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:01:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:02:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:02:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:02:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:02:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:02:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:02:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:02:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:02:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:02:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:02:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:02:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:02:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:02:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:02:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:02:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:02:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:02:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:03:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:03:05 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:03:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:03:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:03:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:03:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:03:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:03:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:03:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:03:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:03:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:03:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:03:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:03:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:03:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:03:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:03:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:04:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:04:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:04:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:04:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:04:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:04:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:04:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:04:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:04:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:04:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:04:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:04:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:04:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:04:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:04:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:04:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:05:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:05:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:05:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:05:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:05:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:05:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:05:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:05:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:05:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:05:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:05:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:05:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:05:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:05:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:05:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:05:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:05:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:06:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:06:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:06:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:06:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:06:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:06:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:06:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:06:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:06:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:06:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:06:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:06:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:06:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:06:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:06:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:06:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:07:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:07:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:07:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:07:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:07:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:07:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:07:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:07:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:07:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:07:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:07:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:07:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:07:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:07:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:07:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:07:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:07:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:08:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:08:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:08:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:08:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:08:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:08:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:08:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:08:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:08:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:08:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:08:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:08:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:08:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:08:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:08:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:08:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:08:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:09:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:09:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:09:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:09:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:09:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:09:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:09:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:09:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:09:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:09:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:09:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:09:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:09:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:09:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:09:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:09:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:10:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:10:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:10:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:10:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:10:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:10:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:10:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:10:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:10:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:10:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:10:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:10:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:10:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:10:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:10:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:10:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:10:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:11:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:11:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:11:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:11:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:11:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:11:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:11:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:11:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:11:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:11:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:11:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:11:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:11:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:11:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:11:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:11:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:12:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:12:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:12:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:12:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:12:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:12:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:12:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:12:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:12:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:12:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:12:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:12:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:12:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:12:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:12:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:12:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:12:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:13:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:13:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:13:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:13:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:13:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:13:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:13:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:13:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:13:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:13:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:13:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:13:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:13:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:13:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:13:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:13:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:14:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:14:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:14:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:14:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:14:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:14:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:14:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:14:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:14:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:14:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:14:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:14:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:14:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:14:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:14:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:14:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:14:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:15:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:15:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:15:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:15:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:15:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:15:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:15:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:15:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:15:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:15:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:15:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:15:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:15:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:15:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:15:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:15:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:16:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:16:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:16:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:16:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:16:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:16:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:16:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:16:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:16:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:16:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:16:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:16:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:16:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:16:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:16:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:16:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:16:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:17:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:17:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:17:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:17:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:17:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:17:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:17:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:17:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:17:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:17:34 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:17:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:17:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:17:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:17:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:17:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:17:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:17:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:18:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:18:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:18:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:18:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:18:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:18:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:18:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:18:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:18:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:18:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:18:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:18:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:18:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:18:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:18:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:18:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:19:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:19:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:19:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:19:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:19:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:19:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:19:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:19:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:19:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:19:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:19:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:19:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:19:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:19:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:19:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:19:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:19:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:20:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:20:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:20:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:20:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:20:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:20:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:20:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:20:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:20:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:20:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:20:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:20:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:20:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:20:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:20:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:20:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:21:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:21:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:21:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:21:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:21:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:21:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:21:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:21:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:21:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:21:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:21:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:21:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:21:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:21:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:21:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:21:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:21:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:22:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:22:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:22:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:22:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:22:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:22:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:22:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:22:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:22:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:22:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:22:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:22:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:22:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:22:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:22:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:22:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:23:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:23:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:23:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:23:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:23:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:23:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:23:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:23:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:23:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:23:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:23:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:23:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:23:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:23:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:23:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:23:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:23:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:24:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:24:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:24:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:24:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:24:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:24:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:24:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:24:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:24:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:24:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:24:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:24:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:24:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:24:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:24:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:24:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:25:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:25:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:25:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:25:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:25:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:25:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:25:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:25:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:25:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:25:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:25:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:25:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:25:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:25:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:25:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:25:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:25:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:26:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:26:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:26:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:26:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:26:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:26:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:26:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:26:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:26:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:26:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:26:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:26:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:26:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:26:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:26:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:26:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:26:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:27:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:27:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:27:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:27:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:27:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:27:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:27:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:27:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:27:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:27:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:27:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:27:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:27:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:27:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:27:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:27:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:28:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:28:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:28:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:28:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:28:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:28:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:28:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:28:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:28:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:28:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:28:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:28:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:28:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:28:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:28:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:28:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:28:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:29:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:29:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:29:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:29:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:29:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:29:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:29:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:29:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:29:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:29:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:29:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:29:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:29:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:29:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:29:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:29:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:29:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:30:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:30:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:30:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:30:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:30:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:30:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:30:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:30:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:30:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:30:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:30:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:30:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:30:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:30:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:30:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:30:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:31:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:31:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:31:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:31:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:31:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:31:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:31:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:31:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:31:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:31:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:31:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:31:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:31:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:31:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:31:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:31:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:31:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:32:00 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:32:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:32:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:32:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:32:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:32:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:32:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:32:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:32:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:32:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:32:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:32:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:32:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:32:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:32:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:32:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:32:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:33:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:33:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:33:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:33:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:33:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:33:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:33:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:33:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:33:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:33:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:33:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:33:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:33:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:33:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:33:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:33:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:34:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:34:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:34:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:34:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:34:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:34:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:34:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:34:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:34:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:34:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:34:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:34:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:34:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:34:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:34:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:34:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:34:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:35:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:35:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:35:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:35:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:35:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:35:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:35:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:35:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:35:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:35:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:35:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:35:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:35:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:35:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:35:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:35:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:35:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:36:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:36:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:36:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:36:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:36:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:36:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:36:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:36:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:36:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:36:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:36:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:36:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:36:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:36:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:36:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:36:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:37:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:37:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:37:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:37:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:37:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:37:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:37:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:37:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:37:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:37:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:37:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:37:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:37:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:37:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:37:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:37:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:37:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:38:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:38:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:38:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:38:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:38:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:38:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:38:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:38:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:38:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:38:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:38:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:38:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:38:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:38:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:38:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:38:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:39:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:39:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:39:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:39:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:39:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:39:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:39:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:39:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:39:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:39:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:39:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:39:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:39:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:39:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:39:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:39:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:39:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:40:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:40:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:40:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:40:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:40:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:40:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:40:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:40:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:40:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:40:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:40:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:40:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:40:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:40:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:40:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:40:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:40:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:41:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:41:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:41:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:41:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:41:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:41:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:41:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:41:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:41:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:41:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:41:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:41:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:41:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:41:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:41:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:41:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:41:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:42:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:42:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:42:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:42:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:42:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:42:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:42:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:42:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:42:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:42:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:42:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:42:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:42:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:42:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:42:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:42:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:43:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:43:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:43:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:43:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:43:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:43:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:43:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:43:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:43:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:43:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:43:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:43:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:43:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:43:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:43:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:43:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:43:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:44:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:44:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:44:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:44:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:44:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:44:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:44:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:44:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:44:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:44:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:44:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:44:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:44:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:44:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:44:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:44:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:44:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:45:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:45:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:45:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:45:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:45:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:45:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:45:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:45:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:45:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:45:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:45:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:45:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:45:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:45:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:45:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:45:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:46:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:46:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:46:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:46:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:46:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:46:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:46:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:46:26 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:46:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:46:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:46:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:46:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:46:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:46:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:46:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:46:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:46:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:47:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:47:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:47:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:47:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:47:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:47:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:47:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:47:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:47:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:47:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:47:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:47:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:47:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:47:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:47:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:47:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:48:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:48:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:48:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:48:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:48:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:48:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:48:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:48:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:48:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:48:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:48:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:48:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:48:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:48:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:48:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:48:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:48:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:49:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:49:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:49:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:49:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:49:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:49:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:49:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:49:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:49:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:49:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:49:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:49:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:49:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:49:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:49:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:49:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:49:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:50:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:50:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:50:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:50:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:50:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:50:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:50:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:50:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:50:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:50:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:50:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:50:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:50:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:50:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:50:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:50:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:51:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:51:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:51:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:51:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:51:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:51:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:51:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:51:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:51:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:51:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:51:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:51:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:51:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:51:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:51:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:51:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:51:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:52:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:52:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:52:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:52:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:52:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:52:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:52:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:52:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:52:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:52:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:52:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:52:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:52:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:52:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:52:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:52:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:52:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:53:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:53:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:53:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:53:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:53:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:53:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:53:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:53:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:53:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:53:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:53:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:53:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:53:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:53:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:53:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:53:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:54:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:54:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:54:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:54:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:54:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:54:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:54:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:54:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:54:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:54:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:54:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:54:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:54:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:54:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:54:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:54:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:54:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:55:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:55:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:55:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:55:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:55:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:55:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:55:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:55:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:55:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:55:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:55:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:55:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:55:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:55:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:55:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:55:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:55:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:56:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:56:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:56:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:56:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:56:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:56:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:56:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:56:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:56:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:56:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:56:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:56:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:56:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:56:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:56:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:56:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:57:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:57:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:57:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:57:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:57:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:57:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:57:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:57:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:57:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:57:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:57:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:57:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:57:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:57:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:57:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:57:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:57:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:58:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:58:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:58:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:58:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:58:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:58:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:58:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:58:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:58:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:58:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:58:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:58:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:58:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:58:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:58:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:58:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:58:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:59:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:59:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:59:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:59:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:59:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:59:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:59:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:59:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:59:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:59:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:59:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:59:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:59:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:59:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:59:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:59:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:00:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:00:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:00:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:00:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:00:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:00:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:00:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:00:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:00:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:00:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:00:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:00:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:00:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:00:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:00:52 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:00:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:01:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:01:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:01:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:01:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:01:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:01:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:01:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:01:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:01:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:01:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:01:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:01:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:01:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:01:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:01:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:01:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:01:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:02:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:02:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:02:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:02:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:02:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:02:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:02:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:02:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:02:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:02:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:02:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:02:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:02:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:02:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:02:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:02:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:02:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:03:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:03:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:03:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:03:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:03:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:03:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:03:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:03:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:03:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:03:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:03:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:03:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:03:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:03:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:03:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:03:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:03:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:04:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:04:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:04:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:04:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:04:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:04:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:04:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:04:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:04:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:04:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:04:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:04:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:04:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:04:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:04:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:04:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:05:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:05:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:05:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:05:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:05:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:05:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:05:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:05:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:05:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:05:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:05:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:05:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:05:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:05:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:05:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:05:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:05:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:06:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:06:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:06:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:06:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:06:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:06:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:06:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:06:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:06:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:06:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:06:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:06:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:06:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:06:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:06:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:06:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:07:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:07:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:07:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:07:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:07:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:07:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:07:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:07:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:07:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:07:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:07:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:07:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:07:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:07:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:07:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:07:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:07:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:08:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:08:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:08:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:08:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:08:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:08:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:08:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:08:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:08:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:08:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:08:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:08:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:08:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:08:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:08:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:08:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:08:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:09:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:09:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:09:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:09:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:09:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:09:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:09:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:09:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:09:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:09:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:09:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:09:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:09:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:09:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:09:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:09:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:10:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:10:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:10:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:10:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:10:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:10:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:10:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:10:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:10:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:10:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:10:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:10:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:10:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:10:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:10:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:10:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:10:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:11:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:11:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:11:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:11:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:11:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:11:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:11:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:11:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:11:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:11:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:11:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:11:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:11:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:11:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:11:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:11:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:11:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:12:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:12:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:12:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:12:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:12:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:12:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:12:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:12:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:12:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:12:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:12:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:12:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:12:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:12:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:12:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:12:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:13:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:13:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:13:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:13:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:13:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:13:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:13:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:13:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:13:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:13:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:13:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:13:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:13:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:13:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:13:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:13:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:13:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:14:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:14:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:14:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:14:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:14:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:14:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:14:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:14:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:14:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:14:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:14:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:14:41 2022 =-=-=-=-=\n"
     ]
    }
   ],
   "source": [
    "result.m02.2 <- my.tsCV(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                        xreg=trainx[,2:4], \n",
    "                        silent=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb72044a-8da0-45cc-8d68-0119fe090cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-02-09\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m02.2\n",
    "from <- x[!is.na(x[,'forecast_start']),][,1][1]\n",
    "from <- index(trainx[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc2e74d7-8d59-4a62-be63-137bc65d7e26",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:14:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:14:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:14:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:14:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:14:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:15:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:15:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:15:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:15:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:15:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:15:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:15:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:15:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:15:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:15:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:15:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:15:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:15:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:15:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:15:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:15:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:16:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:16:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:16:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:16:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:16:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:16:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:16:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:16:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:16:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:16:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:16:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:16:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:16:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:16:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:16:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:16:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:16:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:17:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:17:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:17:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:17:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:17:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:17:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:17:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:17:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:17:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:17:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:17:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:17:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:17:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:17:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:17:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:17:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:18:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:18:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:18:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:18:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:18:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:18:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:18:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:18:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:18:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:18:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:18:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:18:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:18:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:18:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:18:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:18:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:18:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:19:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:19:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:19:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:19:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:19:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:19:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:19:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:19:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:19:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:19:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:19:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:19:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:19:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:19:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:19:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:19:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:19:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:20:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:20:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:20:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:20:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:20:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:20:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:20:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:20:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:20:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:20:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:20:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:20:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:20:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:20:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:20:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:20:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:21:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:21:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:21:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:21:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:21:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:21:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:21:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:21:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:21:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:21:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:21:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:21:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:21:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:21:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:21:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:21:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:21:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:22:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:22:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:22:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:22:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:22:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:22:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:22:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:22:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:22:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:22:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:22:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:22:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:22:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:22:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:22:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:22:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:22:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:23:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:23:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:23:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:23:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:23:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:23:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:23:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:23:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:23:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:23:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:23:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:23:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:23:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:23:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:23:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:23:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:24:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:24:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:24:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:24:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:24:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:24:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:24:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:24:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:24:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:24:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:24:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:24:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:24:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:24:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:24:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:24:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:24:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:25:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:25:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:25:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:25:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:25:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:25:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:25:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:25:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:25:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:25:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:25:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:25:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:25:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:25:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:25:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:25:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:25:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:26:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:26:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:26:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:26:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:26:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:26:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:26:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:26:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:26:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:26:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:26:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:26:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:26:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:26:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:26:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:26:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:27:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:27:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:27:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:27:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:27:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:27:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:27:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:27:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:27:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:27:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:27:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:27:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:27:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:27:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:27:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:27:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:27:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:28:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:28:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:28:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:28:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:28:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:28:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:28:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:28:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:28:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:28:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:28:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:28:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:28:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:28:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:28:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:28:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:29:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:29:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:29:07 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:29:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:29:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:29:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:29:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:29:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:29:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:29:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:29:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:29:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:29:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:29:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:29:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:29:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:29:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:30:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:30:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:30:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:30:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:30:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:30:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:30:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:30:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:30:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:30:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:30:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:30:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:30:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:30:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:30:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:30:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:30:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:31:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:31:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:31:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:31:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:31:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:31:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:31:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:31:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:31:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:31:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:31:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:31:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:31:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:31:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:31:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:31:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:32:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:32:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:32:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:32:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:32:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:32:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:32:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:32:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:32:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:32:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:32:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:32:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:32:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:32:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:32:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:32:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:32:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:33:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:33:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:33:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:33:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:33:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:33:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:33:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:33:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:33:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:33:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:33:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:33:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:33:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:33:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:33:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:33:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:34:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:34:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:34:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:34:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:34:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:34:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:34:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:34:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:34:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:34:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:34:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:34:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:34:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:34:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:34:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:34:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:34:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:35:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:35:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:35:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:35:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:35:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:35:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:35:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:35:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:35:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:35:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:35:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:35:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:35:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:35:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:35:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:35:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:35:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:36:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:36:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:36:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:36:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:36:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:36:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:36:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:36:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:36:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:36:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:36:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:36:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:36:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:36:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:36:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:36:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:37:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:37:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:37:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:37:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:37:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:37:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:37:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:37:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:37:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:37:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:37:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:37:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:37:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:37:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:37:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:37:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:37:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:38:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:38:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:38:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:38:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:38:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:38:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:38:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:38:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:38:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:38:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:38:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:38:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:38:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:38:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:38:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:38:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:38:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:39:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:39:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:39:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:39:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:39:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:39:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:39:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:39:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:39:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:39:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:39:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:39:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:39:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:39:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:39:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:39:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:40:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:40:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:40:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:40:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:40:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:40:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:40:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:40:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:40:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:40:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:40:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:40:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:40:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:40:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:40:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:40:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:40:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:41:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:41:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:41:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:41:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:41:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:41:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:41:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:41:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:41:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:41:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:41:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:41:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:41:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:41:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:41:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:41:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:41:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:42:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:42:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:42:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:42:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:42:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:42:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:42:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:42:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:42:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:42:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:42:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:42:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:42:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:42:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:42:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:42:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:43:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:43:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:43:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:43:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:43:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:43:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:43:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:43:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:43:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:43:32 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:43:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:43:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:43:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:43:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:43:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:43:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:43:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:44:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:44:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:44:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:44:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:44:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:44:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:44:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:44:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:44:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:44:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:44:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:44:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:44:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:44:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:44:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:44:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:44:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:45:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:45:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:45:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:45:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:45:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:45:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:45:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:45:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:45:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:45:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:45:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:45:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:45:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:45:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:45:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:45:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:46:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:46:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:46:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:46:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:46:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:46:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:46:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:46:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:46:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:46:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:46:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:46:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:46:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:46:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:46:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:46:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:46:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:47:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:47:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:47:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:47:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:47:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:47:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:47:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:47:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:47:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:47:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:47:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:47:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:47:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:47:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:47:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:47:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:48:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:48:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:48:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:48:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:48:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:48:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:48:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:48:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:48:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:48:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:48:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:48:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:48:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:48:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:48:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:48:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:48:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:49:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:49:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:49:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:49:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:49:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:49:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:49:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:49:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:49:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:49:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:49:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:49:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:49:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:49:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:49:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:49:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:49:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:50:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:50:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:50:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:50:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:50:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:50:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:50:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:50:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:50:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:50:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:50:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:50:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:50:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:50:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:50:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:50:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:50:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:51:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:51:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:51:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:51:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:51:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:51:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:51:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:51:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:51:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:51:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:51:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:51:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:51:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:51:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:51:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:51:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:52:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:52:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:52:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:52:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:52:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:52:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:52:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:52:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:52:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:52:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:52:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:52:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:52:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:52:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:52:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:52:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:52:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:53:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:53:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:53:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:53:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:53:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:53:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:53:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:53:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:53:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:53:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:53:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:53:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:53:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:53:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:53:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:53:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:54:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:54:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:54:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:54:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:54:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:54:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:54:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:54:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:54:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:54:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:54:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:54:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:54:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:54:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:54:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:54:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:54:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:55:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:55:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:55:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:55:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:55:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:55:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:55:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:55:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:55:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:55:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:55:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:55:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:55:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:55:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:55:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:55:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:55:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:56:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:56:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:56:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:56:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:56:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:56:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:56:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:56:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:56:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:56:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:56:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:56:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:56:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:56:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:56:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:56:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:57:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:57:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:57:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:57:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:57:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:57:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:57:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:57:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:57:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:57:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:57:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:57:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:57:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:57:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:57:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:57:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:57:58 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:58:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:58:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:58:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:58:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:58:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:58:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:58:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:58:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:58:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:58:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:58:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:58:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:58:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:58:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:58:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:58:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:58:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:59:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:59:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:59:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:59:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:59:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:59:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:59:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:59:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:59:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:59:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:59:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:59:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:59:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:59:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:59:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:59:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:00:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:00:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:00:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:00:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:00:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:00:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:00:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:00:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:00:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:00:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:00:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:00:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:00:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:00:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:00:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:00:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:00:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:01:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:01:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:01:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:01:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:01:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:01:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:01:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:01:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:01:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:01:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:01:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:01:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:01:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:01:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:01:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:01:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:02:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:02:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:02:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:02:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:02:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:02:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:02:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:02:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:02:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:02:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:02:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:02:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:02:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:02:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:02:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:02:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:02:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:03:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:03:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:03:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:03:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:03:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:03:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:03:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:03:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:03:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:03:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:03:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:03:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:03:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:03:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:03:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:03:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:03:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:04:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:04:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:04:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:04:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:04:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:04:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:04:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:04:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:04:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:04:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:04:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:04:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:04:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:04:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:04:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:04:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:05:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:05:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:05:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:05:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:05:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:05:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:05:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:05:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:05:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:05:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:05:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:05:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:05:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:05:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:05:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:05:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:05:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:06:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:06:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:06:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:06:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:06:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:06:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:06:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:06:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:06:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:06:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:06:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:06:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:06:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:06:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:06:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:06:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:06:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:07:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:07:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:07:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:07:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:07:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:07:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:07:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:07:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:07:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:07:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:07:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:07:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:07:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:07:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:07:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:07:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:08:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:08:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:08:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:08:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:08:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:08:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:08:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:08:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:08:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:08:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:08:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:08:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:08:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:08:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:08:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:08:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:08:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:09:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:09:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:09:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:09:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:09:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:09:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:09:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:09:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:09:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:09:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:09:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:09:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:09:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:09:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:09:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:09:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:10:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:10:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:10:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:10:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:10:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:10:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:10:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:10:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:10:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:10:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:10:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:10:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:10:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:10:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:10:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:10:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:10:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:11:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:11:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:11:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:11:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:11:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:11:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:11:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:11:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:11:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:11:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:11:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:11:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:11:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:11:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:11:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:11:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:11:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:12:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:12:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:12:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:12:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:12:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:12:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:12:24 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:12:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:12:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:12:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:12:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:12:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:12:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:12:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:12:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:12:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:13:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:13:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:13:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:13:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:13:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:13:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:13:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:13:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:13:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:13:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:13:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:13:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:13:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:13:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:13:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:13:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:13:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:14:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:14:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:14:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:14:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:14:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:14:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:14:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:14:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:14:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:14:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:14:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:14:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:14:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:14:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:14:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:14:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:15:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:15:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:15:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:15:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:15:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:15:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:15:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:15:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:15:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:15:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:15:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:15:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:15:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:15:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:15:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:15:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:15:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:16:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:16:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:16:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:16:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:16:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:16:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:16:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:16:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:16:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:16:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:16:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:16:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:16:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:16:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:16:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:16:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:17:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:17:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:17:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:17:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:17:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:17:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:17:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:17:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:17:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:17:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:17:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:17:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:17:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:17:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:17:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:17:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:17:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:18:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:18:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:18:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:18:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:18:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:18:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:18:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:18:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:18:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:18:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:18:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:18:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:18:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:18:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:18:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:18:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:18:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:19:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:19:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:19:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:19:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:19:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:19:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:19:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:19:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:19:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:19:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:19:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:19:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:19:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:19:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:19:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:19:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:20:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:20:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:20:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:20:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:20:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:20:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:20:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:20:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:20:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:20:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:20:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:20:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:20:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:20:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:20:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:20:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:20:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:21:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:21:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:21:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:21:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:21:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:21:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:21:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:21:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:21:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:21:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:21:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:21:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:21:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:21:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:21:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:21:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:21:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:22:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:22:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:22:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:22:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:22:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:22:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:22:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:22:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:22:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:22:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:22:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:22:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:22:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:22:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:22:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:22:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:23:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:23:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:23:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:23:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:23:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:23:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:23:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:23:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:23:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:23:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:23:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:23:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:23:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:23:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:23:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:23:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:23:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:24:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:24:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:24:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:24:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:24:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:24:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:24:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:24:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:24:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:24:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:24:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:24:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:24:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:24:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:24:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:24:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:25:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:25:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:25:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:25:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:25:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:25:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:25:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:25:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:25:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:25:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:25:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:25:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:25:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:25:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:25:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:25:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:25:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:26:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:26:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:26:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:26:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:26:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:26:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:26:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:26:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:26:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:26:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:26:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:26:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:26:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:26:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:26:51 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:26:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:26:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:27:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:27:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:27:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:27:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:27:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:27:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:27:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:27:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:27:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:27:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:27:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:27:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:27:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:27:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:27:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:27:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:28:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:28:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:28:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:28:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:28:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:28:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:28:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:28:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:28:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:28:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:28:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:28:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:28:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:28:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:28:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:28:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:28:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:29:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:29:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:29:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:29:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:29:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:29:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:29:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:29:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:29:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:29:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:29:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:29:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:29:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:29:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:29:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:29:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:29:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:30:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:30:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:30:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:30:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:30:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:30:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:30:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:30:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:30:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:30:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:30:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:30:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:30:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:30:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:30:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:30:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:31:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:31:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:31:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:31:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:31:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:31:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:31:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:31:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:31:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:31:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:31:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:31:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:31:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:31:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:31:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:31:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:31:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:32:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:32:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:32:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:32:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:32:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:32:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:32:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:32:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:32:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:32:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:32:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:32:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:32:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:32:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:32:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:32:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:32:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:33:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:33:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:33:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:33:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:33:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:33:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:33:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:33:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:33:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:33:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:33:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:33:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:33:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:33:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:33:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:33:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:34:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:34:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:34:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:34:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:34:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:34:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:34:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:34:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:34:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:34:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:34:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:34:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:34:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:34:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:34:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:34:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:34:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:35:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:35:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:35:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:35:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:35:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:35:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:35:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:35:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:35:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:35:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:35:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:35:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:35:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:35:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:35:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:35:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:36:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:36:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:36:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:36:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:36:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:36:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:36:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:36:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:36:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:36:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:36:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:36:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:36:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:36:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:36:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:36:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:36:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:37:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:37:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:37:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:37:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:37:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:37:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:37:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:37:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:37:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:37:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:37:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:37:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:37:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:37:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:37:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:37:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:37:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:38:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:38:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:38:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:38:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:38:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:38:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:38:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:38:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:38:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:38:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:38:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:38:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:38:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:38:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:38:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:38:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:39:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:39:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:39:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:39:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:39:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:39:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:39:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:39:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:39:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:39:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:39:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:39:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:39:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:39:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:39:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:39:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:39:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:40:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:40:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:40:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:40:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:40:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:40:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:40:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:40:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:40:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:40:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:40:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:40:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:40:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:40:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:40:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:40:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:41:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:41:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:41:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:41:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:41:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:41:19 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:41:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:41:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:41:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:41:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:41:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:41:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:41:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:41:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:41:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:41:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:41:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:42:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:42:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:42:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:42:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:42:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:42:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:42:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:42:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:42:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:42:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:42:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:42:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:42:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:42:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:42:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:42:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:43:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:43:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:43:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:43:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:43:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:43:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:43:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:43:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:43:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:43:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:43:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:43:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:43:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:43:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:43:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:43:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:43:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:44:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:44:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:44:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:44:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:44:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:44:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:44:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:44:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:44:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:44:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:44:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:44:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:44:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:44:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:44:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:44:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:45:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:45:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:45:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:45:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:45:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:45:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:45:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:45:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:45:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:45:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:45:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:45:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:45:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:45:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:45:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:45:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:45:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:46:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:46:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:46:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:46:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:46:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:46:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:46:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:46:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:46:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:46:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:46:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:46:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:46:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:46:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:46:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:46:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:46:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:47:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:47:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:47:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:47:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:47:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:47:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:47:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:47:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:47:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:47:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:47:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:47:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:47:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:47:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:47:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:47:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:48:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:48:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:48:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:48:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:48:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:48:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:48:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:48:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:48:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:48:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:48:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:48:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:48:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:48:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:48:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:48:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:48:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:49:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:49:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:49:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:49:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:49:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:49:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:49:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:49:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:49:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:49:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:49:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:49:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:49:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:49:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:49:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:49:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:50:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:50:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:50:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:50:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:50:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:50:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:50:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:50:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:50:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:50:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:50:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:50:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:50:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:50:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:50:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:50:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:50:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:51:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:51:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:51:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:51:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:51:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:51:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:51:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:51:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:51:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:51:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:51:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:51:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:51:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:51:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:51:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:51:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:51:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:52:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:52:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:52:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:52:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:52:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:52:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:52:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:52:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:52:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:52:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:52:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:52:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:52:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:52:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:52:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:52:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:53:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:53:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:53:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:53:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:53:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:53:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:53:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:53:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:53:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:53:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:53:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:53:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:53:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:53:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:53:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:53:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:53:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:54:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:54:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:54:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:54:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:54:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:54:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:54:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:54:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:54:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:54:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:54:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:54:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:54:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:54:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:54:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:54:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:55:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:55:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:55:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:55:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:55:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:55:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:55:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:55:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:55:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:55:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:55:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:55:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:55:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:55:47 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:55:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:55:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:55:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:56:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:56:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:56:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:56:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:56:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:56:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:56:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:56:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:56:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:56:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:56:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:56:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:56:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:56:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:56:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:56:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:56:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:57:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:57:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:57:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:57:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:57:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:57:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:57:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:57:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:57:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:57:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:57:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:57:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:57:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:57:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:57:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:57:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:58:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:58:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:58:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:58:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:58:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:58:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:58:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:58:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:58:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:58:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:58:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:58:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:58:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:58:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:58:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:58:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:58:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:59:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:59:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:59:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:59:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:59:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:59:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:59:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:59:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:59:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:59:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:59:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:59:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:59:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:59:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:59:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:59:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:59:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:00:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:00:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:00:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:00:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:00:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:00:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:00:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:00:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:00:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:00:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:00:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:00:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:00:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:00:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:00:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:00:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:01:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:01:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:01:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:01:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:01:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:01:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:01:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:01:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:01:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:01:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:01:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:01:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:01:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:01:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:01:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:01:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:01:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:02:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:02:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:02:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:02:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:02:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:02:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:02:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:02:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:02:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:02:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:02:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:02:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:02:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:02:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:02:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:02:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:03:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:03:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:03:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:03:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:03:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:03:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:03:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:03:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:03:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:03:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:03:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:03:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:03:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:03:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:03:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:03:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:03:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:04:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:04:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:04:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:04:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:04:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:04:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:04:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:04:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:04:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:04:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:04:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:04:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:04:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:04:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:04:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:04:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:04:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:05:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:05:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:05:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:05:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:05:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:05:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:05:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:05:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:05:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:05:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:05:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:05:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:05:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:05:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:05:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:05:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:06:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:06:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:06:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:06:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:06:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:06:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:06:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:06:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:06:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:06:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:06:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:06:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:06:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:06:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:06:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:06:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:06:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:07:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:07:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:07:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:07:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:07:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:07:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:07:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:07:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:07:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:07:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:07:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:07:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:07:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:07:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:07:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:07:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:07:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:08:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:08:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:08:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:08:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:08:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:08:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:08:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:08:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:08:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:08:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:08:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:08:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:08:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:08:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:08:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:08:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:08:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:09:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:09:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:09:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:09:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:09:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:09:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:09:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:09:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:09:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:09:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:09:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:09:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:09:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:09:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:09:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:09:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:10:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:10:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:10:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:10:12 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:10:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:10:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:10:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:10:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:10:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:10:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:10:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:10:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:10:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:10:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:10:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:10:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:10:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:11:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:11:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:11:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:11:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:11:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:11:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:11:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:11:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:11:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:11:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:11:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:11:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:11:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:11:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:11:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:11:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:12:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:12:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:12:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:12:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:12:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:12:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:12:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:12:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:12:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:12:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:12:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:12:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:12:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:12:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:12:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:12:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:12:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:13:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:13:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:13:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:13:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:13:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:13:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:13:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:13:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:13:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:13:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:13:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:13:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:13:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:13:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:13:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:13:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:14:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:14:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:14:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:14:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:14:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:14:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:14:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:14:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:14:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:14:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:14:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:14:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:14:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:14:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:14:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:14:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:14:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:15:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:15:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:15:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:15:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:15:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:15:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:15:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:15:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:15:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:15:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:15:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:15:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:15:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:15:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:15:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:15:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:15:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:16:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:16:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:16:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:16:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:16:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:16:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:16:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:16:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:16:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:16:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:16:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:16:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:16:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:16:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:16:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:16:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:17:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:17:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:17:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:17:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:17:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:17:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:17:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:17:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:17:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:17:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:17:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:17:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:17:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:17:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:17:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:17:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:17:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:18:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:18:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:18:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:18:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:18:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:18:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:18:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:18:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:18:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:18:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:18:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:18:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:18:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:18:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:18:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:18:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:18:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:19:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:19:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:19:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:19:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:19:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:19:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:19:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:19:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:19:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:19:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:19:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:19:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:19:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:19:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:19:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:19:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:20:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:20:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:20:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:20:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:20:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:20:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:20:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:20:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:20:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:20:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:20:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:20:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:20:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:20:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:20:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:20:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:20:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:21:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:21:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:21:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:21:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:21:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:21:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:21:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:21:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:21:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:21:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:21:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:21:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:21:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:21:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:21:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:21:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:22:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:22:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:22:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:22:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:22:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:22:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:22:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:22:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:22:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:22:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:22:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:22:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:22:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:22:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:22:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:22:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:22:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:23:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:23:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:23:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:23:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:23:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:23:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:23:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:23:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:23:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:23:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:23:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:23:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:23:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:23:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:23:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:23:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:23:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:24:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:24:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:24:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:24:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:24:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:24:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:24:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:24:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:24:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:24:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:24:38 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:24:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:24:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:24:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:24:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:24:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:25:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:25:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:25:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:25:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:25:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:25:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:25:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:25:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:25:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:25:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:25:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:25:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:25:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:25:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:25:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:25:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:25:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:26:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:26:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:26:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:26:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:26:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:26:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:26:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:26:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:26:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:26:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:26:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:26:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:26:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:26:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:26:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:26:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:26:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:27:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:27:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:27:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:27:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:27:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:27:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:27:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:27:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:27:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:27:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:27:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:27:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:27:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:27:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:27:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:27:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:28:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:28:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:28:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:28:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:28:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:28:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:28:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:28:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:28:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:28:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:28:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:28:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:28:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:28:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:28:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:28:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:28:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:29:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:29:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:29:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:29:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:29:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:29:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:29:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:29:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:29:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:29:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:29:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:29:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:29:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:29:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:29:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:29:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:30:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:30:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:30:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:30:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:30:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:30:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:30:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:30:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:30:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:30:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:30:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:30:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:30:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:30:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:30:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:30:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:30:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:31:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:31:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:31:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:31:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:31:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:31:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:31:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:31:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:31:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:31:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:31:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:31:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:31:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:31:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:31:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:31:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:31:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:32:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:32:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:32:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:32:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:32:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:32:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:32:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:32:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:32:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:32:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:32:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:32:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:32:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:32:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:32:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:32:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:33:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:33:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:33:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:33:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:33:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:33:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:33:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:33:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:33:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:33:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:33:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:33:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:33:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:33:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:33:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:33:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:33:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:34:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:34:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:34:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:34:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:34:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:34:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:34:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:34:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:34:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:34:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:34:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:34:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:34:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:34:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:34:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:34:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:35:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:35:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:35:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:35:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:35:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:35:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:35:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:35:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:35:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:35:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:35:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:35:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:35:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:35:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:35:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:35:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:35:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:36:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:36:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:36:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:36:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:36:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:36:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:36:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:36:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:36:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:36:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:36:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:36:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:36:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:36:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:36:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:36:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:36:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:37:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:37:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:37:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:37:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:37:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:37:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:37:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:37:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:37:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:37:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:37:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:37:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:37:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:37:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:37:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:37:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:38:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:38:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:38:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:38:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:38:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:38:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:38:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:38:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:38:29 2022 =-=-=-=-=\n"
     ]
    }
   ],
   "source": [
    "result.m02.3 <- my.tsCV(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                        xreg=trainx[,2:4], silent=F,\n",
    "                        xreg.msize=hori)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc65fefd-60b9-4ab4-a840-d24018cef2fc",
   "metadata": {},
   "source": [
    "## Compare Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58355e11-c950-44f5-b241-665c8d6aa2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my.figsize(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f874535-9c29-405a-add4-9bbce090b23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94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\nAACgUgRCAAAAAFCp/wemoMO+1E4JJwAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- new.get_result(result.m02.1, '1.BSTS')\n",
    "errors.2 <- new.get_result(result.m02.2, '2.BSTS w/ Regressors')\n",
    "errors.3 <- new.get_result(result.m02.3, '3.BSTS w/ Regressors (2)')\n",
    "\n",
    "#x <- errors.1\n",
    "x <- rbind(errors.1, errors.2)\n",
    "x <- rbind(x, errors.3)\n",
    "\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "78dcd688-1d13-455f-a104-9ce887522de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m02 <- result.m02.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18309db-511c-4dca-aae2-184266480211",
   "metadata": {},
   "source": [
    "### save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90ba8638-887a-4a67-868c-d3612e3556db",
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- result.m02.1\n",
    "write.csv(x, file = \"bsts_result_m0201.csv\")\n",
    "x <- result.m02.2\n",
    "write.csv(x, file = \"bsts_result_m0202.csv\")\n",
    "x <- result.m02.3\n",
    "write.csv(x, file = \"bsts_result_m0203.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d128253-162e-4222-b582-fb0ee3ef80e7",
   "metadata": {},
   "source": [
    "### load result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bb1bd39-9ed6-4fb6-8abe-4d35c9b83632",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.m02.1 <- read.csv(file = 'bsts_result_m0201.csv')\n",
    "result.m02.2 <- read.csv(file = 'bsts_result_m0202.csv')\n",
    "result.m02.3 <- read.csv(file = 'bsts_result_m0203.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69617942-9647-4c39-9fab-68b25004a5f6",
   "metadata": {},
   "source": [
    "# ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714a4470-8e12-439a-b2ef-3b3e4d106e65",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1649827c-2f89-40f9-939c-5a35daceab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast <- function(x, h, xreg=NULL, xreg.msize=NULL, order=NULL) {\n",
    "    \n",
    "    if (!is.null(xreg)) {\n",
    "        \n",
    "        if (is.null(xreg.msize)) {\n",
    "            xreg.m <- xreg # calc mean for future with all the xreg\n",
    "        } else {\n",
    "            # calc mean for future with xreg of length xreg.mszie\n",
    "            xreg.m <- tail(xreg, n=xreg.msize)\n",
    "        }\n",
    "        \n",
    "        if (is.null(dim(xreg))) {\n",
    "            xreg.h <- mean(xreg.m)\n",
    "        } else {\n",
    "            xreg.h <- colMeans(xreg.m)  \n",
    "        }\n",
    "        \n",
    "        xreg.h <- data.frame(xreg.h)\n",
    "        colnames(xreg.h) <- colnames(NA)\n",
    "        #colnames(xreg.h) <- colnames(xreg) # error with multiple xreg\n",
    "        xreg.h <- t(xreg.h)\n",
    "        xreg.h <- as.ts(xreg.h[rep(seq_len(nrow(xreg.h)), h), ])\n",
    "        \n",
    "        ## added for single day forecast\n",
    "        xreg.coln <- colnames(xreg)\n",
    "        xreg.h <- data.frame(xreg.h) # convert to frame for the case of single xreg\n",
    "        if ((dim(xreg.h)[2]==1) & (dim(xreg.h)[1]==length(xreg.coln))) {\n",
    "            xreg.h <- t(xreg.h) # the case of h==1\n",
    "        } else {\n",
    "            xreg.h <- as.ts(xreg.h) # convert to ts as xreg is ts\n",
    "        }\n",
    "        \n",
    "    } else {\n",
    "        xreg.h <- NULL\n",
    "    }\n",
    "    if (is.null(order)) {\n",
    "        fc <- forecast(auto.arima(x, trace=TRUE, ic='aicc', seasonal=FALSE, \n",
    "                                  xreg=xreg, \n",
    "                                  #lambda=\"auto\" # not for negative value\n",
    "                                  ), h=h, xreg=xreg.h)\n",
    "    } else {\n",
    "        fc <- forecast(Arima(x, order=order, seasonal=FALSE, \n",
    "                                  xreg=xreg, \n",
    "                                  ), h=h, xreg=xreg.h)\n",
    "    }\n",
    "    return(fc)\n",
    "}\n",
    "\n",
    "arima.forecast <- cv.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1de1569-7395-4fe7-99a4-f041baf77365",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast.2 <- function(x, h, ...) {\n",
    "    new.forecast(x, h, cv.forecast, ...)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0145d7-e293-4fdd-8dbb-f62c0d26e658",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b05b4a06-7253-42c9-b6f0-28b182f99b79",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -8729.901\n",
      " ARIMA(1,0,0) with non-zero mean : -13486.9\n",
      " ARIMA(0,0,1) with non-zero mean : -10820.55\n",
      " ARIMA(0,0,0) with zero mean     : -8407.697\n",
      " ARIMA(2,0,0) with non-zero mean : -13491.63\n",
      " ARIMA(3,0,0) with non-zero mean : -13491.75\n",
      " ARIMA(4,0,0) with non-zero mean : -13496.44\n",
      " ARIMA(5,0,0) with non-zero mean : -13502.01\n",
      " ARIMA(5,0,1) with non-zero mean : -13509.96\n",
      " ARIMA(4,0,1) with non-zero mean : -13504.29\n",
      " ARIMA(5,0,2) with non-zero mean : -13507.99\n",
      " ARIMA(4,0,2) with non-zero mean : -13508.66\n",
      " ARIMA(5,0,1) with zero mean     : -13497.02\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,1) with non-zero mean : -13497.21\n",
      "\n",
      " Best model: ARIMA(5,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -13377.54\n",
      " ARIMA(1,1,0) with drift         : -13378.28\n",
      " ARIMA(0,1,1) with drift         : -13376.14\n",
      " ARIMA(0,1,0)                    : -13379.49\n",
      " ARIMA(1,1,1) with drift         : -13377.51\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -13388.23\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -13351.94\n",
      " ARIMA(0,1,0) with drift         : -13329.65\n",
      " ARIMA(1,1,0) with drift         : -13329.34\n",
      " ARIMA(0,1,1) with drift         : -13328.48\n",
      " ARIMA(0,1,0)                    : -13331.64\n",
      " ARIMA(1,1,2) with drift         : -13333.18\n",
      " ARIMA(2,1,1) with drift         : -13367.24\n",
      " ARIMA(1,1,1) with drift         : -13327.34\n",
      " ARIMA(2,1,0) with drift         : -13329.21\n",
      " ARIMA(3,1,1) with drift         : -13330.64\n",
      " ARIMA(3,1,0) with drift         : -13332.29\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1)                    : -13368.81\n",
      " ARIMA(1,1,1)                    : -13329.32\n",
      " ARIMA(2,1,0)                    : -13331.19\n",
      " ARIMA(3,1,1)                    : -13332.67\n",
      " ARIMA(2,1,2)                    : -13353.95\n",
      " ARIMA(1,1,0)                    : -13331.32\n",
      " ARIMA(1,1,2)                    : -13348.06\n",
      " ARIMA(3,1,0)                    : -13334.28\n",
      " ARIMA(3,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,1)                    : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -13393.73\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -13234.71\n",
      " ARIMA(1,1,0) with drift         : -13232.87\n",
      " ARIMA(0,1,1) with drift         : -13233.97\n",
      " ARIMA(0,1,0)                    : -13236.7\n",
      " ARIMA(1,1,1) with drift         : -13231.87\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -13245.39\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13263.35\n",
      " ARIMA(0,0,0) with non-zero mean : -8706.059\n",
      " ARIMA(1,0,0) with non-zero mean : -13255.84\n",
      " ARIMA(0,0,1) with non-zero mean : -10773.99\n",
      " ARIMA(0,0,0) with zero mean     : -8448.555\n",
      " ARIMA(1,0,2) with non-zero mean : -13260.91\n",
      " ARIMA(2,0,1) with non-zero mean : -13259.89\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -13259.02\n",
      " ARIMA(1,0,1) with non-zero mean : -13262.92\n",
      " ARIMA(1,0,3) with non-zero mean : -13261.08\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -13255.47\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13263\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13234.55\n",
      " ARIMA(0,0,0) with non-zero mean : -8691.834\n",
      " ARIMA(1,0,0) with non-zero mean : -13229.55\n",
      " ARIMA(0,0,1) with non-zero mean : -10751.25\n",
      " ARIMA(0,0,0) with zero mean     : -8433.02\n",
      " ARIMA(1,0,2) with non-zero mean : -13235.37\n",
      " ARIMA(0,0,2) with non-zero mean : -11866.88\n",
      " ARIMA(1,0,1) with non-zero mean : -13237.32\n",
      " ARIMA(2,0,1) with non-zero mean : -13225.93\n",
      " ARIMA(2,0,0) with non-zero mean : -13237.39\n",
      " ARIMA(3,0,0) with non-zero mean : -13234.61\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(2,0,0) with zero mean     : -13228.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,0) with non-zero mean : -13235.12\n",
      "\n",
      " Best model: ARIMA(2,0,0) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13226.64\n",
      " ARIMA(0,0,0) with non-zero mean : -8693.681\n",
      " ARIMA(1,0,0) with non-zero mean : -13220.86\n",
      " ARIMA(0,0,1) with non-zero mean : -10750.64\n",
      " ARIMA(0,0,0) with zero mean     : -8430.203\n",
      " ARIMA(1,0,2) with non-zero mean : -13226.25\n",
      " ARIMA(2,0,1) with non-zero mean : -13226.06\n",
      " ARIMA(3,0,2) with non-zero mean : -13309.63\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -13307.61\n",
      " ARIMA(2,0,3) with non-zero mean : -13226.59\n",
      " ARIMA(4,0,1) with non-zero mean : -13224.04\n",
      " ARIMA(4,0,3) with non-zero mean : -13224.26\n",
      " ARIMA(3,0,2) with zero mean     : -13300.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,2) with non-zero mean : -13225.89\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13223.46\n",
      " ARIMA(0,0,0) with non-zero mean : -8692.073\n",
      " ARIMA(1,0,0) with non-zero mean : -13216.09\n",
      " ARIMA(0,0,1) with non-zero mean : -10746.36\n",
      " ARIMA(0,0,0) with zero mean     : -8438.64\n",
      " ARIMA(1,0,2) with non-zero mean : -13219.99\n",
      " ARIMA(2,0,1) with non-zero mean : -13219.26\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -13218.58\n",
      " ARIMA(1,0,1) with non-zero mean : -13221.81\n",
      " ARIMA(1,0,3) with non-zero mean : -13219.71\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -13215.75\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13222.6\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -8686.987\n",
      " ARIMA(1,0,0) with non-zero mean : -13209.96\n",
      " ARIMA(0,0,1) with non-zero mean : -10738.7\n",
      " ARIMA(0,0,0) with zero mean     : -8426.26\n",
      " ARIMA(2,0,0) with non-zero mean : -13214.47\n",
      " ARIMA(3,0,0) with non-zero mean : -13211.74\n",
      " ARIMA(2,0,1) with non-zero mean : -13212.45\n",
      " ARIMA(1,0,1) with non-zero mean : -13215.28\n",
      " ARIMA(1,0,2) with non-zero mean : -13213.51\n",
      " ARIMA(0,0,2) with non-zero mean : -11840.92\n",
      " ARIMA(1,0,1) with zero mean     : -13207.44\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -13213.63\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13183.35\n",
      " ARIMA(0,0,0) with non-zero mean : -8605.008\n",
      " ARIMA(1,0,0) with non-zero mean : -13178.74\n",
      " ARIMA(0,0,1) with non-zero mean : -10671.87\n",
      " ARIMA(0,0,0) with zero mean     : -8372.744\n",
      " ARIMA(1,0,2) with non-zero mean : -13181.28\n",
      " ARIMA(2,0,1) with non-zero mean : -13180.26\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -13179.48\n",
      " ARIMA(1,0,1) with non-zero mean : -13183.22\n",
      " ARIMA(1,0,3) with non-zero mean : -13180.78\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -13173.21\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13183.36\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13157.75\n",
      " ARIMA(0,0,0) with non-zero mean : -8599.633\n",
      " ARIMA(1,0,0) with non-zero mean : -13156.4\n",
      " ARIMA(0,0,1) with non-zero mean : -10657.5\n",
      " ARIMA(0,0,0) with zero mean     : -8371.167\n",
      " ARIMA(1,0,2) with non-zero mean : -13159.03\n",
      " ARIMA(0,0,2) with non-zero mean : -11765.46\n",
      " ARIMA(1,0,1) with non-zero mean : -13161.04\n",
      " ARIMA(2,0,1) with non-zero mean : -13159.02\n",
      " ARIMA(2,0,0) with non-zero mean : -13160.94\n",
      " ARIMA(1,0,1) with zero mean     : -13153.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -13157.39\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13118.41\n",
      " ARIMA(0,0,0) with non-zero mean : -8582.353\n",
      " ARIMA(1,0,0) with non-zero mean : -13116.65\n",
      " ARIMA(0,0,1) with non-zero mean : -10629.58\n",
      " ARIMA(0,0,0) with zero mean     : -8368.258\n",
      " ARIMA(1,0,2) with non-zero mean : -13119.21\n",
      " ARIMA(0,0,2) with non-zero mean : -11723.45\n",
      " ARIMA(1,0,1) with non-zero mean : -13121.15\n",
      " ARIMA(2,0,1) with non-zero mean : -13118.75\n",
      " ARIMA(2,0,0) with non-zero mean : -13120.42\n",
      " ARIMA(1,0,1) with zero mean     : -13115.91\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -13113.39\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13071.29\n",
      " ARIMA(0,0,0) with non-zero mean : -8638.881\n",
      " ARIMA(1,0,0) with non-zero mean : -13070.54\n",
      " ARIMA(0,0,1) with non-zero mean : -10684.56\n",
      " ARIMA(0,0,0) with zero mean     : -8450.488\n",
      " ARIMA(1,0,2) with non-zero mean : -13073.57\n",
      " ARIMA(0,0,2) with non-zero mean : -11760.84\n",
      " ARIMA(1,0,1) with non-zero mean : -13074.77\n",
      " ARIMA(2,0,1) with non-zero mean : -13072.43\n",
      " ARIMA(2,0,0) with non-zero mean : -13073.94\n",
      " ARIMA(1,0,1) with zero mean     : -13068.78\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -13073.39\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13020.07\n",
      " ARIMA(0,0,0) with non-zero mean : -8626.698\n",
      " ARIMA(1,0,0) with non-zero mean : -13019.34\n",
      " ARIMA(0,0,1) with non-zero mean : -10666.27\n",
      " ARIMA(0,0,0) with zero mean     : -8430.999\n",
      " ARIMA(1,0,2) with non-zero mean : -13022.74\n",
      " ARIMA(0,0,2) with non-zero mean : -11728.64\n",
      " ARIMA(1,0,1) with non-zero mean : -13023.48\n",
      " ARIMA(2,0,1) with non-zero mean : -13021.47\n",
      " ARIMA(2,0,0) with non-zero mean : -13022.39\n",
      " ARIMA(1,0,1) with zero mean     : -13018.08\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -13022.46\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12895.32\n",
      " ARIMA(1,1,0) with drift         : -12892.39\n",
      " ARIMA(0,1,1) with drift         : -12893.4\n",
      " ARIMA(0,1,0)                    : -12897.3\n",
      " ARIMA(1,1,1) with drift         : -12891.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12905.83\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12860.21\n",
      " ARIMA(0,1,0) with drift         : -12826.47\n",
      " ARIMA(1,1,0) with drift         : -12823.83\n",
      " ARIMA(0,1,1) with drift         : -12824.58\n",
      " ARIMA(0,1,0)                    : -12828.46\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : -12831.77\n",
      " ARIMA(3,1,2) with drift         : -12826.3\n",
      " ARIMA(2,1,3) with drift         : -12865.48\n",
      " ARIMA(1,1,3) with drift         : -12829.73\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : -12864.1\n",
      " ARIMA(1,1,4) with drift         : -12827.86\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -12866.89\n",
      " ARIMA(1,1,3)                    : -12831.68\n",
      " ARIMA(2,1,2)                    : -12861.71\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : -12865.52\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,4)                    : -12829.85\n",
      " ARIMA(3,1,2)                    : -12828.31\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3)                    : -12840.65\n",
      "\n",
      " Best model: ARIMA(1,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -8273.531\n",
      " ARIMA(1,0,0) with non-zero mean : -12881.86\n",
      " ARIMA(0,0,1) with non-zero mean : -10351.3\n",
      " ARIMA(0,0,0) with zero mean     : -8122.831\n",
      " ARIMA(2,0,0) with non-zero mean : -12882.19\n",
      " ARIMA(3,0,0) with non-zero mean : -12880.27\n",
      " ARIMA(2,0,1) with non-zero mean : -12880.5\n",
      " ARIMA(1,0,1) with non-zero mean : -12883.25\n",
      " ARIMA(1,0,2) with non-zero mean : -12881.73\n",
      " ARIMA(0,0,2) with non-zero mean : -11451.56\n",
      " ARIMA(1,0,1) with zero mean     : -12879.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -12882.2\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12871.42\n",
      " ARIMA(0,0,0) with non-zero mean : -8262.48\n",
      " ARIMA(1,0,0) with non-zero mean : -12871.81\n",
      " ARIMA(0,0,1) with non-zero mean : -10340.93\n",
      " ARIMA(0,0,0) with zero mean     : -8109.969\n",
      " ARIMA(2,0,0) with non-zero mean : -12874.6\n",
      " ARIMA(3,0,0) with non-zero mean : -12872.38\n",
      " ARIMA(2,0,1) with non-zero mean : -12873.19\n",
      " ARIMA(1,0,1) with non-zero mean : -12874.05\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(2,0,0) with zero mean     : -12871.34\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,0) with non-zero mean : -12872.16\n",
      "\n",
      " Best model: ARIMA(2,0,0) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12770.64\n",
      " ARIMA(1,1,0) with drift         : -12768.42\n",
      " ARIMA(0,1,1) with drift         : -12768.88\n",
      " ARIMA(0,1,0)                    : -12772.63\n",
      " ARIMA(1,1,1) with drift         : -12767.46\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12781.1\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12763.47\n",
      " ARIMA(1,1,0) with drift         : -12760.68\n",
      " ARIMA(0,1,1) with drift         : -12761.67\n",
      " ARIMA(0,1,0)                    : -12765.47\n",
      " ARIMA(1,1,1) with drift         : -12759.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12773.95\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12720.9\n",
      " ARIMA(1,1,0) with drift         : -12718.16\n",
      " ARIMA(0,1,1) with drift         : -12719.09\n",
      " ARIMA(0,1,0)                    : -12722.86\n",
      " ARIMA(1,1,1) with drift         : -12716.81\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12731.32\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12666.53\n",
      " ARIMA(1,1,0) with drift         : -12663.76\n",
      " ARIMA(0,1,1) with drift         : -12664.79\n",
      " ARIMA(0,1,0)                    : -12668.52\n",
      " ARIMA(1,1,1) with drift         : -12662.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12676.95\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12648.97\n",
      " ARIMA(1,1,0) with drift         : -12646.42\n",
      " ARIMA(0,1,1) with drift         : -12647.47\n",
      " ARIMA(0,1,0)                    : -12650.97\n",
      " ARIMA(1,1,1) with drift         : -12645.43\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12659.4\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12632.45\n",
      " ARIMA(0,1,0) with drift         : -12633.22\n",
      " ARIMA(1,1,0) with drift         : -12630.63\n",
      " ARIMA(0,1,1) with drift         : -12631.67\n",
      " ARIMA(0,1,0)                    : -12635.23\n",
      " ARIMA(1,1,1) with drift         : -12629.76\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12643.64\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12619.17\n",
      " ARIMA(1,1,0) with drift         : -12616.45\n",
      " ARIMA(0,1,1) with drift         : -12617.47\n",
      " ARIMA(0,1,0)                    : -12621.17\n",
      " ARIMA(1,1,1) with drift         : -12615.73\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12629.58\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12599.68\n",
      " ARIMA(1,1,0) with drift         : -12597.63\n",
      " ARIMA(0,1,1) with drift         : -12597.91\n",
      " ARIMA(0,1,0)                    : -12601.68\n",
      " ARIMA(1,1,1) with drift         : -12597.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12610.08\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12585.52\n",
      " ARIMA(1,1,0) with drift         : -12583.61\n",
      " ARIMA(0,1,1) with drift         : -12583.79\n",
      " ARIMA(0,1,0)                    : -12587.53\n",
      " ARIMA(1,1,1) with drift         : -12582.95\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12595.92\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12575.75\n",
      " ARIMA(1,1,0) with drift         : -12573.03\n",
      " ARIMA(0,1,1) with drift         : -12574\n",
      " ARIMA(0,1,0)                    : -12577.75\n",
      " ARIMA(1,1,1) with drift         : -12572.21\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12586.14\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12556.22\n",
      " ARIMA(0,1,0) with drift         : -12555.96\n",
      " ARIMA(1,1,0) with drift         : -12553.13\n",
      " ARIMA(0,1,1) with drift         : -12554.03\n",
      " ARIMA(0,1,0)                    : -12557.96\n",
      " ARIMA(1,1,1) with drift         : -12552.09\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12566.34\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12536.16\n",
      " ARIMA(0,1,0) with drift         : -12534.17\n",
      " ARIMA(1,1,0) with drift         : -12531.56\n",
      " ARIMA(0,1,1) with drift         : -12532.27\n",
      " ARIMA(0,1,0)                    : -12536.16\n",
      " ARIMA(1,1,1) with drift         : -12530.62\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12544.53\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12493.21\n",
      " ARIMA(0,1,0) with drift         : -12492.02\n",
      " ARIMA(1,1,0) with drift         : -12489.42\n",
      " ARIMA(0,1,1) with drift         : -12490.39\n",
      " ARIMA(0,1,0)                    : -12494.01\n",
      " ARIMA(1,1,1) with drift         : -12488.94\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12502.36\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12363.39\n",
      " ARIMA(1,1,0) with drift         : -12361.92\n",
      " ARIMA(0,1,1) with drift         : -12362.83\n",
      " ARIMA(0,1,0)                    : -12365.4\n",
      " ARIMA(1,1,1) with drift         : -12361.31\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12373.69\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12316.14\n",
      " ARIMA(0,1,0) with drift         : -12318.09\n",
      " ARIMA(1,1,0) with drift         : -12316.48\n",
      " ARIMA(0,1,1) with drift         : -12317.45\n",
      " ARIMA(0,1,0)                    : -12320.08\n",
      " ARIMA(1,1,1) with drift         : -12315.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12328.35\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12249.54\n",
      " ARIMA(0,1,0) with drift         : -12252.65\n",
      " ARIMA(1,1,0) with drift         : -12251.38\n",
      " ARIMA(0,1,1) with drift         : -12252.12\n",
      " ARIMA(0,1,0)                    : -12254.65\n",
      " ARIMA(1,1,1) with drift         : -12249.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12262.9\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12188.61\n",
      " ARIMA(0,1,0) with drift         : -12192.2\n",
      " ARIMA(1,1,0) with drift         : -12190.99\n",
      " ARIMA(0,1,1) with drift         : -12191.78\n",
      " ARIMA(0,1,0)                    : -12194.2\n",
      " ARIMA(1,1,1) with drift         : -12189.56\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12202.42\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12173.86\n",
      " ARIMA(0,1,0) with drift         : -12177.26\n",
      " ARIMA(1,1,0) with drift         : -12175.8\n",
      " ARIMA(0,1,1) with drift         : -12176.9\n",
      " ARIMA(0,1,0)                    : -12179.26\n",
      " ARIMA(1,1,1) with drift         : -12174.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12187.48\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12149.5\n",
      " ARIMA(0,1,0) with drift         : -12153.1\n",
      " ARIMA(1,1,0) with drift         : -12151.82\n",
      " ARIMA(0,1,1) with drift         : -12152.63\n",
      " ARIMA(0,1,0)                    : -12155.1\n",
      " ARIMA(1,1,1) with drift         : -12150.29\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12163.3\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12128.62\n",
      " ARIMA(1,1,0) with drift         : -12127.02\n",
      " ARIMA(0,1,1) with drift         : -12127.98\n",
      " ARIMA(0,1,0)                    : -12130.62\n",
      " ARIMA(1,1,1) with drift         : -12125.41\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12138.81\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12094.83\n",
      " ARIMA(1,1,0) with drift         : -12093.74\n",
      " ARIMA(0,1,1) with drift         : -12093.52\n",
      " ARIMA(0,1,0)                    : -12096.83\n",
      " ARIMA(1,1,1) with drift         : -12091.74\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12105.01\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12082.79\n",
      " ARIMA(0,1,0) with drift         : -12069.6\n",
      " ARIMA(1,1,0) with drift         : -12068.53\n",
      " ARIMA(0,1,1) with drift         : -12068.08\n",
      " ARIMA(0,1,0)                    : -12071.6\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : -12069.65\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -12085.65\n",
      " ARIMA(1,1,3) with drift         : -12069.73\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : -12083.73\n",
      " ARIMA(1,1,4) with drift         : -12068.47\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -12087.68\n",
      " ARIMA(1,1,3)                    : -12071.71\n",
      " ARIMA(2,1,2)                    : -12068.25\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : -12085.75\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,4)                    : -12070.48\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(1,1,3)                    : -12081.21\n",
      "\n",
      " Best model: ARIMA(1,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12082.77\n",
      " ARIMA(0,1,0) with drift         : -12062.29\n",
      " ARIMA(1,1,0) with drift         : -12059.83\n",
      " ARIMA(0,1,1) with drift         : -12060.73\n",
      " ARIMA(0,1,0)                    : -12064.29\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -12058.07\n",
      " ARIMA(1,1,3) with drift         : -12062.87\n",
      " ARIMA(3,1,1) with drift         : -12071.37\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12093.41\n",
      "\n",
      " Best model: ARIMA(2,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12051.59\n",
      " ARIMA(0,1,0) with drift         : -12056.79\n",
      " ARIMA(1,1,0) with drift         : -12054.21\n",
      " ARIMA(0,1,1) with drift         : -12055.13\n",
      " ARIMA(0,1,0)                    : -12058.79\n",
      " ARIMA(1,1,1) with drift         : -12052.52\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12066.95\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12040.97\n",
      " ARIMA(0,1,0) with drift         : -12045.69\n",
      " ARIMA(1,1,0) with drift         : -12043.05\n",
      " ARIMA(0,1,1) with drift         : -12043.96\n",
      " ARIMA(0,1,0)                    : -12047.7\n",
      " ARIMA(1,1,1) with drift         : -12041.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12055.85\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12035.51\n",
      " ARIMA(1,1,0) with drift         : -12032.9\n",
      " ARIMA(0,1,1) with drift         : -12033.73\n",
      " ARIMA(0,1,0)                    : -12037.51\n",
      " ARIMA(1,1,1) with drift         : -12030.9\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12045.67\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12023.14\n",
      " ARIMA(0,1,0) with drift         : -12028.48\n",
      " ARIMA(1,1,0) with drift         : -12025.73\n",
      " ARIMA(0,1,1) with drift         : -12026.67\n",
      " ARIMA(0,1,0)                    : -12030.49\n",
      " ARIMA(1,1,1) with drift         : -12023.73\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12038.64\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12061.44\n",
      " ARIMA(0,1,0) with drift         : -12023.42\n",
      " ARIMA(1,1,0) with drift         : -12020.51\n",
      " ARIMA(0,1,1) with drift         : -12021.52\n",
      " ARIMA(0,1,0)                    : -12025.42\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : -12021.41\n",
      " ARIMA(3,1,2) with drift         : -12033.17\n",
      " ARIMA(2,1,3) with drift         : -12067.9\n",
      " ARIMA(1,1,3) with drift         : -12035.78\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : -12066.17\n",
      " ARIMA(1,1,4) with drift         : -12034.04\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -12069.61\n",
      " ARIMA(1,1,3)                    : -12037.79\n",
      " ARIMA(2,1,2)                    : -12021.24\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : -12067.88\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,4)                    : -12036.05\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(1,1,3)                    : -12046.92\n",
      "\n",
      " Best model: ARIMA(1,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12015.63\n",
      " ARIMA(0,1,0) with drift         : -12021.2\n",
      " ARIMA(1,1,0) with drift         : -12018.3\n",
      " ARIMA(0,1,1) with drift         : -12019.28\n",
      " ARIMA(0,1,0)                    : -12023.2\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12031.34\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12019.53\n",
      " ARIMA(1,1,0) with drift         : -12016.78\n",
      " ARIMA(0,1,1) with drift         : -12017.59\n",
      " ARIMA(0,1,0)                    : -12021.53\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12029.68\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12017.38\n",
      " ARIMA(1,1,0) with drift         : -12014.64\n",
      " ARIMA(0,1,1) with drift         : -12015.43\n",
      " ARIMA(0,1,0)                    : -12019.38\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12027.53\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12013.54\n",
      " ARIMA(1,1,0) with drift         : -12010.62\n",
      " ARIMA(0,1,1) with drift         : -12011.59\n",
      " ARIMA(0,1,0)                    : -12015.55\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12023.69\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12010.11\n",
      " ARIMA(1,1,0) with drift         : -12007.44\n",
      " ARIMA(0,1,1) with drift         : -12008.17\n",
      " ARIMA(0,1,0)                    : -12012.11\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12020.25\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12001.03\n",
      " ARIMA(1,1,0) with drift         : -11998.11\n",
      " ARIMA(0,1,1) with drift         : -11999.06\n",
      " ARIMA(0,1,0)                    : -12003.03\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12011.17\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11991.51\n",
      " ARIMA(0,1,0) with drift         : -11995.98\n",
      " ARIMA(1,1,0) with drift         : -11993.05\n",
      " ARIMA(0,1,1) with drift         : -11994.03\n",
      " ARIMA(0,1,0)                    : -11997.99\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12006.12\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11996.07\n",
      " ARIMA(1,1,0) with drift         : -11993.21\n",
      " ARIMA(0,1,1) with drift         : -11994.15\n",
      " ARIMA(0,1,0)                    : -11998.07\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12006.21\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11996.85\n",
      " ARIMA(1,1,0) with drift         : -11994.15\n",
      " ARIMA(0,1,1) with drift         : -11994.92\n",
      " ARIMA(0,1,0)                    : -11998.85\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12006.98\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12016.73\n",
      " ARIMA(0,1,0) with drift         : -11995.59\n",
      " ARIMA(1,1,0) with drift         : -11992.68\n",
      " ARIMA(0,1,1) with drift         : -11993.67\n",
      " ARIMA(0,1,0)                    : -11997.59\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12006.39\n",
      " ARIMA(3,1,1) with drift         : -12004.19\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12027.23\n",
      "\n",
      " Best model: ARIMA(2,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12012.2\n",
      " ARIMA(0,1,0) with drift         : -11990.52\n",
      " ARIMA(1,1,0) with drift         : -11987.63\n",
      " ARIMA(0,1,1) with drift         : -11988.63\n",
      " ARIMA(0,1,0)                    : -11992.52\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12001.17\n",
      " ARIMA(3,1,1) with drift         : -11999.02\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12022.54\n",
      "\n",
      " Best model: ARIMA(2,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12043.99\n",
      " ARIMA(0,1,0) with drift         : -11987.17\n",
      " ARIMA(1,1,0) with drift         : -11984.55\n",
      " ARIMA(0,1,1) with drift         : -11985.26\n",
      " ARIMA(0,1,0)                    : -11989.17\n",
      " ARIMA(1,1,2) with drift         : -12023.86\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11982.54\n",
      " ARIMA(1,1,3) with drift         : -11995.32\n",
      " ARIMA(3,1,1) with drift         : -11994.67\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12006.86\n",
      "\n",
      " Best model: ARIMA(1,1,3) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11981.5\n",
      " ARIMA(1,1,0) with drift         : -11979.09\n",
      " ARIMA(0,1,1) with drift         : -11979.6\n",
      " ARIMA(0,1,0)                    : -11983.5\n",
      " ARIMA(1,1,1) with drift         : -11977.09\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11991.63\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11978.9\n",
      " ARIMA(1,1,0) with drift         : -11976.01\n",
      " ARIMA(0,1,1) with drift         : -11977.01\n",
      " ARIMA(0,1,0)                    : -11980.91\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11989.03\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11981.39\n",
      " ARIMA(1,1,0) with drift         : -11978.69\n",
      " ARIMA(0,1,1) with drift         : -11979.53\n",
      " ARIMA(0,1,0)                    : -11983.39\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11991.52\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11986.98\n",
      " ARIMA(1,1,0) with drift         : -11984.6\n",
      " ARIMA(0,1,1) with drift         : -11985.09\n",
      " ARIMA(0,1,0)                    : -11988.99\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11997.12\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11992.9\n",
      " ARIMA(1,1,0) with drift         : -11989.96\n",
      " ARIMA(0,1,1) with drift         : -11990.96\n",
      " ARIMA(0,1,0)                    : -11994.9\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12003.04\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12013.09\n",
      " ARIMA(0,1,0) with drift         : -11992.3\n",
      " ARIMA(1,1,0) with drift         : -11989.52\n",
      " ARIMA(0,1,1) with drift         : -11990.35\n",
      " ARIMA(0,1,0)                    : -11994.3\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12002.95\n",
      " ARIMA(3,1,1) with drift         : -12001.79\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12024.89\n",
      "\n",
      " Best model: ARIMA(2,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11988.37\n",
      " ARIMA(1,1,0) with drift         : -11985.73\n",
      " ARIMA(0,1,1) with drift         : -11986.38\n",
      " ARIMA(0,1,0)                    : -11990.37\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11998.5\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11987.63\n",
      " ARIMA(1,1,0) with drift         : -11984.66\n",
      " ARIMA(0,1,1) with drift         : -11985.63\n",
      " ARIMA(0,1,0)                    : -11989.63\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11997.77\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12008.82\n",
      " ARIMA(0,1,0) with drift         : -11994.44\n",
      " ARIMA(1,1,0) with drift         : -11992.07\n",
      " ARIMA(0,1,1) with drift         : -11992.44\n",
      " ARIMA(0,1,0)                    : -11996.43\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : -11991.26\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12004.44\n",
      " ARIMA(3,1,1) with drift         : -12005.12\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(3,1,1) with drift         : -12014.85\n",
      "\n",
      " Best model: ARIMA(3,1,1) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12059.59\n",
      " ARIMA(0,1,0) with drift         : -12000.97\n",
      " ARIMA(1,1,0) with drift         : -11998.47\n",
      " ARIMA(0,1,1) with drift         : -11998.97\n",
      " ARIMA(0,1,0)                    : -12002.96\n",
      " ARIMA(1,1,2) with drift         : -12039.27\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12008.38\n",
      " ARIMA(3,1,1) with drift         : -12007.62\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -12061.58\n",
      " ARIMA(1,1,2)                    : -12041.15\n",
      " ARIMA(2,1,1)                    : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(1,1,1)                    : Inf\n",
      " ARIMA(1,1,3)                    : -12010.39\n",
      " ARIMA(3,1,1)                    : -12009.59\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(1,1,3)                    : -12023.37\n",
      "\n",
      " Best model: ARIMA(1,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12004.31\n",
      " ARIMA(1,1,0) with drift         : -12001.41\n",
      " ARIMA(0,1,1) with drift         : -12002.33\n",
      " ARIMA(0,1,0)                    : -12006.31\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12014.45\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12001.45\n",
      " ARIMA(1,1,0) with drift         : -11998.66\n",
      " ARIMA(0,1,1) with drift         : -11999.47\n",
      " ARIMA(0,1,0)                    : -12003.45\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12011.58\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11997.55\n",
      " ARIMA(1,1,0) with drift         : -11995.35\n",
      " ARIMA(0,1,1) with drift         : -11995.58\n",
      " ARIMA(0,1,0)                    : -11999.55\n",
      " ARIMA(1,1,1) with drift         : -11996.94\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12007.69\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12000.21\n",
      " ARIMA(1,1,0) with drift         : -11997.28\n",
      " ARIMA(0,1,1) with drift         : -11998.26\n",
      " ARIMA(0,1,0)                    : -12002.22\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12010.35\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12023.7\n",
      " ARIMA(0,1,0) with drift         : -12005.68\n",
      " ARIMA(1,1,0) with drift         : -12003.47\n",
      " ARIMA(0,1,1) with drift         : -12003.75\n",
      " ARIMA(0,1,0)                    : -12007.68\n",
      " ARIMA(1,1,2) with drift         : -12005.34\n",
      " ARIMA(2,1,1) with drift         : -12003.68\n",
      " ARIMA(3,1,2) with drift         : -12015.1\n",
      " ARIMA(2,1,3) with drift         : -12015.95\n",
      " ARIMA(1,1,1) with drift         : -12032.52\n",
      " ARIMA(0,1,2) with drift         : -12004.11\n",
      " ARIMA(2,1,0) with drift         : -12003.5\n",
      " ARIMA(1,1,1)                    : -12034.31\n",
      " ARIMA(0,1,1)                    : -12005.76\n",
      " ARIMA(1,1,0)                    : -12005.48\n",
      " ARIMA(2,1,1)                    : -12005.7\n",
      " ARIMA(1,1,2)                    : -12035.81\n",
      " ARIMA(0,1,2)                    : -12006.11\n",
      " ARIMA(2,1,2)                    : -12025.67\n",
      " ARIMA(1,1,3)                    : -12006.67\n",
      " ARIMA(0,1,3)                    : -12007.76\n",
      " ARIMA(2,1,3)                    : -12017.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,1)                    : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -12028.35\n",
      "\n",
      " Best model: ARIMA(2,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12046.07\n",
      " ARIMA(0,1,0) with drift         : -12011.57\n",
      " ARIMA(1,1,0) with drift         : -12009.1\n",
      " ARIMA(0,1,1) with drift         : -12009.67\n",
      " ARIMA(0,1,0)                    : -12013.57\n",
      " ARIMA(1,1,2) with drift         : -12038.51\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12020.19\n",
      " ARIMA(3,1,1) with drift         : -12017.76\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -12048.07\n",
      " ARIMA(1,1,2)                    : -12040.13\n",
      " ARIMA(2,1,1)                    : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(1,1,1)                    : Inf\n",
      " ARIMA(1,1,3)                    : -12022.21\n",
      " ARIMA(3,1,1)                    : -12019.74\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(1,1,3)                    : -12034.44\n",
      "\n",
      " Best model: ARIMA(1,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12018.83\n",
      " ARIMA(1,1,0) with drift         : -12015.98\n",
      " ARIMA(0,1,1) with drift         : -12016.99\n",
      " ARIMA(0,1,0)                    : -12020.83\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12028.97\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12024.85\n",
      " ARIMA(1,1,0) with drift         : -12022.27\n",
      " ARIMA(0,1,1) with drift         : -12022.98\n",
      " ARIMA(0,1,0)                    : -12026.85\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12035\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12098.61\n",
      " ARIMA(0,1,0) with drift         : -12045.53\n",
      " ARIMA(1,1,0) with drift         : -12043.15\n",
      " ARIMA(0,1,1) with drift         : -12043.76\n",
      " ARIMA(0,1,0)                    : -12047.51\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : -12073.39\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12054.62\n",
      " ARIMA(3,1,1) with drift         : -12044.52\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -12065.34\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(1,1,3) with drift         : -12066.73\n",
      "\n",
      " Best model: ARIMA(1,1,3) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12144.36\n",
      " ARIMA(0,0,0) with non-zero mean : -7379.697\n",
      " ARIMA(1,0,0) with non-zero mean : -12138.61\n",
      " ARIMA(0,0,1) with non-zero mean : -9450.926\n",
      " ARIMA(0,0,0) with zero mean     : -7370.04\n",
      " ARIMA(1,0,2) with non-zero mean : -12135.74\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12143.93\n",
      " ARIMA(1,0,1) with non-zero mean : -12137.74\n",
      " ARIMA(1,0,3) with non-zero mean : -12133.76\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -12146.18\n",
      " ARIMA(1,0,2) with zero mean     : -12137.45\n",
      " ARIMA(2,0,1) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -12145.78\n",
      " ARIMA(1,0,1) with zero mean     : -12139.45\n",
      " ARIMA(1,0,3) with zero mean     : -12135.48\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12147.75\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12147.26\n",
      " ARIMA(0,0,0) with non-zero mean : -7401.445\n",
      " ARIMA(1,0,0) with non-zero mean : -12140.99\n",
      " ARIMA(0,0,1) with non-zero mean : -9469.226\n",
      " ARIMA(0,0,0) with zero mean     : -7394.298\n",
      " ARIMA(1,0,2) with non-zero mean : -12138.1\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -12195.99\n",
      " ARIMA(3,0,1) with non-zero mean : -12147.37\n",
      " ARIMA(4,0,2) with non-zero mean : -12145.28\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,1) with non-zero mean : -12147.34\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -12195.39\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,1) with non-zero mean : -12148.48\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12157.48\n",
      " ARIMA(0,0,0) with non-zero mean : -7410.828\n",
      " ARIMA(1,0,0) with non-zero mean : -12147.29\n",
      " ARIMA(0,0,1) with non-zero mean : -9478.417\n",
      " ARIMA(0,0,0) with zero mean     : -7404.159\n",
      " ARIMA(1,0,2) with non-zero mean : -12144.29\n",
      " ARIMA(2,0,1) with non-zero mean : -12154.72\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(1,0,1) with non-zero mean : -12146.3\n",
      " ARIMA(1,0,3) with non-zero mean : -12142.28\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -12159.07\n",
      " ARIMA(1,0,2) with zero mean     : -12145.95\n",
      " ARIMA(2,0,1) with zero mean     : -12156.33\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -12158.89\n",
      " ARIMA(1,0,1) with zero mean     : -12147.96\n",
      " ARIMA(1,0,3) with zero mean     : -12143.94\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12157.53\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12176.38\n",
      " ARIMA(0,0,0) with non-zero mean : -7415.23\n",
      " ARIMA(1,0,0) with non-zero mean : -12168.98\n",
      " ARIMA(0,0,1) with non-zero mean : -9487.159\n",
      " ARIMA(0,0,0) with zero mean     : -7406.617\n",
      " ARIMA(1,0,2) with non-zero mean : -12166.19\n",
      " ARIMA(2,0,1) with non-zero mean : -12172.69\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(1,0,1) with non-zero mean : -12168.2\n",
      " ARIMA(1,0,3) with non-zero mean : -12164.18\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12174.04\n",
      " ARIMA(2,0,2) with zero mean     : -12178.13\n",
      " ARIMA(1,0,2) with zero mean     : -12167.84\n",
      " ARIMA(2,0,1) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -12178.04\n",
      " ARIMA(1,0,1) with zero mean     : -12169.85\n",
      " ARIMA(1,0,3) with zero mean     : -12165.83\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -12175.41\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12178.54\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12191.2\n",
      " ARIMA(0,0,0) with non-zero mean : -7418.218\n",
      " ARIMA(1,0,0) with non-zero mean : -12177.16\n",
      " ARIMA(0,0,1) with non-zero mean : -9490.666\n",
      " ARIMA(0,0,0) with zero mean     : -7409.668\n",
      " ARIMA(1,0,2) with non-zero mean : -12174.36\n",
      " ARIMA(2,0,1) with non-zero mean : -12187.67\n",
      " ARIMA(3,0,2) with non-zero mean : -12192.93\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -12199.74\n",
      " ARIMA(4,0,1) with non-zero mean : -12195.36\n",
      " ARIMA(5,0,2) with non-zero mean : -12202.29\n",
      " ARIMA(5,0,1) with non-zero mean : -12201.86\n",
      " ARIMA(5,0,3) with non-zero mean : -12200.54\n",
      " ARIMA(4,0,3) with non-zero mean : -12197.97\n",
      " ARIMA(5,0,2) with zero mean     : -12203.38\n",
      " ARIMA(4,0,2) with zero mean     : -12201.32\n",
      " ARIMA(5,0,1) with zero mean     : -12203.33\n",
      " ARIMA(5,0,3) with zero mean     : -12202\n",
      " ARIMA(4,0,1) with zero mean     : -12196.89\n",
      " ARIMA(4,0,3) with zero mean     : -12199.44\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,2) with zero mean     : -12194.79\n",
      "\n",
      " Best model: ARIMA(5,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12230.95\n",
      " ARIMA(0,0,0) with non-zero mean : -7432.886\n",
      " ARIMA(1,0,0) with non-zero mean : -12217.68\n",
      " ARIMA(0,0,1) with non-zero mean : -9511.6\n",
      " ARIMA(0,0,0) with zero mean     : -7420.807\n",
      " ARIMA(1,0,2) with non-zero mean : -12215.37\n",
      " ARIMA(2,0,1) with non-zero mean : -12225.89\n",
      " ARIMA(3,0,2) with non-zero mean : -12228.34\n",
      " ARIMA(2,0,3) with non-zero mean : -12230.77\n",
      " ARIMA(1,0,1) with non-zero mean : -12217.34\n",
      " ARIMA(1,0,3) with non-zero mean : -12213.4\n",
      " ARIMA(3,0,1) with non-zero mean : -12229.7\n",
      " ARIMA(3,0,3) with non-zero mean : -12227.59\n",
      " ARIMA(2,0,2) with zero mean     : -12232.43\n",
      " ARIMA(1,0,2) with zero mean     : -12216.89\n",
      " ARIMA(2,0,1) with zero mean     : -12227.44\n",
      " ARIMA(3,0,2) with zero mean     : -12229.35\n",
      " ARIMA(2,0,3) with zero mean     : -12232.29\n",
      " ARIMA(1,0,1) with zero mean     : -12218.86\n",
      " ARIMA(1,0,3) with zero mean     : -12214.92\n",
      " ARIMA(3,0,1) with zero mean     : -12231.19\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12227.28\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12256.5\n",
      " ARIMA(0,0,0) with non-zero mean : -7445.42\n",
      " ARIMA(1,0,0) with non-zero mean : -12257.49\n",
      " ARIMA(0,0,1) with non-zero mean : -9535.569\n",
      " ARIMA(0,0,0) with zero mean     : -7434.489\n",
      " ARIMA(2,0,0) with non-zero mean : -12258.72\n",
      " ARIMA(3,0,0) with non-zero mean : -12256.04\n",
      " ARIMA(2,0,1) with non-zero mean : -12256.73\n",
      " ARIMA(1,0,1) with non-zero mean : -12258.14\n",
      " ARIMA(3,0,1) with non-zero mean : -12262.6\n",
      " ARIMA(4,0,1) with non-zero mean : -12265.56\n",
      " ARIMA(4,0,0) with non-zero mean : -12253.08\n",
      " ARIMA(5,0,1) with non-zero mean : -12257.65\n",
      " ARIMA(4,0,2) with non-zero mean : -12266.8\n",
      " ARIMA(3,0,2) with non-zero mean : -12306.42\n",
      " ARIMA(3,0,3) with non-zero mean : -12267.78\n",
      " ARIMA(2,0,3) with non-zero mean : -12256.89\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -12308.34\n",
      " ARIMA(2,0,2) with zero mean     : -12257.99\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -12268.17\n",
      " ARIMA(3,0,3) with zero mean     : -12269.37\n",
      " ARIMA(2,0,1) with zero mean     : -12258.26\n",
      " ARIMA(2,0,3) with zero mean     : -12258.42\n",
      " ARIMA(4,0,1) with zero mean     : -12267.17\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,1) with zero mean     : -12267.77\n",
      "\n",
      " Best model: ARIMA(4,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12267.03\n",
      " ARIMA(0,0,0) with non-zero mean : -7448.715\n",
      " ARIMA(1,0,0) with non-zero mean : -12270.76\n",
      " ARIMA(0,0,1) with non-zero mean : -9539.854\n",
      " ARIMA(0,0,0) with zero mean     : -7436.768\n",
      " ARIMA(2,0,0) with non-zero mean : -12271.22\n",
      " ARIMA(3,0,0) with non-zero mean : -12269.75\n",
      " ARIMA(2,0,1) with non-zero mean : -12279.57\n",
      " ARIMA(1,0,1) with non-zero mean : -12271.36\n",
      " ARIMA(3,0,1) with non-zero mean : -12277.62\n",
      " ARIMA(1,0,2) with non-zero mean : -12269.4\n",
      " ARIMA(3,0,2) with non-zero mean : -12277.69\n",
      " ARIMA(2,0,1) with zero mean     : -12271.86\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with non-zero mean : -12276.5\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12284.93\n",
      " ARIMA(0,0,0) with non-zero mean : -7471.436\n",
      " ARIMA(1,0,0) with non-zero mean : -12282\n",
      " ARIMA(0,0,1) with non-zero mean : -9557.207\n",
      " ARIMA(0,0,0) with zero mean     : -7461.747\n",
      " ARIMA(1,0,2) with non-zero mean : -12280.56\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -12291.07\n",
      " ARIMA(3,0,1) with non-zero mean : -12291.38\n",
      " ARIMA(3,0,0) with non-zero mean : -12279.73\n",
      " ARIMA(4,0,1) with non-zero mean : -12289.84\n",
      " ARIMA(2,0,0) with non-zero mean : -12282.65\n",
      " ARIMA(4,0,0) with non-zero mean : -12276.77\n",
      " ARIMA(4,0,2) with non-zero mean : -12288.12\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -12289.07\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12288.43\n",
      " ARIMA(0,0,0) with non-zero mean : -7491.792\n",
      " ARIMA(1,0,0) with non-zero mean : -12281.96\n",
      " ARIMA(0,0,1) with non-zero mean : -9570.926\n",
      " ARIMA(0,0,0) with zero mean     : -7486.785\n",
      " ARIMA(1,0,2) with non-zero mean : -12280.72\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -12278.07\n",
      " ARIMA(2,0,3) with non-zero mean : -12287.42\n",
      " ARIMA(1,0,1) with non-zero mean : -12282.58\n",
      " ARIMA(1,0,3) with non-zero mean : -12278.8\n",
      " ARIMA(3,0,1) with non-zero mean : -12291.64\n",
      " ARIMA(3,0,0) with non-zero mean : -12279.17\n",
      " ARIMA(4,0,1) with non-zero mean : -12289.74\n",
      " ARIMA(2,0,0) with non-zero mean : -12281.9\n",
      " ARIMA(4,0,0) with non-zero mean : -12276.18\n",
      " ARIMA(4,0,2) with non-zero mean : -12287.82\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -12289.87\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12285.11\n",
      " ARIMA(0,0,0) with non-zero mean : -7496.174\n",
      " ARIMA(1,0,0) with non-zero mean : -12281.29\n",
      " ARIMA(0,0,1) with non-zero mean : -9575.749\n",
      " ARIMA(0,0,0) with zero mean     : -7491.335\n",
      " ARIMA(1,0,2) with non-zero mean : -12279.85\n",
      " ARIMA(2,0,1) with non-zero mean : -12280.01\n",
      " ARIMA(3,0,2) with non-zero mean : -12290.63\n",
      " ARIMA(3,0,1) with non-zero mean : -12291.52\n",
      " ARIMA(3,0,0) with non-zero mean : -12279.18\n",
      " ARIMA(4,0,1) with non-zero mean : -12286.39\n",
      " ARIMA(2,0,0) with non-zero mean : -12282.04\n",
      " ARIMA(4,0,0) with non-zero mean : -12276.54\n",
      " ARIMA(4,0,2) with non-zero mean : -12293.13\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12289.1\n",
      " ARIMA(5,0,1) with non-zero mean : -12281.77\n",
      " ARIMA(5,0,3) with non-zero mean : -12288.54\n",
      " ARIMA(4,0,2) with zero mean     : -12294.75\n",
      " ARIMA(3,0,2) with zero mean     : -12292.38\n",
      " ARIMA(4,0,1) with zero mean     : -12288.01\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,1) with zero mean     : -12293.2\n",
      " ARIMA(3,0,3) with zero mean     : -12290.83\n",
      " ARIMA(5,0,1) with zero mean     : -12283.48\n",
      " ARIMA(5,0,3) with zero mean     : -12290.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,2) with zero mean     : -12297.18\n",
      "\n",
      " Best model: ARIMA(4,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12288.25\n",
      " ARIMA(0,0,0) with non-zero mean : -7487.697\n",
      " ARIMA(1,0,0) with non-zero mean : -12283.46\n",
      " ARIMA(0,0,1) with non-zero mean : -9569.537\n",
      " ARIMA(0,0,0) with zero mean     : -7481.002\n",
      " ARIMA(1,0,2) with non-zero mean : -12282.02\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12287.41\n",
      " ARIMA(1,0,1) with non-zero mean : -12283.88\n",
      " ARIMA(1,0,3) with non-zero mean : -12280.08\n",
      " ARIMA(3,0,1) with non-zero mean : -12291.9\n",
      " ARIMA(3,0,0) with non-zero mean : -12281.24\n",
      " ARIMA(4,0,1) with non-zero mean : -12283.79\n",
      " ARIMA(2,0,0) with non-zero mean : -12284.01\n",
      " ARIMA(4,0,0) with non-zero mean : -12279.07\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -12293\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12304.9\n",
      " ARIMA(0,0,0) with non-zero mean : -7489.45\n",
      " ARIMA(1,0,0) with non-zero mean : -12294.5\n",
      " ARIMA(0,0,1) with non-zero mean : -9570.78\n",
      " ARIMA(0,0,0) with zero mean     : -7482.208\n",
      " ARIMA(1,0,2) with non-zero mean : -12292.56\n",
      " ARIMA(2,0,1) with non-zero mean : -12299.81\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12303.87\n",
      " ARIMA(1,0,1) with non-zero mean : -12294.41\n",
      " ARIMA(1,0,3) with non-zero mean : -12290.57\n",
      " ARIMA(3,0,1) with non-zero mean : -12303.05\n",
      " ARIMA(3,0,3) with non-zero mean : -12300.62\n",
      " ARIMA(2,0,2) with zero mean     : -12306.73\n",
      " ARIMA(1,0,2) with zero mean     : -12294.33\n",
      " ARIMA(2,0,1) with zero mean     : -12301.66\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -12305.7\n",
      " ARIMA(1,0,1) with zero mean     : -12296.18\n",
      " ARIMA(1,0,3) with zero mean     : -12292.33\n",
      " ARIMA(3,0,1) with zero mean     : -12304.74\n",
      " ARIMA(3,0,3) with zero mean     : -12302.28\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12305.7\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12296.47\n",
      " ARIMA(0,0,0) with non-zero mean : -7512.433\n",
      " ARIMA(1,0,0) with non-zero mean : -12293.41\n",
      " ARIMA(0,0,1) with non-zero mean : -9590.106\n",
      " ARIMA(0,0,0) with zero mean     : -7507.644\n",
      " ARIMA(1,0,2) with non-zero mean : -12291.22\n",
      " ARIMA(2,0,1) with non-zero mean : -12290.49\n",
      " ARIMA(3,0,2) with non-zero mean : -12349.06\n",
      " ARIMA(3,0,1) with non-zero mean : -12288.8\n",
      " ARIMA(4,0,2) with non-zero mean : -12302.23\n",
      " ARIMA(3,0,3) with non-zero mean : -12348.81\n",
      " ARIMA(2,0,3) with non-zero mean : -12290.13\n",
      " ARIMA(4,0,1) with non-zero mean : -12303.48\n",
      " ARIMA(4,0,3) with non-zero mean : -12301.4\n",
      " ARIMA(3,0,2) with zero mean     : -12350.91\n",
      " ARIMA(2,0,2) with zero mean     : -12291.96\n",
      " ARIMA(3,0,1) with zero mean     : -12304.11\n",
      " ARIMA(4,0,2) with zero mean     : -12304.06\n",
      " ARIMA(3,0,3) with zero mean     : -12350.67\n",
      " ARIMA(2,0,1) with zero mean     : -12292.34\n",
      " ARIMA(2,0,3) with zero mean     : -12291.95\n",
      " ARIMA(4,0,1) with zero mean     : -12305.28\n",
      " ARIMA(4,0,3) with zero mean     : -12303.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,1) with zero mean     : -12302.9\n",
      "\n",
      " Best model: ARIMA(4,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12294.73\n",
      " ARIMA(0,0,0) with non-zero mean : -7523.726\n",
      " ARIMA(1,0,0) with non-zero mean : -12282.66\n",
      " ARIMA(0,0,1) with non-zero mean : -9599.263\n",
      " ARIMA(0,0,0) with zero mean     : -7518.565\n",
      " ARIMA(1,0,2) with non-zero mean : -12280.27\n",
      " ARIMA(2,0,1) with non-zero mean : -12290.51\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12293.89\n",
      " ARIMA(1,0,1) with non-zero mean : -12282.22\n",
      " ARIMA(1,0,3) with non-zero mean : -12278.26\n",
      " ARIMA(3,0,1) with non-zero mean : -12292.79\n",
      " ARIMA(3,0,3) with non-zero mean : -12290.64\n",
      " ARIMA(2,0,2) with zero mean     : -12296.31\n",
      " ARIMA(1,0,2) with zero mean     : -12281.96\n",
      " ARIMA(2,0,1) with zero mean     : -12292.13\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -12295.48\n",
      " ARIMA(1,0,1) with zero mean     : -12283.92\n",
      " ARIMA(1,0,3) with zero mean     : -12279.96\n",
      " ARIMA(3,0,1) with zero mean     : -12294.58\n",
      " ARIMA(3,0,3) with zero mean     : -12292.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12292.19\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12310.49\n",
      " ARIMA(0,0,0) with non-zero mean : -7579.667\n",
      " ARIMA(1,0,0) with non-zero mean : -12312.78\n",
      " ARIMA(0,0,1) with non-zero mean : -9644.894\n",
      " ARIMA(0,0,0) with zero mean     : -7568.096\n",
      " ARIMA(2,0,0) with non-zero mean : -12313.95\n",
      " ARIMA(3,0,0) with non-zero mean : -12311.6\n",
      " ARIMA(2,0,1) with non-zero mean : -12311.94\n",
      " ARIMA(1,0,1) with non-zero mean : -12311.83\n",
      " ARIMA(3,0,1) with non-zero mean : -12308.85\n",
      " ARIMA(2,0,0) with zero mean     : -12315.33\n",
      " ARIMA(1,0,0) with zero mean     : -12314.23\n",
      " ARIMA(3,0,0) with zero mean     : -12312.98\n",
      " ARIMA(2,0,1) with zero mean     : -12313.26\n",
      " ARIMA(1,0,1) with zero mean     : -12313.27\n",
      " ARIMA(3,0,1) with zero mean     : -12310.2\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,0) with zero mean     : -12312.02\n",
      "\n",
      " Best model: ARIMA(2,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -7575.447\n",
      " ARIMA(1,0,0) with non-zero mean : -12376.55\n",
      " ARIMA(0,0,1) with non-zero mean : -9658.299\n",
      " ARIMA(0,0,0) with zero mean     : -7561.632\n",
      " ARIMA(2,0,0) with non-zero mean : -12375.94\n",
      " ARIMA(1,0,1) with non-zero mean : -12375.92\n",
      " ARIMA(2,0,1) with non-zero mean : -12393.48\n",
      " ARIMA(3,0,1) with non-zero mean : -12385.09\n",
      " ARIMA(1,0,2) with non-zero mean : -12374.8\n",
      " ARIMA(3,0,0) with non-zero mean : -12373.92\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -12395.1\n",
      " ARIMA(1,0,1) with zero mean     : -12377.4\n",
      " ARIMA(2,0,0) with zero mean     : -12377.45\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(2,0,2) with zero mean     : Inf\n",
      " ARIMA(1,0,0) with zero mean     : -12378.05\n",
      " ARIMA(1,0,2) with zero mean     : -12376.26\n",
      " ARIMA(3,0,0) with zero mean     : -12375.41\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with zero mean     : -12385.55\n",
      "\n",
      " Best model: ARIMA(2,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12383.96\n",
      " ARIMA(0,0,0) with non-zero mean : -7636.592\n",
      " ARIMA(1,0,0) with non-zero mean : -12385.34\n",
      " ARIMA(0,0,1) with non-zero mean : -9698.714\n",
      " ARIMA(0,0,0) with zero mean     : -7631.109\n",
      " ARIMA(2,0,0) with non-zero mean : -12387.27\n",
      " ARIMA(3,0,0) with non-zero mean : -12385.41\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(1,0,1) with non-zero mean : -12383.83\n",
      " ARIMA(3,0,1) with non-zero mean : -12396.18\n",
      " ARIMA(4,0,1) with non-zero mean : -12382.81\n",
      " ARIMA(3,0,2) with non-zero mean : -12395.78\n",
      " ARIMA(4,0,0) with non-zero mean : -12384.08\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -12389.8\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12386.98\n",
      " ARIMA(0,0,0) with non-zero mean : -7665.854\n",
      " ARIMA(1,0,0) with non-zero mean : -12379.12\n",
      " ARIMA(0,0,1) with non-zero mean : -9722.335\n",
      " ARIMA(0,0,0) with zero mean     : -7662.672\n",
      " ARIMA(1,0,2) with non-zero mean : -12376.91\n",
      " ARIMA(2,0,1) with non-zero mean : -12385.12\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12385.91\n",
      " ARIMA(1,0,1) with non-zero mean : -12377.7\n",
      " ARIMA(1,0,3) with non-zero mean : -12375.44\n",
      " ARIMA(3,0,1) with non-zero mean : -12385.99\n",
      " ARIMA(3,0,3) with non-zero mean : -12396.33\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -12394.71\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -12398.09\n",
      " ARIMA(2,0,3) with zero mean     : -12387.69\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -12388.8\n",
      " ARIMA(2,0,4) with zero mean     : -12377.08\n",
      " ARIMA(4,0,2) with zero mean     : -12396.46\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with zero mean     : -12397.04\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12372.1\n",
      " ARIMA(0,0,0) with non-zero mean : -7638.056\n",
      " ARIMA(1,0,0) with non-zero mean : -12367.87\n",
      " ARIMA(0,0,1) with non-zero mean : -9696.992\n",
      " ARIMA(0,0,0) with zero mean     : -7638.917\n",
      " ARIMA(1,0,2) with non-zero mean : -12365.83\n",
      " ARIMA(2,0,1) with non-zero mean : -12370.39\n",
      " ARIMA(3,0,2) with non-zero mean : -12376.09\n",
      " ARIMA(3,0,1) with non-zero mean : -12376.91\n",
      " ARIMA(3,0,0) with non-zero mean : -12364.17\n",
      " ARIMA(4,0,1) with non-zero mean : -12371.52\n",
      " ARIMA(2,0,0) with non-zero mean : -12365.48\n",
      " ARIMA(4,0,0) with non-zero mean : -12363.21\n",
      " ARIMA(4,0,2) with non-zero mean : -12384.24\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,1) with non-zero mean : -12363.16\n",
      " ARIMA(5,0,3) with non-zero mean : -12358.93\n",
      " ARIMA(4,0,2) with zero mean     : -12386.23\n",
      " ARIMA(3,0,2) with zero mean     : -12377.81\n",
      " ARIMA(4,0,1) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -12399.98\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -12386.19\n",
      "\n",
      " Best model: ARIMA(4,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12382.29\n",
      " ARIMA(0,0,0) with non-zero mean : -7629.492\n",
      " ARIMA(1,0,0) with non-zero mean : -12385.42\n",
      " ARIMA(0,0,1) with non-zero mean : -9699.086\n",
      " ARIMA(0,0,0) with zero mean     : -7630.842\n",
      " ARIMA(2,0,0) with non-zero mean : -12384.88\n",
      " ARIMA(1,0,1) with non-zero mean : -12384.14\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(1,0,0) with zero mean     : -12387.41\n",
      " ARIMA(2,0,0) with zero mean     : -12386.87\n",
      " ARIMA(1,0,1) with zero mean     : -12386.14\n",
      " ARIMA(0,0,1) with zero mean     : -9700.538\n",
      " ARIMA(2,0,1) with zero mean     : -12384.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,0) with zero mean     : -12386.2\n",
      "\n",
      " Best model: ARIMA(1,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12379.96\n",
      " ARIMA(0,0,0) with non-zero mean : -7632.211\n",
      " ARIMA(1,0,0) with non-zero mean : -12374.22\n",
      " ARIMA(0,0,1) with non-zero mean : -9700.155\n",
      " ARIMA(0,0,0) with zero mean     : -7634.093\n",
      " ARIMA(1,0,2) with non-zero mean : -12371.66\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -12387.1\n",
      " ARIMA(3,0,1) with non-zero mean : -12370.64\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12375.05\n",
      " ARIMA(2,0,3) with non-zero mean : -12382.17\n",
      " ARIMA(4,0,1) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -12424.22\n",
      " ARIMA(5,0,3) with non-zero mean : -12430.73\n",
      " ARIMA(5,0,2) with non-zero mean : -12370.49\n",
      " ARIMA(5,0,4) with non-zero mean : -12414.34\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : -12412.76\n",
      "\n",
      " Best model: ARIMA(5,0,4) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12372.17\n",
      " ARIMA(0,0,0) with non-zero mean : -7632.978\n",
      " ARIMA(1,0,0) with non-zero mean : -12362.63\n",
      " ARIMA(0,0,1) with non-zero mean : -9696.85\n",
      " ARIMA(0,0,0) with zero mean     : -7634.852\n",
      " ARIMA(1,0,2) with non-zero mean : -12359.87\n",
      " ARIMA(2,0,1) with non-zero mean : -12370.59\n",
      " ARIMA(3,0,2) with non-zero mean : -12380.13\n",
      " ARIMA(3,0,1) with non-zero mean : -12365.23\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12378.26\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,1) with non-zero mean : -12369.57\n",
      " ARIMA(4,0,3) with non-zero mean : -12413.15\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -12404.7\n",
      " ARIMA(3,0,4) with non-zero mean : -12380.06\n",
      " ARIMA(5,0,2) with non-zero mean : -12357.86\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -12415.18\n",
      " ARIMA(3,0,3) with zero mean     : -12380.26\n",
      " ARIMA(4,0,2) with zero mean     : -12379.48\n",
      " ARIMA(5,0,3) with zero mean     : -12402.01\n",
      " ARIMA(4,0,4) with zero mean     : -12404.73\n",
      " ARIMA(3,0,2) with zero mean     : -12382.14\n",
      " ARIMA(3,0,4) with zero mean     : -12382.08\n",
      " ARIMA(5,0,2) with zero mean     : -12359.88\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -12381.67\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12370.68\n",
      " ARIMA(0,0,0) with non-zero mean : -7632.239\n",
      " ARIMA(1,0,0) with non-zero mean : -12374.84\n",
      " ARIMA(0,0,1) with non-zero mean : -9694.237\n",
      " ARIMA(0,0,0) with zero mean     : -7634.062\n",
      " ARIMA(2,0,0) with non-zero mean : -12372.61\n",
      " ARIMA(1,0,1) with non-zero mean : -12373.2\n",
      " ARIMA(2,0,1) with non-zero mean : -12370.81\n",
      " ARIMA(1,0,0) with zero mean     : -12376.82\n",
      " ARIMA(2,0,0) with zero mean     : -12374.6\n",
      " ARIMA(1,0,1) with zero mean     : -12375.19\n",
      " ARIMA(0,0,1) with zero mean     : -9696.14\n",
      " ARIMA(2,0,1) with zero mean     : -12372.8\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,0) with zero mean     : -12374.11\n",
      "\n",
      " Best model: ARIMA(1,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12380.54\n",
      " ARIMA(0,0,0) with non-zero mean : -7616.551\n",
      " ARIMA(1,0,0) with non-zero mean : -12374.77\n",
      " ARIMA(0,0,1) with non-zero mean : -9683.817\n",
      " ARIMA(0,0,0) with zero mean     : -7618.513\n",
      " ARIMA(1,0,2) with non-zero mean : -12371.59\n",
      " ARIMA(2,0,1) with non-zero mean : -12379.25\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(1,0,1) with non-zero mean : -12373.11\n",
      " ARIMA(1,0,3) with non-zero mean : -12370.14\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12386.46\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -12385\n",
      " ARIMA(2,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -12393.23\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : -12407.97\n",
      " ARIMA(3,0,5) with non-zero mean : -12418.55\n",
      " ARIMA(2,0,5) with non-zero mean : -12380.2\n",
      " ARIMA(3,0,5) with zero mean     : -12420.47\n",
      " ARIMA(2,0,5) with zero mean     : -12382.22\n",
      " ARIMA(3,0,4) with zero mean     : -12391.04\n",
      " ARIMA(4,0,5) with zero mean     : -12409.98\n",
      " ARIMA(2,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : -12395\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with zero mean     : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -12394.39\n",
      "\n",
      " Best model: ARIMA(3,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -7593.37\n",
      " ARIMA(1,0,0) with non-zero mean : -12357.29\n",
      " ARIMA(0,0,1) with non-zero mean : -9659.48\n",
      " ARIMA(0,0,0) with zero mean     : -7594.572\n",
      " ARIMA(2,0,0) with non-zero mean : -12355.13\n",
      " ARIMA(1,0,1) with non-zero mean : -12355.44\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(1,0,0) with zero mean     : -12359.26\n",
      " ARIMA(2,0,0) with zero mean     : -12357.09\n",
      " ARIMA(1,0,1) with zero mean     : -12357.41\n",
      " ARIMA(0,0,1) with zero mean     : -9660.873\n",
      " ARIMA(2,0,1) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,0) with zero mean     : -12357.88\n",
      "\n",
      " Best model: ARIMA(1,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12358.85\n",
      " ARIMA(0,0,0) with non-zero mean : -7612.88\n",
      " ARIMA(1,0,0) with non-zero mean : -12352.73\n",
      " ARIMA(0,0,1) with non-zero mean : -9667.962\n",
      " ARIMA(0,0,0) with zero mean     : -7614.768\n",
      " ARIMA(1,0,2) with non-zero mean : -12349.17\n",
      " ARIMA(2,0,1) with non-zero mean : -12359.18\n",
      " ARIMA(1,0,1) with non-zero mean : -12350.72\n",
      " ARIMA(2,0,0) with non-zero mean : -12349.76\n",
      " ARIMA(3,0,1) with non-zero mean : -12352.18\n",
      " ARIMA(3,0,0) with non-zero mean : -12348.2\n",
      " ARIMA(3,0,2) with non-zero mean : -12402.73\n",
      " ARIMA(4,0,2) with non-zero mean : -12357.4\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,1) with non-zero mean : -12353.57\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -12403.67\n",
      " ARIMA(2,0,2) with zero mean     : -12360.86\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -12359.45\n",
      " ARIMA(3,0,3) with zero mean     : -12405.32\n",
      " ARIMA(2,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -12404.75\n",
      " ARIMA(2,0,4) with zero mean     : -12351.32\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -12360.99\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12245.28\n",
      " ARIMA(0,0,0) with non-zero mean : -7579.394\n",
      " ARIMA(1,0,0) with non-zero mean : -12250.31\n",
      " ARIMA(0,0,1) with non-zero mean : -9614.418\n",
      " ARIMA(0,0,0) with zero mean     : -7580.618\n",
      " ARIMA(2,0,0) with non-zero mean : -12248.88\n",
      " ARIMA(1,0,1) with non-zero mean : -12248.42\n",
      " ARIMA(2,0,1) with non-zero mean : -12247.28\n",
      " ARIMA(1,0,0) with zero mean     : -12252.25\n",
      " ARIMA(2,0,0) with zero mean     : -12250.84\n",
      " ARIMA(1,0,1) with zero mean     : -12250.37\n",
      " ARIMA(0,0,1) with zero mean     : -9615.668\n",
      " ARIMA(2,0,1) with zero mean     : -12249.09\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,0) with zero mean     : -12249.31\n",
      "\n",
      " Best model: ARIMA(1,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11918.13\n",
      " ARIMA(0,0,0) with non-zero mean : -7093.706\n",
      " ARIMA(1,0,0) with non-zero mean : -11917.05\n",
      " ARIMA(0,0,1) with non-zero mean : -9189.946\n",
      " ARIMA(0,0,0) with zero mean     : -7089.844\n",
      " ARIMA(1,0,2) with non-zero mean : -11919.1\n",
      " ARIMA(0,0,2) with non-zero mean : -10255.34\n",
      " ARIMA(1,0,1) with non-zero mean : -11919.47\n",
      " ARIMA(2,0,1) with non-zero mean : -11926.69\n",
      " ARIMA(2,0,0) with non-zero mean : -11918.19\n",
      " ARIMA(3,0,1) with non-zero mean : -11918.52\n",
      " ARIMA(3,0,0) with non-zero mean : -11918.52\n",
      " ARIMA(3,0,2) with non-zero mean : -11964.9\n",
      " ARIMA(4,0,2) with non-zero mean : -11921.13\n",
      " ARIMA(3,0,3) with non-zero mean : -11919.65\n",
      " ARIMA(2,0,3) with non-zero mean : -11921.89\n",
      " ARIMA(4,0,1) with non-zero mean : -11922.48\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11965.73\n",
      " ARIMA(2,0,2) with zero mean     : -11919.78\n",
      " ARIMA(3,0,1) with zero mean     : -11920.19\n",
      " ARIMA(4,0,2) with zero mean     : -11922.77\n",
      " ARIMA(3,0,3) with zero mean     : -11921.72\n",
      " ARIMA(2,0,1) with zero mean     : -11928.33\n",
      " ARIMA(2,0,3) with zero mean     : -11923.53\n",
      " ARIMA(4,0,1) with zero mean     : -11924.09\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11982.88\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11592.45\n",
      " ARIMA(0,1,0) with drift         : -11555.24\n",
      " ARIMA(1,1,0) with drift         : -11572.02\n",
      " ARIMA(0,1,1) with drift         : -11577.1\n",
      " ARIMA(0,1,0)                    : -11557.22\n",
      " ARIMA(1,1,2) with drift         : -11589.93\n",
      " ARIMA(2,1,1) with drift         : -11592.45\n",
      " ARIMA(1,1,1) with drift         : -11581.25\n",
      " ARIMA(2,1,0) with drift         : -11591.47\n",
      " ARIMA(3,1,1) with drift         : -11590.91\n",
      " ARIMA(3,1,0) with drift         : -11592.77\n",
      " ARIMA(4,1,0) with drift         : -11594.37\n",
      " ARIMA(5,1,0) with drift         : -11597.15\n",
      " ARIMA(5,1,1) with drift         : -11624.61\n",
      " ARIMA(4,1,1) with drift         : -11595.39\n",
      " ARIMA(5,1,2) with drift         : -11634.3\n",
      " ARIMA(4,1,2) with drift         : -11650.69\n",
      " ARIMA(3,1,2) with drift         : -11589.14\n",
      " ARIMA(4,1,3) with drift         : -11594.46\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(5,1,3) with drift         : -11642.34\n",
      " ARIMA(4,1,2)                    : -11652.57\n",
      " ARIMA(3,1,2)                    : -11591.12\n",
      " ARIMA(4,1,1)                    : -11597.4\n",
      " ARIMA(5,1,2)                    : -11636.3\n",
      " ARIMA(4,1,3)                    : -11596.53\n",
      " ARIMA(3,1,1)                    : -11592.9\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(5,1,1)                    : Inf\n",
      " ARIMA(5,1,3)                    : -11644.74\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(5,1,3)                    : Inf\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(5,1,2)                    : Inf\n",
      " ARIMA(5,1,2) with drift         : Inf\n",
      " ARIMA(5,1,1) with drift         : -11640.1\n",
      "\n",
      " Best model: ARIMA(5,1,1) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11415.47\n",
      " ARIMA(0,1,0) with drift         : -11362.54\n",
      " ARIMA(1,1,0) with drift         : -11389.78\n",
      " ARIMA(0,1,1) with drift         : -11394.48\n",
      " ARIMA(0,1,0)                    : -11364.55\n",
      " ARIMA(1,1,2) with drift         : -11409.16\n",
      " ARIMA(2,1,1) with drift         : -11412.81\n",
      " ARIMA(3,1,2) with drift         : -11412.71\n",
      " ARIMA(2,1,3) with drift         : -11413.64\n",
      " ARIMA(1,1,1) with drift         : -11398.6\n",
      " ARIMA(1,1,3) with drift         : -11410.51\n",
      " ARIMA(3,1,1) with drift         : -11412.09\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11417.47\n",
      " ARIMA(1,1,2)                    : -11411.16\n",
      " ARIMA(2,1,1)                    : -11414.81\n",
      " ARIMA(3,1,2)                    : -11414.69\n",
      " ARIMA(2,1,3)                    : -11415.64\n",
      " ARIMA(1,1,1)                    : -11400.6\n",
      " ARIMA(1,1,3)                    : -11412.52\n",
      " ARIMA(3,1,1)                    : -11414.08\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11425.36\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11353.65\n",
      " ARIMA(0,1,0) with drift         : -11294.89\n",
      " ARIMA(1,1,0) with drift         : -11324.01\n",
      " ARIMA(0,1,1) with drift         : -11330.99\n",
      " ARIMA(0,1,0)                    : -11296.89\n",
      " ARIMA(1,1,2) with drift         : -11345.36\n",
      " ARIMA(2,1,1) with drift         : -11350.29\n",
      " ARIMA(3,1,2) with drift         : -11350.17\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11334.27\n",
      " ARIMA(1,1,3) with drift         : -11347.22\n",
      " ARIMA(3,1,1) with drift         : -11349.78\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11355.66\n",
      " ARIMA(1,1,2)                    : -11347.37\n",
      " ARIMA(2,1,1)                    : -11352.3\n",
      " ARIMA(3,1,2)                    : -11352.16\n",
      " ARIMA(2,1,3)                    : -11353.71\n",
      " ARIMA(1,1,1)                    : -11336.27\n",
      " ARIMA(1,1,3)                    : -11349.22\n",
      " ARIMA(3,1,1)                    : -11351.79\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11365.31\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11320.7\n",
      " ARIMA(0,1,0) with drift         : -11261.92\n",
      " ARIMA(1,1,0) with drift         : -11289.31\n",
      " ARIMA(0,1,1) with drift         : -11296.15\n",
      " ARIMA(0,1,0)                    : -11263.9\n",
      " ARIMA(1,1,2) with drift         : -11312.32\n",
      " ARIMA(2,1,1) with drift         : -11317.17\n",
      " ARIMA(3,1,2) with drift         : -11317.32\n",
      " ARIMA(2,1,3) with drift         : -11318.7\n",
      " ARIMA(1,1,1) with drift         : -11299.93\n",
      " ARIMA(1,1,3) with drift         : -11314.09\n",
      " ARIMA(3,1,1) with drift         : -11316.82\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11322.69\n",
      " ARIMA(1,1,2)                    : -11314.3\n",
      " ARIMA(2,1,1)                    : -11319.15\n",
      " ARIMA(3,1,2)                    : -11319.28\n",
      " ARIMA(2,1,3)                    : -11320.61\n",
      " ARIMA(1,1,1)                    : -11301.9\n",
      " ARIMA(1,1,3)                    : -11316.07\n",
      " ARIMA(3,1,1)                    : -11318.8\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11331.48\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11266.31\n",
      " ARIMA(0,1,0) with drift         : -11205.21\n",
      " ARIMA(1,1,0) with drift         : -11233.03\n",
      " ARIMA(0,1,1) with drift         : -11240.17\n",
      " ARIMA(0,1,0)                    : -11207.21\n",
      " ARIMA(1,1,2) with drift         : -11254.87\n",
      " ARIMA(2,1,1) with drift         : -11261.21\n",
      " ARIMA(3,1,2) with drift         : -11262.81\n",
      " ARIMA(2,1,3) with drift         : -11264.32\n",
      " ARIMA(1,1,1) with drift         : -11242.56\n",
      " ARIMA(1,1,3) with drift         : -11258.05\n",
      " ARIMA(3,1,1) with drift         : -11262.14\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11268.32\n",
      " ARIMA(1,1,2)                    : -11256.88\n",
      " ARIMA(2,1,1)                    : -11263.21\n",
      " ARIMA(3,1,2)                    : -11264.84\n",
      " ARIMA(2,1,3)                    : -11266.33\n",
      " ARIMA(1,1,1)                    : -11244.57\n",
      " ARIMA(1,1,3)                    : -11260.06\n",
      " ARIMA(3,1,1)                    : -11264.14\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11277.31\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11262.05\n",
      " ARIMA(0,1,0) with drift         : -11192.23\n",
      " ARIMA(1,1,0) with drift         : -11226.71\n",
      " ARIMA(0,1,1) with drift         : -11231.46\n",
      " ARIMA(0,1,0)                    : -11194.21\n",
      " ARIMA(1,1,2) with drift         : -11247.34\n",
      " ARIMA(2,1,1) with drift         : -11252.98\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11305.6\n",
      " ARIMA(1,1,3) with drift         : -11251.68\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : -11261.91\n",
      " ARIMA(1,1,4) with drift         : -11257.86\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11307.46\n",
      " ARIMA(1,1,3)                    : -11253.67\n",
      " ARIMA(2,1,2)                    : -11264.03\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : -11263.89\n",
      " ARIMA(1,1,2)                    : -11249.32\n",
      " ARIMA(1,1,4)                    : -11259.86\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,4)                    : -11294.48\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4)                    : -11267.25\n",
      "\n",
      " Best model: ARIMA(1,1,4)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11328.07\n",
      " ARIMA(0,0,0) with non-zero mean : -6737.816\n",
      " ARIMA(1,0,0) with non-zero mean : -11296.4\n",
      " ARIMA(0,0,1) with non-zero mean : -8758.488\n",
      " ARIMA(0,0,0) with zero mean     : -6726.062\n",
      " ARIMA(1,0,2) with non-zero mean : -11320.74\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11400.22\n",
      " ARIMA(3,0,1) with non-zero mean : -11334.05\n",
      " ARIMA(4,0,2) with non-zero mean : -11349.24\n",
      " ARIMA(3,0,3) with non-zero mean : -11349.61\n",
      " ARIMA(2,0,3) with non-zero mean : -11343.52\n",
      " ARIMA(4,0,1) with non-zero mean : -11346.17\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11401.72\n",
      " ARIMA(2,0,2) with zero mean     : -11329.9\n",
      " ARIMA(3,0,1) with zero mean     : -11335.87\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11351.36\n",
      " ARIMA(2,0,1) with zero mean     : -11314.01\n",
      " ARIMA(2,0,3) with zero mean     : -11345.27\n",
      " ARIMA(4,0,1) with zero mean     : -11347.94\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11350.88\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11324.39\n",
      " ARIMA(0,0,0) with non-zero mean : -6739.838\n",
      " ARIMA(1,0,0) with non-zero mean : -11291.47\n",
      " ARIMA(0,0,1) with non-zero mean : -8753.561\n",
      " ARIMA(0,0,0) with zero mean     : -6728.901\n",
      " ARIMA(1,0,2) with non-zero mean : -11317.24\n",
      " ARIMA(2,0,1) with non-zero mean : -11314.87\n",
      " ARIMA(3,0,2) with non-zero mean : -11397.8\n",
      " ARIMA(3,0,1) with non-zero mean : -11330.92\n",
      " ARIMA(4,0,2) with non-zero mean : -11345.12\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11338.13\n",
      " ARIMA(4,0,1) with non-zero mean : -11342.03\n",
      " ARIMA(4,0,3) with non-zero mean : -11399.92\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11398.25\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11401.72\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11346.63\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11399.42\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11405.72\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11314.12\n",
      " ARIMA(0,0,0) with non-zero mean : -6723.367\n",
      " ARIMA(1,0,0) with non-zero mean : -11283.77\n",
      " ARIMA(0,0,1) with non-zero mean : -8741.907\n",
      " ARIMA(0,0,0) with zero mean     : -6711.968\n",
      " ARIMA(1,0,2) with non-zero mean : -11307.4\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11381.18\n",
      " ARIMA(3,0,1) with non-zero mean : -11320.77\n",
      " ARIMA(4,0,2) with non-zero mean : -11332\n",
      " ARIMA(3,0,3) with non-zero mean : -11332.98\n",
      " ARIMA(2,0,3) with non-zero mean : -11328.13\n",
      " ARIMA(4,0,1) with non-zero mean : -11331.31\n",
      " ARIMA(4,0,3) with non-zero mean : -11383.32\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11382.31\n",
      " ARIMA(3,0,4) with non-zero mean : -11359.17\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11384.72\n",
      " ARIMA(3,0,3) with zero mean     : -11334.68\n",
      " ARIMA(4,0,2) with zero mean     : -11333.85\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11382.66\n",
      " ARIMA(3,0,4) with zero mean     : -11360.21\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with zero mean     : -11440.78\n",
      " ARIMA(5,0,5) with zero mean     : -11456.27\n",
      " ARIMA(4,0,5) with zero mean     : Inf\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,5) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11396.91\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11305.83\n",
      " ARIMA(0,0,0) with non-zero mean : -6670.167\n",
      " ARIMA(1,0,0) with non-zero mean : -11278.25\n",
      " ARIMA(0,0,1) with non-zero mean : -8697.836\n",
      " ARIMA(0,0,0) with zero mean     : -6663.345\n",
      " ARIMA(1,0,2) with non-zero mean : -11300.93\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11382.19\n",
      " ARIMA(3,0,1) with non-zero mean : -11312.28\n",
      " ARIMA(4,0,2) with non-zero mean : -11324.03\n",
      " ARIMA(3,0,3) with non-zero mean : -11324.58\n",
      " ARIMA(2,0,3) with non-zero mean : -11320.3\n",
      " ARIMA(4,0,1) with non-zero mean : -11323.14\n",
      " ARIMA(4,0,3) with non-zero mean : -11382.62\n",
      " ARIMA(5,0,3) with non-zero mean : -11391.42\n",
      " ARIMA(5,0,2) with non-zero mean : -11375.24\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11388.66\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11299.77\n",
      " ARIMA(0,0,0) with non-zero mean : -6664.974\n",
      " ARIMA(1,0,0) with non-zero mean : -11273.07\n",
      " ARIMA(0,0,1) with non-zero mean : -8693.479\n",
      " ARIMA(0,0,0) with zero mean     : -6658.911\n",
      " ARIMA(1,0,2) with non-zero mean : -11295.08\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11384.49\n",
      " ARIMA(3,0,1) with non-zero mean : -11305.45\n",
      " ARIMA(4,0,2) with non-zero mean : -11318.63\n",
      " ARIMA(3,0,3) with non-zero mean : -11318.26\n",
      " ARIMA(2,0,3) with non-zero mean : -11313.84\n",
      " ARIMA(4,0,1) with non-zero mean : -11316.33\n",
      " ARIMA(4,0,3) with non-zero mean : -11379.31\n",
      " ARIMA(3,0,2) with zero mean     : -11386.24\n",
      " ARIMA(2,0,2) with zero mean     : -11301.64\n",
      " ARIMA(3,0,1) with zero mean     : -11307.33\n",
      " ARIMA(4,0,2) with zero mean     : -11320.49\n",
      " ARIMA(3,0,3) with zero mean     : -11320.1\n",
      " ARIMA(2,0,1) with zero mean     : -11294.37\n",
      " ARIMA(2,0,3) with zero mean     : -11315.67\n",
      " ARIMA(4,0,1) with zero mean     : -11318.18\n",
      " ARIMA(4,0,3) with zero mean     : -11381.1\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11385.3\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11310.13\n",
      " ARIMA(0,0,0) with non-zero mean : -6682.719\n",
      " ARIMA(1,0,0) with non-zero mean : -11283.7\n",
      " ARIMA(0,0,1) with non-zero mean : -8709.728\n",
      " ARIMA(0,0,0) with zero mean     : -6679.951\n",
      " ARIMA(1,0,2) with non-zero mean : -11305.28\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11394.4\n",
      " ARIMA(3,0,1) with non-zero mean : -11315.74\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11324.19\n",
      " ARIMA(4,0,1) with non-zero mean : -11326.94\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : -11394.4\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11318.53\n",
      " ARIMA(0,0,0) with non-zero mean : -6684.289\n",
      " ARIMA(1,0,0) with non-zero mean : -11291.02\n",
      " ARIMA(0,0,1) with non-zero mean : -8709.777\n",
      " ARIMA(0,0,0) with zero mean     : -6682.252\n",
      " ARIMA(1,0,2) with non-zero mean : -11313.56\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11407.09\n",
      " ARIMA(3,0,1) with non-zero mean : -11326.07\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -11411.55\n",
      " ARIMA(2,0,3) with non-zero mean : -11332.96\n",
      " ARIMA(4,0,3) with non-zero mean : -11406.01\n",
      " ARIMA(3,0,4) with non-zero mean : -11393.61\n",
      " ARIMA(2,0,4) with non-zero mean : -11372\n",
      " ARIMA(4,0,4) with non-zero mean : -11408.79\n",
      " ARIMA(3,0,3) with zero mean     : -11413.52\n",
      " ARIMA(2,0,3) with zero mean     : -11334.9\n",
      " ARIMA(3,0,2) with zero mean     : -11409.07\n",
      " ARIMA(4,0,3) with zero mean     : -11407.69\n",
      " ARIMA(3,0,4) with zero mean     : -11393.81\n",
      " ARIMA(2,0,2) with zero mean     : -11320.49\n",
      " ARIMA(2,0,4) with zero mean     : -11373.96\n",
      " ARIMA(4,0,2) with zero mean     : -11342.57\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11404.21\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11332.95\n",
      " ARIMA(0,0,0) with non-zero mean : -6690.754\n",
      " ARIMA(1,0,0) with non-zero mean : -11305.57\n",
      " ARIMA(0,0,1) with non-zero mean : -8717.595\n",
      " ARIMA(0,0,0) with zero mean     : -6690.452\n",
      " ARIMA(1,0,2) with non-zero mean : -11328.33\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11416.47\n",
      " ARIMA(3,0,1) with non-zero mean : -11342.34\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -11418.63\n",
      " ARIMA(2,0,3) with non-zero mean : -11348.62\n",
      " ARIMA(4,0,3) with non-zero mean : -11414.74\n",
      " ARIMA(3,0,4) with non-zero mean : -11416.61\n",
      " ARIMA(2,0,4) with non-zero mean : -11388.3\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11420.66\n",
      " ARIMA(2,0,3) with zero mean     : -11350.61\n",
      " ARIMA(3,0,2) with zero mean     : -11418.51\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -11418.65\n",
      " ARIMA(2,0,2) with zero mean     : -11334.95\n",
      " ARIMA(2,0,4) with zero mean     : -11390.32\n",
      " ARIMA(4,0,2) with zero mean     : -11357.1\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11415.5\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11356.17\n",
      " ARIMA(0,0,0) with non-zero mean : -6690.499\n",
      " ARIMA(1,0,0) with non-zero mean : -11329.91\n",
      " ARIMA(0,0,1) with non-zero mean : -8719.031\n",
      " ARIMA(0,0,0) with zero mean     : -6690.897\n",
      " ARIMA(1,0,2) with non-zero mean : -11352.13\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11428.68\n",
      " ARIMA(3,0,1) with non-zero mean : -11362.48\n",
      " ARIMA(4,0,2) with non-zero mean : -11375.33\n",
      " ARIMA(3,0,3) with non-zero mean : -11375.66\n",
      " ARIMA(2,0,3) with non-zero mean : -11371.34\n",
      " ARIMA(4,0,1) with non-zero mean : -11374.63\n",
      " ARIMA(4,0,3) with non-zero mean : -11431.51\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11412.53\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11433.45\n",
      " ARIMA(3,0,3) with zero mean     : -11377.55\n",
      " ARIMA(4,0,2) with zero mean     : -11376.63\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11430.46\n",
      " ARIMA(3,0,4) with zero mean     : -11376.2\n",
      " ARIMA(5,0,2) with zero mean     : -11414.43\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -11432.83\n",
      "\n",
      " Best model: ARIMA(4,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11368.76\n",
      " ARIMA(0,0,0) with non-zero mean : -6688.274\n",
      " ARIMA(1,0,0) with non-zero mean : -11342.11\n",
      " ARIMA(0,0,1) with non-zero mean : -8719.819\n",
      " ARIMA(0,0,0) with zero mean     : -6687.667\n",
      " ARIMA(1,0,2) with non-zero mean : -11363.98\n",
      " ARIMA(2,0,1) with non-zero mean : -11362.28\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11383.19\n",
      " ARIMA(1,0,3) with non-zero mean : -11385.67\n",
      " ARIMA(0,0,3) with non-zero mean : -10195.6\n",
      " ARIMA(1,0,4) with non-zero mean : -11384.18\n",
      " ARIMA(0,0,2) with non-zero mean : -9651.636\n",
      " ARIMA(0,0,4) with non-zero mean : -10619.64\n",
      " ARIMA(2,0,4) with non-zero mean : -11413.52\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11423.72\n",
      " ARIMA(1,0,5) with non-zero mean : -11388.13\n",
      " ARIMA(3,0,5) with non-zero mean : -11416.08\n",
      " ARIMA(2,0,5) with zero mean     : -11425.66\n",
      " ARIMA(1,0,5) with zero mean     : -11390.15\n",
      " ARIMA(2,0,4) with zero mean     : -11415.42\n",
      " ARIMA(3,0,5) with zero mean     : -11418.12\n",
      " ARIMA(1,0,4) with zero mean     : -11386.19\n",
      " ARIMA(3,0,4) with zero mean     : -11485.51\n",
      " ARIMA(3,0,3) with zero mean     : -11390.06\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -11385.19\n",
      " ARIMA(4,0,3) with zero mean     : -11445.33\n",
      " ARIMA(4,0,5) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,5) with zero mean     : -11430.84\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11379.91\n",
      " ARIMA(0,0,0) with non-zero mean : -6735.304\n",
      " ARIMA(1,0,0) with non-zero mean : -11354.43\n",
      " ARIMA(0,0,1) with non-zero mean : -8758.988\n",
      " ARIMA(0,0,0) with zero mean     : -6737.172\n",
      " ARIMA(1,0,2) with non-zero mean : -11375.63\n",
      " ARIMA(2,0,1) with non-zero mean : -11373.84\n",
      " ARIMA(3,0,2) with non-zero mean : -11461.55\n",
      " ARIMA(3,0,1) with non-zero mean : -11386.02\n",
      " ARIMA(4,0,2) with non-zero mean : -11400.26\n",
      " ARIMA(3,0,3) with non-zero mean : -11400.01\n",
      " ARIMA(2,0,3) with non-zero mean : -11395.61\n",
      " ARIMA(4,0,1) with non-zero mean : -11398.44\n",
      " ARIMA(4,0,3) with non-zero mean : -11457.4\n",
      " ARIMA(3,0,2) with zero mean     : -11463.57\n",
      " ARIMA(2,0,2) with zero mean     : -11381.74\n",
      " ARIMA(3,0,1) with zero mean     : -11388.02\n",
      " ARIMA(4,0,2) with zero mean     : -11402.26\n",
      " ARIMA(3,0,3) with zero mean     : -11402.03\n",
      " ARIMA(2,0,1) with zero mean     : -11375.86\n",
      " ARIMA(2,0,3) with zero mean     : -11397.63\n",
      " ARIMA(4,0,1) with zero mean     : -11400.45\n",
      " ARIMA(4,0,3) with zero mean     : -11459.4\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11399.38\n",
      "\n",
      " Best model: ARIMA(4,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11418.83\n",
      " ARIMA(0,0,0) with non-zero mean : -6770.192\n",
      " ARIMA(1,0,0) with non-zero mean : -11389.52\n",
      " ARIMA(0,0,1) with non-zero mean : -8798.915\n",
      " ARIMA(0,0,0) with zero mean     : -6772.157\n",
      " ARIMA(1,0,2) with non-zero mean : -11413.24\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11497.24\n",
      " ARIMA(3,0,1) with non-zero mean : -11425.94\n",
      " ARIMA(4,0,2) with non-zero mean : -11440.64\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11432.73\n",
      " ARIMA(4,0,1) with non-zero mean : -11439.86\n",
      " ARIMA(4,0,3) with non-zero mean : -11482.5\n",
      " ARIMA(3,0,2) with zero mean     : -11499.25\n",
      " ARIMA(2,0,2) with zero mean     : -11420.85\n",
      " ARIMA(3,0,1) with zero mean     : -11427.95\n",
      " ARIMA(4,0,2) with zero mean     : -11442.65\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -11434.74\n",
      " ARIMA(4,0,1) with zero mean     : -11441.87\n",
      " ARIMA(4,0,3) with zero mean     : -11484.67\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11438.64\n",
      "\n",
      " Best model: ARIMA(4,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11414.32\n",
      " ARIMA(0,0,0) with non-zero mean : -6776.125\n",
      " ARIMA(1,0,0) with non-zero mean : -11387.21\n",
      " ARIMA(0,0,1) with non-zero mean : -8799.227\n",
      " ARIMA(0,0,0) with zero mean     : -6777.222\n",
      " ARIMA(1,0,2) with non-zero mean : -11409.82\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11486.69\n",
      " ARIMA(3,0,1) with non-zero mean : -11419.62\n",
      " ARIMA(4,0,2) with non-zero mean : -11432.54\n",
      " ARIMA(3,0,3) with non-zero mean : -11432.11\n",
      " ARIMA(2,0,3) with non-zero mean : -11428.57\n",
      " ARIMA(4,0,1) with non-zero mean : -11432.22\n",
      " ARIMA(4,0,3) with non-zero mean : -11426.07\n",
      " ARIMA(3,0,2) with zero mean     : -11488.4\n",
      " ARIMA(2,0,2) with zero mean     : -11416.24\n",
      " ARIMA(3,0,1) with zero mean     : -11421.53\n",
      " ARIMA(4,0,2) with zero mean     : -11434.45\n",
      " ARIMA(3,0,3) with zero mean     : -11434.02\n",
      " ARIMA(2,0,1) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -11430.48\n",
      " ARIMA(4,0,1) with zero mean     : -11434.15\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11433.84\n",
      "\n",
      " Best model: ARIMA(4,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11396.28\n",
      " ARIMA(0,0,0) with non-zero mean : -6767.655\n",
      " ARIMA(1,0,0) with non-zero mean : -11366.24\n",
      " ARIMA(0,0,1) with non-zero mean : -8786.68\n",
      " ARIMA(0,0,0) with zero mean     : -6768.269\n",
      " ARIMA(1,0,2) with non-zero mean : -11391.4\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11410.85\n",
      " ARIMA(1,0,3) with non-zero mean : -11413.2\n",
      " ARIMA(0,0,3) with non-zero mean : -10241.8\n",
      " ARIMA(1,0,4) with non-zero mean : -11411.5\n",
      " ARIMA(0,0,2) with non-zero mean : -9706.747\n",
      " ARIMA(0,0,4) with non-zero mean : -10664.67\n",
      " ARIMA(2,0,4) with non-zero mean : -11450.27\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11458.58\n",
      " ARIMA(1,0,5) with non-zero mean : -11415.38\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with zero mean     : -11460.53\n",
      " ARIMA(1,0,5) with zero mean     : -11417.36\n",
      " ARIMA(2,0,4) with zero mean     : -11452.21\n",
      " ARIMA(3,0,5) with zero mean     : -11458.99\n",
      " ARIMA(1,0,4) with zero mean     : -11413.48\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,5) with zero mean     : -11459.53\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11379.85\n",
      " ARIMA(0,0,0) with non-zero mean : -6769.06\n",
      " ARIMA(1,0,0) with non-zero mean : -11350.52\n",
      " ARIMA(0,0,1) with non-zero mean : -8784.121\n",
      " ARIMA(0,0,0) with zero mean     : -6770.196\n",
      " ARIMA(1,0,2) with non-zero mean : -11374.77\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11440.14\n",
      " ARIMA(3,0,1) with non-zero mean : -11385.46\n",
      " ARIMA(4,0,2) with non-zero mean : -11398.72\n",
      " ARIMA(3,0,3) with non-zero mean : -11399.1\n",
      " ARIMA(2,0,3) with non-zero mean : -11395.62\n",
      " ARIMA(4,0,1) with non-zero mean : -11397.24\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11442.2\n",
      " ARIMA(2,0,2) with zero mean     : -11381.87\n",
      " ARIMA(3,0,1) with zero mean     : -11387.48\n",
      " ARIMA(4,0,2) with zero mean     : -11400.7\n",
      " ARIMA(3,0,3) with zero mean     : -11401.11\n",
      " ARIMA(2,0,1) with zero mean     : -11375.84\n",
      " ARIMA(2,0,3) with zero mean     : -11397.63\n",
      " ARIMA(4,0,1) with zero mean     : -11399.24\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11400.25\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11368.58\n",
      " ARIMA(0,0,0) with non-zero mean : -6755.177\n",
      " ARIMA(1,0,0) with non-zero mean : -11340.91\n",
      " ARIMA(0,0,1) with non-zero mean : -8775.252\n",
      " ARIMA(0,0,0) with zero mean     : -6756.647\n",
      " ARIMA(1,0,2) with non-zero mean : -11363.4\n",
      " ARIMA(2,0,1) with non-zero mean : -11362.12\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11383.49\n",
      " ARIMA(1,0,3) with non-zero mean : -11385.66\n",
      " ARIMA(0,0,3) with non-zero mean : -10228.52\n",
      " ARIMA(1,0,4) with non-zero mean : -11383.84\n",
      " ARIMA(0,0,2) with non-zero mean : -9695.095\n",
      " ARIMA(0,0,4) with non-zero mean : -10649.52\n",
      " ARIMA(2,0,4) with non-zero mean : -11413.73\n",
      " ARIMA(3,0,4) with non-zero mean : -11467.64\n",
      " ARIMA(3,0,3) with non-zero mean : -11386.95\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : -11449.17\n",
      " ARIMA(2,0,5) with non-zero mean : -11419.96\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -11459.53\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11424.77\n",
      "\n",
      " Best model: ARIMA(2,0,5) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11384.56\n",
      " ARIMA(0,0,0) with non-zero mean : -6817.572\n",
      " ARIMA(1,0,0) with non-zero mean : -11356.29\n",
      " ARIMA(0,0,1) with non-zero mean : -8815.3\n",
      " ARIMA(0,0,0) with zero mean     : -6819.524\n",
      " ARIMA(1,0,2) with non-zero mean : -11378.77\n",
      " ARIMA(2,0,1) with non-zero mean : -11376.91\n",
      " ARIMA(3,0,2) with non-zero mean : -11457.48\n",
      " ARIMA(3,0,1) with non-zero mean : -11390.32\n",
      " ARIMA(4,0,2) with non-zero mean : -11401.89\n",
      " ARIMA(3,0,3) with non-zero mean : -11402.85\n",
      " ARIMA(2,0,3) with non-zero mean : -11397.85\n",
      " ARIMA(4,0,1) with non-zero mean : -11401.42\n",
      " ARIMA(4,0,3) with non-zero mean : -11408.13\n",
      " ARIMA(3,0,2) with zero mean     : -11459.44\n",
      " ARIMA(2,0,2) with zero mean     : -11386.54\n",
      " ARIMA(3,0,1) with zero mean     : -11392.27\n",
      " ARIMA(4,0,2) with zero mean     : -11403.82\n",
      " ARIMA(3,0,3) with zero mean     : -11404.78\n",
      " ARIMA(2,0,1) with zero mean     : -11378.84\n",
      " ARIMA(2,0,3) with zero mean     : -11399.82\n",
      " ARIMA(4,0,1) with zero mean     : -11403.36\n",
      " ARIMA(4,0,3) with zero mean     : -11401.82\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -11429.81\n",
      "\n",
      " Best model: ARIMA(4,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11412.64\n",
      " ARIMA(0,0,0) with non-zero mean : -6848.389\n",
      " ARIMA(1,0,0) with non-zero mean : -11381.79\n",
      " ARIMA(0,0,1) with non-zero mean : -8850.215\n",
      " ARIMA(0,0,0) with zero mean     : -6849.878\n",
      " ARIMA(1,0,2) with non-zero mean : -11405.42\n",
      " ARIMA(2,0,1) with non-zero mean : -11408.53\n",
      " ARIMA(3,0,2) with non-zero mean : -11426.53\n",
      " ARIMA(3,0,1) with non-zero mean : -11419.05\n",
      " ARIMA(4,0,2) with non-zero mean : -11428.85\n",
      " ARIMA(4,0,1) with non-zero mean : -11428.66\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -11427.82\n",
      " ARIMA(5,0,1) with non-zero mean : -11459.29\n",
      " ARIMA(5,0,0) with non-zero mean : -11427.85\n",
      " ARIMA(4,0,0) with non-zero mean : -11430.59\n",
      " ARIMA(5,0,1) with zero mean     : -11461.27\n",
      " ARIMA(4,0,1) with zero mean     : -11430.65\n",
      " ARIMA(5,0,0) with zero mean     : -11429.84\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,0) with zero mean     : -11432.58\n",
      " ARIMA(4,0,2) with zero mean     : -11431.03\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,1) with zero mean     : -11456.59\n",
      "\n",
      " Best model: ARIMA(5,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11417.39\n",
      " ARIMA(0,0,0) with non-zero mean : -6856.506\n",
      " ARIMA(1,0,0) with non-zero mean : -11388.09\n",
      " ARIMA(0,0,1) with non-zero mean : -8862.562\n",
      " ARIMA(0,0,0) with zero mean     : -6858.168\n",
      " ARIMA(1,0,2) with non-zero mean : -11413.18\n",
      " ARIMA(2,0,1) with non-zero mean : -11411.51\n",
      " ARIMA(3,0,2) with non-zero mean : -11436.07\n",
      " ARIMA(3,0,1) with non-zero mean : -11423.64\n",
      " ARIMA(4,0,2) with non-zero mean : -11435.75\n",
      " ARIMA(3,0,3) with non-zero mean : -11435.89\n",
      " ARIMA(2,0,3) with non-zero mean : -11430.71\n",
      " ARIMA(4,0,1) with non-zero mean : -11434.25\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11438.08\n",
      " ARIMA(2,0,2) with zero mean     : -11419.4\n",
      " ARIMA(3,0,1) with zero mean     : -11425.65\n",
      " ARIMA(4,0,2) with zero mean     : -11437.77\n",
      " ARIMA(3,0,3) with zero mean     : -11437.9\n",
      " ARIMA(2,0,1) with zero mean     : -11413.52\n",
      " ARIMA(2,0,3) with zero mean     : -11432.72\n",
      " ARIMA(4,0,1) with zero mean     : -11436.26\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11434.82\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11423.12\n",
      " ARIMA(0,0,0) with non-zero mean : -6855.742\n",
      " ARIMA(1,0,0) with non-zero mean : -11392.02\n",
      " ARIMA(0,0,1) with non-zero mean : -8862.21\n",
      " ARIMA(0,0,0) with zero mean     : -6857.312\n",
      " ARIMA(1,0,2) with non-zero mean : -11417.26\n",
      " ARIMA(2,0,1) with non-zero mean : -11416.16\n",
      " ARIMA(3,0,2) with non-zero mean : -11493.1\n",
      " ARIMA(3,0,1) with non-zero mean : -11428.28\n",
      " ARIMA(4,0,2) with non-zero mean : -11437.52\n",
      " ARIMA(3,0,3) with non-zero mean : -11438.52\n",
      " ARIMA(2,0,3) with non-zero mean : -11434.97\n",
      " ARIMA(4,0,1) with non-zero mean : -11437.01\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11495.07\n",
      " ARIMA(2,0,2) with zero mean     : -11425.08\n",
      " ARIMA(3,0,1) with zero mean     : -11430.27\n",
      " ARIMA(4,0,2) with zero mean     : -11439.6\n",
      " ARIMA(3,0,3) with zero mean     : -11440.51\n",
      " ARIMA(2,0,1) with zero mean     : -11418.15\n",
      " ARIMA(2,0,3) with zero mean     : -11436.96\n",
      " ARIMA(4,0,1) with zero mean     : -11438.99\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11438.77\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11430.97\n",
      " ARIMA(0,0,0) with non-zero mean : -6848.48\n",
      " ARIMA(1,0,0) with non-zero mean : -11402.64\n",
      " ARIMA(0,0,1) with non-zero mean : -8856.769\n",
      " ARIMA(0,0,0) with zero mean     : -6849.649\n",
      " ARIMA(1,0,2) with non-zero mean : -11427.39\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11502.31\n",
      " ARIMA(3,0,1) with non-zero mean : -11437.26\n",
      " ARIMA(4,0,2) with non-zero mean : -11447.51\n",
      " ARIMA(3,0,3) with non-zero mean : -11448.73\n",
      " ARIMA(2,0,3) with non-zero mean : -11443.78\n",
      " ARIMA(4,0,1) with non-zero mean : -11446.63\n",
      " ARIMA(4,0,3) with non-zero mean : -11509.92\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -11446.8\n",
      " ARIMA(5,0,2) with non-zero mean : -11447.79\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11511.9\n",
      " ARIMA(3,0,3) with zero mean     : -11450.67\n",
      " ARIMA(4,0,2) with zero mean     : -11449.59\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11504.14\n",
      " ARIMA(3,0,4) with zero mean     : -11448.79\n",
      " ARIMA(5,0,2) with zero mean     : -11449.75\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11448.04\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11440.69\n",
      " ARIMA(0,0,0) with non-zero mean : -6856.218\n",
      " ARIMA(1,0,0) with non-zero mean : -11411.42\n",
      " ARIMA(0,0,1) with non-zero mean : -8866.494\n",
      " ARIMA(0,0,0) with zero mean     : -6856.027\n",
      " ARIMA(1,0,2) with non-zero mean : -11436.86\n",
      " ARIMA(2,0,1) with non-zero mean : -11435.31\n",
      " ARIMA(3,0,2) with non-zero mean : -11514.58\n",
      " ARIMA(3,0,1) with non-zero mean : -11446.49\n",
      " ARIMA(4,0,2) with non-zero mean : -11454.49\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11453.31\n",
      " ARIMA(4,0,1) with non-zero mean : -11454.65\n",
      " ARIMA(4,0,3) with non-zero mean : -11488.67\n",
      " ARIMA(3,0,2) with zero mean     : -11516.38\n",
      " ARIMA(2,0,2) with zero mean     : -11442.63\n",
      " ARIMA(3,0,1) with zero mean     : -11448.44\n",
      " ARIMA(4,0,2) with zero mean     : -11456.57\n",
      " ARIMA(3,0,3) with zero mean     : -11457.42\n",
      " ARIMA(2,0,1) with zero mean     : -11437.26\n",
      " ARIMA(2,0,3) with zero mean     : -11455.25\n",
      " ARIMA(4,0,1) with zero mean     : -11456.59\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -11493.26\n",
      "\n",
      " Best model: ARIMA(4,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11441.76\n",
      " ARIMA(0,0,0) with non-zero mean : -6867.168\n",
      " ARIMA(1,0,0) with non-zero mean : -11412.83\n",
      " ARIMA(0,0,1) with non-zero mean : -8874.459\n",
      " ARIMA(0,0,0) with zero mean     : -6868.118\n",
      " ARIMA(1,0,2) with non-zero mean : -11438.26\n",
      " ARIMA(2,0,1) with non-zero mean : -11439.57\n",
      " ARIMA(3,0,2) with non-zero mean : -11460.46\n",
      " ARIMA(3,0,1) with non-zero mean : -11452.45\n",
      " ARIMA(4,0,2) with non-zero mean : -11460.15\n",
      " ARIMA(3,0,3) with non-zero mean : -11460.42\n",
      " ARIMA(2,0,3) with non-zero mean : -11457.03\n",
      " ARIMA(4,0,1) with non-zero mean : -11460.67\n",
      " ARIMA(4,0,0) with non-zero mean : -11462.52\n",
      " ARIMA(3,0,0) with non-zero mean : -11445.99\n",
      " ARIMA(5,0,0) with non-zero mean : -11460.51\n",
      " ARIMA(5,0,1) with non-zero mean : -11490.28\n",
      " ARIMA(5,0,2) with non-zero mean : -11489.45\n",
      " ARIMA(5,0,1) with zero mean     : -11492.28\n",
      " ARIMA(4,0,1) with zero mean     : -11462.63\n",
      " ARIMA(5,0,0) with zero mean     : -11462.47\n",
      " ARIMA(5,0,2) with zero mean     : -11491.47\n",
      " ARIMA(4,0,0) with zero mean     : -11464.49\n",
      " ARIMA(4,0,2) with zero mean     : -11462.11\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,1) with zero mean     : -11489.3\n",
      "\n",
      " Best model: ARIMA(5,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11450.16\n",
      " ARIMA(0,0,0) with non-zero mean : -6876.022\n",
      " ARIMA(1,0,0) with non-zero mean : -11420.01\n",
      " ARIMA(0,0,1) with non-zero mean : -8882.957\n",
      " ARIMA(0,0,0) with zero mean     : -6875.829\n",
      " ARIMA(1,0,2) with non-zero mean : -11445.95\n",
      " ARIMA(2,0,1) with non-zero mean : -11444.35\n",
      " ARIMA(3,0,2) with non-zero mean : -11466.46\n",
      " ARIMA(3,0,1) with non-zero mean : -11456.16\n",
      " ARIMA(4,0,2) with non-zero mean : -11465.03\n",
      " ARIMA(3,0,3) with non-zero mean : -11466.1\n",
      " ARIMA(2,0,3) with non-zero mean : -11463.41\n",
      " ARIMA(4,0,1) with non-zero mean : -11464.87\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11468.34\n",
      " ARIMA(2,0,2) with zero mean     : -11452.05\n",
      " ARIMA(3,0,1) with zero mean     : -11458.07\n",
      " ARIMA(4,0,2) with zero mean     : -11466.92\n",
      " ARIMA(3,0,3) with zero mean     : -11468.01\n",
      " ARIMA(2,0,1) with zero mean     : -11446.24\n",
      " ARIMA(2,0,3) with zero mean     : -11465.3\n",
      " ARIMA(4,0,1) with zero mean     : -11466.76\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11467.86\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11459.35\n",
      " ARIMA(0,0,0) with non-zero mean : -6885.081\n",
      " ARIMA(1,0,0) with non-zero mean : -11430.32\n",
      " ARIMA(0,0,1) with non-zero mean : -8894.963\n",
      " ARIMA(0,0,0) with zero mean     : -6883.912\n",
      " ARIMA(1,0,2) with non-zero mean : -11455.26\n",
      " ARIMA(2,0,1) with non-zero mean : -11453.41\n",
      " ARIMA(3,0,2) with non-zero mean : -11478.09\n",
      " ARIMA(3,0,1) with non-zero mean : -11465.83\n",
      " ARIMA(4,0,2) with non-zero mean : -11476.69\n",
      " ARIMA(3,0,3) with non-zero mean : -11477.8\n",
      " ARIMA(2,0,3) with non-zero mean : -11472.47\n",
      " ARIMA(4,0,1) with non-zero mean : -11475.17\n",
      " ARIMA(4,0,3) with non-zero mean : -11529.99\n",
      " ARIMA(5,0,3) with non-zero mean : -11474.61\n",
      " ARIMA(4,0,4) with non-zero mean : -11559.37\n",
      " ARIMA(3,0,4) with non-zero mean : -11492.22\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : -11504.37\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,4) with non-zero mean : -11508.64\n",
      "\n",
      " Best model: ARIMA(4,0,4) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11473.67\n",
      " ARIMA(0,0,0) with non-zero mean : -6904.305\n",
      " ARIMA(1,0,0) with non-zero mean : -11442.86\n",
      " ARIMA(0,0,1) with non-zero mean : -8909.573\n",
      " ARIMA(0,0,0) with zero mean     : -6902.564\n",
      " ARIMA(1,0,2) with non-zero mean : -11467.87\n",
      " ARIMA(2,0,1) with non-zero mean : -11468.18\n",
      " ARIMA(3,0,2) with non-zero mean : -11488.61\n",
      " ARIMA(3,0,1) with non-zero mean : -11478.94\n",
      " ARIMA(4,0,2) with non-zero mean : -11488.89\n",
      " ARIMA(4,0,1) with non-zero mean : -11488.23\n",
      " ARIMA(5,0,2) with non-zero mean : -11530.04\n",
      " ARIMA(5,0,1) with non-zero mean : -11514.48\n",
      " ARIMA(5,0,3) with non-zero mean : -11533.06\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,1) with non-zero mean : -11515.81\n",
      "\n",
      " Best model: ARIMA(5,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11497.17\n",
      " ARIMA(0,0,0) with non-zero mean : -7026.856\n",
      " ARIMA(1,0,0) with non-zero mean : -11463.53\n",
      " ARIMA(0,0,1) with non-zero mean : -8998.064\n",
      " ARIMA(0,0,0) with zero mean     : -7018.215\n",
      " ARIMA(1,0,2) with non-zero mean : -11490.08\n",
      " ARIMA(2,0,1) with non-zero mean : -11479.81\n",
      " ARIMA(3,0,2) with non-zero mean : -11511.03\n",
      " ARIMA(3,0,1) with non-zero mean : -11502\n",
      " ARIMA(4,0,2) with non-zero mean : -11515.83\n",
      " ARIMA(4,0,1) with non-zero mean : -11517.05\n",
      " ARIMA(4,0,0) with non-zero mean : -11516.32\n",
      " ARIMA(5,0,1) with non-zero mean : -11532.81\n",
      " ARIMA(5,0,0) with non-zero mean : -11533.61\n",
      " ARIMA(5,0,0) with zero mean     : -11534.97\n",
      " ARIMA(4,0,0) with zero mean     : -11517.84\n",
      " ARIMA(5,0,1) with zero mean     : -11534.17\n",
      " ARIMA(4,0,1) with zero mean     : -11518.5\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,0) with zero mean     : -11510.2\n",
      "\n",
      " Best model: ARIMA(5,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11522.36\n",
      " ARIMA(0,0,0) with non-zero mean : -6976.397\n",
      " ARIMA(1,0,0) with non-zero mean : -11483.5\n",
      " ARIMA(0,0,1) with non-zero mean : -8955.384\n",
      " ARIMA(0,0,0) with zero mean     : -6973.519\n",
      " ARIMA(1,0,2) with non-zero mean : -11518.05\n",
      " ARIMA(2,0,1) with non-zero mean : -11502.5\n",
      " ARIMA(3,0,2) with non-zero mean : -11539.76\n",
      " ARIMA(3,0,1) with non-zero mean : -11532\n",
      " ARIMA(4,0,2) with non-zero mean : -11540.01\n",
      " ARIMA(4,0,1) with non-zero mean : -11541.17\n",
      " ARIMA(4,0,0) with non-zero mean : -11542.91\n",
      " ARIMA(3,0,0) with non-zero mean : -11523.24\n",
      " ARIMA(5,0,0) with non-zero mean : -11548.94\n",
      " ARIMA(5,0,1) with non-zero mean : -11560.19\n",
      " ARIMA(5,0,2) with non-zero mean : -11558.2\n",
      " ARIMA(5,0,1) with zero mean     : -11562.08\n",
      " ARIMA(4,0,1) with zero mean     : -11543.1\n",
      " ARIMA(5,0,0) with zero mean     : -11550.92\n",
      " ARIMA(5,0,2) with zero mean     : -11560.09\n",
      " ARIMA(4,0,0) with zero mean     : -11544.85\n",
      " ARIMA(4,0,2) with zero mean     : -11541.94\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,1) with zero mean     : -11573.33\n",
      "\n",
      " Best model: ARIMA(5,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11485.88\n",
      " ARIMA(0,0,0) with non-zero mean : -7008.245\n",
      " ARIMA(1,0,0) with non-zero mean : -11447.22\n",
      " ARIMA(0,0,1) with non-zero mean : -8956.127\n",
      " ARIMA(0,0,0) with zero mean     : -7003.898\n",
      " ARIMA(1,0,2) with non-zero mean : -11483.16\n",
      " ARIMA(2,0,1) with non-zero mean : -11482.32\n",
      " ARIMA(3,0,2) with non-zero mean : -11506.05\n",
      " ARIMA(3,0,1) with non-zero mean : -11491.58\n",
      " ARIMA(4,0,2) with non-zero mean : -11505.48\n",
      " ARIMA(3,0,3) with non-zero mean : -11505.8\n",
      " ARIMA(2,0,3) with non-zero mean : -11498.3\n",
      " ARIMA(4,0,1) with non-zero mean : -11502.45\n",
      " ARIMA(4,0,3) with non-zero mean : -11520.2\n",
      " ARIMA(5,0,3) with non-zero mean : -11529.58\n",
      " ARIMA(5,0,2) with non-zero mean : -11525.97\n",
      " ARIMA(5,0,4) with non-zero mean : -11582.08\n",
      " ARIMA(4,0,4) with non-zero mean : -11531.68\n",
      " ARIMA(5,0,5) with non-zero mean : -11565.09\n",
      " ARIMA(4,0,5) with non-zero mean : -11538.66\n",
      " ARIMA(5,0,4) with zero mean     : -11583.66\n",
      " ARIMA(4,0,4) with zero mean     : -11533.24\n",
      " ARIMA(5,0,3) with zero mean     : -11531.52\n",
      " ARIMA(5,0,5) with zero mean     : -11566.72\n",
      " ARIMA(4,0,3) with zero mean     : -11521.86\n",
      " ARIMA(4,0,5) with zero mean     : -11540.44\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,5) with zero mean     : Inf\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with zero mean     : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11532.83\n",
      "\n",
      " Best model: ARIMA(5,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11484.53\n",
      " ARIMA(0,0,0) with non-zero mean : -7045.561\n",
      " ARIMA(1,0,0) with non-zero mean : -11444.21\n",
      " ARIMA(0,0,1) with non-zero mean : -8986.409\n",
      " ARIMA(0,0,0) with zero mean     : -7038.631\n",
      " ARIMA(1,0,2) with non-zero mean : -11482.13\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11504.12\n",
      " ARIMA(3,0,1) with non-zero mean : -11491.11\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11494.91\n",
      " ARIMA(4,0,1) with non-zero mean : -11499.35\n",
      " ARIMA(4,0,3) with non-zero mean : -11526.26\n",
      " ARIMA(5,0,3) with non-zero mean : -11517.71\n",
      " ARIMA(4,0,4) with non-zero mean : -11527.82\n",
      " ARIMA(3,0,4) with non-zero mean : -11575.39\n",
      " ARIMA(2,0,4) with non-zero mean : -11528.58\n",
      " ARIMA(3,0,5) with non-zero mean : -11562.18\n",
      " ARIMA(2,0,5) with non-zero mean : -11534.69\n",
      " ARIMA(4,0,5) with non-zero mean : -11524.81\n",
      " ARIMA(3,0,4) with zero mean     : -11577.89\n",
      " ARIMA(2,0,4) with zero mean     : -11530.23\n",
      " ARIMA(3,0,3) with zero mean     : -11566.83\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with zero mean     : -11564.21\n",
      " ARIMA(2,0,3) with zero mean     : -11496.61\n",
      " ARIMA(2,0,5) with zero mean     : -11536.4\n",
      " ARIMA(4,0,3) with zero mean     : -11527.89\n",
      " ARIMA(4,0,5) with zero mean     : -11526.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with zero mean     : -11533.26\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11512.55\n",
      " ARIMA(0,0,0) with non-zero mean : -7061.255\n",
      " ARIMA(1,0,0) with non-zero mean : -11465.68\n",
      " ARIMA(0,0,1) with non-zero mean : -9005.312\n",
      " ARIMA(0,0,0) with zero mean     : -7056.084\n",
      " ARIMA(1,0,2) with non-zero mean : -11505.82\n",
      " ARIMA(2,0,1) with non-zero mean : -11507.85\n",
      " ARIMA(3,0,2) with non-zero mean : -11529.8\n",
      " ARIMA(3,0,1) with non-zero mean : -11518.26\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -11528.69\n",
      " ARIMA(2,0,3) with non-zero mean : -11525.98\n",
      " ARIMA(4,0,1) with non-zero mean : -11526.77\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11531.71\n",
      " ARIMA(2,0,2) with zero mean     : -11514.51\n",
      " ARIMA(3,0,1) with zero mean     : -11520.21\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11530.61\n",
      " ARIMA(2,0,1) with zero mean     : -11509.79\n",
      " ARIMA(2,0,3) with zero mean     : -11527.91\n",
      " ARIMA(4,0,1) with zero mean     : -11528.68\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11531.16\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11482.71\n",
      " ARIMA(0,0,0) with non-zero mean : -7055.949\n",
      " ARIMA(1,0,0) with non-zero mean : -11440.36\n",
      " ARIMA(0,0,1) with non-zero mean : -8999.116\n",
      " ARIMA(0,0,0) with zero mean     : -7050.65\n",
      " ARIMA(1,0,2) with non-zero mean : -11479.36\n",
      " ARIMA(2,0,1) with non-zero mean : -11479.16\n",
      " ARIMA(3,0,2) with non-zero mean : -11504.84\n",
      " ARIMA(3,0,1) with non-zero mean : -11490.33\n",
      " ARIMA(4,0,2) with non-zero mean : -11502.25\n",
      " ARIMA(3,0,3) with non-zero mean : -11503.38\n",
      " ARIMA(2,0,3) with non-zero mean : -11497.76\n",
      " ARIMA(4,0,1) with non-zero mean : -11502.16\n",
      " ARIMA(4,0,3) with non-zero mean : -11506.83\n",
      " ARIMA(5,0,3) with non-zero mean : -11536.13\n",
      " ARIMA(5,0,2) with non-zero mean : -11529.28\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11522.49\n",
      " ARIMA(5,0,3) with zero mean     : -11537.82\n",
      " ARIMA(4,0,3) with zero mean     : -11507.84\n",
      " ARIMA(5,0,2) with zero mean     : -11530.86\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11503.86\n",
      " ARIMA(4,0,4) with zero mean     : -11523.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with zero mean     : -11537.58\n",
      "\n",
      " Best model: ARIMA(5,0,3) with zero mean     \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11490.37\n",
      " ARIMA(0,0,0) with non-zero mean : -7047.452\n",
      " ARIMA(1,0,0) with non-zero mean : -11444.65\n",
      " ARIMA(0,0,1) with non-zero mean : -8991.749\n",
      " ARIMA(0,0,0) with zero mean     : -7039.512\n",
      " ARIMA(1,0,2) with non-zero mean : -11484.88\n",
      " ARIMA(2,0,1) with non-zero mean : -11485.48\n",
      " ARIMA(3,0,2) with non-zero mean : -11509.2\n",
      " ARIMA(3,0,1) with non-zero mean : -11496.02\n",
      " ARIMA(4,0,2) with non-zero mean : -11507.8\n",
      " ARIMA(3,0,3) with non-zero mean : -11507.44\n",
      " ARIMA(2,0,3) with non-zero mean : -11503.08\n",
      " ARIMA(4,0,1) with non-zero mean : -11507.8\n",
      " ARIMA(4,0,3) with non-zero mean : -11548.82\n",
      " ARIMA(5,0,3) with non-zero mean : -11539.74\n",
      " ARIMA(4,0,4) with non-zero mean : -11525.75\n",
      " ARIMA(3,0,4) with non-zero mean : -11542.99\n",
      " ARIMA(5,0,2) with non-zero mean : -11530.54\n",
      " ARIMA(5,0,4) with non-zero mean : -11540.45\n",
      " ARIMA(4,0,3) with zero mean     : -11550.67\n",
      " ARIMA(3,0,3) with zero mean     : -11509.09\n",
      " ARIMA(4,0,2) with zero mean     : -11509.38\n",
      " ARIMA(5,0,3) with zero mean     : -11540.95\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11510.85\n",
      " ARIMA(3,0,4) with zero mean     : -11544.76\n",
      " ARIMA(5,0,2) with zero mean     : -11532.19\n",
      " ARIMA(5,0,4) with zero mean     : -11579.37\n",
      " ARIMA(5,0,5) with zero mean     : -11543.06\n",
      " ARIMA(4,0,5) with zero mean     : -11592.29\n",
      " ARIMA(3,0,5) with zero mean     : -11545.3\n",
      " ARIMA(4,0,5) with non-zero mean : -11590.86\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,5) with zero mean     : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with zero mean     : -11578.88\n",
      "\n",
      " Best model: ARIMA(5,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11508.12\n",
      " ARIMA(0,0,0) with non-zero mean : -7087.399\n",
      " ARIMA(1,0,0) with non-zero mean : -11462.71\n",
      " ARIMA(0,0,1) with non-zero mean : -9025.635\n",
      " ARIMA(0,0,0) with zero mean     : -7072.381\n",
      " ARIMA(1,0,2) with non-zero mean : -11504.23\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11528.6\n",
      " ARIMA(3,0,1) with non-zero mean : -11515.45\n",
      " ARIMA(4,0,2) with non-zero mean : -11526.53\n",
      " ARIMA(3,0,3) with non-zero mean : -11527.53\n",
      " ARIMA(2,0,3) with non-zero mean : -11520.4\n",
      " ARIMA(4,0,1) with non-zero mean : -11523.82\n",
      " ARIMA(4,0,3) with non-zero mean : -11542.11\n",
      " ARIMA(5,0,3) with non-zero mean : -11554.06\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : -11602.43\n",
      " ARIMA(4,0,4) with non-zero mean : -11549.88\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : -11557.33\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,4) with non-zero mean : -11602.48\n",
      "\n",
      " Best model: ARIMA(5,0,4) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11526.79\n",
      " ARIMA(0,0,0) with non-zero mean : -7092.398\n",
      " ARIMA(1,0,0) with non-zero mean : -11484.3\n",
      " ARIMA(0,0,1) with non-zero mean : -9043.673\n",
      " ARIMA(0,0,0) with zero mean     : -7075.856\n",
      " ARIMA(1,0,2) with non-zero mean : -11524.41\n",
      " ARIMA(2,0,1) with non-zero mean : -11524.82\n",
      " ARIMA(3,0,2) with non-zero mean : -11552.34\n",
      " ARIMA(3,0,1) with non-zero mean : -11541.36\n",
      " ARIMA(4,0,2) with non-zero mean : -11552.16\n",
      " ARIMA(3,0,3) with non-zero mean : -11552.84\n",
      " ARIMA(2,0,3) with non-zero mean : -11543.3\n",
      " ARIMA(4,0,3) with non-zero mean : -11554.74\n",
      " ARIMA(5,0,3) with non-zero mean : -11575.93\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -11577.43\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11553.65\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with zero mean     : -11571.37\n",
      "\n",
      " Best model: ARIMA(5,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11547.91\n",
      " ARIMA(0,0,0) with non-zero mean : -7107.758\n",
      " ARIMA(1,0,0) with non-zero mean : -11504.77\n",
      " ARIMA(0,0,1) with non-zero mean : -9060.209\n",
      " ARIMA(0,0,0) with zero mean     : -7094.49\n",
      " ARIMA(1,0,2) with non-zero mean : -11544.18\n",
      " ARIMA(2,0,1) with non-zero mean : -11542.64\n",
      " ARIMA(3,0,2) with non-zero mean : -11570.25\n",
      " ARIMA(3,0,1) with non-zero mean : -11554.96\n",
      " ARIMA(4,0,2) with non-zero mean : -11567.73\n",
      " ARIMA(3,0,3) with non-zero mean : -11568.73\n",
      " ARIMA(2,0,3) with non-zero mean : -11562.27\n",
      " ARIMA(4,0,1) with non-zero mean : -11563.92\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11571.9\n",
      " ARIMA(2,0,2) with zero mean     : -11549.64\n",
      " ARIMA(3,0,1) with zero mean     : -11556.68\n",
      " ARIMA(4,0,2) with zero mean     : -11569.38\n",
      " ARIMA(3,0,3) with zero mean     : -11570.38\n",
      " ARIMA(2,0,1) with zero mean     : -11544.33\n",
      " ARIMA(2,0,3) with zero mean     : -11563.9\n",
      " ARIMA(4,0,1) with zero mean     : -11565.55\n",
      " ARIMA(4,0,3) with zero mean     : -11629.13\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : -11626\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11570.11\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11556.06\n",
      " ARIMA(0,0,0) with non-zero mean : -7115.878\n",
      " ARIMA(1,0,0) with non-zero mean : -11512.93\n",
      " ARIMA(0,0,1) with non-zero mean : -9071.081\n",
      " ARIMA(0,0,0) with zero mean     : -7107.797\n",
      " ARIMA(1,0,2) with non-zero mean : -11552.01\n",
      " ARIMA(2,0,1) with non-zero mean : -11550.3\n",
      " ARIMA(3,0,2) with non-zero mean : -11577.24\n",
      " ARIMA(3,0,1) with non-zero mean : -11562.77\n",
      " ARIMA(4,0,2) with non-zero mean : -11575.26\n",
      " ARIMA(3,0,3) with non-zero mean : -11575.39\n",
      " ARIMA(2,0,3) with non-zero mean : -11569.65\n",
      " ARIMA(4,0,1) with non-zero mean : -11572.43\n",
      " ARIMA(4,0,3) with non-zero mean : -11632.57\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11572.78\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11634.31\n",
      " ARIMA(3,0,3) with zero mean     : -11577.2\n",
      " ARIMA(4,0,2) with zero mean     : -11577.1\n",
      " ARIMA(5,0,3) with zero mean     : -11596.63\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11579.07\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : -11574.61\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -11598.87\n",
      "\n",
      " Best model: ARIMA(5,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11550.76\n",
      " ARIMA(0,0,0) with non-zero mean : -7126.439\n",
      " ARIMA(1,0,0) with non-zero mean : -11509.95\n",
      " ARIMA(0,0,1) with non-zero mean : -9081.564\n",
      " ARIMA(0,0,0) with zero mean     : -7121.931\n",
      " ARIMA(1,0,2) with non-zero mean : -11547.26\n",
      " ARIMA(2,0,1) with non-zero mean : -11545.45\n",
      " ARIMA(3,0,2) with non-zero mean : -11615.83\n",
      " ARIMA(3,0,1) with non-zero mean : -11557.98\n",
      " ARIMA(4,0,2) with non-zero mean : -11570.85\n",
      " ARIMA(3,0,3) with non-zero mean : -11570.56\n",
      " ARIMA(2,0,3) with non-zero mean : -11564.49\n",
      " ARIMA(4,0,1) with non-zero mean : -11567.12\n",
      " ARIMA(4,0,3) with non-zero mean : -11624.41\n",
      " ARIMA(5,0,3) with non-zero mean : -11590.89\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -11596.23\n",
      " ARIMA(5,0,2) with non-zero mean : -11567.64\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11635.38\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11572.65\n",
      " ARIMA(5,0,3) with zero mean     : -11592.65\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11617.52\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : -11569.6\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : -11638.66\n",
      "\n",
      " Best model: ARIMA(4,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11545.12\n",
      " ARIMA(0,0,0) with non-zero mean : -7119.86\n",
      " ARIMA(1,0,0) with non-zero mean : -11506.09\n",
      " ARIMA(0,0,1) with non-zero mean : -9075.953\n",
      " ARIMA(0,0,0) with zero mean     : -7114.27\n",
      " ARIMA(1,0,2) with non-zero mean : -11541.95\n",
      " ARIMA(2,0,1) with non-zero mean : -11540.33\n",
      " ARIMA(3,0,2) with non-zero mean : -11606\n",
      " ARIMA(3,0,1) with non-zero mean : -11553.66\n",
      " ARIMA(4,0,2) with non-zero mean : -11563.55\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11558.54\n",
      " ARIMA(4,0,1) with non-zero mean : -11561.29\n",
      " ARIMA(4,0,3) with non-zero mean : -11618.61\n",
      " ARIMA(5,0,3) with non-zero mean : -11617\n",
      " ARIMA(4,0,4) with non-zero mean : -11627.13\n",
      " ARIMA(3,0,4) with non-zero mean : -11578.07\n",
      " ARIMA(5,0,4) with non-zero mean : -11649.58\n",
      " ARIMA(5,0,5) with non-zero mean : -11575.81\n",
      " ARIMA(4,0,5) with non-zero mean : -11587.7\n",
      " ARIMA(5,0,4) with zero mean     : -11623.15\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with zero mean     : -11631.44\n",
      "\n",
      " Best model: ARIMA(5,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11546.6\n",
      " ARIMA(0,0,0) with non-zero mean : -7114.313\n",
      " ARIMA(1,0,0) with non-zero mean : -11507.8\n",
      " ARIMA(0,0,1) with non-zero mean : -9072.376\n",
      " ARIMA(0,0,0) with zero mean     : -7106.949\n",
      " ARIMA(1,0,2) with non-zero mean : -11543.3\n",
      " ARIMA(2,0,1) with non-zero mean : -11541.55\n",
      " ARIMA(3,0,2) with non-zero mean : -11566.73\n",
      " ARIMA(3,0,1) with non-zero mean : -11554.22\n",
      " ARIMA(4,0,2) with non-zero mean : -11564.63\n",
      " ARIMA(3,0,3) with non-zero mean : -11565.27\n",
      " ARIMA(2,0,3) with non-zero mean : -11558.99\n",
      " ARIMA(4,0,1) with non-zero mean : -11562.35\n",
      " ARIMA(4,0,3) with non-zero mean : -11613.32\n",
      " ARIMA(5,0,3) with non-zero mean : -11628.52\n",
      " ARIMA(5,0,2) with non-zero mean : -11620.28\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11619.37\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : -11634.67\n",
      "\n",
      " Best model: ARIMA(5,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11551.54\n",
      " ARIMA(0,0,0) with non-zero mean : -7118.416\n",
      " ARIMA(1,0,0) with non-zero mean : -11511.29\n",
      " ARIMA(0,0,1) with non-zero mean : -9078.301\n",
      " ARIMA(0,0,0) with zero mean     : -7111.373\n",
      " ARIMA(1,0,2) with non-zero mean : -11547.03\n",
      " ARIMA(2,0,1) with non-zero mean : -11545.53\n",
      " ARIMA(3,0,2) with non-zero mean : -11615.2\n",
      " ARIMA(3,0,1) with non-zero mean : -11557.44\n",
      " ARIMA(4,0,2) with non-zero mean : -11568.29\n",
      " ARIMA(3,0,3) with non-zero mean : -11568.78\n",
      " ARIMA(2,0,3) with non-zero mean : -11563.36\n",
      " ARIMA(4,0,1) with non-zero mean : -11564.77\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11617.02\n",
      " ARIMA(2,0,2) with zero mean     : -11553.27\n",
      " ARIMA(3,0,1) with zero mean     : -11559.16\n",
      " ARIMA(4,0,2) with zero mean     : -11569.97\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -11547.24\n",
      " ARIMA(2,0,3) with zero mean     : -11565.04\n",
      " ARIMA(4,0,1) with zero mean     : -11566.45\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11620.7\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11554.01\n",
      " ARIMA(0,0,0) with non-zero mean : -7116.973\n",
      " ARIMA(1,0,0) with non-zero mean : -11514.16\n",
      " ARIMA(0,0,1) with non-zero mean : -9078.843\n",
      " ARIMA(0,0,0) with zero mean     : -7110.575\n",
      " ARIMA(1,0,2) with non-zero mean : -11549.31\n",
      " ARIMA(2,0,1) with non-zero mean : -11547.38\n",
      " ARIMA(3,0,2) with non-zero mean : -11617.37\n",
      " ARIMA(3,0,1) with non-zero mean : -11560.2\n",
      " ARIMA(4,0,2) with non-zero mean : -11570.91\n",
      " ARIMA(3,0,3) with non-zero mean : -11632.39\n",
      " ARIMA(2,0,3) with non-zero mean : -11565.17\n",
      " ARIMA(4,0,3) with non-zero mean : -11630.52\n",
      " ARIMA(3,0,4) with non-zero mean : -11585.25\n",
      " ARIMA(2,0,4) with non-zero mean : -11587.21\n",
      " ARIMA(4,0,4) with non-zero mean : -11628.73\n",
      " ARIMA(3,0,3) with zero mean     : -11634.27\n",
      " ARIMA(2,0,3) with zero mean     : -11566.99\n",
      " ARIMA(3,0,2) with zero mean     : -11619.19\n",
      " ARIMA(4,0,3) with zero mean     : -11632.5\n",
      " ARIMA(3,0,4) with zero mean     : -11625.88\n",
      " ARIMA(2,0,2) with zero mean     : -11555.88\n",
      " ARIMA(2,0,4) with zero mean     : -11588.91\n",
      " ARIMA(4,0,2) with zero mean     : -11572.75\n",
      " ARIMA(4,0,4) with zero mean     : -11630.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -11628.23\n",
      "\n",
      " Best model: ARIMA(3,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11551.34\n",
      " ARIMA(0,0,0) with non-zero mean : -7106.605\n",
      " ARIMA(1,0,0) with non-zero mean : -11513.4\n",
      " ARIMA(0,0,1) with non-zero mean : -9071.249\n",
      " ARIMA(0,0,0) with zero mean     : -7102.428\n",
      " ARIMA(1,0,2) with non-zero mean : -11547.63\n",
      " ARIMA(2,0,1) with non-zero mean : -11545.49\n",
      " ARIMA(3,0,2) with non-zero mean : -11617.89\n",
      " ARIMA(3,0,1) with non-zero mean : -11557.32\n",
      " ARIMA(4,0,2) with non-zero mean : -11568.4\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11562.84\n",
      " ARIMA(4,0,1) with non-zero mean : -11564.69\n",
      " ARIMA(4,0,3) with non-zero mean : -11630.55\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11636.38\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : -11589.82\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : -11638.05\n",
      " ARIMA(3,0,4) with zero mean     : -11633.51\n",
      " ARIMA(4,0,3) with zero mean     : -11632.3\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,5) with zero mean     : -11591.73\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,5) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,4) with zero mean     : -11590.88\n",
      "\n",
      " Best model: ARIMA(4,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11548.17\n",
      " ARIMA(0,0,0) with non-zero mean : -7106.547\n",
      " ARIMA(1,0,0) with non-zero mean : -11510.72\n",
      " ARIMA(0,0,1) with non-zero mean : -9069.574\n",
      " ARIMA(0,0,0) with zero mean     : -7102.552\n",
      " ARIMA(1,0,2) with non-zero mean : -11544.52\n",
      " ARIMA(2,0,1) with non-zero mean : -11542.44\n",
      " ARIMA(3,0,2) with non-zero mean : -11617.49\n",
      " ARIMA(3,0,1) with non-zero mean : -11553.85\n",
      " ARIMA(4,0,2) with non-zero mean : -11565.16\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11559.85\n",
      " ARIMA(4,0,1) with non-zero mean : -11561.4\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11619.37\n",
      " ARIMA(2,0,2) with zero mean     : -11550.07\n",
      " ARIMA(3,0,1) with zero mean     : -11555.75\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -11544.33\n",
      " ARIMA(2,0,3) with zero mean     : -11561.72\n",
      " ARIMA(4,0,1) with zero mean     : -11563.27\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11619.52\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11546.07\n",
      " ARIMA(0,0,0) with non-zero mean : -7112.958\n",
      " ARIMA(1,0,0) with non-zero mean : -11508.98\n",
      " ARIMA(0,0,1) with non-zero mean : -9075.459\n",
      " ARIMA(0,0,0) with zero mean     : -7109.358\n",
      " ARIMA(1,0,2) with non-zero mean : -11542.43\n",
      " ARIMA(2,0,1) with non-zero mean : -11540.32\n",
      " ARIMA(3,0,2) with non-zero mean : -11617.21\n",
      " ARIMA(3,0,1) with non-zero mean : -11551.7\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11557.75\n",
      " ARIMA(4,0,1) with non-zero mean : -11559.25\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11618.96\n",
      " ARIMA(2,0,2) with zero mean     : -11547.9\n",
      " ARIMA(3,0,1) with zero mean     : -11553.51\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -11542.14\n",
      " ARIMA(2,0,3) with zero mean     : -11559.55\n",
      " ARIMA(4,0,1) with zero mean     : -11561.06\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11619.15\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11546.69\n",
      " ARIMA(0,0,0) with non-zero mean : -7110.009\n",
      " ARIMA(1,0,0) with non-zero mean : -11509.7\n",
      " ARIMA(0,0,1) with non-zero mean : -9073.832\n",
      " ARIMA(0,0,0) with zero mean     : -7105.975\n",
      " ARIMA(1,0,2) with non-zero mean : -11542.96\n",
      " ARIMA(2,0,1) with non-zero mean : -11540.83\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11558.31\n",
      " ARIMA(1,0,3) with non-zero mean : -11560.89\n",
      " ARIMA(0,0,3) with non-zero mean : -10457.85\n",
      " ARIMA(1,0,4) with non-zero mean : -11559.83\n",
      " ARIMA(0,0,2) with non-zero mean : -9950.234\n",
      " ARIMA(0,0,4) with non-zero mean : -10869.46\n",
      " ARIMA(2,0,4) with non-zero mean : -11584.44\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11592.16\n",
      " ARIMA(1,0,5) with non-zero mean : -11564.19\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with zero mean     : -11594.02\n",
      " ARIMA(1,0,5) with zero mean     : -11566.03\n",
      " ARIMA(2,0,4) with zero mean     : -11586.28\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(1,0,4) with zero mean     : -11561.65\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,5) with zero mean     : -11593.87\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11547.96\n",
      " ARIMA(0,0,0) with non-zero mean : -7112.272\n",
      " ARIMA(1,0,0) with non-zero mean : -11510.05\n",
      " ARIMA(0,0,1) with non-zero mean : -9074.982\n",
      " ARIMA(0,0,0) with zero mean     : -7106.199\n",
      " ARIMA(1,0,2) with non-zero mean : -11544.13\n",
      " ARIMA(2,0,1) with non-zero mean : -11542.04\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11559.77\n",
      " ARIMA(1,0,3) with non-zero mean : -11562.34\n",
      " ARIMA(0,0,3) with non-zero mean : -10457.36\n",
      " ARIMA(1,0,4) with non-zero mean : -11561.29\n",
      " ARIMA(0,0,2) with non-zero mean : -9949.54\n",
      " ARIMA(0,0,4) with non-zero mean : -10868.67\n",
      " ARIMA(2,0,4) with non-zero mean : -11586.17\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11593.93\n",
      " ARIMA(1,0,5) with non-zero mean : -11565.7\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with zero mean     : -11595.61\n",
      " ARIMA(1,0,5) with zero mean     : -11567.42\n",
      " ARIMA(2,0,4) with zero mean     : -11587.81\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(1,0,4) with zero mean     : -11562.99\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,5) with zero mean     : -11595.61\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11551.98\n",
      " ARIMA(0,0,0) with non-zero mean : -7114.245\n",
      " ARIMA(1,0,0) with non-zero mean : -11513.27\n",
      " ARIMA(0,0,1) with non-zero mean : -9076.409\n",
      " ARIMA(0,0,0) with zero mean     : -7108.062\n",
      " ARIMA(1,0,2) with non-zero mean : -11548.07\n",
      " ARIMA(2,0,1) with non-zero mean : -11545.97\n",
      " ARIMA(3,0,2) with non-zero mean : -11621.92\n",
      " ARIMA(3,0,1) with non-zero mean : -11557.83\n",
      " ARIMA(4,0,2) with non-zero mean : -11569.14\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11563.49\n",
      " ARIMA(4,0,1) with non-zero mean : -11565.27\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : -11623.02\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11549.82\n",
      " ARIMA(0,0,0) with non-zero mean : -7108.307\n",
      " ARIMA(1,0,0) with non-zero mean : -11511.15\n",
      " ARIMA(0,0,1) with non-zero mean : -9070.413\n",
      " ARIMA(0,0,0) with zero mean     : -7098.131\n",
      " ARIMA(1,0,2) with non-zero mean : -11546.06\n",
      " ARIMA(2,0,1) with non-zero mean : -11543.98\n",
      " ARIMA(3,0,2) with non-zero mean : -11620.06\n",
      " ARIMA(3,0,1) with non-zero mean : -11555.65\n",
      " ARIMA(4,0,2) with non-zero mean : -11567.5\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11561.41\n",
      " ARIMA(4,0,1) with non-zero mean : -11563.26\n",
      " ARIMA(4,0,3) with non-zero mean : -11630.88\n",
      " ARIMA(5,0,3) with non-zero mean : -11623.84\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11631.65\n",
      " ARIMA(5,0,1) with non-zero mean : -11590.51\n",
      " ARIMA(5,0,2) with zero mean     : -11633.39\n",
      " ARIMA(4,0,2) with zero mean     : -11569.12\n",
      " ARIMA(5,0,1) with zero mean     : -11592.07\n",
      " ARIMA(5,0,3) with zero mean     : -11636.77\n",
      " ARIMA(4,0,3) with zero mean     : -11632.71\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with zero mean     : -11591.97\n",
      "\n",
      " Best model: ARIMA(5,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11546.59\n",
      " ARIMA(0,0,0) with non-zero mean : -7108.494\n",
      " ARIMA(1,0,0) with non-zero mean : -11507.88\n",
      " ARIMA(0,0,1) with non-zero mean : -9068.035\n",
      " ARIMA(0,0,0) with zero mean     : -7100.783\n",
      " ARIMA(1,0,2) with non-zero mean : -11542.94\n",
      " ARIMA(2,0,1) with non-zero mean : -11541.28\n",
      " ARIMA(3,0,2) with non-zero mean : -11614.15\n",
      " ARIMA(3,0,1) with non-zero mean : -11552.61\n",
      " ARIMA(4,0,2) with non-zero mean : -11630.6\n",
      " ARIMA(4,0,1) with non-zero mean : -11560.2\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,1) with non-zero mean : -11587.56\n",
      " ARIMA(5,0,3) with non-zero mean : -11634.25\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : -11635.68\n",
      "\n",
      " Best model: ARIMA(5,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11543.12\n",
      " ARIMA(0,0,0) with non-zero mean : -7104.029\n",
      " ARIMA(1,0,0) with non-zero mean : -11504.2\n",
      " ARIMA(0,0,1) with non-zero mean : -9062.16\n",
      " ARIMA(0,0,0) with zero mean     : -7093.004\n",
      " ARIMA(1,0,2) with non-zero mean : -11538.94\n",
      " ARIMA(2,0,1) with non-zero mean : -11537.27\n",
      " ARIMA(3,0,2) with non-zero mean : -11611.29\n",
      " ARIMA(3,0,1) with non-zero mean : -11548.77\n",
      " ARIMA(4,0,2) with non-zero mean : -11560.94\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11554.65\n",
      " ARIMA(4,0,1) with non-zero mean : -11556.15\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11612.56\n",
      " ARIMA(2,0,2) with zero mean     : -11544.66\n",
      " ARIMA(3,0,1) with zero mean     : -11550.31\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -11538.8\n",
      " ARIMA(2,0,3) with zero mean     : -11556.13\n",
      " ARIMA(4,0,1) with zero mean     : -11557.64\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11614.8\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11541.63\n",
      " ARIMA(0,0,0) with non-zero mean : -7104.001\n",
      " ARIMA(1,0,0) with non-zero mean : -11503.56\n",
      " ARIMA(0,0,1) with non-zero mean : -9064.192\n",
      " ARIMA(0,0,0) with zero mean     : -7092.129\n",
      " ARIMA(1,0,2) with non-zero mean : -11538.1\n",
      " ARIMA(2,0,1) with non-zero mean : -11536.04\n",
      " ARIMA(3,0,2) with non-zero mean : -11611.74\n",
      " ARIMA(3,0,1) with non-zero mean : -11547.4\n",
      " ARIMA(4,0,2) with non-zero mean : -11558.95\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11553.51\n",
      " ARIMA(4,0,1) with non-zero mean : -11555.88\n",
      " ARIMA(4,0,3) with non-zero mean : -11629.28\n",
      " ARIMA(5,0,3) with non-zero mean : -11628.64\n",
      " ARIMA(4,0,4) with non-zero mean : -11616.24\n",
      " ARIMA(3,0,4) with non-zero mean : -11583.02\n",
      " ARIMA(5,0,2) with non-zero mean : -11610.32\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11619.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with non-zero mean : -11580.32\n",
      "\n",
      " Best model: ARIMA(4,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11542.31\n",
      " ARIMA(0,0,0) with non-zero mean : -7104.746\n",
      " ARIMA(1,0,0) with non-zero mean : -11503.98\n",
      " ARIMA(0,0,1) with non-zero mean : -9064.626\n",
      " ARIMA(0,0,0) with zero mean     : -7093.767\n",
      " ARIMA(1,0,2) with non-zero mean : -11538.59\n",
      " ARIMA(2,0,1) with non-zero mean : -11536.52\n",
      " ARIMA(3,0,2) with non-zero mean : -11610.53\n",
      " ARIMA(3,0,1) with non-zero mean : -11548.59\n",
      " ARIMA(4,0,2) with non-zero mean : -11560.71\n",
      " ARIMA(3,0,3) with non-zero mean : -11625.57\n",
      " ARIMA(2,0,3) with non-zero mean : -11554\n",
      " ARIMA(4,0,3) with non-zero mean : -11622.92\n",
      " ARIMA(3,0,4) with non-zero mean : -11580.38\n",
      " ARIMA(2,0,4) with non-zero mean : -11581.82\n",
      " ARIMA(4,0,4) with non-zero mean : -11621.31\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -11627.63\n",
      "\n",
      " Best model: ARIMA(4,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11539.47\n",
      " ARIMA(0,0,0) with non-zero mean : -7102.276\n",
      " ARIMA(1,0,0) with non-zero mean : -11501.5\n",
      " ARIMA(0,0,1) with non-zero mean : -9062.581\n",
      " ARIMA(0,0,0) with zero mean     : -7090.135\n",
      " ARIMA(1,0,2) with non-zero mean : -11535.92\n",
      " ARIMA(2,0,1) with non-zero mean : -11533.8\n",
      " ARIMA(3,0,2) with non-zero mean : -11606.73\n",
      " ARIMA(3,0,1) with non-zero mean : -11545.4\n",
      " ARIMA(4,0,2) with non-zero mean : -11558.05\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11551.07\n",
      " ARIMA(4,0,1) with non-zero mean : -11553.3\n",
      " ARIMA(4,0,3) with non-zero mean : -11619.69\n",
      " ARIMA(5,0,3) with non-zero mean : -11619.9\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11625.96\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : -11583\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : -11627.36\n",
      " ARIMA(3,0,4) with zero mean     : -11622.97\n",
      " ARIMA(4,0,3) with zero mean     : -11621.42\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,5) with zero mean     : -11584.58\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -11621.32\n",
      " ARIMA(5,0,5) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -11626.69\n",
      "\n",
      " Best model: ARIMA(3,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11543\n",
      " ARIMA(0,0,0) with non-zero mean : -7109.443\n",
      " ARIMA(1,0,0) with non-zero mean : -11504.54\n",
      " ARIMA(0,0,1) with non-zero mean : -9066.509\n",
      " ARIMA(0,0,0) with zero mean     : -7097.631\n",
      " ARIMA(1,0,2) with non-zero mean : -11539.42\n",
      " ARIMA(2,0,1) with non-zero mean : -11537.33\n",
      " ARIMA(3,0,2) with non-zero mean : -11607.85\n",
      " ARIMA(3,0,1) with non-zero mean : -11549.09\n",
      " ARIMA(4,0,2) with non-zero mean : -11561.32\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11554.41\n",
      " ARIMA(4,0,1) with non-zero mean : -11556.82\n",
      " ARIMA(4,0,3) with non-zero mean : -11619.75\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11627.91\n",
      " ARIMA(3,0,4) with non-zero mean : -11576.49\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : -11586.89\n",
      " ARIMA(3,0,5) with non-zero mean : -11634.43\n",
      " ARIMA(2,0,5) with non-zero mean : -11590.8\n",
      " ARIMA(2,0,4) with non-zero mean : -11582.07\n",
      " ARIMA(3,0,5) with zero mean     : -11635\n",
      " ARIMA(2,0,5) with zero mean     : -11592.46\n",
      " ARIMA(3,0,4) with zero mean     : -11624.41\n",
      " ARIMA(4,0,5) with zero mean     : -11588.56\n",
      " ARIMA(2,0,4) with zero mean     : -11583.67\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -11629.23\n",
      "\n",
      " Best model: ARIMA(3,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11489.56\n",
      " ARIMA(0,1,0) with drift         : -11407.73\n",
      " ARIMA(1,1,0) with drift         : -11459.08\n",
      " ARIMA(0,1,1) with drift         : -11469.07\n",
      " ARIMA(0,1,0)                    : -11409.73\n",
      " ARIMA(1,1,2) with drift         : -11476.07\n",
      " ARIMA(2,1,1) with drift         : -11481.59\n",
      " ARIMA(3,1,2) with drift         : -11545.27\n",
      " ARIMA(3,1,1) with drift         : -11482.08\n",
      " ARIMA(4,1,2) with drift         : -11551.58\n",
      " ARIMA(4,1,1) with drift         : -11484.96\n",
      " ARIMA(5,1,2) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11548.26\n",
      " ARIMA(5,1,1) with drift         : -11492.25\n",
      " ARIMA(5,1,3) with drift         : -11514.51\n",
      " ARIMA(4,1,2)                    : -11553.38\n",
      " ARIMA(3,1,2)                    : -11547.18\n",
      " ARIMA(4,1,1)                    : -11486.97\n",
      " ARIMA(5,1,2)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(3,1,1)                    : -11484.09\n",
      " ARIMA(3,1,3)                    : -11550.27\n",
      " ARIMA(5,1,1)                    : -11494.27\n",
      " ARIMA(5,1,3)                    : -11516.53\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11568.56\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11488.51\n",
      " ARIMA(0,1,0) with drift         : -11406.48\n",
      " ARIMA(1,1,0) with drift         : -11458.08\n",
      " ARIMA(0,1,1) with drift         : -11467.77\n",
      " ARIMA(0,1,0)                    : -11408.49\n",
      " ARIMA(1,1,2) with drift         : -11474.57\n",
      " ARIMA(2,1,1) with drift         : -11479.9\n",
      " ARIMA(3,1,2) with drift         : -11548.76\n",
      " ARIMA(3,1,1) with drift         : -11480.84\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11550.62\n",
      " ARIMA(2,1,3) with drift         : -11554.97\n",
      " ARIMA(1,1,3) with drift         : -11477.58\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11486.33\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11556.97\n",
      " ARIMA(1,1,3)                    : -11479.59\n",
      " ARIMA(2,1,2)                    : -11490.52\n",
      " ARIMA(3,1,3)                    : -11552.63\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11476.58\n",
      " ARIMA(1,1,4)                    : -11488.34\n",
      " ARIMA(3,1,2)                    : -11550.73\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11567.3\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11539.15\n",
      " ARIMA(0,0,0) with non-zero mean : -7107.673\n",
      " ARIMA(1,0,0) with non-zero mean : -11500.94\n",
      " ARIMA(0,0,1) with non-zero mean : -9065.001\n",
      " ARIMA(0,0,0) with zero mean     : -7096.296\n",
      " ARIMA(1,0,2) with non-zero mean : -11535.64\n",
      " ARIMA(2,0,1) with non-zero mean : -11533.93\n",
      " ARIMA(3,0,2) with non-zero mean : -11608.97\n",
      " ARIMA(3,0,1) with non-zero mean : -11545.34\n",
      " ARIMA(4,0,2) with non-zero mean : -11558.35\n",
      " ARIMA(3,0,3) with non-zero mean : -11559.27\n",
      " ARIMA(2,0,3) with non-zero mean : -11551.85\n",
      " ARIMA(4,0,1) with non-zero mean : -11553.66\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11610.6\n",
      " ARIMA(2,0,2) with zero mean     : -11540.78\n",
      " ARIMA(3,0,1) with zero mean     : -11546.94\n",
      " ARIMA(4,0,2) with zero mean     : -11559.91\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -11535.53\n",
      " ARIMA(2,0,3) with zero mean     : -11553.4\n",
      " ARIMA(4,0,1) with zero mean     : -11555.22\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11611.22\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11484.71\n",
      " ARIMA(0,1,0) with drift         : -11402.92\n",
      " ARIMA(1,1,0) with drift         : -11453.72\n",
      " ARIMA(0,1,1) with drift         : -11463.3\n",
      " ARIMA(0,1,0)                    : -11404.93\n",
      " ARIMA(1,1,2) with drift         : -11470.24\n",
      " ARIMA(2,1,1) with drift         : -11475.7\n",
      " ARIMA(3,1,2) with drift         : -11537.52\n",
      " ARIMA(3,1,1) with drift         : -11476.24\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11479.22\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2) with drift         : -11549.01\n",
      "\n",
      " Best model: ARIMA(3,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11541.88\n",
      " ARIMA(0,0,0) with non-zero mean : -7110.457\n",
      " ARIMA(1,0,0) with non-zero mean : -11504.25\n",
      " ARIMA(0,0,1) with non-zero mean : -9071.053\n",
      " ARIMA(0,0,0) with zero mean     : -7095.669\n",
      " ARIMA(1,0,2) with non-zero mean : -11537.67\n",
      " ARIMA(2,0,1) with non-zero mean : -11535.9\n",
      " ARIMA(3,0,2) with non-zero mean : -11610.43\n",
      " ARIMA(3,0,1) with non-zero mean : -11547.99\n",
      " ARIMA(4,0,2) with non-zero mean : -11561.34\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11554.77\n",
      " ARIMA(4,0,1) with non-zero mean : -11556.7\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11611.69\n",
      " ARIMA(2,0,2) with zero mean     : -11543.41\n",
      " ARIMA(3,0,1) with zero mean     : -11549.52\n",
      " ARIMA(4,0,2) with zero mean     : -11562.84\n",
      " ARIMA(3,0,3) with zero mean     : -11563.17\n",
      " ARIMA(2,0,1) with zero mean     : -11537.42\n",
      " ARIMA(2,0,3) with zero mean     : -11556.22\n",
      " ARIMA(4,0,1) with zero mean     : -11558.16\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11614.18\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11489.65\n",
      " ARIMA(0,1,0) with drift         : -11408.33\n",
      " ARIMA(1,1,0) with drift         : -11457.28\n",
      " ARIMA(0,1,1) with drift         : -11467.04\n",
      " ARIMA(0,1,0)                    : -11410.33\n",
      " ARIMA(1,1,2) with drift         : -11474.81\n",
      " ARIMA(2,1,1) with drift         : -11480.57\n",
      " ARIMA(3,1,2) with drift         : -11549.16\n",
      " ARIMA(3,1,1) with drift         : -11481.79\n",
      " ARIMA(4,1,2) with drift         : -11541.63\n",
      " ARIMA(3,1,3) with drift         : -11548.71\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11551.15\n",
      " ARIMA(2,1,2)                    : -11491.66\n",
      " ARIMA(3,1,1)                    : -11483.8\n",
      " ARIMA(4,1,2)                    : -11543.55\n",
      " ARIMA(3,1,3)                    : -11550.71\n",
      " ARIMA(2,1,1)                    : -11482.57\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11566.72\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11491.43\n",
      " ARIMA(0,1,0) with drift         : -11409.56\n",
      " ARIMA(1,1,0) with drift         : -11458.85\n",
      " ARIMA(0,1,1) with drift         : -11467.94\n",
      " ARIMA(0,1,0)                    : -11411.56\n",
      " ARIMA(1,1,2) with drift         : -11476.06\n",
      " ARIMA(2,1,1) with drift         : -11481.97\n",
      " ARIMA(3,1,2) with drift         : -11552.28\n",
      " ARIMA(3,1,1) with drift         : -11482.84\n",
      " ARIMA(4,1,2) with drift         : -11551.35\n",
      " ARIMA(3,1,3) with drift         : -11551.43\n",
      " ARIMA(2,1,3) with drift         : -11554.61\n",
      " ARIMA(1,1,3) with drift         : -11479.29\n",
      " ARIMA(2,1,4) with drift         : -11548.45\n",
      " ARIMA(1,1,4) with drift         : -11487.19\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11556.62\n",
      " ARIMA(1,1,3)                    : -11481.3\n",
      " ARIMA(2,1,2)                    : -11493.44\n",
      " ARIMA(3,1,3)                    : -11553.42\n",
      " ARIMA(2,1,4)                    : -11550.41\n",
      " ARIMA(1,1,2)                    : -11478.06\n",
      " ARIMA(1,1,4)                    : -11489.19\n",
      " ARIMA(3,1,2)                    : -11554.25\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : -11567.05\n",
      "\n",
      " Best model: ARIMA(2,1,3) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11488.75\n",
      " ARIMA(0,1,0) with drift         : -11408.4\n",
      " ARIMA(1,1,0) with drift         : -11457.15\n",
      " ARIMA(0,1,1) with drift         : -11466.65\n",
      " ARIMA(0,1,0)                    : -11410.4\n",
      " ARIMA(1,1,2) with drift         : -11474.23\n",
      " ARIMA(2,1,1) with drift         : -11479.83\n",
      " ARIMA(3,1,2) with drift         : -11552.95\n",
      " ARIMA(3,1,1) with drift         : -11480.15\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11553.93\n",
      " ARIMA(1,1,3) with drift         : -11477.19\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11485.58\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11555.94\n",
      " ARIMA(1,1,3)                    : -11479.19\n",
      " ARIMA(2,1,2)                    : -11490.76\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11476.23\n",
      " ARIMA(1,1,4)                    : -11487.59\n",
      " ARIMA(3,1,2)                    : -11554.95\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11566.29\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11487.92\n",
      " ARIMA(0,1,0) with drift         : -11407.66\n",
      " ARIMA(1,1,0) with drift         : -11456.44\n",
      " ARIMA(0,1,1) with drift         : -11466.09\n",
      " ARIMA(0,1,0)                    : -11409.66\n",
      " ARIMA(1,1,2) with drift         : -11473.69\n",
      " ARIMA(2,1,1) with drift         : -11479.01\n",
      " ARIMA(3,1,2) with drift         : -11553.48\n",
      " ARIMA(3,1,1) with drift         : -11479.31\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11482.74\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11555.47\n",
      " ARIMA(2,1,2)                    : -11489.93\n",
      " ARIMA(3,1,1)                    : -11481.31\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11481.01\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11565.76\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11488.54\n",
      " ARIMA(0,1,0) with drift         : -11407.27\n",
      " ARIMA(1,1,0) with drift         : -11456.51\n",
      " ARIMA(0,1,1) with drift         : -11465.84\n",
      " ARIMA(0,1,0)                    : -11409.28\n",
      " ARIMA(1,1,2) with drift         : -11473.84\n",
      " ARIMA(2,1,1) with drift         : -11479.38\n",
      " ARIMA(3,1,2) with drift         : -11550.57\n",
      " ARIMA(3,1,1) with drift         : -11479.9\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11549.41\n",
      " ARIMA(2,1,3) with drift         : -11551.1\n",
      " ARIMA(1,1,3) with drift         : -11476.99\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11484.53\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11553.11\n",
      " ARIMA(1,1,3)                    : -11478.99\n",
      " ARIMA(2,1,2)                    : -11490.55\n",
      " ARIMA(3,1,3)                    : -11551.39\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11475.85\n",
      " ARIMA(1,1,4)                    : -11486.54\n",
      " ARIMA(3,1,2)                    : -11552.52\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11565.82\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11483.48\n",
      " ARIMA(0,1,0) with drift         : -11402.7\n",
      " ARIMA(1,1,0) with drift         : -11451.73\n",
      " ARIMA(0,1,1) with drift         : -11461.1\n",
      " ARIMA(0,1,0)                    : -11404.7\n",
      " ARIMA(1,1,2) with drift         : -11468.25\n",
      " ARIMA(2,1,1) with drift         : -11474.04\n",
      " ARIMA(3,1,2) with drift         : -11536.83\n",
      " ARIMA(3,1,1) with drift         : -11474.56\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11549\n",
      " ARIMA(1,1,3) with drift         : -11471.67\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11480.23\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11550.98\n",
      " ARIMA(1,1,3)                    : -11473.67\n",
      " ARIMA(2,1,2)                    : -11485.48\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11470.26\n",
      " ARIMA(1,1,4)                    : -11482.24\n",
      " ARIMA(3,1,2)                    : -11548.92\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11561.42\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11482.57\n",
      " ARIMA(0,1,0) with drift         : -11400.37\n",
      " ARIMA(1,1,0) with drift         : -11450.16\n",
      " ARIMA(0,1,1) with drift         : -11458.84\n",
      " ARIMA(0,1,0)                    : -11402.37\n",
      " ARIMA(1,1,2) with drift         : -11465.69\n",
      " ARIMA(2,1,1) with drift         : -11472.97\n",
      " ARIMA(3,1,2) with drift         : -11540.16\n",
      " ARIMA(3,1,1) with drift         : -11473.79\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11539.88\n",
      " ARIMA(2,1,3) with drift         : -11537.05\n",
      " ARIMA(4,1,1) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11542.16\n",
      " ARIMA(2,1,2)                    : -11484.58\n",
      " ARIMA(3,1,1)                    : -11475.8\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11541.9\n",
      " ARIMA(2,1,1)                    : -11474.98\n",
      " ARIMA(2,1,3)                    : -11538.99\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11558.63\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11479.35\n",
      " ARIMA(0,1,0) with drift         : -11399.67\n",
      " ARIMA(1,1,0) with drift         : -11448.3\n",
      " ARIMA(0,1,1) with drift         : -11457.52\n",
      " ARIMA(0,1,0)                    : -11401.67\n",
      " ARIMA(1,1,2) with drift         : -11464.19\n",
      " ARIMA(2,1,1) with drift         : -11469.55\n",
      " ARIMA(3,1,2) with drift         : -11543.91\n",
      " ARIMA(3,1,1) with drift         : -11470.27\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11545.94\n",
      " ARIMA(2,1,2)                    : -11481.36\n",
      " ARIMA(3,1,1)                    : -11472.28\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11471.56\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11557.18\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11470.5\n",
      " ARIMA(0,1,0) with drift         : -11391.25\n",
      " ARIMA(1,1,0) with drift         : -11440.04\n",
      " ARIMA(0,1,1) with drift         : -11449.27\n",
      " ARIMA(0,1,0)                    : -11393.26\n",
      " ARIMA(1,1,2) with drift         : -11455.74\n",
      " ARIMA(2,1,1) with drift         : -11461.2\n",
      " ARIMA(3,1,2) with drift         : -11525.03\n",
      " ARIMA(3,1,1) with drift         : -11462.98\n",
      " ARIMA(4,1,2) with drift         : -11520.54\n",
      " ARIMA(3,1,3) with drift         : -11524.95\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11466.16\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11526.97\n",
      " ARIMA(2,1,2)                    : -11472.51\n",
      " ARIMA(3,1,1)                    : -11464.99\n",
      " ARIMA(4,1,2)                    : -11522.35\n",
      " ARIMA(3,1,3)                    : -11526.95\n",
      " ARIMA(2,1,1)                    : -11463.21\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : -11468.17\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11548.01\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11465.7\n",
      " ARIMA(0,1,0) with drift         : -11387.82\n",
      " ARIMA(1,1,0) with drift         : -11435.95\n",
      " ARIMA(0,1,1) with drift         : -11445.09\n",
      " ARIMA(0,1,0)                    : -11389.82\n",
      " ARIMA(1,1,2) with drift         : -11451.65\n",
      " ARIMA(2,1,1) with drift         : -11456.63\n",
      " ARIMA(3,1,2) with drift         : -11531.51\n",
      " ARIMA(3,1,1) with drift         : -11456.91\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11459.7\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11533.52\n",
      " ARIMA(2,1,2)                    : -11467.71\n",
      " ARIMA(3,1,1)                    : -11458.92\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11458.63\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11543.83\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11463.12\n",
      " ARIMA(0,1,0) with drift         : -11386.02\n",
      " ARIMA(1,1,0) with drift         : -11433.6\n",
      " ARIMA(0,1,1) with drift         : -11442.58\n",
      " ARIMA(0,1,0)                    : -11388.03\n",
      " ARIMA(1,1,2) with drift         : -11448.94\n",
      " ARIMA(2,1,1) with drift         : -11453.81\n",
      " ARIMA(3,1,2) with drift         : -11525.39\n",
      " ARIMA(3,1,1) with drift         : -11454.66\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11524.52\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11457.02\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11527.4\n",
      " ARIMA(2,1,2)                    : -11465.13\n",
      " ARIMA(3,1,1)                    : -11456.67\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11526.53\n",
      " ARIMA(2,1,1)                    : -11455.82\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : -11459.03\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11541.25\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11458.77\n",
      " ARIMA(0,1,0) with drift         : -11381.36\n",
      " ARIMA(1,1,0) with drift         : -11429.64\n",
      " ARIMA(0,1,1) with drift         : -11438.35\n",
      " ARIMA(0,1,0)                    : -11383.36\n",
      " ARIMA(1,1,2) with drift         : -11444.64\n",
      " ARIMA(2,1,1) with drift         : -11449.51\n",
      " ARIMA(3,1,2) with drift         : -11523.98\n",
      " ARIMA(3,1,1) with drift         : -11449.86\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11522.53\n",
      " ARIMA(2,1,3) with drift         : -11515.81\n",
      " ARIMA(4,1,1) with drift         : -11452.53\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11525.99\n",
      " ARIMA(2,1,2)                    : -11460.78\n",
      " ARIMA(3,1,1)                    : -11451.87\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11524.55\n",
      " ARIMA(2,1,1)                    : -11451.52\n",
      " ARIMA(2,1,3)                    : -11526.75\n",
      " ARIMA(1,1,3)                    : -11449.44\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11446.65\n",
      " ARIMA(1,1,4)                    : -11457.35\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : -11537.12\n",
      "\n",
      " Best model: ARIMA(2,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11461.71\n",
      " ARIMA(0,1,0) with drift         : -11383.29\n",
      " ARIMA(1,1,0) with drift         : -11431.95\n",
      " ARIMA(0,1,1) with drift         : -11440.93\n",
      " ARIMA(0,1,0)                    : -11385.29\n",
      " ARIMA(1,1,2) with drift         : -11446.83\n",
      " ARIMA(2,1,1) with drift         : -11452.16\n",
      " ARIMA(3,1,2) with drift         : -11524.45\n",
      " ARIMA(3,1,1) with drift         : -11453.21\n",
      " ARIMA(4,1,2) with drift         : -11516.21\n",
      " ARIMA(3,1,3) with drift         : -11523.63\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11456.45\n",
      " ARIMA(4,1,3) with drift         : -11557.15\n",
      " ARIMA(5,1,3) with drift         : -11485.61\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(5,1,2) with drift         : Inf\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(4,1,3)                    : -11558.96\n",
      " ARIMA(3,1,3)                    : -11525.63\n",
      " ARIMA(4,1,2)                    : -11518.15\n",
      " ARIMA(5,1,3)                    : -11487.74\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11526.44\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(5,1,2)                    : Inf\n",
      " ARIMA(5,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11539.94\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11464.63\n",
      " ARIMA(0,1,0) with drift         : -11385.89\n",
      " ARIMA(1,1,0) with drift         : -11435.55\n",
      " ARIMA(0,1,1) with drift         : -11444.16\n",
      " ARIMA(0,1,0)                    : -11387.89\n",
      " ARIMA(1,1,2) with drift         : -11450.41\n",
      " ARIMA(2,1,1) with drift         : -11455.3\n",
      " ARIMA(3,1,2) with drift         : -11527.35\n",
      " ARIMA(3,1,1) with drift         : -11455.78\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11529.4\n",
      " ARIMA(1,1,3) with drift         : -11453.12\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11460.64\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11531.41\n",
      " ARIMA(1,1,3)                    : -11455.13\n",
      " ARIMA(2,1,2)                    : -11466.63\n",
      " ARIMA(3,1,3)                    : -11528.15\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11452.43\n",
      " ARIMA(1,1,4)                    : -11462.65\n",
      " ARIMA(3,1,2)                    : -11529.33\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : -11541.1\n",
      "\n",
      " Best model: ARIMA(2,1,3) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11467.17\n",
      " ARIMA(0,1,0) with drift         : -11390.13\n",
      " ARIMA(1,1,0) with drift         : -11438.99\n",
      " ARIMA(0,1,1) with drift         : -11447.86\n",
      " ARIMA(0,1,0)                    : -11392.14\n",
      " ARIMA(1,1,2) with drift         : -11453.3\n",
      " ARIMA(2,1,1) with drift         : -11458.1\n",
      " ARIMA(3,1,2) with drift         : -11528.67\n",
      " ARIMA(3,1,1) with drift         : -11458.43\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11527.28\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11461.22\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11530.68\n",
      " ARIMA(2,1,2)                    : -11469.17\n",
      " ARIMA(3,1,1)                    : -11460.44\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11529.3\n",
      " ARIMA(2,1,1)                    : -11460.11\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : -11463.24\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11544.53\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11457.26\n",
      " ARIMA(0,1,0) with drift         : -11383.29\n",
      " ARIMA(1,1,0) with drift         : -11430.38\n",
      " ARIMA(0,1,1) with drift         : -11438.84\n",
      " ARIMA(0,1,0)                    : -11385.28\n",
      " ARIMA(1,1,2) with drift         : -11444.28\n",
      " ARIMA(2,1,1) with drift         : -11448.59\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11522.67\n",
      " ARIMA(1,1,3) with drift         : -11446.31\n",
      " ARIMA(3,1,3) with drift         : -11520.59\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11454.56\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11524.67\n",
      " ARIMA(1,1,3)                    : -11448.3\n",
      " ARIMA(2,1,2)                    : -11459.25\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11446.27\n",
      " ARIMA(1,1,4)                    : -11456.53\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : -11535.62\n",
      "\n",
      " Best model: ARIMA(2,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11426.76\n",
      " ARIMA(0,1,0) with drift         : -11358.01\n",
      " ARIMA(1,1,0) with drift         : -11402.29\n",
      " ARIMA(0,1,1) with drift         : -11410.68\n",
      " ARIMA(0,1,0)                    : -11360.01\n",
      " ARIMA(1,1,2) with drift         : -11416.65\n",
      " ARIMA(2,1,1) with drift         : -11420.05\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11411.29\n",
      " ARIMA(1,1,3) with drift         : -11417.46\n",
      " ARIMA(3,1,1) with drift         : -11419.14\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11428.77\n",
      " ARIMA(1,1,2)                    : -11418.66\n",
      " ARIMA(2,1,1)                    : -11422.06\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(1,1,1)                    : -11413.29\n",
      " ARIMA(1,1,3)                    : -11419.46\n",
      " ARIMA(3,1,1)                    : -11421.15\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11438.63\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11419.96\n",
      " ARIMA(0,1,0) with drift         : -11350.92\n",
      " ARIMA(1,1,0) with drift         : -11394.9\n",
      " ARIMA(0,1,1) with drift         : -11403.11\n",
      " ARIMA(0,1,0)                    : -11352.92\n",
      " ARIMA(1,1,2) with drift         : -11408.89\n",
      " ARIMA(2,1,1) with drift         : -11412.58\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11403.44\n",
      " ARIMA(1,1,3) with drift         : -11410.03\n",
      " ARIMA(3,1,1) with drift         : -11411.93\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11421.97\n",
      " ARIMA(1,1,2)                    : -11410.89\n",
      " ARIMA(2,1,1)                    : -11414.58\n",
      " ARIMA(3,1,2)                    : -11484.89\n",
      " ARIMA(3,1,1)                    : -11413.93\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : -11417.69\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11497.38\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11416.52\n",
      " ARIMA(0,1,0) with drift         : -11347.64\n",
      " ARIMA(1,1,0) with drift         : -11391.62\n",
      " ARIMA(0,1,1) with drift         : -11399.55\n",
      " ARIMA(0,1,0)                    : -11349.64\n",
      " ARIMA(1,1,2) with drift         : -11405.39\n",
      " ARIMA(2,1,1) with drift         : -11409.03\n",
      " ARIMA(3,1,2) with drift         : -11479.96\n",
      " ARIMA(3,1,1) with drift         : -11408.41\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11481.73\n",
      " ARIMA(1,1,3) with drift         : -11406.63\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11414.79\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11483.74\n",
      " ARIMA(1,1,3)                    : -11408.63\n",
      " ARIMA(2,1,2)                    : -11418.53\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11407.41\n",
      " ARIMA(1,1,4)                    : -11416.8\n",
      " ARIMA(3,1,2)                    : -11481.98\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : -11494.17\n",
      "\n",
      " Best model: ARIMA(2,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11407.96\n",
      " ARIMA(0,1,0) with drift         : -11338.46\n",
      " ARIMA(1,1,0) with drift         : -11382.61\n",
      " ARIMA(0,1,1) with drift         : -11390.38\n",
      " ARIMA(0,1,0)                    : -11340.46\n",
      " ARIMA(1,1,2) with drift         : -11396.61\n",
      " ARIMA(2,1,1) with drift         : -11400.55\n",
      " ARIMA(3,1,2) with drift         : -11471.9\n",
      " ARIMA(3,1,1) with drift         : -11399.74\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11470.53\n",
      " ARIMA(4,1,1) with drift         : -11403.38\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11473.9\n",
      " ARIMA(2,1,2)                    : -11409.97\n",
      " ARIMA(3,1,1)                    : -11401.75\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11402.56\n",
      " ARIMA(2,1,3)                    : -11472.5\n",
      " ARIMA(4,1,1)                    : -11405.4\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11484.35\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11396.17\n",
      " ARIMA(0,1,0) with drift         : -11328.02\n",
      " ARIMA(1,1,0) with drift         : -11371.4\n",
      " ARIMA(0,1,1) with drift         : -11379.49\n",
      " ARIMA(0,1,0)                    : -11330.02\n",
      " ARIMA(1,1,2) with drift         : -11385.91\n",
      " ARIMA(2,1,1) with drift         : -11389.47\n",
      " ARIMA(3,1,2) with drift         : -11458.66\n",
      " ARIMA(3,1,1) with drift         : -11388.42\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11458.39\n",
      " ARIMA(4,1,1) with drift         : -11391.51\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11460.67\n",
      " ARIMA(2,1,2)                    : -11398.17\n",
      " ARIMA(3,1,1)                    : -11390.41\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11391.47\n",
      " ARIMA(2,1,3)                    : -11460.41\n",
      " ARIMA(4,1,1)                    : -11393.51\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11472.04\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11384.39\n",
      " ARIMA(0,1,0) with drift         : -11316.01\n",
      " ARIMA(1,1,0) with drift         : -11360.76\n",
      " ARIMA(0,1,1) with drift         : -11368.5\n",
      " ARIMA(0,1,0)                    : -11318.01\n",
      " ARIMA(1,1,2) with drift         : -11375.04\n",
      " ARIMA(2,1,1) with drift         : -11378.36\n",
      " ARIMA(3,1,2) with drift         : -11443.48\n",
      " ARIMA(3,1,1) with drift         : -11377.21\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11445.13\n",
      " ARIMA(2,1,3) with drift         : -11446.41\n",
      " ARIMA(1,1,3) with drift         : -11375.64\n",
      " ARIMA(2,1,4) with drift         : -11438.15\n",
      " ARIMA(1,1,4) with drift         : -11381.98\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11440.96\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3) with drift         : -11458.24\n",
      "\n",
      " Best model: ARIMA(2,1,3) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11382.84\n",
      " ARIMA(0,1,0) with drift         : -11314.2\n",
      " ARIMA(1,1,0) with drift         : -11359.08\n",
      " ARIMA(0,1,1) with drift         : -11366.52\n",
      " ARIMA(0,1,0)                    : -11316.21\n",
      " ARIMA(1,1,2) with drift         : -11373.79\n",
      " ARIMA(2,1,1) with drift         : -11377.02\n",
      " ARIMA(3,1,2) with drift         : -11443.18\n",
      " ARIMA(3,1,1) with drift         : -11375.83\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11441.2\n",
      " ARIMA(2,1,3) with drift         : -11440.68\n",
      " ARIMA(4,1,1) with drift         : -11378.62\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11445.18\n",
      " ARIMA(2,1,2)                    : -11384.85\n",
      " ARIMA(3,1,1)                    : -11377.84\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11443.21\n",
      " ARIMA(2,1,1)                    : -11379.03\n",
      " ARIMA(2,1,3)                    : -11442.69\n",
      " ARIMA(4,1,1)                    : -11380.64\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11457.01\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11385.06\n",
      " ARIMA(0,1,0) with drift         : -11317.34\n",
      " ARIMA(1,1,0) with drift         : -11361\n",
      " ARIMA(0,1,1) with drift         : -11369.29\n",
      " ARIMA(0,1,0)                    : -11319.34\n",
      " ARIMA(1,1,2) with drift         : -11375.57\n",
      " ARIMA(2,1,1) with drift         : -11378.89\n",
      " ARIMA(3,1,2) with drift         : -11447.76\n",
      " ARIMA(3,1,1) with drift         : -11377.8\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11380.61\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11449.77\n",
      " ARIMA(2,1,2)                    : -11387.06\n",
      " ARIMA(3,1,1)                    : -11379.81\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11380.9\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : -11382.62\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11460.04\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11381.42\n",
      " ARIMA(0,1,0) with drift         : -11314.33\n",
      " ARIMA(1,1,0) with drift         : -11358.1\n",
      " ARIMA(0,1,1) with drift         : -11366.38\n",
      " ARIMA(0,1,0)                    : -11316.34\n",
      " ARIMA(1,1,2) with drift         : -11372.29\n",
      " ARIMA(2,1,1) with drift         : -11375.63\n",
      " ARIMA(3,1,2) with drift         : -11437\n",
      " ARIMA(3,1,1) with drift         : -11375\n",
      " ARIMA(4,1,2) with drift         : -11443.02\n",
      " ARIMA(4,1,1) with drift         : -11377.67\n",
      " ARIMA(5,1,2) with drift         : -11383.28\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(5,1,1) with drift         : -11384.28\n",
      " ARIMA(5,1,3) with drift         : -11460.66\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(5,1,3)                    : -11406.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : -11455.43\n",
      "\n",
      " Best model: ARIMA(3,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11376\n",
      " ARIMA(0,1,0) with drift         : -11310.81\n",
      " ARIMA(1,1,0) with drift         : -11353.5\n",
      " ARIMA(0,1,1) with drift         : -11361.68\n",
      " ARIMA(0,1,0)                    : -11312.81\n",
      " ARIMA(1,1,2) with drift         : -11367.66\n",
      " ARIMA(2,1,1) with drift         : -11370.74\n",
      " ARIMA(3,1,2) with drift         : -11435.23\n",
      " ARIMA(3,1,1) with drift         : -11369.84\n",
      " ARIMA(4,1,2) with drift         : -11435.36\n",
      " ARIMA(4,1,1) with drift         : -11372.57\n",
      " ARIMA(5,1,2) with drift         : -11379.67\n",
      " ARIMA(4,1,3) with drift         : -11462.93\n",
      " ARIMA(3,1,3) with drift         : -11437.7\n",
      " ARIMA(5,1,3) with drift         : -11450.93\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(5,1,4) with drift         : -11457.04\n",
      " ARIMA(4,1,3)                    : -11464.8\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(4,1,2)                    : -11437.24\n",
      " ARIMA(5,1,3)                    : -11452.91\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11437.19\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(5,1,2)                    : -11381.68\n",
      " ARIMA(5,1,4)                    : -11458.98\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(5,1,4)                    : Inf\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(5,1,3)                    : Inf\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11451.79\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11377.46\n",
      " ARIMA(0,1,0) with drift         : -11311.79\n",
      " ARIMA(1,1,0) with drift         : -11353.83\n",
      " ARIMA(0,1,1) with drift         : -11361.84\n",
      " ARIMA(0,1,0)                    : -11313.79\n",
      " ARIMA(1,1,2) with drift         : -11367.56\n",
      " ARIMA(2,1,1) with drift         : -11372.91\n",
      " ARIMA(3,1,2) with drift         : -11421.85\n",
      " ARIMA(3,1,1) with drift         : -11371.51\n",
      " ARIMA(4,1,2) with drift         : -11441.18\n",
      " ARIMA(4,1,1) with drift         : -11374.72\n",
      " ARIMA(5,1,2) with drift         : -11382.23\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11422.45\n",
      " ARIMA(5,1,1) with drift         : -11383.49\n",
      " ARIMA(5,1,3) with drift         : -11452.79\n",
      " ARIMA(5,1,4) with drift         : -11453.95\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(5,1,5) with drift         : Inf\n",
      " ARIMA(4,1,5) with drift         : Inf\n",
      " ARIMA(5,1,4)                    : -11456\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(5,1,3)                    : -11454.45\n",
      " ARIMA(5,1,5)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(4,1,5)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,1,4)                    : Inf\n",
      " ARIMA(5,1,3)                    : Inf\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : -11449.4\n",
      "\n",
      " Best model: ARIMA(3,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11401.14\n",
      " ARIMA(0,1,0) with drift         : -11333.59\n",
      " ARIMA(1,1,0) with drift         : -11375.37\n",
      " ARIMA(0,1,1) with drift         : -11383.32\n",
      " ARIMA(0,1,0)                    : -11335.6\n",
      " ARIMA(1,1,2) with drift         : -11388.38\n",
      " ARIMA(2,1,1) with drift         : -11397.14\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11436.48\n",
      " ARIMA(1,1,3) with drift         : -11388.8\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11395.96\n",
      " ARIMA(3,1,4) with drift         : -11404.42\n",
      " ARIMA(2,1,3)                    : -11438.39\n",
      " ARIMA(1,1,3)                    : -11390.8\n",
      " ARIMA(2,1,2)                    : -11403.15\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11390.39\n",
      " ARIMA(1,1,4)                    : -11397.97\n",
      " ARIMA(3,1,2)                    : -11399.44\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11409.43\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11414.62\n",
      " ARIMA(0,1,0) with drift         : -11349.66\n",
      " ARIMA(1,1,0) with drift         : -11391.07\n",
      " ARIMA(0,1,1) with drift         : -11398.77\n",
      " ARIMA(0,1,0)                    : -11351.66\n",
      " ARIMA(1,1,2) with drift         : -11404.51\n",
      " ARIMA(2,1,1) with drift         : -11408.59\n",
      " ARIMA(3,1,2) with drift         : -11474.76\n",
      " ARIMA(3,1,1) with drift         : -11407.28\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11474.66\n",
      " ARIMA(2,1,3) with drift         : -11475\n",
      " ARIMA(1,1,3) with drift         : -11405.01\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11411.68\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11476.95\n",
      " ARIMA(1,1,3)                    : -11407\n",
      " ARIMA(2,1,2)                    : -11416.63\n",
      " ARIMA(3,1,3)                    : -11476.66\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11406.51\n",
      " ARIMA(1,1,4)                    : -11413.69\n",
      " ARIMA(3,1,2)                    : -11476.73\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : -11489.85\n",
      "\n",
      " Best model: ARIMA(3,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11417\n",
      " ARIMA(0,1,0) with drift         : -11350.81\n",
      " ARIMA(1,1,0) with drift         : -11393.43\n",
      " ARIMA(0,1,1) with drift         : -11401.37\n",
      " ARIMA(0,1,0)                    : -11352.81\n",
      " ARIMA(1,1,2) with drift         : -11408.15\n",
      " ARIMA(2,1,1) with drift         : -11411.62\n",
      " ARIMA(3,1,2) with drift         : -11478.61\n",
      " ARIMA(3,1,1) with drift         : -11410.14\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11477.88\n",
      " ARIMA(2,1,3) with drift         : -11480.64\n",
      " ARIMA(1,1,3) with drift         : -11408.04\n",
      " ARIMA(2,1,4) with drift         : -11470.54\n",
      " ARIMA(1,1,4) with drift         : -11413.2\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11482.64\n",
      " ARIMA(1,1,3)                    : -11410.05\n",
      " ARIMA(2,1,2)                    : -11419\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : -11472.55\n",
      " ARIMA(1,1,2)                    : -11410.17\n",
      " ARIMA(1,1,4)                    : -11415.2\n",
      " ARIMA(3,1,2)                    : -11480.59\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11494.28\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11428.15\n",
      " ARIMA(0,1,0) with drift         : -11363.82\n",
      " ARIMA(1,1,0) with drift         : -11405.04\n",
      " ARIMA(0,1,1) with drift         : -11413.13\n",
      " ARIMA(0,1,0)                    : -11365.82\n",
      " ARIMA(1,1,2) with drift         : -11419.24\n",
      " ARIMA(2,1,1) with drift         : -11423.1\n",
      " ARIMA(3,1,2) with drift         : -11485.43\n",
      " ARIMA(3,1,1) with drift         : -11421.44\n",
      " ARIMA(4,1,2) with drift         : -11470.37\n",
      " ARIMA(3,1,3) with drift         : -11484.77\n",
      " ARIMA(2,1,3) with drift         : -11487.17\n",
      " ARIMA(1,1,3) with drift         : -11419.2\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11425.26\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11489.13\n",
      " ARIMA(1,1,3)                    : -11421.2\n",
      " ARIMA(2,1,2)                    : -11430.16\n",
      " ARIMA(3,1,3)                    : -11486.74\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11421.24\n",
      " ARIMA(1,1,4)                    : -11427.26\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11439.42\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11445.44\n",
      " ARIMA(0,1,0) with drift         : -11379.2\n",
      " ARIMA(1,1,0) with drift         : -11421.84\n",
      " ARIMA(0,1,1) with drift         : -11429.11\n",
      " ARIMA(0,1,0)                    : -11381.2\n",
      " ARIMA(1,1,2) with drift         : -11437.71\n",
      " ARIMA(2,1,1) with drift         : -11440.18\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11507.1\n",
      " ARIMA(1,1,3) with drift         : -11437.5\n",
      " ARIMA(3,1,3) with drift         : -11506.37\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11443.66\n",
      " ARIMA(3,1,4) with drift         : -11533.54\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(3,1,5) with drift         : -11472.61\n",
      " ARIMA(2,1,5) with drift         : -11477.81\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(4,1,5) with drift         : -11542.91\n",
      " ARIMA(5,1,5) with drift         : Inf\n",
      " ARIMA(5,1,4) with drift         : -11515.88\n",
      " ARIMA(4,1,5)                    : -11544.81\n",
      " ARIMA(3,1,5)                    : -11474.62\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(5,1,5)                    : Inf\n",
      " ARIMA(3,1,4)                    : -11533.75\n",
      " ARIMA(5,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,5)                    : Inf\n",
      " ARIMA(4,1,5) with drift         : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,5) with drift         : -11486.28\n",
      "\n",
      " Best model: ARIMA(2,1,5) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11460.12\n",
      " ARIMA(0,1,0) with drift         : -11392.48\n",
      " ARIMA(1,1,0) with drift         : -11436.18\n",
      " ARIMA(0,1,1) with drift         : -11443.02\n",
      " ARIMA(0,1,0)                    : -11394.47\n",
      " ARIMA(1,1,2) with drift         : -11452\n",
      " ARIMA(2,1,1) with drift         : -11454.69\n",
      " ARIMA(3,1,2) with drift         : -11512.45\n",
      " ARIMA(3,1,1) with drift         : -11453.12\n",
      " ARIMA(4,1,2) with drift         : -11538.32\n",
      " ARIMA(4,1,1) with drift         : -11454.98\n",
      " ARIMA(5,1,2) with drift         : -11480.96\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11519.43\n",
      " ARIMA(5,1,1) with drift         : -11465.65\n",
      " ARIMA(5,1,3) with drift         : -11541.25\n",
      " ARIMA(5,1,4) with drift         : -11546.31\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(5,1,5) with drift         : Inf\n",
      " ARIMA(4,1,5) with drift         : Inf\n",
      " ARIMA(5,1,4)                    : -11548.31\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(5,1,3)                    : -11543.22\n",
      " ARIMA(5,1,5)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(4,1,5)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,1,4)                    : Inf\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(5,1,3)                    : Inf\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : -11520.63\n",
      "\n",
      " Best model: ARIMA(3,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11473.66\n",
      " ARIMA(0,1,0) with drift         : -11405.4\n",
      " ARIMA(1,1,0) with drift         : -11449.03\n",
      " ARIMA(0,1,1) with drift         : -11457.36\n",
      " ARIMA(0,1,0)                    : -11407.4\n",
      " ARIMA(1,1,2) with drift         : -11465.21\n",
      " ARIMA(2,1,1) with drift         : -11468.1\n",
      " ARIMA(3,1,2) with drift         : -11522.67\n",
      " ARIMA(3,1,1) with drift         : -11466.94\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11523.94\n",
      " ARIMA(2,1,3) with drift         : -11530.31\n",
      " ARIMA(1,1,3) with drift         : -11464.92\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11469.99\n",
      " ARIMA(3,1,4) with drift         : -11553.79\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(3,1,5) with drift         : -11506.29\n",
      " ARIMA(2,1,5) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(4,1,5) with drift         : Inf\n",
      " ARIMA(3,1,4)                    : -11555.37\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11525.89\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(3,1,5)                    : -11508.29\n",
      " ARIMA(2,1,3)                    : -11532.31\n",
      " ARIMA(2,1,5)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(4,1,5)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(3,1,5)                    : -11517.89\n",
      "\n",
      " Best model: ARIMA(3,1,5)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11563.65\n",
      " ARIMA(0,0,0) with non-zero mean : -7092.942\n",
      " ARIMA(1,0,0) with non-zero mean : -11532.35\n",
      " ARIMA(0,0,1) with non-zero mean : -9062.662\n",
      " ARIMA(0,0,0) with zero mean     : -7069.286\n",
      " ARIMA(1,0,2) with non-zero mean : -11561.12\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11629.33\n",
      " ARIMA(3,0,1) with non-zero mean : -11567.62\n",
      " ARIMA(4,0,2) with non-zero mean : -11577.15\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11570.59\n",
      " ARIMA(4,0,1) with non-zero mean : -11573.86\n",
      " ARIMA(4,0,3) with non-zero mean : -11639.6\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11626.91\n",
      " ARIMA(5,0,4) with non-zero mean : -11629.53\n",
      " ARIMA(4,0,3) with zero mean     : -11641.48\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11643.49\n",
      " ARIMA(3,0,2) with zero mean     : -11630.38\n",
      " ARIMA(4,0,1) with zero mean     : -11575.2\n",
      " ARIMA(5,0,2) with zero mean     : -11627.71\n",
      " ARIMA(3,0,1) with zero mean     : -11569\n",
      " ARIMA(5,0,1) with zero mean     : -11604.21\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11634.59\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11531.84\n",
      " ARIMA(0,1,0) with drift         : -11462.99\n",
      " ARIMA(1,1,0) with drift         : -11505.42\n",
      " ARIMA(0,1,1) with drift         : -11513.88\n",
      " ARIMA(0,1,0)                    : -11464.99\n",
      " ARIMA(1,1,2) with drift         : -11520.31\n",
      " ARIMA(2,1,1) with drift         : -11524.07\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11514.74\n",
      " ARIMA(1,1,3) with drift         : -11521.21\n",
      " ARIMA(3,1,1) with drift         : -11523.29\n",
      " ARIMA(3,1,3) with drift         : -11595.73\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : -11603.16\n",
      " ARIMA(4,1,1) with drift         : -11525.22\n",
      " ARIMA(5,1,2) with drift         : -11560.26\n",
      " ARIMA(5,1,1) with drift         : -11535.35\n",
      " ARIMA(5,1,3) with drift         : -11560.94\n",
      " ARIMA(4,1,2)                    : -11605.05\n",
      " ARIMA(3,1,2)                    : -11599.29\n",
      " ARIMA(4,1,1)                    : -11527.23\n",
      " ARIMA(5,1,2)                    : -11562.29\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(3,1,1)                    : -11525.3\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(5,1,1)                    : -11537.37\n",
      " ARIMA(5,1,3)                    : -11562.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(5,1,3)                    : Inf\n",
      " ARIMA(5,1,2)                    : -11574.41\n",
      "\n",
      " Best model: ARIMA(5,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11540.3\n",
      " ARIMA(0,1,0) with drift         : -11469.86\n",
      " ARIMA(1,1,0) with drift         : -11512.62\n",
      " ARIMA(0,1,1) with drift         : -11521.01\n",
      " ARIMA(0,1,0)                    : -11471.86\n",
      " ARIMA(1,1,2) with drift         : -11527.97\n",
      " ARIMA(2,1,1) with drift         : -11531.89\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11522.06\n",
      " ARIMA(1,1,3) with drift         : -11529.09\n",
      " ARIMA(3,1,1) with drift         : -11531.68\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11542.31\n",
      " ARIMA(1,1,2)                    : -11529.98\n",
      " ARIMA(2,1,1)                    : -11533.89\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(1,1,1)                    : -11524.06\n",
      " ARIMA(1,1,3)                    : -11531.09\n",
      " ARIMA(3,1,1)                    : -11533.69\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11551.54\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11545.43\n",
      " ARIMA(0,1,0) with drift         : -11476.22\n",
      " ARIMA(1,1,0) with drift         : -11519.24\n",
      " ARIMA(0,1,1) with drift         : -11527.35\n",
      " ARIMA(0,1,0)                    : -11478.22\n",
      " ARIMA(1,1,2) with drift         : -11535.3\n",
      " ARIMA(2,1,1) with drift         : -11538.4\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11606.01\n",
      " ARIMA(1,1,3) with drift         : -11536.07\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11543.1\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11608.02\n",
      " ARIMA(1,1,3)                    : -11538.06\n",
      " ARIMA(2,1,2)                    : -11547.44\n",
      " ARIMA(3,1,3)                    : -11608.56\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(4,1,2)                    : -11548.72\n",
      " ARIMA(4,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(2,1,2)                    : -11557.99\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11626.41\n",
      " ARIMA(0,0,0) with non-zero mean : -7180.606\n",
      " ARIMA(1,0,0) with non-zero mean : -11595.23\n",
      " ARIMA(0,0,1) with non-zero mean : -9148.012\n",
      " ARIMA(0,0,0) with zero mean     : -7147.407\n",
      " ARIMA(1,0,2) with non-zero mean : -11622.24\n",
      " ARIMA(2,0,1) with non-zero mean : -11605.97\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11635.32\n",
      " ARIMA(1,0,3) with non-zero mean : -11637.31\n",
      " ARIMA(0,0,3) with non-zero mean : -10542.52\n",
      " ARIMA(1,0,4) with non-zero mean : -11636.59\n",
      " ARIMA(0,0,2) with non-zero mean : -10038.07\n",
      " ARIMA(0,0,4) with non-zero mean : -10971.87\n",
      " ARIMA(2,0,4) with non-zero mean : -11663.67\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11674.55\n",
      " ARIMA(1,0,5) with non-zero mean : -11642.38\n",
      " ARIMA(3,0,5) with non-zero mean : -11671.84\n",
      " ARIMA(2,0,5) with zero mean     : -11675.29\n",
      " ARIMA(1,0,5) with zero mean     : -11643.28\n",
      " ARIMA(2,0,4) with zero mean     : -11664.18\n",
      " ARIMA(3,0,5) with zero mean     : -11672.8\n",
      " ARIMA(1,0,4) with zero mean     : -11637.4\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,5) with zero mean     : -11676.74\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11637.1\n",
      " ARIMA(0,0,0) with non-zero mean : -7183.094\n",
      " ARIMA(1,0,0) with non-zero mean : -11607.12\n",
      " ARIMA(0,0,1) with non-zero mean : -9156.432\n",
      " ARIMA(0,0,0) with zero mean     : -7151.929\n",
      " ARIMA(1,0,2) with non-zero mean : -11633.92\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11646.52\n",
      " ARIMA(1,0,3) with non-zero mean : -11649.07\n",
      " ARIMA(0,0,3) with non-zero mean : -10551.96\n",
      " ARIMA(1,0,4) with non-zero mean : -11648.28\n",
      " ARIMA(0,0,2) with non-zero mean : -10047.3\n",
      " ARIMA(0,0,4) with non-zero mean : -10983.71\n",
      " ARIMA(2,0,4) with non-zero mean : -11680.57\n",
      " ARIMA(3,0,4) with non-zero mean : -11756.89\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11689.65\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11690\n",
      "\n",
      " Best model: ARIMA(2,0,5) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11726.86\n",
      " ARIMA(0,0,0) with non-zero mean : -7219.871\n",
      " ARIMA(1,0,0) with non-zero mean : -11704.34\n",
      " ARIMA(0,0,1) with non-zero mean : -9202.304\n",
      " ARIMA(0,0,0) with zero mean     : -7181.348\n",
      " ARIMA(1,0,2) with non-zero mean : -11725.28\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11821.89\n",
      " ARIMA(3,0,1) with non-zero mean : -11737.16\n",
      " ARIMA(4,0,2) with non-zero mean : -11746.45\n",
      " ARIMA(3,0,3) with non-zero mean : -11841.21\n",
      " ARIMA(2,0,3) with non-zero mean : -11736.78\n",
      " ARIMA(4,0,3) with non-zero mean : -11883.48\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11882.26\n",
      " ARIMA(3,0,4) with non-zero mean : -11841.53\n",
      " ARIMA(5,0,2) with non-zero mean : -11819.23\n",
      " ARIMA(5,0,4) with non-zero mean : -11834.07\n",
      " ARIMA(4,0,3) with zero mean     : -11883.42\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,1) with non-zero mean : -11727.48\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12048.88\n",
      " ARIMA(0,0,0) with non-zero mean : -7798.523\n",
      " ARIMA(1,0,0) with non-zero mean : -12046.89\n",
      " ARIMA(0,0,1) with non-zero mean : -9695.57\n",
      " ARIMA(0,0,0) with zero mean     : -7706.469\n",
      " ARIMA(1,0,2) with non-zero mean : -12050.93\n",
      " ARIMA(0,0,2) with non-zero mean : -10590.18\n",
      " ARIMA(1,0,1) with non-zero mean : -12052.27\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(2,0,0) with non-zero mean : -12051.33\n",
      " ARIMA(1,0,1) with zero mean     : -12048.87\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -12021.88\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12434.36\n",
      " ARIMA(0,0,0) with non-zero mean : -7980.504\n",
      " ARIMA(1,0,0) with non-zero mean : -12372.67\n",
      " ARIMA(0,0,1) with non-zero mean : -9941.412\n",
      " ARIMA(0,0,0) with zero mean     : -7857.589\n",
      " ARIMA(1,0,2) with non-zero mean : -12376.41\n",
      " ARIMA(2,0,1) with non-zero mean : -12436.06\n",
      " ARIMA(1,0,1) with non-zero mean : -12377.95\n",
      " ARIMA(2,0,0) with non-zero mean : -12437.96\n",
      " ARIMA(3,0,0) with non-zero mean : -12435.15\n",
      " ARIMA(3,0,1) with non-zero mean : -12454.73\n",
      " ARIMA(4,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -12464.93\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12537.98\n",
      " ARIMA(2,0,3) with non-zero mean : -12436.37\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -12558.88\n",
      " ARIMA(2,0,4) with non-zero mean : -12437.89\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : -12482.54\n",
      " ARIMA(2,0,5) with non-zero mean : -12443.38\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -12558.06\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : -12501.26\n",
      "\n",
      " Best model: ARIMA(3,0,5) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12731.55\n",
      " ARIMA(0,0,0) with non-zero mean : -8064.913\n",
      " ARIMA(1,0,0) with non-zero mean : -12677.97\n",
      " ARIMA(0,0,1) with non-zero mean : -10058.9\n",
      " ARIMA(0,0,0) with zero mean     : -7927.111\n",
      " ARIMA(1,0,2) with non-zero mean : -12680.87\n",
      " ARIMA(2,0,1) with non-zero mean : -12729.28\n",
      " ARIMA(3,0,2) with non-zero mean : -12759.62\n",
      " ARIMA(3,0,1) with non-zero mean : -12730.55\n",
      " ARIMA(4,0,2) with non-zero mean : -12811.44\n",
      " ARIMA(4,0,1) with non-zero mean : -12738.03\n",
      " ARIMA(5,0,2) with non-zero mean : -12780.21\n",
      " ARIMA(4,0,3) with non-zero mean : -12809.91\n",
      " ARIMA(3,0,3) with non-zero mean : -12761.06\n",
      " ARIMA(5,0,1) with non-zero mean : -12747.6\n",
      " ARIMA(5,0,3) with non-zero mean : -12832.04\n",
      " ARIMA(5,0,4) with non-zero mean : -12815.29\n",
      " ARIMA(4,0,4) with non-zero mean : -12808.46\n",
      " ARIMA(5,0,3) with zero mean     : -12788.39\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -12735.86\n",
      "\n",
      " Best model: ARIMA(5,0,3) with zero mean     \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12838.17\n",
      " ARIMA(0,0,0) with non-zero mean : -8091.392\n",
      " ARIMA(1,0,0) with non-zero mean : -12837.14\n",
      " ARIMA(0,0,1) with non-zero mean : -10097.45\n",
      " ARIMA(0,0,0) with zero mean     : -7938.12\n",
      " ARIMA(1,0,2) with non-zero mean : -12838.32\n",
      " ARIMA(0,0,2) with non-zero mean : -11279.5\n",
      " ARIMA(1,0,1) with non-zero mean : -12837.52\n",
      " ARIMA(1,0,3) with non-zero mean : -12836.31\n",
      " ARIMA(0,0,3) with non-zero mean : -11685.67\n",
      " ARIMA(2,0,1) with non-zero mean : -12838.94\n",
      " ARIMA(2,0,0) with non-zero mean : -12838.65\n",
      " ARIMA(3,0,1) with non-zero mean : -12842.45\n",
      " ARIMA(3,0,0) with non-zero mean : -12841.35\n",
      " ARIMA(4,0,1) with non-zero mean : -12840.34\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,0) with non-zero mean : -12838.9\n",
      " ARIMA(4,0,2) with non-zero mean : -12861.04\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -12898.44\n",
      " ARIMA(3,0,3) with non-zero mean : -12879.27\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -12896.67\n",
      " ARIMA(3,0,4) with non-zero mean : -12878.13\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -12852.41\n",
      "\n",
      " Best model: ARIMA(4,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12927.14\n",
      " ARIMA(0,0,0) with non-zero mean : -8198.192\n",
      " ARIMA(1,0,0) with non-zero mean : -12908.82\n",
      " ARIMA(0,0,1) with non-zero mean : -10141.79\n",
      " ARIMA(0,0,0) with zero mean     : -8024.557\n",
      " ARIMA(1,0,2) with non-zero mean : -12911.9\n",
      " ARIMA(2,0,1) with non-zero mean : -12929.13\n",
      " ARIMA(1,0,1) with non-zero mean : -12908.74\n",
      " ARIMA(2,0,0) with non-zero mean : -12908.7\n",
      " ARIMA(3,0,1) with non-zero mean : -12938.63\n",
      " ARIMA(3,0,0) with non-zero mean : -12936.86\n",
      " ARIMA(4,0,1) with non-zero mean : -12933.76\n",
      " ARIMA(3,0,2) with non-zero mean : -12952.1\n",
      " ARIMA(4,0,2) with non-zero mean : -12950.34\n",
      " ARIMA(3,0,3) with non-zero mean : -12953.03\n",
      " ARIMA(2,0,3) with non-zero mean : -12926.06\n",
      " ARIMA(4,0,3) with non-zero mean : -13011.78\n",
      " ARIMA(5,0,3) with non-zero mean : -12957.38\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -12955.51\n",
      " ARIMA(5,0,2) with non-zero mean : -12958.24\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -12944\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -12921.65\n",
      "\n",
      " Best model: ARIMA(3,0,4) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13034.35\n",
      " ARIMA(0,0,0) with non-zero mean : -8419.008\n",
      " ARIMA(1,0,0) with non-zero mean : -13034.07\n",
      " ARIMA(0,0,1) with non-zero mean : -10368.77\n",
      " ARIMA(0,0,0) with zero mean     : -8212.474\n",
      " ARIMA(1,0,2) with non-zero mean : -13036.71\n",
      " ARIMA(0,0,2) with non-zero mean : -11525.41\n",
      " ARIMA(1,0,1) with non-zero mean : -13033.75\n",
      " ARIMA(1,0,3) with non-zero mean : -13035.61\n",
      " ARIMA(0,0,3) with non-zero mean : -11936.39\n",
      " ARIMA(2,0,1) with non-zero mean : -13032.6\n",
      " ARIMA(2,0,3) with non-zero mean : -13034.24\n",
      " ARIMA(1,0,2) with zero mean     : -13032.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,2) with non-zero mean : -13022.48\n",
      "\n",
      " Best model: ARIMA(1,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13141.92\n",
      " ARIMA(0,0,0) with non-zero mean : -8600.267\n",
      " ARIMA(1,0,0) with non-zero mean : -13132.96\n",
      " ARIMA(0,0,1) with non-zero mean : -10567.03\n",
      " ARIMA(0,0,0) with zero mean     : -8417.529\n",
      " ARIMA(1,0,2) with non-zero mean : -13135.69\n",
      " ARIMA(2,0,1) with non-zero mean : -13143.46\n",
      " ARIMA(1,0,1) with non-zero mean : -13131.3\n",
      " ARIMA(2,0,0) with non-zero mean : -13130.87\n",
      " ARIMA(3,0,1) with non-zero mean : -13141.06\n",
      " ARIMA(3,0,0) with non-zero mean : -13135.48\n",
      " ARIMA(3,0,2) with non-zero mean : -13139.83\n",
      " ARIMA(2,0,1) with zero mean     : -13139.77\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with non-zero mean : -13135.84\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13193.12\n",
      " ARIMA(0,0,0) with non-zero mean : -8651.976\n",
      " ARIMA(1,0,0) with non-zero mean : -13170.43\n",
      " ARIMA(0,0,1) with non-zero mean : -10600.05\n",
      " ARIMA(0,0,0) with zero mean     : -8478.609\n",
      " ARIMA(1,0,2) with non-zero mean : -13174.57\n",
      " ARIMA(2,0,1) with non-zero mean : -13191\n",
      " ARIMA(3,0,2) with non-zero mean : -13202.7\n",
      " ARIMA(3,0,1) with non-zero mean : -13192.86\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -13200.6\n",
      " ARIMA(2,0,3) with non-zero mean : -13191.28\n",
      " ARIMA(4,0,1) with non-zero mean : -13191.15\n",
      " ARIMA(4,0,3) with non-zero mean : -13218.39\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -13200.58\n",
      " ARIMA(5,0,2) with non-zero mean : -13252.64\n",
      " ARIMA(5,0,1) with non-zero mean : -13189.33\n",
      " ARIMA(5,0,2) with zero mean     : -13248.74\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -13185.97\n",
      "\n",
      " Best model: ARIMA(3,0,4) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13224.59\n",
      " ARIMA(0,0,0) with non-zero mean : -8659.661\n",
      " ARIMA(1,0,0) with non-zero mean : -13222\n",
      " ARIMA(0,0,1) with non-zero mean : -10646.41\n",
      " ARIMA(0,0,0) with zero mean     : -8488.456\n",
      " ARIMA(1,0,2) with non-zero mean : -13223.63\n",
      " ARIMA(2,0,1) with non-zero mean : -13221.42\n",
      " ARIMA(3,0,2) with non-zero mean : -13234.74\n",
      " ARIMA(3,0,1) with non-zero mean : -13224.58\n",
      " ARIMA(4,0,2) with non-zero mean : -13224.71\n",
      " ARIMA(3,0,3) with non-zero mean : -13233.34\n",
      " ARIMA(2,0,3) with non-zero mean : -13222.66\n",
      " ARIMA(4,0,1) with non-zero mean : -13223.65\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -13227.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : -13241.51\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13264.36\n",
      " ARIMA(0,0,0) with non-zero mean : -8704.311\n",
      " ARIMA(1,0,0) with non-zero mean : -13253.56\n",
      " ARIMA(0,0,1) with non-zero mean : -10687.09\n",
      " ARIMA(0,0,0) with zero mean     : -8526.564\n",
      " ARIMA(1,0,2) with non-zero mean : -13254.11\n",
      " ARIMA(2,0,1) with non-zero mean : -13262.34\n",
      " ARIMA(3,0,2) with non-zero mean : -13271.99\n",
      " ARIMA(3,0,1) with non-zero mean : -13272.92\n",
      " ARIMA(3,0,0) with non-zero mean : -13267.33\n",
      " ARIMA(4,0,1) with non-zero mean : -13266.58\n",
      " ARIMA(2,0,0) with non-zero mean : -13264.86\n",
      " ARIMA(4,0,0) with non-zero mean : -13267.59\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,1) with zero mean     : -13268.9\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -13257.04\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13286.09\n",
      " ARIMA(0,0,0) with non-zero mean : -8799.759\n",
      " ARIMA(1,0,0) with non-zero mean : -13281.32\n",
      " ARIMA(0,0,1) with non-zero mean : -10765\n",
      " ARIMA(0,0,0) with zero mean     : -8632.875\n",
      " ARIMA(1,0,2) with non-zero mean : -13281.08\n",
      " ARIMA(2,0,1) with non-zero mean : -13284.31\n",
      " ARIMA(3,0,2) with non-zero mean : -13294.12\n",
      " ARIMA(3,0,1) with non-zero mean : -13296\n",
      " ARIMA(3,0,0) with non-zero mean : -13287.48\n",
      " ARIMA(4,0,1) with non-zero mean : -13292.11\n",
      " ARIMA(2,0,0) with non-zero mean : -13286.29\n",
      " ARIMA(4,0,0) with non-zero mean : -13285.57\n",
      " ARIMA(4,0,2) with non-zero mean : -13307.77\n",
      " ARIMA(5,0,2) with non-zero mean : -13333.7\n",
      " ARIMA(5,0,1) with non-zero mean : -13288.79\n",
      " ARIMA(5,0,3) with non-zero mean : -13381.08\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -13370.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -13298.7\n",
      "\n",
      " Best model: ARIMA(4,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13315.22\n",
      " ARIMA(0,0,0) with non-zero mean : -8818.601\n",
      " ARIMA(1,0,0) with non-zero mean : -13308.47\n",
      " ARIMA(0,0,1) with non-zero mean : -10784.96\n",
      " ARIMA(0,0,0) with zero mean     : -8656.278\n",
      " ARIMA(1,0,2) with non-zero mean : -13308.69\n",
      " ARIMA(2,0,1) with non-zero mean : -13316.57\n",
      " ARIMA(1,0,1) with non-zero mean : -13306.78\n",
      " ARIMA(2,0,0) with non-zero mean : -13305.83\n",
      " ARIMA(3,0,1) with non-zero mean : -13313.95\n",
      " ARIMA(3,0,0) with non-zero mean : -13307.08\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -13312.98\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with non-zero mean : -13315.59\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13294.52\n",
      " ARIMA(0,0,0) with non-zero mean : -8751.451\n",
      " ARIMA(1,0,0) with non-zero mean : -13289.34\n",
      " ARIMA(0,0,1) with non-zero mean : -10730.44\n",
      " ARIMA(0,0,0) with zero mean     : -8614.585\n",
      " ARIMA(1,0,2) with non-zero mean : -13289.61\n",
      " ARIMA(2,0,1) with non-zero mean : -13295.78\n",
      " ARIMA(1,0,1) with non-zero mean : -13287.61\n",
      " ARIMA(2,0,0) with non-zero mean : -13286.67\n",
      " ARIMA(3,0,1) with non-zero mean : -13288.61\n",
      " ARIMA(3,0,0) with non-zero mean : -13288.71\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -13293.98\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with non-zero mean : -13296.56\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13281.55\n",
      " ARIMA(0,0,0) with non-zero mean : -8730.333\n",
      " ARIMA(1,0,0) with non-zero mean : -13273.79\n",
      " ARIMA(0,0,1) with non-zero mean : -10715.07\n",
      " ARIMA(0,0,0) with zero mean     : -8603.515\n",
      " ARIMA(1,0,2) with non-zero mean : -13273.78\n",
      " ARIMA(2,0,1) with non-zero mean : -13279.31\n",
      " ARIMA(3,0,2) with non-zero mean : -13289.56\n",
      " ARIMA(3,0,1) with non-zero mean : -13288.08\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -13288.21\n",
      " ARIMA(2,0,3) with non-zero mean : -13279.63\n",
      " ARIMA(4,0,1) with non-zero mean : -13289.48\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -13287.32\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : -13277.09\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13244.45\n",
      " ARIMA(0,0,0) with non-zero mean : -8638.893\n",
      " ARIMA(1,0,0) with non-zero mean : -13241.32\n",
      " ARIMA(0,0,1) with non-zero mean : -10627.38\n",
      " ARIMA(0,0,0) with zero mean     : -8538.471\n",
      " ARIMA(1,0,2) with non-zero mean : -13241.96\n",
      " ARIMA(2,0,1) with non-zero mean : -13242.56\n",
      " ARIMA(3,0,2) with non-zero mean : -13242.28\n",
      " ARIMA(2,0,3) with non-zero mean : -13242.54\n",
      " ARIMA(1,0,1) with non-zero mean : -13239.47\n",
      " ARIMA(1,0,3) with non-zero mean : -13239.97\n",
      " ARIMA(3,0,1) with non-zero mean : -13242.75\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -13243.81\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13247.7\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13202.85\n",
      " ARIMA(0,0,0) with non-zero mean : -8591.905\n",
      " ARIMA(1,0,0) with non-zero mean : -13201\n",
      " ARIMA(0,0,1) with non-zero mean : -10586.47\n",
      " ARIMA(0,0,0) with zero mean     : -8489.949\n",
      " ARIMA(1,0,2) with non-zero mean : -13201.67\n",
      " ARIMA(2,0,1) with non-zero mean : -13200.09\n",
      " ARIMA(3,0,2) with non-zero mean : -13249.76\n",
      " ARIMA(3,0,1) with non-zero mean : -13215.09\n",
      " ARIMA(4,0,2) with non-zero mean : -13220.25\n",
      " ARIMA(3,0,3) with non-zero mean : -13213.48\n",
      " ARIMA(2,0,3) with non-zero mean : -13200.89\n",
      " ARIMA(4,0,1) with non-zero mean : -13210.99\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -13248.67\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -13219.49\n",
      "\n",
      " Best model: ARIMA(4,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13217.65\n",
      " ARIMA(0,0,0) with non-zero mean : -8600.973\n",
      " ARIMA(1,0,0) with non-zero mean : -13216.62\n",
      " ARIMA(0,0,1) with non-zero mean : -10599.03\n",
      " ARIMA(0,0,0) with zero mean     : -8478.971\n",
      " ARIMA(1,0,2) with non-zero mean : -13217.71\n",
      " ARIMA(0,0,2) with non-zero mean : -11739.39\n",
      " ARIMA(1,0,1) with non-zero mean : -13214.72\n",
      " ARIMA(1,0,3) with non-zero mean : -13215.7\n",
      " ARIMA(0,0,3) with non-zero mean : -12182.37\n",
      " ARIMA(2,0,1) with non-zero mean : -13218.8\n",
      " ARIMA(2,0,0) with non-zero mean : -13214.1\n",
      " ARIMA(3,0,1) with non-zero mean : -13230.16\n",
      " ARIMA(3,0,0) with non-zero mean : -13218.76\n",
      " ARIMA(4,0,1) with non-zero mean : -13222.52\n",
      " ARIMA(3,0,2) with non-zero mean : -13230.85\n",
      " ARIMA(4,0,2) with non-zero mean : -13234.85\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -13233.84\n",
      " ARIMA(3,0,3) with non-zero mean : -13229.16\n",
      " ARIMA(5,0,1) with non-zero mean : -13223.37\n",
      " ARIMA(5,0,3) with non-zero mean : -13293.72\n",
      " ARIMA(5,0,4) with non-zero mean : -13262.21\n",
      " ARIMA(4,0,4) with non-zero mean : -13229.1\n",
      " ARIMA(5,0,3) with zero mean     : -13290.35\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -13234.4\n",
      "\n",
      " Best model: ARIMA(4,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13229.23\n",
      " ARIMA(0,0,0) with non-zero mean : -8638.204\n",
      " ARIMA(1,0,0) with non-zero mean : -13222.89\n",
      " ARIMA(0,0,1) with non-zero mean : -10628.86\n",
      " ARIMA(0,0,0) with zero mean     : -8523.826\n",
      " ARIMA(1,0,2) with non-zero mean : -13223.89\n",
      " ARIMA(2,0,1) with non-zero mean : -13230.19\n",
      " ARIMA(1,0,1) with non-zero mean : -13220.98\n",
      " ARIMA(2,0,0) with non-zero mean : -13220.28\n",
      " ARIMA(3,0,1) with non-zero mean : -13227.34\n",
      " ARIMA(3,0,0) with non-zero mean : -13222.97\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -13228.25\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with non-zero mean : -13228.97\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13225.78\n",
      " ARIMA(0,0,0) with non-zero mean : -8640.479\n",
      " ARIMA(1,0,0) with non-zero mean : -13222.35\n",
      " ARIMA(0,0,1) with non-zero mean : -10630.57\n",
      " ARIMA(0,0,0) with zero mean     : -8526.609\n",
      " ARIMA(1,0,2) with non-zero mean : -13223.83\n",
      " ARIMA(2,0,1) with non-zero mean : -13223.03\n",
      " ARIMA(3,0,2) with non-zero mean : -13251.14\n",
      " ARIMA(3,0,1) with non-zero mean : -13231.06\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -13249.33\n",
      " ARIMA(2,0,3) with non-zero mean : -13237.37\n",
      " ARIMA(4,0,1) with non-zero mean : -13228.66\n",
      " ARIMA(4,0,3) with non-zero mean : -13312.69\n",
      " ARIMA(5,0,3) with non-zero mean : -13240.06\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -13225.83\n",
      " ARIMA(5,0,2) with non-zero mean : -13241.89\n",
      " ARIMA(5,0,4) with non-zero mean : -13272.13\n",
      " ARIMA(4,0,3) with zero mean     : -13226.4\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -13240.64\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13273.5\n",
      " ARIMA(0,0,0) with non-zero mean : -8726.392\n",
      " ARIMA(1,0,0) with non-zero mean : -13268.27\n",
      " ARIMA(0,0,1) with non-zero mean : -10693.44\n",
      " ARIMA(0,0,0) with zero mean     : -8598.523\n",
      " ARIMA(1,0,2) with non-zero mean : -13269.54\n",
      " ARIMA(2,0,1) with non-zero mean : -13270.56\n",
      " ARIMA(3,0,2) with non-zero mean : -13290.67\n",
      " ARIMA(3,0,1) with non-zero mean : -13275.6\n",
      " ARIMA(4,0,2) with non-zero mean : -13337.17\n",
      " ARIMA(4,0,1) with non-zero mean : -13273.2\n",
      " ARIMA(5,0,2) with non-zero mean : -13320.19\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -13322.75\n",
      " ARIMA(5,0,1) with non-zero mean : -13288.19\n",
      " ARIMA(5,0,3) with non-zero mean : -13339.1\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -13330.91\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,1) with non-zero mean : -13260.9\n",
      "\n",
      " Best model: ARIMA(5,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13330.8\n",
      " ARIMA(0,0,0) with non-zero mean : -8763.678\n",
      " ARIMA(1,0,0) with non-zero mean : -13327.64\n",
      " ARIMA(0,0,1) with non-zero mean : -10748.55\n",
      " ARIMA(0,0,0) with zero mean     : -8614.882\n",
      " ARIMA(1,0,2) with non-zero mean : -13328.81\n",
      " ARIMA(2,0,1) with non-zero mean : -13325.66\n",
      " ARIMA(3,0,2) with non-zero mean : -13359.55\n",
      " ARIMA(3,0,1) with non-zero mean : -13338.61\n",
      " ARIMA(4,0,2) with non-zero mean : -13350.39\n",
      " ARIMA(3,0,3) with non-zero mean : -13339.44\n",
      " ARIMA(2,0,3) with non-zero mean : -13328.85\n",
      " ARIMA(4,0,1) with non-zero mean : -13346.18\n",
      " ARIMA(4,0,3) with non-zero mean : -13351.1\n",
      " ARIMA(3,0,2) with zero mean     : -13351.9\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -13344.81\n",
      "\n",
      " Best model: ARIMA(4,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13380.83\n",
      " ARIMA(0,0,0) with non-zero mean : -8778.684\n",
      " ARIMA(1,0,0) with non-zero mean : -13373.4\n",
      " ARIMA(0,0,1) with non-zero mean : -10763.15\n",
      " ARIMA(0,0,0) with zero mean     : -8621.15\n",
      " ARIMA(1,0,2) with non-zero mean : -13374.03\n",
      " ARIMA(2,0,1) with non-zero mean : -13379.57\n",
      " ARIMA(3,0,2) with non-zero mean : -13384\n",
      " ARIMA(3,0,1) with non-zero mean : -13385.76\n",
      " ARIMA(3,0,0) with non-zero mean : -13372.9\n",
      " ARIMA(4,0,1) with non-zero mean : -13374.4\n",
      " ARIMA(2,0,0) with non-zero mean : -13370.69\n",
      " ARIMA(4,0,0) with non-zero mean : -13374.31\n",
      " ARIMA(4,0,2) with non-zero mean : -13396.01\n",
      " ARIMA(5,0,2) with non-zero mean : -13400.34\n",
      " ARIMA(5,0,1) with non-zero mean : -13377.97\n",
      " ARIMA(5,0,3) with non-zero mean : -13399.47\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with zero mean     : -13397.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,2) with non-zero mean : -13433.95\n",
      "\n",
      " Best model: ARIMA(5,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13389.44\n",
      " ARIMA(0,0,0) with non-zero mean : -8785.203\n",
      " ARIMA(1,0,0) with non-zero mean : -13383.45\n",
      " ARIMA(0,0,1) with non-zero mean : -10766.55\n",
      " ARIMA(0,0,0) with zero mean     : -8638.774\n",
      " ARIMA(1,0,2) with non-zero mean : -13384.41\n",
      " ARIMA(2,0,1) with non-zero mean : -13386.49\n",
      " ARIMA(3,0,2) with non-zero mean : -13397.52\n",
      " ARIMA(3,0,1) with non-zero mean : -13398.73\n",
      " ARIMA(3,0,0) with non-zero mean : -13387.59\n",
      " ARIMA(4,0,1) with non-zero mean : -13394.72\n",
      " ARIMA(2,0,0) with non-zero mean : -13385.51\n",
      " ARIMA(4,0,0) with non-zero mean : -13385.26\n",
      " ARIMA(4,0,2) with non-zero mean : -13394.06\n",
      " ARIMA(3,0,1) with zero mean     : -13394.67\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -13389.26\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -8817.258\n",
      " ARIMA(1,0,0) with non-zero mean : -13394.02\n",
      " ARIMA(0,0,1) with non-zero mean : -10796.54\n",
      " ARIMA(0,0,0) with zero mean     : -8668.423\n",
      " ARIMA(2,0,0) with non-zero mean : -13393.41\n",
      " ARIMA(1,0,1) with non-zero mean : -13392.02\n",
      " ARIMA(2,0,1) with non-zero mean : -13394.62\n",
      " ARIMA(3,0,1) with non-zero mean : -13399.28\n",
      " ARIMA(3,0,0) with non-zero mean : -13396.73\n",
      " ARIMA(4,0,1) with non-zero mean : -13397.52\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,0) with non-zero mean : -13394.6\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,1) with zero mean     : -13396.56\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -13399.41\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13412.76\n",
      " ARIMA(0,0,0) with non-zero mean : -8835.11\n",
      " ARIMA(1,0,0) with non-zero mean : -13400.98\n",
      " ARIMA(0,0,1) with non-zero mean : -10816.87\n",
      " ARIMA(0,0,0) with zero mean     : -8697.246\n",
      " ARIMA(1,0,2) with non-zero mean : -13402.43\n",
      " ARIMA(2,0,1) with non-zero mean : -13412.29\n",
      " ARIMA(3,0,2) with non-zero mean : -13425.78\n",
      " ARIMA(3,0,1) with non-zero mean : -13408.73\n",
      " ARIMA(4,0,2) with non-zero mean : -13405.3\n",
      " ARIMA(3,0,3) with non-zero mean : -13423.77\n",
      " ARIMA(2,0,3) with non-zero mean : -13411.32\n",
      " ARIMA(4,0,1) with non-zero mean : -13407.09\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -13401.33\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : -13426.43\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13413.99\n",
      " ARIMA(0,0,0) with non-zero mean : -8828.503\n",
      " ARIMA(1,0,0) with non-zero mean : -13410.06\n",
      " ARIMA(0,0,1) with non-zero mean : -10816.85\n",
      " ARIMA(0,0,0) with zero mean     : -8687.243\n",
      " ARIMA(1,0,2) with non-zero mean : -13411.45\n",
      " ARIMA(2,0,1) with non-zero mean : -13412.62\n",
      " ARIMA(3,0,2) with non-zero mean : -13422.23\n",
      " ARIMA(3,0,1) with non-zero mean : -13421.45\n",
      " ARIMA(4,0,2) with non-zero mean : -13418.8\n",
      " ARIMA(3,0,3) with non-zero mean : -13420.35\n",
      " ARIMA(2,0,3) with non-zero mean : -13412.3\n",
      " ARIMA(4,0,1) with non-zero mean : -13420.7\n",
      " ARIMA(4,0,3) with non-zero mean : -13460.7\n",
      " ARIMA(5,0,3) with non-zero mean : -13470.28\n",
      " ARIMA(5,0,2) with non-zero mean : -13454.11\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -13477.53\n",
      " ARIMA(3,0,4) with non-zero mean : -13444.65\n",
      " ARIMA(4,0,5) with non-zero mean : -13473.31\n",
      " ARIMA(3,0,5) with non-zero mean : -13443.48\n",
      " ARIMA(5,0,5) with non-zero mean : -13473.76\n",
      " ARIMA(4,0,4) with zero mean     : -13466.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,4) with non-zero mean : -13490.15\n",
      "\n",
      " Best model: ARIMA(4,0,4) with non-zero mean \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m03.1 <- my.tsCV(train, cv.forecast.2, h=hori, window=wind, step=peri, \n",
    "                        silent=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4247b4e2-a191-4310-9df8-ee11224a71a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-01-24\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m03.1\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3603b7c1-1626-4d08-a2f0-35ea2db6d2db",
   "metadata": {},
   "source": [
    "## Regression with ARIMA errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad1a4e08-fca6-4a5b-b997-cf9d1e3cbe00",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14728.24\n",
      " Regression with ARIMA(0,1,0) errors : -14705.76\n",
      " Regression with ARIMA(1,1,0) errors : -14703.21\n",
      " Regression with ARIMA(0,1,1) errors : -14703.85\n",
      " Regression with ARIMA(0,1,0) errors : -14707.74\n",
      " Regression with ARIMA(1,1,2) errors : -14755.07\n",
      " Regression with ARIMA(0,1,2) errors : -14703.58\n",
      " Regression with ARIMA(1,1,1) errors : -14701.2\n",
      " Regression with ARIMA(1,1,3) errors : -14756.2\n",
      " Regression with ARIMA(0,1,3) errors : -14715.69\n",
      " Regression with ARIMA(2,1,3) errors : -14743.68\n",
      " Regression with ARIMA(1,1,4) errors : -14754.84\n",
      " Regression with ARIMA(0,1,4) errors : -14713.96\n",
      " Regression with ARIMA(2,1,4) errors : -14742.53\n",
      " Regression with ARIMA(1,1,3) errors : -14757.92\n",
      " Regression with ARIMA(0,1,3) errors : -14717.66\n",
      " Regression with ARIMA(1,1,2) errors : -14756.77\n",
      " Regression with ARIMA(2,1,3) errors : -14745.4\n",
      " Regression with ARIMA(1,1,4) errors : -14756.51\n",
      " Regression with ARIMA(0,1,2) errors : -14705.55\n",
      " Regression with ARIMA(0,1,4) errors : -14715.93\n",
      " Regression with ARIMA(2,1,2) errors : -14729.97\n",
      " Regression with ARIMA(2,1,4) errors : -14744.25\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14726.99\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14688.58\n",
      " Regression with ARIMA(1,1,0) errors : -14687.3\n",
      " Regression with ARIMA(0,1,1) errors : -14686.7\n",
      " Regression with ARIMA(0,1,0) errors : -14690.58\n",
      " Regression with ARIMA(1,1,1) errors : -14685.35\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14699.9\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14648.88\n",
      " Regression with ARIMA(1,1,0) errors : -14646.36\n",
      " Regression with ARIMA(0,1,1) errors : -14647.06\n",
      " Regression with ARIMA(0,1,0) errors : -14650.88\n",
      " Regression with ARIMA(1,1,1) errors : -14644.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14660.19\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14557.56\n",
      " Regression with ARIMA(1,1,0) errors : -14555.41\n",
      " Regression with ARIMA(0,1,1) errors : -14555.93\n",
      " Regression with ARIMA(0,1,0) errors : -14559.56\n",
      " Regression with ARIMA(1,1,1) errors : -14553.98\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14568.83\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14466.15\n",
      " Regression with ARIMA(1,1,0) errors : -14464.59\n",
      " Regression with ARIMA(0,1,1) errors : -14465.14\n",
      " Regression with ARIMA(0,1,0) errors : -14468.15\n",
      " Regression with ARIMA(1,1,1) errors : -14463.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14477.38\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14431.62\n",
      " Regression with ARIMA(1,1,0) errors : -14429.42\n",
      " Regression with ARIMA(0,1,1) errors : -14430.5\n",
      " Regression with ARIMA(0,1,0) errors : -14433.63\n",
      " Regression with ARIMA(1,1,1) errors : -14428.06\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14442.84\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14487.01\n",
      " Regression with ARIMA(0,1,0) errors : -14420.66\n",
      " Regression with ARIMA(1,1,0) errors : -14418.52\n",
      " Regression with ARIMA(0,1,1) errors : -14419.3\n",
      " Regression with ARIMA(0,1,0) errors : -14422.67\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14487.4\n",
      " Regression with ARIMA(1,1,1) errors : -14416.73\n",
      " Regression with ARIMA(2,1,0) errors : -14420.92\n",
      " Regression with ARIMA(3,1,1) errors : -14426\n",
      " Regression with ARIMA(3,1,0) errors : -14427.6\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14489.16\n",
      " Regression with ARIMA(1,1,1) errors : -14418.75\n",
      " Regression with ARIMA(2,1,0) errors : -14422.93\n",
      " Regression with ARIMA(3,1,1) errors : -14427.99\n",
      " Regression with ARIMA(2,1,2) errors : -14488.71\n",
      " Regression with ARIMA(1,1,0) errors : -14420.53\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -14429.61\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -14440.44\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14445.76\n",
      " Regression with ARIMA(0,1,0) errors : -14415.25\n",
      " Regression with ARIMA(1,1,0) errors : -14413.72\n",
      " Regression with ARIMA(0,1,1) errors : -14413.85\n",
      " Regression with ARIMA(0,1,0) errors : -14417.26\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14433.81\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14468.58\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14468.82\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14469.94\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14471.73\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14470.6\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14426.46\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14421.25\n",
      " Regression with ARIMA(1,1,0) errors : -14418.78\n",
      " Regression with ARIMA(0,1,1) errors : -14419.77\n",
      " Regression with ARIMA(0,1,0) errors : -14423.26\n",
      " Regression with ARIMA(1,1,1) errors : -14417.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14432.47\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14414.4\n",
      " Regression with ARIMA(1,1,0) errors : -14411.72\n",
      " Regression with ARIMA(0,1,1) errors : -14412.71\n",
      " Regression with ARIMA(0,1,0) errors : -14416.41\n",
      " Regression with ARIMA(1,1,1) errors : -14410.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14425.61\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14371.6\n",
      " Regression with ARIMA(1,1,0) errors : -14369.53\n",
      " Regression with ARIMA(0,1,1) errors : -14370.05\n",
      " Regression with ARIMA(0,1,0) errors : -14373.59\n",
      " Regression with ARIMA(1,1,1) errors : -14368.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14382.78\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14319.68\n",
      " Regression with ARIMA(0,1,0) errors : -14316.26\n",
      " Regression with ARIMA(1,1,0) errors : -14313.77\n",
      " Regression with ARIMA(0,1,1) errors : -14314.65\n",
      " Regression with ARIMA(0,1,0) errors : -14318.23\n",
      " Regression with ARIMA(1,1,2) errors : -14385.93\n",
      " Regression with ARIMA(0,1,2) errors : -14319.04\n",
      " Regression with ARIMA(1,1,1) errors : -14312.24\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14327.45\n",
      " Regression with ARIMA(2,1,1) errors : -14356.37\n",
      " Regression with ARIMA(2,1,3) errors : -14367.96\n",
      " Regression with ARIMA(1,1,2) errors : -14387.45\n",
      " Regression with ARIMA(0,1,2) errors : -14321.01\n",
      " Regression with ARIMA(1,1,1) errors : -14314.22\n",
      " Regression with ARIMA(2,1,2) errors : -14321.64\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(0,1,1) errors : -14316.62\n",
      " Regression with ARIMA(0,1,3) errors : -14329.42\n",
      " Regression with ARIMA(2,1,1) errors : -14358.04\n",
      " Regression with ARIMA(2,1,3) errors : -14369.57\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14338.56\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14254.7\n",
      " Regression with ARIMA(1,1,0) errors : -14252.25\n",
      " Regression with ARIMA(0,1,1) errors : -14252.87\n",
      " Regression with ARIMA(0,1,0) errors : -14256.7\n",
      " Regression with ARIMA(1,1,1) errors : -14250.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14265.84\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14249.15\n",
      " Regression with ARIMA(1,1,0) errors : -14246.58\n",
      " Regression with ARIMA(0,1,1) errors : -14247.46\n",
      " Regression with ARIMA(0,1,0) errors : -14251.14\n",
      " Regression with ARIMA(1,1,1) errors : -14245.11\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14260.28\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14341.48\n",
      " Regression with ARIMA(0,0,0) errors : -10840.14\n",
      " Regression with ARIMA(1,0,0) errors : -14339.73\n",
      " Regression with ARIMA(0,0,1) errors : -12569.99\n",
      " Regression with ARIMA(0,0,0) errors : -9528.814\n",
      " Regression with ARIMA(1,0,2) errors : -14343.89\n",
      " Regression with ARIMA(0,0,2) errors : -13424.35\n",
      " Regression with ARIMA(1,0,1) errors : -14345.89\n",
      " Regression with ARIMA(2,0,1) errors : -14342.88\n",
      " Regression with ARIMA(2,0,0) errors : -14344.83\n",
      " Regression with ARIMA(1,0,1) errors : -14199.07\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14344.44\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14131.23\n",
      " Regression with ARIMA(1,1,0) errors : -14129.6\n",
      " Regression with ARIMA(0,1,1) errors : -14129.22\n",
      " Regression with ARIMA(0,1,0) errors : -14133.21\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14142.29\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14104.7\n",
      " Regression with ARIMA(1,1,0) errors : -14102.15\n",
      " Regression with ARIMA(0,1,1) errors : -14102.72\n",
      " Regression with ARIMA(0,1,0) errors : -14106.71\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14115.78\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14094.76\n",
      " Regression with ARIMA(1,1,0) errors : -14092.35\n",
      " Regression with ARIMA(0,1,1) errors : -14092.76\n",
      " Regression with ARIMA(0,1,0) errors : -14096.76\n",
      " Regression with ARIMA(1,1,1) errors : -14091.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14105.82\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14158.82\n",
      " Regression with ARIMA(0,1,0) errors : -14086.53\n",
      " Regression with ARIMA(1,1,0) errors : -14083.63\n",
      " Regression with ARIMA(0,1,1) errors : -14084.57\n",
      " Regression with ARIMA(0,1,0) errors : -14088.54\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14155.6\n",
      " Regression with ARIMA(3,1,2) errors : -14153.06\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : -14177.73\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14178.44\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14179.86\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14181.4\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14179.99\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14166.32\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14097.6\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14074.57\n",
      " Regression with ARIMA(1,1,0) errors : -14071.57\n",
      " Regression with ARIMA(0,1,1) errors : -14072.57\n",
      " Regression with ARIMA(0,1,0) errors : -14076.57\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14085.63\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14156.68\n",
      " Regression with ARIMA(0,0,0) errors : -10543.02\n",
      " Regression with ARIMA(1,0,0) errors : -14157.58\n",
      " Regression with ARIMA(0,0,1) errors : -12288.52\n",
      " Regression with ARIMA(0,0,0) errors : -9161.948\n",
      " Regression with ARIMA(2,0,0) errors : -14160.85\n",
      " Regression with ARIMA(3,0,0) errors : -14159.41\n",
      " Regression with ARIMA(2,0,1) errors : -14158.76\n",
      " Regression with ARIMA(1,0,1) errors : -14161.58\n",
      " Regression with ARIMA(1,0,2) errors : -14159.57\n",
      " Regression with ARIMA(0,0,2) errors : -13166.06\n",
      " Regression with ARIMA(1,0,1) errors : -14036.84\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14160.49\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14097.59\n",
      " Regression with ARIMA(0,0,0) errors : -10474.05\n",
      " Regression with ARIMA(1,0,0) errors : -14096.1\n",
      " Regression with ARIMA(0,0,1) errors : -12234.47\n",
      " Regression with ARIMA(0,0,0) errors : -9152.683\n",
      " Regression with ARIMA(1,0,2) errors : -14099.35\n",
      " Regression with ARIMA(0,0,2) errors : -13115.29\n",
      " Regression with ARIMA(1,0,1) errors : -14101.37\n",
      " Regression with ARIMA(2,0,1) errors : -14098.29\n",
      " Regression with ARIMA(2,0,0) errors : -14100.36\n",
      " Regression with ARIMA(1,0,1) errors : -13962.68\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14100.49\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13956.34\n",
      " Regression with ARIMA(1,1,0) errors : -13954.24\n",
      " Regression with ARIMA(0,1,1) errors : -13954.58\n",
      " Regression with ARIMA(0,1,0) errors : -13958.35\n",
      " Regression with ARIMA(1,1,1) errors : -13952.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13967.35\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13942.25\n",
      " Regression with ARIMA(1,1,0) errors : -13939.51\n",
      " Regression with ARIMA(0,1,1) errors : -13940.54\n",
      " Regression with ARIMA(0,1,0) errors : -13944.26\n",
      " Regression with ARIMA(1,1,1) errors : -13938.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13953.25\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14057.56\n",
      " Regression with ARIMA(0,0,0) errors : -10451.94\n",
      " Regression with ARIMA(1,0,0) errors : -14055.02\n",
      " Regression with ARIMA(0,0,1) errors : -12212.26\n",
      " Regression with ARIMA(0,0,0) errors : -9125.585\n",
      " Regression with ARIMA(1,0,2) errors : -14059.61\n",
      " Regression with ARIMA(0,0,2) errors : -13092.48\n",
      " Regression with ARIMA(1,0,1) errors : -14061.59\n",
      " Regression with ARIMA(2,0,1) errors : -14058.81\n",
      " Regression with ARIMA(2,0,0) errors : -14060.82\n",
      " Regression with ARIMA(1,0,1) errors : -13926.65\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14060.43\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14049.73\n",
      " Regression with ARIMA(0,0,0) errors : -10463.36\n",
      " Regression with ARIMA(1,0,0) errors : -14047.15\n",
      " Regression with ARIMA(0,0,1) errors : -12215.94\n",
      " Regression with ARIMA(0,0,0) errors : -9113.651\n",
      " Regression with ARIMA(1,0,2) errors : -14050.93\n",
      " Regression with ARIMA(0,0,2) errors : -13088.83\n",
      " Regression with ARIMA(1,0,1) errors : -14052.85\n",
      " Regression with ARIMA(2,0,1) errors : -14049.93\n",
      " Regression with ARIMA(2,0,0) errors : -14051.82\n",
      " Regression with ARIMA(1,0,1) errors : -13912.48\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14051.09\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13911.02\n",
      " Regression with ARIMA(1,1,0) errors : -13908.48\n",
      " Regression with ARIMA(0,1,1) errors : -13909.2\n",
      " Regression with ARIMA(0,1,0) errors : -13913.03\n",
      " Regression with ARIMA(1,1,1) errors : -13907.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13922.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13900.07\n",
      " Regression with ARIMA(1,1,0) errors : -13897.25\n",
      " Regression with ARIMA(0,1,1) errors : -13898.14\n",
      " Regression with ARIMA(0,1,0) errors : -13902.07\n",
      " Regression with ARIMA(1,1,1) errors : -13896.05\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13911.05\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13876.42\n",
      " Regression with ARIMA(0,1,0) errors : -13873.69\n",
      " Regression with ARIMA(1,1,0) errors : -13870.8\n",
      " Regression with ARIMA(0,1,1) errors : -13871.79\n",
      " Regression with ARIMA(0,1,0) errors : -13875.69\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -13951.7\n",
      " Regression with ARIMA(1,1,1) errors : -13869.75\n",
      " Regression with ARIMA(2,1,0) errors : -13877.74\n",
      " Regression with ARIMA(3,1,1) errors : -13879.69\n",
      " Regression with ARIMA(3,1,0) errors : -13878.26\n",
      " Regression with ARIMA(3,1,2) errors : -13880.96\n",
      " Regression with ARIMA(2,1,1) errors : -13953.47\n",
      " Regression with ARIMA(1,1,1) errors : -13871.73\n",
      " Regression with ARIMA(2,1,0) errors : -13879.75\n",
      " Regression with ARIMA(3,1,1) errors : -13881.7\n",
      " Regression with ARIMA(2,1,2) errors : -13878.44\n",
      " Regression with ARIMA(1,1,0) errors : -13872.8\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -13880.27\n",
      " Regression with ARIMA(3,1,2) errors : -13883\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -13906.38\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13861.23\n",
      " Regression with ARIMA(1,1,0) errors : -13858.29\n",
      " Regression with ARIMA(0,1,1) errors : -13859.25\n",
      " Regression with ARIMA(0,1,0) errors : -13863.23\n",
      " Regression with ARIMA(1,1,1) errors : -13857.3\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13872.19\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13896.9\n",
      " Regression with ARIMA(0,0,0) errors : -10196.26\n",
      " Regression with ARIMA(1,0,0) errors : -13893.1\n",
      " Regression with ARIMA(0,0,1) errors : -11966.99\n",
      " Regression with ARIMA(0,0,0) errors : -8742.913\n",
      " Regression with ARIMA(1,0,2) errors : -13897.42\n",
      " Regression with ARIMA(0,0,2) errors : -12878.36\n",
      " Regression with ARIMA(1,0,1) errors : -13899.18\n",
      " Regression with ARIMA(2,0,1) errors : -13896.32\n",
      " Regression with ARIMA(2,0,0) errors : -13897.97\n",
      " Regression with ARIMA(1,0,1) errors : -13775.62\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13898.36\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13779.66\n",
      " Regression with ARIMA(0,0,0) errors : -10097.98\n",
      " Regression with ARIMA(1,0,0) errors : -13771.91\n",
      " Regression with ARIMA(0,0,1) errors : -11865.72\n",
      " Regression with ARIMA(0,0,0) errors : -8710.896\n",
      " Regression with ARIMA(1,0,2) errors : -13777.93\n",
      " Regression with ARIMA(2,0,1) errors : -13777.15\n",
      " Regression with ARIMA(3,0,2) errors : -13783.79\n",
      " Regression with ARIMA(3,0,1) errors : -13778.18\n",
      " Regression with ARIMA(4,0,2) errors : -13782.79\n",
      " Regression with ARIMA(3,0,3) errors : -13790.74\n",
      " Regression with ARIMA(2,0,3) errors : -13778.27\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13781.06\n",
      " Regression with ARIMA(2,0,4) errors : -13781.18\n",
      " Regression with ARIMA(4,0,4) errors : -13783.64\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,3) errors : -13791.61\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13736.94\n",
      " Regression with ARIMA(0,0,0) errors : -10002.66\n",
      " Regression with ARIMA(1,0,0) errors : -13730.41\n",
      " Regression with ARIMA(0,0,1) errors : -11778.89\n",
      " Regression with ARIMA(0,0,0) errors : -8620.765\n",
      " Regression with ARIMA(1,0,2) errors : -13736.26\n",
      " Regression with ARIMA(2,0,1) errors : -13735.25\n",
      " Regression with ARIMA(3,0,2) errors : -13738.48\n",
      " Regression with ARIMA(3,0,1) errors : -13735.53\n",
      " Regression with ARIMA(4,0,2) errors : -13732.51\n",
      " Regression with ARIMA(3,0,3) errors : -13747.21\n",
      " Regression with ARIMA(2,0,3) errors : -13735.02\n",
      " Regression with ARIMA(4,0,3) errors : -13743.42\n",
      " Regression with ARIMA(3,0,4) errors : -13736.01\n",
      " Regression with ARIMA(2,0,4) errors : -13737.88\n",
      " Regression with ARIMA(4,0,4) errors : -13742.31\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,3) errors : -13748.29\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13671.5\n",
      " Regression with ARIMA(0,0,0) errors : -9894.943\n",
      " Regression with ARIMA(1,0,0) errors : -13665.86\n",
      " Regression with ARIMA(0,0,1) errors : -11694.71\n",
      " Regression with ARIMA(0,0,0) errors : -8560.227\n",
      " Regression with ARIMA(1,0,2) errors : -13672.38\n",
      " Regression with ARIMA(0,0,2) errors : -12612.9\n",
      " Regression with ARIMA(1,0,1) errors : -13674.2\n",
      " Regression with ARIMA(2,0,1) errors : -13671.58\n",
      " Regression with ARIMA(2,0,0) errors : -13673.48\n",
      " Regression with ARIMA(1,0,1) errors : -13559.42\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13673.28\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13629.1\n",
      " Regression with ARIMA(0,0,0) errors : -9878.792\n",
      " Regression with ARIMA(1,0,0) errors : -13624.85\n",
      " Regression with ARIMA(0,0,1) errors : -11666.73\n",
      " Regression with ARIMA(0,0,0) errors : -8556.701\n",
      " Regression with ARIMA(1,0,2) errors : -13629.96\n",
      " Regression with ARIMA(0,0,2) errors : -12579.75\n",
      " Regression with ARIMA(1,0,1) errors : -13631.19\n",
      " Regression with ARIMA(2,0,1) errors : -13629.28\n",
      " Regression with ARIMA(2,0,0) errors : -13630.88\n",
      " Regression with ARIMA(1,0,1) errors : -13512.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13630.37\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13611.31\n",
      " Regression with ARIMA(0,0,0) errors : -9870.771\n",
      " Regression with ARIMA(1,0,0) errors : -13607.01\n",
      " Regression with ARIMA(0,0,1) errors : -11652.28\n",
      " Regression with ARIMA(0,0,0) errors : -8549.922\n",
      " Regression with ARIMA(1,0,2) errors : -13611.78\n",
      " Regression with ARIMA(0,0,2) errors : -12567.48\n",
      " Regression with ARIMA(1,0,1) errors : -13612.86\n",
      " Regression with ARIMA(2,0,1) errors : -13620.17\n",
      " Regression with ARIMA(2,0,0) errors : -13612.21\n",
      " Regression with ARIMA(3,0,1) errors : -13610.14\n",
      " Regression with ARIMA(3,0,0) errors : -13609.99\n",
      " Regression with ARIMA(3,0,2) errors : -13609.53\n",
      " Regression with ARIMA(2,0,1) errors : -13511.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13612.06\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13585.71\n",
      " Regression with ARIMA(0,0,0) errors : -9844.615\n",
      " Regression with ARIMA(1,0,0) errors : -13581.02\n",
      " Regression with ARIMA(0,0,1) errors : -11622.06\n",
      " Regression with ARIMA(0,0,0) errors : -8510.432\n",
      " Regression with ARIMA(1,0,2) errors : -13586.32\n",
      " Regression with ARIMA(0,0,2) errors : -12543.41\n",
      " Regression with ARIMA(1,0,1) errors : -13587.02\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -13586.54\n",
      " Regression with ARIMA(1,0,1) errors : -13475.64\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13585.99\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13574.71\n",
      " Regression with ARIMA(0,0,0) errors : -9826.549\n",
      " Regression with ARIMA(1,0,0) errors : -13570.27\n",
      " Regression with ARIMA(0,0,1) errors : -11609.5\n",
      " Regression with ARIMA(0,0,0) errors : -8481.914\n",
      " Regression with ARIMA(1,0,2) errors : -13575.26\n",
      " Regression with ARIMA(0,0,2) errors : -12534.01\n",
      " Regression with ARIMA(1,0,1) errors : -13576.15\n",
      " Regression with ARIMA(2,0,1) errors : -13583.87\n",
      " Regression with ARIMA(2,0,0) errors : -13575.76\n",
      " Regression with ARIMA(3,0,1) errors : -13573.56\n",
      " Regression with ARIMA(3,0,0) errors : -13574.15\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13575.33\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13420.85\n",
      " Regression with ARIMA(1,1,0) errors : -13418.28\n",
      " Regression with ARIMA(0,1,1) errors : -13419.05\n",
      " Regression with ARIMA(0,1,0) errors : -13422.86\n",
      " Regression with ARIMA(1,1,1) errors : -13416.27\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13431.63\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13406.54\n",
      " Regression with ARIMA(1,1,0) errors : -13403.97\n",
      " Regression with ARIMA(0,1,1) errors : -13404.69\n",
      " Regression with ARIMA(0,1,0) errors : -13408.55\n",
      " Regression with ARIMA(1,1,1) errors : -13401.96\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13417.31\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13398.85\n",
      " Regression with ARIMA(1,1,0) errors : -13397.03\n",
      " Regression with ARIMA(0,1,1) errors : -13396.96\n",
      " Regression with ARIMA(0,1,0) errors : -13400.86\n",
      " Regression with ARIMA(1,1,1) errors : -13395.03\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13409.61\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13388.05\n",
      " Regression with ARIMA(1,1,0) errors : -13385.34\n",
      " Regression with ARIMA(0,1,1) errors : -13386.18\n",
      " Regression with ARIMA(0,1,0) errors : -13390.05\n",
      " Regression with ARIMA(1,1,1) errors : -13383.59\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13398.81\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13385.45\n",
      " Regression with ARIMA(1,1,0) errors : -13382.92\n",
      " Regression with ARIMA(0,1,1) errors : -13383.57\n",
      " Regression with ARIMA(0,1,0) errors : -13387.46\n",
      " Regression with ARIMA(1,1,1) errors : -13380.91\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13396.21\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13381.56\n",
      " Regression with ARIMA(1,1,0) errors : -13380.11\n",
      " Regression with ARIMA(0,1,1) errors : -13379.6\n",
      " Regression with ARIMA(0,1,0) errors : -13383.57\n",
      " Regression with ARIMA(1,1,1) errors : -13378.27\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13392.32\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13382.25\n",
      " Regression with ARIMA(1,1,0) errors : -13380.87\n",
      " Regression with ARIMA(0,1,1) errors : -13380.28\n",
      " Regression with ARIMA(0,1,0) errors : -13384.26\n",
      " Regression with ARIMA(1,1,1) errors : -13379.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13393.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13380.14\n",
      " Regression with ARIMA(1,1,0) errors : -13377.47\n",
      " Regression with ARIMA(0,1,1) errors : -13378.15\n",
      " Regression with ARIMA(0,1,0) errors : -13382.15\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.9\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13378.91\n",
      " Regression with ARIMA(1,1,0) errors : -13377.73\n",
      " Regression with ARIMA(0,1,1) errors : -13376.9\n",
      " Regression with ARIMA(0,1,0) errors : -13380.91\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13389.66\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13379.35\n",
      " Regression with ARIMA(1,1,0) errors : -13377.78\n",
      " Regression with ARIMA(0,1,1) errors : -13377.34\n",
      " Regression with ARIMA(0,1,0) errors : -13381.35\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.1\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13379.9\n",
      " Regression with ARIMA(1,1,0) errors : -13377.2\n",
      " Regression with ARIMA(0,1,1) errors : -13377.89\n",
      " Regression with ARIMA(0,1,0) errors : -13381.91\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.66\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13381.25\n",
      " Regression with ARIMA(1,1,0) errors : -13378.41\n",
      " Regression with ARIMA(0,1,1) errors : -13379.25\n",
      " Regression with ARIMA(0,1,0) errors : -13383.26\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13392.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13376.01\n",
      " Regression with ARIMA(1,1,0) errors : -13373.65\n",
      " Regression with ARIMA(0,1,1) errors : -13374\n",
      " Regression with ARIMA(0,1,0) errors : -13378.02\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13386.77\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13369.58\n",
      " Regression with ARIMA(1,1,0) errors : -13366.83\n",
      " Regression with ARIMA(0,1,1) errors : -13367.57\n",
      " Regression with ARIMA(0,1,0) errors : -13371.59\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13380.33\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13497.89\n",
      " Regression with ARIMA(0,0,0) errors : -9950.123\n",
      " Regression with ARIMA(1,0,0) errors : -13493.27\n",
      " Regression with ARIMA(0,0,1) errors : -11642.05\n",
      " Regression with ARIMA(0,0,0) errors : -8458.864\n",
      " Regression with ARIMA(1,0,2) errors : -13494.53\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -13496.04\n",
      " Regression with ARIMA(1,0,1) errors : -13495.7\n",
      " Regression with ARIMA(1,0,3) errors : -13492.7\n",
      " Regression with ARIMA(3,0,1) errors : -13497.36\n",
      " Regression with ARIMA(3,0,3) errors : -13498.01\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13507.72\n",
      " Regression with ARIMA(2,0,4) errors : -13500.47\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13500.7\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13506.03\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13499.98\n",
      " Regression with ARIMA(0,0,0) errors : -9960.775\n",
      " Regression with ARIMA(1,0,0) errors : -13495.47\n",
      " Regression with ARIMA(0,0,1) errors : -11645.81\n",
      " Regression with ARIMA(0,0,0) errors : -8453.629\n",
      " Regression with ARIMA(1,0,2) errors : -13496.49\n",
      " Regression with ARIMA(2,0,1) errors : -13507.19\n",
      " Regression with ARIMA(1,0,1) errors : -13497.52\n",
      " Regression with ARIMA(2,0,0) errors : -13496.74\n",
      " Regression with ARIMA(3,0,1) errors : -13497.31\n",
      " Regression with ARIMA(3,0,0) errors : -13495.2\n",
      " Regression with ARIMA(3,0,2) errors : -13495.71\n",
      " Regression with ARIMA(2,0,1) errors : -13378.82\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13506.74\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13497.77\n",
      " Regression with ARIMA(0,0,0) errors : -9958.269\n",
      " Regression with ARIMA(1,0,0) errors : -13494.31\n",
      " Regression with ARIMA(0,0,1) errors : -11644.45\n",
      " Regression with ARIMA(0,0,0) errors : -8449.905\n",
      " Regression with ARIMA(1,0,2) errors : -13495.3\n",
      " Regression with ARIMA(2,0,1) errors : -13507.9\n",
      " Regression with ARIMA(1,0,1) errors : -13496.33\n",
      " Regression with ARIMA(2,0,0) errors : -13495.6\n",
      " Regression with ARIMA(3,0,1) errors : -13496.54\n",
      " Regression with ARIMA(3,0,0) errors : -13493.75\n",
      " Regression with ARIMA(3,0,2) errors : -13495.71\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13508.08\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13493.96\n",
      " Regression with ARIMA(0,0,0) errors : -9977.205\n",
      " Regression with ARIMA(1,0,0) errors : -13489.97\n",
      " Regression with ARIMA(0,0,1) errors : -11647.24\n",
      " Regression with ARIMA(0,0,0) errors : -8450.876\n",
      " Regression with ARIMA(1,0,2) errors : -13490.98\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13488.95\n",
      " Regression with ARIMA(2,0,3) errors : -13487.5\n",
      " Regression with ARIMA(1,0,1) errors : -13492.01\n",
      " Regression with ARIMA(1,0,3) errors : -13489.23\n",
      " Regression with ARIMA(3,0,1) errors : -13492.37\n",
      " Regression with ARIMA(3,0,3) errors : -13486.94\n",
      " Regression with ARIMA(2,0,2) errors : -13356.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.62\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.03\n",
      " Regression with ARIMA(0,0,0) errors : -10035.28\n",
      " Regression with ARIMA(1,0,0) errors : -13487.39\n",
      " Regression with ARIMA(0,0,1) errors : -11673.35\n",
      " Regression with ARIMA(0,0,0) errors : -8457.324\n",
      " Regression with ARIMA(1,0,2) errors : -13488\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13489.24\n",
      " Regression with ARIMA(2,0,3) errors : -13489.21\n",
      " Regression with ARIMA(1,0,1) errors : -13488.93\n",
      " Regression with ARIMA(1,0,3) errors : -13486.24\n",
      " Regression with ARIMA(3,0,1) errors : -13491.09\n",
      " Regression with ARIMA(3,0,0) errors : -13487.21\n",
      " Regression with ARIMA(4,0,1) errors : -13487.57\n",
      " Regression with ARIMA(2,0,0) errors : -13488.97\n",
      " Regression with ARIMA(4,0,0) errors : -13485.19\n",
      " Regression with ARIMA(4,0,2) errors : -13498.14\n",
      " Regression with ARIMA(5,0,2) errors : -13499.05\n",
      " Regression with ARIMA(5,0,1) errors : -13492.88\n",
      " Regression with ARIMA(5,0,3) errors : -13497.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13501.63\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.2\n",
      " Regression with ARIMA(0,0,0) errors : -10019.33\n",
      " Regression with ARIMA(1,0,0) errors : -13487.57\n",
      " Regression with ARIMA(0,0,1) errors : -11667.27\n",
      " Regression with ARIMA(0,0,0) errors : -8455.887\n",
      " Regression with ARIMA(1,0,2) errors : -13488.56\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13489.44\n",
      " Regression with ARIMA(2,0,3) errors : -13490.16\n",
      " Regression with ARIMA(1,0,1) errors : -13489.31\n",
      " Regression with ARIMA(1,0,3) errors : -13486.85\n",
      " Regression with ARIMA(3,0,1) errors : -13491.32\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13350.82\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.68\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13489.2\n",
      " Regression with ARIMA(0,0,0) errors : -10028.88\n",
      " Regression with ARIMA(1,0,0) errors : -13485\n",
      " Regression with ARIMA(0,0,1) errors : -11673.96\n",
      " Regression with ARIMA(0,0,0) errors : -8443.256\n",
      " Regression with ARIMA(1,0,2) errors : -13486.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -13487.2\n",
      " Regression with ARIMA(1,0,1) errors : -13487.01\n",
      " Regression with ARIMA(1,0,3) errors : -13484.63\n",
      " Regression with ARIMA(3,0,1) errors : -13491.48\n",
      " Regression with ARIMA(3,0,0) errors : -13487\n",
      " Regression with ARIMA(4,0,1) errors : -13489.1\n",
      " Regression with ARIMA(2,0,0) errors : -13486.23\n",
      " Regression with ARIMA(4,0,0) errors : -13484.88\n",
      " Regression with ARIMA(4,0,2) errors : -13500.18\n",
      " Regression with ARIMA(5,0,2) errors : -13502.09\n",
      " Regression with ARIMA(5,0,1) errors : -13494.32\n",
      " Regression with ARIMA(5,0,3) errors : -13500.12\n",
      " Regression with ARIMA(4,0,3) errors : -13500.55\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13500.88\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492\n",
      " Regression with ARIMA(0,0,0) errors : -10028.08\n",
      " Regression with ARIMA(1,0,0) errors : -13487.35\n",
      " Regression with ARIMA(0,0,1) errors : -11679.14\n",
      " Regression with ARIMA(0,0,0) errors : -8442.705\n",
      " Regression with ARIMA(1,0,2) errors : -13488.66\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13487.58\n",
      " Regression with ARIMA(2,0,3) errors : -13489.99\n",
      " Regression with ARIMA(1,0,1) errors : -13489.51\n",
      " Regression with ARIMA(1,0,3) errors : -13487.09\n",
      " Regression with ARIMA(3,0,1) errors : -13489.86\n",
      " Regression with ARIMA(3,0,3) errors : -13482.34\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.71\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13496.48\n",
      " Regression with ARIMA(0,0,0) errors : -10046.87\n",
      " Regression with ARIMA(1,0,0) errors : -13491.11\n",
      " Regression with ARIMA(0,0,1) errors : -11686.59\n",
      " Regression with ARIMA(0,0,0) errors : -8439.819\n",
      " Regression with ARIMA(1,0,2) errors : -13492.36\n",
      " Regression with ARIMA(2,0,1) errors : -13506.72\n",
      " Regression with ARIMA(1,0,1) errors : -13493.26\n",
      " Regression with ARIMA(2,0,0) errors : -13492.87\n",
      " Regression with ARIMA(3,0,1) errors : -13494.79\n",
      " Regression with ARIMA(3,0,0) errors : -13491.08\n",
      " Regression with ARIMA(3,0,2) errors : -13506.27\n",
      " Regression with ARIMA(2,0,1) errors : -13358.47\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13505.42\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.02\n",
      " Regression with ARIMA(0,0,0) errors : -10051.63\n",
      " Regression with ARIMA(1,0,0) errors : -13487.72\n",
      " Regression with ARIMA(0,0,1) errors : -11688.79\n",
      " Regression with ARIMA(0,0,0) errors : -8460.12\n",
      " Regression with ARIMA(1,0,2) errors : -13489\n",
      " Regression with ARIMA(2,0,1) errors : -13501\n",
      " Regression with ARIMA(1,0,1) errors : -13489.93\n",
      " Regression with ARIMA(2,0,0) errors : -13489.16\n",
      " Regression with ARIMA(3,0,1) errors : -13490.72\n",
      " Regression with ARIMA(3,0,0) errors : -13487.43\n",
      " Regression with ARIMA(3,0,2) errors : -13488.68\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13501.14\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13500.43\n",
      " Regression with ARIMA(0,0,0) errors : -10047.97\n",
      " Regression with ARIMA(1,0,0) errors : -13495.4\n",
      " Regression with ARIMA(0,0,1) errors : -11686.73\n",
      " Regression with ARIMA(0,0,0) errors : -8459.472\n",
      " Regression with ARIMA(1,0,2) errors : -13496.66\n",
      " Regression with ARIMA(2,0,1) errors : -13510.38\n",
      " Regression with ARIMA(1,0,1) errors : -13497.58\n",
      " Regression with ARIMA(2,0,0) errors : -13497.07\n",
      " Regression with ARIMA(3,0,1) errors : -13498.19\n",
      " Regression with ARIMA(3,0,0) errors : -13495.29\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13509.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10051.61\n",
      " Regression with ARIMA(1,0,0) errors : -13499.36\n",
      " Regression with ARIMA(0,0,1) errors : -11694.33\n",
      " Regression with ARIMA(0,0,0) errors : -8454.72\n",
      " Regression with ARIMA(2,0,0) errors : -13501.93\n",
      " Regression with ARIMA(3,0,0) errors : -13500.22\n",
      " Regression with ARIMA(2,0,1) errors : -13512.21\n",
      " Regression with ARIMA(1,0,1) errors : -13501.76\n",
      " Regression with ARIMA(3,0,1) errors : -13503.01\n",
      " Regression with ARIMA(1,0,2) errors : -13500.7\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13514.04\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13505.3\n",
      " Regression with ARIMA(0,0,0) errors : -10067.87\n",
      " Regression with ARIMA(1,0,0) errors : -13500.56\n",
      " Regression with ARIMA(0,0,1) errors : -11703.92\n",
      " Regression with ARIMA(0,0,0) errors : -8459.352\n",
      " Regression with ARIMA(1,0,2) errors : -13501.48\n",
      " Regression with ARIMA(2,0,1) errors : -13513.92\n",
      " Regression with ARIMA(1,0,1) errors : -13502.47\n",
      " Regression with ARIMA(2,0,0) errors : -13501.76\n",
      " Regression with ARIMA(3,0,1) errors : -13504.22\n",
      " Regression with ARIMA(3,0,0) errors : -13499.98\n",
      " Regression with ARIMA(3,0,2) errors : -13502.51\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13509.66\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13504.43\n",
      " Regression with ARIMA(0,0,0) errors : -10066.73\n",
      " Regression with ARIMA(1,0,0) errors : -13500.34\n",
      " Regression with ARIMA(0,0,1) errors : -11703.9\n",
      " Regression with ARIMA(0,0,0) errors : -8459.982\n",
      " Regression with ARIMA(1,0,2) errors : -13501.46\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13502.1\n",
      " Regression with ARIMA(2,0,3) errors : -13502.47\n",
      " Regression with ARIMA(1,0,1) errors : -13502.43\n",
      " Regression with ARIMA(1,0,3) errors : -13499.75\n",
      " Regression with ARIMA(3,0,1) errors : -13504.38\n",
      " Regression with ARIMA(3,0,3) errors : -13511.67\n",
      " Regression with ARIMA(4,0,3) errors : -13502.32\n",
      " Regression with ARIMA(3,0,4) errors : -13513.38\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -13510.29\n",
      " Regression with ARIMA(3,0,5) errors : -13505.27\n",
      " Regression with ARIMA(2,0,5) errors : -13506.32\n",
      " Regression with ARIMA(4,0,5) errors : -13507.77\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13512.15\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13504.84\n",
      " Regression with ARIMA(0,0,0) errors : -10082.23\n",
      " Regression with ARIMA(1,0,0) errors : -13499.69\n",
      " Regression with ARIMA(0,0,1) errors : -11711.37\n",
      " Regression with ARIMA(0,0,0) errors : -8482.428\n",
      " Regression with ARIMA(1,0,2) errors : -13500.44\n",
      " Regression with ARIMA(2,0,1) errors : -13506.21\n",
      " Regression with ARIMA(1,0,1) errors : -13501.67\n",
      " Regression with ARIMA(2,0,0) errors : -13507.48\n",
      " Regression with ARIMA(3,0,0) errors : -13505.43\n",
      " Regression with ARIMA(3,0,1) errors : -13508.06\n",
      " Regression with ARIMA(4,0,1) errors : -13504.51\n",
      " Regression with ARIMA(3,0,2) errors : -13507\n",
      " Regression with ARIMA(4,0,0) errors : -13503.26\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -13503.39\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13511.77\n",
      " Regression with ARIMA(0,0,0) errors : -10089.38\n",
      " Regression with ARIMA(1,0,0) errors : -13508.45\n",
      " Regression with ARIMA(0,0,1) errors : -11717.82\n",
      " Regression with ARIMA(0,0,0) errors : -8486.146\n",
      " Regression with ARIMA(1,0,2) errors : -13508.73\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13508.14\n",
      " Regression with ARIMA(2,0,3) errors : -13509.84\n",
      " Regression with ARIMA(1,0,1) errors : -13509.99\n",
      " Regression with ARIMA(1,0,3) errors : -13507.09\n",
      " Regression with ARIMA(3,0,1) errors : -13509.92\n",
      " Regression with ARIMA(3,0,3) errors : -13517.49\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13519.73\n",
      " Regression with ARIMA(2,0,4) errors : -13513.32\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13514.28\n",
      " Regression with ARIMA(4,0,5) errors : -13514.96\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13520.01\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13510.51\n",
      " Regression with ARIMA(0,0,0) errors : -10105.18\n",
      " Regression with ARIMA(1,0,0) errors : -13507.88\n",
      " Regression with ARIMA(0,0,1) errors : -11721.86\n",
      " Regression with ARIMA(0,0,0) errors : -8493.114\n",
      " Regression with ARIMA(1,0,2) errors : -13508.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13516.56\n",
      " Regression with ARIMA(3,0,1) errors : -13506.85\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13515.63\n",
      " Regression with ARIMA(2,0,3) errors : -13508.55\n",
      " Regression with ARIMA(4,0,1) errors : -13509.07\n",
      " Regression with ARIMA(4,0,3) errors : -13513.32\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13519.6\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13508.31\n",
      " Regression with ARIMA(0,0,0) errors : -10126.55\n",
      " Regression with ARIMA(1,0,0) errors : -13507.44\n",
      " Regression with ARIMA(0,0,1) errors : -11732.75\n",
      " Regression with ARIMA(0,0,0) errors : -8479.726\n",
      " Regression with ARIMA(1,0,2) errors : -13507.67\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13508.26\n",
      " Regression with ARIMA(2,0,3) errors : -13506.52\n",
      " Regression with ARIMA(1,0,1) errors : -13508.92\n",
      " Regression with ARIMA(0,0,2) errors : -12538.44\n",
      " Regression with ARIMA(2,0,0) errors : -13508.97\n",
      " Regression with ARIMA(3,0,0) errors : -13506.81\n",
      " Regression with ARIMA(3,0,1) errors : -13510.29\n",
      " Regression with ARIMA(4,0,1) errors : -13507.38\n",
      " Regression with ARIMA(4,0,0) errors : -13504.51\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -13510.44\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10215.23\n",
      " Regression with ARIMA(1,0,0) errors : -13503.24\n",
      " Regression with ARIMA(0,0,1) errors : -11765.85\n",
      " Regression with ARIMA(0,0,0) errors : -8496.584\n",
      " Regression with ARIMA(2,0,0) errors : -13503.84\n",
      " Regression with ARIMA(3,0,0) errors : -13502.9\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13504.35\n",
      " Regression with ARIMA(1,0,2) errors : -13503.03\n",
      " Regression with ARIMA(0,0,2) errors : -12548.3\n",
      " Regression with ARIMA(1,0,1) errors : -13380.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13503.51\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10218.34\n",
      " Regression with ARIMA(1,0,0) errors : -13503.41\n",
      " Regression with ARIMA(0,0,1) errors : -11768.16\n",
      " Regression with ARIMA(0,0,0) errors : -8499.03\n",
      " Regression with ARIMA(2,0,0) errors : -13503.77\n",
      " Regression with ARIMA(3,0,0) errors : -13502.7\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13504.25\n",
      " Regression with ARIMA(1,0,2) errors : -13502.87\n",
      " Regression with ARIMA(0,0,2) errors : -12542.4\n",
      " Regression with ARIMA(1,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13503.42\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13509.32\n",
      " Regression with ARIMA(0,0,0) errors : -10219.25\n",
      " Regression with ARIMA(1,0,0) errors : -13507.76\n",
      " Regression with ARIMA(0,0,1) errors : -11765.04\n",
      " Regression with ARIMA(0,0,0) errors : -8502.109\n",
      " Regression with ARIMA(1,0,2) errors : -13506.99\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13502.83\n",
      " Regression with ARIMA(2,0,3) errors : -13507.36\n",
      " Regression with ARIMA(1,0,1) errors : -13508.29\n",
      " Regression with ARIMA(1,0,3) errors : -13505.45\n",
      " Regression with ARIMA(3,0,1) errors : -13506.88\n",
      " Regression with ARIMA(3,0,3) errors : -13513.93\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13514.85\n",
      " Regression with ARIMA(2,0,4) errors : -13509.02\n",
      " Regression with ARIMA(4,0,4) errors : -13512.96\n",
      " Regression with ARIMA(3,0,5) errors : -13508.01\n",
      " Regression with ARIMA(2,0,5) errors : -13510.83\n",
      " Regression with ARIMA(4,0,5) errors : -13505.08\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13517.28\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10222.58\n",
      " Regression with ARIMA(1,0,0) errors : -13506.49\n",
      " Regression with ARIMA(0,0,1) errors : -11761.77\n",
      " Regression with ARIMA(0,0,0) errors : -8501.931\n",
      " Regression with ARIMA(2,0,0) errors : -13505.83\n",
      " Regression with ARIMA(1,0,1) errors : -13506.71\n",
      " Regression with ARIMA(2,0,1) errors : -13516.88\n",
      " Regression with ARIMA(3,0,1) errors : -13512.26\n",
      " Regression with ARIMA(1,0,2) errors : -13505.56\n",
      " Regression with ARIMA(3,0,0) errors : -13505.02\n",
      " Regression with ARIMA(3,0,2) errors : -13499.27\n",
      " Regression with ARIMA(2,0,1) errors : -13367.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13503.41\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13512.51\n",
      " Regression with ARIMA(0,0,0) errors : -10227.27\n",
      " Regression with ARIMA(1,0,0) errors : -13513.98\n",
      " Regression with ARIMA(0,0,1) errors : -11762.97\n",
      " Regression with ARIMA(0,0,0) errors : -8502.27\n",
      " Regression with ARIMA(2,0,0) errors : -13514.25\n",
      " Regression with ARIMA(3,0,0) errors : -13513.04\n",
      " Regression with ARIMA(2,0,1) errors : -13512.24\n",
      " Regression with ARIMA(1,0,1) errors : -13514.02\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -13380.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,0) errors : -13511.98\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13526.34\n",
      " Regression with ARIMA(0,0,0) errors : -10223.66\n",
      " Regression with ARIMA(1,0,0) errors : -13526.45\n",
      " Regression with ARIMA(0,0,1) errors : -11757.01\n",
      " Regression with ARIMA(0,0,0) errors : -8519.276\n",
      " Regression with ARIMA(2,0,0) errors : -13525.32\n",
      " Regression with ARIMA(1,0,1) errors : -13526.23\n",
      " Regression with ARIMA(2,0,1) errors : -13535.26\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13525.01\n",
      " Regression with ARIMA(3,0,0) errors : -13523.41\n",
      " Regression with ARIMA(3,0,2) errors : -13520.69\n",
      " Regression with ARIMA(2,0,1) errors : -13408.03\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13521.31\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10227.11\n",
      " Regression with ARIMA(1,0,0) errors : -13535.83\n",
      " Regression with ARIMA(0,0,1) errors : -11776.31\n",
      " Regression with ARIMA(0,0,0) errors : -8558.409\n",
      " Regression with ARIMA(2,0,0) errors : -13535.04\n",
      " Regression with ARIMA(1,0,1) errors : -13535.63\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13535.07\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10239.17\n",
      " Regression with ARIMA(1,0,0) errors : -13532.83\n",
      " Regression with ARIMA(0,0,1) errors : -11782.72\n",
      " Regression with ARIMA(0,0,0) errors : -8566.374\n",
      " Regression with ARIMA(2,0,0) errors : -13533.02\n",
      " Regression with ARIMA(3,0,0) errors : -13531.58\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13532.77\n",
      " Regression with ARIMA(3,0,1) errors : -13532.73\n",
      " Regression with ARIMA(2,0,0) errors : -13415.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,0) errors : -13531.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13539.55\n",
      " Regression with ARIMA(0,0,0) errors : -10238.93\n",
      " Regression with ARIMA(1,0,0) errors : -13540.07\n",
      " Regression with ARIMA(0,0,1) errors : -11784.97\n",
      " Regression with ARIMA(0,0,0) errors : -8571.174\n",
      " Regression with ARIMA(2,0,0) errors : -13539.5\n",
      " Regression with ARIMA(1,0,1) errors : -13540.16\n",
      " Regression with ARIMA(2,0,1) errors : -13549.2\n",
      " Regression with ARIMA(3,0,1) errors : -13539.61\n",
      " Regression with ARIMA(1,0,2) errors : -13539.06\n",
      " Regression with ARIMA(3,0,0) errors : -13537.64\n",
      " Regression with ARIMA(3,0,2) errors : -13537.96\n",
      " Regression with ARIMA(2,0,1) errors : -13400.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13550.1\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13537.09\n",
      " Regression with ARIMA(0,0,0) errors : -10239.99\n",
      " Regression with ARIMA(1,0,0) errors : -13540.98\n",
      " Regression with ARIMA(0,0,1) errors : -11788.21\n",
      " Regression with ARIMA(0,0,0) errors : -8584.355\n",
      " Regression with ARIMA(2,0,0) errors : -13540.68\n",
      " Regression with ARIMA(1,0,1) errors : -13540.96\n",
      " Regression with ARIMA(2,0,1) errors : -13550.79\n",
      " Regression with ARIMA(3,0,1) errors : -13544.63\n",
      " Regression with ARIMA(1,0,2) errors : -13539.89\n",
      " Regression with ARIMA(3,0,0) errors : -13538.95\n",
      " Regression with ARIMA(3,0,2) errors : -13543.48\n",
      " Regression with ARIMA(2,0,1) errors : -13423.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : -13541.93\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13563.2\n",
      " Regression with ARIMA(0,0,0) errors : -10221.42\n",
      " Regression with ARIMA(1,0,0) errors : -13558.89\n",
      " Regression with ARIMA(0,0,1) errors : -11783.59\n",
      " Regression with ARIMA(0,0,0) errors : -8587.344\n",
      " Regression with ARIMA(1,0,2) errors : -13557.75\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13560.36\n",
      " Regression with ARIMA(2,0,3) errors : -13561.2\n",
      " Regression with ARIMA(1,0,1) errors : -13558.83\n",
      " Regression with ARIMA(1,0,3) errors : -13556.36\n",
      " Regression with ARIMA(3,0,1) errors : -13562.66\n",
      " Regression with ARIMA(3,0,3) errors : -13569.83\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13571.17\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -13563.95\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13566.38\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13567.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13570.4\n",
      " Regression with ARIMA(0,0,0) errors : -10190.39\n",
      " Regression with ARIMA(1,0,0) errors : -13568.75\n",
      " Regression with ARIMA(0,0,1) errors : -11771.15\n",
      " Regression with ARIMA(0,0,0) errors : -8593.643\n",
      " Regression with ARIMA(1,0,2) errors : -13567.8\n",
      " Regression with ARIMA(2,0,1) errors : -13578.25\n",
      " Regression with ARIMA(1,0,1) errors : -13568.87\n",
      " Regression with ARIMA(2,0,0) errors : -13567.98\n",
      " Regression with ARIMA(3,0,1) errors : -13566.18\n",
      " Regression with ARIMA(3,0,0) errors : -13566.18\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : -13449.02\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13568.25\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13634.9\n",
      " Regression with ARIMA(0,0,0) errors : -10190.23\n",
      " Regression with ARIMA(1,0,0) errors : -13630.94\n",
      " Regression with ARIMA(0,0,1) errors : -11790.6\n",
      " Regression with ARIMA(0,0,0) errors : -8611.59\n",
      " Regression with ARIMA(1,0,2) errors : -13631.17\n",
      " Regression with ARIMA(2,0,1) errors : -13641.72\n",
      " Regression with ARIMA(1,0,1) errors : -13631.97\n",
      " Regression with ARIMA(2,0,0) errors : -13632.33\n",
      " Regression with ARIMA(3,0,1) errors : -13630.61\n",
      " Regression with ARIMA(3,0,0) errors : -13630.85\n",
      " Regression with ARIMA(3,0,2) errors : -13642.1\n",
      " Regression with ARIMA(4,0,2) errors : -13636.63\n",
      " Regression with ARIMA(3,0,3) errors : -13640.47\n",
      " Regression with ARIMA(2,0,3) errors : -13632.93\n",
      " Regression with ARIMA(4,0,1) errors : -13631.33\n",
      " Regression with ARIMA(4,0,3) errors : -13636.07\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13640.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13645.23\n",
      " Regression with ARIMA(0,0,0) errors : -10202.47\n",
      " Regression with ARIMA(1,0,0) errors : -13645.74\n",
      " Regression with ARIMA(0,0,1) errors : -11804.3\n",
      " Regression with ARIMA(0,0,0) errors : -8622.517\n",
      " Regression with ARIMA(2,0,0) errors : -13646.54\n",
      " Regression with ARIMA(3,0,0) errors : -13646.95\n",
      " Regression with ARIMA(4,0,0) errors : -13644.57\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -13646.54\n",
      " Regression with ARIMA(3,0,0) errors : -13536.11\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,0) errors : -13645.14\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13662.78\n",
      " Regression with ARIMA(0,0,0) errors : -10203.12\n",
      " Regression with ARIMA(1,0,0) errors : -13661.7\n",
      " Regression with ARIMA(0,0,1) errors : -11801.53\n",
      " Regression with ARIMA(0,0,0) errors : -8623.09\n",
      " Regression with ARIMA(1,0,2) errors : -13661.65\n",
      " Regression with ARIMA(2,0,1) errors : -13670.27\n",
      " Regression with ARIMA(1,0,1) errors : -13662.54\n",
      " Regression with ARIMA(2,0,0) errors : -13662.03\n",
      " Regression with ARIMA(3,0,1) errors : -13660.85\n",
      " Regression with ARIMA(3,0,0) errors : -13660.75\n",
      " Regression with ARIMA(3,0,2) errors : -13668.59\n",
      " Regression with ARIMA(2,0,1) errors : -13554.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13669.89\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13665.71\n",
      " Regression with ARIMA(0,0,0) errors : -10188.87\n",
      " Regression with ARIMA(1,0,0) errors : -13663.7\n",
      " Regression with ARIMA(0,0,1) errors : -11795.42\n",
      " Regression with ARIMA(0,0,0) errors : -8643.892\n",
      " Regression with ARIMA(1,0,2) errors : -13663.8\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13660.35\n",
      " Regression with ARIMA(2,0,3) errors : -13663.69\n",
      " Regression with ARIMA(1,0,1) errors : -13664.64\n",
      " Regression with ARIMA(1,0,3) errors : -13662.17\n",
      " Regression with ARIMA(3,0,1) errors : -13664.67\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13565.22\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13665.83\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13656.64\n",
      " Regression with ARIMA(0,0,0) errors : -10191.97\n",
      " Regression with ARIMA(1,0,0) errors : -13653.06\n",
      " Regression with ARIMA(0,0,1) errors : -11788.05\n",
      " Regression with ARIMA(0,0,0) errors : -8651.602\n",
      " Regression with ARIMA(1,0,2) errors : -13653.54\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13653.21\n",
      " Regression with ARIMA(2,0,3) errors : -13654.62\n",
      " Regression with ARIMA(1,0,1) errors : -13654.33\n",
      " Regression with ARIMA(1,0,3) errors : -13651.95\n",
      " Regression with ARIMA(3,0,1) errors : -13655.42\n",
      " Regression with ARIMA(3,0,3) errors : -13661.07\n",
      " Regression with ARIMA(4,0,3) errors : -13648.86\n",
      " Regression with ARIMA(3,0,4) errors : -13662.96\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13661.06\n",
      " Regression with ARIMA(4,0,5) errors : -13659.57\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13659.73\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13649.41\n",
      " Regression with ARIMA(0,0,0) errors : -10167.99\n",
      " Regression with ARIMA(1,0,0) errors : -13648.99\n",
      " Regression with ARIMA(0,0,1) errors : -11774.26\n",
      " Regression with ARIMA(0,0,0) errors : -8653.868\n",
      " Regression with ARIMA(1,0,2) errors : -13649.56\n",
      " Regression with ARIMA(0,0,2) errors : -12612.9\n",
      " Regression with ARIMA(1,0,1) errors : -13650.24\n",
      " Regression with ARIMA(2,0,1) errors : -13660.4\n",
      " Regression with ARIMA(2,0,0) errors : -13649.71\n",
      " Regression with ARIMA(3,0,1) errors : -13651.41\n",
      " Regression with ARIMA(3,0,0) errors : -13648.4\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13661.18\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13655.63\n",
      " Regression with ARIMA(0,0,0) errors : -10165.57\n",
      " Regression with ARIMA(1,0,0) errors : -13654.18\n",
      " Regression with ARIMA(0,0,1) errors : -11773.14\n",
      " Regression with ARIMA(0,0,0) errors : -8656.522\n",
      " Regression with ARIMA(1,0,2) errors : -13654.42\n",
      " Regression with ARIMA(2,0,1) errors : -13665.49\n",
      " Regression with ARIMA(1,0,1) errors : -13655.18\n",
      " Regression with ARIMA(2,0,0) errors : -13654.5\n",
      " Regression with ARIMA(3,0,1) errors : -13655.23\n",
      " Regression with ARIMA(3,0,0) errors : -13653.04\n",
      " Regression with ARIMA(3,0,2) errors : -13653.31\n",
      " Regression with ARIMA(2,0,1) errors : -13554.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13666.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13657.3\n",
      " Regression with ARIMA(0,0,0) errors : -10165.83\n",
      " Regression with ARIMA(1,0,0) errors : -13655.15\n",
      " Regression with ARIMA(0,0,1) errors : -11771.76\n",
      " Regression with ARIMA(0,0,0) errors : -8655.923\n",
      " Regression with ARIMA(1,0,2) errors : -13655.23\n",
      " Regression with ARIMA(2,0,1) errors : -13667.08\n",
      " Regression with ARIMA(1,0,1) errors : -13656.02\n",
      " Regression with ARIMA(2,0,0) errors : -13655.19\n",
      " Regression with ARIMA(3,0,1) errors : -13655.86\n",
      " Regression with ARIMA(3,0,0) errors : -13658.04\n",
      " Regression with ARIMA(3,0,2) errors : -13655.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13666.52\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13655.6\n",
      " Regression with ARIMA(0,0,0) errors : -10159.47\n",
      " Regression with ARIMA(1,0,0) errors : -13654.74\n",
      " Regression with ARIMA(0,0,1) errors : -11765.48\n",
      " Regression with ARIMA(0,0,0) errors : -8662.39\n",
      " Regression with ARIMA(1,0,2) errors : -13655.14\n",
      " Regression with ARIMA(2,0,1) errors : -13671.56\n",
      " Regression with ARIMA(1,0,1) errors : -13655.72\n",
      " Regression with ARIMA(2,0,0) errors : -13656.86\n",
      " Regression with ARIMA(3,0,1) errors : -13656.12\n",
      " Regression with ARIMA(3,0,0) errors : -13655.95\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13665.81\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13656.79\n",
      " Regression with ARIMA(0,0,0) errors : -10173.96\n",
      " Regression with ARIMA(1,0,0) errors : -13652.05\n",
      " Regression with ARIMA(0,0,1) errors : -11777.5\n",
      " Regression with ARIMA(0,0,0) errors : -8700.468\n",
      " Regression with ARIMA(1,0,2) errors : -13652.23\n",
      " Regression with ARIMA(2,0,1) errors : -13668.02\n",
      " Regression with ARIMA(1,0,1) errors : -13652.1\n",
      " Regression with ARIMA(2,0,0) errors : -13652.19\n",
      " Regression with ARIMA(3,0,1) errors : -13656.11\n",
      " Regression with ARIMA(3,0,0) errors : -13652.01\n",
      " Regression with ARIMA(3,0,2) errors : -13662.39\n",
      " Regression with ARIMA(2,0,1) errors : -13548.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13662.69\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13625.68\n",
      " Regression with ARIMA(0,1,0) errors : -13621.46\n",
      " Regression with ARIMA(1,1,0) errors : -13624.34\n",
      " Regression with ARIMA(0,1,1) errors : -13619.6\n",
      " Regression with ARIMA(0,1,0) errors : -13623.47\n",
      " Regression with ARIMA(1,1,2) errors : -13629.17\n",
      " Regression with ARIMA(0,1,2) errors : -13617.77\n",
      " Regression with ARIMA(1,1,1) errors : -13628.01\n",
      " Regression with ARIMA(1,1,3) errors : -13633.78\n",
      " Regression with ARIMA(0,1,3) errors : -13616.46\n",
      " Regression with ARIMA(2,1,3) errors : -13627.37\n",
      " Regression with ARIMA(1,1,4) errors : -13638.05\n",
      " Regression with ARIMA(0,1,4) errors : -13614.88\n",
      " Regression with ARIMA(2,1,4) errors : -13627.68\n",
      " Regression with ARIMA(1,1,5) errors : -13657.04\n",
      " Regression with ARIMA(0,1,5) errors : -13617.4\n",
      " Regression with ARIMA(2,1,5) errors : -13647.25\n",
      " Regression with ARIMA(1,1,5) errors : -13658.92\n",
      " Regression with ARIMA(0,1,5) errors : -13619.42\n",
      " Regression with ARIMA(1,1,4) errors : -13639.93\n",
      " Regression with ARIMA(2,1,5) errors : -13649.14\n",
      " Regression with ARIMA(0,1,4) errors : -13616.89\n",
      " Regression with ARIMA(2,1,4) errors : -13629.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,0) errors : -13628.45\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13669.46\n",
      " Regression with ARIMA(0,1,0) errors : -13667.96\n",
      " Regression with ARIMA(1,1,0) errors : -13665.88\n",
      " Regression with ARIMA(0,1,1) errors : -13666.47\n",
      " Regression with ARIMA(0,1,0) errors : -13669.95\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13678.82\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10272.74\n",
      " Regression with ARIMA(1,0,0) errors : -13772.01\n",
      " Regression with ARIMA(0,0,1) errors : -11891.74\n",
      " Regression with ARIMA(0,0,0) errors : -8843.671\n",
      " Regression with ARIMA(2,0,0) errors : -13770.9\n",
      " Regression with ARIMA(1,0,1) errors : -13771.44\n",
      " Regression with ARIMA(2,0,1) errors : -13785.75\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13772.19\n",
      " Regression with ARIMA(3,0,0) errors : -13772.31\n",
      " Regression with ARIMA(3,0,2) errors : -13785.11\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13783.28\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13764.52\n",
      " Regression with ARIMA(0,0,0) errors : -10268.04\n",
      " Regression with ARIMA(1,0,0) errors : -13761.23\n",
      " Regression with ARIMA(0,0,1) errors : -11885.1\n",
      " Regression with ARIMA(0,0,0) errors : -8858.715\n",
      " Regression with ARIMA(1,0,2) errors : -13761.55\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13782.76\n",
      " Regression with ARIMA(3,0,1) errors : -13780.45\n",
      " Regression with ARIMA(4,0,2) errors : -13778.02\n",
      " Regression with ARIMA(3,0,3) errors : -13780.93\n",
      " Regression with ARIMA(2,0,3) errors : -13762.9\n",
      " Regression with ARIMA(4,0,1) errors : -13774.34\n",
      " Regression with ARIMA(4,0,3) errors : -13775.95\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13775.78\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13769.81\n",
      " Regression with ARIMA(0,0,0) errors : -10265.3\n",
      " Regression with ARIMA(1,0,0) errors : -13762.85\n",
      " Regression with ARIMA(0,0,1) errors : -11881.84\n",
      " Regression with ARIMA(0,0,0) errors : -8821.143\n",
      " Regression with ARIMA(1,0,2) errors : -13762.57\n",
      " Regression with ARIMA(2,0,1) errors : -13768.3\n",
      " Regression with ARIMA(3,0,2) errors : -13783.22\n",
      " Regression with ARIMA(3,0,1) errors : -13768.49\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13781.28\n",
      " Regression with ARIMA(2,0,3) errors : -13768.18\n",
      " Regression with ARIMA(4,0,1) errors : -13769.2\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13777.69\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13769.38\n",
      " Regression with ARIMA(0,0,0) errors : -10260.46\n",
      " Regression with ARIMA(1,0,0) errors : -13763.75\n",
      " Regression with ARIMA(0,0,1) errors : -11877.06\n",
      " Regression with ARIMA(0,0,0) errors : -8820.979\n",
      " Regression with ARIMA(1,0,2) errors : -13763.9\n",
      " Regression with ARIMA(2,0,1) errors : -13767.21\n",
      " Regression with ARIMA(3,0,2) errors : -13781.12\n",
      " Regression with ARIMA(3,0,1) errors : -13768.51\n",
      " Regression with ARIMA(4,0,2) errors : -13781.64\n",
      " Regression with ARIMA(4,0,1) errors : -13767.06\n",
      " Regression with ARIMA(5,0,2) errors : -13779.5\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13781.37\n",
      " Regression with ARIMA(5,0,1) errors : -13775.92\n",
      " Regression with ARIMA(5,0,3) errors : -13777.89\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,2) errors : -13774.84\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13730.6\n",
      " Regression with ARIMA(0,0,0) errors : -10252.14\n",
      " Regression with ARIMA(1,0,0) errors : -13734.15\n",
      " Regression with ARIMA(0,0,1) errors : -11865.14\n",
      " Regression with ARIMA(0,0,0) errors : -8811.741\n",
      " Regression with ARIMA(2,0,0) errors : -13732.86\n",
      " Regression with ARIMA(1,0,1) errors : -13733.55\n",
      " Regression with ARIMA(2,0,1) errors : -13745.03\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13733.84\n",
      " Regression with ARIMA(3,0,0) errors : -13732.77\n",
      " Regression with ARIMA(3,0,2) errors : -13730.31\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13733.34\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10248.64\n",
      " Regression with ARIMA(1,0,0) errors : -13726.11\n",
      " Regression with ARIMA(0,0,1) errors : -11859.38\n",
      " Regression with ARIMA(0,0,0) errors : -8814.75\n",
      " Regression with ARIMA(2,0,0) errors : -13726.2\n",
      " Regression with ARIMA(3,0,0) errors : -13726.52\n",
      " Regression with ARIMA(4,0,0) errors : -13725.54\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : -13736.42\n",
      " Regression with ARIMA(1,0,1) errors : -13725.25\n",
      " Regression with ARIMA(1,0,2) errors : -13725.96\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,0) errors : -13725.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10253.6\n",
      " Regression with ARIMA(1,0,0) errors : -13735.62\n",
      " Regression with ARIMA(0,0,1) errors : -11865.12\n",
      " Regression with ARIMA(0,0,0) errors : -8816.856\n",
      " Regression with ARIMA(2,0,0) errors : -13733.87\n",
      " Regression with ARIMA(1,0,1) errors : -13734.66\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13733.14\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13750.01\n",
      " Regression with ARIMA(0,0,0) errors : -10257.06\n",
      " Regression with ARIMA(1,0,0) errors : -13738.28\n",
      " Regression with ARIMA(0,0,1) errors : -11865.9\n",
      " Regression with ARIMA(0,0,0) errors : -8780.029\n",
      " Regression with ARIMA(1,0,2) errors : -13737.34\n",
      " Regression with ARIMA(2,0,1) errors : -13751.1\n",
      " Regression with ARIMA(1,0,1) errors : -13737.18\n",
      " Regression with ARIMA(2,0,0) errors : -13736.6\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,0) errors : -13736.27\n",
      " Regression with ARIMA(3,0,2) errors : -13732.63\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13735.84\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10256.83\n",
      " Regression with ARIMA(1,0,0) errors : -13730.95\n",
      " Regression with ARIMA(0,0,1) errors : -11861.77\n",
      " Regression with ARIMA(0,0,0) errors : -8779.258\n",
      " Regression with ARIMA(2,0,0) errors : -13729.15\n",
      " Regression with ARIMA(1,0,1) errors : -13729.46\n",
      " Regression with ARIMA(2,0,1) errors : -13743.66\n",
      " Regression with ARIMA(3,0,1) errors : -13740.11\n",
      " Regression with ARIMA(1,0,2) errors : -13729.66\n",
      " Regression with ARIMA(3,0,0) errors : -13731.65\n",
      " Regression with ARIMA(3,0,2) errors : -13742.18\n",
      " Regression with ARIMA(2,0,1) errors : -13618.71\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13744.27\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13704.92\n",
      " Regression with ARIMA(0,0,0) errors : -10273.67\n",
      " Regression with ARIMA(1,0,0) errors : -13706.69\n",
      " Regression with ARIMA(0,0,1) errors : -11878.39\n",
      " Regression with ARIMA(0,0,0) errors : -8797.955\n",
      " Regression with ARIMA(2,0,0) errors : -13704.19\n",
      " Regression with ARIMA(1,0,1) errors : -13704.98\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13577.35\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13704.77\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13513.55\n",
      " Regression with ARIMA(0,0,0) errors : -10068.34\n",
      " Regression with ARIMA(1,0,0) errors : -13520.38\n",
      " Regression with ARIMA(0,0,1) errors : -11654.6\n",
      " Regression with ARIMA(0,0,0) errors : -8614.487\n",
      " Regression with ARIMA(2,0,0) errors : -13517.43\n",
      " Regression with ARIMA(1,0,1) errors : -13518.38\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13517.53\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12970.83\n",
      " Regression with ARIMA(0,1,0) errors : -12930.49\n",
      " Regression with ARIMA(1,1,0) errors : -12945.11\n",
      " Regression with ARIMA(0,1,1) errors : -12947.22\n",
      " Regression with ARIMA(0,1,0) errors : -12932.5\n",
      " Regression with ARIMA(1,1,2) errors : -12962.91\n",
      " Regression with ARIMA(2,1,1) errors : -12971.71\n",
      " Regression with ARIMA(1,1,1) errors : -12955.51\n",
      " Regression with ARIMA(2,1,0) errors : -12969.84\n",
      " Regression with ARIMA(3,1,1) errors : -12974.24\n",
      " Regression with ARIMA(3,1,0) errors : -12974.64\n",
      " Regression with ARIMA(4,1,0) errors : -12978.76\n",
      " Regression with ARIMA(5,1,0) errors : -12976.29\n",
      " Regression with ARIMA(4,1,1) errors : -12976.71\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,0) errors : -12980.76\n",
      " Regression with ARIMA(3,1,0) errors : -12976.65\n",
      " Regression with ARIMA(5,1,0) errors : -12978.28\n",
      " Regression with ARIMA(4,1,1) errors : -12978.77\n",
      " Regression with ARIMA(3,1,1) errors : -12976.24\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,1,0) errors : -12980.2\n",
      "\n",
      " Best model: Regression with ARIMA(4,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12722.08\n",
      " Regression with ARIMA(0,1,0) errors : -12682.87\n",
      " Regression with ARIMA(1,1,0) errors : -12702.85\n",
      " Regression with ARIMA(0,1,1) errors : -12708.6\n",
      " Regression with ARIMA(0,1,0) errors : -12684.84\n",
      " Regression with ARIMA(1,1,2) errors : -12720.75\n",
      " Regression with ARIMA(2,1,1) errors : -12722.99\n",
      " Regression with ARIMA(1,1,1) errors : -12711.35\n",
      " Regression with ARIMA(2,1,0) errors : -12720.41\n",
      " Regression with ARIMA(3,1,1) errors : -12722.13\n",
      " Regression with ARIMA(3,1,0) errors : -12724.07\n",
      " Regression with ARIMA(4,1,0) errors : -12721.18\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -12726.05\n",
      " Regression with ARIMA(2,1,0) errors : -12722.38\n",
      " Regression with ARIMA(4,1,0) errors : -12723.17\n",
      " Regression with ARIMA(3,1,1) errors : -12724.11\n",
      " Regression with ARIMA(2,1,1) errors : -12724.96\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,0) errors : -12736.42\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12560.78\n",
      " Regression with ARIMA(0,1,0) errors : -12505.96\n",
      " Regression with ARIMA(1,1,0) errors : -12527.34\n",
      " Regression with ARIMA(0,1,1) errors : -12533.58\n",
      " Regression with ARIMA(0,1,0) errors : -12507.97\n",
      " Regression with ARIMA(1,1,2) errors : -12551.89\n",
      " Regression with ARIMA(2,1,1) errors : -12557.49\n",
      " Regression with ARIMA(3,1,2) errors : -12557.93\n",
      " Regression with ARIMA(2,1,3) errors : -12558.92\n",
      " Regression with ARIMA(1,1,1) errors : -12537.48\n",
      " Regression with ARIMA(1,1,3) errors : -12554.56\n",
      " Regression with ARIMA(3,1,1) errors : -12557.55\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12562.8\n",
      " Regression with ARIMA(1,1,2) errors : -12553.91\n",
      " Regression with ARIMA(2,1,1) errors : -12559.5\n",
      " Regression with ARIMA(3,1,2) errors : -12559.9\n",
      " Regression with ARIMA(2,1,3) errors : -12560.93\n",
      " Regression with ARIMA(1,1,1) errors : -12539.48\n",
      " Regression with ARIMA(1,1,3) errors : -12556.58\n",
      " Regression with ARIMA(3,1,1) errors : -12559.56\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12572.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12525.75\n",
      " Regression with ARIMA(0,1,0) errors : -12472.26\n",
      " Regression with ARIMA(1,1,0) errors : -12494.36\n",
      " Regression with ARIMA(0,1,1) errors : -12499.92\n",
      " Regression with ARIMA(0,1,0) errors : -12474.27\n",
      " Regression with ARIMA(1,1,2) errors : -12516.93\n",
      " Regression with ARIMA(2,1,1) errors : -12522.47\n",
      " Regression with ARIMA(3,1,2) errors : -12522.7\n",
      " Regression with ARIMA(2,1,3) errors : -12523.75\n",
      " Regression with ARIMA(1,1,1) errors : -12502.95\n",
      " Regression with ARIMA(1,1,3) errors : -12520.19\n",
      " Regression with ARIMA(3,1,1) errors : -12522.74\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12527.77\n",
      " Regression with ARIMA(1,1,2) errors : -12518.94\n",
      " Regression with ARIMA(2,1,1) errors : -12524.48\n",
      " Regression with ARIMA(3,1,2) errors : -12524.7\n",
      " Regression with ARIMA(2,1,3) errors : -12525.77\n",
      " Regression with ARIMA(1,1,1) errors : -12504.95\n",
      " Regression with ARIMA(1,1,3) errors : -12522.21\n",
      " Regression with ARIMA(3,1,1) errors : -12524.75\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12537.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12470.37\n",
      " Regression with ARIMA(0,1,0) errors : -12414.35\n",
      " Regression with ARIMA(1,1,0) errors : -12436.58\n",
      " Regression with ARIMA(0,1,1) errors : -12443.12\n",
      " Regression with ARIMA(0,1,0) errors : -12416.35\n",
      " Regression with ARIMA(1,1,2) errors : -12461.95\n",
      " Regression with ARIMA(2,1,1) errors : -12468.01\n",
      " Regression with ARIMA(3,1,2) errors : -12467.45\n",
      " Regression with ARIMA(2,1,3) errors : -12468.34\n",
      " Regression with ARIMA(1,1,1) errors : -12445.63\n",
      " Regression with ARIMA(1,1,3) errors : -12464.82\n",
      " Regression with ARIMA(3,1,1) errors : -12468.7\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12472.37\n",
      " Regression with ARIMA(1,1,2) errors : -12463.95\n",
      " Regression with ARIMA(2,1,1) errors : -12470\n",
      " Regression with ARIMA(3,1,2) errors : -12469.45\n",
      " Regression with ARIMA(2,1,3) errors : -12470.36\n",
      " Regression with ARIMA(1,1,1) errors : -12447.62\n",
      " Regression with ARIMA(1,1,3) errors : -12466.82\n",
      " Regression with ARIMA(3,1,1) errors : -12470.69\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12481.51\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12415.46\n",
      " Regression with ARIMA(0,1,0) errors : -12357.7\n",
      " Regression with ARIMA(1,1,0) errors : -12377.73\n",
      " Regression with ARIMA(0,1,1) errors : -12382.8\n",
      " Regression with ARIMA(0,1,0) errors : -12359.71\n",
      " Regression with ARIMA(1,1,2) errors : -12397.26\n",
      " Regression with ARIMA(2,1,1) errors : -12405.48\n",
      " Regression with ARIMA(3,1,2) errors : -12413.51\n",
      " Regression with ARIMA(2,1,3) errors : -12414.64\n",
      " Regression with ARIMA(1,1,1) errors : -12383.72\n",
      " Regression with ARIMA(1,1,3) errors : -12404.76\n",
      " Regression with ARIMA(3,1,1) errors : -12410.9\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12417.47\n",
      " Regression with ARIMA(1,1,2) errors : -12399.27\n",
      " Regression with ARIMA(2,1,1) errors : -12407.49\n",
      " Regression with ARIMA(3,1,2) errors : -12415.52\n",
      " Regression with ARIMA(2,1,3) errors : -12416.65\n",
      " Regression with ARIMA(1,1,1) errors : -12385.73\n",
      " Regression with ARIMA(1,1,3) errors : -12406.78\n",
      " Regression with ARIMA(3,1,1) errors : -12412.92\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12422.35\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12392.88\n",
      " Regression with ARIMA(0,1,0) errors : -12334.96\n",
      " Regression with ARIMA(1,1,0) errors : -12358.48\n",
      " Regression with ARIMA(0,1,1) errors : -12364.77\n",
      " Regression with ARIMA(0,1,0) errors : -12336.95\n",
      " Regression with ARIMA(1,1,2) errors : -12380.24\n",
      " Regression with ARIMA(2,1,1) errors : -12390.33\n",
      " Regression with ARIMA(3,1,2) errors : -12392.56\n",
      " Regression with ARIMA(2,1,3) errors : -12390.88\n",
      " Regression with ARIMA(1,1,1) errors : -12366.94\n",
      " Regression with ARIMA(1,1,3) errors : -12386.73\n",
      " Regression with ARIMA(3,1,1) errors : -12394.33\n",
      " Regression with ARIMA(3,1,0) errors : -12396.28\n",
      " Regression with ARIMA(2,1,0) errors : -12381.04\n",
      " Regression with ARIMA(4,1,0) errors : -12409.24\n",
      " Regression with ARIMA(5,1,0) errors : -12418.87\n",
      " Regression with ARIMA(5,1,1) errors : -12429.22\n",
      " Regression with ARIMA(4,1,1) errors : -12408.98\n",
      " Regression with ARIMA(5,1,2) errors : -12419\n",
      " Regression with ARIMA(4,1,2) errors : -12415.77\n",
      " Regression with ARIMA(5,1,1) errors : -12431.1\n",
      " Regression with ARIMA(4,1,1) errors : -12410.99\n",
      " Regression with ARIMA(5,1,0) errors : -12420.89\n",
      " Regression with ARIMA(5,1,2) errors : -12421.01\n",
      " Regression with ARIMA(4,1,0) errors : -12411.25\n",
      " Regression with ARIMA(4,1,2) errors : -12417.78\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,0) errors : -12408.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12405.22\n",
      " Regression with ARIMA(0,1,0) errors : -12342.22\n",
      " Regression with ARIMA(1,1,0) errors : -12369.17\n",
      " Regression with ARIMA(0,1,1) errors : -12375.11\n",
      " Regression with ARIMA(0,1,0) errors : -12344.23\n",
      " Regression with ARIMA(1,1,2) errors : -12390.01\n",
      " Regression with ARIMA(2,1,1) errors : -12397.17\n",
      " Regression with ARIMA(3,1,2) errors : -12404.33\n",
      " Regression with ARIMA(2,1,3) errors : -12403.26\n",
      " Regression with ARIMA(1,1,1) errors : -12376.7\n",
      " Regression with ARIMA(1,1,3) errors : -12397.27\n",
      " Regression with ARIMA(3,1,1) errors : -12402.52\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12407.23\n",
      " Regression with ARIMA(1,1,2) errors : -12392.02\n",
      " Regression with ARIMA(2,1,1) errors : -12399.19\n",
      " Regression with ARIMA(3,1,2) errors : -12406.34\n",
      " Regression with ARIMA(2,1,3) errors : -12405.28\n",
      " Regression with ARIMA(1,1,1) errors : -12378.71\n",
      " Regression with ARIMA(1,1,3) errors : -12399.28\n",
      " Regression with ARIMA(3,1,1) errors : -12404.53\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12418.09\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12479.1\n",
      " Regression with ARIMA(0,0,0) errors : -8904.547\n",
      " Regression with ARIMA(1,0,0) errors : -12457.86\n",
      " Regression with ARIMA(0,0,1) errors : -10586.67\n",
      " Regression with ARIMA(0,0,0) errors : -7757.971\n",
      " Regression with ARIMA(1,0,2) errors : -12470.62\n",
      " Regression with ARIMA(2,0,1) errors : -12467.78\n",
      " Regression with ARIMA(3,0,2) errors : -12535.04\n",
      " Regression with ARIMA(3,0,1) errors : -12486.22\n",
      " Regression with ARIMA(4,0,2) errors : -12504.23\n",
      " Regression with ARIMA(3,0,3) errors : -12504.59\n",
      " Regression with ARIMA(2,0,3) errors : -12501.85\n",
      " Regression with ARIMA(4,0,1) errors : -12505.69\n",
      " Regression with ARIMA(4,0,3) errors : -12533.86\n",
      " Regression with ARIMA(3,0,2) errors : -12438.48\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12506.31\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12465.71\n",
      " Regression with ARIMA(0,0,0) errors : -8892.805\n",
      " Regression with ARIMA(1,0,0) errors : -12446.23\n",
      " Regression with ARIMA(0,0,1) errors : -10571.36\n",
      " Regression with ARIMA(0,0,0) errors : -7709.597\n",
      " Regression with ARIMA(1,0,2) errors : -12458.34\n",
      " Regression with ARIMA(2,0,1) errors : -12455.94\n",
      " Regression with ARIMA(3,0,2) errors : -12524.46\n",
      " Regression with ARIMA(3,0,1) errors : -12471.77\n",
      " Regression with ARIMA(4,0,2) errors : -12490.22\n",
      " Regression with ARIMA(3,0,3) errors : -12489.3\n",
      " Regression with ARIMA(2,0,3) errors : -12488.4\n",
      " Regression with ARIMA(4,0,1) errors : -12491.45\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12529.33\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12465.29\n",
      " Regression with ARIMA(0,0,0) errors : -8894.651\n",
      " Regression with ARIMA(1,0,0) errors : -12445.35\n",
      " Regression with ARIMA(0,0,1) errors : -10573.51\n",
      " Regression with ARIMA(0,0,0) errors : -7703.577\n",
      " Regression with ARIMA(1,0,2) errors : -12457.79\n",
      " Regression with ARIMA(2,0,1) errors : -12455.34\n",
      " Regression with ARIMA(3,0,2) errors : -12521.44\n",
      " Regression with ARIMA(3,0,1) errors : -12471.75\n",
      " Regression with ARIMA(4,0,2) errors : -12489.95\n",
      " Regression with ARIMA(3,0,3) errors : -12489.87\n",
      " Regression with ARIMA(2,0,3) errors : -12487.74\n",
      " Regression with ARIMA(4,0,1) errors : -12490.93\n",
      " Regression with ARIMA(4,0,3) errors : -12517.07\n",
      " Regression with ARIMA(3,0,2) errors : -12443.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12527.75\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12457.74\n",
      " Regression with ARIMA(0,0,0) errors : -8888.053\n",
      " Regression with ARIMA(1,0,0) errors : -12438.77\n",
      " Regression with ARIMA(0,0,1) errors : -10568.72\n",
      " Regression with ARIMA(0,0,0) errors : -7699.325\n",
      " Regression with ARIMA(1,0,2) errors : -12450.59\n",
      " Regression with ARIMA(2,0,1) errors : -12447.71\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12479.45\n",
      " Regression with ARIMA(1,0,3) errors : -12482.41\n",
      " Regression with ARIMA(0,0,3) errors : -11655.39\n",
      " Regression with ARIMA(1,0,4) errors : -12480.42\n",
      " Regression with ARIMA(0,0,2) errors : -11226.37\n",
      " Regression with ARIMA(0,0,4) errors : -11987.9\n",
      " Regression with ARIMA(2,0,4) errors : -12508.61\n",
      " Regression with ARIMA(3,0,4) errors : -12510.98\n",
      " Regression with ARIMA(3,0,3) errors : -12480.89\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12508.89\n",
      " Regression with ARIMA(2,0,5) errors : -12511.16\n",
      " Regression with ARIMA(1,0,5) errors : -12481.3\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12511.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12454.54\n",
      " Regression with ARIMA(0,0,0) errors : -8881.322\n",
      " Regression with ARIMA(1,0,0) errors : -12434.91\n",
      " Regression with ARIMA(0,0,1) errors : -10562.75\n",
      " Regression with ARIMA(0,0,0) errors : -7707.396\n",
      " Regression with ARIMA(1,0,2) errors : -12446.19\n",
      " Regression with ARIMA(2,0,1) errors : -12444.84\n",
      " Regression with ARIMA(3,0,2) errors : -12469.19\n",
      " Regression with ARIMA(3,0,1) errors : -12458.01\n",
      " Regression with ARIMA(4,0,2) errors : -12484.21\n",
      " Regression with ARIMA(4,0,1) errors : -12483.69\n",
      " Regression with ARIMA(5,0,2) errors : -12502.19\n",
      " Regression with ARIMA(5,0,1) errors : -12498.17\n",
      " Regression with ARIMA(5,0,3) errors : -12504.05\n",
      " Regression with ARIMA(4,0,3) errors : -12482.32\n",
      " Regression with ARIMA(5,0,4) errors : -12490.42\n",
      " Regression with ARIMA(4,0,4) errors : -12481.71\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : -12506.66\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12464.6\n",
      " Regression with ARIMA(0,0,0) errors : -8887.118\n",
      " Regression with ARIMA(1,0,0) errors : -12445.24\n",
      " Regression with ARIMA(0,0,1) errors : -10561.18\n",
      " Regression with ARIMA(0,0,0) errors : -7708.215\n",
      " Regression with ARIMA(1,0,2) errors : -12456.91\n",
      " Regression with ARIMA(2,0,1) errors : -12455.73\n",
      " Regression with ARIMA(3,0,2) errors : -12528.24\n",
      " Regression with ARIMA(3,0,1) errors : -12470.67\n",
      " Regression with ARIMA(4,0,2) errors : -12491.02\n",
      " Regression with ARIMA(3,0,3) errors : -12487.94\n",
      " Regression with ARIMA(2,0,3) errors : -12488.17\n",
      " Regression with ARIMA(4,0,1) errors : -12491.62\n",
      " Regression with ARIMA(4,0,3) errors : -12490.61\n",
      " Regression with ARIMA(3,0,2) errors : -12436.46\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12488.78\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12482.33\n",
      " Regression with ARIMA(0,0,0) errors : -8891.815\n",
      " Regression with ARIMA(1,0,0) errors : -12463.17\n",
      " Regression with ARIMA(0,0,1) errors : -10569.71\n",
      " Regression with ARIMA(0,0,0) errors : -7717.256\n",
      " Regression with ARIMA(1,0,2) errors : -12475.08\n",
      " Regression with ARIMA(2,0,1) errors : -12474.77\n",
      " Regression with ARIMA(3,0,2) errors : -12536.91\n",
      " Regression with ARIMA(3,0,1) errors : -12489.05\n",
      " Regression with ARIMA(4,0,2) errors : -12507.21\n",
      " Regression with ARIMA(3,0,3) errors : -12507.02\n",
      " Regression with ARIMA(2,0,3) errors : -12506.61\n",
      " Regression with ARIMA(4,0,1) errors : -12508.71\n",
      " Regression with ARIMA(4,0,3) errors : -12506.62\n",
      " Regression with ARIMA(3,0,2) errors : -12453.39\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12508.55\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12503.57\n",
      " Regression with ARIMA(0,0,0) errors : -8896.241\n",
      " Regression with ARIMA(1,0,0) errors : -12485.86\n",
      " Regression with ARIMA(0,0,1) errors : -10569.77\n",
      " Regression with ARIMA(0,0,0) errors : -7714.817\n",
      " Regression with ARIMA(1,0,2) errors : -12497.82\n",
      " Regression with ARIMA(2,0,1) errors : -12496.35\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12527.94\n",
      " Regression with ARIMA(1,0,3) errors : -12530.81\n",
      " Regression with ARIMA(0,0,3) errors : -11677.03\n",
      " Regression with ARIMA(1,0,4) errors : -12528.79\n",
      " Regression with ARIMA(0,0,2) errors : -11229.55\n",
      " Regression with ARIMA(0,0,4) errors : -12012.79\n",
      " Regression with ARIMA(2,0,4) errors : -12555.48\n",
      " Regression with ARIMA(3,0,4) errors : -12559.17\n",
      " Regression with ARIMA(3,0,3) errors : -12529.19\n",
      " Regression with ARIMA(4,0,4) errors : -12555.94\n",
      " Regression with ARIMA(3,0,5) errors : -12539.67\n",
      " Regression with ARIMA(2,0,5) errors : -12558.37\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -12560.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12499.29\n",
      " Regression with ARIMA(0,0,0) errors : -8896.211\n",
      " Regression with ARIMA(1,0,0) errors : -12479.6\n",
      " Regression with ARIMA(0,0,1) errors : -10569.06\n",
      " Regression with ARIMA(0,0,0) errors : -7726.249\n",
      " Regression with ARIMA(1,0,2) errors : -12491.43\n",
      " Regression with ARIMA(2,0,1) errors : -12490.08\n",
      " Regression with ARIMA(3,0,2) errors : -12549.65\n",
      " Regression with ARIMA(3,0,1) errors : -12505.95\n",
      " Regression with ARIMA(4,0,2) errors : -12523.02\n",
      " Regression with ARIMA(3,0,3) errors : -12522.73\n",
      " Regression with ARIMA(2,0,3) errors : -12520.84\n",
      " Regression with ARIMA(4,0,1) errors : -12524.79\n",
      " Regression with ARIMA(4,0,3) errors : -12548.68\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12521.78\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12522.71\n",
      " Regression with ARIMA(0,0,0) errors : -8912.717\n",
      " Regression with ARIMA(1,0,0) errors : -12499.7\n",
      " Regression with ARIMA(0,0,1) errors : -10598.43\n",
      " Regression with ARIMA(0,0,0) errors : -7791.064\n",
      " Regression with ARIMA(1,0,2) errors : -12511.99\n",
      " Regression with ARIMA(2,0,1) errors : -12511.69\n",
      " Regression with ARIMA(3,0,2) errors : -12565.33\n",
      " Regression with ARIMA(3,0,1) errors : -12529.16\n",
      " Regression with ARIMA(4,0,2) errors : -12545.66\n",
      " Regression with ARIMA(3,0,3) errors : -12545.28\n",
      " Regression with ARIMA(2,0,3) errors : -12543.96\n",
      " Regression with ARIMA(4,0,1) errors : -12547.58\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12526.08\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.95\n",
      " Regression with ARIMA(0,0,0) errors : -8942.089\n",
      " Regression with ARIMA(1,0,0) errors : -12527.3\n",
      " Regression with ARIMA(0,0,1) errors : -10625.79\n",
      " Regression with ARIMA(0,0,0) errors : -7815.365\n",
      " Regression with ARIMA(1,0,2) errors : -12539.1\n",
      " Regression with ARIMA(2,0,1) errors : -12537.44\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12568.26\n",
      " Regression with ARIMA(1,0,3) errors : -12570.63\n",
      " Regression with ARIMA(0,0,3) errors : -11727.96\n",
      " Regression with ARIMA(1,0,4) errors : -12568.62\n",
      " Regression with ARIMA(0,0,2) errors : -11285.05\n",
      " Regression with ARIMA(0,0,4) errors : -12063.02\n",
      " Regression with ARIMA(2,0,4) errors : -12594.01\n",
      " Regression with ARIMA(3,0,4) errors : -12602.32\n",
      " Regression with ARIMA(3,0,3) errors : -12568.74\n",
      " Regression with ARIMA(4,0,4) errors : -12567.01\n",
      " Regression with ARIMA(3,0,5) errors : -12578.76\n",
      " Regression with ARIMA(2,0,5) errors : -12598.99\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12467.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -12600.43\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12532.16\n",
      " Regression with ARIMA(0,0,0) errors : -8934.83\n",
      " Regression with ARIMA(1,0,0) errors : -12512.55\n",
      " Regression with ARIMA(0,0,1) errors : -10617.82\n",
      " Regression with ARIMA(0,0,0) errors : -7779.834\n",
      " Regression with ARIMA(1,0,2) errors : -12525.18\n",
      " Regression with ARIMA(2,0,1) errors : -12523.58\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12554.76\n",
      " Regression with ARIMA(1,0,3) errors : -12557.17\n",
      " Regression with ARIMA(0,0,3) errors : -11723.56\n",
      " Regression with ARIMA(1,0,4) errors : -12555.2\n",
      " Regression with ARIMA(0,0,2) errors : -11272.84\n",
      " Regression with ARIMA(0,0,4) errors : -12053.22\n",
      " Regression with ARIMA(2,0,4) errors : -12583\n",
      " Regression with ARIMA(3,0,4) errors : -12586.36\n",
      " Regression with ARIMA(3,0,3) errors : -12555.78\n",
      " Regression with ARIMA(4,0,4) errors : -12586.4\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12572.16\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12559.34\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,5) errors : -12569.81\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : -12587.09\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12509.71\n",
      " Regression with ARIMA(0,0,0) errors : -8923.006\n",
      " Regression with ARIMA(1,0,0) errors : -12490.06\n",
      " Regression with ARIMA(0,0,1) errors : -10606.06\n",
      " Regression with ARIMA(0,0,0) errors : -7778.001\n",
      " Regression with ARIMA(1,0,2) errors : -12503.3\n",
      " Regression with ARIMA(2,0,1) errors : -12501.4\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12532.82\n",
      " Regression with ARIMA(1,0,3) errors : -12535.75\n",
      " Regression with ARIMA(0,0,3) errors : -11707.59\n",
      " Regression with ARIMA(1,0,4) errors : -12533.75\n",
      " Regression with ARIMA(0,0,2) errors : -11261.54\n",
      " Regression with ARIMA(0,0,4) errors : -12037.84\n",
      " Regression with ARIMA(2,0,4) errors : -12562.35\n",
      " Regression with ARIMA(3,0,4) errors : -12563.64\n",
      " Regression with ARIMA(3,0,3) errors : -12534.12\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12540.3\n",
      " Regression with ARIMA(2,0,5) errors : -12565.8\n",
      " Regression with ARIMA(1,0,5) errors : -12534.53\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12565.48\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12497.83\n",
      " Regression with ARIMA(0,0,0) errors : -8905.257\n",
      " Regression with ARIMA(1,0,0) errors : -12479.66\n",
      " Regression with ARIMA(0,0,1) errors : -10592.39\n",
      " Regression with ARIMA(0,0,0) errors : -7770.197\n",
      " Regression with ARIMA(1,0,2) errors : -12491.59\n",
      " Regression with ARIMA(2,0,1) errors : -12491.59\n",
      " Regression with ARIMA(3,0,2) errors : -12541.44\n",
      " Regression with ARIMA(3,0,1) errors : -12505.67\n",
      " Regression with ARIMA(4,0,2) errors : -12524.33\n",
      " Regression with ARIMA(3,0,3) errors : -12524.65\n",
      " Regression with ARIMA(2,0,3) errors : -12523.33\n",
      " Regression with ARIMA(4,0,1) errors : -12525.8\n",
      " Regression with ARIMA(4,0,3) errors : -12554.64\n",
      " Regression with ARIMA(5,0,3) errors : -12551.24\n",
      " Regression with ARIMA(4,0,4) errors : -12549.94\n",
      " Regression with ARIMA(3,0,4) errors : -12553.02\n",
      " Regression with ARIMA(5,0,2) errors : -12548.7\n",
      " Regression with ARIMA(5,0,4) errors : -12528.29\n",
      " Regression with ARIMA(4,0,3) errors : -12482.77\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12554.1\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12497.83\n",
      " Regression with ARIMA(0,0,0) errors : -8898.064\n",
      " Regression with ARIMA(1,0,0) errors : -12477.67\n",
      " Regression with ARIMA(0,0,1) errors : -10586.17\n",
      " Regression with ARIMA(0,0,0) errors : -7763.444\n",
      " Regression with ARIMA(1,0,2) errors : -12489.24\n",
      " Regression with ARIMA(2,0,1) errors : -12490.62\n",
      " Regression with ARIMA(3,0,2) errors : -12555.3\n",
      " Regression with ARIMA(3,0,1) errors : -12503.83\n",
      " Regression with ARIMA(4,0,2) errors : -12522.97\n",
      " Regression with ARIMA(3,0,3) errors : -12522.77\n",
      " Regression with ARIMA(2,0,3) errors : -12522.46\n",
      " Regression with ARIMA(4,0,1) errors : -12524.5\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12474.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12523.61\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12513.83\n",
      " Regression with ARIMA(0,0,0) errors : -8943.164\n",
      " Regression with ARIMA(1,0,0) errors : -12488.42\n",
      " Regression with ARIMA(0,0,1) errors : -10621.1\n",
      " Regression with ARIMA(0,0,0) errors : -7868.129\n",
      " Regression with ARIMA(1,0,2) errors : -12499.53\n",
      " Regression with ARIMA(2,0,1) errors : -12510\n",
      " Regression with ARIMA(3,0,2) errors : -12538.21\n",
      " Regression with ARIMA(3,0,1) errors : -12522.06\n",
      " Regression with ARIMA(4,0,2) errors : -12545.22\n",
      " Regression with ARIMA(4,0,1) errors : -12546.86\n",
      " Regression with ARIMA(4,0,0) errors : -12546.27\n",
      " Regression with ARIMA(5,0,1) errors : -12549.63\n",
      " Regression with ARIMA(5,0,0) errors : -12550.19\n",
      " Regression with ARIMA(5,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,0) errors : -12530.49\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12537.41\n",
      " Regression with ARIMA(0,0,0) errors : -8980.404\n",
      " Regression with ARIMA(1,0,0) errors : -12515.87\n",
      " Regression with ARIMA(0,0,1) errors : -10652.29\n",
      " Regression with ARIMA(0,0,0) errors : -7878.327\n",
      " Regression with ARIMA(1,0,2) errors : -12530.48\n",
      " Regression with ARIMA(2,0,1) errors : -12528.68\n",
      " Regression with ARIMA(3,0,2) errors : -12554.48\n",
      " Regression with ARIMA(3,0,1) errors : -12543.44\n",
      " Regression with ARIMA(4,0,2) errors : -12559.77\n",
      " Regression with ARIMA(4,0,1) errors : -12561.17\n",
      " Regression with ARIMA(4,0,0) errors : -12562.64\n",
      " Regression with ARIMA(3,0,0) errors : -12534.45\n",
      " Regression with ARIMA(5,0,0) errors : -12560.32\n",
      " Regression with ARIMA(5,0,1) errors : -12583.89\n",
      " Regression with ARIMA(5,0,2) errors : -12582.7\n",
      " Regression with ARIMA(5,0,1) errors : -12494.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12584.44\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.24\n",
      " Regression with ARIMA(0,0,0) errors : -8985.481\n",
      " Regression with ARIMA(1,0,0) errors : -12523.97\n",
      " Regression with ARIMA(0,0,1) errors : -10655.97\n",
      " Regression with ARIMA(0,0,0) errors : -7884.878\n",
      " Regression with ARIMA(1,0,2) errors : -12538.88\n",
      " Regression with ARIMA(2,0,1) errors : -12537.23\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12566.95\n",
      " Regression with ARIMA(1,0,3) errors : -12569.82\n",
      " Regression with ARIMA(0,0,3) errors : -11754.84\n",
      " Regression with ARIMA(1,0,4) errors : -12567.97\n",
      " Regression with ARIMA(0,0,2) errors : -11299.19\n",
      " Regression with ARIMA(0,0,4) errors : -12073.38\n",
      " Regression with ARIMA(2,0,4) errors : -12592.97\n",
      " Regression with ARIMA(3,0,4) errors : -12597.31\n",
      " Regression with ARIMA(3,0,3) errors : -12567.29\n",
      " Regression with ARIMA(4,0,4) errors : -12596.6\n",
      " Regression with ARIMA(3,0,5) errors : -12570.58\n",
      " Regression with ARIMA(2,0,5) errors : -12597.68\n",
      " Regression with ARIMA(1,0,5) errors : -12568.02\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12597.69\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12546.78\n",
      " Regression with ARIMA(0,0,0) errors : -8970.223\n",
      " Regression with ARIMA(1,0,0) errors : -12525.95\n",
      " Regression with ARIMA(0,0,1) errors : -10649.53\n",
      " Regression with ARIMA(0,0,0) errors : -7878.626\n",
      " Regression with ARIMA(1,0,2) errors : -12540.83\n",
      " Regression with ARIMA(2,0,1) errors : -12539.25\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12568.27\n",
      " Regression with ARIMA(1,0,3) errors : -12571.19\n",
      " Regression with ARIMA(0,0,3) errors : -11751.13\n",
      " Regression with ARIMA(1,0,4) errors : -12569.31\n",
      " Regression with ARIMA(0,0,2) errors : -11296.38\n",
      " Regression with ARIMA(0,0,4) errors : -12067\n",
      " Regression with ARIMA(2,0,4) errors : -12594.34\n",
      " Regression with ARIMA(3,0,4) errors : -12595.54\n",
      " Regression with ARIMA(3,0,3) errors : -12568.5\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12574.84\n",
      " Regression with ARIMA(2,0,5) errors : -12598.8\n",
      " Regression with ARIMA(1,0,5) errors : -12569.08\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12597.59\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.79\n",
      " Regression with ARIMA(0,0,0) errors : -8964.909\n",
      " Regression with ARIMA(1,0,0) errors : -12525.68\n",
      " Regression with ARIMA(0,0,1) errors : -10646.25\n",
      " Regression with ARIMA(0,0,0) errors : -7885.222\n",
      " Regression with ARIMA(1,0,2) errors : -12540.83\n",
      " Regression with ARIMA(2,0,1) errors : -12539.59\n",
      " Regression with ARIMA(3,0,2) errors : -12603.07\n",
      " Regression with ARIMA(3,0,1) errors : -12554.12\n",
      " Regression with ARIMA(4,0,2) errors : -12569.57\n",
      " Regression with ARIMA(3,0,3) errors : -12569.71\n",
      " Regression with ARIMA(2,0,3) errors : -12568.45\n",
      " Regression with ARIMA(4,0,1) errors : -12570.93\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12494.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12570.9\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12548.69\n",
      " Regression with ARIMA(0,0,0) errors : -8959.862\n",
      " Regression with ARIMA(1,0,0) errors : -12529.05\n",
      " Regression with ARIMA(0,0,1) errors : -10643.71\n",
      " Regression with ARIMA(0,0,0) errors : -7886.635\n",
      " Regression with ARIMA(1,0,2) errors : -12544.11\n",
      " Regression with ARIMA(2,0,1) errors : -12544.13\n",
      " Regression with ARIMA(3,0,2) errors : -12571.06\n",
      " Regression with ARIMA(3,0,1) errors : -12561.51\n",
      " Regression with ARIMA(4,0,2) errors : -12576.07\n",
      " Regression with ARIMA(4,0,1) errors : -12578.07\n",
      " Regression with ARIMA(4,0,0) errors : -12579.62\n",
      " Regression with ARIMA(3,0,0) errors : -12551.25\n",
      " Regression with ARIMA(5,0,0) errors : -12579.64\n",
      " Regression with ARIMA(5,0,1) errors : Inf\n",
      " Regression with ARIMA(5,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,0) errors : -12575.23\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12551.97\n",
      " Regression with ARIMA(0,0,0) errors : -8967.683\n",
      " Regression with ARIMA(1,0,0) errors : -12529.69\n",
      " Regression with ARIMA(0,0,1) errors : -10653.67\n",
      " Regression with ARIMA(0,0,0) errors : -7896.484\n",
      " Regression with ARIMA(1,0,2) errors : -12544.97\n",
      " Regression with ARIMA(2,0,1) errors : -12543.7\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12573.37\n",
      " Regression with ARIMA(1,0,3) errors : -12575.68\n",
      " Regression with ARIMA(0,0,3) errors : -11753.95\n",
      " Regression with ARIMA(1,0,4) errors : -12573.8\n",
      " Regression with ARIMA(0,0,2) errors : -11300.67\n",
      " Regression with ARIMA(0,0,4) errors : -12074.69\n",
      " Regression with ARIMA(2,0,4) errors : -12591.45\n",
      " Regression with ARIMA(3,0,4) errors : -12595.99\n",
      " Regression with ARIMA(3,0,3) errors : -12573.8\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12580.86\n",
      " Regression with ARIMA(2,0,5) errors : -12597\n",
      " Regression with ARIMA(1,0,5) errors : -12573.86\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12603.04\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12556.25\n",
      " Regression with ARIMA(0,0,0) errors : -8962.755\n",
      " Regression with ARIMA(1,0,0) errors : -12535.8\n",
      " Regression with ARIMA(0,0,1) errors : -10648.64\n",
      " Regression with ARIMA(0,0,0) errors : -7898.839\n",
      " Regression with ARIMA(1,0,2) errors : -12550.14\n",
      " Regression with ARIMA(2,0,1) errors : -12548.54\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12578.72\n",
      " Regression with ARIMA(1,0,3) errors : -12581.63\n",
      " Regression with ARIMA(0,0,3) errors : -11752.88\n",
      " Regression with ARIMA(1,0,4) errors : -12579.7\n",
      " Regression with ARIMA(0,0,2) errors : -11299.22\n",
      " Regression with ARIMA(0,0,4) errors : -12072.91\n",
      " Regression with ARIMA(2,0,4) errors : -12605.06\n",
      " Regression with ARIMA(3,0,4) errors : -12603.2\n",
      " Regression with ARIMA(2,0,5) errors : -12609.26\n",
      " Regression with ARIMA(1,0,5) errors : -12579.72\n",
      " Regression with ARIMA(3,0,5) errors : -12582.04\n",
      " Regression with ARIMA(2,0,5) errors : -12540.55\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12607.82\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12570.6\n",
      " Regression with ARIMA(0,0,0) errors : -8967.56\n",
      " Regression with ARIMA(1,0,0) errors : -12549.25\n",
      " Regression with ARIMA(0,0,1) errors : -10654.34\n",
      " Regression with ARIMA(0,0,0) errors : -7906.854\n",
      " Regression with ARIMA(1,0,2) errors : -12564.03\n",
      " Regression with ARIMA(2,0,1) errors : -12563.91\n",
      " Regression with ARIMA(3,0,2) errors : -12627.87\n",
      " Regression with ARIMA(3,0,1) errors : -12577.27\n",
      " Regression with ARIMA(4,0,2) errors : -12593.34\n",
      " Regression with ARIMA(3,0,3) errors : -12593.82\n",
      " Regression with ARIMA(2,0,3) errors : -12593.22\n",
      " Regression with ARIMA(4,0,1) errors : -12594.72\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12522.09\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12594.39\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12576.56\n",
      " Regression with ARIMA(0,0,0) errors : -8968.532\n",
      " Regression with ARIMA(1,0,0) errors : -12555.14\n",
      " Regression with ARIMA(0,0,1) errors : -10657.19\n",
      " Regression with ARIMA(0,0,0) errors : -7936.331\n",
      " Regression with ARIMA(1,0,2) errors : -12569.91\n",
      " Regression with ARIMA(2,0,1) errors : -12570.88\n",
      " Regression with ARIMA(3,0,2) errors : -12594.83\n",
      " Regression with ARIMA(3,0,1) errors : -12583.62\n",
      " Regression with ARIMA(4,0,2) errors : -12601.21\n",
      " Regression with ARIMA(4,0,1) errors : -12602.62\n",
      " Regression with ARIMA(4,0,0) errors : -12603.98\n",
      " Regression with ARIMA(3,0,0) errors : -12574.44\n",
      " Regression with ARIMA(5,0,0) errors : -12601.82\n",
      " Regression with ARIMA(5,0,1) errors : -12626.33\n",
      " Regression with ARIMA(5,0,2) errors : -12625.22\n",
      " Regression with ARIMA(5,0,1) errors : -12547.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12620.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12601.85\n",
      " Regression with ARIMA(0,0,0) errors : -9048.224\n",
      " Regression with ARIMA(1,0,0) errors : -12582.93\n",
      " Regression with ARIMA(0,0,1) errors : -10732.82\n",
      " Regression with ARIMA(0,0,0) errors : -8067.123\n",
      " Regression with ARIMA(1,0,2) errors : -12598.44\n",
      " Regression with ARIMA(2,0,1) errors : -12601.12\n",
      " Regression with ARIMA(3,0,2) errors : -12619.05\n",
      " Regression with ARIMA(3,0,1) errors : -12618.74\n",
      " Regression with ARIMA(4,0,2) errors : -12650.56\n",
      " Regression with ARIMA(4,0,1) errors : -12652.27\n",
      " Regression with ARIMA(4,0,0) errors : -12652.06\n",
      " Regression with ARIMA(5,0,1) errors : -12662.55\n",
      " Regression with ARIMA(5,0,0) errors : -12658.45\n",
      " Regression with ARIMA(5,0,2) errors : -12663.08\n",
      " Regression with ARIMA(5,0,3) errors : -12661.14\n",
      " Regression with ARIMA(4,0,3) errors : -12649.44\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -12652.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12607.62\n",
      " Regression with ARIMA(0,0,0) errors : -9029.222\n",
      " Regression with ARIMA(1,0,0) errors : -12581.78\n",
      " Regression with ARIMA(0,0,1) errors : -10679.8\n",
      " Regression with ARIMA(0,0,0) errors : -7988.616\n",
      " Regression with ARIMA(1,0,2) errors : -12606.76\n",
      " Regression with ARIMA(2,0,1) errors : -12606.03\n",
      " Regression with ARIMA(3,0,2) errors : -12633.3\n",
      " Regression with ARIMA(3,0,1) errors : -12616.63\n",
      " Regression with ARIMA(4,0,2) errors : -12637.18\n",
      " Regression with ARIMA(4,0,1) errors : -12639.14\n",
      " Regression with ARIMA(4,0,0) errors : -12638.63\n",
      " Regression with ARIMA(5,0,1) errors : -12657.77\n",
      " Regression with ARIMA(5,0,0) errors : -12639.34\n",
      " Regression with ARIMA(5,0,2) errors : -12656.11\n",
      " Regression with ARIMA(5,0,1) errors : -12576.93\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12665.38\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12515.14\n",
      " Regression with ARIMA(0,1,0) errors : -12443.47\n",
      " Regression with ARIMA(1,1,0) errors : -12487.68\n",
      " Regression with ARIMA(0,1,1) errors : -12495.53\n",
      " Regression with ARIMA(0,1,0) errors : -12445.47\n",
      " Regression with ARIMA(1,1,2) errors : -12499.79\n",
      " Regression with ARIMA(2,1,1) errors : -12505.72\n",
      " Regression with ARIMA(3,1,2) errors : -12545.83\n",
      " Regression with ARIMA(3,1,1) errors : -12512.71\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -12547.75\n",
      " Regression with ARIMA(2,1,2) errors : -12517.15\n",
      " Regression with ARIMA(3,1,1) errors : -12514.72\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -12507.73\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12527.28\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12606.67\n",
      " Regression with ARIMA(0,0,0) errors : -9078.123\n",
      " Regression with ARIMA(1,0,0) errors : -12575.25\n",
      " Regression with ARIMA(0,0,1) errors : -10725.64\n",
      " Regression with ARIMA(0,0,0) errors : -8063.193\n",
      " Regression with ARIMA(1,0,2) errors : -12597.15\n",
      " Regression with ARIMA(2,0,1) errors : -12601.19\n",
      " Regression with ARIMA(3,0,2) errors : -12625.54\n",
      " Regression with ARIMA(3,0,1) errors : -12611.94\n",
      " Regression with ARIMA(4,0,2) errors : -12627.49\n",
      " Regression with ARIMA(4,0,1) errors : -12627.75\n",
      " Regression with ARIMA(4,0,0) errors : -12627.47\n",
      " Regression with ARIMA(5,0,1) errors : -12646.75\n",
      " Regression with ARIMA(5,0,0) errors : -12630.02\n",
      " Regression with ARIMA(5,0,2) errors : -12645.2\n",
      " Regression with ARIMA(5,0,1) errors : -12548.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12650.4\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12592.63\n",
      " Regression with ARIMA(0,0,0) errors : -9082.048\n",
      " Regression with ARIMA(1,0,0) errors : -12566.66\n",
      " Regression with ARIMA(0,0,1) errors : -10726.09\n",
      " Regression with ARIMA(0,0,0) errors : -8059.077\n",
      " Regression with ARIMA(1,0,2) errors : -12588.96\n",
      " Regression with ARIMA(2,0,1) errors : -12589.11\n",
      " Regression with ARIMA(3,0,2) errors : -12638.23\n",
      " Regression with ARIMA(3,0,1) errors : -12600.16\n",
      " Regression with ARIMA(4,0,2) errors : -12617.62\n",
      " Regression with ARIMA(3,0,3) errors : -12618.48\n",
      " Regression with ARIMA(2,0,3) errors : -12614.14\n",
      " Regression with ARIMA(4,0,1) errors : -12616.7\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12548.15\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12652.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12584\n",
      " Regression with ARIMA(0,0,0) errors : -9072.623\n",
      " Regression with ARIMA(1,0,0) errors : -12558.92\n",
      " Regression with ARIMA(0,0,1) errors : -10724.45\n",
      " Regression with ARIMA(0,0,0) errors : -8059.797\n",
      " Regression with ARIMA(1,0,2) errors : -12579.62\n",
      " Regression with ARIMA(2,0,1) errors : -12579.45\n",
      " Regression with ARIMA(3,0,2) errors : -12637.15\n",
      " Regression with ARIMA(3,0,1) errors : -12590.09\n",
      " Regression with ARIMA(4,0,2) errors : -12609.14\n",
      " Regression with ARIMA(3,0,3) errors : -12608.81\n",
      " Regression with ARIMA(2,0,3) errors : -12605.33\n",
      " Regression with ARIMA(4,0,1) errors : -12609.45\n",
      " Regression with ARIMA(4,0,3) errors : -12638.04\n",
      " Regression with ARIMA(5,0,3) errors : -12624.89\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12633.6\n",
      " Regression with ARIMA(5,0,2) errors : -12623.44\n",
      " Regression with ARIMA(5,0,4) errors : -12618.15\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12645.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12597.56\n",
      " Regression with ARIMA(0,0,0) errors : -9087.133\n",
      " Regression with ARIMA(1,0,0) errors : -12572.15\n",
      " Regression with ARIMA(0,0,1) errors : -10736.93\n",
      " Regression with ARIMA(0,0,0) errors : -8079.117\n",
      " Regression with ARIMA(1,0,2) errors : -12594.14\n",
      " Regression with ARIMA(2,0,1) errors : -12593.03\n",
      " Regression with ARIMA(3,0,2) errors : -12658.36\n",
      " Regression with ARIMA(3,0,1) errors : -12603.77\n",
      " Regression with ARIMA(4,0,2) errors : -12622.07\n",
      " Regression with ARIMA(3,0,3) errors : -12622.59\n",
      " Regression with ARIMA(2,0,3) errors : -12619.12\n",
      " Regression with ARIMA(4,0,1) errors : -12620.82\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12548.61\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12655.81\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12610.85\n",
      " Regression with ARIMA(0,0,0) errors : -9095.509\n",
      " Regression with ARIMA(1,0,0) errors : -12584.86\n",
      " Regression with ARIMA(0,0,1) errors : -10749.33\n",
      " Regression with ARIMA(0,0,0) errors : -8097.852\n",
      " Regression with ARIMA(1,0,2) errors : -12606.97\n",
      " Regression with ARIMA(2,0,1) errors : -12608.39\n",
      " Regression with ARIMA(3,0,2) errors : -12658.34\n",
      " Regression with ARIMA(3,0,1) errors : -12619.38\n",
      " Regression with ARIMA(4,0,2) errors : -12636.67\n",
      " Regression with ARIMA(3,0,3) errors : -12637.2\n",
      " Regression with ARIMA(2,0,3) errors : -12634.49\n",
      " Regression with ARIMA(4,0,1) errors : -12636.79\n",
      " Regression with ARIMA(4,0,3) errors : -12679.01\n",
      " Regression with ARIMA(5,0,3) errors : -12665.31\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12669.72\n",
      " Regression with ARIMA(5,0,2) errors : -12665.96\n",
      " Regression with ARIMA(5,0,4) errors : -12644.1\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12661.83\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.42\n",
      " Regression with ARIMA(0,0,0) errors : -9117.955\n",
      " Regression with ARIMA(1,0,0) errors : -12604.61\n",
      " Regression with ARIMA(0,0,1) errors : -10769.78\n",
      " Regression with ARIMA(0,0,0) errors : -8106.906\n",
      " Regression with ARIMA(1,0,2) errors : -12626.91\n",
      " Regression with ARIMA(2,0,1) errors : -12625.67\n",
      " Regression with ARIMA(3,0,2) errors : -12690.09\n",
      " Regression with ARIMA(3,0,1) errors : -12637.43\n",
      " Regression with ARIMA(4,0,2) errors : -12655.81\n",
      " Regression with ARIMA(3,0,3) errors : -12655.49\n",
      " Regression with ARIMA(2,0,3) errors : -12652.79\n",
      " Regression with ARIMA(4,0,1) errors : -12654.8\n",
      " Regression with ARIMA(4,0,3) errors : -12693.24\n",
      " Regression with ARIMA(5,0,3) errors : -12662.02\n",
      " Regression with ARIMA(4,0,4) errors : -12671.03\n",
      " Regression with ARIMA(3,0,4) errors : -12677.48\n",
      " Regression with ARIMA(5,0,2) errors : -12662.99\n",
      " Regression with ARIMA(5,0,4) errors : -12675.56\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12692.59\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12641.13\n",
      " Regression with ARIMA(0,0,0) errors : -9120.512\n",
      " Regression with ARIMA(1,0,0) errors : -12614.69\n",
      " Regression with ARIMA(0,0,1) errors : -10777.29\n",
      " Regression with ARIMA(0,0,0) errors : -8113.97\n",
      " Regression with ARIMA(1,0,2) errors : -12636.3\n",
      " Regression with ARIMA(2,0,1) errors : -12634.97\n",
      " Regression with ARIMA(3,0,2) errors : -12703.57\n",
      " Regression with ARIMA(3,0,1) errors : -12648.05\n",
      " Regression with ARIMA(4,0,2) errors : -12667.51\n",
      " Regression with ARIMA(3,0,3) errors : -12666.81\n",
      " Regression with ARIMA(2,0,3) errors : -12663.2\n",
      " Regression with ARIMA(4,0,1) errors : -12665.98\n",
      " Regression with ARIMA(4,0,3) errors : -12703.17\n",
      " Regression with ARIMA(3,0,2) errors : -12608.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.93\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12643.6\n",
      " Regression with ARIMA(0,0,0) errors : -9119.216\n",
      " Regression with ARIMA(1,0,0) errors : -12616.26\n",
      " Regression with ARIMA(0,0,1) errors : -10777.52\n",
      " Regression with ARIMA(0,0,0) errors : -8101.041\n",
      " Regression with ARIMA(1,0,2) errors : -12637.47\n",
      " Regression with ARIMA(2,0,1) errors : -12640.52\n",
      " Regression with ARIMA(3,0,2) errors : -12680.71\n",
      " Regression with ARIMA(3,0,1) errors : -12652.57\n",
      " Regression with ARIMA(4,0,2) errors : -12672.29\n",
      " Regression with ARIMA(3,0,3) errors : -12671.04\n",
      " Regression with ARIMA(2,0,3) errors : -12668.46\n",
      " Regression with ARIMA(4,0,1) errors : -12671.99\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12605.13\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12704.4\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12641.82\n",
      " Regression with ARIMA(0,0,0) errors : -9125.129\n",
      " Regression with ARIMA(1,0,0) errors : -12617.13\n",
      " Regression with ARIMA(0,0,1) errors : -10783.88\n",
      " Regression with ARIMA(0,0,0) errors : -8122.685\n",
      " Regression with ARIMA(1,0,2) errors : -12638.09\n",
      " Regression with ARIMA(2,0,1) errors : -12636.93\n",
      " Regression with ARIMA(3,0,2) errors : -12695.39\n",
      " Regression with ARIMA(3,0,1) errors : -12649.51\n",
      " Regression with ARIMA(4,0,2) errors : -12667.03\n",
      " Regression with ARIMA(3,0,3) errors : -12667.49\n",
      " Regression with ARIMA(2,0,3) errors : -12664.06\n",
      " Regression with ARIMA(4,0,1) errors : -12666.82\n",
      " Regression with ARIMA(4,0,3) errors : -12707.83\n",
      " Regression with ARIMA(5,0,3) errors : -12686.77\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12686.56\n",
      " Regression with ARIMA(5,0,2) errors : -12685.94\n",
      " Regression with ARIMA(5,0,4) errors : -12670.08\n",
      " Regression with ARIMA(4,0,3) errors : -12637.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12704.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12640.83\n",
      " Regression with ARIMA(0,0,0) errors : -9124.201\n",
      " Regression with ARIMA(1,0,0) errors : -12614.79\n",
      " Regression with ARIMA(0,0,1) errors : -10783.44\n",
      " Regression with ARIMA(0,0,0) errors : -8122.209\n",
      " Regression with ARIMA(1,0,2) errors : -12635.64\n",
      " Regression with ARIMA(2,0,1) errors : -12634.86\n",
      " Regression with ARIMA(3,0,2) errors : -12695.41\n",
      " Regression with ARIMA(3,0,1) errors : -12647.57\n",
      " Regression with ARIMA(4,0,2) errors : -12665.91\n",
      " Regression with ARIMA(3,0,3) errors : -12665.62\n",
      " Regression with ARIMA(2,0,3) errors : -12662.3\n",
      " Regression with ARIMA(4,0,1) errors : -12664.73\n",
      " Regression with ARIMA(4,0,3) errors : -12708.36\n",
      " Regression with ARIMA(5,0,3) errors : -12683.74\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12676.17\n",
      " Regression with ARIMA(4,0,3) errors : -12636.53\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12702.9\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.35\n",
      " Regression with ARIMA(0,0,0) errors : -9121.854\n",
      " Regression with ARIMA(1,0,0) errors : -12613.51\n",
      " Regression with ARIMA(0,0,1) errors : -10782.18\n",
      " Regression with ARIMA(0,0,0) errors : -8117.61\n",
      " Regression with ARIMA(1,0,2) errors : -12633.27\n",
      " Regression with ARIMA(2,0,1) errors : -12632.06\n",
      " Regression with ARIMA(3,0,2) errors : -12698.45\n",
      " Regression with ARIMA(3,0,1) errors : -12643.7\n",
      " Regression with ARIMA(4,0,2) errors : -12660.83\n",
      " Regression with ARIMA(3,0,3) errors : -12661.66\n",
      " Regression with ARIMA(2,0,3) errors : -12658.11\n",
      " Regression with ARIMA(4,0,1) errors : -12659.62\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12597.25\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12700.82\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.09\n",
      " Regression with ARIMA(0,0,0) errors : -9116.676\n",
      " Regression with ARIMA(1,0,0) errors : -12611.67\n",
      " Regression with ARIMA(0,0,1) errors : -10780.74\n",
      " Regression with ARIMA(0,0,0) errors : -8116.581\n",
      " Regression with ARIMA(1,0,2) errors : -12630.99\n",
      " Regression with ARIMA(2,0,1) errors : -12629.63\n",
      " Regression with ARIMA(3,0,2) errors : -12699.18\n",
      " Regression with ARIMA(3,0,1) errors : -12641.18\n",
      " Regression with ARIMA(4,0,2) errors : -12658.75\n",
      " Regression with ARIMA(3,0,3) errors : -12659.44\n",
      " Regression with ARIMA(2,0,3) errors : -12655.65\n",
      " Regression with ARIMA(4,0,1) errors : -12657.53\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12615.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12699.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12639.03\n",
      " Regression with ARIMA(0,0,0) errors : -9117.537\n",
      " Regression with ARIMA(1,0,0) errors : -12615.18\n",
      " Regression with ARIMA(0,0,1) errors : -10783.7\n",
      " Regression with ARIMA(0,0,0) errors : -8118.136\n",
      " Regression with ARIMA(1,0,2) errors : -12634.65\n",
      " Regression with ARIMA(2,0,1) errors : -12633.24\n",
      " Regression with ARIMA(3,0,2) errors : -12699.98\n",
      " Regression with ARIMA(3,0,1) errors : -12645.33\n",
      " Regression with ARIMA(4,0,2) errors : -12662.46\n",
      " Regression with ARIMA(3,0,3) errors : -12663.29\n",
      " Regression with ARIMA(2,0,3) errors : -12659.28\n",
      " Regression with ARIMA(4,0,1) errors : -12661.46\n",
      " Regression with ARIMA(4,0,3) errors : -12704.33\n",
      " Regression with ARIMA(5,0,3) errors : -12680.72\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12676.03\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12672.54\n",
      " Regression with ARIMA(4,0,3) errors : -12599.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12703.36\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.78\n",
      " Regression with ARIMA(0,0,0) errors : -9113.603\n",
      " Regression with ARIMA(1,0,0) errors : -12610.36\n",
      " Regression with ARIMA(0,0,1) errors : -10781.97\n",
      " Regression with ARIMA(0,0,0) errors : -8111.354\n",
      " Regression with ARIMA(1,0,2) errors : -12629.21\n",
      " Regression with ARIMA(2,0,1) errors : -12627.93\n",
      " Regression with ARIMA(3,0,2) errors : -12693.18\n",
      " Regression with ARIMA(3,0,1) errors : -12639.63\n",
      " Regression with ARIMA(4,0,2) errors : -12657.34\n",
      " Regression with ARIMA(3,0,3) errors : -12657.78\n",
      " Regression with ARIMA(2,0,3) errors : -12654.23\n",
      " Regression with ARIMA(4,0,1) errors : -12656.4\n",
      " Regression with ARIMA(4,0,3) errors : -12699.31\n",
      " Regression with ARIMA(5,0,3) errors : -12674.55\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12675.54\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12667.95\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.07\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.46\n",
      " Regression with ARIMA(0,0,0) errors : -9119.245\n",
      " Regression with ARIMA(1,0,0) errors : -12613.96\n",
      " Regression with ARIMA(0,0,1) errors : -10785.81\n",
      " Regression with ARIMA(0,0,0) errors : -8116.382\n",
      " Regression with ARIMA(1,0,2) errors : -12632.76\n",
      " Regression with ARIMA(2,0,1) errors : -12631.28\n",
      " Regression with ARIMA(3,0,2) errors : -12700.56\n",
      " Regression with ARIMA(3,0,1) errors : -12643.51\n",
      " Regression with ARIMA(4,0,2) errors : -12660.35\n",
      " Regression with ARIMA(3,0,3) errors : -12660.75\n",
      " Regression with ARIMA(2,0,3) errors : -12657.34\n",
      " Regression with ARIMA(4,0,1) errors : -12659.28\n",
      " Regression with ARIMA(4,0,3) errors : -12705.25\n",
      " Regression with ARIMA(5,0,3) errors : -12677.25\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12659.26\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12674.2\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12701.28\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.91\n",
      " Regression with ARIMA(0,0,0) errors : -9115.346\n",
      " Regression with ARIMA(1,0,0) errors : -12609.25\n",
      " Regression with ARIMA(0,0,1) errors : -10783.59\n",
      " Regression with ARIMA(0,0,0) errors : -8119.022\n",
      " Regression with ARIMA(1,0,2) errors : -12628.07\n",
      " Regression with ARIMA(2,0,1) errors : -12626.55\n",
      " Regression with ARIMA(3,0,2) errors : -12695.08\n",
      " Regression with ARIMA(3,0,1) errors : -12639.09\n",
      " Regression with ARIMA(4,0,2) errors : -12655.57\n",
      " Regression with ARIMA(3,0,3) errors : -12655.97\n",
      " Regression with ARIMA(2,0,3) errors : -12652.64\n",
      " Regression with ARIMA(4,0,1) errors : -12654.48\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12608.86\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12697.61\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12634.77\n",
      " Regression with ARIMA(0,0,0) errors : -9112.722\n",
      " Regression with ARIMA(1,0,0) errors : -12611.67\n",
      " Regression with ARIMA(0,0,1) errors : -10782.69\n",
      " Regression with ARIMA(0,0,0) errors : -8118.407\n",
      " Regression with ARIMA(1,0,2) errors : -12630.3\n",
      " Regression with ARIMA(2,0,1) errors : -12628.79\n",
      " Regression with ARIMA(3,0,2) errors : -12698.97\n",
      " Regression with ARIMA(3,0,1) errors : -12640.78\n",
      " Regression with ARIMA(4,0,2) errors : -12656.92\n",
      " Regression with ARIMA(3,0,3) errors : -12657.7\n",
      " Regression with ARIMA(2,0,3) errors : -12654.48\n",
      " Regression with ARIMA(4,0,1) errors : -12655.94\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12604.1\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12699.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.36\n",
      " Regression with ARIMA(0,0,0) errors : -9119.25\n",
      " Regression with ARIMA(1,0,0) errors : -12613.66\n",
      " Regression with ARIMA(0,0,1) errors : -10784.04\n",
      " Regression with ARIMA(0,0,0) errors : -8121.82\n",
      " Regression with ARIMA(1,0,2) errors : -12632.84\n",
      " Regression with ARIMA(2,0,1) errors : -12631.38\n",
      " Regression with ARIMA(3,0,2) errors : -12686.69\n",
      " Regression with ARIMA(3,0,1) errors : -12643.65\n",
      " Regression with ARIMA(4,0,2) errors : -12661.74\n",
      " Regression with ARIMA(3,0,3) errors : -12661.05\n",
      " Regression with ARIMA(2,0,3) errors : -12657.15\n",
      " Regression with ARIMA(4,0,1) errors : -12661.45\n",
      " Regression with ARIMA(4,0,3) errors : -12661.55\n",
      " Regression with ARIMA(3,0,2) errors : -12592.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.86\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.03\n",
      " Regression with ARIMA(0,0,0) errors : -9124.803\n",
      " Regression with ARIMA(1,0,0) errors : -12611.58\n",
      " Regression with ARIMA(0,0,1) errors : -10785.79\n",
      " Regression with ARIMA(0,0,0) errors : -8120.735\n",
      " Regression with ARIMA(1,0,2) errors : -12631.26\n",
      " Regression with ARIMA(2,0,1) errors : -12629.83\n",
      " Regression with ARIMA(3,0,2) errors : -12695.7\n",
      " Regression with ARIMA(3,0,1) errors : -12642.68\n",
      " Regression with ARIMA(4,0,2) errors : -12659.94\n",
      " Regression with ARIMA(3,0,3) errors : -12660.68\n",
      " Regression with ARIMA(2,0,3) errors : -12655.54\n",
      " Regression with ARIMA(4,0,1) errors : -12658.46\n",
      " Regression with ARIMA(4,0,3) errors : -12702.36\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12659.16\n",
      " Regression with ARIMA(5,0,2) errors : -12657.49\n",
      " Regression with ARIMA(5,0,4) errors : -12659.7\n",
      " Regression with ARIMA(4,0,3) errors : -12584.34\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.35\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12639.64\n",
      " Regression with ARIMA(0,0,0) errors : -9126.097\n",
      " Regression with ARIMA(1,0,0) errors : -12614.91\n",
      " Regression with ARIMA(0,0,1) errors : -10785.02\n",
      " Regression with ARIMA(0,0,0) errors : -8116.995\n",
      " Regression with ARIMA(1,0,2) errors : -12635.07\n",
      " Regression with ARIMA(2,0,1) errors : -12633.58\n",
      " Regression with ARIMA(3,0,2) errors : -12700.58\n",
      " Regression with ARIMA(3,0,1) errors : -12646.01\n",
      " Regression with ARIMA(4,0,2) errors : -12662.46\n",
      " Regression with ARIMA(3,0,3) errors : -12663.22\n",
      " Regression with ARIMA(2,0,3) errors : -12659.45\n",
      " Regression with ARIMA(4,0,1) errors : -12661.32\n",
      " Regression with ARIMA(4,0,3) errors : -12707.82\n",
      " Regression with ARIMA(5,0,3) errors : -12680.87\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.94\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12674.86\n",
      " Regression with ARIMA(4,0,3) errors : -12602.62\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12703.26\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.76\n",
      " Regression with ARIMA(0,0,0) errors : -9126.664\n",
      " Regression with ARIMA(1,0,0) errors : -12610.17\n",
      " Regression with ARIMA(0,0,1) errors : -10784.22\n",
      " Regression with ARIMA(0,0,0) errors : -8120.924\n",
      " Regression with ARIMA(1,0,2) errors : -12630.62\n",
      " Regression with ARIMA(2,0,1) errors : -12629.52\n",
      " Regression with ARIMA(3,0,2) errors : -12694.59\n",
      " Regression with ARIMA(3,0,1) errors : -12642.09\n",
      " Regression with ARIMA(4,0,2) errors : -12658.44\n",
      " Regression with ARIMA(3,0,3) errors : -12658.75\n",
      " Regression with ARIMA(2,0,3) errors : -12655.04\n",
      " Regression with ARIMA(4,0,1) errors : -12657.14\n",
      " Regression with ARIMA(4,0,3) errors : -12704.19\n",
      " Regression with ARIMA(5,0,3) errors : -12674.9\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.25\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12664.74\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.55\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.01\n",
      " Regression with ARIMA(0,0,0) errors : -9129.67\n",
      " Regression with ARIMA(1,0,0) errors : -12606.43\n",
      " Regression with ARIMA(0,0,1) errors : -10786.26\n",
      " Regression with ARIMA(0,0,0) errors : -8109.689\n",
      " Regression with ARIMA(1,0,2) errors : -12626.33\n",
      " Regression with ARIMA(2,0,1) errors : -12625.7\n",
      " Regression with ARIMA(3,0,2) errors : -12685.15\n",
      " Regression with ARIMA(3,0,1) errors : -12638.15\n",
      " Regression with ARIMA(4,0,2) errors : -12654.36\n",
      " Regression with ARIMA(3,0,3) errors : -12654.53\n",
      " Regression with ARIMA(2,0,3) errors : -12651.32\n",
      " Regression with ARIMA(4,0,1) errors : -12653.1\n",
      " Regression with ARIMA(4,0,3) errors : -12701.37\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12653.24\n",
      " Regression with ARIMA(3,0,4) errors : -12676.54\n",
      " Regression with ARIMA(5,0,2) errors : -12652.64\n",
      " Regression with ARIMA(5,0,4) errors : -12668.09\n",
      " Regression with ARIMA(4,0,3) errors : -12590.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.56\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.77\n",
      " Regression with ARIMA(0,0,0) errors : -9125.562\n",
      " Regression with ARIMA(1,0,0) errors : -12610.64\n",
      " Regression with ARIMA(0,0,1) errors : -10785.7\n",
      " Regression with ARIMA(0,0,0) errors : -8108.179\n",
      " Regression with ARIMA(1,0,2) errors : -12630.51\n",
      " Regression with ARIMA(2,0,1) errors : -12629.36\n",
      " Regression with ARIMA(3,0,2) errors : -12694.15\n",
      " Regression with ARIMA(3,0,1) errors : -12642.13\n",
      " Regression with ARIMA(4,0,2) errors : -12658.37\n",
      " Regression with ARIMA(3,0,3) errors : -12658.83\n",
      " Regression with ARIMA(2,0,3) errors : -12655.24\n",
      " Regression with ARIMA(4,0,1) errors : -12657.12\n",
      " Regression with ARIMA(4,0,3) errors : -12704.42\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12679.15\n",
      " Regression with ARIMA(3,0,4) errors : -12677.56\n",
      " Regression with ARIMA(5,0,2) errors : -12656.96\n",
      " Regression with ARIMA(5,0,4) errors : -12670.89\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12699.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.76\n",
      " Regression with ARIMA(0,0,0) errors : -9119.29\n",
      " Regression with ARIMA(1,0,0) errors : -12609.83\n",
      " Regression with ARIMA(0,0,1) errors : -10782.32\n",
      " Regression with ARIMA(0,0,0) errors : -8104.093\n",
      " Regression with ARIMA(1,0,2) errors : -12629.02\n",
      " Regression with ARIMA(2,0,1) errors : -12627.65\n",
      " Regression with ARIMA(3,0,2) errors : -12693.41\n",
      " Regression with ARIMA(3,0,1) errors : -12640.24\n",
      " Regression with ARIMA(4,0,2) errors : -12657.4\n",
      " Regression with ARIMA(3,0,3) errors : -12657.65\n",
      " Regression with ARIMA(2,0,3) errors : -12654\n",
      " Regression with ARIMA(4,0,1) errors : -12655.98\n",
      " Regression with ARIMA(4,0,3) errors : -12700.63\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12678.52\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12666.19\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.72\n",
      " Regression with ARIMA(0,0,0) errors : -9127.533\n",
      " Regression with ARIMA(1,0,0) errors : -12608.51\n",
      " Regression with ARIMA(0,0,1) errors : -10784.58\n",
      " Regression with ARIMA(0,0,0) errors : -8099.693\n",
      " Regression with ARIMA(1,0,2) errors : -12627.71\n",
      " Regression with ARIMA(2,0,1) errors : -12626.53\n",
      " Regression with ARIMA(3,0,2) errors : -12687.4\n",
      " Regression with ARIMA(3,0,1) errors : -12638.82\n",
      " Regression with ARIMA(4,0,2) errors : -12655.24\n",
      " Regression with ARIMA(3,0,3) errors : -12655.99\n",
      " Regression with ARIMA(2,0,3) errors : -12651.92\n",
      " Regression with ARIMA(4,0,1) errors : -12654.76\n",
      " Regression with ARIMA(4,0,3) errors : -12698.43\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12654.62\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -12611.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12696.67\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.19\n",
      " Regression with ARIMA(0,0,0) errors : -9131.072\n",
      " Regression with ARIMA(1,0,0) errors : -12612.33\n",
      " Regression with ARIMA(0,0,1) errors : -10786.34\n",
      " Regression with ARIMA(0,0,0) errors : -8111.89\n",
      " Regression with ARIMA(1,0,2) errors : -12632.14\n",
      " Regression with ARIMA(2,0,1) errors : -12630.94\n",
      " Regression with ARIMA(3,0,2) errors : -12697.09\n",
      " Regression with ARIMA(3,0,1) errors : -12642.55\n",
      " Regression with ARIMA(4,0,2) errors : -12659.42\n",
      " Regression with ARIMA(3,0,3) errors : -12660.03\n",
      " Regression with ARIMA(2,0,3) errors : -12656.53\n",
      " Regression with ARIMA(4,0,1) errors : -12658.14\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12614.5\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12700.42\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.26\n",
      " Regression with ARIMA(0,0,0) errors : -9126.592\n",
      " Regression with ARIMA(1,0,0) errors : -12609.67\n",
      " Regression with ARIMA(0,0,1) errors : -10781.77\n",
      " Regression with ARIMA(0,0,0) errors : -8113.176\n",
      " Regression with ARIMA(1,0,2) errors : -12629.18\n",
      " Regression with ARIMA(2,0,1) errors : -12627.73\n",
      " Regression with ARIMA(3,0,2) errors : -12692.71\n",
      " Regression with ARIMA(3,0,1) errors : -12639.26\n",
      " Regression with ARIMA(4,0,2) errors : -12656.27\n",
      " Regression with ARIMA(3,0,3) errors : -12657.03\n",
      " Regression with ARIMA(2,0,3) errors : -12652.75\n",
      " Regression with ARIMA(4,0,1) errors : -12654.72\n",
      " Regression with ARIMA(4,0,3) errors : -12699.6\n",
      " Regression with ARIMA(5,0,3) errors : -12672.77\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12668.99\n",
      " Regression with ARIMA(4,0,3) errors : -12626.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12697.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.51\n",
      " Regression with ARIMA(0,0,0) errors : -9120.766\n",
      " Regression with ARIMA(1,0,0) errors : -12607\n",
      " Regression with ARIMA(0,0,1) errors : -10776.09\n",
      " Regression with ARIMA(0,0,0) errors : -8111.103\n",
      " Regression with ARIMA(1,0,2) errors : -12626.77\n",
      " Regression with ARIMA(2,0,1) errors : -12625.53\n",
      " Regression with ARIMA(3,0,2) errors : -12685.73\n",
      " Regression with ARIMA(3,0,1) errors : -12637.75\n",
      " Regression with ARIMA(4,0,2) errors : -12654.14\n",
      " Regression with ARIMA(3,0,3) errors : -12654.51\n",
      " Regression with ARIMA(2,0,3) errors : -12650.91\n",
      " Regression with ARIMA(4,0,1) errors : -12654.37\n",
      " Regression with ARIMA(4,0,3) errors : -12686.13\n",
      " Regression with ARIMA(5,0,3) errors : -12700.25\n",
      " Regression with ARIMA(5,0,2) errors : -12654.47\n",
      " Regression with ARIMA(5,0,4) errors : -12662.71\n",
      " Regression with ARIMA(4,0,4) errors : -12698.47\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : -12673.47\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12629.83\n",
      " Regression with ARIMA(0,0,0) errors : -9123.342\n",
      " Regression with ARIMA(1,0,0) errors : -12606.52\n",
      " Regression with ARIMA(0,0,1) errors : -10778\n",
      " Regression with ARIMA(0,0,0) errors : -8105.722\n",
      " Regression with ARIMA(1,0,2) errors : -12626.01\n",
      " Regression with ARIMA(2,0,1) errors : -12624.6\n",
      " Regression with ARIMA(3,0,2) errors : -12689.93\n",
      " Regression with ARIMA(3,0,1) errors : -12636.27\n",
      " Regression with ARIMA(4,0,2) errors : -12652.8\n",
      " Regression with ARIMA(3,0,3) errors : -12653.27\n",
      " Regression with ARIMA(2,0,3) errors : -12649.98\n",
      " Regression with ARIMA(4,0,1) errors : -12652.27\n",
      " Regression with ARIMA(4,0,3) errors : -12694.07\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12670.15\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12654.04\n",
      " Regression with ARIMA(4,0,3) errors : -12618.5\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.06\n",
      " Regression with ARIMA(0,0,0) errors : -9131.681\n",
      " Regression with ARIMA(1,0,0) errors : -12608.01\n",
      " Regression with ARIMA(0,0,1) errors : -10782.66\n",
      " Regression with ARIMA(0,0,0) errors : -8107.119\n",
      " Regression with ARIMA(1,0,2) errors : -12628.11\n",
      " Regression with ARIMA(2,0,1) errors : -12626.67\n",
      " Regression with ARIMA(3,0,2) errors : -12693.49\n",
      " Regression with ARIMA(3,0,1) errors : -12638.11\n",
      " Regression with ARIMA(4,0,2) errors : -12655.3\n",
      " Regression with ARIMA(3,0,3) errors : -12655.92\n",
      " Regression with ARIMA(2,0,3) errors : -12652.11\n",
      " Regression with ARIMA(4,0,1) errors : -12653.8\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12610.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12696.06\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.24\n",
      " Regression with ARIMA(0,0,0) errors : -9131.239\n",
      " Regression with ARIMA(1,0,0) errors : -12606.95\n",
      " Regression with ARIMA(0,0,1) errors : -10780.44\n",
      " Regression with ARIMA(0,0,0) errors : -8112.5\n",
      " Regression with ARIMA(1,0,2) errors : -12627\n",
      " Regression with ARIMA(2,0,1) errors : -12625.5\n",
      " Regression with ARIMA(3,0,2) errors : -12689.64\n",
      " Regression with ARIMA(3,0,1) errors : -12638.39\n",
      " Regression with ARIMA(4,0,2) errors : -12654.7\n",
      " Regression with ARIMA(3,0,3) errors : -12654.57\n",
      " Regression with ARIMA(2,0,3) errors : -12650.34\n",
      " Regression with ARIMA(4,0,1) errors : -12654\n",
      " Regression with ARIMA(4,0,3) errors : -12691.8\n",
      " Regression with ARIMA(5,0,3) errors : -12674.84\n",
      " Regression with ARIMA(4,0,4) errors : -12670.68\n",
      " Regression with ARIMA(3,0,4) errors : -12676.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12662.77\n",
      " Regression with ARIMA(4,0,3) errors : -12620.21\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.43\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.92\n",
      " Regression with ARIMA(0,0,0) errors : -9128.861\n",
      " Regression with ARIMA(1,0,0) errors : -12610.07\n",
      " Regression with ARIMA(0,0,1) errors : -10783.53\n",
      " Regression with ARIMA(0,0,0) errors : -8110.608\n",
      " Regression with ARIMA(1,0,2) errors : -12629.79\n",
      " Regression with ARIMA(2,0,1) errors : -12628.8\n",
      " Regression with ARIMA(3,0,2) errors : -12690.81\n",
      " Regression with ARIMA(3,0,1) errors : -12640.88\n",
      " Regression with ARIMA(4,0,2) errors : -12657.06\n",
      " Regression with ARIMA(3,0,3) errors : -12657.59\n",
      " Regression with ARIMA(2,0,3) errors : -12654.11\n",
      " Regression with ARIMA(4,0,1) errors : -12656.04\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12597.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12697.96\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12634.62\n",
      " Regression with ARIMA(0,0,0) errors : -9126.781\n",
      " Regression with ARIMA(1,0,0) errors : -12610.65\n",
      " Regression with ARIMA(0,0,1) errors : -10781.97\n",
      " Regression with ARIMA(0,0,0) errors : -8113.142\n",
      " Regression with ARIMA(1,0,2) errors : -12630.54\n",
      " Regression with ARIMA(2,0,1) errors : -12629.23\n",
      " Regression with ARIMA(3,0,2) errors : -12696.42\n",
      " Regression with ARIMA(3,0,1) errors : -12641.18\n",
      " Regression with ARIMA(4,0,2) errors : -12657.47\n",
      " Regression with ARIMA(3,0,3) errors : -12658.27\n",
      " Regression with ARIMA(2,0,3) errors : -12654.69\n",
      " Regression with ARIMA(4,0,1) errors : -12656.72\n",
      " Regression with ARIMA(4,0,3) errors : -12703.68\n",
      " Regression with ARIMA(5,0,3) errors : -12677.09\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12669.72\n",
      " Regression with ARIMA(4,0,3) errors : -12577.74\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.4\n",
      " Regression with ARIMA(0,0,0) errors : -9125.689\n",
      " Regression with ARIMA(1,0,0) errors : -12612.41\n",
      " Regression with ARIMA(0,0,1) errors : -10783.44\n",
      " Regression with ARIMA(0,0,0) errors : -8112.957\n",
      " Regression with ARIMA(1,0,2) errors : -12632.37\n",
      " Regression with ARIMA(2,0,1) errors : -12631.02\n",
      " Regression with ARIMA(3,0,2) errors : -12698.98\n",
      " Regression with ARIMA(3,0,1) errors : -12642.99\n",
      " Regression with ARIMA(4,0,2) errors : -12659.39\n",
      " Regression with ARIMA(3,0,3) errors : -12660.05\n",
      " Regression with ARIMA(2,0,3) errors : -12656.41\n",
      " Regression with ARIMA(4,0,1) errors : -12658.4\n",
      " Regression with ARIMA(4,0,3) errors : -12705.73\n",
      " Regression with ARIMA(5,0,3) errors : -12677.06\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12682.47\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12672.68\n",
      " Regression with ARIMA(4,0,3) errors : -12592.32\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.68\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.3\n",
      " Regression with ARIMA(0,0,0) errors : -9115.868\n",
      " Regression with ARIMA(1,0,0) errors : -12611.51\n",
      " Regression with ARIMA(0,0,1) errors : -10777.8\n",
      " Regression with ARIMA(0,0,0) errors : -8111.841\n",
      " Regression with ARIMA(1,0,2) errors : -12631.09\n",
      " Regression with ARIMA(2,0,1) errors : -12629.64\n",
      " Regression with ARIMA(3,0,2) errors : -12698.43\n",
      " Regression with ARIMA(3,0,1) errors : -12641.39\n",
      " Regression with ARIMA(4,0,2) errors : -12658.34\n",
      " Regression with ARIMA(3,0,3) errors : -12658.92\n",
      " Regression with ARIMA(2,0,3) errors : -12655.53\n",
      " Regression with ARIMA(4,0,1) errors : -12657.54\n",
      " Regression with ARIMA(4,0,3) errors : -12704.55\n",
      " Regression with ARIMA(5,0,3) errors : -12677.45\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12671.36\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.66\n",
      " Regression with ARIMA(0,0,0) errors : -9124.945\n",
      " Regression with ARIMA(1,0,0) errors : -12612.72\n",
      " Regression with ARIMA(0,0,1) errors : -10780.08\n",
      " Regression with ARIMA(0,0,0) errors : -8108.834\n",
      " Regression with ARIMA(1,0,2) errors : -12632.51\n",
      " Regression with ARIMA(2,0,1) errors : -12631.82\n",
      " Regression with ARIMA(3,0,2) errors : -12694.27\n",
      " Regression with ARIMA(3,0,1) errors : -12643.59\n",
      " Regression with ARIMA(4,0,2) errors : -12660.23\n",
      " Regression with ARIMA(3,0,3) errors : -12660.57\n",
      " Regression with ARIMA(2,0,3) errors : -12657.73\n",
      " Regression with ARIMA(4,0,1) errors : -12659.39\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12588.55\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.13\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12627.74\n",
      " Regression with ARIMA(0,0,0) errors : -9117.039\n",
      " Regression with ARIMA(1,0,0) errors : -12604.36\n",
      " Regression with ARIMA(0,0,1) errors : -10772.74\n",
      " Regression with ARIMA(0,0,0) errors : -8100.168\n",
      " Regression with ARIMA(1,0,2) errors : -12624.03\n",
      " Regression with ARIMA(2,0,1) errors : -12622.73\n",
      " Regression with ARIMA(3,0,2) errors : -12688.87\n",
      " Regression with ARIMA(3,0,1) errors : -12635.29\n",
      " Regression with ARIMA(4,0,2) errors : -12652.41\n",
      " Regression with ARIMA(3,0,3) errors : -12652.42\n",
      " Regression with ARIMA(2,0,3) errors : -12648.98\n",
      " Regression with ARIMA(4,0,1) errors : -12651.73\n",
      " Regression with ARIMA(4,0,3) errors : -12695.02\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12668.42\n",
      " Regression with ARIMA(3,0,4) errors : -12666.86\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12662.55\n",
      " Regression with ARIMA(4,0,3) errors : -12583.67\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12692.62\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12629.95\n",
      " Regression with ARIMA(0,0,0) errors : -9111.839\n",
      " Regression with ARIMA(1,0,0) errors : -12606.59\n",
      " Regression with ARIMA(0,0,1) errors : -10768.97\n",
      " Regression with ARIMA(0,0,0) errors : -8094.359\n",
      " Regression with ARIMA(1,0,2) errors : -12626.11\n",
      " Regression with ARIMA(2,0,1) errors : -12624.99\n",
      " Regression with ARIMA(3,0,2) errors : -12691.49\n",
      " Regression with ARIMA(3,0,1) errors : -12636.29\n",
      " Regression with ARIMA(4,0,2) errors : -12654.61\n",
      " Regression with ARIMA(3,0,3) errors : -12655.25\n",
      " Regression with ARIMA(2,0,3) errors : -12651.79\n",
      " Regression with ARIMA(4,0,1) errors : -12653.54\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12606.28\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12694.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12625.86\n",
      " Regression with ARIMA(0,0,0) errors : -9104.057\n",
      " Regression with ARIMA(1,0,0) errors : -12602.52\n",
      " Regression with ARIMA(0,0,1) errors : -10763.32\n",
      " Regression with ARIMA(0,0,0) errors : -8093.859\n",
      " Regression with ARIMA(1,0,2) errors : -12621.83\n",
      " Regression with ARIMA(2,0,1) errors : -12620.75\n",
      " Regression with ARIMA(3,0,2) errors : -12688.22\n",
      " Regression with ARIMA(3,0,1) errors : -12631.52\n",
      " Regression with ARIMA(4,0,2) errors : -12652.06\n",
      " Regression with ARIMA(3,0,3) errors : -12650.46\n",
      " Regression with ARIMA(2,0,3) errors : -12647.56\n",
      " Regression with ARIMA(4,0,1) errors : -12651.23\n",
      " Regression with ARIMA(4,0,3) errors : -12681.28\n",
      " Regression with ARIMA(3,0,2) errors : -12603.68\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12690.63\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12618.91\n",
      " Regression with ARIMA(0,0,0) errors : -9103.363\n",
      " Regression with ARIMA(1,0,0) errors : -12597.31\n",
      " Regression with ARIMA(0,0,1) errors : -10765.68\n",
      " Regression with ARIMA(0,0,0) errors : -8091.292\n",
      " Regression with ARIMA(1,0,2) errors : -12615.19\n",
      " Regression with ARIMA(2,0,1) errors : -12613.85\n",
      " Regression with ARIMA(3,0,2) errors : -12682.31\n",
      " Regression with ARIMA(3,0,1) errors : -12625.35\n",
      " Regression with ARIMA(4,0,2) errors : -12644.79\n",
      " Regression with ARIMA(3,0,3) errors : -12644.37\n",
      " Regression with ARIMA(2,0,3) errors : -12640.45\n",
      " Regression with ARIMA(4,0,1) errors : -12643.65\n",
      " Regression with ARIMA(4,0,3) errors : -12682.08\n",
      " Regression with ARIMA(3,0,2) errors : -12580.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12684.69\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12615.06\n",
      " Regression with ARIMA(0,0,0) errors : -9099.58\n",
      " Regression with ARIMA(1,0,0) errors : -12592.84\n",
      " Regression with ARIMA(0,0,1) errors : -10762.48\n",
      " Regression with ARIMA(0,0,0) errors : -8087.004\n",
      " Regression with ARIMA(1,0,2) errors : -12610.83\n",
      " Regression with ARIMA(2,0,1) errors : -12609.67\n",
      " Regression with ARIMA(3,0,2) errors : -12677.21\n",
      " Regression with ARIMA(3,0,1) errors : -12621.08\n",
      " Regression with ARIMA(4,0,2) errors : -12640.17\n",
      " Regression with ARIMA(3,0,3) errors : -12640.85\n",
      " Regression with ARIMA(2,0,3) errors : -12636.93\n",
      " Regression with ARIMA(4,0,1) errors : -12638.83\n",
      " Regression with ARIMA(4,0,3) errors : -12684.27\n",
      " Regression with ARIMA(5,0,3) errors : -12658.04\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12639.53\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12654.82\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12680.01\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12613.46\n",
      " Regression with ARIMA(0,0,0) errors : -9099.695\n",
      " Regression with ARIMA(1,0,0) errors : -12591.66\n",
      " Regression with ARIMA(0,0,1) errors : -10763.22\n",
      " Regression with ARIMA(0,0,0) errors : -8089.962\n",
      " Regression with ARIMA(1,0,2) errors : -12609.68\n",
      " Regression with ARIMA(2,0,1) errors : -12608.39\n",
      " Regression with ARIMA(3,0,2) errors : -12677.01\n",
      " Regression with ARIMA(3,0,1) errors : -12619.63\n",
      " Regression with ARIMA(4,0,2) errors : -12638.73\n",
      " Regression with ARIMA(3,0,3) errors : -12639.14\n",
      " Regression with ARIMA(2,0,3) errors : -12635.44\n",
      " Regression with ARIMA(4,0,1) errors : -12637.36\n",
      " Regression with ARIMA(4,0,3) errors : -12681.2\n",
      " Regression with ARIMA(5,0,3) errors : -12656.69\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12660.48\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12652.18\n",
      " Regression with ARIMA(4,0,3) errors : -12597.54\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12678.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12615.16\n",
      " Regression with ARIMA(0,0,0) errors : -9100.818\n",
      " Regression with ARIMA(1,0,0) errors : -12593.22\n",
      " Regression with ARIMA(0,0,1) errors : -10765.31\n",
      " Regression with ARIMA(0,0,0) errors : -8091.06\n",
      " Regression with ARIMA(1,0,2) errors : -12611.24\n",
      " Regression with ARIMA(2,0,1) errors : -12609.93\n",
      " Regression with ARIMA(3,0,2) errors : -12679.3\n",
      " Regression with ARIMA(3,0,1) errors : -12621.06\n",
      " Regression with ARIMA(4,0,2) errors : -12639.78\n",
      " Regression with ARIMA(3,0,3) errors : -12640.43\n",
      " Regression with ARIMA(2,0,3) errors : -12636.97\n",
      " Regression with ARIMA(4,0,1) errors : -12638.66\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12594.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12679.67\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12617.12\n",
      " Regression with ARIMA(0,0,0) errors : -9109.583\n",
      " Regression with ARIMA(1,0,0) errors : -12595.07\n",
      " Regression with ARIMA(0,0,1) errors : -10771.08\n",
      " Regression with ARIMA(0,0,0) errors : -8093.37\n",
      " Regression with ARIMA(1,0,2) errors : -12613.21\n",
      " Regression with ARIMA(2,0,1) errors : -12611.88\n",
      " Regression with ARIMA(3,0,2) errors : -12678.72\n",
      " Regression with ARIMA(3,0,1) errors : -12623\n",
      " Regression with ARIMA(4,0,2) errors : -12641.23\n",
      " Regression with ARIMA(3,0,3) errors : -12641.89\n",
      " Regression with ARIMA(2,0,3) errors : -12638.42\n",
      " Regression with ARIMA(4,0,1) errors : -12640.06\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12592.8\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12681.68\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12619.74\n",
      " Regression with ARIMA(0,0,0) errors : -9112.072\n",
      " Regression with ARIMA(1,0,0) errors : -12597.43\n",
      " Regression with ARIMA(0,0,1) errors : -10771.67\n",
      " Regression with ARIMA(0,0,0) errors : -8099.27\n",
      " Regression with ARIMA(1,0,2) errors : -12615.95\n",
      " Regression with ARIMA(2,0,1) errors : -12614.81\n",
      " Regression with ARIMA(3,0,2) errors : -12684.97\n",
      " Regression with ARIMA(3,0,1) errors : -12626.06\n",
      " Regression with ARIMA(4,0,2) errors : -12644.83\n",
      " Regression with ARIMA(3,0,3) errors : -12645.37\n",
      " Regression with ARIMA(2,0,3) errors : -12641.62\n",
      " Regression with ARIMA(4,0,1) errors : -12643.67\n",
      " Regression with ARIMA(4,0,3) errors : -12690.35\n",
      " Regression with ARIMA(5,0,3) errors : -12663.66\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12668.79\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12658.85\n",
      " Regression with ARIMA(4,0,3) errors : -12609.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12685.05\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12619.78\n",
      " Regression with ARIMA(0,0,0) errors : -9111.436\n",
      " Regression with ARIMA(1,0,0) errors : -12596.51\n",
      " Regression with ARIMA(0,0,1) errors : -10769.82\n",
      " Regression with ARIMA(0,0,0) errors : -8099.19\n",
      " Regression with ARIMA(1,0,2) errors : -12615.12\n",
      " Regression with ARIMA(2,0,1) errors : -12615.29\n",
      " Regression with ARIMA(3,0,2) errors : -12677.01\n",
      " Regression with ARIMA(3,0,1) errors : -12626.47\n",
      " Regression with ARIMA(4,0,2) errors : -12646.5\n",
      " Regression with ARIMA(3,0,3) errors : -12647.04\n",
      " Regression with ARIMA(2,0,3) errors : -12642.14\n",
      " Regression with ARIMA(4,0,1) errors : -12644.59\n",
      " Regression with ARIMA(4,0,3) errors : -12686.33\n",
      " Regression with ARIMA(5,0,3) errors : -12661.66\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12668.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12657.53\n",
      " Regression with ARIMA(4,0,3) errors : -12608.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12683.18\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12616.6\n",
      " Regression with ARIMA(0,0,0) errors : -9093.993\n",
      " Regression with ARIMA(1,0,0) errors : -12593.32\n",
      " Regression with ARIMA(0,0,1) errors : -10754.58\n",
      " Regression with ARIMA(0,0,0) errors : -8057.969\n",
      " Regression with ARIMA(1,0,2) errors : -12612.81\n",
      " Regression with ARIMA(2,0,1) errors : -12611.61\n",
      " Regression with ARIMA(3,0,2) errors : -12678.85\n",
      " Regression with ARIMA(3,0,1) errors : -12622.82\n",
      " Regression with ARIMA(4,0,2) errors : -12641.44\n",
      " Regression with ARIMA(3,0,3) errors : -12642.14\n",
      " Regression with ARIMA(2,0,3) errors : -12638.25\n",
      " Regression with ARIMA(4,0,1) errors : -12639.95\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12583.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12680.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12583.96\n",
      " Regression with ARIMA(0,0,0) errors : -9092.613\n",
      " Regression with ARIMA(1,0,0) errors : -12563.7\n",
      " Regression with ARIMA(0,0,1) errors : -10747.78\n",
      " Regression with ARIMA(0,0,0) errors : -8051.218\n",
      " Regression with ARIMA(1,0,2) errors : -12580.28\n",
      " Regression with ARIMA(2,0,1) errors : -12579.03\n",
      " Regression with ARIMA(3,0,2) errors : -12646.7\n",
      " Regression with ARIMA(3,0,1) errors : -12589.65\n",
      " Regression with ARIMA(4,0,2) errors : -12606.27\n",
      " Regression with ARIMA(3,0,3) errors : -12606.89\n",
      " Regression with ARIMA(2,0,3) errors : -12603.05\n",
      " Regression with ARIMA(4,0,1) errors : -12604.75\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12556.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12648.35\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12577.66\n",
      " Regression with ARIMA(0,0,0) errors : -9095.204\n",
      " Regression with ARIMA(1,0,0) errors : -12557.4\n",
      " Regression with ARIMA(0,0,1) errors : -10745.91\n",
      " Regression with ARIMA(0,0,0) errors : -8037.239\n",
      " Regression with ARIMA(1,0,2) errors : -12573.72\n",
      " Regression with ARIMA(2,0,1) errors : -12572.35\n",
      " Regression with ARIMA(3,0,2) errors : -12641.2\n",
      " Regression with ARIMA(3,0,1) errors : -12583.1\n",
      " Regression with ARIMA(4,0,2) errors : -12600.41\n",
      " Regression with ARIMA(3,0,3) errors : -12601.11\n",
      " Regression with ARIMA(2,0,3) errors : -12597.21\n",
      " Regression with ARIMA(4,0,1) errors : -12599.03\n",
      " Regression with ARIMA(4,0,3) errors : -12644.07\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12622.13\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12612.01\n",
      " Regression with ARIMA(4,0,3) errors : -12563.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12642.54\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12575.52\n",
      " Regression with ARIMA(0,0,0) errors : -9101.37\n",
      " Regression with ARIMA(1,0,0) errors : -12554.94\n",
      " Regression with ARIMA(0,0,1) errors : -10747.52\n",
      " Regression with ARIMA(0,0,0) errors : -8033.351\n",
      " Regression with ARIMA(1,0,2) errors : -12571.38\n",
      " Regression with ARIMA(2,0,1) errors : -12570.05\n",
      " Regression with ARIMA(3,0,2) errors : -12638.35\n",
      " Regression with ARIMA(3,0,1) errors : -12581.07\n",
      " Regression with ARIMA(4,0,2) errors : -12598.59\n",
      " Regression with ARIMA(3,0,3) errors : -12599.01\n",
      " Regression with ARIMA(2,0,3) errors : -12595.34\n",
      " Regression with ARIMA(4,0,1) errors : -12597.11\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12519.88\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12639.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12565.83\n",
      " Regression with ARIMA(0,0,0) errors : -9101.364\n",
      " Regression with ARIMA(1,0,0) errors : -12545.42\n",
      " Regression with ARIMA(0,0,1) errors : -10744.99\n",
      " Regression with ARIMA(0,0,0) errors : -8028.435\n",
      " Regression with ARIMA(1,0,2) errors : -12561.69\n",
      " Regression with ARIMA(2,0,1) errors : -12560.33\n",
      " Regression with ARIMA(3,0,2) errors : -12625.38\n",
      " Regression with ARIMA(3,0,1) errors : -12571.55\n",
      " Regression with ARIMA(4,0,2) errors : -12589.48\n",
      " Regression with ARIMA(3,0,3) errors : -12589.91\n",
      " Regression with ARIMA(2,0,3) errors : -12585.25\n",
      " Regression with ARIMA(4,0,1) errors : -12587.54\n",
      " Regression with ARIMA(4,0,3) errors : -12629.39\n",
      " Regression with ARIMA(5,0,3) errors : -12606.27\n",
      " Regression with ARIMA(4,0,4) errors : -12632.75\n",
      " Regression with ARIMA(3,0,4) errors : -12604.33\n",
      " Regression with ARIMA(5,0,4) errors : -12602.45\n",
      " Regression with ARIMA(4,0,5) errors : -12606.94\n",
      " Regression with ARIMA(3,0,5) errors : -12601.51\n",
      " Regression with ARIMA(5,0,5) errors : -12608.1\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12629.36\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12550.88\n",
      " Regression with ARIMA(0,0,0) errors : -9082.974\n",
      " Regression with ARIMA(1,0,0) errors : -12530.87\n",
      " Regression with ARIMA(0,0,1) errors : -10726.19\n",
      " Regression with ARIMA(0,0,0) errors : -7990.949\n",
      " Regression with ARIMA(1,0,2) errors : -12547.22\n",
      " Regression with ARIMA(2,0,1) errors : -12546.03\n",
      " Regression with ARIMA(3,0,2) errors : -12611.03\n",
      " Regression with ARIMA(3,0,1) errors : -12556.14\n",
      " Regression with ARIMA(4,0,2) errors : -12573.38\n",
      " Regression with ARIMA(3,0,3) errors : -12573.93\n",
      " Regression with ARIMA(2,0,3) errors : -12570.37\n",
      " Regression with ARIMA(4,0,1) errors : -12572.13\n",
      " Regression with ARIMA(4,0,3) errors : -12616.54\n",
      " Regression with ARIMA(5,0,3) errors : -12590.07\n",
      " Regression with ARIMA(4,0,4) errors : -12620.02\n",
      " Regression with ARIMA(3,0,4) errors : -12593.33\n",
      " Regression with ARIMA(5,0,4) errors : -12585.19\n",
      " Regression with ARIMA(4,0,5) errors : -12590.96\n",
      " Regression with ARIMA(3,0,5) errors : -12586.08\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12613.46\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12541.98\n",
      " Regression with ARIMA(0,0,0) errors : -9085.693\n",
      " Regression with ARIMA(1,0,0) errors : -12521.52\n",
      " Regression with ARIMA(0,0,1) errors : -10727.61\n",
      " Regression with ARIMA(0,0,0) errors : -7984.545\n",
      " Regression with ARIMA(1,0,2) errors : -12537.92\n",
      " Regression with ARIMA(2,0,1) errors : -12537.24\n",
      " Regression with ARIMA(3,0,2) errors : -12601.89\n",
      " Regression with ARIMA(3,0,1) errors : -12547.19\n",
      " Regression with ARIMA(4,0,2) errors : -12564.24\n",
      " Regression with ARIMA(3,0,3) errors : -12564.26\n",
      " Regression with ARIMA(2,0,3) errors : -12561.62\n",
      " Regression with ARIMA(4,0,1) errors : -12563.37\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12499.3\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12602.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.96\n",
      " Regression with ARIMA(0,0,0) errors : -9090.727\n",
      " Regression with ARIMA(1,0,0) errors : -12524.23\n",
      " Regression with ARIMA(0,0,1) errors : -10729.14\n",
      " Regression with ARIMA(0,0,0) errors : -7988.192\n",
      " Regression with ARIMA(1,0,2) errors : -12541.23\n",
      " Regression with ARIMA(2,0,1) errors : -12541.2\n",
      " Regression with ARIMA(3,0,2) errors : -12596.53\n",
      " Regression with ARIMA(3,0,1) errors : -12551.61\n",
      " Regression with ARIMA(4,0,2) errors : -12568.27\n",
      " Regression with ARIMA(3,0,3) errors : -12568.72\n",
      " Regression with ARIMA(2,0,3) errors : -12565.53\n",
      " Regression with ARIMA(4,0,1) errors : -12567.05\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12496.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12605.49\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12548.88\n",
      " Regression with ARIMA(0,0,0) errors : -9100.305\n",
      " Regression with ARIMA(1,0,0) errors : -12527.5\n",
      " Regression with ARIMA(0,0,1) errors : -10736.35\n",
      " Regression with ARIMA(0,0,0) errors : -7988.759\n",
      " Regression with ARIMA(1,0,2) errors : -12544.66\n",
      " Regression with ARIMA(2,0,1) errors : -12543.65\n",
      " Regression with ARIMA(3,0,2) errors : -12605.4\n",
      " Regression with ARIMA(3,0,1) errors : -12554.44\n",
      " Regression with ARIMA(4,0,2) errors : -12571.11\n",
      " Regression with ARIMA(3,0,3) errors : -12571.91\n",
      " Regression with ARIMA(2,0,3) errors : -12568.5\n",
      " Regression with ARIMA(4,0,1) errors : -12570.06\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12504.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12608.79\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.27\n",
      " Regression with ARIMA(0,0,0) errors : -9095.28\n",
      " Regression with ARIMA(1,0,0) errors : -12526.27\n",
      " Regression with ARIMA(0,0,1) errors : -10733.95\n",
      " Regression with ARIMA(0,0,0) errors : -7985.631\n",
      " Regression with ARIMA(1,0,2) errors : -12543.29\n",
      " Regression with ARIMA(2,0,1) errors : -12541.96\n",
      " Regression with ARIMA(3,0,2) errors : -12605.92\n",
      " Regression with ARIMA(3,0,1) errors : -12552.76\n",
      " Regression with ARIMA(4,0,2) errors : -12569.38\n",
      " Regression with ARIMA(3,0,3) errors : -12569.97\n",
      " Regression with ARIMA(2,0,3) errors : -12566.62\n",
      " Regression with ARIMA(4,0,1) errors : -12568.51\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12514.77\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12607.57\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12551.72\n",
      " Regression with ARIMA(0,0,0) errors : -9094.616\n",
      " Regression with ARIMA(1,0,0) errors : -12527.72\n",
      " Regression with ARIMA(0,0,1) errors : -10731.91\n",
      " Regression with ARIMA(0,0,0) errors : -7984.814\n",
      " Regression with ARIMA(1,0,2) errors : -12544.83\n",
      " Regression with ARIMA(2,0,1) errors : -12545.69\n",
      " Regression with ARIMA(3,0,2) errors : -12599.12\n",
      " Regression with ARIMA(3,0,1) errors : -12556.69\n",
      " Regression with ARIMA(4,0,2) errors : -12574.58\n",
      " Regression with ARIMA(3,0,3) errors : -12572.21\n",
      " Regression with ARIMA(2,0,3) errors : -12570.48\n",
      " Regression with ARIMA(4,0,1) errors : -12574.57\n",
      " Regression with ARIMA(4,0,3) errors : -12602.14\n",
      " Regression with ARIMA(5,0,3) errors : -12593.97\n",
      " Regression with ARIMA(4,0,4) errors : -12614.31\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12592.12\n",
      " Regression with ARIMA(4,0,5) errors : -12613.12\n",
      " Regression with ARIMA(3,0,5) errors : -12593.98\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -12615.97\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.25\n",
      " Regression with ARIMA(0,0,0) errors : -9103.285\n",
      " Regression with ARIMA(1,0,0) errors : -12525.6\n",
      " Regression with ARIMA(0,0,1) errors : -10740.02\n",
      " Regression with ARIMA(0,0,0) errors : -7987.126\n",
      " Regression with ARIMA(1,0,2) errors : -12542.63\n",
      " Regression with ARIMA(2,0,1) errors : -12541.09\n",
      " Regression with ARIMA(3,0,2) errors : -12595.27\n",
      " Regression with ARIMA(3,0,1) errors : -12553.61\n",
      " Regression with ARIMA(4,0,2) errors : -12567.35\n",
      " Regression with ARIMA(3,0,3) errors : -12568.1\n",
      " Regression with ARIMA(2,0,3) errors : -12564.84\n",
      " Regression with ARIMA(4,0,1) errors : -12567.61\n",
      " Regression with ARIMA(4,0,3) errors : -12599.93\n",
      " Regression with ARIMA(5,0,3) errors : -12585.25\n",
      " Regression with ARIMA(4,0,4) errors : -12587.13\n",
      " Regression with ARIMA(3,0,4) errors : -12586.59\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12587.56\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12603.94\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12563.76\n",
      " Regression with ARIMA(0,0,0) errors : -9114.748\n",
      " Regression with ARIMA(1,0,0) errors : -12542.44\n",
      " Regression with ARIMA(0,0,1) errors : -10750.26\n",
      " Regression with ARIMA(0,0,0) errors : -7996.79\n",
      " Regression with ARIMA(1,0,2) errors : -12559.52\n",
      " Regression with ARIMA(2,0,1) errors : -12557.88\n",
      " Regression with ARIMA(3,0,2) errors : -12623.24\n",
      " Regression with ARIMA(3,0,1) errors : -12569.07\n",
      " Regression with ARIMA(4,0,2) errors : -12584.06\n",
      " Regression with ARIMA(3,0,3) errors : -12584.83\n",
      " Regression with ARIMA(2,0,3) errors : -12581.2\n",
      " Regression with ARIMA(4,0,1) errors : -12583.59\n",
      " Regression with ARIMA(4,0,3) errors : -12622.16\n",
      " Regression with ARIMA(3,0,2) errors : -12529.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12623.55\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12571.66\n",
      " Regression with ARIMA(0,0,0) errors : -9119.255\n",
      " Regression with ARIMA(1,0,0) errors : -12550.63\n",
      " Regression with ARIMA(0,0,1) errors : -10754.38\n",
      " Regression with ARIMA(0,0,0) errors : -7999.828\n",
      " Regression with ARIMA(1,0,2) errors : -12567.56\n",
      " Regression with ARIMA(2,0,1) errors : -12565.97\n",
      " Regression with ARIMA(3,0,2) errors : -12623.38\n",
      " Regression with ARIMA(3,0,1) errors : -12577.61\n",
      " Regression with ARIMA(4,0,2) errors : -12592.71\n",
      " Regression with ARIMA(3,0,3) errors : -12593.33\n",
      " Regression with ARIMA(2,0,3) errors : -12589.24\n",
      " Regression with ARIMA(4,0,1) errors : -12591.99\n",
      " Regression with ARIMA(4,0,3) errors : -12628.14\n",
      " Regression with ARIMA(5,0,3) errors : -12611.42\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12608.22\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12601.46\n",
      " Regression with ARIMA(4,0,3) errors : -12518.46\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12632.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12570.69\n",
      " Regression with ARIMA(0,0,0) errors : -9115.278\n",
      " Regression with ARIMA(1,0,0) errors : -12549.82\n",
      " Regression with ARIMA(0,0,1) errors : -10753.47\n",
      " Regression with ARIMA(0,0,0) errors : -8003.712\n",
      " Regression with ARIMA(1,0,2) errors : -12566.64\n",
      " Regression with ARIMA(2,0,1) errors : -12564.99\n",
      " Regression with ARIMA(3,0,2) errors : -12627.12\n",
      " Regression with ARIMA(3,0,1) errors : -12576.67\n",
      " Regression with ARIMA(4,0,2) errors : -12592.86\n",
      " Regression with ARIMA(3,0,3) errors : -12593.53\n",
      " Regression with ARIMA(2,0,3) errors : -12588.09\n",
      " Regression with ARIMA(4,0,1) errors : -12591.37\n",
      " Regression with ARIMA(4,0,3) errors : -12631.06\n",
      " Regression with ARIMA(5,0,3) errors : -12608.52\n",
      " Regression with ARIMA(4,0,4) errors : -12636.78\n",
      " Regression with ARIMA(3,0,4) errors : -12595.05\n",
      " Regression with ARIMA(5,0,4) errors : -12606.13\n",
      " Regression with ARIMA(4,0,5) errors : -12611.46\n",
      " Regression with ARIMA(3,0,5) errors : -12589.1\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12631.52\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12578.38\n",
      " Regression with ARIMA(0,0,0) errors : -9111.17\n",
      " Regression with ARIMA(1,0,0) errors : -12558.92\n",
      " Regression with ARIMA(0,0,1) errors : -10753.78\n",
      " Regression with ARIMA(0,0,0) errors : -8020.573\n",
      " Regression with ARIMA(1,0,2) errors : -12574.68\n",
      " Regression with ARIMA(2,0,1) errors : -12573.05\n",
      " Regression with ARIMA(3,0,2) errors : -12623.18\n",
      " Regression with ARIMA(3,0,1) errors : -12586.14\n",
      " Regression with ARIMA(4,0,2) errors : -12599.85\n",
      " Regression with ARIMA(3,0,3) errors : -12600.52\n",
      " Regression with ARIMA(2,0,3) errors : -12595.7\n",
      " Regression with ARIMA(4,0,1) errors : -12599.55\n",
      " Regression with ARIMA(4,0,3) errors : -12630.95\n",
      " Regression with ARIMA(5,0,3) errors : -12614.41\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12610.87\n",
      " Regression with ARIMA(5,0,2) errors : -12611.96\n",
      " Regression with ARIMA(5,0,4) errors : -12609.33\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12639.79\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12589.89\n",
      " Regression with ARIMA(0,0,0) errors : -9118.887\n",
      " Regression with ARIMA(1,0,0) errors : -12570.44\n",
      " Regression with ARIMA(0,0,1) errors : -10762.54\n",
      " Regression with ARIMA(0,0,0) errors : -8023.134\n",
      " Regression with ARIMA(1,0,2) errors : -12586.06\n",
      " Regression with ARIMA(2,0,1) errors : -12584.58\n",
      " Regression with ARIMA(3,0,2) errors : -12650.24\n",
      " Regression with ARIMA(3,0,1) errors : -12595.09\n",
      " Regression with ARIMA(4,0,2) errors : -12610.13\n",
      " Regression with ARIMA(3,0,3) errors : -12611.25\n",
      " Regression with ARIMA(2,0,3) errors : -12607.47\n",
      " Regression with ARIMA(4,0,1) errors : -12610.04\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12562.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12652.57\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12605.76\n",
      " Regression with ARIMA(0,0,0) errors : -9124.298\n",
      " Regression with ARIMA(1,0,0) errors : -12585.84\n",
      " Regression with ARIMA(0,0,1) errors : -10776.69\n",
      " Regression with ARIMA(0,0,0) errors : -8072.897\n",
      " Regression with ARIMA(1,0,2) errors : -12601.79\n",
      " Regression with ARIMA(2,0,1) errors : -12600.13\n",
      " Regression with ARIMA(3,0,2) errors : -12662.69\n",
      " Regression with ARIMA(3,0,1) errors : -12612.34\n",
      " Regression with ARIMA(4,0,2) errors : -12629.9\n",
      " Regression with ARIMA(3,0,3) errors : -12629.01\n",
      " Regression with ARIMA(2,0,3) errors : -12623.63\n",
      " Regression with ARIMA(4,0,1) errors : -12627.83\n",
      " Regression with ARIMA(4,0,3) errors : -12662.1\n",
      " Regression with ARIMA(3,0,2) errors : -12538.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12668.81\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12617.98\n",
      " Regression with ARIMA(0,0,0) errors : -9103.826\n",
      " Regression with ARIMA(1,0,0) errors : -12597.39\n",
      " Regression with ARIMA(0,0,1) errors : -10769.07\n",
      " Regression with ARIMA(0,0,0) errors : -8071.78\n",
      " Regression with ARIMA(1,0,2) errors : -12613.58\n",
      " Regression with ARIMA(2,0,1) errors : -12612.03\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12634.81\n",
      " Regression with ARIMA(1,0,3) errors : -12637.74\n",
      " Regression with ARIMA(0,0,3) errors : -11857.74\n",
      " Regression with ARIMA(1,0,4) errors : -12635.79\n",
      " Regression with ARIMA(0,0,2) errors : -11425.89\n",
      " Regression with ARIMA(0,0,4) errors : -12183.34\n",
      " Regression with ARIMA(2,0,4) errors : -12660.74\n",
      " Regression with ARIMA(3,0,4) errors : -12661.91\n",
      " Regression with ARIMA(3,0,3) errors : -12639.57\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12664.79\n",
      " Regression with ARIMA(1,0,5) errors : -12637.48\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12662.8\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12648.96\n",
      " Regression with ARIMA(0,0,0) errors : -9121.032\n",
      " Regression with ARIMA(1,0,0) errors : -12628.13\n",
      " Regression with ARIMA(0,0,1) errors : -10785.99\n",
      " Regression with ARIMA(0,0,0) errors : -8086.924\n",
      " Regression with ARIMA(1,0,2) errors : -12643.58\n",
      " Regression with ARIMA(2,0,1) errors : -12645.29\n",
      " Regression with ARIMA(3,0,2) errors : -12693.39\n",
      " Regression with ARIMA(3,0,1) errors : -12657.07\n",
      " Regression with ARIMA(4,0,2) errors : -12674.99\n",
      " Regression with ARIMA(3,0,3) errors : -12674.05\n",
      " Regression with ARIMA(2,0,3) errors : -12670.13\n",
      " Regression with ARIMA(4,0,1) errors : -12673.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12586.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12712.63\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12660.79\n",
      " Regression with ARIMA(0,0,0) errors : -9128.864\n",
      " Regression with ARIMA(1,0,0) errors : -12639.5\n",
      " Regression with ARIMA(0,0,1) errors : -10794.45\n",
      " Regression with ARIMA(0,0,0) errors : -8086.79\n",
      " Regression with ARIMA(1,0,2) errors : -12656.36\n",
      " Regression with ARIMA(2,0,1) errors : -12654.67\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12681.02\n",
      " Regression with ARIMA(1,0,3) errors : -12683.93\n",
      " Regression with ARIMA(0,0,3) errors : -11882.7\n",
      " Regression with ARIMA(1,0,4) errors : -12681.93\n",
      " Regression with ARIMA(0,0,2) errors : -11451.05\n",
      " Regression with ARIMA(0,0,4) errors : -12222.24\n",
      " Regression with ARIMA(2,0,4) errors : -12708.43\n",
      " Regression with ARIMA(3,0,4) errors : -12700.64\n",
      " Regression with ARIMA(2,0,5) errors : -12711.77\n",
      " Regression with ARIMA(1,0,5) errors : -12684.46\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12635.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12712.16\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12663.87\n",
      " Regression with ARIMA(0,0,0) errors : -9125.032\n",
      " Regression with ARIMA(1,0,0) errors : -12642.83\n",
      " Regression with ARIMA(0,0,1) errors : -10795.06\n",
      " Regression with ARIMA(0,0,0) errors : -8088.558\n",
      " Regression with ARIMA(1,0,2) errors : -12659.49\n",
      " Regression with ARIMA(2,0,1) errors : -12657.96\n",
      " Regression with ARIMA(3,0,2) errors : -12717.9\n",
      " Regression with ARIMA(3,0,1) errors : -12671.05\n",
      " Regression with ARIMA(4,0,2) errors : -12688.31\n",
      " Regression with ARIMA(3,0,3) errors : -12688.66\n",
      " Regression with ARIMA(2,0,3) errors : -12684.8\n",
      " Regression with ARIMA(4,0,1) errors : -12687.93\n",
      " Regression with ARIMA(4,0,3) errors : -12724.73\n",
      " Regression with ARIMA(5,0,3) errors : -12705.98\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12706.33\n",
      " Regression with ARIMA(5,0,2) errors : -12704.8\n",
      " Regression with ARIMA(5,0,4) errors : -12707.76\n",
      " Regression with ARIMA(4,0,3) errors : -12626.28\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12711.43\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12675.17\n",
      " Regression with ARIMA(0,0,0) errors : -9127.822\n",
      " Regression with ARIMA(1,0,0) errors : -12652.69\n",
      " Regression with ARIMA(0,0,1) errors : -10797.32\n",
      " Regression with ARIMA(0,0,0) errors : -8122.42\n",
      " Regression with ARIMA(1,0,2) errors : -12669.49\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12695.32\n",
      " Regression with ARIMA(1,0,3) errors : -12697.68\n",
      " Regression with ARIMA(0,0,3) errors : -11885.17\n",
      " Regression with ARIMA(1,0,4) errors : -12695.67\n",
      " Regression with ARIMA(0,0,2) errors : -11454.21\n",
      " Regression with ARIMA(0,0,4) errors : -12223.07\n",
      " Regression with ARIMA(2,0,4) errors : -12724.02\n",
      " Regression with ARIMA(3,0,4) errors : -12727\n",
      " Regression with ARIMA(3,0,3) errors : -12699.87\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12728.15\n",
      " Regression with ARIMA(1,0,5) errors : -12698.24\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12723.48\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12683.94\n",
      " Regression with ARIMA(0,0,0) errors : -9138.188\n",
      " Regression with ARIMA(1,0,0) errors : -12661.92\n",
      " Regression with ARIMA(0,0,1) errors : -10809.04\n",
      " Regression with ARIMA(0,0,0) errors : -8146.342\n",
      " Regression with ARIMA(1,0,2) errors : -12678.66\n",
      " Regression with ARIMA(2,0,1) errors : -12676.73\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12704.85\n",
      " Regression with ARIMA(1,0,3) errors : -12707.91\n",
      " Regression with ARIMA(0,0,3) errors : -11899.86\n",
      " Regression with ARIMA(1,0,4) errors : -12705.92\n",
      " Regression with ARIMA(0,0,2) errors : -11462.84\n",
      " Regression with ARIMA(0,0,4) errors : -12239.61\n",
      " Regression with ARIMA(2,0,4) errors : -12733.61\n",
      " Regression with ARIMA(3,0,4) errors : -12727.8\n",
      " Regression with ARIMA(2,0,5) errors : -12736.88\n",
      " Regression with ARIMA(1,0,5) errors : -12708.11\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12658.61\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12738.19\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12707.9\n",
      " Regression with ARIMA(0,0,0) errors : -9146.696\n",
      " Regression with ARIMA(1,0,0) errors : -12685.85\n",
      " Regression with ARIMA(0,0,1) errors : -10816.31\n",
      " Regression with ARIMA(0,0,0) errors : -8145.991\n",
      " Regression with ARIMA(1,0,2) errors : -12701.98\n",
      " Regression with ARIMA(2,0,1) errors : -12702.83\n",
      " Regression with ARIMA(3,0,2) errors : -12752.59\n",
      " Regression with ARIMA(3,0,1) errors : -12716.78\n",
      " Regression with ARIMA(4,0,2) errors : -12776.93\n",
      " Regression with ARIMA(4,0,1) errors : -12738.81\n",
      " Regression with ARIMA(5,0,2) errors : -12750.69\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -12740.15\n",
      " Regression with ARIMA(5,0,1) errors : -12807.17\n",
      " Regression with ARIMA(5,0,0) errors : -12741.34\n",
      " Regression with ARIMA(4,0,0) errors : -12738.7\n",
      " Regression with ARIMA(5,0,1) errors : -12728.9\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12760.88\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12912.84\n",
      " Regression with ARIMA(0,0,0) errors : -9287.558\n",
      " Regression with ARIMA(1,0,0) errors : -12838.23\n",
      " Regression with ARIMA(0,0,1) errors : -10970.44\n",
      " Regression with ARIMA(0,0,0) errors : -8334.607\n",
      " Regression with ARIMA(1,0,2) errors : -12850.07\n",
      " Regression with ARIMA(2,0,1) errors : -12896.83\n",
      " Regression with ARIMA(3,0,2) errors : -12886.59\n",
      " Regression with ARIMA(2,0,3) errors : -12920.49\n",
      " Regression with ARIMA(1,0,3) errors : -12869.31\n",
      " Regression with ARIMA(3,0,3) errors : -12922.93\n",
      " Regression with ARIMA(4,0,3) errors : -12951.22\n",
      " Regression with ARIMA(4,0,2) errors : -12979.64\n",
      " Regression with ARIMA(4,0,1) errors : -12919.17\n",
      " Regression with ARIMA(5,0,2) errors : -13016.01\n",
      " Regression with ARIMA(5,0,1) errors : -12918.05\n",
      " Regression with ARIMA(5,0,3) errors : -13009.45\n",
      " Regression with ARIMA(5,0,2) errors : -12924.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -12851.52\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13340.53\n",
      " Regression with ARIMA(0,0,0) errors : -9896.247\n",
      " Regression with ARIMA(1,0,0) errors : -13321.04\n",
      " Regression with ARIMA(0,0,1) errors : -11543.52\n",
      " Regression with ARIMA(0,0,0) errors : -8940.049\n",
      " Regression with ARIMA(1,0,2) errors : -13322.44\n",
      " Regression with ARIMA(2,0,1) errors : -13321.63\n",
      " Regression with ARIMA(3,0,2) errors : -13355.77\n",
      " Regression with ARIMA(3,0,1) errors : -13337\n",
      " Regression with ARIMA(4,0,2) errors : -13354.79\n",
      " Regression with ARIMA(3,0,3) errors : -13380.32\n",
      " Regression with ARIMA(2,0,3) errors : -13333.79\n",
      " Regression with ARIMA(4,0,3) errors : -13412.84\n",
      " Regression with ARIMA(5,0,3) errors : -13428.89\n",
      " Regression with ARIMA(5,0,2) errors : -13429.21\n",
      " Regression with ARIMA(5,0,1) errors : -13348.63\n",
      " Regression with ARIMA(4,0,1) errors : -13348.07\n",
      " Regression with ARIMA(5,0,2) errors : -13296.63\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13383.36\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13638.8\n",
      " Regression with ARIMA(0,1,0) errors : -13557.1\n",
      " Regression with ARIMA(1,1,0) errors : -13569.73\n",
      " Regression with ARIMA(0,1,1) errors : -13568.98\n",
      " Regression with ARIMA(0,1,0) errors : -13559.1\n",
      " Regression with ARIMA(1,1,2) errors : -13569.88\n",
      " Regression with ARIMA(2,1,1) errors : -13572.21\n",
      " Regression with ARIMA(3,1,2) errors : -13655.74\n",
      " Regression with ARIMA(3,1,1) errors : -13608.61\n",
      " Regression with ARIMA(4,1,2) errors : -13690.96\n",
      " Regression with ARIMA(4,1,1) errors : -13635.24\n",
      " Regression with ARIMA(5,1,2) errors : -13685.37\n",
      " Regression with ARIMA(4,1,3) errors : -13668.95\n",
      " Regression with ARIMA(3,1,3) errors : -13656.78\n",
      " Regression with ARIMA(5,1,1) errors : -13674.36\n",
      " Regression with ARIMA(5,1,3) errors : -13699.07\n",
      " Regression with ARIMA(5,1,4) errors : -13798\n",
      " Regression with ARIMA(4,1,4) errors : -13766.7\n",
      " Regression with ARIMA(5,1,5) errors : -13796.13\n",
      " Regression with ARIMA(4,1,5) errors : -13791.29\n",
      " Regression with ARIMA(5,1,4) errors : -13800.01\n",
      " Regression with ARIMA(4,1,4) errors : -13768.68\n",
      " Regression with ARIMA(5,1,3) errors : -13701.1\n",
      " Regression with ARIMA(5,1,5) errors : -13798.15\n",
      " Regression with ARIMA(4,1,3) errors : -13669.36\n",
      " Regression with ARIMA(4,1,5) errors : -13793.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,4) errors : -13627.14\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13856.97\n",
      " Regression with ARIMA(0,1,0) errors : -13830.28\n",
      " Regression with ARIMA(1,1,0) errors : -13844.83\n",
      " Regression with ARIMA(0,1,1) errors : -13841.77\n",
      " Regression with ARIMA(0,1,0) errors : -13832.29\n",
      " Regression with ARIMA(1,1,2) errors : -13852.88\n",
      " Regression with ARIMA(2,1,1) errors : -13857.98\n",
      " Regression with ARIMA(1,1,1) errors : -13853.24\n",
      " Regression with ARIMA(2,1,0) errors : -13857.59\n",
      " Regression with ARIMA(3,1,1) errors : -13856.45\n",
      " Regression with ARIMA(3,1,0) errors : -13855.79\n",
      " Regression with ARIMA(3,1,2) errors : -13853.87\n",
      " Regression with ARIMA(2,1,1) errors : -13859.99\n",
      " Regression with ARIMA(1,1,1) errors : -13855.24\n",
      " Regression with ARIMA(2,1,0) errors : -13859.61\n",
      " Regression with ARIMA(3,1,1) errors : -13858.47\n",
      " Regression with ARIMA(2,1,2) errors : -13858.99\n",
      " Regression with ARIMA(1,1,0) errors : -13846.84\n",
      " Regression with ARIMA(1,1,2) errors : -13854.88\n",
      " Regression with ARIMA(3,1,0) errors : -13857.8\n",
      " Regression with ARIMA(3,1,2) errors : -13855.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : -13852.22\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,1) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13947.36\n",
      " Regression with ARIMA(0,1,0) errors : -13900.86\n",
      " Regression with ARIMA(1,1,0) errors : -13932.84\n",
      " Regression with ARIMA(0,1,1) errors : -13911.73\n",
      " Regression with ARIMA(0,1,0) errors : -13902.87\n",
      " Regression with ARIMA(1,1,2) errors : -13939.01\n",
      " Regression with ARIMA(2,1,1) errors : -13943.65\n",
      " Regression with ARIMA(3,1,2) errors : -13959.09\n",
      " Regression with ARIMA(3,1,1) errors : -13956.45\n",
      " Regression with ARIMA(4,1,2) errors : -14000.17\n",
      " Regression with ARIMA(4,1,1) errors : -13952.05\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : -14004.61\n",
      " Regression with ARIMA(3,1,3) errors : -13984.19\n",
      " Regression with ARIMA(5,1,3) errors : -14058.98\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : -14034.52\n",
      " Regression with ARIMA(5,1,3) errors : -14060.9\n",
      " Regression with ARIMA(4,1,3) errors : -14006.63\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : -14002.15\n",
      " Regression with ARIMA(4,1,4) errors : -14036.43\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : -13974.19\n",
      "\n",
      " Best model: Regression with ARIMA(4,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14051.09\n",
      " Regression with ARIMA(0,1,0) errors : -14017.53\n",
      " Regression with ARIMA(1,1,0) errors : -14026.02\n",
      " Regression with ARIMA(0,1,1) errors : -14026.4\n",
      " Regression with ARIMA(0,1,0) errors : -14019.51\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14049.92\n",
      " Regression with ARIMA(3,1,2) errors : -14072.45\n",
      " Regression with ARIMA(3,1,1) errors : -14060.26\n",
      " Regression with ARIMA(4,1,2) errors : -14078.94\n",
      " Regression with ARIMA(4,1,1) errors : -14061.76\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : -14126.2\n",
      " Regression with ARIMA(2,1,3) errors : -14050.56\n",
      " Regression with ARIMA(3,1,4) errors : -14077.3\n",
      " Regression with ARIMA(2,1,4) errors : -14048.58\n",
      " Regression with ARIMA(4,1,4) errors : -14193.59\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14215.31\n",
      " Regression with ARIMA(2,1,5) errors : -14059.26\n",
      " Regression with ARIMA(3,1,5) errors : -14216.42\n",
      " Regression with ARIMA(2,1,5) errors : -14061.28\n",
      " Regression with ARIMA(3,1,4) errors : -14177.43\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14050.61\n",
      " Regression with ARIMA(4,1,4) errors : -14194.71\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -14036.04\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14232.72\n",
      " Regression with ARIMA(0,1,0) errors : -14162.77\n",
      " Regression with ARIMA(1,1,0) errors : -14185.38\n",
      " Regression with ARIMA(0,1,1) errors : -14173.07\n",
      " Regression with ARIMA(0,1,0) errors : -14164.75\n",
      " Regression with ARIMA(1,1,2) errors : -14207.81\n",
      " Regression with ARIMA(2,1,1) errors : -14224.23\n",
      " Regression with ARIMA(3,1,2) errors : -14248.4\n",
      " Regression with ARIMA(3,1,1) errors : -14225.86\n",
      " Regression with ARIMA(4,1,2) errors : -14270.04\n",
      " Regression with ARIMA(4,1,1) errors : -14226.79\n",
      " Regression with ARIMA(5,1,2) errors : -14276.69\n",
      " Regression with ARIMA(5,1,1) errors : -14239.31\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : -14278.66\n",
      " Regression with ARIMA(4,1,2) errors : -14272.05\n",
      " Regression with ARIMA(5,1,1) errors : -14241.32\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : -14228.77\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,1) errors : -14188.43\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14269.51\n",
      " Regression with ARIMA(1,1,0) errors : -14280.67\n",
      " Regression with ARIMA(0,1,1) errors : -14275.99\n",
      " Regression with ARIMA(0,1,0) errors : -14271.49\n",
      " Regression with ARIMA(2,1,0) errors : -14280.26\n",
      " Regression with ARIMA(1,1,1) errors : -14283.64\n",
      " Regression with ARIMA(2,1,1) errors : -14282.63\n",
      " Regression with ARIMA(1,1,2) errors : -14281.81\n",
      " Regression with ARIMA(0,1,2) errors : -14276.35\n",
      " Regression with ARIMA(1,1,1) errors : -14285.62\n",
      " Regression with ARIMA(0,1,1) errors : -14277.97\n",
      " Regression with ARIMA(1,1,0) errors : -14282.66\n",
      " Regression with ARIMA(2,1,1) errors : -14284.63\n",
      " Regression with ARIMA(1,1,2) errors : -14283.8\n",
      " Regression with ARIMA(0,1,2) errors : -14278.33\n",
      " Regression with ARIMA(2,1,0) errors : -14282.25\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14292.77\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14392.52\n",
      " Regression with ARIMA(0,1,0) errors : -14319.87\n",
      " Regression with ARIMA(1,1,0) errors : -14323.95\n",
      " Regression with ARIMA(0,1,1) errors : -14324.28\n",
      " Regression with ARIMA(0,1,0) errors : -14321.88\n",
      " Regression with ARIMA(1,1,2) errors : -14328.67\n",
      " Regression with ARIMA(2,1,1) errors : -14322.2\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14396.05\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14397.58\n",
      " Regression with ARIMA(1,1,4) errors : -14325.55\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14409.11\n",
      " Regression with ARIMA(0,1,5) errors : -14329.22\n",
      " Regression with ARIMA(0,1,4) errors : -14322.36\n",
      " Regression with ARIMA(1,1,5) errors : -14410.56\n",
      " Regression with ARIMA(0,1,5) errors : -14331.23\n",
      " Regression with ARIMA(1,1,4) errors : -14327.56\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(0,1,4) errors : -14324.37\n",
      " Regression with ARIMA(2,1,4) errors : -14399.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,5) errors : -14340.4\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14414.39\n",
      " Regression with ARIMA(0,1,0) errors : -14347.05\n",
      " Regression with ARIMA(1,1,0) errors : -14351.5\n",
      " Regression with ARIMA(0,1,1) errors : -14351.98\n",
      " Regression with ARIMA(0,1,0) errors : -14349.06\n",
      " Regression with ARIMA(1,1,2) errors : -14355.74\n",
      " Regression with ARIMA(2,1,1) errors : -14357.14\n",
      " Regression with ARIMA(3,1,2) errors : -14356.58\n",
      " Regression with ARIMA(2,1,3) errors : -14416.78\n",
      " Regression with ARIMA(1,1,3) errors : -14352.44\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14426.08\n",
      " Regression with ARIMA(1,1,4) errors : -14352.46\n",
      " Regression with ARIMA(3,1,4) errors : -14359.23\n",
      " Regression with ARIMA(2,1,5) errors : -14433.08\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14448.43\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14449.79\n",
      " Regression with ARIMA(2,1,5) errors : -14434.5\n",
      " Regression with ARIMA(3,1,4) errors : -14361.25\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14427.62\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14373.05\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14467.17\n",
      " Regression with ARIMA(0,1,0) errors : -14387.79\n",
      " Regression with ARIMA(1,1,0) errors : -14392.42\n",
      " Regression with ARIMA(0,1,1) errors : -14393.12\n",
      " Regression with ARIMA(0,1,0) errors : -14389.79\n",
      " Regression with ARIMA(1,1,2) errors : -14393.52\n",
      " Regression with ARIMA(2,1,1) errors : -14392.46\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14467.02\n",
      " Regression with ARIMA(1,1,1) errors : -14394.63\n",
      " Regression with ARIMA(1,1,3) errors : -14391.52\n",
      " Regression with ARIMA(3,1,1) errors : -14450.2\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -14468.77\n",
      " Regression with ARIMA(1,1,2) errors : -14395.53\n",
      " Regression with ARIMA(2,1,1) errors : -14394.46\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14468.52\n",
      " Regression with ARIMA(1,1,1) errors : -14396.63\n",
      " Regression with ARIMA(1,1,3) errors : -14393.52\n",
      " Regression with ARIMA(3,1,1) errors : -14452.03\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : -14406.82\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11132.19\n",
      " Regression with ARIMA(1,0,0) errors : -14540.36\n",
      " Regression with ARIMA(0,0,1) errors : -12745.99\n",
      " Regression with ARIMA(0,0,0) errors : -9972.371\n",
      " Regression with ARIMA(2,0,0) errors : -14537.54\n",
      " Regression with ARIMA(1,0,1) errors : -14538.45\n",
      " Regression with ARIMA(2,0,1) errors : -14542.87\n",
      " Regression with ARIMA(3,0,1) errors : -14558.56\n",
      " Regression with ARIMA(3,0,0) errors : -14548.35\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -14559.21\n",
      " Regression with ARIMA(4,0,2) errors : -14555.78\n",
      " Regression with ARIMA(3,0,3) errors : -14558.89\n",
      " Regression with ARIMA(2,0,3) errors : -14545.56\n",
      " Regression with ARIMA(4,0,3) errors : -14553.54\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14560.17\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11151.48\n",
      " Regression with ARIMA(1,0,0) errors : -14551.11\n",
      " Regression with ARIMA(0,0,1) errors : -12768.97\n",
      " Regression with ARIMA(0,0,0) errors : -9991.611\n",
      " Regression with ARIMA(2,0,0) errors : -14548.25\n",
      " Regression with ARIMA(1,0,1) errors : -14549.23\n",
      " Regression with ARIMA(2,0,1) errors : -14552.94\n",
      " Regression with ARIMA(3,0,1) errors : -14567.66\n",
      " Regression with ARIMA(3,0,0) errors : -14558.46\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,0) errors : -14557.43\n",
      " Regression with ARIMA(4,0,2) errors : -14572.3\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -14567.45\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,1) errors : -14571.65\n",
      " Regression with ARIMA(5,0,3) errors : -14591.07\n",
      " Regression with ARIMA(5,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -14588.65\n",
      " Regression with ARIMA(5,0,3) errors : -14466.83\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -14592.39\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14560.15\n",
      " Regression with ARIMA(0,0,0) errors : -11132.88\n",
      " Regression with ARIMA(1,0,0) errors : -14543.96\n",
      " Regression with ARIMA(0,0,1) errors : -12748.49\n",
      " Regression with ARIMA(0,0,0) errors : -9916.669\n",
      " Regression with ARIMA(1,0,2) errors : -14552.05\n",
      " Regression with ARIMA(2,0,1) errors : -14544.14\n",
      " Regression with ARIMA(3,0,2) errors : -14551.85\n",
      " Regression with ARIMA(2,0,3) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -14542.09\n",
      " Regression with ARIMA(1,0,3) errors : -14551.93\n",
      " Regression with ARIMA(3,0,1) errors : -14569.13\n",
      " Regression with ARIMA(3,0,0) errors : -14553.2\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -14542.46\n",
      " Regression with ARIMA(4,0,0) errors : -14553.19\n",
      " Regression with ARIMA(4,0,2) errors : -14568.72\n",
      " Regression with ARIMA(3,0,1) errors : -14400.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -14566.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11155.69\n",
      " Regression with ARIMA(1,0,0) errors : -14548.92\n",
      " Regression with ARIMA(0,0,1) errors : -12768.48\n",
      " Regression with ARIMA(0,0,0) errors : -9907.063\n",
      " Regression with ARIMA(2,0,0) errors : -14546.07\n",
      " Regression with ARIMA(1,0,1) errors : -14546.93\n",
      " Regression with ARIMA(2,0,1) errors : -14550.78\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -14554.96\n",
      " Regression with ARIMA(0,0,2) errors : -13588.57\n",
      " Regression with ARIMA(1,0,3) errors : -14555.05\n",
      " Regression with ARIMA(0,0,3) errors : -13929.67\n",
      " Regression with ARIMA(2,0,3) errors : -14552.73\n",
      " Regression with ARIMA(1,0,4) errors : -14561.38\n",
      " Regression with ARIMA(0,0,4) errors : -14217.43\n",
      " Regression with ARIMA(2,0,4) errors : -14559.98\n",
      " Regression with ARIMA(1,0,5) errors : -14560.36\n",
      " Regression with ARIMA(0,0,5) errors : -14327\n",
      " Regression with ARIMA(2,0,5) errors : -14558.11\n",
      " Regression with ARIMA(1,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,4) errors : -14560.62\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14379.34\n",
      " Regression with ARIMA(1,1,0) errors : -14383.72\n",
      " Regression with ARIMA(0,1,1) errors : -14382.54\n",
      " Regression with ARIMA(0,1,0) errors : -14381.35\n",
      " Regression with ARIMA(2,1,0) errors : -14382.72\n",
      " Regression with ARIMA(1,1,1) errors : -14384.5\n",
      " Regression with ARIMA(2,1,1) errors : -14382.23\n",
      " Regression with ARIMA(1,1,2) errors : -14382.66\n",
      " Regression with ARIMA(0,1,2) errors : -14382.21\n",
      " Regression with ARIMA(1,1,1) errors : -14386.51\n",
      " Regression with ARIMA(0,1,1) errors : -14384.55\n",
      " Regression with ARIMA(1,1,0) errors : -14385.73\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : -14384.54\n",
      " Regression with ARIMA(0,1,2) errors : -14384.22\n",
      " Regression with ARIMA(2,1,0) errors : -14384.73\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14397.22\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14483.22\n",
      " Regression with ARIMA(0,0,0) errors : -11017.35\n",
      " Regression with ARIMA(1,0,0) errors : -14460.22\n",
      " Regression with ARIMA(0,0,1) errors : -12640.36\n",
      " Regression with ARIMA(0,0,0) errors : -9780.733\n",
      " Regression with ARIMA(1,0,2) errors : -14467.99\n",
      " Regression with ARIMA(2,0,1) errors : -14461.13\n",
      " Regression with ARIMA(3,0,2) errors : -14483.56\n",
      " Regression with ARIMA(3,0,1) errors : -14483.17\n",
      " Regression with ARIMA(4,0,2) errors : -14480.81\n",
      " Regression with ARIMA(3,0,3) errors : -14482.96\n",
      " Regression with ARIMA(2,0,3) errors : -14464.37\n",
      " Regression with ARIMA(4,0,1) errors : -14477.63\n",
      " Regression with ARIMA(4,0,3) errors : -14478.99\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14477.22\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14498.8\n",
      " Regression with ARIMA(0,0,0) errors : -11029\n",
      " Regression with ARIMA(1,0,0) errors : -14478.15\n",
      " Regression with ARIMA(0,0,1) errors : -12661.86\n",
      " Regression with ARIMA(0,0,0) errors : -9798.577\n",
      " Regression with ARIMA(1,0,2) errors : -14485.32\n",
      " Regression with ARIMA(2,0,1) errors : -14479.56\n",
      " Regression with ARIMA(3,0,2) errors : -14498.67\n",
      " Regression with ARIMA(2,0,3) errors : -14482.25\n",
      " Regression with ARIMA(1,0,1) errors : -14476.18\n",
      " Regression with ARIMA(1,0,3) errors : -14486.49\n",
      " Regression with ARIMA(3,0,1) errors : -14499.33\n",
      " Regression with ARIMA(3,0,0) errors : -14485.04\n",
      " Regression with ARIMA(4,0,1) errors : -14493.81\n",
      " Regression with ARIMA(2,0,0) errors : -14475.19\n",
      " Regression with ARIMA(4,0,0) errors : -14489\n",
      " Regression with ARIMA(4,0,2) errors : -14497.35\n",
      " Regression with ARIMA(3,0,1) errors : -14328.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -14499.04\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14499.82\n",
      " Regression with ARIMA(0,0,0) errors : -11030.92\n",
      " Regression with ARIMA(1,0,0) errors : -14479.83\n",
      " Regression with ARIMA(0,0,1) errors : -12666.18\n",
      " Regression with ARIMA(0,0,0) errors : -9815.953\n",
      " Regression with ARIMA(1,0,2) errors : -14487.24\n",
      " Regression with ARIMA(2,0,1) errors : -14480.13\n",
      " Regression with ARIMA(3,0,2) errors : -14499.16\n",
      " Regression with ARIMA(2,0,3) errors : -14482.98\n",
      " Regression with ARIMA(1,0,1) errors : -14477.85\n",
      " Regression with ARIMA(1,0,3) errors : -14488.5\n",
      " Regression with ARIMA(3,0,1) errors : -14497.61\n",
      " Regression with ARIMA(3,0,3) errors : -14499.03\n",
      " Regression with ARIMA(2,0,2) errors : -14337.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14481.43\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14520.82\n",
      " Regression with ARIMA(0,0,0) errors : -11039.14\n",
      " Regression with ARIMA(1,0,0) errors : -14493.69\n",
      " Regression with ARIMA(0,0,1) errors : -12672\n",
      " Regression with ARIMA(0,0,0) errors : -9822.197\n",
      " Regression with ARIMA(1,0,2) errors : -14500.76\n",
      " Regression with ARIMA(2,0,1) errors : -14497.56\n",
      " Regression with ARIMA(3,0,2) errors : -14524.84\n",
      " Regression with ARIMA(3,0,1) errors : -14518.61\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -14524.22\n",
      " Regression with ARIMA(2,0,3) errors : -14520.02\n",
      " Regression with ARIMA(4,0,1) errors : -14521.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14510.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14421.28\n",
      " Regression with ARIMA(1,1,0) errors : -14438.68\n",
      " Regression with ARIMA(0,1,1) errors : -14424.25\n",
      " Regression with ARIMA(0,1,0) errors : -14423.29\n",
      " Regression with ARIMA(2,1,0) errors : -14439.8\n",
      " Regression with ARIMA(3,1,0) errors : -14439.79\n",
      " Regression with ARIMA(2,1,1) errors : -14444.89\n",
      " Regression with ARIMA(1,1,1) errors : -14446.77\n",
      " Regression with ARIMA(1,1,2) errors : -14444.79\n",
      " Regression with ARIMA(0,1,2) errors : -14423.33\n",
      " Regression with ARIMA(1,1,1) errors : -14448.78\n",
      " Regression with ARIMA(0,1,1) errors : -14426.26\n",
      " Regression with ARIMA(1,1,0) errors : -14440.69\n",
      " Regression with ARIMA(2,1,1) errors : -14446.9\n",
      " Regression with ARIMA(1,1,2) errors : -14446.8\n",
      " Regression with ARIMA(0,1,2) errors : -14425.34\n",
      " Regression with ARIMA(2,1,0) errors : -14441.81\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14440.01\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14553.28\n",
      " Regression with ARIMA(0,1,0) errors : -14483.96\n",
      " Regression with ARIMA(1,1,0) errors : -14484.77\n",
      " Regression with ARIMA(0,1,1) errors : -14485.54\n",
      " Regression with ARIMA(0,1,0) errors : -14485.96\n",
      " Regression with ARIMA(1,1,2) errors : -14488.25\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14562.68\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14567.68\n",
      " Regression with ARIMA(1,1,4) errors : -14484.21\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14585.28\n",
      " Regression with ARIMA(1,1,5) errors : -14492.24\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14586.81\n",
      " Regression with ARIMA(1,1,5) errors : -14494.25\n",
      " Regression with ARIMA(2,1,4) errors : -14569.27\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : -14485.81\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14504.5\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14595.43\n",
      " Regression with ARIMA(0,1,0) errors : -14527.09\n",
      " Regression with ARIMA(1,1,0) errors : -14529.37\n",
      " Regression with ARIMA(0,1,1) errors : -14529.7\n",
      " Regression with ARIMA(0,1,0) errors : -14529.09\n",
      " Regression with ARIMA(1,1,2) errors : -14533.99\n",
      " Regression with ARIMA(2,1,1) errors : -14543.6\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14601.94\n",
      " Regression with ARIMA(1,1,3) errors : -14532.49\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14605.78\n",
      " Regression with ARIMA(1,1,4) errors : -14530.67\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14537.39\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14607.58\n",
      " Regression with ARIMA(1,1,4) errors : -14532.67\n",
      " Regression with ARIMA(2,1,3) errors : -14603.75\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : -14534.49\n",
      " Regression with ARIMA(1,1,5) errors : -14539.39\n",
      " Regression with ARIMA(3,1,3) errors : -14598.8\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14549.06\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14516.87\n",
      " Regression with ARIMA(1,1,0) errors : -14525.36\n",
      " Regression with ARIMA(0,1,1) errors : -14520.46\n",
      " Regression with ARIMA(0,1,0) errors : -14518.88\n",
      " Regression with ARIMA(2,1,0) errors : -14523.87\n",
      " Regression with ARIMA(1,1,1) errors : -14523.58\n",
      " Regression with ARIMA(2,1,1) errors : -14528.44\n",
      " Regression with ARIMA(3,1,1) errors : -14605.73\n",
      " Regression with ARIMA(3,1,0) errors : -14522.73\n",
      " Regression with ARIMA(4,1,1) errors : -14552.02\n",
      " Regression with ARIMA(3,1,2) errors : -14601.37\n",
      " Regression with ARIMA(4,1,0) errors : -14523.8\n",
      " Regression with ARIMA(4,1,2) errors : -14570.42\n",
      " Regression with ARIMA(3,1,1) errors : -14607.28\n",
      " Regression with ARIMA(2,1,1) errors : -14530.46\n",
      " Regression with ARIMA(3,1,0) errors : -14524.74\n",
      " Regression with ARIMA(4,1,1) errors : -14553.78\n",
      " Regression with ARIMA(3,1,2) errors : -14602.92\n",
      " Regression with ARIMA(2,1,0) errors : -14525.88\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,0) errors : -14525.81\n",
      " Regression with ARIMA(4,1,2) errors : -14572.1\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14535.51\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11250.18\n",
      " Regression with ARIMA(1,0,0) errors : -14656.36\n",
      " Regression with ARIMA(0,0,1) errors : -12862.56\n",
      " Regression with ARIMA(0,0,0) errors : -10027.92\n",
      " Regression with ARIMA(2,0,0) errors : -14654.03\n",
      " Regression with ARIMA(1,0,1) errors : -14654.36\n",
      " Regression with ARIMA(2,0,1) errors : -14660.84\n",
      " Regression with ARIMA(3,0,1) errors : -14661.21\n",
      " Regression with ARIMA(3,0,0) errors : -14664.08\n",
      " Regression with ARIMA(4,0,0) errors : -14664.12\n",
      " Regression with ARIMA(5,0,0) errors : -14670.91\n",
      " Regression with ARIMA(5,0,1) errors : -14674.19\n",
      " Regression with ARIMA(4,0,1) errors : -14674.78\n",
      " Regression with ARIMA(4,0,2) errors : -14678.29\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : -14693.27\n",
      " Regression with ARIMA(5,0,3) errors : -14691.32\n",
      " Regression with ARIMA(4,0,3) errors : -14661.91\n",
      " Regression with ARIMA(5,0,2) errors : -14579.72\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -14701.58\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11249.56\n",
      " Regression with ARIMA(1,0,0) errors : -14656.24\n",
      " Regression with ARIMA(0,0,1) errors : -12864.81\n",
      " Regression with ARIMA(0,0,0) errors : -10027.74\n",
      " Regression with ARIMA(2,0,0) errors : -14657.78\n",
      " Regression with ARIMA(3,0,0) errors : -14666.92\n",
      " Regression with ARIMA(4,0,0) errors : -14666.09\n",
      " Regression with ARIMA(3,0,1) errors : -14664.16\n",
      " Regression with ARIMA(2,0,1) errors : -14658.57\n",
      " Regression with ARIMA(4,0,1) errors : -14666.46\n",
      " Regression with ARIMA(3,0,0) errors : -14546.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,0) errors : -14662.78\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14675.28\n",
      " Regression with ARIMA(0,0,0) errors : -11256.19\n",
      " Regression with ARIMA(1,0,0) errors : -14668.76\n",
      " Regression with ARIMA(0,0,1) errors : -12871.85\n",
      " Regression with ARIMA(0,0,0) errors : -10034.68\n",
      " Regression with ARIMA(1,0,2) errors : -14674.7\n",
      " Regression with ARIMA(2,0,1) errors : -14674.96\n",
      " Regression with ARIMA(3,0,2) errors : -14693.42\n",
      " Regression with ARIMA(3,0,1) errors : -14675.56\n",
      " Regression with ARIMA(4,0,2) errors : -14690.6\n",
      " Regression with ARIMA(3,0,3) errors : -14692.29\n",
      " Regression with ARIMA(2,0,3) errors : -14676.55\n",
      " Regression with ARIMA(4,0,1) errors : -14675.31\n",
      " Regression with ARIMA(4,0,3) errors : -14683.71\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14692.38\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m03.2 <- my.tsCV(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                       silent=F,\n",
    "                       xreg=trainx[,2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e4fa7c88-54f4-4a91-954c-62b4b79f5327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-01-24\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m03.2\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435ab53e-426a-4b91-9d3a-d037e4dd9995",
   "metadata": {},
   "source": [
    "## Regressor mean of smaller period for forecast \n",
    "- Regressor mean for forecast is calculated from the number of latest 'horizon' period\n",
    "- the 1st model used the number of latest 'window' period for the calc of regressor mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "035d6b87-06c6-4440-88ae-98eaf1e6ca7b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14728.24\n",
      " Regression with ARIMA(0,1,0) errors : -14705.76\n",
      " Regression with ARIMA(1,1,0) errors : -14703.21\n",
      " Regression with ARIMA(0,1,1) errors : -14703.85\n",
      " Regression with ARIMA(0,1,0) errors : -14707.74\n",
      " Regression with ARIMA(1,1,2) errors : -14755.07\n",
      " Regression with ARIMA(0,1,2) errors : -14703.58\n",
      " Regression with ARIMA(1,1,1) errors : -14701.2\n",
      " Regression with ARIMA(1,1,3) errors : -14756.2\n",
      " Regression with ARIMA(0,1,3) errors : -14715.69\n",
      " Regression with ARIMA(2,1,3) errors : -14743.68\n",
      " Regression with ARIMA(1,1,4) errors : -14754.84\n",
      " Regression with ARIMA(0,1,4) errors : -14713.96\n",
      " Regression with ARIMA(2,1,4) errors : -14742.53\n",
      " Regression with ARIMA(1,1,3) errors : -14757.92\n",
      " Regression with ARIMA(0,1,3) errors : -14717.66\n",
      " Regression with ARIMA(1,1,2) errors : -14756.77\n",
      " Regression with ARIMA(2,1,3) errors : -14745.4\n",
      " Regression with ARIMA(1,1,4) errors : -14756.51\n",
      " Regression with ARIMA(0,1,2) errors : -14705.55\n",
      " Regression with ARIMA(0,1,4) errors : -14715.93\n",
      " Regression with ARIMA(2,1,2) errors : -14729.97\n",
      " Regression with ARIMA(2,1,4) errors : -14744.25\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14726.99\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14688.58\n",
      " Regression with ARIMA(1,1,0) errors : -14687.3\n",
      " Regression with ARIMA(0,1,1) errors : -14686.7\n",
      " Regression with ARIMA(0,1,0) errors : -14690.58\n",
      " Regression with ARIMA(1,1,1) errors : -14685.35\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14699.9\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14648.88\n",
      " Regression with ARIMA(1,1,0) errors : -14646.36\n",
      " Regression with ARIMA(0,1,1) errors : -14647.06\n",
      " Regression with ARIMA(0,1,0) errors : -14650.88\n",
      " Regression with ARIMA(1,1,1) errors : -14644.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14660.19\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14557.56\n",
      " Regression with ARIMA(1,1,0) errors : -14555.41\n",
      " Regression with ARIMA(0,1,1) errors : -14555.93\n",
      " Regression with ARIMA(0,1,0) errors : -14559.56\n",
      " Regression with ARIMA(1,1,1) errors : -14553.98\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14568.83\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14466.15\n",
      " Regression with ARIMA(1,1,0) errors : -14464.59\n",
      " Regression with ARIMA(0,1,1) errors : -14465.14\n",
      " Regression with ARIMA(0,1,0) errors : -14468.15\n",
      " Regression with ARIMA(1,1,1) errors : -14463.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14477.38\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14431.62\n",
      " Regression with ARIMA(1,1,0) errors : -14429.42\n",
      " Regression with ARIMA(0,1,1) errors : -14430.5\n",
      " Regression with ARIMA(0,1,0) errors : -14433.63\n",
      " Regression with ARIMA(1,1,1) errors : -14428.06\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14442.84\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14487.01\n",
      " Regression with ARIMA(0,1,0) errors : -14420.66\n",
      " Regression with ARIMA(1,1,0) errors : -14418.52\n",
      " Regression with ARIMA(0,1,1) errors : -14419.3\n",
      " Regression with ARIMA(0,1,0) errors : -14422.67\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14487.4\n",
      " Regression with ARIMA(1,1,1) errors : -14416.73\n",
      " Regression with ARIMA(2,1,0) errors : -14420.92\n",
      " Regression with ARIMA(3,1,1) errors : -14426\n",
      " Regression with ARIMA(3,1,0) errors : -14427.6\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14489.16\n",
      " Regression with ARIMA(1,1,1) errors : -14418.75\n",
      " Regression with ARIMA(2,1,0) errors : -14422.93\n",
      " Regression with ARIMA(3,1,1) errors : -14427.99\n",
      " Regression with ARIMA(2,1,2) errors : -14488.71\n",
      " Regression with ARIMA(1,1,0) errors : -14420.53\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -14429.61\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -14440.44\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14445.76\n",
      " Regression with ARIMA(0,1,0) errors : -14415.25\n",
      " Regression with ARIMA(1,1,0) errors : -14413.72\n",
      " Regression with ARIMA(0,1,1) errors : -14413.85\n",
      " Regression with ARIMA(0,1,0) errors : -14417.26\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14433.81\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14468.58\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14468.82\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14469.94\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14471.73\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14470.6\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14426.46\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14421.25\n",
      " Regression with ARIMA(1,1,0) errors : -14418.78\n",
      " Regression with ARIMA(0,1,1) errors : -14419.77\n",
      " Regression with ARIMA(0,1,0) errors : -14423.26\n",
      " Regression with ARIMA(1,1,1) errors : -14417.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14432.47\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14414.4\n",
      " Regression with ARIMA(1,1,0) errors : -14411.72\n",
      " Regression with ARIMA(0,1,1) errors : -14412.71\n",
      " Regression with ARIMA(0,1,0) errors : -14416.41\n",
      " Regression with ARIMA(1,1,1) errors : -14410.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14425.61\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14371.6\n",
      " Regression with ARIMA(1,1,0) errors : -14369.53\n",
      " Regression with ARIMA(0,1,1) errors : -14370.05\n",
      " Regression with ARIMA(0,1,0) errors : -14373.59\n",
      " Regression with ARIMA(1,1,1) errors : -14368.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14382.78\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14319.68\n",
      " Regression with ARIMA(0,1,0) errors : -14316.26\n",
      " Regression with ARIMA(1,1,0) errors : -14313.77\n",
      " Regression with ARIMA(0,1,1) errors : -14314.65\n",
      " Regression with ARIMA(0,1,0) errors : -14318.23\n",
      " Regression with ARIMA(1,1,2) errors : -14385.93\n",
      " Regression with ARIMA(0,1,2) errors : -14319.04\n",
      " Regression with ARIMA(1,1,1) errors : -14312.24\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14327.45\n",
      " Regression with ARIMA(2,1,1) errors : -14356.37\n",
      " Regression with ARIMA(2,1,3) errors : -14367.96\n",
      " Regression with ARIMA(1,1,2) errors : -14387.45\n",
      " Regression with ARIMA(0,1,2) errors : -14321.01\n",
      " Regression with ARIMA(1,1,1) errors : -14314.22\n",
      " Regression with ARIMA(2,1,2) errors : -14321.64\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(0,1,1) errors : -14316.62\n",
      " Regression with ARIMA(0,1,3) errors : -14329.42\n",
      " Regression with ARIMA(2,1,1) errors : -14358.04\n",
      " Regression with ARIMA(2,1,3) errors : -14369.57\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14338.56\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14254.7\n",
      " Regression with ARIMA(1,1,0) errors : -14252.25\n",
      " Regression with ARIMA(0,1,1) errors : -14252.87\n",
      " Regression with ARIMA(0,1,0) errors : -14256.7\n",
      " Regression with ARIMA(1,1,1) errors : -14250.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14265.84\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14249.15\n",
      " Regression with ARIMA(1,1,0) errors : -14246.58\n",
      " Regression with ARIMA(0,1,1) errors : -14247.46\n",
      " Regression with ARIMA(0,1,0) errors : -14251.14\n",
      " Regression with ARIMA(1,1,1) errors : -14245.11\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14260.28\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14341.48\n",
      " Regression with ARIMA(0,0,0) errors : -10840.14\n",
      " Regression with ARIMA(1,0,0) errors : -14339.73\n",
      " Regression with ARIMA(0,0,1) errors : -12569.99\n",
      " Regression with ARIMA(0,0,0) errors : -9528.814\n",
      " Regression with ARIMA(1,0,2) errors : -14343.89\n",
      " Regression with ARIMA(0,0,2) errors : -13424.35\n",
      " Regression with ARIMA(1,0,1) errors : -14345.89\n",
      " Regression with ARIMA(2,0,1) errors : -14342.88\n",
      " Regression with ARIMA(2,0,0) errors : -14344.83\n",
      " Regression with ARIMA(1,0,1) errors : -14199.07\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14344.44\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14131.23\n",
      " Regression with ARIMA(1,1,0) errors : -14129.6\n",
      " Regression with ARIMA(0,1,1) errors : -14129.22\n",
      " Regression with ARIMA(0,1,0) errors : -14133.21\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14142.29\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14104.7\n",
      " Regression with ARIMA(1,1,0) errors : -14102.15\n",
      " Regression with ARIMA(0,1,1) errors : -14102.72\n",
      " Regression with ARIMA(0,1,0) errors : -14106.71\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14115.78\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14094.76\n",
      " Regression with ARIMA(1,1,0) errors : -14092.35\n",
      " Regression with ARIMA(0,1,1) errors : -14092.76\n",
      " Regression with ARIMA(0,1,0) errors : -14096.76\n",
      " Regression with ARIMA(1,1,1) errors : -14091.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14105.82\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14158.82\n",
      " Regression with ARIMA(0,1,0) errors : -14086.53\n",
      " Regression with ARIMA(1,1,0) errors : -14083.63\n",
      " Regression with ARIMA(0,1,1) errors : -14084.57\n",
      " Regression with ARIMA(0,1,0) errors : -14088.54\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14155.6\n",
      " Regression with ARIMA(3,1,2) errors : -14153.06\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : -14177.73\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14178.44\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14179.86\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14181.4\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14179.99\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14166.32\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14097.6\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14074.57\n",
      " Regression with ARIMA(1,1,0) errors : -14071.57\n",
      " Regression with ARIMA(0,1,1) errors : -14072.57\n",
      " Regression with ARIMA(0,1,0) errors : -14076.57\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14085.63\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14156.68\n",
      " Regression with ARIMA(0,0,0) errors : -10543.02\n",
      " Regression with ARIMA(1,0,0) errors : -14157.58\n",
      " Regression with ARIMA(0,0,1) errors : -12288.52\n",
      " Regression with ARIMA(0,0,0) errors : -9161.948\n",
      " Regression with ARIMA(2,0,0) errors : -14160.85\n",
      " Regression with ARIMA(3,0,0) errors : -14159.41\n",
      " Regression with ARIMA(2,0,1) errors : -14158.76\n",
      " Regression with ARIMA(1,0,1) errors : -14161.58\n",
      " Regression with ARIMA(1,0,2) errors : -14159.57\n",
      " Regression with ARIMA(0,0,2) errors : -13166.06\n",
      " Regression with ARIMA(1,0,1) errors : -14036.84\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14160.49\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14097.59\n",
      " Regression with ARIMA(0,0,0) errors : -10474.05\n",
      " Regression with ARIMA(1,0,0) errors : -14096.1\n",
      " Regression with ARIMA(0,0,1) errors : -12234.47\n",
      " Regression with ARIMA(0,0,0) errors : -9152.683\n",
      " Regression with ARIMA(1,0,2) errors : -14099.35\n",
      " Regression with ARIMA(0,0,2) errors : -13115.29\n",
      " Regression with ARIMA(1,0,1) errors : -14101.37\n",
      " Regression with ARIMA(2,0,1) errors : -14098.29\n",
      " Regression with ARIMA(2,0,0) errors : -14100.36\n",
      " Regression with ARIMA(1,0,1) errors : -13962.68\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14100.49\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13956.34\n",
      " Regression with ARIMA(1,1,0) errors : -13954.24\n",
      " Regression with ARIMA(0,1,1) errors : -13954.58\n",
      " Regression with ARIMA(0,1,0) errors : -13958.35\n",
      " Regression with ARIMA(1,1,1) errors : -13952.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13967.35\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13942.25\n",
      " Regression with ARIMA(1,1,0) errors : -13939.51\n",
      " Regression with ARIMA(0,1,1) errors : -13940.54\n",
      " Regression with ARIMA(0,1,0) errors : -13944.26\n",
      " Regression with ARIMA(1,1,1) errors : -13938.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13953.25\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14057.56\n",
      " Regression with ARIMA(0,0,0) errors : -10451.94\n",
      " Regression with ARIMA(1,0,0) errors : -14055.02\n",
      " Regression with ARIMA(0,0,1) errors : -12212.26\n",
      " Regression with ARIMA(0,0,0) errors : -9125.585\n",
      " Regression with ARIMA(1,0,2) errors : -14059.61\n",
      " Regression with ARIMA(0,0,2) errors : -13092.48\n",
      " Regression with ARIMA(1,0,1) errors : -14061.59\n",
      " Regression with ARIMA(2,0,1) errors : -14058.81\n",
      " Regression with ARIMA(2,0,0) errors : -14060.82\n",
      " Regression with ARIMA(1,0,1) errors : -13926.65\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14060.43\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14049.73\n",
      " Regression with ARIMA(0,0,0) errors : -10463.36\n",
      " Regression with ARIMA(1,0,0) errors : -14047.15\n",
      " Regression with ARIMA(0,0,1) errors : -12215.94\n",
      " Regression with ARIMA(0,0,0) errors : -9113.651\n",
      " Regression with ARIMA(1,0,2) errors : -14050.93\n",
      " Regression with ARIMA(0,0,2) errors : -13088.83\n",
      " Regression with ARIMA(1,0,1) errors : -14052.85\n",
      " Regression with ARIMA(2,0,1) errors : -14049.93\n",
      " Regression with ARIMA(2,0,0) errors : -14051.82\n",
      " Regression with ARIMA(1,0,1) errors : -13912.48\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14051.09\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13911.02\n",
      " Regression with ARIMA(1,1,0) errors : -13908.48\n",
      " Regression with ARIMA(0,1,1) errors : -13909.2\n",
      " Regression with ARIMA(0,1,0) errors : -13913.03\n",
      " Regression with ARIMA(1,1,1) errors : -13907.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13922.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13900.07\n",
      " Regression with ARIMA(1,1,0) errors : -13897.25\n",
      " Regression with ARIMA(0,1,1) errors : -13898.14\n",
      " Regression with ARIMA(0,1,0) errors : -13902.07\n",
      " Regression with ARIMA(1,1,1) errors : -13896.05\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13911.05\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13876.42\n",
      " Regression with ARIMA(0,1,0) errors : -13873.69\n",
      " Regression with ARIMA(1,1,0) errors : -13870.8\n",
      " Regression with ARIMA(0,1,1) errors : -13871.79\n",
      " Regression with ARIMA(0,1,0) errors : -13875.69\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -13951.7\n",
      " Regression with ARIMA(1,1,1) errors : -13869.75\n",
      " Regression with ARIMA(2,1,0) errors : -13877.74\n",
      " Regression with ARIMA(3,1,1) errors : -13879.69\n",
      " Regression with ARIMA(3,1,0) errors : -13878.26\n",
      " Regression with ARIMA(3,1,2) errors : -13880.96\n",
      " Regression with ARIMA(2,1,1) errors : -13953.47\n",
      " Regression with ARIMA(1,1,1) errors : -13871.73\n",
      " Regression with ARIMA(2,1,0) errors : -13879.75\n",
      " Regression with ARIMA(3,1,1) errors : -13881.7\n",
      " Regression with ARIMA(2,1,2) errors : -13878.44\n",
      " Regression with ARIMA(1,1,0) errors : -13872.8\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -13880.27\n",
      " Regression with ARIMA(3,1,2) errors : -13883\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -13906.38\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13861.23\n",
      " Regression with ARIMA(1,1,0) errors : -13858.29\n",
      " Regression with ARIMA(0,1,1) errors : -13859.25\n",
      " Regression with ARIMA(0,1,0) errors : -13863.23\n",
      " Regression with ARIMA(1,1,1) errors : -13857.3\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13872.19\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13896.9\n",
      " Regression with ARIMA(0,0,0) errors : -10196.26\n",
      " Regression with ARIMA(1,0,0) errors : -13893.1\n",
      " Regression with ARIMA(0,0,1) errors : -11966.99\n",
      " Regression with ARIMA(0,0,0) errors : -8742.913\n",
      " Regression with ARIMA(1,0,2) errors : -13897.42\n",
      " Regression with ARIMA(0,0,2) errors : -12878.36\n",
      " Regression with ARIMA(1,0,1) errors : -13899.18\n",
      " Regression with ARIMA(2,0,1) errors : -13896.32\n",
      " Regression with ARIMA(2,0,0) errors : -13897.97\n",
      " Regression with ARIMA(1,0,1) errors : -13775.62\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13898.36\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13779.66\n",
      " Regression with ARIMA(0,0,0) errors : -10097.98\n",
      " Regression with ARIMA(1,0,0) errors : -13771.91\n",
      " Regression with ARIMA(0,0,1) errors : -11865.72\n",
      " Regression with ARIMA(0,0,0) errors : -8710.896\n",
      " Regression with ARIMA(1,0,2) errors : -13777.93\n",
      " Regression with ARIMA(2,0,1) errors : -13777.15\n",
      " Regression with ARIMA(3,0,2) errors : -13783.79\n",
      " Regression with ARIMA(3,0,1) errors : -13778.18\n",
      " Regression with ARIMA(4,0,2) errors : -13782.79\n",
      " Regression with ARIMA(3,0,3) errors : -13790.74\n",
      " Regression with ARIMA(2,0,3) errors : -13778.27\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13781.06\n",
      " Regression with ARIMA(2,0,4) errors : -13781.18\n",
      " Regression with ARIMA(4,0,4) errors : -13783.64\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,3) errors : -13791.61\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13736.94\n",
      " Regression with ARIMA(0,0,0) errors : -10002.66\n",
      " Regression with ARIMA(1,0,0) errors : -13730.41\n",
      " Regression with ARIMA(0,0,1) errors : -11778.89\n",
      " Regression with ARIMA(0,0,0) errors : -8620.765\n",
      " Regression with ARIMA(1,0,2) errors : -13736.26\n",
      " Regression with ARIMA(2,0,1) errors : -13735.25\n",
      " Regression with ARIMA(3,0,2) errors : -13738.48\n",
      " Regression with ARIMA(3,0,1) errors : -13735.53\n",
      " Regression with ARIMA(4,0,2) errors : -13732.51\n",
      " Regression with ARIMA(3,0,3) errors : -13747.21\n",
      " Regression with ARIMA(2,0,3) errors : -13735.02\n",
      " Regression with ARIMA(4,0,3) errors : -13743.42\n",
      " Regression with ARIMA(3,0,4) errors : -13736.01\n",
      " Regression with ARIMA(2,0,4) errors : -13737.88\n",
      " Regression with ARIMA(4,0,4) errors : -13742.31\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,3) errors : -13748.29\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13671.5\n",
      " Regression with ARIMA(0,0,0) errors : -9894.943\n",
      " Regression with ARIMA(1,0,0) errors : -13665.86\n",
      " Regression with ARIMA(0,0,1) errors : -11694.71\n",
      " Regression with ARIMA(0,0,0) errors : -8560.227\n",
      " Regression with ARIMA(1,0,2) errors : -13672.38\n",
      " Regression with ARIMA(0,0,2) errors : -12612.9\n",
      " Regression with ARIMA(1,0,1) errors : -13674.2\n",
      " Regression with ARIMA(2,0,1) errors : -13671.58\n",
      " Regression with ARIMA(2,0,0) errors : -13673.48\n",
      " Regression with ARIMA(1,0,1) errors : -13559.42\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13673.28\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13629.1\n",
      " Regression with ARIMA(0,0,0) errors : -9878.792\n",
      " Regression with ARIMA(1,0,0) errors : -13624.85\n",
      " Regression with ARIMA(0,0,1) errors : -11666.73\n",
      " Regression with ARIMA(0,0,0) errors : -8556.701\n",
      " Regression with ARIMA(1,0,2) errors : -13629.96\n",
      " Regression with ARIMA(0,0,2) errors : -12579.75\n",
      " Regression with ARIMA(1,0,1) errors : -13631.19\n",
      " Regression with ARIMA(2,0,1) errors : -13629.28\n",
      " Regression with ARIMA(2,0,0) errors : -13630.88\n",
      " Regression with ARIMA(1,0,1) errors : -13512.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13630.37\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13611.31\n",
      " Regression with ARIMA(0,0,0) errors : -9870.771\n",
      " Regression with ARIMA(1,0,0) errors : -13607.01\n",
      " Regression with ARIMA(0,0,1) errors : -11652.28\n",
      " Regression with ARIMA(0,0,0) errors : -8549.922\n",
      " Regression with ARIMA(1,0,2) errors : -13611.78\n",
      " Regression with ARIMA(0,0,2) errors : -12567.48\n",
      " Regression with ARIMA(1,0,1) errors : -13612.86\n",
      " Regression with ARIMA(2,0,1) errors : -13620.17\n",
      " Regression with ARIMA(2,0,0) errors : -13612.21\n",
      " Regression with ARIMA(3,0,1) errors : -13610.14\n",
      " Regression with ARIMA(3,0,0) errors : -13609.99\n",
      " Regression with ARIMA(3,0,2) errors : -13609.53\n",
      " Regression with ARIMA(2,0,1) errors : -13511.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13612.06\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13585.71\n",
      " Regression with ARIMA(0,0,0) errors : -9844.615\n",
      " Regression with ARIMA(1,0,0) errors : -13581.02\n",
      " Regression with ARIMA(0,0,1) errors : -11622.06\n",
      " Regression with ARIMA(0,0,0) errors : -8510.432\n",
      " Regression with ARIMA(1,0,2) errors : -13586.32\n",
      " Regression with ARIMA(0,0,2) errors : -12543.41\n",
      " Regression with ARIMA(1,0,1) errors : -13587.02\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -13586.54\n",
      " Regression with ARIMA(1,0,1) errors : -13475.64\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13585.99\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13574.71\n",
      " Regression with ARIMA(0,0,0) errors : -9826.549\n",
      " Regression with ARIMA(1,0,0) errors : -13570.27\n",
      " Regression with ARIMA(0,0,1) errors : -11609.5\n",
      " Regression with ARIMA(0,0,0) errors : -8481.914\n",
      " Regression with ARIMA(1,0,2) errors : -13575.26\n",
      " Regression with ARIMA(0,0,2) errors : -12534.01\n",
      " Regression with ARIMA(1,0,1) errors : -13576.15\n",
      " Regression with ARIMA(2,0,1) errors : -13583.87\n",
      " Regression with ARIMA(2,0,0) errors : -13575.76\n",
      " Regression with ARIMA(3,0,1) errors : -13573.56\n",
      " Regression with ARIMA(3,0,0) errors : -13574.15\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13575.33\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13420.85\n",
      " Regression with ARIMA(1,1,0) errors : -13418.28\n",
      " Regression with ARIMA(0,1,1) errors : -13419.05\n",
      " Regression with ARIMA(0,1,0) errors : -13422.86\n",
      " Regression with ARIMA(1,1,1) errors : -13416.27\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13431.63\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13406.54\n",
      " Regression with ARIMA(1,1,0) errors : -13403.97\n",
      " Regression with ARIMA(0,1,1) errors : -13404.69\n",
      " Regression with ARIMA(0,1,0) errors : -13408.55\n",
      " Regression with ARIMA(1,1,1) errors : -13401.96\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13417.31\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13398.85\n",
      " Regression with ARIMA(1,1,0) errors : -13397.03\n",
      " Regression with ARIMA(0,1,1) errors : -13396.96\n",
      " Regression with ARIMA(0,1,0) errors : -13400.86\n",
      " Regression with ARIMA(1,1,1) errors : -13395.03\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13409.61\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13388.05\n",
      " Regression with ARIMA(1,1,0) errors : -13385.34\n",
      " Regression with ARIMA(0,1,1) errors : -13386.18\n",
      " Regression with ARIMA(0,1,0) errors : -13390.05\n",
      " Regression with ARIMA(1,1,1) errors : -13383.59\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13398.81\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13385.45\n",
      " Regression with ARIMA(1,1,0) errors : -13382.92\n",
      " Regression with ARIMA(0,1,1) errors : -13383.57\n",
      " Regression with ARIMA(0,1,0) errors : -13387.46\n",
      " Regression with ARIMA(1,1,1) errors : -13380.91\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13396.21\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13381.56\n",
      " Regression with ARIMA(1,1,0) errors : -13380.11\n",
      " Regression with ARIMA(0,1,1) errors : -13379.6\n",
      " Regression with ARIMA(0,1,0) errors : -13383.57\n",
      " Regression with ARIMA(1,1,1) errors : -13378.27\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13392.32\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13382.25\n",
      " Regression with ARIMA(1,1,0) errors : -13380.87\n",
      " Regression with ARIMA(0,1,1) errors : -13380.28\n",
      " Regression with ARIMA(0,1,0) errors : -13384.26\n",
      " Regression with ARIMA(1,1,1) errors : -13379.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13393.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13380.14\n",
      " Regression with ARIMA(1,1,0) errors : -13377.47\n",
      " Regression with ARIMA(0,1,1) errors : -13378.15\n",
      " Regression with ARIMA(0,1,0) errors : -13382.15\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.9\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13378.91\n",
      " Regression with ARIMA(1,1,0) errors : -13377.73\n",
      " Regression with ARIMA(0,1,1) errors : -13376.9\n",
      " Regression with ARIMA(0,1,0) errors : -13380.91\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13389.66\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13379.35\n",
      " Regression with ARIMA(1,1,0) errors : -13377.78\n",
      " Regression with ARIMA(0,1,1) errors : -13377.34\n",
      " Regression with ARIMA(0,1,0) errors : -13381.35\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.1\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13379.9\n",
      " Regression with ARIMA(1,1,0) errors : -13377.2\n",
      " Regression with ARIMA(0,1,1) errors : -13377.89\n",
      " Regression with ARIMA(0,1,0) errors : -13381.91\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.66\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13381.25\n",
      " Regression with ARIMA(1,1,0) errors : -13378.41\n",
      " Regression with ARIMA(0,1,1) errors : -13379.25\n",
      " Regression with ARIMA(0,1,0) errors : -13383.26\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13392.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13376.01\n",
      " Regression with ARIMA(1,1,0) errors : -13373.65\n",
      " Regression with ARIMA(0,1,1) errors : -13374\n",
      " Regression with ARIMA(0,1,0) errors : -13378.02\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13386.77\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13369.58\n",
      " Regression with ARIMA(1,1,0) errors : -13366.83\n",
      " Regression with ARIMA(0,1,1) errors : -13367.57\n",
      " Regression with ARIMA(0,1,0) errors : -13371.59\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13380.33\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13497.89\n",
      " Regression with ARIMA(0,0,0) errors : -9950.123\n",
      " Regression with ARIMA(1,0,0) errors : -13493.27\n",
      " Regression with ARIMA(0,0,1) errors : -11642.05\n",
      " Regression with ARIMA(0,0,0) errors : -8458.864\n",
      " Regression with ARIMA(1,0,2) errors : -13494.53\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -13496.04\n",
      " Regression with ARIMA(1,0,1) errors : -13495.7\n",
      " Regression with ARIMA(1,0,3) errors : -13492.7\n",
      " Regression with ARIMA(3,0,1) errors : -13497.36\n",
      " Regression with ARIMA(3,0,3) errors : -13498.01\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13507.72\n",
      " Regression with ARIMA(2,0,4) errors : -13500.47\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13500.7\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13506.03\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13499.98\n",
      " Regression with ARIMA(0,0,0) errors : -9960.775\n",
      " Regression with ARIMA(1,0,0) errors : -13495.47\n",
      " Regression with ARIMA(0,0,1) errors : -11645.81\n",
      " Regression with ARIMA(0,0,0) errors : -8453.629\n",
      " Regression with ARIMA(1,0,2) errors : -13496.49\n",
      " Regression with ARIMA(2,0,1) errors : -13507.19\n",
      " Regression with ARIMA(1,0,1) errors : -13497.52\n",
      " Regression with ARIMA(2,0,0) errors : -13496.74\n",
      " Regression with ARIMA(3,0,1) errors : -13497.31\n",
      " Regression with ARIMA(3,0,0) errors : -13495.2\n",
      " Regression with ARIMA(3,0,2) errors : -13495.71\n",
      " Regression with ARIMA(2,0,1) errors : -13378.82\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13506.74\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13497.77\n",
      " Regression with ARIMA(0,0,0) errors : -9958.269\n",
      " Regression with ARIMA(1,0,0) errors : -13494.31\n",
      " Regression with ARIMA(0,0,1) errors : -11644.45\n",
      " Regression with ARIMA(0,0,0) errors : -8449.905\n",
      " Regression with ARIMA(1,0,2) errors : -13495.3\n",
      " Regression with ARIMA(2,0,1) errors : -13507.9\n",
      " Regression with ARIMA(1,0,1) errors : -13496.33\n",
      " Regression with ARIMA(2,0,0) errors : -13495.6\n",
      " Regression with ARIMA(3,0,1) errors : -13496.54\n",
      " Regression with ARIMA(3,0,0) errors : -13493.75\n",
      " Regression with ARIMA(3,0,2) errors : -13495.71\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13508.08\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13493.96\n",
      " Regression with ARIMA(0,0,0) errors : -9977.205\n",
      " Regression with ARIMA(1,0,0) errors : -13489.97\n",
      " Regression with ARIMA(0,0,1) errors : -11647.24\n",
      " Regression with ARIMA(0,0,0) errors : -8450.876\n",
      " Regression with ARIMA(1,0,2) errors : -13490.98\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13488.95\n",
      " Regression with ARIMA(2,0,3) errors : -13487.5\n",
      " Regression with ARIMA(1,0,1) errors : -13492.01\n",
      " Regression with ARIMA(1,0,3) errors : -13489.23\n",
      " Regression with ARIMA(3,0,1) errors : -13492.37\n",
      " Regression with ARIMA(3,0,3) errors : -13486.94\n",
      " Regression with ARIMA(2,0,2) errors : -13356.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.62\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.03\n",
      " Regression with ARIMA(0,0,0) errors : -10035.28\n",
      " Regression with ARIMA(1,0,0) errors : -13487.39\n",
      " Regression with ARIMA(0,0,1) errors : -11673.35\n",
      " Regression with ARIMA(0,0,0) errors : -8457.324\n",
      " Regression with ARIMA(1,0,2) errors : -13488\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13489.24\n",
      " Regression with ARIMA(2,0,3) errors : -13489.21\n",
      " Regression with ARIMA(1,0,1) errors : -13488.93\n",
      " Regression with ARIMA(1,0,3) errors : -13486.24\n",
      " Regression with ARIMA(3,0,1) errors : -13491.09\n",
      " Regression with ARIMA(3,0,0) errors : -13487.21\n",
      " Regression with ARIMA(4,0,1) errors : -13487.57\n",
      " Regression with ARIMA(2,0,0) errors : -13488.97\n",
      " Regression with ARIMA(4,0,0) errors : -13485.19\n",
      " Regression with ARIMA(4,0,2) errors : -13498.14\n",
      " Regression with ARIMA(5,0,2) errors : -13499.05\n",
      " Regression with ARIMA(5,0,1) errors : -13492.88\n",
      " Regression with ARIMA(5,0,3) errors : -13497.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13501.63\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.2\n",
      " Regression with ARIMA(0,0,0) errors : -10019.33\n",
      " Regression with ARIMA(1,0,0) errors : -13487.57\n",
      " Regression with ARIMA(0,0,1) errors : -11667.27\n",
      " Regression with ARIMA(0,0,0) errors : -8455.887\n",
      " Regression with ARIMA(1,0,2) errors : -13488.56\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13489.44\n",
      " Regression with ARIMA(2,0,3) errors : -13490.16\n",
      " Regression with ARIMA(1,0,1) errors : -13489.31\n",
      " Regression with ARIMA(1,0,3) errors : -13486.85\n",
      " Regression with ARIMA(3,0,1) errors : -13491.32\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13350.82\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.68\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13489.2\n",
      " Regression with ARIMA(0,0,0) errors : -10028.88\n",
      " Regression with ARIMA(1,0,0) errors : -13485\n",
      " Regression with ARIMA(0,0,1) errors : -11673.96\n",
      " Regression with ARIMA(0,0,0) errors : -8443.256\n",
      " Regression with ARIMA(1,0,2) errors : -13486.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -13487.2\n",
      " Regression with ARIMA(1,0,1) errors : -13487.01\n",
      " Regression with ARIMA(1,0,3) errors : -13484.63\n",
      " Regression with ARIMA(3,0,1) errors : -13491.48\n",
      " Regression with ARIMA(3,0,0) errors : -13487\n",
      " Regression with ARIMA(4,0,1) errors : -13489.1\n",
      " Regression with ARIMA(2,0,0) errors : -13486.23\n",
      " Regression with ARIMA(4,0,0) errors : -13484.88\n",
      " Regression with ARIMA(4,0,2) errors : -13500.18\n",
      " Regression with ARIMA(5,0,2) errors : -13502.09\n",
      " Regression with ARIMA(5,0,1) errors : -13494.32\n",
      " Regression with ARIMA(5,0,3) errors : -13500.12\n",
      " Regression with ARIMA(4,0,3) errors : -13500.55\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13500.88\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492\n",
      " Regression with ARIMA(0,0,0) errors : -10028.08\n",
      " Regression with ARIMA(1,0,0) errors : -13487.35\n",
      " Regression with ARIMA(0,0,1) errors : -11679.14\n",
      " Regression with ARIMA(0,0,0) errors : -8442.705\n",
      " Regression with ARIMA(1,0,2) errors : -13488.66\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13487.58\n",
      " Regression with ARIMA(2,0,3) errors : -13489.99\n",
      " Regression with ARIMA(1,0,1) errors : -13489.51\n",
      " Regression with ARIMA(1,0,3) errors : -13487.09\n",
      " Regression with ARIMA(3,0,1) errors : -13489.86\n",
      " Regression with ARIMA(3,0,3) errors : -13482.34\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.71\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13496.48\n",
      " Regression with ARIMA(0,0,0) errors : -10046.87\n",
      " Regression with ARIMA(1,0,0) errors : -13491.11\n",
      " Regression with ARIMA(0,0,1) errors : -11686.59\n",
      " Regression with ARIMA(0,0,0) errors : -8439.819\n",
      " Regression with ARIMA(1,0,2) errors : -13492.36\n",
      " Regression with ARIMA(2,0,1) errors : -13506.72\n",
      " Regression with ARIMA(1,0,1) errors : -13493.26\n",
      " Regression with ARIMA(2,0,0) errors : -13492.87\n",
      " Regression with ARIMA(3,0,1) errors : -13494.79\n",
      " Regression with ARIMA(3,0,0) errors : -13491.08\n",
      " Regression with ARIMA(3,0,2) errors : -13506.27\n",
      " Regression with ARIMA(2,0,1) errors : -13358.47\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13505.42\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.02\n",
      " Regression with ARIMA(0,0,0) errors : -10051.63\n",
      " Regression with ARIMA(1,0,0) errors : -13487.72\n",
      " Regression with ARIMA(0,0,1) errors : -11688.79\n",
      " Regression with ARIMA(0,0,0) errors : -8460.12\n",
      " Regression with ARIMA(1,0,2) errors : -13489\n",
      " Regression with ARIMA(2,0,1) errors : -13501\n",
      " Regression with ARIMA(1,0,1) errors : -13489.93\n",
      " Regression with ARIMA(2,0,0) errors : -13489.16\n",
      " Regression with ARIMA(3,0,1) errors : -13490.72\n",
      " Regression with ARIMA(3,0,0) errors : -13487.43\n",
      " Regression with ARIMA(3,0,2) errors : -13488.68\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13501.14\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13500.43\n",
      " Regression with ARIMA(0,0,0) errors : -10047.97\n",
      " Regression with ARIMA(1,0,0) errors : -13495.4\n",
      " Regression with ARIMA(0,0,1) errors : -11686.73\n",
      " Regression with ARIMA(0,0,0) errors : -8459.472\n",
      " Regression with ARIMA(1,0,2) errors : -13496.66\n",
      " Regression with ARIMA(2,0,1) errors : -13510.38\n",
      " Regression with ARIMA(1,0,1) errors : -13497.58\n",
      " Regression with ARIMA(2,0,0) errors : -13497.07\n",
      " Regression with ARIMA(3,0,1) errors : -13498.19\n",
      " Regression with ARIMA(3,0,0) errors : -13495.29\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13509.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10051.61\n",
      " Regression with ARIMA(1,0,0) errors : -13499.36\n",
      " Regression with ARIMA(0,0,1) errors : -11694.33\n",
      " Regression with ARIMA(0,0,0) errors : -8454.72\n",
      " Regression with ARIMA(2,0,0) errors : -13501.93\n",
      " Regression with ARIMA(3,0,0) errors : -13500.22\n",
      " Regression with ARIMA(2,0,1) errors : -13512.21\n",
      " Regression with ARIMA(1,0,1) errors : -13501.76\n",
      " Regression with ARIMA(3,0,1) errors : -13503.01\n",
      " Regression with ARIMA(1,0,2) errors : -13500.7\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13514.04\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13505.3\n",
      " Regression with ARIMA(0,0,0) errors : -10067.87\n",
      " Regression with ARIMA(1,0,0) errors : -13500.56\n",
      " Regression with ARIMA(0,0,1) errors : -11703.92\n",
      " Regression with ARIMA(0,0,0) errors : -8459.352\n",
      " Regression with ARIMA(1,0,2) errors : -13501.48\n",
      " Regression with ARIMA(2,0,1) errors : -13513.92\n",
      " Regression with ARIMA(1,0,1) errors : -13502.47\n",
      " Regression with ARIMA(2,0,0) errors : -13501.76\n",
      " Regression with ARIMA(3,0,1) errors : -13504.22\n",
      " Regression with ARIMA(3,0,0) errors : -13499.98\n",
      " Regression with ARIMA(3,0,2) errors : -13502.51\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13509.66\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13504.43\n",
      " Regression with ARIMA(0,0,0) errors : -10066.73\n",
      " Regression with ARIMA(1,0,0) errors : -13500.34\n",
      " Regression with ARIMA(0,0,1) errors : -11703.9\n",
      " Regression with ARIMA(0,0,0) errors : -8459.982\n",
      " Regression with ARIMA(1,0,2) errors : -13501.46\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13502.1\n",
      " Regression with ARIMA(2,0,3) errors : -13502.47\n",
      " Regression with ARIMA(1,0,1) errors : -13502.43\n",
      " Regression with ARIMA(1,0,3) errors : -13499.75\n",
      " Regression with ARIMA(3,0,1) errors : -13504.38\n",
      " Regression with ARIMA(3,0,3) errors : -13511.67\n",
      " Regression with ARIMA(4,0,3) errors : -13502.32\n",
      " Regression with ARIMA(3,0,4) errors : -13513.38\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -13510.29\n",
      " Regression with ARIMA(3,0,5) errors : -13505.27\n",
      " Regression with ARIMA(2,0,5) errors : -13506.32\n",
      " Regression with ARIMA(4,0,5) errors : -13507.77\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13512.15\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13504.84\n",
      " Regression with ARIMA(0,0,0) errors : -10082.23\n",
      " Regression with ARIMA(1,0,0) errors : -13499.69\n",
      " Regression with ARIMA(0,0,1) errors : -11711.37\n",
      " Regression with ARIMA(0,0,0) errors : -8482.428\n",
      " Regression with ARIMA(1,0,2) errors : -13500.44\n",
      " Regression with ARIMA(2,0,1) errors : -13506.21\n",
      " Regression with ARIMA(1,0,1) errors : -13501.67\n",
      " Regression with ARIMA(2,0,0) errors : -13507.48\n",
      " Regression with ARIMA(3,0,0) errors : -13505.43\n",
      " Regression with ARIMA(3,0,1) errors : -13508.06\n",
      " Regression with ARIMA(4,0,1) errors : -13504.51\n",
      " Regression with ARIMA(3,0,2) errors : -13507\n",
      " Regression with ARIMA(4,0,0) errors : -13503.26\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -13503.39\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13511.77\n",
      " Regression with ARIMA(0,0,0) errors : -10089.38\n",
      " Regression with ARIMA(1,0,0) errors : -13508.45\n",
      " Regression with ARIMA(0,0,1) errors : -11717.82\n",
      " Regression with ARIMA(0,0,0) errors : -8486.146\n",
      " Regression with ARIMA(1,0,2) errors : -13508.73\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13508.14\n",
      " Regression with ARIMA(2,0,3) errors : -13509.84\n",
      " Regression with ARIMA(1,0,1) errors : -13509.99\n",
      " Regression with ARIMA(1,0,3) errors : -13507.09\n",
      " Regression with ARIMA(3,0,1) errors : -13509.92\n",
      " Regression with ARIMA(3,0,3) errors : -13517.49\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13519.73\n",
      " Regression with ARIMA(2,0,4) errors : -13513.32\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13514.28\n",
      " Regression with ARIMA(4,0,5) errors : -13514.96\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13520.01\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13510.51\n",
      " Regression with ARIMA(0,0,0) errors : -10105.18\n",
      " Regression with ARIMA(1,0,0) errors : -13507.88\n",
      " Regression with ARIMA(0,0,1) errors : -11721.86\n",
      " Regression with ARIMA(0,0,0) errors : -8493.114\n",
      " Regression with ARIMA(1,0,2) errors : -13508.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13516.56\n",
      " Regression with ARIMA(3,0,1) errors : -13506.85\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13515.63\n",
      " Regression with ARIMA(2,0,3) errors : -13508.55\n",
      " Regression with ARIMA(4,0,1) errors : -13509.07\n",
      " Regression with ARIMA(4,0,3) errors : -13513.32\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13519.6\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13508.31\n",
      " Regression with ARIMA(0,0,0) errors : -10126.55\n",
      " Regression with ARIMA(1,0,0) errors : -13507.44\n",
      " Regression with ARIMA(0,0,1) errors : -11732.75\n",
      " Regression with ARIMA(0,0,0) errors : -8479.726\n",
      " Regression with ARIMA(1,0,2) errors : -13507.67\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13508.26\n",
      " Regression with ARIMA(2,0,3) errors : -13506.52\n",
      " Regression with ARIMA(1,0,1) errors : -13508.92\n",
      " Regression with ARIMA(0,0,2) errors : -12538.44\n",
      " Regression with ARIMA(2,0,0) errors : -13508.97\n",
      " Regression with ARIMA(3,0,0) errors : -13506.81\n",
      " Regression with ARIMA(3,0,1) errors : -13510.29\n",
      " Regression with ARIMA(4,0,1) errors : -13507.38\n",
      " Regression with ARIMA(4,0,0) errors : -13504.51\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -13510.44\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10215.23\n",
      " Regression with ARIMA(1,0,0) errors : -13503.24\n",
      " Regression with ARIMA(0,0,1) errors : -11765.85\n",
      " Regression with ARIMA(0,0,0) errors : -8496.584\n",
      " Regression with ARIMA(2,0,0) errors : -13503.84\n",
      " Regression with ARIMA(3,0,0) errors : -13502.9\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13504.35\n",
      " Regression with ARIMA(1,0,2) errors : -13503.03\n",
      " Regression with ARIMA(0,0,2) errors : -12548.3\n",
      " Regression with ARIMA(1,0,1) errors : -13380.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13503.51\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10218.34\n",
      " Regression with ARIMA(1,0,0) errors : -13503.41\n",
      " Regression with ARIMA(0,0,1) errors : -11768.16\n",
      " Regression with ARIMA(0,0,0) errors : -8499.03\n",
      " Regression with ARIMA(2,0,0) errors : -13503.77\n",
      " Regression with ARIMA(3,0,0) errors : -13502.7\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13504.25\n",
      " Regression with ARIMA(1,0,2) errors : -13502.87\n",
      " Regression with ARIMA(0,0,2) errors : -12542.4\n",
      " Regression with ARIMA(1,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13503.42\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13509.32\n",
      " Regression with ARIMA(0,0,0) errors : -10219.25\n",
      " Regression with ARIMA(1,0,0) errors : -13507.76\n",
      " Regression with ARIMA(0,0,1) errors : -11765.04\n",
      " Regression with ARIMA(0,0,0) errors : -8502.109\n",
      " Regression with ARIMA(1,0,2) errors : -13506.99\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13502.83\n",
      " Regression with ARIMA(2,0,3) errors : -13507.36\n",
      " Regression with ARIMA(1,0,1) errors : -13508.29\n",
      " Regression with ARIMA(1,0,3) errors : -13505.45\n",
      " Regression with ARIMA(3,0,1) errors : -13506.88\n",
      " Regression with ARIMA(3,0,3) errors : -13513.93\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13514.85\n",
      " Regression with ARIMA(2,0,4) errors : -13509.02\n",
      " Regression with ARIMA(4,0,4) errors : -13512.96\n",
      " Regression with ARIMA(3,0,5) errors : -13508.01\n",
      " Regression with ARIMA(2,0,5) errors : -13510.83\n",
      " Regression with ARIMA(4,0,5) errors : -13505.08\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13517.28\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10222.58\n",
      " Regression with ARIMA(1,0,0) errors : -13506.49\n",
      " Regression with ARIMA(0,0,1) errors : -11761.77\n",
      " Regression with ARIMA(0,0,0) errors : -8501.931\n",
      " Regression with ARIMA(2,0,0) errors : -13505.83\n",
      " Regression with ARIMA(1,0,1) errors : -13506.71\n",
      " Regression with ARIMA(2,0,1) errors : -13516.88\n",
      " Regression with ARIMA(3,0,1) errors : -13512.26\n",
      " Regression with ARIMA(1,0,2) errors : -13505.56\n",
      " Regression with ARIMA(3,0,0) errors : -13505.02\n",
      " Regression with ARIMA(3,0,2) errors : -13499.27\n",
      " Regression with ARIMA(2,0,1) errors : -13367.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13503.41\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13512.51\n",
      " Regression with ARIMA(0,0,0) errors : -10227.27\n",
      " Regression with ARIMA(1,0,0) errors : -13513.98\n",
      " Regression with ARIMA(0,0,1) errors : -11762.97\n",
      " Regression with ARIMA(0,0,0) errors : -8502.27\n",
      " Regression with ARIMA(2,0,0) errors : -13514.25\n",
      " Regression with ARIMA(3,0,0) errors : -13513.04\n",
      " Regression with ARIMA(2,0,1) errors : -13512.24\n",
      " Regression with ARIMA(1,0,1) errors : -13514.02\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -13380.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,0) errors : -13511.98\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13526.34\n",
      " Regression with ARIMA(0,0,0) errors : -10223.66\n",
      " Regression with ARIMA(1,0,0) errors : -13526.45\n",
      " Regression with ARIMA(0,0,1) errors : -11757.01\n",
      " Regression with ARIMA(0,0,0) errors : -8519.276\n",
      " Regression with ARIMA(2,0,0) errors : -13525.32\n",
      " Regression with ARIMA(1,0,1) errors : -13526.23\n",
      " Regression with ARIMA(2,0,1) errors : -13535.26\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13525.01\n",
      " Regression with ARIMA(3,0,0) errors : -13523.41\n",
      " Regression with ARIMA(3,0,2) errors : -13520.69\n",
      " Regression with ARIMA(2,0,1) errors : -13408.03\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13521.31\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10227.11\n",
      " Regression with ARIMA(1,0,0) errors : -13535.83\n",
      " Regression with ARIMA(0,0,1) errors : -11776.31\n",
      " Regression with ARIMA(0,0,0) errors : -8558.409\n",
      " Regression with ARIMA(2,0,0) errors : -13535.04\n",
      " Regression with ARIMA(1,0,1) errors : -13535.63\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13535.07\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10239.17\n",
      " Regression with ARIMA(1,0,0) errors : -13532.83\n",
      " Regression with ARIMA(0,0,1) errors : -11782.72\n",
      " Regression with ARIMA(0,0,0) errors : -8566.374\n",
      " Regression with ARIMA(2,0,0) errors : -13533.02\n",
      " Regression with ARIMA(3,0,0) errors : -13531.58\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13532.77\n",
      " Regression with ARIMA(3,0,1) errors : -13532.73\n",
      " Regression with ARIMA(2,0,0) errors : -13415.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,0) errors : -13531.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13539.55\n",
      " Regression with ARIMA(0,0,0) errors : -10238.93\n",
      " Regression with ARIMA(1,0,0) errors : -13540.07\n",
      " Regression with ARIMA(0,0,1) errors : -11784.97\n",
      " Regression with ARIMA(0,0,0) errors : -8571.174\n",
      " Regression with ARIMA(2,0,0) errors : -13539.5\n",
      " Regression with ARIMA(1,0,1) errors : -13540.16\n",
      " Regression with ARIMA(2,0,1) errors : -13549.2\n",
      " Regression with ARIMA(3,0,1) errors : -13539.61\n",
      " Regression with ARIMA(1,0,2) errors : -13539.06\n",
      " Regression with ARIMA(3,0,0) errors : -13537.64\n",
      " Regression with ARIMA(3,0,2) errors : -13537.96\n",
      " Regression with ARIMA(2,0,1) errors : -13400.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13550.1\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13537.09\n",
      " Regression with ARIMA(0,0,0) errors : -10239.99\n",
      " Regression with ARIMA(1,0,0) errors : -13540.98\n",
      " Regression with ARIMA(0,0,1) errors : -11788.21\n",
      " Regression with ARIMA(0,0,0) errors : -8584.355\n",
      " Regression with ARIMA(2,0,0) errors : -13540.68\n",
      " Regression with ARIMA(1,0,1) errors : -13540.96\n",
      " Regression with ARIMA(2,0,1) errors : -13550.79\n",
      " Regression with ARIMA(3,0,1) errors : -13544.63\n",
      " Regression with ARIMA(1,0,2) errors : -13539.89\n",
      " Regression with ARIMA(3,0,0) errors : -13538.95\n",
      " Regression with ARIMA(3,0,2) errors : -13543.48\n",
      " Regression with ARIMA(2,0,1) errors : -13423.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : -13541.93\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13563.2\n",
      " Regression with ARIMA(0,0,0) errors : -10221.42\n",
      " Regression with ARIMA(1,0,0) errors : -13558.89\n",
      " Regression with ARIMA(0,0,1) errors : -11783.59\n",
      " Regression with ARIMA(0,0,0) errors : -8587.344\n",
      " Regression with ARIMA(1,0,2) errors : -13557.75\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13560.36\n",
      " Regression with ARIMA(2,0,3) errors : -13561.2\n",
      " Regression with ARIMA(1,0,1) errors : -13558.83\n",
      " Regression with ARIMA(1,0,3) errors : -13556.36\n",
      " Regression with ARIMA(3,0,1) errors : -13562.66\n",
      " Regression with ARIMA(3,0,3) errors : -13569.83\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13571.17\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -13563.95\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13566.38\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13567.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13570.4\n",
      " Regression with ARIMA(0,0,0) errors : -10190.39\n",
      " Regression with ARIMA(1,0,0) errors : -13568.75\n",
      " Regression with ARIMA(0,0,1) errors : -11771.15\n",
      " Regression with ARIMA(0,0,0) errors : -8593.643\n",
      " Regression with ARIMA(1,0,2) errors : -13567.8\n",
      " Regression with ARIMA(2,0,1) errors : -13578.25\n",
      " Regression with ARIMA(1,0,1) errors : -13568.87\n",
      " Regression with ARIMA(2,0,0) errors : -13567.98\n",
      " Regression with ARIMA(3,0,1) errors : -13566.18\n",
      " Regression with ARIMA(3,0,0) errors : -13566.18\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : -13449.02\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13568.25\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13634.9\n",
      " Regression with ARIMA(0,0,0) errors : -10190.23\n",
      " Regression with ARIMA(1,0,0) errors : -13630.94\n",
      " Regression with ARIMA(0,0,1) errors : -11790.6\n",
      " Regression with ARIMA(0,0,0) errors : -8611.59\n",
      " Regression with ARIMA(1,0,2) errors : -13631.17\n",
      " Regression with ARIMA(2,0,1) errors : -13641.72\n",
      " Regression with ARIMA(1,0,1) errors : -13631.97\n",
      " Regression with ARIMA(2,0,0) errors : -13632.33\n",
      " Regression with ARIMA(3,0,1) errors : -13630.61\n",
      " Regression with ARIMA(3,0,0) errors : -13630.85\n",
      " Regression with ARIMA(3,0,2) errors : -13642.1\n",
      " Regression with ARIMA(4,0,2) errors : -13636.63\n",
      " Regression with ARIMA(3,0,3) errors : -13640.47\n",
      " Regression with ARIMA(2,0,3) errors : -13632.93\n",
      " Regression with ARIMA(4,0,1) errors : -13631.33\n",
      " Regression with ARIMA(4,0,3) errors : -13636.07\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13640.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13645.23\n",
      " Regression with ARIMA(0,0,0) errors : -10202.47\n",
      " Regression with ARIMA(1,0,0) errors : -13645.74\n",
      " Regression with ARIMA(0,0,1) errors : -11804.3\n",
      " Regression with ARIMA(0,0,0) errors : -8622.517\n",
      " Regression with ARIMA(2,0,0) errors : -13646.54\n",
      " Regression with ARIMA(3,0,0) errors : -13646.95\n",
      " Regression with ARIMA(4,0,0) errors : -13644.57\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -13646.54\n",
      " Regression with ARIMA(3,0,0) errors : -13536.11\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,0) errors : -13645.14\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13662.78\n",
      " Regression with ARIMA(0,0,0) errors : -10203.12\n",
      " Regression with ARIMA(1,0,0) errors : -13661.7\n",
      " Regression with ARIMA(0,0,1) errors : -11801.53\n",
      " Regression with ARIMA(0,0,0) errors : -8623.09\n",
      " Regression with ARIMA(1,0,2) errors : -13661.65\n",
      " Regression with ARIMA(2,0,1) errors : -13670.27\n",
      " Regression with ARIMA(1,0,1) errors : -13662.54\n",
      " Regression with ARIMA(2,0,0) errors : -13662.03\n",
      " Regression with ARIMA(3,0,1) errors : -13660.85\n",
      " Regression with ARIMA(3,0,0) errors : -13660.75\n",
      " Regression with ARIMA(3,0,2) errors : -13668.59\n",
      " Regression with ARIMA(2,0,1) errors : -13554.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13669.89\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13665.71\n",
      " Regression with ARIMA(0,0,0) errors : -10188.87\n",
      " Regression with ARIMA(1,0,0) errors : -13663.7\n",
      " Regression with ARIMA(0,0,1) errors : -11795.42\n",
      " Regression with ARIMA(0,0,0) errors : -8643.892\n",
      " Regression with ARIMA(1,0,2) errors : -13663.8\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13660.35\n",
      " Regression with ARIMA(2,0,3) errors : -13663.69\n",
      " Regression with ARIMA(1,0,1) errors : -13664.64\n",
      " Regression with ARIMA(1,0,3) errors : -13662.17\n",
      " Regression with ARIMA(3,0,1) errors : -13664.67\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13565.22\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13665.83\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13656.64\n",
      " Regression with ARIMA(0,0,0) errors : -10191.97\n",
      " Regression with ARIMA(1,0,0) errors : -13653.06\n",
      " Regression with ARIMA(0,0,1) errors : -11788.05\n",
      " Regression with ARIMA(0,0,0) errors : -8651.602\n",
      " Regression with ARIMA(1,0,2) errors : -13653.54\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13653.21\n",
      " Regression with ARIMA(2,0,3) errors : -13654.62\n",
      " Regression with ARIMA(1,0,1) errors : -13654.33\n",
      " Regression with ARIMA(1,0,3) errors : -13651.95\n",
      " Regression with ARIMA(3,0,1) errors : -13655.42\n",
      " Regression with ARIMA(3,0,3) errors : -13661.07\n",
      " Regression with ARIMA(4,0,3) errors : -13648.86\n",
      " Regression with ARIMA(3,0,4) errors : -13662.96\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13661.06\n",
      " Regression with ARIMA(4,0,5) errors : -13659.57\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13659.73\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13649.41\n",
      " Regression with ARIMA(0,0,0) errors : -10167.99\n",
      " Regression with ARIMA(1,0,0) errors : -13648.99\n",
      " Regression with ARIMA(0,0,1) errors : -11774.26\n",
      " Regression with ARIMA(0,0,0) errors : -8653.868\n",
      " Regression with ARIMA(1,0,2) errors : -13649.56\n",
      " Regression with ARIMA(0,0,2) errors : -12612.9\n",
      " Regression with ARIMA(1,0,1) errors : -13650.24\n",
      " Regression with ARIMA(2,0,1) errors : -13660.4\n",
      " Regression with ARIMA(2,0,0) errors : -13649.71\n",
      " Regression with ARIMA(3,0,1) errors : -13651.41\n",
      " Regression with ARIMA(3,0,0) errors : -13648.4\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13661.18\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13655.63\n",
      " Regression with ARIMA(0,0,0) errors : -10165.57\n",
      " Regression with ARIMA(1,0,0) errors : -13654.18\n",
      " Regression with ARIMA(0,0,1) errors : -11773.14\n",
      " Regression with ARIMA(0,0,0) errors : -8656.522\n",
      " Regression with ARIMA(1,0,2) errors : -13654.42\n",
      " Regression with ARIMA(2,0,1) errors : -13665.49\n",
      " Regression with ARIMA(1,0,1) errors : -13655.18\n",
      " Regression with ARIMA(2,0,0) errors : -13654.5\n",
      " Regression with ARIMA(3,0,1) errors : -13655.23\n",
      " Regression with ARIMA(3,0,0) errors : -13653.04\n",
      " Regression with ARIMA(3,0,2) errors : -13653.31\n",
      " Regression with ARIMA(2,0,1) errors : -13554.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13666.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13657.3\n",
      " Regression with ARIMA(0,0,0) errors : -10165.83\n",
      " Regression with ARIMA(1,0,0) errors : -13655.15\n",
      " Regression with ARIMA(0,0,1) errors : -11771.76\n",
      " Regression with ARIMA(0,0,0) errors : -8655.923\n",
      " Regression with ARIMA(1,0,2) errors : -13655.23\n",
      " Regression with ARIMA(2,0,1) errors : -13667.08\n",
      " Regression with ARIMA(1,0,1) errors : -13656.02\n",
      " Regression with ARIMA(2,0,0) errors : -13655.19\n",
      " Regression with ARIMA(3,0,1) errors : -13655.86\n",
      " Regression with ARIMA(3,0,0) errors : -13658.04\n",
      " Regression with ARIMA(3,0,2) errors : -13655.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13666.52\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13655.6\n",
      " Regression with ARIMA(0,0,0) errors : -10159.47\n",
      " Regression with ARIMA(1,0,0) errors : -13654.74\n",
      " Regression with ARIMA(0,0,1) errors : -11765.48\n",
      " Regression with ARIMA(0,0,0) errors : -8662.39\n",
      " Regression with ARIMA(1,0,2) errors : -13655.14\n",
      " Regression with ARIMA(2,0,1) errors : -13671.56\n",
      " Regression with ARIMA(1,0,1) errors : -13655.72\n",
      " Regression with ARIMA(2,0,0) errors : -13656.86\n",
      " Regression with ARIMA(3,0,1) errors : -13656.12\n",
      " Regression with ARIMA(3,0,0) errors : -13655.95\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13665.81\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13656.79\n",
      " Regression with ARIMA(0,0,0) errors : -10173.96\n",
      " Regression with ARIMA(1,0,0) errors : -13652.05\n",
      " Regression with ARIMA(0,0,1) errors : -11777.5\n",
      " Regression with ARIMA(0,0,0) errors : -8700.468\n",
      " Regression with ARIMA(1,0,2) errors : -13652.23\n",
      " Regression with ARIMA(2,0,1) errors : -13668.02\n",
      " Regression with ARIMA(1,0,1) errors : -13652.1\n",
      " Regression with ARIMA(2,0,0) errors : -13652.19\n",
      " Regression with ARIMA(3,0,1) errors : -13656.11\n",
      " Regression with ARIMA(3,0,0) errors : -13652.01\n",
      " Regression with ARIMA(3,0,2) errors : -13662.39\n",
      " Regression with ARIMA(2,0,1) errors : -13548.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13662.69\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13625.68\n",
      " Regression with ARIMA(0,1,0) errors : -13621.46\n",
      " Regression with ARIMA(1,1,0) errors : -13624.34\n",
      " Regression with ARIMA(0,1,1) errors : -13619.6\n",
      " Regression with ARIMA(0,1,0) errors : -13623.47\n",
      " Regression with ARIMA(1,1,2) errors : -13629.17\n",
      " Regression with ARIMA(0,1,2) errors : -13617.77\n",
      " Regression with ARIMA(1,1,1) errors : -13628.01\n",
      " Regression with ARIMA(1,1,3) errors : -13633.78\n",
      " Regression with ARIMA(0,1,3) errors : -13616.46\n",
      " Regression with ARIMA(2,1,3) errors : -13627.37\n",
      " Regression with ARIMA(1,1,4) errors : -13638.05\n",
      " Regression with ARIMA(0,1,4) errors : -13614.88\n",
      " Regression with ARIMA(2,1,4) errors : -13627.68\n",
      " Regression with ARIMA(1,1,5) errors : -13657.04\n",
      " Regression with ARIMA(0,1,5) errors : -13617.4\n",
      " Regression with ARIMA(2,1,5) errors : -13647.25\n",
      " Regression with ARIMA(1,1,5) errors : -13658.92\n",
      " Regression with ARIMA(0,1,5) errors : -13619.42\n",
      " Regression with ARIMA(1,1,4) errors : -13639.93\n",
      " Regression with ARIMA(2,1,5) errors : -13649.14\n",
      " Regression with ARIMA(0,1,4) errors : -13616.89\n",
      " Regression with ARIMA(2,1,4) errors : -13629.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,0) errors : -13628.45\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13669.46\n",
      " Regression with ARIMA(0,1,0) errors : -13667.96\n",
      " Regression with ARIMA(1,1,0) errors : -13665.88\n",
      " Regression with ARIMA(0,1,1) errors : -13666.47\n",
      " Regression with ARIMA(0,1,0) errors : -13669.95\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13678.82\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10272.74\n",
      " Regression with ARIMA(1,0,0) errors : -13772.01\n",
      " Regression with ARIMA(0,0,1) errors : -11891.74\n",
      " Regression with ARIMA(0,0,0) errors : -8843.671\n",
      " Regression with ARIMA(2,0,0) errors : -13770.9\n",
      " Regression with ARIMA(1,0,1) errors : -13771.44\n",
      " Regression with ARIMA(2,0,1) errors : -13785.75\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13772.19\n",
      " Regression with ARIMA(3,0,0) errors : -13772.31\n",
      " Regression with ARIMA(3,0,2) errors : -13785.11\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13783.28\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13764.52\n",
      " Regression with ARIMA(0,0,0) errors : -10268.04\n",
      " Regression with ARIMA(1,0,0) errors : -13761.23\n",
      " Regression with ARIMA(0,0,1) errors : -11885.1\n",
      " Regression with ARIMA(0,0,0) errors : -8858.715\n",
      " Regression with ARIMA(1,0,2) errors : -13761.55\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13782.76\n",
      " Regression with ARIMA(3,0,1) errors : -13780.45\n",
      " Regression with ARIMA(4,0,2) errors : -13778.02\n",
      " Regression with ARIMA(3,0,3) errors : -13780.93\n",
      " Regression with ARIMA(2,0,3) errors : -13762.9\n",
      " Regression with ARIMA(4,0,1) errors : -13774.34\n",
      " Regression with ARIMA(4,0,3) errors : -13775.95\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13775.78\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13769.81\n",
      " Regression with ARIMA(0,0,0) errors : -10265.3\n",
      " Regression with ARIMA(1,0,0) errors : -13762.85\n",
      " Regression with ARIMA(0,0,1) errors : -11881.84\n",
      " Regression with ARIMA(0,0,0) errors : -8821.143\n",
      " Regression with ARIMA(1,0,2) errors : -13762.57\n",
      " Regression with ARIMA(2,0,1) errors : -13768.3\n",
      " Regression with ARIMA(3,0,2) errors : -13783.22\n",
      " Regression with ARIMA(3,0,1) errors : -13768.49\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13781.28\n",
      " Regression with ARIMA(2,0,3) errors : -13768.18\n",
      " Regression with ARIMA(4,0,1) errors : -13769.2\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13777.69\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13769.38\n",
      " Regression with ARIMA(0,0,0) errors : -10260.46\n",
      " Regression with ARIMA(1,0,0) errors : -13763.75\n",
      " Regression with ARIMA(0,0,1) errors : -11877.06\n",
      " Regression with ARIMA(0,0,0) errors : -8820.979\n",
      " Regression with ARIMA(1,0,2) errors : -13763.9\n",
      " Regression with ARIMA(2,0,1) errors : -13767.21\n",
      " Regression with ARIMA(3,0,2) errors : -13781.12\n",
      " Regression with ARIMA(3,0,1) errors : -13768.51\n",
      " Regression with ARIMA(4,0,2) errors : -13781.64\n",
      " Regression with ARIMA(4,0,1) errors : -13767.06\n",
      " Regression with ARIMA(5,0,2) errors : -13779.5\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13781.37\n",
      " Regression with ARIMA(5,0,1) errors : -13775.92\n",
      " Regression with ARIMA(5,0,3) errors : -13777.89\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,2) errors : -13774.84\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13730.6\n",
      " Regression with ARIMA(0,0,0) errors : -10252.14\n",
      " Regression with ARIMA(1,0,0) errors : -13734.15\n",
      " Regression with ARIMA(0,0,1) errors : -11865.14\n",
      " Regression with ARIMA(0,0,0) errors : -8811.741\n",
      " Regression with ARIMA(2,0,0) errors : -13732.86\n",
      " Regression with ARIMA(1,0,1) errors : -13733.55\n",
      " Regression with ARIMA(2,0,1) errors : -13745.03\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13733.84\n",
      " Regression with ARIMA(3,0,0) errors : -13732.77\n",
      " Regression with ARIMA(3,0,2) errors : -13730.31\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13733.34\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10248.64\n",
      " Regression with ARIMA(1,0,0) errors : -13726.11\n",
      " Regression with ARIMA(0,0,1) errors : -11859.38\n",
      " Regression with ARIMA(0,0,0) errors : -8814.75\n",
      " Regression with ARIMA(2,0,0) errors : -13726.2\n",
      " Regression with ARIMA(3,0,0) errors : -13726.52\n",
      " Regression with ARIMA(4,0,0) errors : -13725.54\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : -13736.42\n",
      " Regression with ARIMA(1,0,1) errors : -13725.25\n",
      " Regression with ARIMA(1,0,2) errors : -13725.96\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,0) errors : -13725.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10253.6\n",
      " Regression with ARIMA(1,0,0) errors : -13735.62\n",
      " Regression with ARIMA(0,0,1) errors : -11865.12\n",
      " Regression with ARIMA(0,0,0) errors : -8816.856\n",
      " Regression with ARIMA(2,0,0) errors : -13733.87\n",
      " Regression with ARIMA(1,0,1) errors : -13734.66\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13733.14\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13750.01\n",
      " Regression with ARIMA(0,0,0) errors : -10257.06\n",
      " Regression with ARIMA(1,0,0) errors : -13738.28\n",
      " Regression with ARIMA(0,0,1) errors : -11865.9\n",
      " Regression with ARIMA(0,0,0) errors : -8780.029\n",
      " Regression with ARIMA(1,0,2) errors : -13737.34\n",
      " Regression with ARIMA(2,0,1) errors : -13751.1\n",
      " Regression with ARIMA(1,0,1) errors : -13737.18\n",
      " Regression with ARIMA(2,0,0) errors : -13736.6\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,0) errors : -13736.27\n",
      " Regression with ARIMA(3,0,2) errors : -13732.63\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13735.84\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10256.83\n",
      " Regression with ARIMA(1,0,0) errors : -13730.95\n",
      " Regression with ARIMA(0,0,1) errors : -11861.77\n",
      " Regression with ARIMA(0,0,0) errors : -8779.258\n",
      " Regression with ARIMA(2,0,0) errors : -13729.15\n",
      " Regression with ARIMA(1,0,1) errors : -13729.46\n",
      " Regression with ARIMA(2,0,1) errors : -13743.66\n",
      " Regression with ARIMA(3,0,1) errors : -13740.11\n",
      " Regression with ARIMA(1,0,2) errors : -13729.66\n",
      " Regression with ARIMA(3,0,0) errors : -13731.65\n",
      " Regression with ARIMA(3,0,2) errors : -13742.18\n",
      " Regression with ARIMA(2,0,1) errors : -13618.71\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13744.27\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13704.92\n",
      " Regression with ARIMA(0,0,0) errors : -10273.67\n",
      " Regression with ARIMA(1,0,0) errors : -13706.69\n",
      " Regression with ARIMA(0,0,1) errors : -11878.39\n",
      " Regression with ARIMA(0,0,0) errors : -8797.955\n",
      " Regression with ARIMA(2,0,0) errors : -13704.19\n",
      " Regression with ARIMA(1,0,1) errors : -13704.98\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13577.35\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13704.77\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13513.55\n",
      " Regression with ARIMA(0,0,0) errors : -10068.34\n",
      " Regression with ARIMA(1,0,0) errors : -13520.38\n",
      " Regression with ARIMA(0,0,1) errors : -11654.6\n",
      " Regression with ARIMA(0,0,0) errors : -8614.487\n",
      " Regression with ARIMA(2,0,0) errors : -13517.43\n",
      " Regression with ARIMA(1,0,1) errors : -13518.38\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13517.53\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12970.83\n",
      " Regression with ARIMA(0,1,0) errors : -12930.49\n",
      " Regression with ARIMA(1,1,0) errors : -12945.11\n",
      " Regression with ARIMA(0,1,1) errors : -12947.22\n",
      " Regression with ARIMA(0,1,0) errors : -12932.5\n",
      " Regression with ARIMA(1,1,2) errors : -12962.91\n",
      " Regression with ARIMA(2,1,1) errors : -12971.71\n",
      " Regression with ARIMA(1,1,1) errors : -12955.51\n",
      " Regression with ARIMA(2,1,0) errors : -12969.84\n",
      " Regression with ARIMA(3,1,1) errors : -12974.24\n",
      " Regression with ARIMA(3,1,0) errors : -12974.64\n",
      " Regression with ARIMA(4,1,0) errors : -12978.76\n",
      " Regression with ARIMA(5,1,0) errors : -12976.29\n",
      " Regression with ARIMA(4,1,1) errors : -12976.71\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,0) errors : -12980.76\n",
      " Regression with ARIMA(3,1,0) errors : -12976.65\n",
      " Regression with ARIMA(5,1,0) errors : -12978.28\n",
      " Regression with ARIMA(4,1,1) errors : -12978.77\n",
      " Regression with ARIMA(3,1,1) errors : -12976.24\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,1,0) errors : -12980.2\n",
      "\n",
      " Best model: Regression with ARIMA(4,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12722.08\n",
      " Regression with ARIMA(0,1,0) errors : -12682.87\n",
      " Regression with ARIMA(1,1,0) errors : -12702.85\n",
      " Regression with ARIMA(0,1,1) errors : -12708.6\n",
      " Regression with ARIMA(0,1,0) errors : -12684.84\n",
      " Regression with ARIMA(1,1,2) errors : -12720.75\n",
      " Regression with ARIMA(2,1,1) errors : -12722.99\n",
      " Regression with ARIMA(1,1,1) errors : -12711.35\n",
      " Regression with ARIMA(2,1,0) errors : -12720.41\n",
      " Regression with ARIMA(3,1,1) errors : -12722.13\n",
      " Regression with ARIMA(3,1,0) errors : -12724.07\n",
      " Regression with ARIMA(4,1,0) errors : -12721.18\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -12726.05\n",
      " Regression with ARIMA(2,1,0) errors : -12722.38\n",
      " Regression with ARIMA(4,1,0) errors : -12723.17\n",
      " Regression with ARIMA(3,1,1) errors : -12724.11\n",
      " Regression with ARIMA(2,1,1) errors : -12724.96\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,0) errors : -12736.42\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12560.78\n",
      " Regression with ARIMA(0,1,0) errors : -12505.96\n",
      " Regression with ARIMA(1,1,0) errors : -12527.34\n",
      " Regression with ARIMA(0,1,1) errors : -12533.58\n",
      " Regression with ARIMA(0,1,0) errors : -12507.97\n",
      " Regression with ARIMA(1,1,2) errors : -12551.89\n",
      " Regression with ARIMA(2,1,1) errors : -12557.49\n",
      " Regression with ARIMA(3,1,2) errors : -12557.93\n",
      " Regression with ARIMA(2,1,3) errors : -12558.92\n",
      " Regression with ARIMA(1,1,1) errors : -12537.48\n",
      " Regression with ARIMA(1,1,3) errors : -12554.56\n",
      " Regression with ARIMA(3,1,1) errors : -12557.55\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12562.8\n",
      " Regression with ARIMA(1,1,2) errors : -12553.91\n",
      " Regression with ARIMA(2,1,1) errors : -12559.5\n",
      " Regression with ARIMA(3,1,2) errors : -12559.9\n",
      " Regression with ARIMA(2,1,3) errors : -12560.93\n",
      " Regression with ARIMA(1,1,1) errors : -12539.48\n",
      " Regression with ARIMA(1,1,3) errors : -12556.58\n",
      " Regression with ARIMA(3,1,1) errors : -12559.56\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12572.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12525.75\n",
      " Regression with ARIMA(0,1,0) errors : -12472.26\n",
      " Regression with ARIMA(1,1,0) errors : -12494.36\n",
      " Regression with ARIMA(0,1,1) errors : -12499.92\n",
      " Regression with ARIMA(0,1,0) errors : -12474.27\n",
      " Regression with ARIMA(1,1,2) errors : -12516.93\n",
      " Regression with ARIMA(2,1,1) errors : -12522.47\n",
      " Regression with ARIMA(3,1,2) errors : -12522.7\n",
      " Regression with ARIMA(2,1,3) errors : -12523.75\n",
      " Regression with ARIMA(1,1,1) errors : -12502.95\n",
      " Regression with ARIMA(1,1,3) errors : -12520.19\n",
      " Regression with ARIMA(3,1,1) errors : -12522.74\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12527.77\n",
      " Regression with ARIMA(1,1,2) errors : -12518.94\n",
      " Regression with ARIMA(2,1,1) errors : -12524.48\n",
      " Regression with ARIMA(3,1,2) errors : -12524.7\n",
      " Regression with ARIMA(2,1,3) errors : -12525.77\n",
      " Regression with ARIMA(1,1,1) errors : -12504.95\n",
      " Regression with ARIMA(1,1,3) errors : -12522.21\n",
      " Regression with ARIMA(3,1,1) errors : -12524.75\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12537.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12470.37\n",
      " Regression with ARIMA(0,1,0) errors : -12414.35\n",
      " Regression with ARIMA(1,1,0) errors : -12436.58\n",
      " Regression with ARIMA(0,1,1) errors : -12443.12\n",
      " Regression with ARIMA(0,1,0) errors : -12416.35\n",
      " Regression with ARIMA(1,1,2) errors : -12461.95\n",
      " Regression with ARIMA(2,1,1) errors : -12468.01\n",
      " Regression with ARIMA(3,1,2) errors : -12467.45\n",
      " Regression with ARIMA(2,1,3) errors : -12468.34\n",
      " Regression with ARIMA(1,1,1) errors : -12445.63\n",
      " Regression with ARIMA(1,1,3) errors : -12464.82\n",
      " Regression with ARIMA(3,1,1) errors : -12468.7\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12472.37\n",
      " Regression with ARIMA(1,1,2) errors : -12463.95\n",
      " Regression with ARIMA(2,1,1) errors : -12470\n",
      " Regression with ARIMA(3,1,2) errors : -12469.45\n",
      " Regression with ARIMA(2,1,3) errors : -12470.36\n",
      " Regression with ARIMA(1,1,1) errors : -12447.62\n",
      " Regression with ARIMA(1,1,3) errors : -12466.82\n",
      " Regression with ARIMA(3,1,1) errors : -12470.69\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12481.51\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12415.46\n",
      " Regression with ARIMA(0,1,0) errors : -12357.7\n",
      " Regression with ARIMA(1,1,0) errors : -12377.73\n",
      " Regression with ARIMA(0,1,1) errors : -12382.8\n",
      " Regression with ARIMA(0,1,0) errors : -12359.71\n",
      " Regression with ARIMA(1,1,2) errors : -12397.26\n",
      " Regression with ARIMA(2,1,1) errors : -12405.48\n",
      " Regression with ARIMA(3,1,2) errors : -12413.51\n",
      " Regression with ARIMA(2,1,3) errors : -12414.64\n",
      " Regression with ARIMA(1,1,1) errors : -12383.72\n",
      " Regression with ARIMA(1,1,3) errors : -12404.76\n",
      " Regression with ARIMA(3,1,1) errors : -12410.9\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12417.47\n",
      " Regression with ARIMA(1,1,2) errors : -12399.27\n",
      " Regression with ARIMA(2,1,1) errors : -12407.49\n",
      " Regression with ARIMA(3,1,2) errors : -12415.52\n",
      " Regression with ARIMA(2,1,3) errors : -12416.65\n",
      " Regression with ARIMA(1,1,1) errors : -12385.73\n",
      " Regression with ARIMA(1,1,3) errors : -12406.78\n",
      " Regression with ARIMA(3,1,1) errors : -12412.92\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12422.35\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12392.88\n",
      " Regression with ARIMA(0,1,0) errors : -12334.96\n",
      " Regression with ARIMA(1,1,0) errors : -12358.48\n",
      " Regression with ARIMA(0,1,1) errors : -12364.77\n",
      " Regression with ARIMA(0,1,0) errors : -12336.95\n",
      " Regression with ARIMA(1,1,2) errors : -12380.24\n",
      " Regression with ARIMA(2,1,1) errors : -12390.33\n",
      " Regression with ARIMA(3,1,2) errors : -12392.56\n",
      " Regression with ARIMA(2,1,3) errors : -12390.88\n",
      " Regression with ARIMA(1,1,1) errors : -12366.94\n",
      " Regression with ARIMA(1,1,3) errors : -12386.73\n",
      " Regression with ARIMA(3,1,1) errors : -12394.33\n",
      " Regression with ARIMA(3,1,0) errors : -12396.28\n",
      " Regression with ARIMA(2,1,0) errors : -12381.04\n",
      " Regression with ARIMA(4,1,0) errors : -12409.24\n",
      " Regression with ARIMA(5,1,0) errors : -12418.87\n",
      " Regression with ARIMA(5,1,1) errors : -12429.22\n",
      " Regression with ARIMA(4,1,1) errors : -12408.98\n",
      " Regression with ARIMA(5,1,2) errors : -12419\n",
      " Regression with ARIMA(4,1,2) errors : -12415.77\n",
      " Regression with ARIMA(5,1,1) errors : -12431.1\n",
      " Regression with ARIMA(4,1,1) errors : -12410.99\n",
      " Regression with ARIMA(5,1,0) errors : -12420.89\n",
      " Regression with ARIMA(5,1,2) errors : -12421.01\n",
      " Regression with ARIMA(4,1,0) errors : -12411.25\n",
      " Regression with ARIMA(4,1,2) errors : -12417.78\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,0) errors : -12408.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12405.22\n",
      " Regression with ARIMA(0,1,0) errors : -12342.22\n",
      " Regression with ARIMA(1,1,0) errors : -12369.17\n",
      " Regression with ARIMA(0,1,1) errors : -12375.11\n",
      " Regression with ARIMA(0,1,0) errors : -12344.23\n",
      " Regression with ARIMA(1,1,2) errors : -12390.01\n",
      " Regression with ARIMA(2,1,1) errors : -12397.17\n",
      " Regression with ARIMA(3,1,2) errors : -12404.33\n",
      " Regression with ARIMA(2,1,3) errors : -12403.26\n",
      " Regression with ARIMA(1,1,1) errors : -12376.7\n",
      " Regression with ARIMA(1,1,3) errors : -12397.27\n",
      " Regression with ARIMA(3,1,1) errors : -12402.52\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12407.23\n",
      " Regression with ARIMA(1,1,2) errors : -12392.02\n",
      " Regression with ARIMA(2,1,1) errors : -12399.19\n",
      " Regression with ARIMA(3,1,2) errors : -12406.34\n",
      " Regression with ARIMA(2,1,3) errors : -12405.28\n",
      " Regression with ARIMA(1,1,1) errors : -12378.71\n",
      " Regression with ARIMA(1,1,3) errors : -12399.28\n",
      " Regression with ARIMA(3,1,1) errors : -12404.53\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12418.09\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12479.1\n",
      " Regression with ARIMA(0,0,0) errors : -8904.547\n",
      " Regression with ARIMA(1,0,0) errors : -12457.86\n",
      " Regression with ARIMA(0,0,1) errors : -10586.67\n",
      " Regression with ARIMA(0,0,0) errors : -7757.971\n",
      " Regression with ARIMA(1,0,2) errors : -12470.62\n",
      " Regression with ARIMA(2,0,1) errors : -12467.78\n",
      " Regression with ARIMA(3,0,2) errors : -12535.04\n",
      " Regression with ARIMA(3,0,1) errors : -12486.22\n",
      " Regression with ARIMA(4,0,2) errors : -12504.23\n",
      " Regression with ARIMA(3,0,3) errors : -12504.59\n",
      " Regression with ARIMA(2,0,3) errors : -12501.85\n",
      " Regression with ARIMA(4,0,1) errors : -12505.69\n",
      " Regression with ARIMA(4,0,3) errors : -12533.86\n",
      " Regression with ARIMA(3,0,2) errors : -12438.48\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12506.31\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12465.71\n",
      " Regression with ARIMA(0,0,0) errors : -8892.805\n",
      " Regression with ARIMA(1,0,0) errors : -12446.23\n",
      " Regression with ARIMA(0,0,1) errors : -10571.36\n",
      " Regression with ARIMA(0,0,0) errors : -7709.597\n",
      " Regression with ARIMA(1,0,2) errors : -12458.34\n",
      " Regression with ARIMA(2,0,1) errors : -12455.94\n",
      " Regression with ARIMA(3,0,2) errors : -12524.46\n",
      " Regression with ARIMA(3,0,1) errors : -12471.77\n",
      " Regression with ARIMA(4,0,2) errors : -12490.22\n",
      " Regression with ARIMA(3,0,3) errors : -12489.3\n",
      " Regression with ARIMA(2,0,3) errors : -12488.4\n",
      " Regression with ARIMA(4,0,1) errors : -12491.45\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12529.33\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12465.29\n",
      " Regression with ARIMA(0,0,0) errors : -8894.651\n",
      " Regression with ARIMA(1,0,0) errors : -12445.35\n",
      " Regression with ARIMA(0,0,1) errors : -10573.51\n",
      " Regression with ARIMA(0,0,0) errors : -7703.577\n",
      " Regression with ARIMA(1,0,2) errors : -12457.79\n",
      " Regression with ARIMA(2,0,1) errors : -12455.34\n",
      " Regression with ARIMA(3,0,2) errors : -12521.44\n",
      " Regression with ARIMA(3,0,1) errors : -12471.75\n",
      " Regression with ARIMA(4,0,2) errors : -12489.95\n",
      " Regression with ARIMA(3,0,3) errors : -12489.87\n",
      " Regression with ARIMA(2,0,3) errors : -12487.74\n",
      " Regression with ARIMA(4,0,1) errors : -12490.93\n",
      " Regression with ARIMA(4,0,3) errors : -12517.07\n",
      " Regression with ARIMA(3,0,2) errors : -12443.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12527.75\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12457.74\n",
      " Regression with ARIMA(0,0,0) errors : -8888.053\n",
      " Regression with ARIMA(1,0,0) errors : -12438.77\n",
      " Regression with ARIMA(0,0,1) errors : -10568.72\n",
      " Regression with ARIMA(0,0,0) errors : -7699.325\n",
      " Regression with ARIMA(1,0,2) errors : -12450.59\n",
      " Regression with ARIMA(2,0,1) errors : -12447.71\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12479.45\n",
      " Regression with ARIMA(1,0,3) errors : -12482.41\n",
      " Regression with ARIMA(0,0,3) errors : -11655.39\n",
      " Regression with ARIMA(1,0,4) errors : -12480.42\n",
      " Regression with ARIMA(0,0,2) errors : -11226.37\n",
      " Regression with ARIMA(0,0,4) errors : -11987.9\n",
      " Regression with ARIMA(2,0,4) errors : -12508.61\n",
      " Regression with ARIMA(3,0,4) errors : -12510.98\n",
      " Regression with ARIMA(3,0,3) errors : -12480.89\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12508.89\n",
      " Regression with ARIMA(2,0,5) errors : -12511.16\n",
      " Regression with ARIMA(1,0,5) errors : -12481.3\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12511.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12454.54\n",
      " Regression with ARIMA(0,0,0) errors : -8881.322\n",
      " Regression with ARIMA(1,0,0) errors : -12434.91\n",
      " Regression with ARIMA(0,0,1) errors : -10562.75\n",
      " Regression with ARIMA(0,0,0) errors : -7707.396\n",
      " Regression with ARIMA(1,0,2) errors : -12446.19\n",
      " Regression with ARIMA(2,0,1) errors : -12444.84\n",
      " Regression with ARIMA(3,0,2) errors : -12469.19\n",
      " Regression with ARIMA(3,0,1) errors : -12458.01\n",
      " Regression with ARIMA(4,0,2) errors : -12484.21\n",
      " Regression with ARIMA(4,0,1) errors : -12483.69\n",
      " Regression with ARIMA(5,0,2) errors : -12502.19\n",
      " Regression with ARIMA(5,0,1) errors : -12498.17\n",
      " Regression with ARIMA(5,0,3) errors : -12504.05\n",
      " Regression with ARIMA(4,0,3) errors : -12482.32\n",
      " Regression with ARIMA(5,0,4) errors : -12490.42\n",
      " Regression with ARIMA(4,0,4) errors : -12481.71\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : -12506.66\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12464.6\n",
      " Regression with ARIMA(0,0,0) errors : -8887.118\n",
      " Regression with ARIMA(1,0,0) errors : -12445.24\n",
      " Regression with ARIMA(0,0,1) errors : -10561.18\n",
      " Regression with ARIMA(0,0,0) errors : -7708.215\n",
      " Regression with ARIMA(1,0,2) errors : -12456.91\n",
      " Regression with ARIMA(2,0,1) errors : -12455.73\n",
      " Regression with ARIMA(3,0,2) errors : -12528.24\n",
      " Regression with ARIMA(3,0,1) errors : -12470.67\n",
      " Regression with ARIMA(4,0,2) errors : -12491.02\n",
      " Regression with ARIMA(3,0,3) errors : -12487.94\n",
      " Regression with ARIMA(2,0,3) errors : -12488.17\n",
      " Regression with ARIMA(4,0,1) errors : -12491.62\n",
      " Regression with ARIMA(4,0,3) errors : -12490.61\n",
      " Regression with ARIMA(3,0,2) errors : -12436.46\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12488.78\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12482.33\n",
      " Regression with ARIMA(0,0,0) errors : -8891.815\n",
      " Regression with ARIMA(1,0,0) errors : -12463.17\n",
      " Regression with ARIMA(0,0,1) errors : -10569.71\n",
      " Regression with ARIMA(0,0,0) errors : -7717.256\n",
      " Regression with ARIMA(1,0,2) errors : -12475.08\n",
      " Regression with ARIMA(2,0,1) errors : -12474.77\n",
      " Regression with ARIMA(3,0,2) errors : -12536.91\n",
      " Regression with ARIMA(3,0,1) errors : -12489.05\n",
      " Regression with ARIMA(4,0,2) errors : -12507.21\n",
      " Regression with ARIMA(3,0,3) errors : -12507.02\n",
      " Regression with ARIMA(2,0,3) errors : -12506.61\n",
      " Regression with ARIMA(4,0,1) errors : -12508.71\n",
      " Regression with ARIMA(4,0,3) errors : -12506.62\n",
      " Regression with ARIMA(3,0,2) errors : -12453.39\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12508.55\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12503.57\n",
      " Regression with ARIMA(0,0,0) errors : -8896.241\n",
      " Regression with ARIMA(1,0,0) errors : -12485.86\n",
      " Regression with ARIMA(0,0,1) errors : -10569.77\n",
      " Regression with ARIMA(0,0,0) errors : -7714.817\n",
      " Regression with ARIMA(1,0,2) errors : -12497.82\n",
      " Regression with ARIMA(2,0,1) errors : -12496.35\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12527.94\n",
      " Regression with ARIMA(1,0,3) errors : -12530.81\n",
      " Regression with ARIMA(0,0,3) errors : -11677.03\n",
      " Regression with ARIMA(1,0,4) errors : -12528.79\n",
      " Regression with ARIMA(0,0,2) errors : -11229.55\n",
      " Regression with ARIMA(0,0,4) errors : -12012.79\n",
      " Regression with ARIMA(2,0,4) errors : -12555.48\n",
      " Regression with ARIMA(3,0,4) errors : -12559.17\n",
      " Regression with ARIMA(3,0,3) errors : -12529.19\n",
      " Regression with ARIMA(4,0,4) errors : -12555.94\n",
      " Regression with ARIMA(3,0,5) errors : -12539.67\n",
      " Regression with ARIMA(2,0,5) errors : -12558.37\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -12560.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12499.29\n",
      " Regression with ARIMA(0,0,0) errors : -8896.211\n",
      " Regression with ARIMA(1,0,0) errors : -12479.6\n",
      " Regression with ARIMA(0,0,1) errors : -10569.06\n",
      " Regression with ARIMA(0,0,0) errors : -7726.249\n",
      " Regression with ARIMA(1,0,2) errors : -12491.43\n",
      " Regression with ARIMA(2,0,1) errors : -12490.08\n",
      " Regression with ARIMA(3,0,2) errors : -12549.65\n",
      " Regression with ARIMA(3,0,1) errors : -12505.95\n",
      " Regression with ARIMA(4,0,2) errors : -12523.02\n",
      " Regression with ARIMA(3,0,3) errors : -12522.73\n",
      " Regression with ARIMA(2,0,3) errors : -12520.84\n",
      " Regression with ARIMA(4,0,1) errors : -12524.79\n",
      " Regression with ARIMA(4,0,3) errors : -12548.68\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12521.78\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12522.71\n",
      " Regression with ARIMA(0,0,0) errors : -8912.717\n",
      " Regression with ARIMA(1,0,0) errors : -12499.7\n",
      " Regression with ARIMA(0,0,1) errors : -10598.43\n",
      " Regression with ARIMA(0,0,0) errors : -7791.064\n",
      " Regression with ARIMA(1,0,2) errors : -12511.99\n",
      " Regression with ARIMA(2,0,1) errors : -12511.69\n",
      " Regression with ARIMA(3,0,2) errors : -12565.33\n",
      " Regression with ARIMA(3,0,1) errors : -12529.16\n",
      " Regression with ARIMA(4,0,2) errors : -12545.66\n",
      " Regression with ARIMA(3,0,3) errors : -12545.28\n",
      " Regression with ARIMA(2,0,3) errors : -12543.96\n",
      " Regression with ARIMA(4,0,1) errors : -12547.58\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12526.08\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.95\n",
      " Regression with ARIMA(0,0,0) errors : -8942.089\n",
      " Regression with ARIMA(1,0,0) errors : -12527.3\n",
      " Regression with ARIMA(0,0,1) errors : -10625.79\n",
      " Regression with ARIMA(0,0,0) errors : -7815.365\n",
      " Regression with ARIMA(1,0,2) errors : -12539.1\n",
      " Regression with ARIMA(2,0,1) errors : -12537.44\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12568.26\n",
      " Regression with ARIMA(1,0,3) errors : -12570.63\n",
      " Regression with ARIMA(0,0,3) errors : -11727.96\n",
      " Regression with ARIMA(1,0,4) errors : -12568.62\n",
      " Regression with ARIMA(0,0,2) errors : -11285.05\n",
      " Regression with ARIMA(0,0,4) errors : -12063.02\n",
      " Regression with ARIMA(2,0,4) errors : -12594.01\n",
      " Regression with ARIMA(3,0,4) errors : -12602.32\n",
      " Regression with ARIMA(3,0,3) errors : -12568.74\n",
      " Regression with ARIMA(4,0,4) errors : -12567.01\n",
      " Regression with ARIMA(3,0,5) errors : -12578.76\n",
      " Regression with ARIMA(2,0,5) errors : -12598.99\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12467.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -12600.43\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12532.16\n",
      " Regression with ARIMA(0,0,0) errors : -8934.83\n",
      " Regression with ARIMA(1,0,0) errors : -12512.55\n",
      " Regression with ARIMA(0,0,1) errors : -10617.82\n",
      " Regression with ARIMA(0,0,0) errors : -7779.834\n",
      " Regression with ARIMA(1,0,2) errors : -12525.18\n",
      " Regression with ARIMA(2,0,1) errors : -12523.58\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12554.76\n",
      " Regression with ARIMA(1,0,3) errors : -12557.17\n",
      " Regression with ARIMA(0,0,3) errors : -11723.56\n",
      " Regression with ARIMA(1,0,4) errors : -12555.2\n",
      " Regression with ARIMA(0,0,2) errors : -11272.84\n",
      " Regression with ARIMA(0,0,4) errors : -12053.22\n",
      " Regression with ARIMA(2,0,4) errors : -12583\n",
      " Regression with ARIMA(3,0,4) errors : -12586.36\n",
      " Regression with ARIMA(3,0,3) errors : -12555.78\n",
      " Regression with ARIMA(4,0,4) errors : -12586.4\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12572.16\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12559.34\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,5) errors : -12569.81\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : -12587.09\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12509.71\n",
      " Regression with ARIMA(0,0,0) errors : -8923.006\n",
      " Regression with ARIMA(1,0,0) errors : -12490.06\n",
      " Regression with ARIMA(0,0,1) errors : -10606.06\n",
      " Regression with ARIMA(0,0,0) errors : -7778.001\n",
      " Regression with ARIMA(1,0,2) errors : -12503.3\n",
      " Regression with ARIMA(2,0,1) errors : -12501.4\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12532.82\n",
      " Regression with ARIMA(1,0,3) errors : -12535.75\n",
      " Regression with ARIMA(0,0,3) errors : -11707.59\n",
      " Regression with ARIMA(1,0,4) errors : -12533.75\n",
      " Regression with ARIMA(0,0,2) errors : -11261.54\n",
      " Regression with ARIMA(0,0,4) errors : -12037.84\n",
      " Regression with ARIMA(2,0,4) errors : -12562.35\n",
      " Regression with ARIMA(3,0,4) errors : -12563.64\n",
      " Regression with ARIMA(3,0,3) errors : -12534.12\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12540.3\n",
      " Regression with ARIMA(2,0,5) errors : -12565.8\n",
      " Regression with ARIMA(1,0,5) errors : -12534.53\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12565.48\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12497.83\n",
      " Regression with ARIMA(0,0,0) errors : -8905.257\n",
      " Regression with ARIMA(1,0,0) errors : -12479.66\n",
      " Regression with ARIMA(0,0,1) errors : -10592.39\n",
      " Regression with ARIMA(0,0,0) errors : -7770.197\n",
      " Regression with ARIMA(1,0,2) errors : -12491.59\n",
      " Regression with ARIMA(2,0,1) errors : -12491.59\n",
      " Regression with ARIMA(3,0,2) errors : -12541.44\n",
      " Regression with ARIMA(3,0,1) errors : -12505.67\n",
      " Regression with ARIMA(4,0,2) errors : -12524.33\n",
      " Regression with ARIMA(3,0,3) errors : -12524.65\n",
      " Regression with ARIMA(2,0,3) errors : -12523.33\n",
      " Regression with ARIMA(4,0,1) errors : -12525.8\n",
      " Regression with ARIMA(4,0,3) errors : -12554.64\n",
      " Regression with ARIMA(5,0,3) errors : -12551.24\n",
      " Regression with ARIMA(4,0,4) errors : -12549.94\n",
      " Regression with ARIMA(3,0,4) errors : -12553.02\n",
      " Regression with ARIMA(5,0,2) errors : -12548.7\n",
      " Regression with ARIMA(5,0,4) errors : -12528.29\n",
      " Regression with ARIMA(4,0,3) errors : -12482.77\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12554.1\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12497.83\n",
      " Regression with ARIMA(0,0,0) errors : -8898.064\n",
      " Regression with ARIMA(1,0,0) errors : -12477.67\n",
      " Regression with ARIMA(0,0,1) errors : -10586.17\n",
      " Regression with ARIMA(0,0,0) errors : -7763.444\n",
      " Regression with ARIMA(1,0,2) errors : -12489.24\n",
      " Regression with ARIMA(2,0,1) errors : -12490.62\n",
      " Regression with ARIMA(3,0,2) errors : -12555.3\n",
      " Regression with ARIMA(3,0,1) errors : -12503.83\n",
      " Regression with ARIMA(4,0,2) errors : -12522.97\n",
      " Regression with ARIMA(3,0,3) errors : -12522.77\n",
      " Regression with ARIMA(2,0,3) errors : -12522.46\n",
      " Regression with ARIMA(4,0,1) errors : -12524.5\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12474.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12523.61\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12513.83\n",
      " Regression with ARIMA(0,0,0) errors : -8943.164\n",
      " Regression with ARIMA(1,0,0) errors : -12488.42\n",
      " Regression with ARIMA(0,0,1) errors : -10621.1\n",
      " Regression with ARIMA(0,0,0) errors : -7868.129\n",
      " Regression with ARIMA(1,0,2) errors : -12499.53\n",
      " Regression with ARIMA(2,0,1) errors : -12510\n",
      " Regression with ARIMA(3,0,2) errors : -12538.21\n",
      " Regression with ARIMA(3,0,1) errors : -12522.06\n",
      " Regression with ARIMA(4,0,2) errors : -12545.22\n",
      " Regression with ARIMA(4,0,1) errors : -12546.86\n",
      " Regression with ARIMA(4,0,0) errors : -12546.27\n",
      " Regression with ARIMA(5,0,1) errors : -12549.63\n",
      " Regression with ARIMA(5,0,0) errors : -12550.19\n",
      " Regression with ARIMA(5,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,0) errors : -12530.49\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12537.41\n",
      " Regression with ARIMA(0,0,0) errors : -8980.404\n",
      " Regression with ARIMA(1,0,0) errors : -12515.87\n",
      " Regression with ARIMA(0,0,1) errors : -10652.29\n",
      " Regression with ARIMA(0,0,0) errors : -7878.327\n",
      " Regression with ARIMA(1,0,2) errors : -12530.48\n",
      " Regression with ARIMA(2,0,1) errors : -12528.68\n",
      " Regression with ARIMA(3,0,2) errors : -12554.48\n",
      " Regression with ARIMA(3,0,1) errors : -12543.44\n",
      " Regression with ARIMA(4,0,2) errors : -12559.77\n",
      " Regression with ARIMA(4,0,1) errors : -12561.17\n",
      " Regression with ARIMA(4,0,0) errors : -12562.64\n",
      " Regression with ARIMA(3,0,0) errors : -12534.45\n",
      " Regression with ARIMA(5,0,0) errors : -12560.32\n",
      " Regression with ARIMA(5,0,1) errors : -12583.89\n",
      " Regression with ARIMA(5,0,2) errors : -12582.7\n",
      " Regression with ARIMA(5,0,1) errors : -12494.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12584.44\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.24\n",
      " Regression with ARIMA(0,0,0) errors : -8985.481\n",
      " Regression with ARIMA(1,0,0) errors : -12523.97\n",
      " Regression with ARIMA(0,0,1) errors : -10655.97\n",
      " Regression with ARIMA(0,0,0) errors : -7884.878\n",
      " Regression with ARIMA(1,0,2) errors : -12538.88\n",
      " Regression with ARIMA(2,0,1) errors : -12537.23\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12566.95\n",
      " Regression with ARIMA(1,0,3) errors : -12569.82\n",
      " Regression with ARIMA(0,0,3) errors : -11754.84\n",
      " Regression with ARIMA(1,0,4) errors : -12567.97\n",
      " Regression with ARIMA(0,0,2) errors : -11299.19\n",
      " Regression with ARIMA(0,0,4) errors : -12073.38\n",
      " Regression with ARIMA(2,0,4) errors : -12592.97\n",
      " Regression with ARIMA(3,0,4) errors : -12597.31\n",
      " Regression with ARIMA(3,0,3) errors : -12567.29\n",
      " Regression with ARIMA(4,0,4) errors : -12596.6\n",
      " Regression with ARIMA(3,0,5) errors : -12570.58\n",
      " Regression with ARIMA(2,0,5) errors : -12597.68\n",
      " Regression with ARIMA(1,0,5) errors : -12568.02\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12597.69\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12546.78\n",
      " Regression with ARIMA(0,0,0) errors : -8970.223\n",
      " Regression with ARIMA(1,0,0) errors : -12525.95\n",
      " Regression with ARIMA(0,0,1) errors : -10649.53\n",
      " Regression with ARIMA(0,0,0) errors : -7878.626\n",
      " Regression with ARIMA(1,0,2) errors : -12540.83\n",
      " Regression with ARIMA(2,0,1) errors : -12539.25\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12568.27\n",
      " Regression with ARIMA(1,0,3) errors : -12571.19\n",
      " Regression with ARIMA(0,0,3) errors : -11751.13\n",
      " Regression with ARIMA(1,0,4) errors : -12569.31\n",
      " Regression with ARIMA(0,0,2) errors : -11296.38\n",
      " Regression with ARIMA(0,0,4) errors : -12067\n",
      " Regression with ARIMA(2,0,4) errors : -12594.34\n",
      " Regression with ARIMA(3,0,4) errors : -12595.54\n",
      " Regression with ARIMA(3,0,3) errors : -12568.5\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12574.84\n",
      " Regression with ARIMA(2,0,5) errors : -12598.8\n",
      " Regression with ARIMA(1,0,5) errors : -12569.08\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12597.59\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.79\n",
      " Regression with ARIMA(0,0,0) errors : -8964.909\n",
      " Regression with ARIMA(1,0,0) errors : -12525.68\n",
      " Regression with ARIMA(0,0,1) errors : -10646.25\n",
      " Regression with ARIMA(0,0,0) errors : -7885.222\n",
      " Regression with ARIMA(1,0,2) errors : -12540.83\n",
      " Regression with ARIMA(2,0,1) errors : -12539.59\n",
      " Regression with ARIMA(3,0,2) errors : -12603.07\n",
      " Regression with ARIMA(3,0,1) errors : -12554.12\n",
      " Regression with ARIMA(4,0,2) errors : -12569.57\n",
      " Regression with ARIMA(3,0,3) errors : -12569.71\n",
      " Regression with ARIMA(2,0,3) errors : -12568.45\n",
      " Regression with ARIMA(4,0,1) errors : -12570.93\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12494.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12570.9\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12548.69\n",
      " Regression with ARIMA(0,0,0) errors : -8959.862\n",
      " Regression with ARIMA(1,0,0) errors : -12529.05\n",
      " Regression with ARIMA(0,0,1) errors : -10643.71\n",
      " Regression with ARIMA(0,0,0) errors : -7886.635\n",
      " Regression with ARIMA(1,0,2) errors : -12544.11\n",
      " Regression with ARIMA(2,0,1) errors : -12544.13\n",
      " Regression with ARIMA(3,0,2) errors : -12571.06\n",
      " Regression with ARIMA(3,0,1) errors : -12561.51\n",
      " Regression with ARIMA(4,0,2) errors : -12576.07\n",
      " Regression with ARIMA(4,0,1) errors : -12578.07\n",
      " Regression with ARIMA(4,0,0) errors : -12579.62\n",
      " Regression with ARIMA(3,0,0) errors : -12551.25\n",
      " Regression with ARIMA(5,0,0) errors : -12579.64\n",
      " Regression with ARIMA(5,0,1) errors : Inf\n",
      " Regression with ARIMA(5,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,0) errors : -12575.23\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12551.97\n",
      " Regression with ARIMA(0,0,0) errors : -8967.683\n",
      " Regression with ARIMA(1,0,0) errors : -12529.69\n",
      " Regression with ARIMA(0,0,1) errors : -10653.67\n",
      " Regression with ARIMA(0,0,0) errors : -7896.484\n",
      " Regression with ARIMA(1,0,2) errors : -12544.97\n",
      " Regression with ARIMA(2,0,1) errors : -12543.7\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12573.37\n",
      " Regression with ARIMA(1,0,3) errors : -12575.68\n",
      " Regression with ARIMA(0,0,3) errors : -11753.95\n",
      " Regression with ARIMA(1,0,4) errors : -12573.8\n",
      " Regression with ARIMA(0,0,2) errors : -11300.67\n",
      " Regression with ARIMA(0,0,4) errors : -12074.69\n",
      " Regression with ARIMA(2,0,4) errors : -12591.45\n",
      " Regression with ARIMA(3,0,4) errors : -12595.99\n",
      " Regression with ARIMA(3,0,3) errors : -12573.8\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12580.86\n",
      " Regression with ARIMA(2,0,5) errors : -12597\n",
      " Regression with ARIMA(1,0,5) errors : -12573.86\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12603.04\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12556.25\n",
      " Regression with ARIMA(0,0,0) errors : -8962.755\n",
      " Regression with ARIMA(1,0,0) errors : -12535.8\n",
      " Regression with ARIMA(0,0,1) errors : -10648.64\n",
      " Regression with ARIMA(0,0,0) errors : -7898.839\n",
      " Regression with ARIMA(1,0,2) errors : -12550.14\n",
      " Regression with ARIMA(2,0,1) errors : -12548.54\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12578.72\n",
      " Regression with ARIMA(1,0,3) errors : -12581.63\n",
      " Regression with ARIMA(0,0,3) errors : -11752.88\n",
      " Regression with ARIMA(1,0,4) errors : -12579.7\n",
      " Regression with ARIMA(0,0,2) errors : -11299.22\n",
      " Regression with ARIMA(0,0,4) errors : -12072.91\n",
      " Regression with ARIMA(2,0,4) errors : -12605.06\n",
      " Regression with ARIMA(3,0,4) errors : -12603.2\n",
      " Regression with ARIMA(2,0,5) errors : -12609.26\n",
      " Regression with ARIMA(1,0,5) errors : -12579.72\n",
      " Regression with ARIMA(3,0,5) errors : -12582.04\n",
      " Regression with ARIMA(2,0,5) errors : -12540.55\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12607.82\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12570.6\n",
      " Regression with ARIMA(0,0,0) errors : -8967.56\n",
      " Regression with ARIMA(1,0,0) errors : -12549.25\n",
      " Regression with ARIMA(0,0,1) errors : -10654.34\n",
      " Regression with ARIMA(0,0,0) errors : -7906.854\n",
      " Regression with ARIMA(1,0,2) errors : -12564.03\n",
      " Regression with ARIMA(2,0,1) errors : -12563.91\n",
      " Regression with ARIMA(3,0,2) errors : -12627.87\n",
      " Regression with ARIMA(3,0,1) errors : -12577.27\n",
      " Regression with ARIMA(4,0,2) errors : -12593.34\n",
      " Regression with ARIMA(3,0,3) errors : -12593.82\n",
      " Regression with ARIMA(2,0,3) errors : -12593.22\n",
      " Regression with ARIMA(4,0,1) errors : -12594.72\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12522.09\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12594.39\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12576.56\n",
      " Regression with ARIMA(0,0,0) errors : -8968.532\n",
      " Regression with ARIMA(1,0,0) errors : -12555.14\n",
      " Regression with ARIMA(0,0,1) errors : -10657.19\n",
      " Regression with ARIMA(0,0,0) errors : -7936.331\n",
      " Regression with ARIMA(1,0,2) errors : -12569.91\n",
      " Regression with ARIMA(2,0,1) errors : -12570.88\n",
      " Regression with ARIMA(3,0,2) errors : -12594.83\n",
      " Regression with ARIMA(3,0,1) errors : -12583.62\n",
      " Regression with ARIMA(4,0,2) errors : -12601.21\n",
      " Regression with ARIMA(4,0,1) errors : -12602.62\n",
      " Regression with ARIMA(4,0,0) errors : -12603.98\n",
      " Regression with ARIMA(3,0,0) errors : -12574.44\n",
      " Regression with ARIMA(5,0,0) errors : -12601.82\n",
      " Regression with ARIMA(5,0,1) errors : -12626.33\n",
      " Regression with ARIMA(5,0,2) errors : -12625.22\n",
      " Regression with ARIMA(5,0,1) errors : -12547.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12620.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12601.85\n",
      " Regression with ARIMA(0,0,0) errors : -9048.224\n",
      " Regression with ARIMA(1,0,0) errors : -12582.93\n",
      " Regression with ARIMA(0,0,1) errors : -10732.82\n",
      " Regression with ARIMA(0,0,0) errors : -8067.123\n",
      " Regression with ARIMA(1,0,2) errors : -12598.44\n",
      " Regression with ARIMA(2,0,1) errors : -12601.12\n",
      " Regression with ARIMA(3,0,2) errors : -12619.05\n",
      " Regression with ARIMA(3,0,1) errors : -12618.74\n",
      " Regression with ARIMA(4,0,2) errors : -12650.56\n",
      " Regression with ARIMA(4,0,1) errors : -12652.27\n",
      " Regression with ARIMA(4,0,0) errors : -12652.06\n",
      " Regression with ARIMA(5,0,1) errors : -12662.55\n",
      " Regression with ARIMA(5,0,0) errors : -12658.45\n",
      " Regression with ARIMA(5,0,2) errors : -12663.08\n",
      " Regression with ARIMA(5,0,3) errors : -12661.14\n",
      " Regression with ARIMA(4,0,3) errors : -12649.44\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -12652.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12607.62\n",
      " Regression with ARIMA(0,0,0) errors : -9029.222\n",
      " Regression with ARIMA(1,0,0) errors : -12581.78\n",
      " Regression with ARIMA(0,0,1) errors : -10679.8\n",
      " Regression with ARIMA(0,0,0) errors : -7988.616\n",
      " Regression with ARIMA(1,0,2) errors : -12606.76\n",
      " Regression with ARIMA(2,0,1) errors : -12606.03\n",
      " Regression with ARIMA(3,0,2) errors : -12633.3\n",
      " Regression with ARIMA(3,0,1) errors : -12616.63\n",
      " Regression with ARIMA(4,0,2) errors : -12637.18\n",
      " Regression with ARIMA(4,0,1) errors : -12639.14\n",
      " Regression with ARIMA(4,0,0) errors : -12638.63\n",
      " Regression with ARIMA(5,0,1) errors : -12657.77\n",
      " Regression with ARIMA(5,0,0) errors : -12639.34\n",
      " Regression with ARIMA(5,0,2) errors : -12656.11\n",
      " Regression with ARIMA(5,0,1) errors : -12576.93\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12665.38\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12515.14\n",
      " Regression with ARIMA(0,1,0) errors : -12443.47\n",
      " Regression with ARIMA(1,1,0) errors : -12487.68\n",
      " Regression with ARIMA(0,1,1) errors : -12495.53\n",
      " Regression with ARIMA(0,1,0) errors : -12445.47\n",
      " Regression with ARIMA(1,1,2) errors : -12499.79\n",
      " Regression with ARIMA(2,1,1) errors : -12505.72\n",
      " Regression with ARIMA(3,1,2) errors : -12545.83\n",
      " Regression with ARIMA(3,1,1) errors : -12512.71\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -12547.75\n",
      " Regression with ARIMA(2,1,2) errors : -12517.15\n",
      " Regression with ARIMA(3,1,1) errors : -12514.72\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -12507.73\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12527.28\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12606.67\n",
      " Regression with ARIMA(0,0,0) errors : -9078.123\n",
      " Regression with ARIMA(1,0,0) errors : -12575.25\n",
      " Regression with ARIMA(0,0,1) errors : -10725.64\n",
      " Regression with ARIMA(0,0,0) errors : -8063.193\n",
      " Regression with ARIMA(1,0,2) errors : -12597.15\n",
      " Regression with ARIMA(2,0,1) errors : -12601.19\n",
      " Regression with ARIMA(3,0,2) errors : -12625.54\n",
      " Regression with ARIMA(3,0,1) errors : -12611.94\n",
      " Regression with ARIMA(4,0,2) errors : -12627.49\n",
      " Regression with ARIMA(4,0,1) errors : -12627.75\n",
      " Regression with ARIMA(4,0,0) errors : -12627.47\n",
      " Regression with ARIMA(5,0,1) errors : -12646.75\n",
      " Regression with ARIMA(5,0,0) errors : -12630.02\n",
      " Regression with ARIMA(5,0,2) errors : -12645.2\n",
      " Regression with ARIMA(5,0,1) errors : -12548.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12650.4\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12592.63\n",
      " Regression with ARIMA(0,0,0) errors : -9082.048\n",
      " Regression with ARIMA(1,0,0) errors : -12566.66\n",
      " Regression with ARIMA(0,0,1) errors : -10726.09\n",
      " Regression with ARIMA(0,0,0) errors : -8059.077\n",
      " Regression with ARIMA(1,0,2) errors : -12588.96\n",
      " Regression with ARIMA(2,0,1) errors : -12589.11\n",
      " Regression with ARIMA(3,0,2) errors : -12638.23\n",
      " Regression with ARIMA(3,0,1) errors : -12600.16\n",
      " Regression with ARIMA(4,0,2) errors : -12617.62\n",
      " Regression with ARIMA(3,0,3) errors : -12618.48\n",
      " Regression with ARIMA(2,0,3) errors : -12614.14\n",
      " Regression with ARIMA(4,0,1) errors : -12616.7\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12548.15\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12652.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12584\n",
      " Regression with ARIMA(0,0,0) errors : -9072.623\n",
      " Regression with ARIMA(1,0,0) errors : -12558.92\n",
      " Regression with ARIMA(0,0,1) errors : -10724.45\n",
      " Regression with ARIMA(0,0,0) errors : -8059.797\n",
      " Regression with ARIMA(1,0,2) errors : -12579.62\n",
      " Regression with ARIMA(2,0,1) errors : -12579.45\n",
      " Regression with ARIMA(3,0,2) errors : -12637.15\n",
      " Regression with ARIMA(3,0,1) errors : -12590.09\n",
      " Regression with ARIMA(4,0,2) errors : -12609.14\n",
      " Regression with ARIMA(3,0,3) errors : -12608.81\n",
      " Regression with ARIMA(2,0,3) errors : -12605.33\n",
      " Regression with ARIMA(4,0,1) errors : -12609.45\n",
      " Regression with ARIMA(4,0,3) errors : -12638.04\n",
      " Regression with ARIMA(5,0,3) errors : -12624.89\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12633.6\n",
      " Regression with ARIMA(5,0,2) errors : -12623.44\n",
      " Regression with ARIMA(5,0,4) errors : -12618.15\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12645.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12597.56\n",
      " Regression with ARIMA(0,0,0) errors : -9087.133\n",
      " Regression with ARIMA(1,0,0) errors : -12572.15\n",
      " Regression with ARIMA(0,0,1) errors : -10736.93\n",
      " Regression with ARIMA(0,0,0) errors : -8079.117\n",
      " Regression with ARIMA(1,0,2) errors : -12594.14\n",
      " Regression with ARIMA(2,0,1) errors : -12593.03\n",
      " Regression with ARIMA(3,0,2) errors : -12658.36\n",
      " Regression with ARIMA(3,0,1) errors : -12603.77\n",
      " Regression with ARIMA(4,0,2) errors : -12622.07\n",
      " Regression with ARIMA(3,0,3) errors : -12622.59\n",
      " Regression with ARIMA(2,0,3) errors : -12619.12\n",
      " Regression with ARIMA(4,0,1) errors : -12620.82\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12548.61\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12655.81\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12610.85\n",
      " Regression with ARIMA(0,0,0) errors : -9095.509\n",
      " Regression with ARIMA(1,0,0) errors : -12584.86\n",
      " Regression with ARIMA(0,0,1) errors : -10749.33\n",
      " Regression with ARIMA(0,0,0) errors : -8097.852\n",
      " Regression with ARIMA(1,0,2) errors : -12606.97\n",
      " Regression with ARIMA(2,0,1) errors : -12608.39\n",
      " Regression with ARIMA(3,0,2) errors : -12658.34\n",
      " Regression with ARIMA(3,0,1) errors : -12619.38\n",
      " Regression with ARIMA(4,0,2) errors : -12636.67\n",
      " Regression with ARIMA(3,0,3) errors : -12637.2\n",
      " Regression with ARIMA(2,0,3) errors : -12634.49\n",
      " Regression with ARIMA(4,0,1) errors : -12636.79\n",
      " Regression with ARIMA(4,0,3) errors : -12679.01\n",
      " Regression with ARIMA(5,0,3) errors : -12665.31\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12669.72\n",
      " Regression with ARIMA(5,0,2) errors : -12665.96\n",
      " Regression with ARIMA(5,0,4) errors : -12644.1\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12661.83\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.42\n",
      " Regression with ARIMA(0,0,0) errors : -9117.955\n",
      " Regression with ARIMA(1,0,0) errors : -12604.61\n",
      " Regression with ARIMA(0,0,1) errors : -10769.78\n",
      " Regression with ARIMA(0,0,0) errors : -8106.906\n",
      " Regression with ARIMA(1,0,2) errors : -12626.91\n",
      " Regression with ARIMA(2,0,1) errors : -12625.67\n",
      " Regression with ARIMA(3,0,2) errors : -12690.09\n",
      " Regression with ARIMA(3,0,1) errors : -12637.43\n",
      " Regression with ARIMA(4,0,2) errors : -12655.81\n",
      " Regression with ARIMA(3,0,3) errors : -12655.49\n",
      " Regression with ARIMA(2,0,3) errors : -12652.79\n",
      " Regression with ARIMA(4,0,1) errors : -12654.8\n",
      " Regression with ARIMA(4,0,3) errors : -12693.24\n",
      " Regression with ARIMA(5,0,3) errors : -12662.02\n",
      " Regression with ARIMA(4,0,4) errors : -12671.03\n",
      " Regression with ARIMA(3,0,4) errors : -12677.48\n",
      " Regression with ARIMA(5,0,2) errors : -12662.99\n",
      " Regression with ARIMA(5,0,4) errors : -12675.56\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12692.59\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12641.13\n",
      " Regression with ARIMA(0,0,0) errors : -9120.512\n",
      " Regression with ARIMA(1,0,0) errors : -12614.69\n",
      " Regression with ARIMA(0,0,1) errors : -10777.29\n",
      " Regression with ARIMA(0,0,0) errors : -8113.97\n",
      " Regression with ARIMA(1,0,2) errors : -12636.3\n",
      " Regression with ARIMA(2,0,1) errors : -12634.97\n",
      " Regression with ARIMA(3,0,2) errors : -12703.57\n",
      " Regression with ARIMA(3,0,1) errors : -12648.05\n",
      " Regression with ARIMA(4,0,2) errors : -12667.51\n",
      " Regression with ARIMA(3,0,3) errors : -12666.81\n",
      " Regression with ARIMA(2,0,3) errors : -12663.2\n",
      " Regression with ARIMA(4,0,1) errors : -12665.98\n",
      " Regression with ARIMA(4,0,3) errors : -12703.17\n",
      " Regression with ARIMA(3,0,2) errors : -12608.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.93\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12643.6\n",
      " Regression with ARIMA(0,0,0) errors : -9119.216\n",
      " Regression with ARIMA(1,0,0) errors : -12616.26\n",
      " Regression with ARIMA(0,0,1) errors : -10777.52\n",
      " Regression with ARIMA(0,0,0) errors : -8101.041\n",
      " Regression with ARIMA(1,0,2) errors : -12637.47\n",
      " Regression with ARIMA(2,0,1) errors : -12640.52\n",
      " Regression with ARIMA(3,0,2) errors : -12680.71\n",
      " Regression with ARIMA(3,0,1) errors : -12652.57\n",
      " Regression with ARIMA(4,0,2) errors : -12672.29\n",
      " Regression with ARIMA(3,0,3) errors : -12671.04\n",
      " Regression with ARIMA(2,0,3) errors : -12668.46\n",
      " Regression with ARIMA(4,0,1) errors : -12671.99\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12605.13\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12704.4\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12641.82\n",
      " Regression with ARIMA(0,0,0) errors : -9125.129\n",
      " Regression with ARIMA(1,0,0) errors : -12617.13\n",
      " Regression with ARIMA(0,0,1) errors : -10783.88\n",
      " Regression with ARIMA(0,0,0) errors : -8122.685\n",
      " Regression with ARIMA(1,0,2) errors : -12638.09\n",
      " Regression with ARIMA(2,0,1) errors : -12636.93\n",
      " Regression with ARIMA(3,0,2) errors : -12695.39\n",
      " Regression with ARIMA(3,0,1) errors : -12649.51\n",
      " Regression with ARIMA(4,0,2) errors : -12667.03\n",
      " Regression with ARIMA(3,0,3) errors : -12667.49\n",
      " Regression with ARIMA(2,0,3) errors : -12664.06\n",
      " Regression with ARIMA(4,0,1) errors : -12666.82\n",
      " Regression with ARIMA(4,0,3) errors : -12707.83\n",
      " Regression with ARIMA(5,0,3) errors : -12686.77\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12686.56\n",
      " Regression with ARIMA(5,0,2) errors : -12685.94\n",
      " Regression with ARIMA(5,0,4) errors : -12670.08\n",
      " Regression with ARIMA(4,0,3) errors : -12637.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12704.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12640.83\n",
      " Regression with ARIMA(0,0,0) errors : -9124.201\n",
      " Regression with ARIMA(1,0,0) errors : -12614.79\n",
      " Regression with ARIMA(0,0,1) errors : -10783.44\n",
      " Regression with ARIMA(0,0,0) errors : -8122.209\n",
      " Regression with ARIMA(1,0,2) errors : -12635.64\n",
      " Regression with ARIMA(2,0,1) errors : -12634.86\n",
      " Regression with ARIMA(3,0,2) errors : -12695.41\n",
      " Regression with ARIMA(3,0,1) errors : -12647.57\n",
      " Regression with ARIMA(4,0,2) errors : -12665.91\n",
      " Regression with ARIMA(3,0,3) errors : -12665.62\n",
      " Regression with ARIMA(2,0,3) errors : -12662.3\n",
      " Regression with ARIMA(4,0,1) errors : -12664.73\n",
      " Regression with ARIMA(4,0,3) errors : -12708.36\n",
      " Regression with ARIMA(5,0,3) errors : -12683.74\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12676.17\n",
      " Regression with ARIMA(4,0,3) errors : -12636.53\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12702.9\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.35\n",
      " Regression with ARIMA(0,0,0) errors : -9121.854\n",
      " Regression with ARIMA(1,0,0) errors : -12613.51\n",
      " Regression with ARIMA(0,0,1) errors : -10782.18\n",
      " Regression with ARIMA(0,0,0) errors : -8117.61\n",
      " Regression with ARIMA(1,0,2) errors : -12633.27\n",
      " Regression with ARIMA(2,0,1) errors : -12632.06\n",
      " Regression with ARIMA(3,0,2) errors : -12698.45\n",
      " Regression with ARIMA(3,0,1) errors : -12643.7\n",
      " Regression with ARIMA(4,0,2) errors : -12660.83\n",
      " Regression with ARIMA(3,0,3) errors : -12661.66\n",
      " Regression with ARIMA(2,0,3) errors : -12658.11\n",
      " Regression with ARIMA(4,0,1) errors : -12659.62\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12597.25\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12700.82\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.09\n",
      " Regression with ARIMA(0,0,0) errors : -9116.676\n",
      " Regression with ARIMA(1,0,0) errors : -12611.67\n",
      " Regression with ARIMA(0,0,1) errors : -10780.74\n",
      " Regression with ARIMA(0,0,0) errors : -8116.581\n",
      " Regression with ARIMA(1,0,2) errors : -12630.99\n",
      " Regression with ARIMA(2,0,1) errors : -12629.63\n",
      " Regression with ARIMA(3,0,2) errors : -12699.18\n",
      " Regression with ARIMA(3,0,1) errors : -12641.18\n",
      " Regression with ARIMA(4,0,2) errors : -12658.75\n",
      " Regression with ARIMA(3,0,3) errors : -12659.44\n",
      " Regression with ARIMA(2,0,3) errors : -12655.65\n",
      " Regression with ARIMA(4,0,1) errors : -12657.53\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12615.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12699.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12639.03\n",
      " Regression with ARIMA(0,0,0) errors : -9117.537\n",
      " Regression with ARIMA(1,0,0) errors : -12615.18\n",
      " Regression with ARIMA(0,0,1) errors : -10783.7\n",
      " Regression with ARIMA(0,0,0) errors : -8118.136\n",
      " Regression with ARIMA(1,0,2) errors : -12634.65\n",
      " Regression with ARIMA(2,0,1) errors : -12633.24\n",
      " Regression with ARIMA(3,0,2) errors : -12699.98\n",
      " Regression with ARIMA(3,0,1) errors : -12645.33\n",
      " Regression with ARIMA(4,0,2) errors : -12662.46\n",
      " Regression with ARIMA(3,0,3) errors : -12663.29\n",
      " Regression with ARIMA(2,0,3) errors : -12659.28\n",
      " Regression with ARIMA(4,0,1) errors : -12661.46\n",
      " Regression with ARIMA(4,0,3) errors : -12704.33\n",
      " Regression with ARIMA(5,0,3) errors : -12680.72\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12676.03\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12672.54\n",
      " Regression with ARIMA(4,0,3) errors : -12599.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12703.36\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.78\n",
      " Regression with ARIMA(0,0,0) errors : -9113.603\n",
      " Regression with ARIMA(1,0,0) errors : -12610.36\n",
      " Regression with ARIMA(0,0,1) errors : -10781.97\n",
      " Regression with ARIMA(0,0,0) errors : -8111.354\n",
      " Regression with ARIMA(1,0,2) errors : -12629.21\n",
      " Regression with ARIMA(2,0,1) errors : -12627.93\n",
      " Regression with ARIMA(3,0,2) errors : -12693.18\n",
      " Regression with ARIMA(3,0,1) errors : -12639.63\n",
      " Regression with ARIMA(4,0,2) errors : -12657.34\n",
      " Regression with ARIMA(3,0,3) errors : -12657.78\n",
      " Regression with ARIMA(2,0,3) errors : -12654.23\n",
      " Regression with ARIMA(4,0,1) errors : -12656.4\n",
      " Regression with ARIMA(4,0,3) errors : -12699.31\n",
      " Regression with ARIMA(5,0,3) errors : -12674.55\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12675.54\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12667.95\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.07\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.46\n",
      " Regression with ARIMA(0,0,0) errors : -9119.245\n",
      " Regression with ARIMA(1,0,0) errors : -12613.96\n",
      " Regression with ARIMA(0,0,1) errors : -10785.81\n",
      " Regression with ARIMA(0,0,0) errors : -8116.382\n",
      " Regression with ARIMA(1,0,2) errors : -12632.76\n",
      " Regression with ARIMA(2,0,1) errors : -12631.28\n",
      " Regression with ARIMA(3,0,2) errors : -12700.56\n",
      " Regression with ARIMA(3,0,1) errors : -12643.51\n",
      " Regression with ARIMA(4,0,2) errors : -12660.35\n",
      " Regression with ARIMA(3,0,3) errors : -12660.75\n",
      " Regression with ARIMA(2,0,3) errors : -12657.34\n",
      " Regression with ARIMA(4,0,1) errors : -12659.28\n",
      " Regression with ARIMA(4,0,3) errors : -12705.25\n",
      " Regression with ARIMA(5,0,3) errors : -12677.25\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12659.26\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12674.2\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12701.28\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.91\n",
      " Regression with ARIMA(0,0,0) errors : -9115.346\n",
      " Regression with ARIMA(1,0,0) errors : -12609.25\n",
      " Regression with ARIMA(0,0,1) errors : -10783.59\n",
      " Regression with ARIMA(0,0,0) errors : -8119.022\n",
      " Regression with ARIMA(1,0,2) errors : -12628.07\n",
      " Regression with ARIMA(2,0,1) errors : -12626.55\n",
      " Regression with ARIMA(3,0,2) errors : -12695.08\n",
      " Regression with ARIMA(3,0,1) errors : -12639.09\n",
      " Regression with ARIMA(4,0,2) errors : -12655.57\n",
      " Regression with ARIMA(3,0,3) errors : -12655.97\n",
      " Regression with ARIMA(2,0,3) errors : -12652.64\n",
      " Regression with ARIMA(4,0,1) errors : -12654.48\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12608.86\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12697.61\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12634.77\n",
      " Regression with ARIMA(0,0,0) errors : -9112.722\n",
      " Regression with ARIMA(1,0,0) errors : -12611.67\n",
      " Regression with ARIMA(0,0,1) errors : -10782.69\n",
      " Regression with ARIMA(0,0,0) errors : -8118.407\n",
      " Regression with ARIMA(1,0,2) errors : -12630.3\n",
      " Regression with ARIMA(2,0,1) errors : -12628.79\n",
      " Regression with ARIMA(3,0,2) errors : -12698.97\n",
      " Regression with ARIMA(3,0,1) errors : -12640.78\n",
      " Regression with ARIMA(4,0,2) errors : -12656.92\n",
      " Regression with ARIMA(3,0,3) errors : -12657.7\n",
      " Regression with ARIMA(2,0,3) errors : -12654.48\n",
      " Regression with ARIMA(4,0,1) errors : -12655.94\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12604.1\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12699.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.36\n",
      " Regression with ARIMA(0,0,0) errors : -9119.25\n",
      " Regression with ARIMA(1,0,0) errors : -12613.66\n",
      " Regression with ARIMA(0,0,1) errors : -10784.04\n",
      " Regression with ARIMA(0,0,0) errors : -8121.82\n",
      " Regression with ARIMA(1,0,2) errors : -12632.84\n",
      " Regression with ARIMA(2,0,1) errors : -12631.38\n",
      " Regression with ARIMA(3,0,2) errors : -12686.69\n",
      " Regression with ARIMA(3,0,1) errors : -12643.65\n",
      " Regression with ARIMA(4,0,2) errors : -12661.74\n",
      " Regression with ARIMA(3,0,3) errors : -12661.05\n",
      " Regression with ARIMA(2,0,3) errors : -12657.15\n",
      " Regression with ARIMA(4,0,1) errors : -12661.45\n",
      " Regression with ARIMA(4,0,3) errors : -12661.55\n",
      " Regression with ARIMA(3,0,2) errors : -12592.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.86\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.03\n",
      " Regression with ARIMA(0,0,0) errors : -9124.803\n",
      " Regression with ARIMA(1,0,0) errors : -12611.58\n",
      " Regression with ARIMA(0,0,1) errors : -10785.79\n",
      " Regression with ARIMA(0,0,0) errors : -8120.735\n",
      " Regression with ARIMA(1,0,2) errors : -12631.26\n",
      " Regression with ARIMA(2,0,1) errors : -12629.83\n",
      " Regression with ARIMA(3,0,2) errors : -12695.7\n",
      " Regression with ARIMA(3,0,1) errors : -12642.68\n",
      " Regression with ARIMA(4,0,2) errors : -12659.94\n",
      " Regression with ARIMA(3,0,3) errors : -12660.68\n",
      " Regression with ARIMA(2,0,3) errors : -12655.54\n",
      " Regression with ARIMA(4,0,1) errors : -12658.46\n",
      " Regression with ARIMA(4,0,3) errors : -12702.36\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12659.16\n",
      " Regression with ARIMA(5,0,2) errors : -12657.49\n",
      " Regression with ARIMA(5,0,4) errors : -12659.7\n",
      " Regression with ARIMA(4,0,3) errors : -12584.34\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.35\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12639.64\n",
      " Regression with ARIMA(0,0,0) errors : -9126.097\n",
      " Regression with ARIMA(1,0,0) errors : -12614.91\n",
      " Regression with ARIMA(0,0,1) errors : -10785.02\n",
      " Regression with ARIMA(0,0,0) errors : -8116.995\n",
      " Regression with ARIMA(1,0,2) errors : -12635.07\n",
      " Regression with ARIMA(2,0,1) errors : -12633.58\n",
      " Regression with ARIMA(3,0,2) errors : -12700.58\n",
      " Regression with ARIMA(3,0,1) errors : -12646.01\n",
      " Regression with ARIMA(4,0,2) errors : -12662.46\n",
      " Regression with ARIMA(3,0,3) errors : -12663.22\n",
      " Regression with ARIMA(2,0,3) errors : -12659.45\n",
      " Regression with ARIMA(4,0,1) errors : -12661.32\n",
      " Regression with ARIMA(4,0,3) errors : -12707.82\n",
      " Regression with ARIMA(5,0,3) errors : -12680.87\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.94\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12674.86\n",
      " Regression with ARIMA(4,0,3) errors : -12602.62\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12703.26\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.76\n",
      " Regression with ARIMA(0,0,0) errors : -9126.664\n",
      " Regression with ARIMA(1,0,0) errors : -12610.17\n",
      " Regression with ARIMA(0,0,1) errors : -10784.22\n",
      " Regression with ARIMA(0,0,0) errors : -8120.924\n",
      " Regression with ARIMA(1,0,2) errors : -12630.62\n",
      " Regression with ARIMA(2,0,1) errors : -12629.52\n",
      " Regression with ARIMA(3,0,2) errors : -12694.59\n",
      " Regression with ARIMA(3,0,1) errors : -12642.09\n",
      " Regression with ARIMA(4,0,2) errors : -12658.44\n",
      " Regression with ARIMA(3,0,3) errors : -12658.75\n",
      " Regression with ARIMA(2,0,3) errors : -12655.04\n",
      " Regression with ARIMA(4,0,1) errors : -12657.14\n",
      " Regression with ARIMA(4,0,3) errors : -12704.19\n",
      " Regression with ARIMA(5,0,3) errors : -12674.9\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.25\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12664.74\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.55\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.01\n",
      " Regression with ARIMA(0,0,0) errors : -9129.67\n",
      " Regression with ARIMA(1,0,0) errors : -12606.43\n",
      " Regression with ARIMA(0,0,1) errors : -10786.26\n",
      " Regression with ARIMA(0,0,0) errors : -8109.689\n",
      " Regression with ARIMA(1,0,2) errors : -12626.33\n",
      " Regression with ARIMA(2,0,1) errors : -12625.7\n",
      " Regression with ARIMA(3,0,2) errors : -12685.15\n",
      " Regression with ARIMA(3,0,1) errors : -12638.15\n",
      " Regression with ARIMA(4,0,2) errors : -12654.36\n",
      " Regression with ARIMA(3,0,3) errors : -12654.53\n",
      " Regression with ARIMA(2,0,3) errors : -12651.32\n",
      " Regression with ARIMA(4,0,1) errors : -12653.1\n",
      " Regression with ARIMA(4,0,3) errors : -12701.37\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12653.24\n",
      " Regression with ARIMA(3,0,4) errors : -12676.54\n",
      " Regression with ARIMA(5,0,2) errors : -12652.64\n",
      " Regression with ARIMA(5,0,4) errors : -12668.09\n",
      " Regression with ARIMA(4,0,3) errors : -12590.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.56\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.77\n",
      " Regression with ARIMA(0,0,0) errors : -9125.562\n",
      " Regression with ARIMA(1,0,0) errors : -12610.64\n",
      " Regression with ARIMA(0,0,1) errors : -10785.7\n",
      " Regression with ARIMA(0,0,0) errors : -8108.179\n",
      " Regression with ARIMA(1,0,2) errors : -12630.51\n",
      " Regression with ARIMA(2,0,1) errors : -12629.36\n",
      " Regression with ARIMA(3,0,2) errors : -12694.15\n",
      " Regression with ARIMA(3,0,1) errors : -12642.13\n",
      " Regression with ARIMA(4,0,2) errors : -12658.37\n",
      " Regression with ARIMA(3,0,3) errors : -12658.83\n",
      " Regression with ARIMA(2,0,3) errors : -12655.24\n",
      " Regression with ARIMA(4,0,1) errors : -12657.12\n",
      " Regression with ARIMA(4,0,3) errors : -12704.42\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12679.15\n",
      " Regression with ARIMA(3,0,4) errors : -12677.56\n",
      " Regression with ARIMA(5,0,2) errors : -12656.96\n",
      " Regression with ARIMA(5,0,4) errors : -12670.89\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12699.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.76\n",
      " Regression with ARIMA(0,0,0) errors : -9119.29\n",
      " Regression with ARIMA(1,0,0) errors : -12609.83\n",
      " Regression with ARIMA(0,0,1) errors : -10782.32\n",
      " Regression with ARIMA(0,0,0) errors : -8104.093\n",
      " Regression with ARIMA(1,0,2) errors : -12629.02\n",
      " Regression with ARIMA(2,0,1) errors : -12627.65\n",
      " Regression with ARIMA(3,0,2) errors : -12693.41\n",
      " Regression with ARIMA(3,0,1) errors : -12640.24\n",
      " Regression with ARIMA(4,0,2) errors : -12657.4\n",
      " Regression with ARIMA(3,0,3) errors : -12657.65\n",
      " Regression with ARIMA(2,0,3) errors : -12654\n",
      " Regression with ARIMA(4,0,1) errors : -12655.98\n",
      " Regression with ARIMA(4,0,3) errors : -12700.63\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12678.52\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12666.19\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.72\n",
      " Regression with ARIMA(0,0,0) errors : -9127.533\n",
      " Regression with ARIMA(1,0,0) errors : -12608.51\n",
      " Regression with ARIMA(0,0,1) errors : -10784.58\n",
      " Regression with ARIMA(0,0,0) errors : -8099.693\n",
      " Regression with ARIMA(1,0,2) errors : -12627.71\n",
      " Regression with ARIMA(2,0,1) errors : -12626.53\n",
      " Regression with ARIMA(3,0,2) errors : -12687.4\n",
      " Regression with ARIMA(3,0,1) errors : -12638.82\n",
      " Regression with ARIMA(4,0,2) errors : -12655.24\n",
      " Regression with ARIMA(3,0,3) errors : -12655.99\n",
      " Regression with ARIMA(2,0,3) errors : -12651.92\n",
      " Regression with ARIMA(4,0,1) errors : -12654.76\n",
      " Regression with ARIMA(4,0,3) errors : -12698.43\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12654.62\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -12611.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12696.67\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.19\n",
      " Regression with ARIMA(0,0,0) errors : -9131.072\n",
      " Regression with ARIMA(1,0,0) errors : -12612.33\n",
      " Regression with ARIMA(0,0,1) errors : -10786.34\n",
      " Regression with ARIMA(0,0,0) errors : -8111.89\n",
      " Regression with ARIMA(1,0,2) errors : -12632.14\n",
      " Regression with ARIMA(2,0,1) errors : -12630.94\n",
      " Regression with ARIMA(3,0,2) errors : -12697.09\n",
      " Regression with ARIMA(3,0,1) errors : -12642.55\n",
      " Regression with ARIMA(4,0,2) errors : -12659.42\n",
      " Regression with ARIMA(3,0,3) errors : -12660.03\n",
      " Regression with ARIMA(2,0,3) errors : -12656.53\n",
      " Regression with ARIMA(4,0,1) errors : -12658.14\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12614.5\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12700.42\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.26\n",
      " Regression with ARIMA(0,0,0) errors : -9126.592\n",
      " Regression with ARIMA(1,0,0) errors : -12609.67\n",
      " Regression with ARIMA(0,0,1) errors : -10781.77\n",
      " Regression with ARIMA(0,0,0) errors : -8113.176\n",
      " Regression with ARIMA(1,0,2) errors : -12629.18\n",
      " Regression with ARIMA(2,0,1) errors : -12627.73\n",
      " Regression with ARIMA(3,0,2) errors : -12692.71\n",
      " Regression with ARIMA(3,0,1) errors : -12639.26\n",
      " Regression with ARIMA(4,0,2) errors : -12656.27\n",
      " Regression with ARIMA(3,0,3) errors : -12657.03\n",
      " Regression with ARIMA(2,0,3) errors : -12652.75\n",
      " Regression with ARIMA(4,0,1) errors : -12654.72\n",
      " Regression with ARIMA(4,0,3) errors : -12699.6\n",
      " Regression with ARIMA(5,0,3) errors : -12672.77\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12668.99\n",
      " Regression with ARIMA(4,0,3) errors : -12626.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12697.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.51\n",
      " Regression with ARIMA(0,0,0) errors : -9120.766\n",
      " Regression with ARIMA(1,0,0) errors : -12607\n",
      " Regression with ARIMA(0,0,1) errors : -10776.09\n",
      " Regression with ARIMA(0,0,0) errors : -8111.103\n",
      " Regression with ARIMA(1,0,2) errors : -12626.77\n",
      " Regression with ARIMA(2,0,1) errors : -12625.53\n",
      " Regression with ARIMA(3,0,2) errors : -12685.73\n",
      " Regression with ARIMA(3,0,1) errors : -12637.75\n",
      " Regression with ARIMA(4,0,2) errors : -12654.14\n",
      " Regression with ARIMA(3,0,3) errors : -12654.51\n",
      " Regression with ARIMA(2,0,3) errors : -12650.91\n",
      " Regression with ARIMA(4,0,1) errors : -12654.37\n",
      " Regression with ARIMA(4,0,3) errors : -12686.13\n",
      " Regression with ARIMA(5,0,3) errors : -12700.25\n",
      " Regression with ARIMA(5,0,2) errors : -12654.47\n",
      " Regression with ARIMA(5,0,4) errors : -12662.71\n",
      " Regression with ARIMA(4,0,4) errors : -12698.47\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : -12673.47\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12629.83\n",
      " Regression with ARIMA(0,0,0) errors : -9123.342\n",
      " Regression with ARIMA(1,0,0) errors : -12606.52\n",
      " Regression with ARIMA(0,0,1) errors : -10778\n",
      " Regression with ARIMA(0,0,0) errors : -8105.722\n",
      " Regression with ARIMA(1,0,2) errors : -12626.01\n",
      " Regression with ARIMA(2,0,1) errors : -12624.6\n",
      " Regression with ARIMA(3,0,2) errors : -12689.93\n",
      " Regression with ARIMA(3,0,1) errors : -12636.27\n",
      " Regression with ARIMA(4,0,2) errors : -12652.8\n",
      " Regression with ARIMA(3,0,3) errors : -12653.27\n",
      " Regression with ARIMA(2,0,3) errors : -12649.98\n",
      " Regression with ARIMA(4,0,1) errors : -12652.27\n",
      " Regression with ARIMA(4,0,3) errors : -12694.07\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12670.15\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12654.04\n",
      " Regression with ARIMA(4,0,3) errors : -12618.5\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.06\n",
      " Regression with ARIMA(0,0,0) errors : -9131.681\n",
      " Regression with ARIMA(1,0,0) errors : -12608.01\n",
      " Regression with ARIMA(0,0,1) errors : -10782.66\n",
      " Regression with ARIMA(0,0,0) errors : -8107.119\n",
      " Regression with ARIMA(1,0,2) errors : -12628.11\n",
      " Regression with ARIMA(2,0,1) errors : -12626.67\n",
      " Regression with ARIMA(3,0,2) errors : -12693.49\n",
      " Regression with ARIMA(3,0,1) errors : -12638.11\n",
      " Regression with ARIMA(4,0,2) errors : -12655.3\n",
      " Regression with ARIMA(3,0,3) errors : -12655.92\n",
      " Regression with ARIMA(2,0,3) errors : -12652.11\n",
      " Regression with ARIMA(4,0,1) errors : -12653.8\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12610.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12696.06\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.24\n",
      " Regression with ARIMA(0,0,0) errors : -9131.239\n",
      " Regression with ARIMA(1,0,0) errors : -12606.95\n",
      " Regression with ARIMA(0,0,1) errors : -10780.44\n",
      " Regression with ARIMA(0,0,0) errors : -8112.5\n",
      " Regression with ARIMA(1,0,2) errors : -12627\n",
      " Regression with ARIMA(2,0,1) errors : -12625.5\n",
      " Regression with ARIMA(3,0,2) errors : -12689.64\n",
      " Regression with ARIMA(3,0,1) errors : -12638.39\n",
      " Regression with ARIMA(4,0,2) errors : -12654.7\n",
      " Regression with ARIMA(3,0,3) errors : -12654.57\n",
      " Regression with ARIMA(2,0,3) errors : -12650.34\n",
      " Regression with ARIMA(4,0,1) errors : -12654\n",
      " Regression with ARIMA(4,0,3) errors : -12691.8\n",
      " Regression with ARIMA(5,0,3) errors : -12674.84\n",
      " Regression with ARIMA(4,0,4) errors : -12670.68\n",
      " Regression with ARIMA(3,0,4) errors : -12676.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12662.77\n",
      " Regression with ARIMA(4,0,3) errors : -12620.21\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.43\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.92\n",
      " Regression with ARIMA(0,0,0) errors : -9128.861\n",
      " Regression with ARIMA(1,0,0) errors : -12610.07\n",
      " Regression with ARIMA(0,0,1) errors : -10783.53\n",
      " Regression with ARIMA(0,0,0) errors : -8110.608\n",
      " Regression with ARIMA(1,0,2) errors : -12629.79\n",
      " Regression with ARIMA(2,0,1) errors : -12628.8\n",
      " Regression with ARIMA(3,0,2) errors : -12690.81\n",
      " Regression with ARIMA(3,0,1) errors : -12640.88\n",
      " Regression with ARIMA(4,0,2) errors : -12657.06\n",
      " Regression with ARIMA(3,0,3) errors : -12657.59\n",
      " Regression with ARIMA(2,0,3) errors : -12654.11\n",
      " Regression with ARIMA(4,0,1) errors : -12656.04\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12597.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12697.96\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12634.62\n",
      " Regression with ARIMA(0,0,0) errors : -9126.781\n",
      " Regression with ARIMA(1,0,0) errors : -12610.65\n",
      " Regression with ARIMA(0,0,1) errors : -10781.97\n",
      " Regression with ARIMA(0,0,0) errors : -8113.142\n",
      " Regression with ARIMA(1,0,2) errors : -12630.54\n",
      " Regression with ARIMA(2,0,1) errors : -12629.23\n",
      " Regression with ARIMA(3,0,2) errors : -12696.42\n",
      " Regression with ARIMA(3,0,1) errors : -12641.18\n",
      " Regression with ARIMA(4,0,2) errors : -12657.47\n",
      " Regression with ARIMA(3,0,3) errors : -12658.27\n",
      " Regression with ARIMA(2,0,3) errors : -12654.69\n",
      " Regression with ARIMA(4,0,1) errors : -12656.72\n",
      " Regression with ARIMA(4,0,3) errors : -12703.68\n",
      " Regression with ARIMA(5,0,3) errors : -12677.09\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12669.72\n",
      " Regression with ARIMA(4,0,3) errors : -12577.74\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.4\n",
      " Regression with ARIMA(0,0,0) errors : -9125.689\n",
      " Regression with ARIMA(1,0,0) errors : -12612.41\n",
      " Regression with ARIMA(0,0,1) errors : -10783.44\n",
      " Regression with ARIMA(0,0,0) errors : -8112.957\n",
      " Regression with ARIMA(1,0,2) errors : -12632.37\n",
      " Regression with ARIMA(2,0,1) errors : -12631.02\n",
      " Regression with ARIMA(3,0,2) errors : -12698.98\n",
      " Regression with ARIMA(3,0,1) errors : -12642.99\n",
      " Regression with ARIMA(4,0,2) errors : -12659.39\n",
      " Regression with ARIMA(3,0,3) errors : -12660.05\n",
      " Regression with ARIMA(2,0,3) errors : -12656.41\n",
      " Regression with ARIMA(4,0,1) errors : -12658.4\n",
      " Regression with ARIMA(4,0,3) errors : -12705.73\n",
      " Regression with ARIMA(5,0,3) errors : -12677.06\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12682.47\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12672.68\n",
      " Regression with ARIMA(4,0,3) errors : -12592.32\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.68\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.3\n",
      " Regression with ARIMA(0,0,0) errors : -9115.868\n",
      " Regression with ARIMA(1,0,0) errors : -12611.51\n",
      " Regression with ARIMA(0,0,1) errors : -10777.8\n",
      " Regression with ARIMA(0,0,0) errors : -8111.841\n",
      " Regression with ARIMA(1,0,2) errors : -12631.09\n",
      " Regression with ARIMA(2,0,1) errors : -12629.64\n",
      " Regression with ARIMA(3,0,2) errors : -12698.43\n",
      " Regression with ARIMA(3,0,1) errors : -12641.39\n",
      " Regression with ARIMA(4,0,2) errors : -12658.34\n",
      " Regression with ARIMA(3,0,3) errors : -12658.92\n",
      " Regression with ARIMA(2,0,3) errors : -12655.53\n",
      " Regression with ARIMA(4,0,1) errors : -12657.54\n",
      " Regression with ARIMA(4,0,3) errors : -12704.55\n",
      " Regression with ARIMA(5,0,3) errors : -12677.45\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12671.36\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.66\n",
      " Regression with ARIMA(0,0,0) errors : -9124.945\n",
      " Regression with ARIMA(1,0,0) errors : -12612.72\n",
      " Regression with ARIMA(0,0,1) errors : -10780.08\n",
      " Regression with ARIMA(0,0,0) errors : -8108.834\n",
      " Regression with ARIMA(1,0,2) errors : -12632.51\n",
      " Regression with ARIMA(2,0,1) errors : -12631.82\n",
      " Regression with ARIMA(3,0,2) errors : -12694.27\n",
      " Regression with ARIMA(3,0,1) errors : -12643.59\n",
      " Regression with ARIMA(4,0,2) errors : -12660.23\n",
      " Regression with ARIMA(3,0,3) errors : -12660.57\n",
      " Regression with ARIMA(2,0,3) errors : -12657.73\n",
      " Regression with ARIMA(4,0,1) errors : -12659.39\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12588.55\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.13\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12627.74\n",
      " Regression with ARIMA(0,0,0) errors : -9117.039\n",
      " Regression with ARIMA(1,0,0) errors : -12604.36\n",
      " Regression with ARIMA(0,0,1) errors : -10772.74\n",
      " Regression with ARIMA(0,0,0) errors : -8100.168\n",
      " Regression with ARIMA(1,0,2) errors : -12624.03\n",
      " Regression with ARIMA(2,0,1) errors : -12622.73\n",
      " Regression with ARIMA(3,0,2) errors : -12688.87\n",
      " Regression with ARIMA(3,0,1) errors : -12635.29\n",
      " Regression with ARIMA(4,0,2) errors : -12652.41\n",
      " Regression with ARIMA(3,0,3) errors : -12652.42\n",
      " Regression with ARIMA(2,0,3) errors : -12648.98\n",
      " Regression with ARIMA(4,0,1) errors : -12651.73\n",
      " Regression with ARIMA(4,0,3) errors : -12695.02\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12668.42\n",
      " Regression with ARIMA(3,0,4) errors : -12666.86\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12662.55\n",
      " Regression with ARIMA(4,0,3) errors : -12583.67\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12692.62\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12629.95\n",
      " Regression with ARIMA(0,0,0) errors : -9111.839\n",
      " Regression with ARIMA(1,0,0) errors : -12606.59\n",
      " Regression with ARIMA(0,0,1) errors : -10768.97\n",
      " Regression with ARIMA(0,0,0) errors : -8094.359\n",
      " Regression with ARIMA(1,0,2) errors : -12626.11\n",
      " Regression with ARIMA(2,0,1) errors : -12624.99\n",
      " Regression with ARIMA(3,0,2) errors : -12691.49\n",
      " Regression with ARIMA(3,0,1) errors : -12636.29\n",
      " Regression with ARIMA(4,0,2) errors : -12654.61\n",
      " Regression with ARIMA(3,0,3) errors : -12655.25\n",
      " Regression with ARIMA(2,0,3) errors : -12651.79\n",
      " Regression with ARIMA(4,0,1) errors : -12653.54\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12606.28\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12694.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12625.86\n",
      " Regression with ARIMA(0,0,0) errors : -9104.057\n",
      " Regression with ARIMA(1,0,0) errors : -12602.52\n",
      " Regression with ARIMA(0,0,1) errors : -10763.32\n",
      " Regression with ARIMA(0,0,0) errors : -8093.859\n",
      " Regression with ARIMA(1,0,2) errors : -12621.83\n",
      " Regression with ARIMA(2,0,1) errors : -12620.75\n",
      " Regression with ARIMA(3,0,2) errors : -12688.22\n",
      " Regression with ARIMA(3,0,1) errors : -12631.52\n",
      " Regression with ARIMA(4,0,2) errors : -12652.06\n",
      " Regression with ARIMA(3,0,3) errors : -12650.46\n",
      " Regression with ARIMA(2,0,3) errors : -12647.56\n",
      " Regression with ARIMA(4,0,1) errors : -12651.23\n",
      " Regression with ARIMA(4,0,3) errors : -12681.28\n",
      " Regression with ARIMA(3,0,2) errors : -12603.68\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12690.63\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12618.91\n",
      " Regression with ARIMA(0,0,0) errors : -9103.363\n",
      " Regression with ARIMA(1,0,0) errors : -12597.31\n",
      " Regression with ARIMA(0,0,1) errors : -10765.68\n",
      " Regression with ARIMA(0,0,0) errors : -8091.292\n",
      " Regression with ARIMA(1,0,2) errors : -12615.19\n",
      " Regression with ARIMA(2,0,1) errors : -12613.85\n",
      " Regression with ARIMA(3,0,2) errors : -12682.31\n",
      " Regression with ARIMA(3,0,1) errors : -12625.35\n",
      " Regression with ARIMA(4,0,2) errors : -12644.79\n",
      " Regression with ARIMA(3,0,3) errors : -12644.37\n",
      " Regression with ARIMA(2,0,3) errors : -12640.45\n",
      " Regression with ARIMA(4,0,1) errors : -12643.65\n",
      " Regression with ARIMA(4,0,3) errors : -12682.08\n",
      " Regression with ARIMA(3,0,2) errors : -12580.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12684.69\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12615.06\n",
      " Regression with ARIMA(0,0,0) errors : -9099.58\n",
      " Regression with ARIMA(1,0,0) errors : -12592.84\n",
      " Regression with ARIMA(0,0,1) errors : -10762.48\n",
      " Regression with ARIMA(0,0,0) errors : -8087.004\n",
      " Regression with ARIMA(1,0,2) errors : -12610.83\n",
      " Regression with ARIMA(2,0,1) errors : -12609.67\n",
      " Regression with ARIMA(3,0,2) errors : -12677.21\n",
      " Regression with ARIMA(3,0,1) errors : -12621.08\n",
      " Regression with ARIMA(4,0,2) errors : -12640.17\n",
      " Regression with ARIMA(3,0,3) errors : -12640.85\n",
      " Regression with ARIMA(2,0,3) errors : -12636.93\n",
      " Regression with ARIMA(4,0,1) errors : -12638.83\n",
      " Regression with ARIMA(4,0,3) errors : -12684.27\n",
      " Regression with ARIMA(5,0,3) errors : -12658.04\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12639.53\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12654.82\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12680.01\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12613.46\n",
      " Regression with ARIMA(0,0,0) errors : -9099.695\n",
      " Regression with ARIMA(1,0,0) errors : -12591.66\n",
      " Regression with ARIMA(0,0,1) errors : -10763.22\n",
      " Regression with ARIMA(0,0,0) errors : -8089.962\n",
      " Regression with ARIMA(1,0,2) errors : -12609.68\n",
      " Regression with ARIMA(2,0,1) errors : -12608.39\n",
      " Regression with ARIMA(3,0,2) errors : -12677.01\n",
      " Regression with ARIMA(3,0,1) errors : -12619.63\n",
      " Regression with ARIMA(4,0,2) errors : -12638.73\n",
      " Regression with ARIMA(3,0,3) errors : -12639.14\n",
      " Regression with ARIMA(2,0,3) errors : -12635.44\n",
      " Regression with ARIMA(4,0,1) errors : -12637.36\n",
      " Regression with ARIMA(4,0,3) errors : -12681.2\n",
      " Regression with ARIMA(5,0,3) errors : -12656.69\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12660.48\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12652.18\n",
      " Regression with ARIMA(4,0,3) errors : -12597.54\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12678.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12615.16\n",
      " Regression with ARIMA(0,0,0) errors : -9100.818\n",
      " Regression with ARIMA(1,0,0) errors : -12593.22\n",
      " Regression with ARIMA(0,0,1) errors : -10765.31\n",
      " Regression with ARIMA(0,0,0) errors : -8091.06\n",
      " Regression with ARIMA(1,0,2) errors : -12611.24\n",
      " Regression with ARIMA(2,0,1) errors : -12609.93\n",
      " Regression with ARIMA(3,0,2) errors : -12679.3\n",
      " Regression with ARIMA(3,0,1) errors : -12621.06\n",
      " Regression with ARIMA(4,0,2) errors : -12639.78\n",
      " Regression with ARIMA(3,0,3) errors : -12640.43\n",
      " Regression with ARIMA(2,0,3) errors : -12636.97\n",
      " Regression with ARIMA(4,0,1) errors : -12638.66\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12594.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12679.67\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12617.12\n",
      " Regression with ARIMA(0,0,0) errors : -9109.583\n",
      " Regression with ARIMA(1,0,0) errors : -12595.07\n",
      " Regression with ARIMA(0,0,1) errors : -10771.08\n",
      " Regression with ARIMA(0,0,0) errors : -8093.37\n",
      " Regression with ARIMA(1,0,2) errors : -12613.21\n",
      " Regression with ARIMA(2,0,1) errors : -12611.88\n",
      " Regression with ARIMA(3,0,2) errors : -12678.72\n",
      " Regression with ARIMA(3,0,1) errors : -12623\n",
      " Regression with ARIMA(4,0,2) errors : -12641.23\n",
      " Regression with ARIMA(3,0,3) errors : -12641.89\n",
      " Regression with ARIMA(2,0,3) errors : -12638.42\n",
      " Regression with ARIMA(4,0,1) errors : -12640.06\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12592.8\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12681.68\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12619.74\n",
      " Regression with ARIMA(0,0,0) errors : -9112.072\n",
      " Regression with ARIMA(1,0,0) errors : -12597.43\n",
      " Regression with ARIMA(0,0,1) errors : -10771.67\n",
      " Regression with ARIMA(0,0,0) errors : -8099.27\n",
      " Regression with ARIMA(1,0,2) errors : -12615.95\n",
      " Regression with ARIMA(2,0,1) errors : -12614.81\n",
      " Regression with ARIMA(3,0,2) errors : -12684.97\n",
      " Regression with ARIMA(3,0,1) errors : -12626.06\n",
      " Regression with ARIMA(4,0,2) errors : -12644.83\n",
      " Regression with ARIMA(3,0,3) errors : -12645.37\n",
      " Regression with ARIMA(2,0,3) errors : -12641.62\n",
      " Regression with ARIMA(4,0,1) errors : -12643.67\n",
      " Regression with ARIMA(4,0,3) errors : -12690.35\n",
      " Regression with ARIMA(5,0,3) errors : -12663.66\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12668.79\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12658.85\n",
      " Regression with ARIMA(4,0,3) errors : -12609.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12685.05\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12619.78\n",
      " Regression with ARIMA(0,0,0) errors : -9111.436\n",
      " Regression with ARIMA(1,0,0) errors : -12596.51\n",
      " Regression with ARIMA(0,0,1) errors : -10769.82\n",
      " Regression with ARIMA(0,0,0) errors : -8099.19\n",
      " Regression with ARIMA(1,0,2) errors : -12615.12\n",
      " Regression with ARIMA(2,0,1) errors : -12615.29\n",
      " Regression with ARIMA(3,0,2) errors : -12677.01\n",
      " Regression with ARIMA(3,0,1) errors : -12626.47\n",
      " Regression with ARIMA(4,0,2) errors : -12646.5\n",
      " Regression with ARIMA(3,0,3) errors : -12647.04\n",
      " Regression with ARIMA(2,0,3) errors : -12642.14\n",
      " Regression with ARIMA(4,0,1) errors : -12644.59\n",
      " Regression with ARIMA(4,0,3) errors : -12686.33\n",
      " Regression with ARIMA(5,0,3) errors : -12661.66\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12668.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12657.53\n",
      " Regression with ARIMA(4,0,3) errors : -12608.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12683.18\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12616.6\n",
      " Regression with ARIMA(0,0,0) errors : -9093.993\n",
      " Regression with ARIMA(1,0,0) errors : -12593.32\n",
      " Regression with ARIMA(0,0,1) errors : -10754.58\n",
      " Regression with ARIMA(0,0,0) errors : -8057.969\n",
      " Regression with ARIMA(1,0,2) errors : -12612.81\n",
      " Regression with ARIMA(2,0,1) errors : -12611.61\n",
      " Regression with ARIMA(3,0,2) errors : -12678.85\n",
      " Regression with ARIMA(3,0,1) errors : -12622.82\n",
      " Regression with ARIMA(4,0,2) errors : -12641.44\n",
      " Regression with ARIMA(3,0,3) errors : -12642.14\n",
      " Regression with ARIMA(2,0,3) errors : -12638.25\n",
      " Regression with ARIMA(4,0,1) errors : -12639.95\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12583.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12680.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12583.96\n",
      " Regression with ARIMA(0,0,0) errors : -9092.613\n",
      " Regression with ARIMA(1,0,0) errors : -12563.7\n",
      " Regression with ARIMA(0,0,1) errors : -10747.78\n",
      " Regression with ARIMA(0,0,0) errors : -8051.218\n",
      " Regression with ARIMA(1,0,2) errors : -12580.28\n",
      " Regression with ARIMA(2,0,1) errors : -12579.03\n",
      " Regression with ARIMA(3,0,2) errors : -12646.7\n",
      " Regression with ARIMA(3,0,1) errors : -12589.65\n",
      " Regression with ARIMA(4,0,2) errors : -12606.27\n",
      " Regression with ARIMA(3,0,3) errors : -12606.89\n",
      " Regression with ARIMA(2,0,3) errors : -12603.05\n",
      " Regression with ARIMA(4,0,1) errors : -12604.75\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12556.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12648.35\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12577.66\n",
      " Regression with ARIMA(0,0,0) errors : -9095.204\n",
      " Regression with ARIMA(1,0,0) errors : -12557.4\n",
      " Regression with ARIMA(0,0,1) errors : -10745.91\n",
      " Regression with ARIMA(0,0,0) errors : -8037.239\n",
      " Regression with ARIMA(1,0,2) errors : -12573.72\n",
      " Regression with ARIMA(2,0,1) errors : -12572.35\n",
      " Regression with ARIMA(3,0,2) errors : -12641.2\n",
      " Regression with ARIMA(3,0,1) errors : -12583.1\n",
      " Regression with ARIMA(4,0,2) errors : -12600.41\n",
      " Regression with ARIMA(3,0,3) errors : -12601.11\n",
      " Regression with ARIMA(2,0,3) errors : -12597.21\n",
      " Regression with ARIMA(4,0,1) errors : -12599.03\n",
      " Regression with ARIMA(4,0,3) errors : -12644.07\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12622.13\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12612.01\n",
      " Regression with ARIMA(4,0,3) errors : -12563.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12642.54\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12575.52\n",
      " Regression with ARIMA(0,0,0) errors : -9101.37\n",
      " Regression with ARIMA(1,0,0) errors : -12554.94\n",
      " Regression with ARIMA(0,0,1) errors : -10747.52\n",
      " Regression with ARIMA(0,0,0) errors : -8033.351\n",
      " Regression with ARIMA(1,0,2) errors : -12571.38\n",
      " Regression with ARIMA(2,0,1) errors : -12570.05\n",
      " Regression with ARIMA(3,0,2) errors : -12638.35\n",
      " Regression with ARIMA(3,0,1) errors : -12581.07\n",
      " Regression with ARIMA(4,0,2) errors : -12598.59\n",
      " Regression with ARIMA(3,0,3) errors : -12599.01\n",
      " Regression with ARIMA(2,0,3) errors : -12595.34\n",
      " Regression with ARIMA(4,0,1) errors : -12597.11\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12519.88\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12639.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12565.83\n",
      " Regression with ARIMA(0,0,0) errors : -9101.364\n",
      " Regression with ARIMA(1,0,0) errors : -12545.42\n",
      " Regression with ARIMA(0,0,1) errors : -10744.99\n",
      " Regression with ARIMA(0,0,0) errors : -8028.435\n",
      " Regression with ARIMA(1,0,2) errors : -12561.69\n",
      " Regression with ARIMA(2,0,1) errors : -12560.33\n",
      " Regression with ARIMA(3,0,2) errors : -12625.38\n",
      " Regression with ARIMA(3,0,1) errors : -12571.55\n",
      " Regression with ARIMA(4,0,2) errors : -12589.48\n",
      " Regression with ARIMA(3,0,3) errors : -12589.91\n",
      " Regression with ARIMA(2,0,3) errors : -12585.25\n",
      " Regression with ARIMA(4,0,1) errors : -12587.54\n",
      " Regression with ARIMA(4,0,3) errors : -12629.39\n",
      " Regression with ARIMA(5,0,3) errors : -12606.27\n",
      " Regression with ARIMA(4,0,4) errors : -12632.75\n",
      " Regression with ARIMA(3,0,4) errors : -12604.33\n",
      " Regression with ARIMA(5,0,4) errors : -12602.45\n",
      " Regression with ARIMA(4,0,5) errors : -12606.94\n",
      " Regression with ARIMA(3,0,5) errors : -12601.51\n",
      " Regression with ARIMA(5,0,5) errors : -12608.1\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12629.36\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12550.88\n",
      " Regression with ARIMA(0,0,0) errors : -9082.974\n",
      " Regression with ARIMA(1,0,0) errors : -12530.87\n",
      " Regression with ARIMA(0,0,1) errors : -10726.19\n",
      " Regression with ARIMA(0,0,0) errors : -7990.949\n",
      " Regression with ARIMA(1,0,2) errors : -12547.22\n",
      " Regression with ARIMA(2,0,1) errors : -12546.03\n",
      " Regression with ARIMA(3,0,2) errors : -12611.03\n",
      " Regression with ARIMA(3,0,1) errors : -12556.14\n",
      " Regression with ARIMA(4,0,2) errors : -12573.38\n",
      " Regression with ARIMA(3,0,3) errors : -12573.93\n",
      " Regression with ARIMA(2,0,3) errors : -12570.37\n",
      " Regression with ARIMA(4,0,1) errors : -12572.13\n",
      " Regression with ARIMA(4,0,3) errors : -12616.54\n",
      " Regression with ARIMA(5,0,3) errors : -12590.07\n",
      " Regression with ARIMA(4,0,4) errors : -12620.02\n",
      " Regression with ARIMA(3,0,4) errors : -12593.33\n",
      " Regression with ARIMA(5,0,4) errors : -12585.19\n",
      " Regression with ARIMA(4,0,5) errors : -12590.96\n",
      " Regression with ARIMA(3,0,5) errors : -12586.08\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12613.46\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12541.98\n",
      " Regression with ARIMA(0,0,0) errors : -9085.693\n",
      " Regression with ARIMA(1,0,0) errors : -12521.52\n",
      " Regression with ARIMA(0,0,1) errors : -10727.61\n",
      " Regression with ARIMA(0,0,0) errors : -7984.545\n",
      " Regression with ARIMA(1,0,2) errors : -12537.92\n",
      " Regression with ARIMA(2,0,1) errors : -12537.24\n",
      " Regression with ARIMA(3,0,2) errors : -12601.89\n",
      " Regression with ARIMA(3,0,1) errors : -12547.19\n",
      " Regression with ARIMA(4,0,2) errors : -12564.24\n",
      " Regression with ARIMA(3,0,3) errors : -12564.26\n",
      " Regression with ARIMA(2,0,3) errors : -12561.62\n",
      " Regression with ARIMA(4,0,1) errors : -12563.37\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12499.3\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12602.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.96\n",
      " Regression with ARIMA(0,0,0) errors : -9090.727\n",
      " Regression with ARIMA(1,0,0) errors : -12524.23\n",
      " Regression with ARIMA(0,0,1) errors : -10729.14\n",
      " Regression with ARIMA(0,0,0) errors : -7988.192\n",
      " Regression with ARIMA(1,0,2) errors : -12541.23\n",
      " Regression with ARIMA(2,0,1) errors : -12541.2\n",
      " Regression with ARIMA(3,0,2) errors : -12596.53\n",
      " Regression with ARIMA(3,0,1) errors : -12551.61\n",
      " Regression with ARIMA(4,0,2) errors : -12568.27\n",
      " Regression with ARIMA(3,0,3) errors : -12568.72\n",
      " Regression with ARIMA(2,0,3) errors : -12565.53\n",
      " Regression with ARIMA(4,0,1) errors : -12567.05\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12496.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12605.49\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12548.88\n",
      " Regression with ARIMA(0,0,0) errors : -9100.305\n",
      " Regression with ARIMA(1,0,0) errors : -12527.5\n",
      " Regression with ARIMA(0,0,1) errors : -10736.35\n",
      " Regression with ARIMA(0,0,0) errors : -7988.759\n",
      " Regression with ARIMA(1,0,2) errors : -12544.66\n",
      " Regression with ARIMA(2,0,1) errors : -12543.65\n",
      " Regression with ARIMA(3,0,2) errors : -12605.4\n",
      " Regression with ARIMA(3,0,1) errors : -12554.44\n",
      " Regression with ARIMA(4,0,2) errors : -12571.11\n",
      " Regression with ARIMA(3,0,3) errors : -12571.91\n",
      " Regression with ARIMA(2,0,3) errors : -12568.5\n",
      " Regression with ARIMA(4,0,1) errors : -12570.06\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12504.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12608.79\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.27\n",
      " Regression with ARIMA(0,0,0) errors : -9095.28\n",
      " Regression with ARIMA(1,0,0) errors : -12526.27\n",
      " Regression with ARIMA(0,0,1) errors : -10733.95\n",
      " Regression with ARIMA(0,0,0) errors : -7985.631\n",
      " Regression with ARIMA(1,0,2) errors : -12543.29\n",
      " Regression with ARIMA(2,0,1) errors : -12541.96\n",
      " Regression with ARIMA(3,0,2) errors : -12605.92\n",
      " Regression with ARIMA(3,0,1) errors : -12552.76\n",
      " Regression with ARIMA(4,0,2) errors : -12569.38\n",
      " Regression with ARIMA(3,0,3) errors : -12569.97\n",
      " Regression with ARIMA(2,0,3) errors : -12566.62\n",
      " Regression with ARIMA(4,0,1) errors : -12568.51\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12514.77\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12607.57\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12551.72\n",
      " Regression with ARIMA(0,0,0) errors : -9094.616\n",
      " Regression with ARIMA(1,0,0) errors : -12527.72\n",
      " Regression with ARIMA(0,0,1) errors : -10731.91\n",
      " Regression with ARIMA(0,0,0) errors : -7984.814\n",
      " Regression with ARIMA(1,0,2) errors : -12544.83\n",
      " Regression with ARIMA(2,0,1) errors : -12545.69\n",
      " Regression with ARIMA(3,0,2) errors : -12599.12\n",
      " Regression with ARIMA(3,0,1) errors : -12556.69\n",
      " Regression with ARIMA(4,0,2) errors : -12574.58\n",
      " Regression with ARIMA(3,0,3) errors : -12572.21\n",
      " Regression with ARIMA(2,0,3) errors : -12570.48\n",
      " Regression with ARIMA(4,0,1) errors : -12574.57\n",
      " Regression with ARIMA(4,0,3) errors : -12602.14\n",
      " Regression with ARIMA(5,0,3) errors : -12593.97\n",
      " Regression with ARIMA(4,0,4) errors : -12614.31\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12592.12\n",
      " Regression with ARIMA(4,0,5) errors : -12613.12\n",
      " Regression with ARIMA(3,0,5) errors : -12593.98\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -12615.97\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.25\n",
      " Regression with ARIMA(0,0,0) errors : -9103.285\n",
      " Regression with ARIMA(1,0,0) errors : -12525.6\n",
      " Regression with ARIMA(0,0,1) errors : -10740.02\n",
      " Regression with ARIMA(0,0,0) errors : -7987.126\n",
      " Regression with ARIMA(1,0,2) errors : -12542.63\n",
      " Regression with ARIMA(2,0,1) errors : -12541.09\n",
      " Regression with ARIMA(3,0,2) errors : -12595.27\n",
      " Regression with ARIMA(3,0,1) errors : -12553.61\n",
      " Regression with ARIMA(4,0,2) errors : -12567.35\n",
      " Regression with ARIMA(3,0,3) errors : -12568.1\n",
      " Regression with ARIMA(2,0,3) errors : -12564.84\n",
      " Regression with ARIMA(4,0,1) errors : -12567.61\n",
      " Regression with ARIMA(4,0,3) errors : -12599.93\n",
      " Regression with ARIMA(5,0,3) errors : -12585.25\n",
      " Regression with ARIMA(4,0,4) errors : -12587.13\n",
      " Regression with ARIMA(3,0,4) errors : -12586.59\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12587.56\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12603.94\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12563.76\n",
      " Regression with ARIMA(0,0,0) errors : -9114.748\n",
      " Regression with ARIMA(1,0,0) errors : -12542.44\n",
      " Regression with ARIMA(0,0,1) errors : -10750.26\n",
      " Regression with ARIMA(0,0,0) errors : -7996.79\n",
      " Regression with ARIMA(1,0,2) errors : -12559.52\n",
      " Regression with ARIMA(2,0,1) errors : -12557.88\n",
      " Regression with ARIMA(3,0,2) errors : -12623.24\n",
      " Regression with ARIMA(3,0,1) errors : -12569.07\n",
      " Regression with ARIMA(4,0,2) errors : -12584.06\n",
      " Regression with ARIMA(3,0,3) errors : -12584.83\n",
      " Regression with ARIMA(2,0,3) errors : -12581.2\n",
      " Regression with ARIMA(4,0,1) errors : -12583.59\n",
      " Regression with ARIMA(4,0,3) errors : -12622.16\n",
      " Regression with ARIMA(3,0,2) errors : -12529.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12623.55\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12571.66\n",
      " Regression with ARIMA(0,0,0) errors : -9119.255\n",
      " Regression with ARIMA(1,0,0) errors : -12550.63\n",
      " Regression with ARIMA(0,0,1) errors : -10754.38\n",
      " Regression with ARIMA(0,0,0) errors : -7999.828\n",
      " Regression with ARIMA(1,0,2) errors : -12567.56\n",
      " Regression with ARIMA(2,0,1) errors : -12565.97\n",
      " Regression with ARIMA(3,0,2) errors : -12623.38\n",
      " Regression with ARIMA(3,0,1) errors : -12577.61\n",
      " Regression with ARIMA(4,0,2) errors : -12592.71\n",
      " Regression with ARIMA(3,0,3) errors : -12593.33\n",
      " Regression with ARIMA(2,0,3) errors : -12589.24\n",
      " Regression with ARIMA(4,0,1) errors : -12591.99\n",
      " Regression with ARIMA(4,0,3) errors : -12628.14\n",
      " Regression with ARIMA(5,0,3) errors : -12611.42\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12608.22\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12601.46\n",
      " Regression with ARIMA(4,0,3) errors : -12518.46\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12632.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12570.69\n",
      " Regression with ARIMA(0,0,0) errors : -9115.278\n",
      " Regression with ARIMA(1,0,0) errors : -12549.82\n",
      " Regression with ARIMA(0,0,1) errors : -10753.47\n",
      " Regression with ARIMA(0,0,0) errors : -8003.712\n",
      " Regression with ARIMA(1,0,2) errors : -12566.64\n",
      " Regression with ARIMA(2,0,1) errors : -12564.99\n",
      " Regression with ARIMA(3,0,2) errors : -12627.12\n",
      " Regression with ARIMA(3,0,1) errors : -12576.67\n",
      " Regression with ARIMA(4,0,2) errors : -12592.86\n",
      " Regression with ARIMA(3,0,3) errors : -12593.53\n",
      " Regression with ARIMA(2,0,3) errors : -12588.09\n",
      " Regression with ARIMA(4,0,1) errors : -12591.37\n",
      " Regression with ARIMA(4,0,3) errors : -12631.06\n",
      " Regression with ARIMA(5,0,3) errors : -12608.52\n",
      " Regression with ARIMA(4,0,4) errors : -12636.78\n",
      " Regression with ARIMA(3,0,4) errors : -12595.05\n",
      " Regression with ARIMA(5,0,4) errors : -12606.13\n",
      " Regression with ARIMA(4,0,5) errors : -12611.46\n",
      " Regression with ARIMA(3,0,5) errors : -12589.1\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12631.52\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12578.38\n",
      " Regression with ARIMA(0,0,0) errors : -9111.17\n",
      " Regression with ARIMA(1,0,0) errors : -12558.92\n",
      " Regression with ARIMA(0,0,1) errors : -10753.78\n",
      " Regression with ARIMA(0,0,0) errors : -8020.573\n",
      " Regression with ARIMA(1,0,2) errors : -12574.68\n",
      " Regression with ARIMA(2,0,1) errors : -12573.05\n",
      " Regression with ARIMA(3,0,2) errors : -12623.18\n",
      " Regression with ARIMA(3,0,1) errors : -12586.14\n",
      " Regression with ARIMA(4,0,2) errors : -12599.85\n",
      " Regression with ARIMA(3,0,3) errors : -12600.52\n",
      " Regression with ARIMA(2,0,3) errors : -12595.7\n",
      " Regression with ARIMA(4,0,1) errors : -12599.55\n",
      " Regression with ARIMA(4,0,3) errors : -12630.95\n",
      " Regression with ARIMA(5,0,3) errors : -12614.41\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12610.87\n",
      " Regression with ARIMA(5,0,2) errors : -12611.96\n",
      " Regression with ARIMA(5,0,4) errors : -12609.33\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12639.79\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12589.89\n",
      " Regression with ARIMA(0,0,0) errors : -9118.887\n",
      " Regression with ARIMA(1,0,0) errors : -12570.44\n",
      " Regression with ARIMA(0,0,1) errors : -10762.54\n",
      " Regression with ARIMA(0,0,0) errors : -8023.134\n",
      " Regression with ARIMA(1,0,2) errors : -12586.06\n",
      " Regression with ARIMA(2,0,1) errors : -12584.58\n",
      " Regression with ARIMA(3,0,2) errors : -12650.24\n",
      " Regression with ARIMA(3,0,1) errors : -12595.09\n",
      " Regression with ARIMA(4,0,2) errors : -12610.13\n",
      " Regression with ARIMA(3,0,3) errors : -12611.25\n",
      " Regression with ARIMA(2,0,3) errors : -12607.47\n",
      " Regression with ARIMA(4,0,1) errors : -12610.04\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12562.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12652.57\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12605.76\n",
      " Regression with ARIMA(0,0,0) errors : -9124.298\n",
      " Regression with ARIMA(1,0,0) errors : -12585.84\n",
      " Regression with ARIMA(0,0,1) errors : -10776.69\n",
      " Regression with ARIMA(0,0,0) errors : -8072.897\n",
      " Regression with ARIMA(1,0,2) errors : -12601.79\n",
      " Regression with ARIMA(2,0,1) errors : -12600.13\n",
      " Regression with ARIMA(3,0,2) errors : -12662.69\n",
      " Regression with ARIMA(3,0,1) errors : -12612.34\n",
      " Regression with ARIMA(4,0,2) errors : -12629.9\n",
      " Regression with ARIMA(3,0,3) errors : -12629.01\n",
      " Regression with ARIMA(2,0,3) errors : -12623.63\n",
      " Regression with ARIMA(4,0,1) errors : -12627.83\n",
      " Regression with ARIMA(4,0,3) errors : -12662.1\n",
      " Regression with ARIMA(3,0,2) errors : -12538.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12668.81\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12617.98\n",
      " Regression with ARIMA(0,0,0) errors : -9103.826\n",
      " Regression with ARIMA(1,0,0) errors : -12597.39\n",
      " Regression with ARIMA(0,0,1) errors : -10769.07\n",
      " Regression with ARIMA(0,0,0) errors : -8071.78\n",
      " Regression with ARIMA(1,0,2) errors : -12613.58\n",
      " Regression with ARIMA(2,0,1) errors : -12612.03\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12634.81\n",
      " Regression with ARIMA(1,0,3) errors : -12637.74\n",
      " Regression with ARIMA(0,0,3) errors : -11857.74\n",
      " Regression with ARIMA(1,0,4) errors : -12635.79\n",
      " Regression with ARIMA(0,0,2) errors : -11425.89\n",
      " Regression with ARIMA(0,0,4) errors : -12183.34\n",
      " Regression with ARIMA(2,0,4) errors : -12660.74\n",
      " Regression with ARIMA(3,0,4) errors : -12661.91\n",
      " Regression with ARIMA(3,0,3) errors : -12639.57\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12664.79\n",
      " Regression with ARIMA(1,0,5) errors : -12637.48\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12662.8\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12648.96\n",
      " Regression with ARIMA(0,0,0) errors : -9121.032\n",
      " Regression with ARIMA(1,0,0) errors : -12628.13\n",
      " Regression with ARIMA(0,0,1) errors : -10785.99\n",
      " Regression with ARIMA(0,0,0) errors : -8086.924\n",
      " Regression with ARIMA(1,0,2) errors : -12643.58\n",
      " Regression with ARIMA(2,0,1) errors : -12645.29\n",
      " Regression with ARIMA(3,0,2) errors : -12693.39\n",
      " Regression with ARIMA(3,0,1) errors : -12657.07\n",
      " Regression with ARIMA(4,0,2) errors : -12674.99\n",
      " Regression with ARIMA(3,0,3) errors : -12674.05\n",
      " Regression with ARIMA(2,0,3) errors : -12670.13\n",
      " Regression with ARIMA(4,0,1) errors : -12673.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12586.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12712.63\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12660.79\n",
      " Regression with ARIMA(0,0,0) errors : -9128.864\n",
      " Regression with ARIMA(1,0,0) errors : -12639.5\n",
      " Regression with ARIMA(0,0,1) errors : -10794.45\n",
      " Regression with ARIMA(0,0,0) errors : -8086.79\n",
      " Regression with ARIMA(1,0,2) errors : -12656.36\n",
      " Regression with ARIMA(2,0,1) errors : -12654.67\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12681.02\n",
      " Regression with ARIMA(1,0,3) errors : -12683.93\n",
      " Regression with ARIMA(0,0,3) errors : -11882.7\n",
      " Regression with ARIMA(1,0,4) errors : -12681.93\n",
      " Regression with ARIMA(0,0,2) errors : -11451.05\n",
      " Regression with ARIMA(0,0,4) errors : -12222.24\n",
      " Regression with ARIMA(2,0,4) errors : -12708.43\n",
      " Regression with ARIMA(3,0,4) errors : -12700.64\n",
      " Regression with ARIMA(2,0,5) errors : -12711.77\n",
      " Regression with ARIMA(1,0,5) errors : -12684.46\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12635.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12712.16\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12663.87\n",
      " Regression with ARIMA(0,0,0) errors : -9125.032\n",
      " Regression with ARIMA(1,0,0) errors : -12642.83\n",
      " Regression with ARIMA(0,0,1) errors : -10795.06\n",
      " Regression with ARIMA(0,0,0) errors : -8088.558\n",
      " Regression with ARIMA(1,0,2) errors : -12659.49\n",
      " Regression with ARIMA(2,0,1) errors : -12657.96\n",
      " Regression with ARIMA(3,0,2) errors : -12717.9\n",
      " Regression with ARIMA(3,0,1) errors : -12671.05\n",
      " Regression with ARIMA(4,0,2) errors : -12688.31\n",
      " Regression with ARIMA(3,0,3) errors : -12688.66\n",
      " Regression with ARIMA(2,0,3) errors : -12684.8\n",
      " Regression with ARIMA(4,0,1) errors : -12687.93\n",
      " Regression with ARIMA(4,0,3) errors : -12724.73\n",
      " Regression with ARIMA(5,0,3) errors : -12705.98\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12706.33\n",
      " Regression with ARIMA(5,0,2) errors : -12704.8\n",
      " Regression with ARIMA(5,0,4) errors : -12707.76\n",
      " Regression with ARIMA(4,0,3) errors : -12626.28\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12711.43\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12675.17\n",
      " Regression with ARIMA(0,0,0) errors : -9127.822\n",
      " Regression with ARIMA(1,0,0) errors : -12652.69\n",
      " Regression with ARIMA(0,0,1) errors : -10797.32\n",
      " Regression with ARIMA(0,0,0) errors : -8122.42\n",
      " Regression with ARIMA(1,0,2) errors : -12669.49\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12695.32\n",
      " Regression with ARIMA(1,0,3) errors : -12697.68\n",
      " Regression with ARIMA(0,0,3) errors : -11885.17\n",
      " Regression with ARIMA(1,0,4) errors : -12695.67\n",
      " Regression with ARIMA(0,0,2) errors : -11454.21\n",
      " Regression with ARIMA(0,0,4) errors : -12223.07\n",
      " Regression with ARIMA(2,0,4) errors : -12724.02\n",
      " Regression with ARIMA(3,0,4) errors : -12727\n",
      " Regression with ARIMA(3,0,3) errors : -12699.87\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12728.15\n",
      " Regression with ARIMA(1,0,5) errors : -12698.24\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12723.48\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12683.94\n",
      " Regression with ARIMA(0,0,0) errors : -9138.188\n",
      " Regression with ARIMA(1,0,0) errors : -12661.92\n",
      " Regression with ARIMA(0,0,1) errors : -10809.04\n",
      " Regression with ARIMA(0,0,0) errors : -8146.342\n",
      " Regression with ARIMA(1,0,2) errors : -12678.66\n",
      " Regression with ARIMA(2,0,1) errors : -12676.73\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12704.85\n",
      " Regression with ARIMA(1,0,3) errors : -12707.91\n",
      " Regression with ARIMA(0,0,3) errors : -11899.86\n",
      " Regression with ARIMA(1,0,4) errors : -12705.92\n",
      " Regression with ARIMA(0,0,2) errors : -11462.84\n",
      " Regression with ARIMA(0,0,4) errors : -12239.61\n",
      " Regression with ARIMA(2,0,4) errors : -12733.61\n",
      " Regression with ARIMA(3,0,4) errors : -12727.8\n",
      " Regression with ARIMA(2,0,5) errors : -12736.88\n",
      " Regression with ARIMA(1,0,5) errors : -12708.11\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12658.61\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12738.19\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12707.9\n",
      " Regression with ARIMA(0,0,0) errors : -9146.696\n",
      " Regression with ARIMA(1,0,0) errors : -12685.85\n",
      " Regression with ARIMA(0,0,1) errors : -10816.31\n",
      " Regression with ARIMA(0,0,0) errors : -8145.991\n",
      " Regression with ARIMA(1,0,2) errors : -12701.98\n",
      " Regression with ARIMA(2,0,1) errors : -12702.83\n",
      " Regression with ARIMA(3,0,2) errors : -12752.59\n",
      " Regression with ARIMA(3,0,1) errors : -12716.78\n",
      " Regression with ARIMA(4,0,2) errors : -12776.93\n",
      " Regression with ARIMA(4,0,1) errors : -12738.81\n",
      " Regression with ARIMA(5,0,2) errors : -12750.69\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -12740.15\n",
      " Regression with ARIMA(5,0,1) errors : -12807.17\n",
      " Regression with ARIMA(5,0,0) errors : -12741.34\n",
      " Regression with ARIMA(4,0,0) errors : -12738.7\n",
      " Regression with ARIMA(5,0,1) errors : -12728.9\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12760.88\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12912.84\n",
      " Regression with ARIMA(0,0,0) errors : -9287.558\n",
      " Regression with ARIMA(1,0,0) errors : -12838.23\n",
      " Regression with ARIMA(0,0,1) errors : -10970.44\n",
      " Regression with ARIMA(0,0,0) errors : -8334.607\n",
      " Regression with ARIMA(1,0,2) errors : -12850.07\n",
      " Regression with ARIMA(2,0,1) errors : -12896.83\n",
      " Regression with ARIMA(3,0,2) errors : -12886.59\n",
      " Regression with ARIMA(2,0,3) errors : -12920.49\n",
      " Regression with ARIMA(1,0,3) errors : -12869.31\n",
      " Regression with ARIMA(3,0,3) errors : -12922.93\n",
      " Regression with ARIMA(4,0,3) errors : -12951.22\n",
      " Regression with ARIMA(4,0,2) errors : -12979.64\n",
      " Regression with ARIMA(4,0,1) errors : -12919.17\n",
      " Regression with ARIMA(5,0,2) errors : -13016.01\n",
      " Regression with ARIMA(5,0,1) errors : -12918.05\n",
      " Regression with ARIMA(5,0,3) errors : -13009.45\n",
      " Regression with ARIMA(5,0,2) errors : -12924.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -12851.52\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13340.53\n",
      " Regression with ARIMA(0,0,0) errors : -9896.247\n",
      " Regression with ARIMA(1,0,0) errors : -13321.04\n",
      " Regression with ARIMA(0,0,1) errors : -11543.52\n",
      " Regression with ARIMA(0,0,0) errors : -8940.049\n",
      " Regression with ARIMA(1,0,2) errors : -13322.44\n",
      " Regression with ARIMA(2,0,1) errors : -13321.63\n",
      " Regression with ARIMA(3,0,2) errors : -13355.77\n",
      " Regression with ARIMA(3,0,1) errors : -13337\n",
      " Regression with ARIMA(4,0,2) errors : -13354.79\n",
      " Regression with ARIMA(3,0,3) errors : -13380.32\n",
      " Regression with ARIMA(2,0,3) errors : -13333.79\n",
      " Regression with ARIMA(4,0,3) errors : -13412.84\n",
      " Regression with ARIMA(5,0,3) errors : -13428.89\n",
      " Regression with ARIMA(5,0,2) errors : -13429.21\n",
      " Regression with ARIMA(5,0,1) errors : -13348.63\n",
      " Regression with ARIMA(4,0,1) errors : -13348.07\n",
      " Regression with ARIMA(5,0,2) errors : -13296.63\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13383.36\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13638.8\n",
      " Regression with ARIMA(0,1,0) errors : -13557.1\n",
      " Regression with ARIMA(1,1,0) errors : -13569.73\n",
      " Regression with ARIMA(0,1,1) errors : -13568.98\n",
      " Regression with ARIMA(0,1,0) errors : -13559.1\n",
      " Regression with ARIMA(1,1,2) errors : -13569.88\n",
      " Regression with ARIMA(2,1,1) errors : -13572.21\n",
      " Regression with ARIMA(3,1,2) errors : -13655.74\n",
      " Regression with ARIMA(3,1,1) errors : -13608.61\n",
      " Regression with ARIMA(4,1,2) errors : -13690.96\n",
      " Regression with ARIMA(4,1,1) errors : -13635.24\n",
      " Regression with ARIMA(5,1,2) errors : -13685.37\n",
      " Regression with ARIMA(4,1,3) errors : -13668.95\n",
      " Regression with ARIMA(3,1,3) errors : -13656.78\n",
      " Regression with ARIMA(5,1,1) errors : -13674.36\n",
      " Regression with ARIMA(5,1,3) errors : -13699.07\n",
      " Regression with ARIMA(5,1,4) errors : -13798\n",
      " Regression with ARIMA(4,1,4) errors : -13766.7\n",
      " Regression with ARIMA(5,1,5) errors : -13796.13\n",
      " Regression with ARIMA(4,1,5) errors : -13791.29\n",
      " Regression with ARIMA(5,1,4) errors : -13800.01\n",
      " Regression with ARIMA(4,1,4) errors : -13768.68\n",
      " Regression with ARIMA(5,1,3) errors : -13701.1\n",
      " Regression with ARIMA(5,1,5) errors : -13798.15\n",
      " Regression with ARIMA(4,1,3) errors : -13669.36\n",
      " Regression with ARIMA(4,1,5) errors : -13793.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,4) errors : -13627.14\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13856.97\n",
      " Regression with ARIMA(0,1,0) errors : -13830.28\n",
      " Regression with ARIMA(1,1,0) errors : -13844.83\n",
      " Regression with ARIMA(0,1,1) errors : -13841.77\n",
      " Regression with ARIMA(0,1,0) errors : -13832.29\n",
      " Regression with ARIMA(1,1,2) errors : -13852.88\n",
      " Regression with ARIMA(2,1,1) errors : -13857.98\n",
      " Regression with ARIMA(1,1,1) errors : -13853.24\n",
      " Regression with ARIMA(2,1,0) errors : -13857.59\n",
      " Regression with ARIMA(3,1,1) errors : -13856.45\n",
      " Regression with ARIMA(3,1,0) errors : -13855.79\n",
      " Regression with ARIMA(3,1,2) errors : -13853.87\n",
      " Regression with ARIMA(2,1,1) errors : -13859.99\n",
      " Regression with ARIMA(1,1,1) errors : -13855.24\n",
      " Regression with ARIMA(2,1,0) errors : -13859.61\n",
      " Regression with ARIMA(3,1,1) errors : -13858.47\n",
      " Regression with ARIMA(2,1,2) errors : -13858.99\n",
      " Regression with ARIMA(1,1,0) errors : -13846.84\n",
      " Regression with ARIMA(1,1,2) errors : -13854.88\n",
      " Regression with ARIMA(3,1,0) errors : -13857.8\n",
      " Regression with ARIMA(3,1,2) errors : -13855.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : -13852.22\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,1) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13947.36\n",
      " Regression with ARIMA(0,1,0) errors : -13900.86\n",
      " Regression with ARIMA(1,1,0) errors : -13932.84\n",
      " Regression with ARIMA(0,1,1) errors : -13911.73\n",
      " Regression with ARIMA(0,1,0) errors : -13902.87\n",
      " Regression with ARIMA(1,1,2) errors : -13939.01\n",
      " Regression with ARIMA(2,1,1) errors : -13943.65\n",
      " Regression with ARIMA(3,1,2) errors : -13959.09\n",
      " Regression with ARIMA(3,1,1) errors : -13956.45\n",
      " Regression with ARIMA(4,1,2) errors : -14000.17\n",
      " Regression with ARIMA(4,1,1) errors : -13952.05\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : -14004.61\n",
      " Regression with ARIMA(3,1,3) errors : -13984.19\n",
      " Regression with ARIMA(5,1,3) errors : -14058.98\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : -14034.52\n",
      " Regression with ARIMA(5,1,3) errors : -14060.9\n",
      " Regression with ARIMA(4,1,3) errors : -14006.63\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : -14002.15\n",
      " Regression with ARIMA(4,1,4) errors : -14036.43\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : -13974.19\n",
      "\n",
      " Best model: Regression with ARIMA(4,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14051.09\n",
      " Regression with ARIMA(0,1,0) errors : -14017.53\n",
      " Regression with ARIMA(1,1,0) errors : -14026.02\n",
      " Regression with ARIMA(0,1,1) errors : -14026.4\n",
      " Regression with ARIMA(0,1,0) errors : -14019.51\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14049.92\n",
      " Regression with ARIMA(3,1,2) errors : -14072.45\n",
      " Regression with ARIMA(3,1,1) errors : -14060.26\n",
      " Regression with ARIMA(4,1,2) errors : -14078.94\n",
      " Regression with ARIMA(4,1,1) errors : -14061.76\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : -14126.2\n",
      " Regression with ARIMA(2,1,3) errors : -14050.56\n",
      " Regression with ARIMA(3,1,4) errors : -14077.3\n",
      " Regression with ARIMA(2,1,4) errors : -14048.58\n",
      " Regression with ARIMA(4,1,4) errors : -14193.59\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14215.31\n",
      " Regression with ARIMA(2,1,5) errors : -14059.26\n",
      " Regression with ARIMA(3,1,5) errors : -14216.42\n",
      " Regression with ARIMA(2,1,5) errors : -14061.28\n",
      " Regression with ARIMA(3,1,4) errors : -14177.43\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14050.61\n",
      " Regression with ARIMA(4,1,4) errors : -14194.71\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -14036.04\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14232.72\n",
      " Regression with ARIMA(0,1,0) errors : -14162.77\n",
      " Regression with ARIMA(1,1,0) errors : -14185.38\n",
      " Regression with ARIMA(0,1,1) errors : -14173.07\n",
      " Regression with ARIMA(0,1,0) errors : -14164.75\n",
      " Regression with ARIMA(1,1,2) errors : -14207.81\n",
      " Regression with ARIMA(2,1,1) errors : -14224.23\n",
      " Regression with ARIMA(3,1,2) errors : -14248.4\n",
      " Regression with ARIMA(3,1,1) errors : -14225.86\n",
      " Regression with ARIMA(4,1,2) errors : -14270.04\n",
      " Regression with ARIMA(4,1,1) errors : -14226.79\n",
      " Regression with ARIMA(5,1,2) errors : -14276.69\n",
      " Regression with ARIMA(5,1,1) errors : -14239.31\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : -14278.66\n",
      " Regression with ARIMA(4,1,2) errors : -14272.05\n",
      " Regression with ARIMA(5,1,1) errors : -14241.32\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : -14228.77\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,1) errors : -14188.43\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14269.51\n",
      " Regression with ARIMA(1,1,0) errors : -14280.67\n",
      " Regression with ARIMA(0,1,1) errors : -14275.99\n",
      " Regression with ARIMA(0,1,0) errors : -14271.49\n",
      " Regression with ARIMA(2,1,0) errors : -14280.26\n",
      " Regression with ARIMA(1,1,1) errors : -14283.64\n",
      " Regression with ARIMA(2,1,1) errors : -14282.63\n",
      " Regression with ARIMA(1,1,2) errors : -14281.81\n",
      " Regression with ARIMA(0,1,2) errors : -14276.35\n",
      " Regression with ARIMA(1,1,1) errors : -14285.62\n",
      " Regression with ARIMA(0,1,1) errors : -14277.97\n",
      " Regression with ARIMA(1,1,0) errors : -14282.66\n",
      " Regression with ARIMA(2,1,1) errors : -14284.63\n",
      " Regression with ARIMA(1,1,2) errors : -14283.8\n",
      " Regression with ARIMA(0,1,2) errors : -14278.33\n",
      " Regression with ARIMA(2,1,0) errors : -14282.25\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14292.77\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14392.52\n",
      " Regression with ARIMA(0,1,0) errors : -14319.87\n",
      " Regression with ARIMA(1,1,0) errors : -14323.95\n",
      " Regression with ARIMA(0,1,1) errors : -14324.28\n",
      " Regression with ARIMA(0,1,0) errors : -14321.88\n",
      " Regression with ARIMA(1,1,2) errors : -14328.67\n",
      " Regression with ARIMA(2,1,1) errors : -14322.2\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14396.05\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14397.58\n",
      " Regression with ARIMA(1,1,4) errors : -14325.55\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14409.11\n",
      " Regression with ARIMA(0,1,5) errors : -14329.22\n",
      " Regression with ARIMA(0,1,4) errors : -14322.36\n",
      " Regression with ARIMA(1,1,5) errors : -14410.56\n",
      " Regression with ARIMA(0,1,5) errors : -14331.23\n",
      " Regression with ARIMA(1,1,4) errors : -14327.56\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(0,1,4) errors : -14324.37\n",
      " Regression with ARIMA(2,1,4) errors : -14399.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,5) errors : -14340.4\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14414.39\n",
      " Regression with ARIMA(0,1,0) errors : -14347.05\n",
      " Regression with ARIMA(1,1,0) errors : -14351.5\n",
      " Regression with ARIMA(0,1,1) errors : -14351.98\n",
      " Regression with ARIMA(0,1,0) errors : -14349.06\n",
      " Regression with ARIMA(1,1,2) errors : -14355.74\n",
      " Regression with ARIMA(2,1,1) errors : -14357.14\n",
      " Regression with ARIMA(3,1,2) errors : -14356.58\n",
      " Regression with ARIMA(2,1,3) errors : -14416.78\n",
      " Regression with ARIMA(1,1,3) errors : -14352.44\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14426.08\n",
      " Regression with ARIMA(1,1,4) errors : -14352.46\n",
      " Regression with ARIMA(3,1,4) errors : -14359.23\n",
      " Regression with ARIMA(2,1,5) errors : -14433.08\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14448.43\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14449.79\n",
      " Regression with ARIMA(2,1,5) errors : -14434.5\n",
      " Regression with ARIMA(3,1,4) errors : -14361.25\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14427.62\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14373.05\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14467.17\n",
      " Regression with ARIMA(0,1,0) errors : -14387.79\n",
      " Regression with ARIMA(1,1,0) errors : -14392.42\n",
      " Regression with ARIMA(0,1,1) errors : -14393.12\n",
      " Regression with ARIMA(0,1,0) errors : -14389.79\n",
      " Regression with ARIMA(1,1,2) errors : -14393.52\n",
      " Regression with ARIMA(2,1,1) errors : -14392.46\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14467.02\n",
      " Regression with ARIMA(1,1,1) errors : -14394.63\n",
      " Regression with ARIMA(1,1,3) errors : -14391.52\n",
      " Regression with ARIMA(3,1,1) errors : -14450.2\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -14468.77\n",
      " Regression with ARIMA(1,1,2) errors : -14395.53\n",
      " Regression with ARIMA(2,1,1) errors : -14394.46\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14468.52\n",
      " Regression with ARIMA(1,1,1) errors : -14396.63\n",
      " Regression with ARIMA(1,1,3) errors : -14393.52\n",
      " Regression with ARIMA(3,1,1) errors : -14452.03\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : -14406.82\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11132.19\n",
      " Regression with ARIMA(1,0,0) errors : -14540.36\n",
      " Regression with ARIMA(0,0,1) errors : -12745.99\n",
      " Regression with ARIMA(0,0,0) errors : -9972.371\n",
      " Regression with ARIMA(2,0,0) errors : -14537.54\n",
      " Regression with ARIMA(1,0,1) errors : -14538.45\n",
      " Regression with ARIMA(2,0,1) errors : -14542.87\n",
      " Regression with ARIMA(3,0,1) errors : -14558.56\n",
      " Regression with ARIMA(3,0,0) errors : -14548.35\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -14559.21\n",
      " Regression with ARIMA(4,0,2) errors : -14555.78\n",
      " Regression with ARIMA(3,0,3) errors : -14558.89\n",
      " Regression with ARIMA(2,0,3) errors : -14545.56\n",
      " Regression with ARIMA(4,0,3) errors : -14553.54\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14560.17\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11151.48\n",
      " Regression with ARIMA(1,0,0) errors : -14551.11\n",
      " Regression with ARIMA(0,0,1) errors : -12768.97\n",
      " Regression with ARIMA(0,0,0) errors : -9991.611\n",
      " Regression with ARIMA(2,0,0) errors : -14548.25\n",
      " Regression with ARIMA(1,0,1) errors : -14549.23\n",
      " Regression with ARIMA(2,0,1) errors : -14552.94\n",
      " Regression with ARIMA(3,0,1) errors : -14567.66\n",
      " Regression with ARIMA(3,0,0) errors : -14558.46\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,0) errors : -14557.43\n",
      " Regression with ARIMA(4,0,2) errors : -14572.3\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -14567.45\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,1) errors : -14571.65\n",
      " Regression with ARIMA(5,0,3) errors : -14591.07\n",
      " Regression with ARIMA(5,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -14588.65\n",
      " Regression with ARIMA(5,0,3) errors : -14466.83\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -14592.39\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14560.15\n",
      " Regression with ARIMA(0,0,0) errors : -11132.88\n",
      " Regression with ARIMA(1,0,0) errors : -14543.96\n",
      " Regression with ARIMA(0,0,1) errors : -12748.49\n",
      " Regression with ARIMA(0,0,0) errors : -9916.669\n",
      " Regression with ARIMA(1,0,2) errors : -14552.05\n",
      " Regression with ARIMA(2,0,1) errors : -14544.14\n",
      " Regression with ARIMA(3,0,2) errors : -14551.85\n",
      " Regression with ARIMA(2,0,3) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -14542.09\n",
      " Regression with ARIMA(1,0,3) errors : -14551.93\n",
      " Regression with ARIMA(3,0,1) errors : -14569.13\n",
      " Regression with ARIMA(3,0,0) errors : -14553.2\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -14542.46\n",
      " Regression with ARIMA(4,0,0) errors : -14553.19\n",
      " Regression with ARIMA(4,0,2) errors : -14568.72\n",
      " Regression with ARIMA(3,0,1) errors : -14400.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -14566.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11155.69\n",
      " Regression with ARIMA(1,0,0) errors : -14548.92\n",
      " Regression with ARIMA(0,0,1) errors : -12768.48\n",
      " Regression with ARIMA(0,0,0) errors : -9907.063\n",
      " Regression with ARIMA(2,0,0) errors : -14546.07\n",
      " Regression with ARIMA(1,0,1) errors : -14546.93\n",
      " Regression with ARIMA(2,0,1) errors : -14550.78\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -14554.96\n",
      " Regression with ARIMA(0,0,2) errors : -13588.57\n",
      " Regression with ARIMA(1,0,3) errors : -14555.05\n",
      " Regression with ARIMA(0,0,3) errors : -13929.67\n",
      " Regression with ARIMA(2,0,3) errors : -14552.73\n",
      " Regression with ARIMA(1,0,4) errors : -14561.38\n",
      " Regression with ARIMA(0,0,4) errors : -14217.43\n",
      " Regression with ARIMA(2,0,4) errors : -14559.98\n",
      " Regression with ARIMA(1,0,5) errors : -14560.36\n",
      " Regression with ARIMA(0,0,5) errors : -14327\n",
      " Regression with ARIMA(2,0,5) errors : -14558.11\n",
      " Regression with ARIMA(1,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,4) errors : -14560.62\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14379.34\n",
      " Regression with ARIMA(1,1,0) errors : -14383.72\n",
      " Regression with ARIMA(0,1,1) errors : -14382.54\n",
      " Regression with ARIMA(0,1,0) errors : -14381.35\n",
      " Regression with ARIMA(2,1,0) errors : -14382.72\n",
      " Regression with ARIMA(1,1,1) errors : -14384.5\n",
      " Regression with ARIMA(2,1,1) errors : -14382.23\n",
      " Regression with ARIMA(1,1,2) errors : -14382.66\n",
      " Regression with ARIMA(0,1,2) errors : -14382.21\n",
      " Regression with ARIMA(1,1,1) errors : -14386.51\n",
      " Regression with ARIMA(0,1,1) errors : -14384.55\n",
      " Regression with ARIMA(1,1,0) errors : -14385.73\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : -14384.54\n",
      " Regression with ARIMA(0,1,2) errors : -14384.22\n",
      " Regression with ARIMA(2,1,0) errors : -14384.73\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14397.22\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14483.22\n",
      " Regression with ARIMA(0,0,0) errors : -11017.35\n",
      " Regression with ARIMA(1,0,0) errors : -14460.22\n",
      " Regression with ARIMA(0,0,1) errors : -12640.36\n",
      " Regression with ARIMA(0,0,0) errors : -9780.733\n",
      " Regression with ARIMA(1,0,2) errors : -14467.99\n",
      " Regression with ARIMA(2,0,1) errors : -14461.13\n",
      " Regression with ARIMA(3,0,2) errors : -14483.56\n",
      " Regression with ARIMA(3,0,1) errors : -14483.17\n",
      " Regression with ARIMA(4,0,2) errors : -14480.81\n",
      " Regression with ARIMA(3,0,3) errors : -14482.96\n",
      " Regression with ARIMA(2,0,3) errors : -14464.37\n",
      " Regression with ARIMA(4,0,1) errors : -14477.63\n",
      " Regression with ARIMA(4,0,3) errors : -14478.99\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14477.22\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14498.8\n",
      " Regression with ARIMA(0,0,0) errors : -11029\n",
      " Regression with ARIMA(1,0,0) errors : -14478.15\n",
      " Regression with ARIMA(0,0,1) errors : -12661.86\n",
      " Regression with ARIMA(0,0,0) errors : -9798.577\n",
      " Regression with ARIMA(1,0,2) errors : -14485.32\n",
      " Regression with ARIMA(2,0,1) errors : -14479.56\n",
      " Regression with ARIMA(3,0,2) errors : -14498.67\n",
      " Regression with ARIMA(2,0,3) errors : -14482.25\n",
      " Regression with ARIMA(1,0,1) errors : -14476.18\n",
      " Regression with ARIMA(1,0,3) errors : -14486.49\n",
      " Regression with ARIMA(3,0,1) errors : -14499.33\n",
      " Regression with ARIMA(3,0,0) errors : -14485.04\n",
      " Regression with ARIMA(4,0,1) errors : -14493.81\n",
      " Regression with ARIMA(2,0,0) errors : -14475.19\n",
      " Regression with ARIMA(4,0,0) errors : -14489\n",
      " Regression with ARIMA(4,0,2) errors : -14497.35\n",
      " Regression with ARIMA(3,0,1) errors : -14328.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -14499.04\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14499.82\n",
      " Regression with ARIMA(0,0,0) errors : -11030.92\n",
      " Regression with ARIMA(1,0,0) errors : -14479.83\n",
      " Regression with ARIMA(0,0,1) errors : -12666.18\n",
      " Regression with ARIMA(0,0,0) errors : -9815.953\n",
      " Regression with ARIMA(1,0,2) errors : -14487.24\n",
      " Regression with ARIMA(2,0,1) errors : -14480.13\n",
      " Regression with ARIMA(3,0,2) errors : -14499.16\n",
      " Regression with ARIMA(2,0,3) errors : -14482.98\n",
      " Regression with ARIMA(1,0,1) errors : -14477.85\n",
      " Regression with ARIMA(1,0,3) errors : -14488.5\n",
      " Regression with ARIMA(3,0,1) errors : -14497.61\n",
      " Regression with ARIMA(3,0,3) errors : -14499.03\n",
      " Regression with ARIMA(2,0,2) errors : -14337.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14481.43\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14520.82\n",
      " Regression with ARIMA(0,0,0) errors : -11039.14\n",
      " Regression with ARIMA(1,0,0) errors : -14493.69\n",
      " Regression with ARIMA(0,0,1) errors : -12672\n",
      " Regression with ARIMA(0,0,0) errors : -9822.197\n",
      " Regression with ARIMA(1,0,2) errors : -14500.76\n",
      " Regression with ARIMA(2,0,1) errors : -14497.56\n",
      " Regression with ARIMA(3,0,2) errors : -14524.84\n",
      " Regression with ARIMA(3,0,1) errors : -14518.61\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -14524.22\n",
      " Regression with ARIMA(2,0,3) errors : -14520.02\n",
      " Regression with ARIMA(4,0,1) errors : -14521.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14510.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14421.28\n",
      " Regression with ARIMA(1,1,0) errors : -14438.68\n",
      " Regression with ARIMA(0,1,1) errors : -14424.25\n",
      " Regression with ARIMA(0,1,0) errors : -14423.29\n",
      " Regression with ARIMA(2,1,0) errors : -14439.8\n",
      " Regression with ARIMA(3,1,0) errors : -14439.79\n",
      " Regression with ARIMA(2,1,1) errors : -14444.89\n",
      " Regression with ARIMA(1,1,1) errors : -14446.77\n",
      " Regression with ARIMA(1,1,2) errors : -14444.79\n",
      " Regression with ARIMA(0,1,2) errors : -14423.33\n",
      " Regression with ARIMA(1,1,1) errors : -14448.78\n",
      " Regression with ARIMA(0,1,1) errors : -14426.26\n",
      " Regression with ARIMA(1,1,0) errors : -14440.69\n",
      " Regression with ARIMA(2,1,1) errors : -14446.9\n",
      " Regression with ARIMA(1,1,2) errors : -14446.8\n",
      " Regression with ARIMA(0,1,2) errors : -14425.34\n",
      " Regression with ARIMA(2,1,0) errors : -14441.81\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14440.01\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14553.28\n",
      " Regression with ARIMA(0,1,0) errors : -14483.96\n",
      " Regression with ARIMA(1,1,0) errors : -14484.77\n",
      " Regression with ARIMA(0,1,1) errors : -14485.54\n",
      " Regression with ARIMA(0,1,0) errors : -14485.96\n",
      " Regression with ARIMA(1,1,2) errors : -14488.25\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14562.68\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14567.68\n",
      " Regression with ARIMA(1,1,4) errors : -14484.21\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14585.28\n",
      " Regression with ARIMA(1,1,5) errors : -14492.24\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14586.81\n",
      " Regression with ARIMA(1,1,5) errors : -14494.25\n",
      " Regression with ARIMA(2,1,4) errors : -14569.27\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : -14485.81\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14504.5\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14595.43\n",
      " Regression with ARIMA(0,1,0) errors : -14527.09\n",
      " Regression with ARIMA(1,1,0) errors : -14529.37\n",
      " Regression with ARIMA(0,1,1) errors : -14529.7\n",
      " Regression with ARIMA(0,1,0) errors : -14529.09\n",
      " Regression with ARIMA(1,1,2) errors : -14533.99\n",
      " Regression with ARIMA(2,1,1) errors : -14543.6\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14601.94\n",
      " Regression with ARIMA(1,1,3) errors : -14532.49\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14605.78\n",
      " Regression with ARIMA(1,1,4) errors : -14530.67\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14537.39\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14607.58\n",
      " Regression with ARIMA(1,1,4) errors : -14532.67\n",
      " Regression with ARIMA(2,1,3) errors : -14603.75\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : -14534.49\n",
      " Regression with ARIMA(1,1,5) errors : -14539.39\n",
      " Regression with ARIMA(3,1,3) errors : -14598.8\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14549.06\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14516.87\n",
      " Regression with ARIMA(1,1,0) errors : -14525.36\n",
      " Regression with ARIMA(0,1,1) errors : -14520.46\n",
      " Regression with ARIMA(0,1,0) errors : -14518.88\n",
      " Regression with ARIMA(2,1,0) errors : -14523.87\n",
      " Regression with ARIMA(1,1,1) errors : -14523.58\n",
      " Regression with ARIMA(2,1,1) errors : -14528.44\n",
      " Regression with ARIMA(3,1,1) errors : -14605.73\n",
      " Regression with ARIMA(3,1,0) errors : -14522.73\n",
      " Regression with ARIMA(4,1,1) errors : -14552.02\n",
      " Regression with ARIMA(3,1,2) errors : -14601.37\n",
      " Regression with ARIMA(4,1,0) errors : -14523.8\n",
      " Regression with ARIMA(4,1,2) errors : -14570.42\n",
      " Regression with ARIMA(3,1,1) errors : -14607.28\n",
      " Regression with ARIMA(2,1,1) errors : -14530.46\n",
      " Regression with ARIMA(3,1,0) errors : -14524.74\n",
      " Regression with ARIMA(4,1,1) errors : -14553.78\n",
      " Regression with ARIMA(3,1,2) errors : -14602.92\n",
      " Regression with ARIMA(2,1,0) errors : -14525.88\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,0) errors : -14525.81\n",
      " Regression with ARIMA(4,1,2) errors : -14572.1\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14535.51\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11250.18\n",
      " Regression with ARIMA(1,0,0) errors : -14656.36\n",
      " Regression with ARIMA(0,0,1) errors : -12862.56\n",
      " Regression with ARIMA(0,0,0) errors : -10027.92\n",
      " Regression with ARIMA(2,0,0) errors : -14654.03\n",
      " Regression with ARIMA(1,0,1) errors : -14654.36\n",
      " Regression with ARIMA(2,0,1) errors : -14660.84\n",
      " Regression with ARIMA(3,0,1) errors : -14661.21\n",
      " Regression with ARIMA(3,0,0) errors : -14664.08\n",
      " Regression with ARIMA(4,0,0) errors : -14664.12\n",
      " Regression with ARIMA(5,0,0) errors : -14670.91\n",
      " Regression with ARIMA(5,0,1) errors : -14674.19\n",
      " Regression with ARIMA(4,0,1) errors : -14674.78\n",
      " Regression with ARIMA(4,0,2) errors : -14678.29\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : -14693.27\n",
      " Regression with ARIMA(5,0,3) errors : -14691.32\n",
      " Regression with ARIMA(4,0,3) errors : -14661.91\n",
      " Regression with ARIMA(5,0,2) errors : -14579.72\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -14701.58\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11249.56\n",
      " Regression with ARIMA(1,0,0) errors : -14656.24\n",
      " Regression with ARIMA(0,0,1) errors : -12864.81\n",
      " Regression with ARIMA(0,0,0) errors : -10027.74\n",
      " Regression with ARIMA(2,0,0) errors : -14657.78\n",
      " Regression with ARIMA(3,0,0) errors : -14666.92\n",
      " Regression with ARIMA(4,0,0) errors : -14666.09\n",
      " Regression with ARIMA(3,0,1) errors : -14664.16\n",
      " Regression with ARIMA(2,0,1) errors : -14658.57\n",
      " Regression with ARIMA(4,0,1) errors : -14666.46\n",
      " Regression with ARIMA(3,0,0) errors : -14546.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,0) errors : -14662.78\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14675.28\n",
      " Regression with ARIMA(0,0,0) errors : -11256.19\n",
      " Regression with ARIMA(1,0,0) errors : -14668.76\n",
      " Regression with ARIMA(0,0,1) errors : -12871.85\n",
      " Regression with ARIMA(0,0,0) errors : -10034.68\n",
      " Regression with ARIMA(1,0,2) errors : -14674.7\n",
      " Regression with ARIMA(2,0,1) errors : -14674.96\n",
      " Regression with ARIMA(3,0,2) errors : -14693.42\n",
      " Regression with ARIMA(3,0,1) errors : -14675.56\n",
      " Regression with ARIMA(4,0,2) errors : -14690.6\n",
      " Regression with ARIMA(3,0,3) errors : -14692.29\n",
      " Regression with ARIMA(2,0,3) errors : -14676.55\n",
      " Regression with ARIMA(4,0,1) errors : -14675.31\n",
      " Regression with ARIMA(4,0,3) errors : -14683.71\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14692.38\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m03.3 <- my.tsCV(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                        xreg.msize=hori,\n",
    "                        xreg=trainx[,2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dfd95132-f6b6-449a-80b4-b9750616bde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-01-24\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m03.3\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53f2b51-a9df-4dbd-bdd6-d77af2fe524f",
   "metadata": {},
   "source": [
    "## Compare Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed9c467c-feac-4461-816b-ac6a0abcae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "my.figsize(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e499e5ce-1237-49e0-a787-a1be8de29cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94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\nAiEAAAAARCgCIQAAAABEqN8A7/I9MqUZXSEAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- new.get_result(result.m03.1, '1. ARIMA')\n",
    "errors.2 <- new.get_result(result.m03.2, '2. ARIMA Errors 2')\n",
    "n <- paste('3. ARIMA Errors (future regressor mean of', hori ,'days)', sep=' ')\n",
    "errors.3 <- new.get_result(result.m03.3, n)\n",
    "\n",
    "x <- rbind(errors.1, errors.2)\n",
    "x <- rbind(x, errors.3)\n",
    "\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b58831-3950-4988-b3bf-3f5313d409f9",
   "metadata": {},
   "source": [
    "### save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab39eccc-4453-4c0e-b430-b46b51c21e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- result.m03.1\n",
    "write.csv(x, file = \"arima_result_m0301.csv\")\n",
    "x <- result.m03.2\n",
    "write.csv(x, file = \"arima_result_m0302.csv\")\n",
    "x <- result.m03.3\n",
    "write.csv(x, file = \"arima_result_m0303.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c35829-53d8-47e0-b381-71b6dfd0d856",
   "metadata": {},
   "source": [
    "### load result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c522e476-b850-4a80-8d6f-4d52ec6b5ae5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.m03.1 <- read.csv(file = 'arima_result_m0301.csv')\n",
    "result.m03.2 <- read.csv(file = 'arima_result_m0302.csv')\n",
    "result.m03.3 <- read.csv(file = 'arima_result_m0303.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9f0a8df7-b56a-46aa-9af5-d6702ae1057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m03 <- result.m03.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88acae2-994b-4716-b170-6ce34970d63e",
   "metadata": {},
   "source": [
    "# ARIMA+GARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748e4290-f9bd-441f-a136-17269a33122d",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f191fab1-f27c-4776-857e-0122f16923dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast <- function(x, h, \n",
    "                        mxreg=NULL, mxreg.msize=NULL, \n",
    "                        vxreg=NULL, vxreg.msize=NULL,\n",
    "                        order=NULL) {\n",
    "    forc <- ag2.forecast(x, h, \n",
    "                         mxreg=mxreg, mxreg.msize=mxreg.msize, \n",
    "                         vxreg=vxreg, vxreg.msize=vxreg.msize, \n",
    "                         out.sample=0, order=order)\n",
    "    if (!is.na(forc)) {\n",
    "        fc <- list(method = \"ARIMA+GARCH Forecasting\", mean=forc@forecast$seriesFor[,1],\n",
    "                   arima.order=forc@users$arima.order)\n",
    "        attr(fc$mean, \"names\") <- NULL\n",
    "        return(fc)\n",
    "    }\n",
    "}\n",
    "\n",
    "agarch.forecast <- cv.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad24908e-79eb-4b66-afa7-325b1c04fd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast.2 <- function(x, h, ...) {\n",
    "    new.forecast(x, h, cv.forecast, ...)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8dd1a8-1213-4b11-be11-ed86fa7e0ac2",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3fc5c70c-df6f-49dd-b5a3-d09dcd858c0e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 % done.\n",
      "\n",
      "30 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in seq.int(r1$year, by = by, length.out = length.out) : \n",
      "  'from' must be a finite number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50 % done.\n",
      "\n",
      "60 % done.\n",
      "\n",
      "70 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n"
     ]
    }
   ],
   "source": [
    "result.m04.1 <- my.tsCV(train, cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                        silent=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4916d16-6a26-4c9c-bb1b-30988b39aa2a",
   "metadata": {},
   "source": [
    "## Regressors for mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce4d19cd-012a-426c-bd7f-9d312c363316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n",
      "20 % done.\n",
      "\n",
      "30 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in seq.int(r1$year, by = by, length.out = length.out) : \n",
      "  'from' must be a finite number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50 % done.\n",
      "\n",
      "60 % done.\n",
      "\n",
      "70 % done.\n",
      "\n",
      "80 % done.\n",
      "\n",
      "90 % done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m04.2 <- my.tsCV(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                        mxreg=trainx[,2:4], silent=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b54ebef-c351-4357-8f97-9c524bd47711",
   "metadata": {},
   "source": [
    "## Regressors for variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "665586fb-e4bf-4356-86fb-2be0133969fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 % done.\n",
      "\n",
      "30 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in seq.int(r1$year, by = by, length.out = length.out) : \n",
      "  'from' must be a finite number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40 % done.\n",
      "\n",
      "50 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60 % done.\n",
      "\n",
      "70 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90 % done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m04.3 <- my.tsCV(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                        vxreg=trainx[,2:4], silent=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26215cf2-deb9-45fa-be1f-ea72448a97b7",
   "metadata": {},
   "source": [
    "## Regressors for both of mean & variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "048f72f1-594f-416e-8dc4-a12ecb877efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n",
      "20 % done.\n",
      "\n",
      "30 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n",
      "Error in seq.int(r1$year, by = by, length.out = length.out) : \n",
      "  'from' must be a finite number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40 % done.\n",
      "\n",
      "50 % done.\n",
      "\n",
      "60 % done.\n",
      "\n",
      "70 % done.\n",
      "\n",
      "80 % done.\n",
      "\n",
      "90 % done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m04.4 <- my.tsCV(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                        mxreg=trainx[,2:4], vxreg=trainx[,2:4], \n",
    "                        silent=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b4805d3a-1bc0-47e4-95f8-d358940ab858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-02-09\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m04.4\n",
    "from <- x[!is.na(x[,'forecast_start']),][,1][1]\n",
    "from <- index(trainx[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8c970c-798b-4d41-9930-01e336c80952",
   "metadata": {},
   "source": [
    "## Compare Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "624fa65b-7533-4f86-86de-0c335271b0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94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\nNBQKQgAAAAAAAA31N3JokEpCIEkuAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- new.get_result(result.m04.1, '1.AG')\n",
    "errors.2 <- new.get_result(result.m04.2, '2.AG with mxreg')\n",
    "errors.3 <- new.get_result(result.m04.3, '3.AG with vxreg')\n",
    "errors.4 <- new.get_result(result.m04.4, '4.AG with m&v xreg')\n",
    "\n",
    "x <- rbind(errors.1, errors.2)\n",
    "x <- rbind(x, errors.3)\n",
    "x <- rbind(x, errors.4)\n",
    "\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec0491-dff8-4c4b-8965-bcbfbecf1375",
   "metadata": {},
   "source": [
    "### save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4121890e-a78d-4c57-a282-e65c742ce8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- result.m04.1\n",
    "write.csv(x, file = \"agarch_result_m0401.csv\")\n",
    "x <- result.m04.2\n",
    "write.csv(x, file = \"agarch_result_m0402.csv\")\n",
    "x <- result.m04.3\n",
    "write.csv(x, file = \"agarch_result_m0403.csv\")\n",
    "x <- result.m04.4\n",
    "write.csv(x, file = \"agarch_result_m0404.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ddbbe0-2e37-4bbc-b30e-eb93048e1f1a",
   "metadata": {},
   "source": [
    "### load result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "199edcd6-5769-43b7-84e5-7169ce2ca863",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.m04.1 <- read.csv(file = 'agarch_result_m0401.csv')\n",
    "result.m04.2 <- read.csv(file = 'agarch_result_m0402.csv')\n",
    "result.m04.3 <- read.csv(file = 'agarch_result_m0403.csv')\n",
    "result.m04.4 <- read.csv(file = 'agarch_result_m0404.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5ab8b4ec-19dc-42d8-bdcf-2c6d98936fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m04 <- result.m04.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b679ca19-bc28-4b63-a30c-4307392c4bca",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f404eb3-7cf4-4a6f-9bce-53f24d25335e",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "26450ef3-ca0d-435c-b61b-67fabb48a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.forecast <- function(\n",
    "    train.label, train.features, test.label, test.features,\n",
    "    nrounds = 1000, early_stopping_rounds = 3,\n",
    "    max_depth = 6, \n",
    "    eta = 0.3, # learning rate\n",
    "    # In linear regression task, this simply corresponds to minimum number of instances needed to be in each node. \n",
    "    # The larger min_child_weight is, the more conservative the algorithm will be. range: [0,?]\n",
    "    #min_child_weight = 1 ,\n",
    "    # Minimum loss reduction required to make a further partition on a leaf node of the tree. \n",
    "    # The larger gamma is, the more conservative the algorithm will be. range: [0,?]\n",
    "    #gamma = 0,\n",
    "    verbose=0,\n",
    "    sample.n=0,\n",
    "    result.error=FALSE\n",
    ") \n",
    "{\n",
    "    if (is.null(dim(test.features))) {\n",
    "        # conver to matrix for the case of 1 day prediction\n",
    "        test.features <- t(test.features)\n",
    "    }\n",
    "    model <- xgboost(data = train.features,\n",
    "                     label = train.label,\n",
    "                     nrounds = nrounds,\n",
    "                     objective = \"reg:squarederror\",\n",
    "                     early_stopping_rounds = early_stopping_rounds,\n",
    "                     max_depth = max_depth,\n",
    "                     eta = eta,\n",
    "                     verbose=verbose)\n",
    "\n",
    "    pred <- predict(model, test.features)\n",
    "    \n",
    "    if (result.error) {\n",
    "        h = length(pred)\n",
    "        idx = 1:h\n",
    "        if ((sample.n>0) & (sample.n<h)) {\n",
    "            idx <- sort(sample(idx, sample.n))\n",
    "        }\n",
    "\n",
    "        # calc errors\n",
    "        rmse <- sqrt((pred[idx] - test.label[idx])^2)\n",
    "        mape <- abs(1 - pred[idx] / test.label[idx])\n",
    "        result <- list(rmse.mean=mean(rmse), rmse.sigma=sd(rmse), \n",
    "                       mape.mean=mean(mape), mape.sigma=sd(mape))\n",
    "        return(result)\n",
    "    } else {\n",
    "        res <- list(model=model, pred=pred)\n",
    "        return(res)\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "xgb.gridsearch <- function(label, features, test.h, hyper_grid, verbose=1) {\n",
    "    len <- length(label)\n",
    "    idx.train <- 1:(len-test.h)\n",
    "    idx.test <- (len-test.h+1):(len)\n",
    "    train.label <- label[idx.train]\n",
    "    train.features <- features[idx.train,]\n",
    "    test.label <- label[idx.test]\n",
    "    test.features <- features[idx.test,]\n",
    "    \n",
    "    xgb_test_rmse <- NULL\n",
    "    xgb_test_mape <- NULL\n",
    "\n",
    "    for (j in 1:nrow(hyper_grid)) {\n",
    "        #set.seed(123)\n",
    "        \n",
    "        errors <- xgb.forecast(train.label, train.features, test.label, test.features,\n",
    "                            nrounds = 1000, early_stopping_rounds = 3,\n",
    "                            max_depth = hyper_grid$max_depth[j], \n",
    "                            eta = hyper_grid$eta[j],\n",
    "                            verbose=0, result.error=TRUE)\n",
    "        # calc errors\n",
    "        xgb_test_rmse[j] <- errors$rmse.mean\n",
    "        xgb_test_mape[j] <- errors$mape.mean\n",
    "    }\n",
    "\n",
    "    #ideal hyperparamters\n",
    "    r <- hyper_grid[which.min(xgb_test_rmse), ]\n",
    "    if (verbose>0) {\n",
    "        print(r)\n",
    "    }\n",
    "    return(r)\n",
    "}\n",
    "\n",
    "\n",
    "xgb.tsCV <- function (label, features, max_depth = 6, eta = .25,\n",
    "                      h = 1, window = NULL, initial = 0, step = 1, \n",
    "                      count.freq=0.1, ...) \n",
    "{\n",
    "    y <- as.ts(label)\n",
    "    n <- length(y)\n",
    "    step <- round(step)\n",
    "    step_ind <- seq(step, n - 1L, by = step)\n",
    "\n",
    "    if (initial >= n) \n",
    "        stop(\"initial period too long\")\n",
    "\n",
    "    xreg <- ts(as.matrix(features))\n",
    "    if (NROW(xreg) != length(y)) \n",
    "        stop(\"features must be of the same size as label\")\n",
    "    tsp(xreg) <- tsp(y)\n",
    " \n",
    "    if (is.null(window)) {\n",
    "        indx <- seq(1 + initial, n - 1L)\n",
    "    } else {\n",
    "        indx <- seq(window + initial, n - 1L, by = 1L)\n",
    "    }\n",
    "    indx <- intersect(indx, step_ind)\n",
    "\n",
    "    e.cols <- c('forecast_start', 'forecast_end', \n",
    "                'rmse.mean', 'rmse.sigma', 'mape.mean', 'mape.sigma')\n",
    "    e <- ts(matrix(NA_real_, nrow = floor(n/step), ncol = length(e.cols)))\n",
    "    colnames(e) <- e.cols\n",
    "    \n",
    "    ###\n",
    "    hyper_grid <- expand.grid(max_depth = max_depth, eta = eta)\n",
    "    if (nrow(hyper_grid)>1) {\n",
    "        hyper_grid.flag <- TRUE\n",
    "    } else {\n",
    "        hyper_grid.flag <- FALSE\n",
    "    }\n",
    "    \n",
    "\n",
    "    indx.len <- length(indx)\n",
    "    by <- round(count.freq*indx.len)\n",
    "    by <- max(1, by)\n",
    "    print.when <- seq(0, indx.len, by=by)\n",
    "    \n",
    "    cnt <- 0\n",
    "    \n",
    "    for (i in indx) {\n",
    "        # get new start of subset of y & xreg\n",
    "        if (is.null(window)) {\n",
    "            start <- 1L\n",
    "        } else {\n",
    "            if (i - window >= 0L) {\n",
    "                start <- i - window + 1L\n",
    "            } else {\n",
    "                stop(\"small window\")\n",
    "            }\n",
    "        }\n",
    "        train.label <- subset(y, start=start, end = i)\n",
    "        train.features <- as.matrix(subset(xreg, start=start, end=i))\n",
    "        \n",
    "        # get test data\n",
    "        start <- i+1\n",
    "        end <- i+h\n",
    "        if (end <= nrow(xreg)) {\n",
    "            test.label <- subset(y, start=start, end=end)\n",
    "            test.features <- as.matrix(subset(xreg, start=start, end=end))\n",
    "        } else {\n",
    "            next\n",
    "        }\n",
    "        \n",
    "        # tune hyperparams\n",
    "        if (hyper_grid.flag) {\n",
    "            res <- xgb.gridsearch(train.label, train.features, h, hyper_grid)\n",
    "            max_depth.best <- res$max_depth\n",
    "            eta.best <- res$eta\n",
    "        } else {\n",
    "            max_depth.best <- max_depth\n",
    "            eta.best <- eta\n",
    "        }\n",
    "        \n",
    "        # train model\n",
    "        errors <- xgb.forecast(train.label, train.features, test.label, test.features,\n",
    "                                nrounds = 1000, early_stopping_rounds = 3,\n",
    "                                max_depth = max_depth.best,\n",
    "                                eta = eta.best, result.error=TRUE, ...)\n",
    "        # calc errors\n",
    "        e[i/step, ] <- c(start, end, errors$rmse.mean, errors$rmse.sigma, \n",
    "                                     errors$mape.mean, errors$mape.sigma)\n",
    "\n",
    "        cnt <- cnt + 1\n",
    "        if (cnt %in% print.when) {\n",
    "            message(sprintf(\"%0.0f %% done.\", 100*cnt/length(indx)))\n",
    "        }\n",
    "    }\n",
    "    #return(na.omit(e)) # times of NA kept in e as attr(na.action)\n",
    "    return(e)\n",
    "}\n",
    "\n",
    "\n",
    "xgb.tsCV.mean <- function(label, features, cols=c(1,2,3,5), ...) {\n",
    "    e <- xgb.tsCV(label, features, ...)\n",
    "    result <- e[,cols]\n",
    "    colnames(result) <- c('forecast_start', 'forecast_end', 'rmse', 'mape')\n",
    "    return(result)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9ef27a-3429-4873-81bd-39c5a8842043",
   "metadata": {},
   "source": [
    "### set label & features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "41c44a85-e47f-47bb-b011-36242e342e1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             logret_fwd     logret      rsi    bbands        macd\n",
       "1991-02-19 -0.003987479 0.10602550 72.59254 0.8419486 -0.03641515\n",
       "1991-02-20  0.003935860 0.09798126 66.25313 0.7706927 -0.18551057\n",
       "1991-02-21  0.006853764 0.10585688 66.00481 0.7330987 -0.30953562\n",
       "1991-02-22  0.011366830 0.10194779 66.54491 0.7402938 -0.39546732\n",
       "1991-02-25  0.024316594 0.09259647 67.84742 0.7305630 -0.43573971\n",
       "1991-02-26  0.033979664 0.07655978 60.80133 0.6379610 -0.55105032"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "            logret_fwd       logret      rsi    bbands       macd\n",
       "1991-03-20 0.043297723 -0.003987479 52.32729 0.2955472 -0.5878001\n",
       "1991-03-21 0.038451421  0.003935860 50.29479 0.3135024 -0.6182388\n",
       "1991-03-22 0.038123240  0.006853764 51.65309 0.2490278 -0.6049896\n",
       "1991-03-25 0.034364782  0.011366830 55.10298 0.4057512 -0.5386086\n",
       "1991-03-26 0.007808953  0.024316594 62.94322 0.6945332 -0.3702197\n",
       "1991-03-27 0.009730005  0.033979664 61.25189 0.8281562 -0.2741769"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.ml <- merge(lag.xts(trainx$y, -lookahead), trainx, join='left', fill=NA)\n",
    "colnames(train.ml) <- c('logret_fwd', 'logret', 'rsi','bbands','macd')\n",
    "train.ml <- na.omit(train.ml)\n",
    "\n",
    "x <- head(train.ml, lookahead+6)\n",
    "head(x)\n",
    "tail(x)\n",
    "#tail(train.ml)\n",
    "\n",
    "idx.label <- 1\n",
    "idx.feautres <- 2:5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5a72f7-a53b-4172-9753-65db6e1810b9",
   "metadata": {},
   "source": [
    "## Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "df96df9e-dc59-4ec1-89d5-b364e10ca18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"10 % done.\"\n",
      "[1] \"20 % done.\"\n",
      "[1] \"30 % done.\"\n",
      "[1] \"40 % done.\"\n",
      "[1] \"50 % done.\"\n",
      "[1] \"61 % done.\"\n",
      "[1] \"71 % done.\"\n",
      "[1] \"81 % done.\"\n",
      "[1] \"91 % done.\"\n"
     ]
    }
   ],
   "source": [
    "result.m05.1 <- xgb.tsCV.mean(train.ml[,idx.label], train.ml[,idx.feautres], \n",
    "                              h=1, window=wind, step=peri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bc486be0-bde8-476d-9bdb-aaddc7d822d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-02-09\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m05.1\n",
    "from <- x[!is.na(x[,'forecast_start']),][,1][1]\n",
    "from <- index(trainx[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf56a93b-2659-491f-aeb0-639ca5afcc61",
   "metadata": {},
   "source": [
    "## Tuning params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3a5f7df4-0ca0-4beb-9270-5d8804fe7460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "25"
      ],
      "text/latex": [
       "25"
      ],
      "text/markdown": [
       "25"
      ],
      "text/plain": [
       "[1] 25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#max_depth <- seq(4, 8, 1)\n",
    "#eta <- c(0.01, 0.05, 0.1, 0.2, 0.3)\n",
    "\n",
    "max_depth <- seq(4, 8, 1)\n",
    "eta <- c(0.01, 0.05, 0.1, 0.2, 0.3)\n",
    "\n",
    "x <- expand.grid(max_depth = max_depth, eta = eta)\n",
    "nrow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "abe039a1-18cb-4a44-9909-88f34afdb9c4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   max_depth eta\n",
      "21         4 0.3\n",
      "   max_depth eta\n",
      "11         4 0.1\n",
      "   max_depth eta\n",
      "15         8 0.1\n",
      "   max_depth eta\n",
      "21         4 0.3\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "   max_depth eta\n",
      "18         6 0.2\n",
      "   max_depth eta\n",
      "18         6 0.2\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "23         6 0.3\n",
      "  max_depth  eta\n",
      "9         7 0.05\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "   max_depth eta\n",
      "21         4 0.3\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "   max_depth eta\n",
      "23         6 0.3\n",
      "  max_depth  eta\n",
      "8         6 0.05\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "22         5 0.3\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "   max_depth  eta\n",
      "10         8 0.05\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "   max_depth eta\n",
      "11         4 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   max_depth eta\n",
      "14         7 0.1\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "   max_depth eta\n",
      "21         4 0.3\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "25         8 0.3\n",
      "   max_depth  eta\n",
      "10         8 0.05\n",
      "   max_depth eta\n",
      "25         8 0.3\n",
      "   max_depth eta\n",
      "16         4 0.2\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "   max_depth eta\n",
      "22         5 0.3\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "9         7 0.05\n",
      "  max_depth  eta\n",
      "8         6 0.05\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "19         7 0.2\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "6         4 0.05\n",
      "   max_depth eta\n",
      "15         8 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "13         6 0.1\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "   max_depth eta\n",
      "25         8 0.3\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "   max_depth eta\n",
      "24         7 0.3\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "   max_depth eta\n",
      "13         6 0.1\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "16         4 0.2\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "   max_depth  eta\n",
      "10         8 0.05\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "   max_depth eta\n",
      "25         8 0.3\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "4         7 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  max_depth  eta\n",
      "6         4 0.05\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "9         7 0.05\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "20         8 0.2\n",
      "   max_depth eta\n",
      "23         6 0.3\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "6         4 0.05\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "25         8 0.3\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "   max_depth eta\n",
      "22         5 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "   max_depth eta\n",
      "16         4 0.2\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "   max_depth eta\n",
      "21         4 0.3\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "   max_depth eta\n",
      "25         8 0.3\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "12         5 0.1\n",
      "   max_depth eta\n",
      "21         4 0.3\n",
      "   max_depth  eta\n",
      "10         8 0.05\n",
      "   max_depth eta\n",
      "20         8 0.2\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "   max_depth eta\n",
      "20         8 0.2\n",
      "   max_depth eta\n",
      "15         8 0.1\n",
      "   max_depth eta\n",
      "23         6 0.3\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "24         7 0.3\n",
      "   max_depth eta\n",
      "23         6 0.3\n",
      "   max_depth eta\n",
      "19         7 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   max_depth eta\n",
      "13         6 0.1\n",
      "   max_depth eta\n",
      "21         4 0.3\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "   max_depth eta\n",
      "23         6 0.3\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "20         8 0.2\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "13         6 0.1\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "24         7 0.3\n",
      "   max_depth eta\n",
      "14         7 0.1\n",
      "   max_depth eta\n",
      "15         8 0.1\n",
      "  max_depth  eta\n",
      "8         6 0.05\n",
      "   max_depth eta\n",
      "16         4 0.2\n",
      "  max_depth  eta\n",
      "6         4 0.05\n",
      "   max_depth eta\n",
      "22         5 0.3\n",
      "   max_depth eta\n",
      "25         8 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "  max_depth  eta\n",
      "9         7 0.05\n",
      "   max_depth eta\n",
      "11         4 0.1\n",
      "  max_depth  eta\n",
      "9         7 0.05\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "16         4 0.2\n",
      "  max_depth  eta\n",
      "6         4 0.05\n",
      "   max_depth eta\n",
      "25         8 0.3\n",
      "   max_depth eta\n",
      "12         5 0.1\n",
      "  max_depth  eta\n",
      "7         5 0.05\n",
      "   max_depth eta\n",
      "17         5 0.2\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "   max_depth eta\n",
      "14         7 0.1\n",
      "   max_depth  eta\n",
      "10         8 0.05\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "20         8 0.2\n",
      "   max_depth eta\n",
      "25         8 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  max_depth  eta\n",
      "9         7 0.05\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "   max_depth eta\n",
      "14         7 0.1\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "   max_depth eta\n",
      "19         7 0.2\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "   max_depth eta\n",
      "20         8 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "19         7 0.2\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "   max_depth eta\n",
      "18         6 0.2\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "23         6 0.3\n",
      "   max_depth eta\n",
      "25         8 0.3\n",
      "   max_depth eta\n",
      "24         7 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   max_depth eta\n",
      "17         5 0.2\n",
      "  max_depth  eta\n",
      "8         6 0.05\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "23         6 0.3\n",
      "   max_depth eta\n",
      "23         6 0.3\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "15         8 0.1\n",
      "   max_depth eta\n",
      "14         7 0.1\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "22         5 0.3\n",
      "   max_depth eta\n",
      "21         4 0.3\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "17         5 0.2\n",
      "   max_depth eta\n",
      "23         6 0.3\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "   max_depth eta\n",
      "18         6 0.2\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "   max_depth eta\n",
      "12         5 0.1\n"
     ]
    }
   ],
   "source": [
    "result.m05.2 <- xgb.tsCV.mean(train.ml[,idx.label], train.ml[,idx.feautres], \n",
    "                              h=hori, window=wind, step=peri,\n",
    "                              max_depth = max_depth, eta = eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dc8e1c-2053-444f-84cb-5bd9132cecf3",
   "metadata": {},
   "source": [
    "## Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "82ffd869-5005-4fdb-8977-7712eac50d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my.figsize(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "12fa005b-99d2-4390-8adc-0eaf9f019ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94\nAAAgAElEQVR4nOzdZ3hU1dqH8WcmM+khhTRCAoTeewkgIB0pAVG6ghQVXlBRulIE5CjCEVAQ\nRHoRUESUqggiREC6SIkQakICIYQE0qe9H+Y4JiHEATJMyL5/H841s/baa56NOQP/rLXXVplM\nJgEAAAAAKI/a3gUAAAAAAOyDQAgAAAAACkUgBAAAAACFIhACAAAAgEIRCAEAAABAoQiEAAAA\nAKBQBEIAAAAAUCgCIQAAAAAolMbeBdjWvXv39Hq9vasAbMvDw0NE7t27Z+9CAKDAaDQaNze3\nzMzMjIwMe9cC2Ja3t7e9S4CiFfFAaDQaDQaDvasAbEulUqlUKn7UARQlarVarVaLCF9uAGBT\nLBkFAAAAAIUq4jOEjo6Ojo6O9q4CsC3zL9Hd3NzsXQgAFBjzN5tWq+XLDQBsqogHQpPJZDQa\n7V0FYFsmk4klowCKJG79AABbK+KBUKfT6XQ6e1cB2JaLi4uIsO8CgKJEq9W6uLgYDAa+3FDk\nubu727sEKBr3EAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAA\nFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAA\nACgUgRAAAAAAFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAA\nAABQKI29CwAAAMjh5s2bW7dujYuL8/b2btGiRfXq1e1dEQAUWSqTyWTvGmwoOTlZp9PZuwrA\ntry9vVUqVWJior0LAYACcO7cufHjx2dmZlpahgwZ8uKLL9qxJMCmfH197V0CFI0lowAAoLAw\nGo0ff/xx9jQoIitXroyJibFXSQBQtBEIAQBAYREXFxcXF5erUafTHT9+3C71AECRRyAEAACF\nxYNu9DAYDE+4EgBQCAIhAAAoLEqWLOnh4XF/e+XKlZ98MQCgBARCAABQWGi12uHDh+dqbN++\nfZUqVexSDwAUeTx2AgAAFCLPPvush4fHxo0br1275uvr26pVq86dO9u7KAAosnjsBPDU47ET\nAIoerVbr6emZnp6emppq71oA2+KxE7AvlowCAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIAAAAA\nUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAACkUgBAAAAACFIhACAAAAgEIRCAEAAABAoQiEAAAA\nAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAACkUgBAAAAACFIhACAAAAgEIRCAEA\nAABAoQiEwFPv+eef79Chg72rAAAAwNOHQAgAAAAACkUgBAAAAACFIhACAAAAgEIRCAEAAABA\noQiEAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAACkUgBAAAAACFIhACAAAA\ngEIRCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAACkUgBAAA\nAACFIhACAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAAABRKY+8C\nAAAAcsvKyrp+/bpWq1Wr+eU1ANgQX7IAAKDQOXv2bNeuXdetW2fvQgCgiCMQAgAAAIBCEQgB\nAAAAQKEIhAAAAACgUARCAAAAAFAoAiEAAAAAKBSBEAAAAAAUikAIAAAAAApFIAQAAAAAhSIQ\nAgAAAIBCEQgBAAAAQKEIhAAAAACgUARCAAAAAFAoAiEAAAAAKBSBEAAAAAAUikAIAAAAAApF\nIAQAAAAAhSIQAgAAAIBCEQgBAAAAQKEIhAAAAACgUARCAAAAAFAoAiEAAAAAKBSBEAAAAAAU\nikAIAAAAAApFIAQAAAAAhSIQAgAAAIBCEQgBAAAAQKE0Nh09JSVl8eLFR44c0ev11atXHzZs\nmL+///3drl+/PmfOnKioqM2bN//ruVaOCQAAAADIn21nCOfOnXvt2rXp06fPmTPHwcFh2rRp\nRqMxV5/9+/e/++67wcHBVp5rzZgAAAAAgH9lw0CYkJBw+PDhN998s3z58sHBwSNHjrx+/fof\nf/yRq5tOp5s9e3ZYWJg151o5JgAAAADgX9kwEF64cMHR0TE0NNT81t3dPSQk5MKFC7m6tWrV\nys/Pz8pzrRwTAAAAAPCvbHgP4d27dz08PFQqlaXF09MzOTn5cc719PTMf8yIiIjJkydb3s6a\nNatu3bqPdRnAU6J48eL2LgEACoyrq6uIaDQavtwAwKZsu6lM9uQmIiaT6fHPzX9MZ2fnkiVL\nWt5qtVqDwWD9hwJPL37UARQl5r/fTSYTX24o8jQa2/6DHMifDX/+vLy87t69azKZLBEuOTnZ\n29v7cc791zHr16+/evVqy9vk5OSkpKSCuR6gcONHHUBRkp6eLiIGg4EvNxR5vr6+9i4BimbD\newgrVqyo0+mioqLMb5OTk6OjoytXrvw45z7OmAAAAACA7GwYCL29vZs2bfrZZ59FRUVFR0d/\n8skn5cuXr1atmojs2rVry5Yt5m537txJSEi4d++eiCQkJCQkJGRkZDzo3HzGBAAAAAA8FNsu\nWR4xYsSXX345ceJEo9FYp06dkSNHmpd6njx58u7du126dBGRMWPGxMfHm/sPGjRIRIYMGRIe\nHv6gcx/UDgAAAAB4KKqH2ujlqZOcnKzT6exdBWBbgwYNysjI+Oqrr+xdCAAUmDNnzowaNerl\nl1/u16+fvWsBbIt7CGFfNlwyCgAAAAAozAiEAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAA\nABSKQAgAAAAACkUgBAAAAACFIhACAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAA\nAAAoFIEQAAAAABSKQAgAAAAACkUgBAAAAACFIhACAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIA\nAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAACkUgBAAAAACFIhACAAAAgEIRCAEAAABAoQiE\nAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAACkUgBAAAAACFIhACAAAAgEIR\nCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAACkUgBAAAAACF\nIhACAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAA\nCkUgBAAAAACFIhACAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAAAAAolMbeBeBJ\n0+l027dvz8zMtHchKDApKSl6vf7rr7+2dyEoMFqt9rnnnnN2drZ3IQAAoIgjECrO77//vnDh\nQntXgYK3bNkye5eAguTh4dGmTRt7VwEAAIo4AqHi6HQ6EekU5B9W3NvetQDIw7HEpM3Xb+r1\nensXAgAAij4CoUJVcHdr5V/c3lUAyEOqXi/Xb9q7CgAAoAhsKgMAAAAACkUgBAAAAACFIhAC\nAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAACkUg\nBAAAAACFIhACAAAAgEIRCAEAAABAoTT2LgAAgALw5Zdffvvtt/auAgVs9erVq1evtncVKDBl\nypRZtGiRvasAkAOBEABQFFy6dElE0koGi0pl71oA5MH5VvyVK1eMRqNazQo1oBAhEAIAio6/\n/u9No5OTvasAkIdKn811v3rZ3lUAyI1ACNjN6Vu3J+87cCAmLtNgqO5XfGxY/S4Vyj5a571X\nY2YeOnoqPkFvNFTw8R5et1bvapVUIkmZmYHzFuc54NfPdwrP+XEX7yTXX/6Vi1YT+8arBXWN\nAAAAKMwIhIB9RN1Jav3VRj9X16nNGxdzdFxz5lzP77ZtuC+kWdN5W9TlHt9tq+XvO7FpQweV\nasO58wO3/XQ5+e67TRq4ajQLO7TKNdruK9Gb/ooK9SqWvdEkMuzH3el6vYuWrwUAAACl4F9+\ngH3M+O2w3mj6uU/3QHc3EelZtWLjlevH/RLRpULZ++9/yr/z5H0HS3sW29PvRReNRkQG1qpW\nb9lX844cn9CkgaODw8Ca1bIPlZyZNS3i99fq1Kjh55u9fdkfpw/H3mhVOuRk/C1bXjcAAAAK\nEW7qBezAYDJtjbr8XLky5oAnIg4q1cvVq1xOSj51Xx7Lv7PRZBpYq9qsVs3MaVBEtGp1o6DA\n5MysNJ3u/o9+f/9BndH4frOw7I1xKanv7v1tbFiDUp4eBXypAAAAKMQIhIAdXEm6ey8rq4Z/\njjm62gF+IvJnfMJDdVarVCPq1epcPtRyyCRyNuF2sIe7m1aba6hztxO/PHn6/WfCvHLuuvHm\nrr3BHh5jwuo99pUBAADgacKSUcAObqSmikiAq2v2Rj9XFxGJS0l7tM6ZBkN8alpsSuqi46f+\nvHV7ZZf293/u1P2HyngWG1grxyLSjZEXtkVd/vWlHlr2AQcAAFAYAiFgBxl6g4g4OuQIYE4O\nDiKSadA/WuffYmI7btgsIqWKeazv1rFjuTK5xjl3O/H78xfnt2/pkO0pbYkZGW///OvwerUa\nlAh43KsCAADA04YJAcAOnDXmOGfI3phhMIiIsyb3r2ms7FzL3/fb7p2/eK51WMkSL27aOnnf\nwVzjfHHiT3dHx15VKmVvHLN7v6tWm+uWQgAAACgEM4SAHZRwdxORG6k5VofeSEkVkZLu7o/W\nubiLS6fyoSIyoEbVkGLuHx86Gl6hbP2/5/30RuM35y60L1va3fGfGwt/vnLtqzOR33TvbDJJ\nSpZORPRGk4ikZOk0arU5iAIAAKAIIxACdlDGs5i3s9OJG/HZG4/E3RSROoF+D9X5Vlr65vMX\nawf4ZV/z2aRk0H/l+Olbty2B8HDsjdvp6e3Lls4+yNaoyyaRFzdtzfWJvnMXPVeuzHcvdHms\niwSgTJcuypIv5M9TotNJaDl56WVp2uwRO584JmtWycUo0RskJES6vyht2olKJSkp0qVD3gNO\n/1Ceyflx12Nk8ABxcpbvtxXE5QFAUUMgBOxArVJ1q1j+qzORV5PvlvYsJiIZesOKU2dr+PlW\nLu7zUJ2TM7Pe+fnXRiVL/NT7efXfNwf+cjVaRLI/Q+Lg9RsiUjPnVqVv1a/ds3KF7C2zfz/2\nW0zsdy908XZxLvjLBlDkxcTIm8PF20uGvC6urvLTTpn0rkz7T+6QZk3nA7/JxAlSvrwMGCRq\ntez5Wf4zXeLipP8r4uwko8flHu3oEfl1rwQF5Wg0mWT2TMnMFCe+0wAgbwRCwD7ea9rwhwuX\n2q3/bkS9Wm5a7fJTZ67dvbetZ1fz0a1Rl3t9t+3jVs2G16uVf2dPJ8exYfVnHDjcZt2m7pXK\nOzk4RERf//rc+UZBgc+WCrZ83F+JiSJS1sszew2hXp6hOVv8T59zUKubBOf8FxUAWGnlMjHo\nZe4CKV5cRKR1W3ltkHz+mTR9RrJtZ2VV5yVfSGCgfLZQzI/J6dRFBvWXr9fLywNEo5VOOZcw\npKbI8qXStZuULZejfdsWOXtG6tWXCxdsdckA8JRjUxnAPoI93H/p90INv+LTI34fvWef1sFh\nW8+uLf6OcEaTyWAyGU0mazpPeqbR8k7tDEbjf347PGFvxOlbtyc3C9vWs5s62z+/bqdnqFUq\nd0fHJ3yZABTEaJQDERLW5H8BT0TUaunQUeJi5WLUw3U2GaVTFxnxplgemqrRSLXqkpoimZl5\nfPTSL8Wgl8Gv5Wi8nSCLPpd+/SUgsMCuEQCKHGYIAbup6OO9sXvnPA+FVyibMfYNKzuLSJ9q\nlfpUq/SgoyLy7YPPzW5Rh9aLOrS2picA5BYXK2lpUr58jsYKFUVELkZJ+QoP1/mFHjkOmUxy\n+ZL4+4vzfYs/r16RHzbLW+9Irk255vxX/P2l70syZ/YjXxMAFHkEQgAAUBBu3xYR8c55I7SX\n1z+HHqGzTid3EuXWLdm8SS5elElT8vjcpV9KiRK5F5Hu3SMHfpPPF8l9z/IBAGTHtyQAACgI\nWVkiIhptjkbzSnXzoUfofOoPGT1SRCQgUKbNkMZNco9z9YpE7JN3xog6210w9+7KvDnywotS\nueqjXQoAKAeBEAAAFARznNPlzH7mdGe5FfBhO5evIDNmSnKSHD0i742Xvv1kyOs5Ttm8SVxc\npHXbHI3zPxVn59y3FAIA8kIgBAAABcHXV0QkMTFHo3n9p6/vI3b29JQmTUVEnusk/gGydrU8\n01wqV/nfUYNBftktDcPExeWfU44ell0/ygcfiskk6en/6yYi6eni4CDsrQUAOREIAQBAQShR\nQjw85HxkjsZzZ0VEKt6361X+nZPuyL5fpWLFHGs+a9SU9Wvl0sV/AuHZM5KcLI3CcgzyW4SY\nTPLe+Nyf2LGthDWRDz9+lEsDgKKLQAgAAAqCSi3Nn5WfdsqNOAksISKSlSXbt0rZclK6zMN1\nTk2Rz+ZK1eoy91NR/X1z4PGjIpLjGRJn/hSR3PuX9uwtrdrkaFm3Rk6dkg8/lmLFCupaAaDI\nIBACAIAC0n+gROyTt9+UF3qIs7Ns2yo3b8isOf87eiBCJr0rw9+Q7j3+pbObu/R9WVYtl7dG\nSIuWotXKqZOyZ7dUqy516/7zcdeuiYgElcxRQ4kgKRGUo2Wnjzg4SI2aNrtsAHiKEQgBAEAB\n8feXzxbKos9l+VIxGKRiRZk1R+r8HeGMJjEaxWiyqvPAwRIcLN9/JyuXi14ngSVk4BB5sec/\nE4YikpwkKnWOGwgBAA+JQAgAAApOSCmZ8VHeh55pJr9EWNtZRNq2l7bt8/usGTOtKmnMeBlz\n3y2FAAAREVH/excAAAAAQFFEIAQAAAAAhSIQAgAAAIBCEQgBAAAAQKEIhAAAAACgUOwyqlDf\nxsRF3Eq0dxUA8pCQlWXvEgAAgFIU8UDo6Ojo6Oho7yoKFycnJxGJTsuITsuwdy0AHsjJycnN\nzc3eVTxNHBwc7F0CgH/n5uamVrNCDShEinggNJlMRqPR3lUULvyBAE8Fo9FoMBjsXcXTxGQy\niYhTYqLRid8DAoWRWq8XEYPBYP5/K4BCoogHQp1Op9Pp7F1F4WL+AwlwdvJ21Nq7FgB5SMrS\n3cjI1Ol0GRlM4z8E82+7qv73wU85B1AIZGRkMEOYi7u7u71LgKIV8UCIB+lTKqhHSAl7VwEg\nD1tib3507qK9qwAAAIrAb2gAAAAAQKGYIQQAFB2x7TuaNPzVBhRGfgciHO+wwzlQ6PC3JgCg\n6LjZ/Fmjk5O9qwCQB8/TfxIIgUKIJaMAAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAAFIpA\nCAAAAAAKRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAaexcAAACQ04XzsnyJ/BUp\nGRkSVFK6dJXO4aL++7fYJ47JmlVyMUr0BgkJke4vSpt2olJJSop06ZD3gNM/lGeaPbHyAeAp\nQiAEAACFyZnT8vYb4usnvfqKq6v8ulfmzJbY6zJ0uIjIgd9k4gQpX14GDBK1Wvb8LP+ZLnFx\n0v8VcXaS0eNyj3b0iPy6V4KCnvx1AMBTgUAIAAAKkyVfiJOTLFgk3j4iIp06y+tDZPN38upQ\ncXCQJV9IYKB8tlCcnEREOnWRQf3l6/Xy8gDRaKVTlxxDpabI8qXStZuULWeHCwGApwGBEAAA\nFKi33xCdXkaPlfnz5MxpcXKSOnXljbfFx0dMJrl7N++zHBzE3V1EpG176Rz+vzQoIiq1VK0m\nF87LvXviWUw6dZESJf6XBkVEo5Fq1WXndsnMFGfn3GMu/VIMehn8mi2uEgCKBgIhAAAoUBqt\nxF6Xmf+RAQNl3Lty7qxMnypZWTJjpty5Iy+E531WSClZ9ZWISMfOuQ9djxFPT/EsJiq1vNAj\nxyGTSS5fEn//PNLg1Svyw2Z5653/5UwAQF4IhAAAoECpVBIfL+MnSp26IiJ+/tJwhxw7KiaT\nFPOQ2XPzPuv+RGe29xc5ekReGyaqbFuj63RyJ1Fu3ZLNm+TiRZk0JY8Tl34pJUrkXkQKAMiJ\nQAgAAAqaViu16/zz1tdPMjMlK1OcnKVe/YcY59AB+WiGNG4ivfvkaD/1h4weKSISECjTZkjj\nJrlPvHpFIvbJO2P+2ZsUAJAXAiEAAChonl6iUv3z1pzKjKaHG2TzJvlsrjRvIe9NzjE9KCLl\nK8iMmZKcJEePyHvjpW8/GfJ67nNdXKR120crHwCUg0AIAACeFGs2lTFb8Kls/Fr6viRDXs+R\nLc08PaVJUxGR5zqJf4CsXS3PNJfKVf531GCQX3ZLwzBxcSnwKwCAIoZACAAAnhRrNpURkSWL\n5duNMmqsdM7ZOemO7PtVKlaUylX/aaxRU9avlUsX/wmEZ89IcrI0Civw8gGg6CEQAgCAJ8Wa\nTWWOHpG1q+SNkbnToIhotfLZXKlaXeZ++s8i0uNHRUQCAv/pduZPEZHyFQqubgAosgiEAADg\nSdFo/2VTGYNB5n0inp7i5CTbtuQ4VL+BBARK35dl1XJ5a4S0aClarZw6KXt2S7XqUrfuPz2v\nXRMRCSppgwsAgKKGQAgAAAqNlBSJiRYRmT0z96HpH0pAoAwcLMHB8v13snK56HUSWEIGDpEX\ne+bYdSY5SVRqbiAEAGsQCAEAQIH6+L+5W956R956x6pzPT3ll4h/6dO2vbRtn1+HGfeFSQDA\nAxAIgafbiZu3pkccOnYjPk2nL+vlOaR29UG1qjn8vSPf3qsxMw8dPRWfoDcaKvh4D69bq3e1\nSpbd+jZGXlhw7I+/bt/JMhrKeBZ7qXqVYXVrOjk42OtaAAAA8IQRCIGn2O+xN9qt2xTk4f52\nw7oejtrv/rr4xk+/XEpK/vDZpiKyLepyj++21fL3ndi0oYNKteHc+YHbfrqcfPfdJg1EZN6R\nE+N+iehTtdJ7TRs6qh1+uRo94ZeI36/HrevW0d6XBQAAgCeEQAg8xSbtO+Ci0fza70V/N1cR\nGVizWtNVG744cWp688YatXryvoOlPYvt6feii0YjIgNrVau37Kt5R45PaNJAJbL0jzOhXp7L\nOrczTxg2L1XyTMLt785fvJOR6e3sZNfLAgAAwBNCIATsqd36TVkG4+ftW43eve/32BvOGs2z\npUp+0qZFgJurSSQxPT3PsxzUai8nJxHpW7XyoJoacxoUEbVK1TAo8MTNW0kZmT4uzgNrVSvj\nWcycBkVEq1Y3Cgpcffpcmk7nptU6axwcDDke9uzmqHVQqVgyCgAAoBwEQsCeHNUOl+4kv7bj\n5/eaNPzS3/dw3M0BW37MMBi+7d45PjWt9IKleZ5V0cf71JCXROSVmlVzHYq6k1TcxcXHxVmt\nUo2oVyv7IZPI2YTbwR7ublqtiIxsUGfQtl0fHjwyuGY1J43ml6vRm/+6OLRuTVctXwsAAABK\nwb/8AHtSqSTmXsrSTm1blAoWkec93NeEltpzJdok4u3stL1XtzzPMie6+337V9TuK9EftGii\nzjbzl2kwxKemxaakLjp+6s9bt1d2+d/WfH2rVXZ0cBi6c/fU/YdERK1SjQurP7lZWAFfIQAA\nAAoxAiFgZ04ODs1LBVveBrm7pev16Tq9q1bTqnSI9ePsuHjl1e27OpYr807Dutnbf4uJ7bhh\ns4iUKuaxvlvHjuXKmNsjoq8P27mneUjJwbWqu2g1Oy9e+fjQUUeNw4TGDQrgqgAAAPA0IBAC\ndlbcxSX7jXwOarWIGE2mhxpk0fFTo3bv61ax3PLO7dQ5bgyUWv6+33bvnJCevvtK9Iubto5u\nVG9a88ZGk+nVHbvLe3tu7N7Z3L9V6RC90TQ94vcelSuU9/Z6/OsCAABA4UcgBAopazaVMRuz\nZ/9nR0+OCas3rXkT1X2di7u4dCofKiIDalQNKeb+8aGj4RXKFndxvpyUPDasfvb02KpMyOfH\n//g99gaBEAAAQCEIhEAhZc2mMiIyZd/BBcf+WNC+5eBa1bP3uZWWvvn8xdoBfg1KBFgam5QM\n+q8cP33rdqOSgSKSZTBkPyXTYLi/EQAAAEUYgRAopKzZVGb3leiZh45+0qZ5rjQoIo4ODu/8\n/GujkiV+6v28ZRrwl6vRIlLK06O8t5enk+Ouy9f+86zJcnTPlWgRqRcYIAAAAFAGAiFQSDk6\nOOS/qYzeaBz5897iLi4uGs3yU2eyH2pdplSpYh5jw+rPOHC4zbpN3SuVd3JwiIi+/vW5842C\nAp8tFaxWqSY/EzZq976uG38YWLOaq1bz8+VrK06d6VG5Qk1/XxtfGWBDoevXmNRqe1cBIA/O\nt+LtXQKAPBAIgadVcmbmhcQkERm2c0+uQ18/36lUMY9JzzQq7+216MSp//x2OMtoKF2s2ORm\nYW/Uq22eEhxer1aAm+tnR08O2b5LbzSFehWb3Cws1w6lwFMkMDBQRLz+PGXvQgA8UEBAgJpf\n2QCFjMr0kJsZPl2Sk5N1Op29qyhcfvnll5kzZ46sGNojpIS9awGQhy2xNz86d3HkyJEdOnSw\ndy1PE6PRmJqaau8qUGAiIyMnTZrUs2fPHj162LsWFBhnZ2ftAx6lq2S+vqzNgT0xQwgAKArU\narWHh4e9q0CBcXV1FREnJyf+swKATTFrDwAAAAAKRSAEAAAAAIWyasloSkrKjh07fvzxxxMn\nTty6dSspKcnLy8vPz6927dodOnR47rnn3N3dbV0oAAAAAKBg/csMYUZGxqxZs0JDQ3v27Ll6\n9WqdTlehQoW2bdtWqFBBp9OtWbOmZ8+eoaGhs2fPzsjIeDIVAwAAAAAKRH4zhJcvX+7evfup\nU6d69OgxYMCAFi1amO/wtkhNTf31119Xrlw5bty4r7766ttvvw0NDbVxwQAAAACAgpFfIKxX\nr17t2rVPnz5dpUqVPDu4ubl17NixY8eO586dGz58eL169RITE21TJwAAAACggILEL+kAACAA\nSURBVOW3ZHT48OG7du16UBrMrkqVKrt27fq///u/gisMAAAAAGBb+c0QTp8+Pfvb9PT0Y8eO\nXb9+vXXr1r6+vnq9XqP553QHB4cPPvjAVmUCAAAAAAqatY+dmDVrVmBgYLNmzXr37h0VFSUi\nU6ZMGTRokMFgsGV5AAAAAABbsSoQLlmyZOzYsc8+++yiRYssjZUqVVq9evWsWbNsVhsAAAAA\nwIasCoTz588fOnTo999/P2DAAEtj//79x4wZs3r1apvVBgAAAACwIasCYWRk5AsvvHB/e4sW\nLS5fvlzQJQEAAAAAngSrAqFWq01PT7+//ebNm1qttqBLAgAAAAA8CVYFwoYNG86dOzczMzN7\nY1JS0qxZs8LCwmxTGAAAAADAtvJ77ITFlClTWrduXbVq1fbt24vI4sWLFy1atHnz5rS0tOzb\nzAAAAAAAniJWzRA2b978xx9/9PLyWrhwoYgsX7585cqVlSpV2rVrV9OmTW1cIQAAAADAJqya\nIRSRVq1aHTt2LCEhITo6WqVSlS5d2tvb26aVAQAAAABsytpAaObr6+vr62ujUgAAAAAAT1J+\ngbBy5crWDBEZGVlAxQAAAAAAnpz8AiGTgQAAAABQhOUXCCMiIvI/OTU1NTY2tkDrAQAAAAA8\nIVbtMvoghw4devbZZwuoEgAAAADAE2XtpjLbtm1bt27dtWvXjEajucVgMJw5c8bJyclmtQEA\nAAAAbMiqQLh+/fo+ffpoNJrAwMCYmJigoKDk5OTU1NSWLVuOGjXK1iUCAAAAAGzBqiWjs2fP\n7tixY2JiYnR0tJOT0+7du5OSkhYuXKjRaFq0aGHrEgEAAAAAtmDVDOH58+enTp3q4eHxz2ka\nzdChQy9evDhu3LgFCxbYrDzYSnR6xtE7yfauAkAerqSm27sEAACgFFYFQrVarVKpzK8dHR3v\n3btnfh0eHt6zZ08C4dPFwcFBRL6Njvs2Os7etQB4IPP/VQEAAGzKqkBYuXLl5cuXt23bVqvV\nBgUF7d27t0GDBiJy+/ZtSzjE06J+/fovvfRSVlaWvQtBgdm+fbterw8PD7d3ISgwGo0mLCzM\n3lUAAICiz6pA+NZbb/Xt2/fevXs7d+5s3779pEmTYmJiihcv/sUXX9SqVcvWJaJgubq6vvTS\nS/auAgUpIiIiIyNj0KBB9i4EAAAUFu+///7UqVP9/PyuX7+u1WpzHX311VeXLFnStGnTf33w\neJ569+69devWlJSUf+35zDPPJCQkREZGPsKn4MmwKhD26dNHrVZfu3ZNRN5///1z5859+umn\nIhISEjJv3jzbFggAAADg4anV6sTExB07duRaRpSRkfHNN984OjraqzAUKtY+h7BXr17mF97e\n3j/99FNsbOzdu3fLlSt3/+8bAAAAANidWq1u1KjRihUrcgXCH374ITU1tX79+vYqDIWKVY+d\nEJG4uLjPPvvM8lar1X799dcJCQm2qQoAAADAY9Hr9d26ddu2bdvt27ezt69ataply5a5Zgh3\n7NjRvHlzDw8PFxeX6tWrf/LJJyaTyXzIZDJNmzYtJCTE2dm5Ro0aGzdutOw3afbbb7+1bdu2\nWLFiLi4uderUWbZsWZ71xMXFvfrqq6VLl3Z2dg4MDHzhhRdYSloYWBUI//rrr7p1644ePdrS\nkpaWNmXKlHr16kVFRdmsNgAAAACP7vnnn9fr9evWrbO0xMfH//jjj717986+xeDmzZs7deok\nIitWrPj++++bNGkyatSoMWPGmI/OmjVrypQpzZo127Jly3vvvTdlypQTJ05Yzt27d2/Lli11\nOt2aNWt++OGHsLCwwYMHz549+/5iunfvvnXr1smTJ2/fvn327Nnnz59v0aJFWlqarS4e1rFq\nyej48ePd3d1/+OEHS0vp0qXPnj0bHh4+fvz4jRs32qw8AAAAAI+oZMmSrVq1WrFixYgRI8wt\n69at02q1PXr0WLx4saXbhAkTgoODd+3a5eTkJCLt2rVLSEj49NNPJ0yY4OPjM2/evGrVqq1d\nu9Y8Mdi8efMyZcpYJhhHjx4dHBz8448/ms9t27ZtbGzsBx98MHz4cBcXF8tH3L1799ChQ+PG\njRs8eLC5pWnTpuvXr09KSnJ1dX0ifxjIm1UzhPv373/33XfNj5qwqFKlypgxY/bt22ebwgAA\nAAA8rldeeeXYsWNnzpwxv121alW3bt08PDwsHWJjYyMjI5977jlzojPr1KmTTqc7dOhQdHR0\nbGxsq1atLMtEg4KCLPcfJiQkHDt2rEOHDiaTKeNvHTt2TE5OPnbsWPYyXF1dfX19169fv3v3\nbqPRKCKhoaETJkwICgqy6eXjX1kVCFNTU7P/fFhoNJrU1NSCLgkAAABAwXj++ec9PDxWrFgh\nImfPnj1+/Hj//v2zd7h+/bqIBAcHZ28057S4uLgbN26IiL+///1HRSQ6OlpEFi5c6JLN0KFD\nLcNaaDSa7du3q1SqNm3a+Pn59erVa926dQaDoYCvFg/PqkBYp06dlStXmqO8RWpq6qJFi2rX\nrm2bwgAAAAA8LldX1x49eqxZs8ZgMKxatapEiRJt27bN3sE89Zf9lkIRMe8oo1KpLFvLZGcJ\ncuZzBw4cePA+rVu3znVWgwYNoqKi9uzZM2TIkHPnzvXt27d58+aZmZkFd614FFbdQzhp0qTO\nnTtXrVq1bdu2AQEBGRkZMTExW7ZsSUpK2rZtm61LBAAAAPDIBgwYsGzZsoiIiPXr1/ft29fB\nwSH70ZCQEPl7rs8iJiZGRIKDg/38/ETk5s2b2Y9euXLF/KJUqVIiYjQaw8LCrKnEwcGhZcuW\nLVu2nDlz5hdffDF06NANGzbkmrHEE2bVDOFzzz23ZcsWJyen+fPnT5o0acaMGStXrgwJCdmy\nZUuHDh1sXSIAAACAR9asWbOyZcvOmjXr6tWr96evgICAGjVqbN26NT093dK4efNmV1fXxo0b\nlylTxtfX13Ljn4hERkaeOnXK/NrHx6dhw4abN29OSkqynLtq1aqJEyfq9frsn3L06NHevXvH\nx8dbWswTldlbYBfWPoewY8eOf/zxR3x8/PHjx48fP37r1q2TJ0927NjRpsUBAAAAeEwqlap/\n//7btm2rVatWzZo17+/w4Ycf3rlzp23btt9+++2WLVv69u27Y8eOSZMmFStWTK1WDxs27Ny5\nc927d9+4cePnn3/eoUOHevXqWc79+OOP09LSmjVrtnr16p9++mnSpElDhgyJjY3VaHIsRSxZ\nsuTOnTvbtm27bNmyXbt2rVu37qWXXnJycurSpYvNrx/5smrJqIikpaUlJyeXKFHCz88vIyNj\nw4YNt27dCg8Pr1ixok3rAwAAAPCY+vfvP3Xq1ActzuzUqdP27dtnzJgxYMAAvV5ftWrVZcuW\nDRw40Hx0ypQpOp1uxYoVO3bsqFSp0ty5c/fu3Xvy5Enz0RYtWuzZs2fatGnDhw/X6XShoaHT\npk2zPMPQokSJEvv27Zs2bdp7772XmJhYvHjxhg0b7tu3r1KlSra7algj7/tEc4mMjGzRosXb\nb789fvx4vV7fvHnzgwcPioizs3NERET23xAUNsnJyTqdzt5VALY1aNCgjIyMr776yt6FAECB\nOXPmzKhRo15++eV+/frZuxbAtnx9fe1dAhTNqiWj7733XmBgYK9evURkw4YNBw8eXLx48cWL\nF+vUqTNjxgwbVwgAAAAAsAmrAmFERMS4ceNCQ0NF5Pvvv69Zs+arr75atmzZESNGHD582MYV\nAgAAAABswqpAmJSUVKJECRExGo27d++27Czq5+eXkJBgw+oAAAAAADZjVSAMCAi4dOmSiPzy\nyy+JiYnPPfecuT06Orp48eI2rA4AAAAAYDNW7TLarl27iRMnXrhwYf369WXKlGnWrJmIxMfH\nz5s3r2nTpjauEAAAAABgE1YFwunTp585c2bmzJl+fn47duxwcHAQkTfffPPatWtr1661cYUA\nAAAAAJuwKhCWKFHi4MGDd+/edXV1tTxicvTo0XPnzg0MDLRleQAAAAAAW7H2wfQiUqxYsexv\n69evX9DFAAAAAACeHKs2lQEAAAAAFD0EQgAAAABQqIdYMgoAAACg8Lt3754thvXw8LDFsLAv\nZggBAAAAJTIajTaKjniKEAgBAAAAJZo/f37v3r0zMjLsXQjsyaolo1qt1snJKc9DKpWqWLFi\ntWvXHj16dMuWLQu0NgAAAAC2cuvWrbS0tLS0NGdnZ3vXAruxaoZw2LBh1apVS01NLV26dLt2\n7dq3bx8aGpqamlqnTp3w8PCqVatGRES0adNm586dti4XAAAAAFBQrJoh7NKlyw8//HDgwIHG\njRtbGg8ePDhgwIC5c+fWq1cvOTm5Xbt2M2bM6NChg81KBQAAAAAUJKsC4bhx4z744IPsaVBE\nGjduPH78+FGjRu3du9fT03PkyJGvvvpqrhNTUlIWL1585MgRvV5fvXr1YcOG+fv7W9/n+vXr\nc+bMiYqK2rx580ONCQAAACjcmTNn5s+fbzQaH9QhNjZWRMaOHevg4PCgPnXr1n399ddtUh8K\nB6sC4ZkzZwICAu5vDwoKOnLkiPm1q6urSqXK1WHu3LkJCQnTp093dnZesWLFtGnTPv30U7Va\nbU2f/fv3L1mypE6dOlFRUQ87JgAAAKBwx48fj4yMdNU4aO77V7qZWqSYVnPr2tUHjZCiN9y5\nc4dAWLRZFQj9/PyWLFnSpk2bXJFv3bp1bm5uIqLX67/44ovKlStnP5qQkHD48OG5c+eWLVtW\nREaOHPnyyy//8ccfderUsaaPTqebPXv2xYsX9+7d+1BjAgAAADCZTCIytVrFJr7ejzbC8xFH\nTQVaEgohqybWBg8e/PXXX9esWfOdd96ZNWvW7Nmzx40b16hRo1WrVvXu3VtEevbsuWPHjlGj\nRmU/68KFC46OjqGhoea37u7uISEhFy5csLJPq1at/Pz8clVizZgAAAAAnry//vorLCxMo8lv\nzunatWvDhg0LDQ11cnLy8fFp2rTpypUrLUfr16+v+puXl1eDBg3Wrl2b6+iJEyeyD6jX6wMD\nA1UqlV6vf7SSFM6qP5opU6ZoNJr58+fPmTPH0ujp6fn2229/9NFHItKiRYsePXqYw6HF3bt3\nPTw8sk8qenp6JicnP2yfh+ofERExefJky9tZs2bVrVvXmmsEnnbFixe3dwkAUGBcXV1FRKPR\n8OUGPC02bNjw9ttvt23b9ujRow/qc/bs2WbNmgUHB3/44YdVqlRJT0/funXra6+9duHChQ8+\n+MDc55VXXpk+fbqIJCcnr1q16uWXX65YsWKDBg3MR/39/ZcuXTp//nzLmNu3b3/QfZLWlASr\nAqFarZ40adLEiROvXr0aHx9vMpmKFy8eGhpquf30rbfeyvPEXEtMzdPWj9DH+v7Ozs4lS5a0\nvNVqtQaDIf8BgaKBH3UARYn573eTycSXG4q8IjN5lZmZeejQoePHj2ef08tl6NChQUFBR48e\n1Wq15pawsLC6dev++eefRqPRvC2Im5tbcHCwiAQHB8+YMWP27Nlnz561BMKOHTuuXbt29uzZ\nlmcnLlu2rE2bNuvWrXu0kvAQP3+JiYmnT5+Oi4tTq9XBwcEBAQEeHh759Pfy8rp7967JZLJE\nuOTkZG9v74ft81D969evv3r1asvb5OTkpKQk668ReHrxow6gKElPTxcRg8HAlxuKPF9fX3uX\nUDD69+8vIsePH39Qh7i4uP37969Zs8aSBs26d+/evXv3+/tnZWV98cUXxYoVa9OmjaWxXr16\n+/fv37RpU9++fUUkPj5+586da9euzTMQ/mtJECsDodFoHDVq1IIFC3Q6naXRzc1typQpY8aM\nedBZFStW1Ol0UVFRFSpUEJHk5OTo6OhcG89Y0+dx+gMAAADKdO/ePRH5NuZGRMKdRxxBb9Bk\nZBRUPZcuXRKRatWq5d9t8eLFK1asEJG0tDQfH59Vq1ZlXwAoIoMGDVq6dKk5EK5evbply5a5\nOuChWBUIP/nkk7lz53bv3r1jx45BQUEmkykmJmbTpk1jx44NCAgwJ+/7eXt7N23a9LPPPnvz\nzTednJyWLFlSvnx580/Arl27MjIyunTpkk+fO3fuGAwG889xQkKCiLi7u+fTHwAAAIDFjRs3\nROTQ7UdMg2aa9PQCKkccHR1FJPvWL15eXikpKebXmzZtCg8PF5FevXpNmTJFRNLS0o4cOTJw\n4MAZM2Zkf/TFK6+88v7771+6dKls2bLLly83d8YjsyoQLl++/PXXX1+0aFH2xtdee613797z\n5s17UCAUkREjRnz55ZcTJ040Go116tQZOXKkeannyZMn796926VLl3z6jBkzJj4+3jzOoEGD\nRGTIkCHh4eEP6g8AAADAokKFChEREROqlK/rXezRRhh69E9VMc+CqqdcuXIODg4nTpyoX7++\nueXgwYPm+4SbNGli2RjG09OzfPny5tc1a9aMj4+fPHly9kAYFBTUvn37ZcuWde3a9caNG127\ndmVR6OOwKhBevHhx7ty597f37ds3186iubi6ur711lv3bzmTfaHpg/osWbLkocYEAAAAkIuP\nozbIxfnRznVQqUwFN/Xi4+PTqVOnGTNm9O3b1/ww8ypVqojIg/YINTOZTPc/T2Lw4MHjxo1L\nSUnp16+feeIRj8yqQKjRaMxLN3PJysqybDQKAAAAQLFu3Lih1+tv374tIjExMSLi5eXl7u6+\ndOnSlJQU83TO559/3rhx4yZNmkycOLFWrVqZmZnHjx///PPPPT09q1evbh4nNTXVfHpGRsax\nY8fmzJnTq1evXJ/VuXPnoUOHrlmzZvfu3Y9QUsFf/NPMqgfT16lTZ968eVlZWdkb09PT586d\ny1P+AAAAAISFhYWEhAwZMsRgMISEhISEhJhX/O3atWvLli3mPiVLljx58mSHDh3MgbBp06YL\nFizo1q3b6dOnLctEV6xYYT69evXqkydPfuONN7I/C91Mo9H079+/dOnStWrVeoSSkJ1VM4QT\nJkzo3LlzhQoVOnToEBwcnJWVFR0dvXXr1qSkpJ07d9q6RAAAAACF3JUrV/JsX79+ffa3Pj4+\nM2fOnDlzZp6d83+CfPajH3/8seV1WFhYng8zf1BJyM6qQNixY8dNmzZNmDBh8eLFlsaaNWuu\nXr06+1NBAAAAABQqh27fuZWZ+WjnZhiNTgVbDQofax9M361bt27dusXGxl6/fl2lUoWEhAQE\nBNi0MgAAAACPzNnZWUS+jbnxOIMEOxEJizhrA6FZUFBQUFCQjUoBAAAAUFDCw8MDAwPz2cNz\nw4YNkZGRo0aNymeflTJlytikOBQa+QXCypUrWzNEZGRkARUDAAAAoGA4Ozs3b948nw7mLTqb\nNGni4+PzpIpCoZNfIPT19X1idQAAAAAAnrD8AmFERMQTqwMAAADAk6RSqSz/C8XK7zmEgwYN\nSk9Pt3Kg9PT0wYMHF0RJAAAAAGyuc+fOPXr08PLysnchsKf8AuGePXsaNWq0d+/efx1l//79\nYWFh5lXIAAAAAAq/hg0b/t///R8zhAqXXyA8duxYYGBgy5Ytn3322eXLl8fExOTqcP369VWr\nVrVu3bp58+YBAQHHjh2zZakAAAAAgIKU3z2ExYsX37lz51dffTV16tRBgwaJiJ+fn7+/v6en\nZ3Jy8q1bt+Lj40WkQoUKa9as6dOnj1qdX7wEAAAAABQq//IcQrVa/dJLL/Xp0+fAgQM//vjj\nH3/8cevWrcTERC8vr7Jly9aqVat9+/aNGzd2cHB4MuUCAAAAKBB37tyJjY2tVq2avQuBPVn1\nYHoHB4dmzZo1a9bM1tUAAAAAeDI+//zzPXv2fP/99/k8mB5FHos8AQAAACXKyMgwGo1ZWVn2\nLgT2RCAEAAAAAIUiEAIAAACAQll1DyEAAACAp8u+ffumTp1qNBrz7/bCCy/kc7Rhw4YzZ84s\n0LpQuBAIAQAAgCLoypUrRqMxLaik3s3t0UZwv3zp8uXLBVsVChsCIQAAAFBkxT7XKbnKIz5Y\nosYHUwq2GNjClStXQkND//zzz+rVqz/C6dxDCAAAAOBxxcbG9uvXz9/f39PTs0WLFocPH86z\n27Vr14YNGxYaGurk5OTj49O0adOVK1dajtavX1/1Ny8vrwYNGqxduzbX0RMnTmQfUK/XBwYG\nqlQqvV5vo0t7THv27Dl69Ki9q3ggAiEAAACAx9W1a9eYmJiffvrp2LFjQUFBnTt3Tk1NzdXn\n7NmzderUOXDgwIcffnj48OHt27e3bNnytddemzhxoqXPK6+8Eh0dHR0d/dtvv7Vq1erll18+\ncuSI5ai/v//SpUuzj7l9+/Z/vU/yYel0ugIc7ZNPPiEQAgAAACiyEhMTy5Qps3jx4tq1a5cv\nX37mzJm3bt06ffp0rm5Dhw4NCgo6evRo7969a9WqFRYW9sEHH6xbt06r1VpCnZubW3BwcHBw\ncLVq1WbMmKFSqc6ePWsZoWPHjmvXrs3IyLC0LFu2rE2bNveXlJGRoVKpli5d2rx58+Dg4CpV\nqvzwww/mQ2fPnm3Xrp23t7eXl1f79u2joqJERKfTqVSq5cuXh4aGDho06EHdTCaTSqVas2ZN\n8+bNS5QoUaNGjT///POdd96pXLlyQEDA/RvwtGrVavv27SNHjqxXr15KSopKpdq7d6/5UFRU\nlEqlioqKMo/59ddft2vXrnz58qVLl161apW5z82bN3v16uXl5VW8ePF27dqdOXPG3H7y5MlG\njRq5ubnVrFnz0KFDD/9f7B8EQgAAAACPxcfH55tvvqlUqZL57fXr19VqdcmSJbP3iYuL279/\n//jx47Vabfb27t27T5kyRa3OHUyysrIWLlxYrFix7HmvXr16xYsX37Rpk/ltfHz8zp0789wo\nVaPRiMi8efM2btwYExMzcuTIF1988erVqyLSo0ePwMDAa9euXbt2zd3dfcCAASKi1WpVKtXC\nhQu/++67BQsWPKibSqVycHBYuHDhli1boqOjPT09W7Zs2aBBg8jIyCVLlrz33nvx8fHZy9iz\nZ0+pUqXmzp177NixB/3pmcf86KOPli9fHhUVNXbs2GHDhpnnV/v16ycily5diomJadiwYZs2\nbdLS0oxG4/PPP1+5cuWbN29u2bJl4cKF+fyn+VcPsalMenr6sWPHrl+/3rp1a19fX71eb/5T\nBgAAAFDYmJNJyPffBf2449FG0N67l+rk9LBnJSYmDh48+M033wwODs7efunSJRGpVu1fdrhZ\nvHjxihUrRCQtLc3Hx2fVqlW5guWgQYOWLl3at29fEVm9enXLli1zdcjulVde8ff3F5EhQ4aM\nHTt2+/btw4YN27dvn7Ozs5ubm4j07du3T58+5jk6tVodHh5eu3Zt87kP6iYiL730kqenp4g8\n88wzV65c6dOnj4i0bNnSYDBcvnzZ/IkPq3///uYL6dy584gRI65cuSIiu3fvvnHjho+Pj4hM\nmzZtwYIFW7duDQ4OvnLlys8//+zu7u7u7v7222/v27fvET7RzNpEN2vWrA8++ODu3bsicvDg\nQV9f3ylTpsTFxX355ZcODg6P/PEAAAAAbCEzM1NEtPfuatJy38tnJZXRaDAYHuqUyMjILl26\ntGnT5r///W+uQ46OjiKSfesXLy+vlJQU8+tNmzaFh4eLSK9evaZMmSIiaWlpR44cGThw4IwZ\nM15//XXLWa+88sr7779/6dKlsmXLLl++3Nz5QcqVK2d+4eDgUKJEiejoaBE5ceLERx99dOnS\nJaPRmJ6ertPpDAaDea6rQoUKlnPz6WbJus7OzpY46uzsLCLp6ekP9SdmUbp0afMLJycn8zgx\nMTEiEhgYmL3bpUuXzLm0TJky5paKFSs+2ieaWRUIlyxZMnbs2PDw8I4dOw4dOtTcWKlSpY8/\n/rhixYrjx49/nAoAAAAAFLiQkBARufTSgMd57IRfzuWd+du9e3evXr3ef//9ESNG3H+0XLly\nDg4OJ06cqF+/vrnl4MGD5sDZpEkTyz2Enp6e5cuXN7+uWbNmfHz85MmTswfCoKCg9u3bL1u2\nrGvXrjdu3Ojatevx48cfVFL2QGswGJydna9evdq5c+cpU6Zs377d0dHxhx9+6Nq1q6WP098z\novl3M88T3v/6oeTaC+f+ccwtaWlpLi4u2dstdxiaPeb2qlbdQzh//vyhQ4d+//335oWzZv37\n9x8zZszq1asf5+MBAAAAFAERERE9e/Zcs2ZNnmlQRHx8fDp16jRjxgzL7qNVqlSpXr161apV\n8xnWZDLdH3gGDx78zTffrF27tl+/fuaJxwc5f/68+UVmZmZsbGxISMiRI0cMBsP48ePNJz5o\n/08ruz0UJycnlUqVlZVlfmteFJoP83TlyZMnLS3mZbfBwcEmk+natWvmRstOM4/GqkAYGRmZ\n552aLVq0uHz58uN8PAAAAICnXXp6+oABA0aOHFm9evWYv5mD39KlS+fNm2fu9vnnnxuNxiZN\nmnzzzTfnz5//888/V65c2bhxY09PT8tD1VNTU82nR0VFbdiwYc6cOb169cr1cZ07d05OTl6z\nZo15O9B8rF69+tSpU5mZmbNmzTIajeHh4cHBwXq9fv/+/Uajcd26dXv27BGR2NjYXCda2c0a\nrq6uUVFRt2/f1mq15cuX37lzp4ikpKTMnz8//xOrVq3aqlWr0aNHR0dH63S6hQsX1qhR48aN\nG40bNy5evPjUqVPv3Llz7ty5fx0nf1YFQq1Wm+da2Js3b2ofZhIZAAAAQNFz4MCBS5cuTZ48\nOSSb5cuXi8iuXbu2bNli7layZMmTJ0926NBh4sSJtWrVatq06YIFC7p163b69GnLMtEVK1aY\nT69evfrkyZPfeOONOXPm5Po4jUbTv3//0qVL16pVK//Chg8fPnz4cG9v76+++v/27j06qvLQ\nG/Ce3IBAQCBcDQqKolTwYAGhFS0gLZaKCh7FSxErHnTV21Gx3jgoluMFH9LVWAAAIABJREFU\nK7j0AEIXKkrViopyiYgiRVm4VLzQorZBj4pcDDEQ7jDJzPfHrJOVD5BOMZNh2M/zV+bd7578\nRlx7zS/73Xv/6cUXX2zevHmvXr1Gjx597rnntmzZcvHixXPnzu3WrVv37t33Ol+X5LRkjBo1\nasqUKT179gyCYMqUKQsWLOjQocOZZ5557bXXBv9sweesWbOKioq6dOnStGnTp556qri4uHXr\n1g0aNJg/f/5f//rXtm3bXnjhhYmnOB70sxMj8Xj8n07q379/EAQLFiyIx+MNGjRYvnx5r169\nNm/e3KdPn7Zt2y5cuPDgfncdqKioqN3HSsIh6De/+c2uXbv+9Kc/pTsIQK35+9//PmbMmPPP\nP/+CCy5IdxZIrcLCwlp/z61btwZBMHPmzMcff3z1Ff/xQ64hPDI3989//nPiZUFBQa1FTL3K\nysrc3Nzi4uKBAwemO8shLambyowdO7Z///6dO3f+xS9+EQTBtGnTpk6dOmfOnB07dkydOjXF\nCQGA0DnppJMWL168c+fO6muNgIPTctlbR6za+wHxScrZuTOwHvBwl1QhPP300xcuXDh69OjE\nQw8TJ3979uz5wAMP/PSnP01tQAAA4F+XeHhd488+/SFv0rRp01qKwyEq2ecQ9uvXb8WKFWVl\nZWvWrIlEIkcffbT/OQAA4JD1q1/9qnv37ge4QOyhhx56//33J0+efMQRR3zfnANsOsTl5OQk\nc3EcyRbCHTt2VFRUtGnTprCwcNeuXc8999zGjRsHDx78Ax+DCAAApMhezzTfS+JB6q1atUqc\nSySckn3sRIcOHZ588skgCCorK/v16zdixIjRo0effPLJK1asSHFCAAAAUiKpQnjHHXe0bt06\n8QCQ5557bvny5dOmTfv888+7des2fvz4FCcEAABqX3Z2dhAEOTnJrhnksJTUP//bb789ceLE\nDh06BEHw8ssvd+3a9corrwyC4JprrrnllltSGxAAAEiBESNG9OnTp3HjxukOQjolVQg3b97c\npk2bIAhisdgbb7wxcuTIxHiLFi3KyspSmA4AAEiN9u3bt2/fPt0pSLOkCmGrVq2++OKLvn37\nvvnmm+Xl5WeddVZifM2aNc2bN09lPAAA4F+TWU+QJ72SKoQ///nP77zzzpKSkmeffbZ9+/Z9\n+vQJgqC0tPThhx/2HEIAAIAMlVQhvOeee1atWnX//fe3aNGiuLg4cfnpdddd9/XXX8+aNSvF\nCQEAAEiJpAphmzZtli9fvmXLlvz8/OrbEN18882TJk068LNNAAAAOGT9CzeZbdiw4fbt22Ox\nWOJlx44dgyDYvHnzEUcckZJoAAAApFJShbCkpGTkyJHLly+PRqP7bo3H47WdCgAAgJRLqhCO\nGjXqww8/PP/889u2bevJlQAAAIeHpNrdu++++/zzz1c/bQIAAIDDQFYykxo1anTsscemOgoA\nAAB1KalCeNlllz3++OOpjgIAAEBdSmrJ6Pjx44cOHdq7d+/TTjutefPme2299dZbUxAMAACA\n1EqqEE6aNOmVV14JguCdd97Zd6tCCAAAkImSKoQTJ04866yzbr31VncZBQAAOGwk1e6+++67\nP/zhDyeeeGKq0wAAAFBnkrqpTJcuXb777rtURwEAAKAuJVUIH3300TvvvHPFihWpTgMAAECd\nSWrJ6M033/z111937969UaNG+95l9Msvv6z9XAAAAKRYUoUwKyurY8eOxx13XKrTAAAAUGeS\nKoR/+ctfUp0DAACAOvbPryHcs2dPjx495s2bVwdpAAAAqDP/vBDm5eWtW7du9erVdZAGAACA\nOpPUXUYfe+yxP/7xjy+99FJlZWWqAwEAAFA3krqGcMKECdnZ2UOGDMnJyWnRokVeXl7Nre4y\nCgAAkImSKoSVlZVNmzbt379/qtMAAABQZ5IqhMuWLUt1DgAAAOpYUtcQAgAAcPhRCAEAAEJK\nIQQAAAgphRAAACCkFEIAAICQUggBAABCSiEEAAAIKYUQAAAgpBRCAACAkFIIAQAAQkohBAAA\nCCmFEAAAIKQUQgAAgJBSCAEAAEJKIQQAAAgphRAAACCkFEIAAICQUggBAABCSiEEAAAIKYUQ\nAAAgpBRCAACAkFIIAQAAQkohBAAACCmFEAAAIKQUQgAAgJBSCAEAAEJKIQQAAAgphRAAACCk\nFEIAAICQUggBAABCSiEEAAAIKYUQAAAgpBRCAACAkFIIAQAAQkohBAAACKmcdAdIrby8vLy8\nvHSngLrQsGHDdEcAqDVZWVlBEOTm5jq4AaTUYV4IY7FYLBZLdwqoC5WVlemOAFBrsrOzgyCI\nxWIObgApdZgXwsrKymg0mu4UUBd2796d7ggAtSY3NzcIgqqqKgc3DnsFBQXpjkCouYYQAAAg\npBRCAACAkFIIAQAAQkohBAAACCmFEAAAIKQUQgAAgJBSCAEAAEJKIQQAAAgphRAAACCkFEIA\nAICQUggBAABCSiEEAAAIKYUQAAAgpBRCAACAkFIIAQAAQkohBAAACCmFEAAAIKQUQgAAgJBS\nCAEAAEJKIQQAAAgphRAAACCkFEIAAICQUggBAABCSiEEAAAIKYUQAAAgpBRCAACAkFIIAQAA\nQkohBAAACKmcdAcAfqi77767qqoq3SkAAMg8CiFkvK5du0YikfLy8nQHAQAgw1gyCgAAEFIK\nIQAAQEhZMgqZ7R//+EdJSUkQBMccc8yJJ56Y7jgAAGQShRAy2KOPPjpv3rzql7/4xS9uuOGG\nSCSSxkgAAGQQS0YhUy1atKhmGwyCYOHChcXFxenKAwBAxlEIIVMtXrx438HXX3+97pMAAJCh\nFELIVNu2bUtyEAAA9kshhEzVrl27JAcBAGC/FELIVBdeeGF2dnbNkaysrIsvvjhdeQAAyDgK\nIWSqv/3tb1VVVTVHYrHYypUr05UHAICMoxBCplq6dOm+g2+99VbdJwEAIEMphJCpduzYse/g\n9u3b6z4JAAAZSiGETNW+ffskBwEAYL8UQshUl156acOGDWuONGjQYPjw4enKAwBAxlEIIVO1\natXq/vvv79KlS05OTnZ29o9+9KP77rvvyCOPTHcuAAAyRiQej6c7QwpVVFREo9F0p4DUatSo\nUSQS2bp1a7qDANSa3NzcJk2a7Ny506XRHPYKCwvTHYFQy0l3AOCHys3NjUQi6U4BAEDmsWQU\nAAAgpBRCAACAkFIIAQAAQkohBAAACCmFEAAAIKQUQgAAgJBSCAEAAEJKIQQAAAgphRAAACCk\nFEIAAICQUggBAABCSiEEAAAIKYUQAAAgpBRCAACAkFIIAQAAQkohBAAACCmFEAAAIKQUQgAA\ngJBSCAEAAEJKIQQAAAgphRAAACCkFEIAAICQUggBAABCSiEEAAAIKYUQAAAgpBRCAACAkFII\nAQAAQkohBAAACCmFEAAAIKQUQgAAgJDKSXcA4AfZsmVLSUlJEAStWrVq3LhxuuMAAJBJFELI\nYHPnzp0xY8bOnTuDIKhfv/6IESPOPffcdIcCACBjWDIKmerDDz/8n//5n0QbDIJg165dU6dO\nfffdd9ObCgCADKIQQqZ6+eWX9x2cM2dO3ScBACBDKYSQqcrKyvYd3LhxY90nAQAgQymEkKla\ntGix72DLli3rPgkAABlKIYRMdd555+07OGTIkLpPAgBAhlIIIVN17dr1hhtuaNSoUeJlfn7+\nNddc8+Mf/zi9qQAAyCCReDye7gwpVFFREY1G050CUmjHjh2lpaXxeLxly5YNGzZMdxyA2pGb\nm9ukSZOdO3du37493VkgtQoLC9MdgVDzHELIbPn5+d26dYtEIuXl5enOAgBAhrFkFAAAIKQU\nQgAAgJCyZBQy244dO7788kvXEAIAcBAUQshgCxcunD59+rZt24IgyM/Pv+KKKwYNGpTuUAAA\nZAxLRiFTrVy5cuLEiYk2GATBjh07HnnkkRUrVqQ3FQAAGUQhhEw1Z86cfQdffPHFuk8CAECG\nUgghU5WWliY5CAAA+6UQQqba73NsW7ZsWfdJAADIUAohZKpzzjknyUEAANgvhRAyVbdu3X77\n2982aNAg8bJevXqjRo3q2bNnelMBAJBBIvF4PN0ZUqiioiIajaY7BaTQli1bNmzYEARB69at\nGzdunO44ALUjNze3SZMmO3fu3L59e7qzQGrt9xoQqDOeQwiZrXHjxkcffXQkEikvL093FgAA\nMowlowAAACGV2jOE27ZtmzZt2nvvvVdZWXnSSSddffXV+94C8fvmHGDftWvXTpw4cfXq1ft9\nDhsAAADJSO0ZwkmTJn399df33HPPxIkTs7Ozx40bF4vFkpzzfeNvvfXW7bffXlRUlNLkAAAA\nh70UFsKysrJ33333uuuu69ixY1FR0Q033LB27dqPP/44mTkH2DcajT744IO9evVKXXIAAIAw\nSGEhLCkpycvL69ChQ+Jlo0aN2rVrV1JSksycA+zbr1+/Fi1apC42AABASKTwGsItW7YUFBRE\nIpHqkSZNmlRUVCQzp0mTJv903/168803R48eXf1y8uTJHstGSLhpNXD4adCgQfXTVgFIhdTe\nVKZmowuCYL/PPPy+Ocnsu6+CgoITTzyx+mX9+vUrKyuTTAsZKjs7OxKJ+F8dOJxEIpHs7OxY\nLLbv3QfgMJOT4zlwpFMK//874ogjtmzZEo/Hq6tdRUVF06ZNk5mTzL771b1796eeeqr6ZUVF\nxebNm2vn88Chp6ysbObMmZ988kk8Hu/cufPw4cMtqAYOD4kH0+/evduD6TnsWeNDeqXwGsLj\njz8+Go2uXr068bKiomLNmjUnnHBCMnOS2RdCbsuWLTfccMNrr732zTffrF27dtGiRddee62/\ngAAAkLwUFsKmTZv+9Kc/feSRR1avXr1mzZqHHnqoY8eOP/rRj4IgWLRo0dy5cw8w5wD7btq0\nqaysbOvWrUEQlJWVlZWV7dq1K3WfAg5ZTz/9dFlZWc2RzZs3P/nkk+nKAwBAxokkeW3ewdmx\nY8f06dOXL18ei8W6det21VVXJZZ9TpgwYcuWLffcc88B5nzf+MiRI0tLS2v+lpEjRw4ePHi/\nASoqKqLRaOo+IKTR9ddf//e//32vwfbt20+dOjUteQBqUWLJ6M6dOy0Z5bBnySjpldpCmHYK\nIYexm266adWqVXsNHnfccY888kha8gDUIoWQ8FAISa8ULhkFUqpHjx5JDgIAwH4phJCphg4d\nWvMhK0EQHH/88RdddFG68gAAkHEsGYUMVlVVtXDhwk8//TQej3fq1Omss87yLCPg8GDJKOFh\nySjppRBCxmvatGkkEikvL093EIBaoxASHgoh6WXJKAAAQEgphAAAACGlEAIAAISUQggAABBS\nCiEAAEBIKYQAAAAhpRACAACElEIIAAAQUgohAABASCmEAAAAIaUQAgAAhJRCCAAAEFIKIQAA\nQEgphAAAACGlEAIAAISUQggAABBSCiEAAEBIKYQAAAAhpRACAACElEIIAAAQUgohAABASCmE\nAAAAIaUQAgAAhJRCCAAAEFIKIQAAQEgphAAAACGlEAIAAISUQggAABBSCiEAAEBIKYQAAAAh\npRACAACElEIIAAAQUgohAABASCmEAAAAIaUQAgAAhJRCCAAAEFIKIQAAQEgphAAAACGlEAIA\nAISUQggAABBSCiEAAEBIKYQAAAAhpRACAACElEIIAAAQUgohAABASCmEAAAAIaUQAgAAhJRC\nCAAAEFIKIQAAQEgphAAAACGlEAIAAISUQggAABBSCiEAAEBIKYQAAAAhpRACAACElEIIAAAQ\nUgohAABASCmEAAAAIaUQAgAAhJRCCAAAEFIKIQAAQEgphAAAACGlEAIAAISUQggAABBSCiEA\nAEBIKYQAAAAhpRACAACElEIIAAAQUgohAABASCmEAAAAIaUQAgAAhJRCCAAAEFIKIQAAQEgp\nhAAAACGlEAIAAISUQggAABBSOekOAPwg5eXlK1eujMfjRUVFzZs3T3ccAAAyiUIIGeyFF154\n8skn9+zZEwRBbm7uJZdcMmzYsHSHAgAgY1gyCpnqvffemz59eqINBkEQjUafeOKJZcuWpTcV\nAAAZRCGETDVv3rwkBwEAYL8UQshU33333b6DZWVldZ8EAIAMpRBCpmrdunWSgwAAsF8KIWSq\nIUOG7Dt4/vnn130SAAAylEIImapz58633HJL48aNEy8LCgpuuummk08+Ob2pAADIIJF4PJ7u\nDClUUVERjUbTnQJSaM+ePeXl5fF4vFmzZvXq1Ut3HIDakZub26RJk507d27fvj3dWSC1CgsL\n0x2BUPMcQshseXl5J554YiQSKS8vT3cWAAAyjCWjAAAAIaUQAgAAhJRCCAAAEFIKIQAAQEgp\nhAAAACGlEAIAAISUQggAABBSCiEAAEBIKYQAAAAhpRACAACEVE66A6RWXl5eXl5eulNAamVl\nZQVB0LBhw3QHAag1iSNbbm6ugxtASh3mhTAWi8VisXSngNSKx+ORSKSysjLdQQBqTXZ2dhAE\nsVjMwQ0gpQ7zQlhZWRmNRtOdAlIrPz8/CILdu3enOwhArcnNzQ2CoKqqysGNw15BQUG6IxBq\nriEEAAAIKYUQAAAgpBRCAACAkFIIAQAAQkohBAAACCmFEAAAIKQUQgAAgJBSCAEAAEJKIQQA\nAAgphRAAACCkFEIAAICQisTj8XRnAH6QyZMnR6PR66+/Pt1BAGrNV199NWvWrN69e/ft2zfd\nWQAOZ84QQsZ79dVX58+fn+4UALVp48aNL7744ieffJLuIACHOYUQAAAgpBRCAACAkFIIAQAA\nQspNZQAAAELKGUIAAICQUggBAABCSiEEAKhlpaWlgwcP/uqrr9IdBOCfyEl3AAiptWvXTpw4\ncfXq1XPmzPm+ORs3bpw9e/aKFSvKy8vr169fVFQ0cODAfv36JbbeeOONq1evTvycn5/ftm3b\nwYMH/+xnP6u5ddKkScccc0z1G1ZVVV1++eWbN29+6aWXsrOzDyISkFnKy8sff/zxjz76KBqN\ndujQ4fLLLz/++OP3nVbHR5tDwcqVK/Pz8zt27JjuIABpphBCGrz11lt//OMfu3XrVv0da19r\n1qy59dZbmzdvftlllxUVFe3Zs+e999579NFH161bd+mllybm9O/f/5JLLgmCYMeOHYsXL544\nceKRRx553HHHJbY2adJk0aJFo0aNqn7PFStWfN99pJKJBGSc3//+9/Xq1bv77rsbNGjw9NNP\n33PPPdOnT69fv37NOXV8tDloVVVVtdgt58yZ06NHD4UQQCGENIhGow8++ODnn3++ZMmS75sz\nefLkZs2aTZw4sfoLUKdOnY499tgvv/wyHo9HIpEgCOrXr19YWJjY+utf//qll15as2ZN9Ve0\n7t27L1my5PLLL8/Ly0uMLFq06OSTT166dOnBRQIyy9atW1u1anXppZceeeSRQRCMGDHiiiuu\n+Prrr/c6SViXR5s9e/acf/7511577eLFizds2NCgQYMRI0b07NkzCII1a9ZMnz69pKQkHo93\n6tTpqquuatOmTVVV1XnnnXfdddc9++yznTt3vvHGG/c7LR6Pn3POOTfeeOPChQvXrVvXuHHj\nm2+++fXXX3///fe3bdt27rnnDh06tGaMO+64429/+9vHH3/82muv3XvvvRdccMH48eO7dOkS\nBMH69etHjRr12GOPtW7d+pxzzrnllltee+21DRs2VFVVXXLJJYmzpps3b542bdoHH3yQnZ19\n7LHHjhw58qijjgqC4Isvvpg8efJXX33VunXrCy64oBb/KQFSxzWEkAb9+vVr0aLFASZs2rRp\n1apVQ4cO3evP4b17977ooosS389qqqysLC4uzs/PP/nkk6sHO3bsWFBQsHz58sTLioqKDz74\n4Cc/+cnBRQIyTkFBwe9+97tEGwyC4LvvvotEIs2aNas5p46PNonf8sorr9x6662PP/744MGD\n77333tLS0iAI7rvvvqZNm86YMWPGjBn169efOHFiYn4kEikuLr799tuvuuqq75sWiUSysrIW\nLFgwZsyYGTNm5Ofn33777ccdd9yUKVOuvfbap556qqKiomaM8ePHt2jRYuTIkYnd9yvxnrNn\nz77++uunTZs2ZMiQKVOm7Nq1KwiCP/zhD0EQTJ8+/fHHHz/++OPHjBmze/fueDz+3//930VF\nRU899dSYMWMWLFhwgH8agEOHM4RwKNqwYUMQBIk/OR/Aq6+++sYbbwRBsHv37kaNGv3nf/5n\n8+bNa04YMGDAokWLzjjjjCAI3nzzzS5duuw1AQiJrVu3PvLII2effXb1ib6EtBxt+vfv36RJ\nkyAIfv7znz/xxBMrVqw466yz7rvvvtzc3MRy1jPOOGPChAmJ85ORSKRnz57VFyh+37QgCPr2\n7Zufnx8EQefOnUtLS08//fQgCLp27RqLxb799tvEb/xX9evXL/FBevTo8dhjjyW668cffzxz\n5syCgoIgCC655JL58+e/9957hYWFpaWlw4YNq1+/fv369c8555xVq1YdxG8EqGMKIRyKcnJy\ngiCIxWLVI8OGDUv8ZToIgttvvz2xwqpPnz4XXXRREAS7d+8uKSl5+OGHf/3rXw8cOLB6r/79\n+//pT3/asGFD69atX3/99cRkIGy++eabe+6559/+7d+uuOKKvTal5WjTpk2bxA9ZWVlNmzbd\nuHFjEARffPHF7NmzN2zYEI/Hd+/eXVVVFYvFEmcU27ZtW73vAaZVV9C8vLzqn3NzcxOx/9X/\naAnVSycS77Nnz56ysrIgCIYPH15zWiJPJBJp2bJlYqT6xCzAIU4hhENR69ats7KyPv/88+ob\nHkyYMCHxje2WW26p/urWsGHD6u9V7du3r6iomDVrVs2vaM2aNTvllFNef/31U089ddOmTaee\neurnn39etx8FSLOPP/74gQceuPjiiwcNGrTv1rQcbWr2z1gslpeXV1paOm7cuIsuumjs2LE5\nOTnvvvvu73//++o5iTIWBMGBp+27wPUg1My23/dMjMyePbv6gsmExYsX13xZVVX1w8MA1AHX\nEMKhqKCgoHv37s8//3z13+nbtWt39NFHH3hZVzwe3+urTBAEAwYMWLZs2ZIlS372s58lTgUA\n4fHJJ5888MADN910037bYJCmo83atWsTP0Sj0fLy8sLCwpKSklgsNnTo0MSOJSUl+90xyWn/\nktzc3EgkUllZmXiZWBR6AInTlV988UX1SGLZbWFhYTweT5ztDILg66+//uHZAOqAQghpsGnT\nprKysq1btwZBUFZWVlZWlvgqtmjRorlz5ybmXH311bFY7JZbblm2bNnatWu/+uqrxYsXjx49\numHDhkcffXRizq5duxK7r1+//q233nr55ZdPO+20vX5Xjx49tm/fvmTJkjPPPPMgIgGZa8+e\nPZMmTRo8ePBRRx1V9n/SfrQJguDNN9/88ssvo9Hoiy++GI/HTz311MLCwqqqqk8++SQejy9d\nunTlypVBEJSXl++1Y5LTklGvXr3169dv3bo1Ozu7TZs2H3zwQeJjzp8//8A7tmvXrmvXrjNm\nzCgrK6uqqiouLr722ms3bdp0wgknFBQUPPPMM9u2bVuzZs28efMOIhVA3XO6ANJg9OjR1X+E\n/s1vfhMEwciRIwcPHvzRRx9t2bLl7LPPDoKgefPmDz/88AsvvPD0009v3LgxOzu7qKiod+/e\nv/zlLxN3TQiC4I033kjc5iE3N7dly5a/+tWv9rq1ehAE2dnZ/fr1+/jjjzt06HAQkWrzYwN1\n69NPP92wYcOsWbNmzZpVPThq1KhBgwal8WgTBMGgQYOmTp26evXqVq1a3XbbbQUFBZ06dRoy\nZMj48eMjkUjv3r3HjBlz55133njjjYn7eVZLcloyBg4cOHPmzHfeeWfatGlXX3311KlTly9f\nfsQRR1x66aXvvvvugRd83nTTTdOnT7/mmmtisVj79u3vuuuupk2bBkEwduzYKVOmjBgxok2b\nNiNGjLj77rstHAUOfZFaf24sAMB+JZ4reNddd51yyinpzgJAEFgyCgAAEFoKIQAAQEhZMgoA\nABBSzhACAACElEIIAAAQUgohAABASCmEAAAAIaUQAhy27rrrrkgk0rJly2g0uu/WK6+8MhKJ\nnHbaaQf35sOGDWvUqFEyM0877bQTTjjh4H4LAJBSCiHA4SwrK6u8vLy4uHiv8V27dj3//PN5\neXlpSQUAHCIUQoDDWVZWVq9evZ544om9xl955ZXt27efcsop6QgFABwqFEKAw1llZeW55547\nf/787777rub4zJkz+/btu9cZwuLi4tNPP72goKBBgwYnnXTSQw89VP2s2ng8Pm7cuHbt2tWv\nX79Lly6zZ8+ORCI19122bNmAAQMaN27coEGDbt26zZgxY7951q9ff+WVVx599NH169dv3br1\n0KFDP/vss1r9xADAv0AhBDjMnXfeeZWVlc8880z1SGlp6cKFC4cNG7Znz57qwTlz5gwaNCgI\ngieeeOLll1/+yU9+ctNNN40ePTqxdcKECWPHju3Tp8/cuXPvuOOOsWPHfvjhh9X7LlmypG/f\nvtFo9Omnn37llVd69ep1xRVXPPjgg/uGGTJkyLx58/7rv/5rwYIFDz744D/+8Y8zzjhjx44d\nqfrwAMABRar/+gvAYeauu+66++67d+7cefbZZ2/atOn9999PjD/88MO33Xbbt99+O2DAgJyc\nnLfffjsIghNPPHH79u0lJSX16tVLTEuUt/Xr1zdr1qyoqKhp06Z//etfEycG161b1759+7y8\nvG3btgVB0L179/Ly8k8//bR633POOecvf/nL+vXrGzRocNppp5WVlX322Wdbtmxp0qTJ7373\nu/vuuy8x7X//93+fffbZyy67rG3btnX8HwcACJwhBAiDESNGrFixYtWqVYmXM2fOPPfccwsK\nCqonrFu37rPPPjvrrLOqG10QBIMGDYpGo++8886aNWvWrVvXr1+n89gEAAADfElEQVS/6mWi\nbdu27d69e+LnsrKyFStWDBw4MB6P7/o/v/zlLysqKlasWFEzRn5+fmFh4bPPPvvGG2/EYrEg\nCDp06HDbbbdpgwCQLgohwOHvvPPOKygoSNxa5pNPPvnggw+GDx9ec8LatWuDICgqKqo5mOhp\n69ev37BhQxAELVu23HdrEARr1qwJgmDKlCkNarjqqquq37ZaTk7OggULIpHImWee2aJFiwsv\nvPCZZ56pqqqq5U8LACQtJ90BAEi5/Pz8f//3f3/66afvu+++mTNntmnTZsCAATUnJE791byk\nMAiCxDUFkcj+Ly6oLnKJfS+//PL/+I//2GtOx44d9xrp0aPH6tWrly5d+uqrrxYXF//5z39+\n9NFHFy9eXPPMJABQZxRCgFC47LLLZsyY8fbbbz/77LMXX3xxdnZ2za3t2rUL/u9cX7Vvvvkm\nCIKioqIWLVoEQfDtt9/W3Prll18mfjjqqKOCIIjFYr169UomSXZ2dt++ffv27Xv//fc/9thj\nV1111XPPPbfXGUsAoG5YMgoQCn369DnmmGMmTJjw1Vdf7du+WrVq1aVLl3nz5u3cubN6cM6c\nOfn5+b17927fvn1hYWH1hX9BEHz22WcrV65M/NysWbOePXvOmTNn8+bN1fvOnDnzzjvvrKys\nrPlb3n///WHDhpWWllaPJE5U1hwBAOqSQggQCpFIZPjw4fPnzz/55JO7du2674R7771306ZN\nAwYMeOGFF+bOnXvxxRcXFxePGTOmcePGWVlZV1999aeffjpkyJDZs2dPnjx54MCBP/7xj6v3\nfeCBB3bs2NGnT5+nnnrqtddeGzNmzMiRI9etW5eT8/+tQznyyCNfffXVAQMGzJgxY9GiRc88\n88yll15ar169s88+O+WfHwDYH0tGAcJi+PDhd9999/ctzhw0aNCCBQvGjx9/2WWXVVZWdu7c\necaMGZdffnli69ixY6PR6BNPPFFcXNypU6dJkyYtWbLko48+Smw944wzFi9ePG7cuN/+9rfR\naLRDhw7jxo2rfoZhtTZt2ixdunTcuHF33HFHeXl58+bNe/bsuXTp0k6dOqXuUwMAB+A5hAAA\nACFlySgAAEBIKYQAAAAhpRACAACElEIIAAAQUgohAABASCmEAAAAIaUQAgAAhJRCCAAAEFIK\nIQAAQEgphAAAACGlEAIAAITU/wNXoy9tZhBYHQAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- new.get_result(result.m05.1, '1.GBM 1')\n",
    "errors.2 <- new.get_result(result.m05.2, '2.GBM param tuned')\n",
    "\n",
    "x <- errors.1\n",
    "x <- rbind(x, errors.2)\n",
    "\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6d5142-2f6f-4a02-a902-047b11d9a798",
   "metadata": {},
   "source": [
    "### save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "120fef0e-57e6-41e7-ae91-5608745ac02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- result.m05.1\n",
    "write.csv(x, file = \"gbm_result_m0501.csv\")\n",
    "x <- result.m05.2\n",
    "write.csv(x, file = \"gbm_result_m0502.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8a8c50-2cdd-4346-9796-f3fa26f85ebf",
   "metadata": {},
   "source": [
    "### load result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2934e69f-478c-4b34-9e90-2334ec83da27",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.m05.1 <- read.csv(file = 'gbm_result_m0501.csv')\n",
    "result.m05.2 <- read.csv(file = 'gbm_result_m0502.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ec947a05-e8a1-497a-8ce4-36da525d0607",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m05 <- result.m05.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb209ef-30c2-4407-b353-1a388b17d202",
   "metadata": {},
   "source": [
    "# Model Comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0354ec8e-7fb9-4e81-b6a2-1a7ae38e78a9",
   "metadata": {},
   "source": [
    "## Compare RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b9a63c6f-09de-4820-a6e8-a454f4973d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.1 <- new.get_result(result.m01, '1. Prophet')\n",
    "errors.2 <- new.get_result(result.m02, '2. BSTS')\n",
    "errors.3 <- new.get_result(result.m03, '3. ARIMA')\n",
    "errors.4 <- new.get_result(result.m04, '4. ARIMA+GARCH')\n",
    "errors.5 <- new.get_result(result.m05, '5. Gradient Boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cdce5921-5128-4900-93de-9fac46ef2018",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "errors.list <- list(errors.1, errors.2, errors.3, errors.4, errors.5)\n",
    "x <- errors.list[[1]]\n",
    "for (e in errors.list[2:length(errors.list)]) {\n",
    "    x <- rbind(x, e)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "746b9782-7441-4411-af40-1ae84d581af8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAAJYCAIAAAD9hIhNAAAACXBIWXMAABJ0AAASdAHeZh94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\nWzgyh2XEUx4AAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 300,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my.figsize(10, 5)\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57162eb1-2a21-443b-94fe-fd176981c1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0324495146564848"
      ],
      "text/latex": [
       "0.0324495146564848"
      ],
      "text/markdown": [
       "0.0324495146564848"
      ],
      "text/plain": [
       "[1] 0.03244951"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.0254550555297444"
      ],
      "text/latex": [
       "0.0254550555297444"
      ],
      "text/markdown": [
       "0.0254550555297444"
      ],
      "text/plain": [
       "[1] 0.02545506"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x <- abs(train)\n",
    "mean(x)\n",
    "median(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fd06f2b6-2391-499a-ae18-3310b7dc6dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "write.csv(x, file = \"result_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ecd9183-bd3c-4bb3-a95b-ead1f2325b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- read.csv(file = 'result_comparison.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6adf8ad-567c-461e-a306-052d9af2451b",
   "metadata": {},
   "source": [
    "## Forecast with best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309063c7-e344-49e4-9133-5244187e25e3",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad29bbd-9f3d-4ff8-923c-065ca2d71c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookahead <- 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "71d180f2-663e-4941-802f-ab6930a5714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "#set.seed(NULL)\n",
    "\n",
    "h <- 21\n",
    "\n",
    "# idx works for gbm as well\n",
    "idx <- wind:(nrow(trainx)-wind-h-lookahead)\n",
    "idx <- sample(idx, 1)\n",
    "\n",
    "idx.train <- idx:(idx+wind-1)\n",
    "idx.test <- (idx+wind):(idx+wind+h-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a9fe8b40-08f6-4a32-bcd6-4d92f46bba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.train <- trainx[idx.train]\n",
    "x.test <- trainx[idx.test]\n",
    "\n",
    "x.train.r <- x.train[,1]\n",
    "x.train.xr <- x.train[,2:4]\n",
    "x.test.r <- x.test[,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409f9b45-a059-4857-b5c3-62c07ef2197b",
   "metadata": {},
   "source": [
    "### ARIMA+GARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "92b3c562-c59d-447a-a865-08bbb9f19ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94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\nAElFTkSuQmCC",
      "text/plain": [
       "Plot with title “Forecast Series\n",
       " w/th unconditional 1-Sigma bands”"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fc <- ag2.forecast(x.train.r, h, vxreg=x.train.xr)\n",
    "ag2.plot(fc, figsize=c(10,6), test=x.test.r) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221d9e25-b7a3-4601-8e7f-65b8675897f0",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "31da8a77-3e6b-405a-afa2-1c2113fd74c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11546.54\n",
      " ARIMA(0,0,0) with non-zero mean : -7110.071\n",
      " ARIMA(1,0,0) with non-zero mean : -11509.39\n",
      " ARIMA(0,0,1) with non-zero mean : -9074.031\n",
      " ARIMA(0,0,0) with zero mean     : -7106.064\n",
      " ARIMA(1,0,2) with non-zero mean : -11542.62\n",
      " ARIMA(2,0,1) with non-zero mean : -11541.07\n",
      " ARIMA(3,0,2) with non-zero mean : -11612.69\n",
      " ARIMA(3,0,1) with non-zero mean : -11552.61\n",
      " ARIMA(4,0,2) with non-zero mean : -11564.03\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11558.44\n",
      " ARIMA(4,0,1) with non-zero mean : -11560.04\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11620.27\n",
      " ARIMA(2,0,2) with zero mean     : -11548.39\n",
      " ARIMA(3,0,1) with zero mean     : -11554.45\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -11542.93\n",
      " ARIMA(2,0,3) with zero mean     : -11560.27\n",
      " ARIMA(4,0,1) with zero mean     : -11561.87\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11618.38\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAAJYCAIAAAD9hIhNAAAACXBIWXMAABJ0AAASdAHeZh94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\nAAAAIer/AdHUfTk5sRMyAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 300,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my.figsize(10,5)\n",
    "fc <- arima.forecast(x.train.r, h)\n",
    "my.plot_forecast(fc, future=h, test=x.test.r, past=h*6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a409c4-cd50-4988-b7b7-f21e6686cde4",
   "metadata": {},
   "source": [
    "### BSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "593b009d-e6dd-4ea7-be64-7c7f90a0094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsts.lines <- function(fc, obs, ...) {\n",
    "    n1 <- ncol(fc$distribution)\n",
    "    time <- index(fc$original.series)\n",
    "    deltat <- tail(diff(tail(time, 2)), 1)\n",
    "    pred.time <- tail(time, 1) + (1:n1) * deltat\n",
    "    obs <- obs[1:length(pred.time)]\n",
    "    index(obs) <- pred.time\n",
    "    #l <- lines(obs)\n",
    "    l <- lines(pred.time, as.numeric(obs), ...)\n",
    "    return(l)\n",
    "}\n",
    "\n",
    "fc <- bsts.forecast(x.train.r, h, ping=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0f465369-8164-42ed-b14e-7c1f080628be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NULL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHQAAALQCAIAAAB+M7AjAAAACXBIWXMAABJ0AAASdAHeZh94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\nAAAAkMH/B16wXptUp2nQAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 570
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my.figsize(9.5,6)\n",
    "plot(fc, plot.original=h*6, ylim=c(-0.1, 0.1))\n",
    "bsts.lines(fc, x.test.r, col='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baafb572-6e5c-431b-bec0-9a79cdcd280a",
   "metadata": {},
   "source": [
    "### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a7ceeffb-6b2b-4e2f-9441-654f79477776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h.gbm <- 1\n",
    "#h.gbm <- h\n",
    "\n",
    "train.ml <- merge(lag.xts(trainx$y, -lookahead), trainx, join='left', fill=NA)\n",
    "colnames(train.ml) <- c('logret_fwd', 'logret', 'rsi','bbands','macd')\n",
    "idx.label <- 1\n",
    "idx.feautres <- 2:5\n",
    "\n",
    "x.train.ml <- train.ml[idx.train]\n",
    "x.test.ml <- train.ml[idx.test[1:h.gbm]]\n",
    "\n",
    "x.train.label <- x.train.ml[,idx.label]\n",
    "x.train.features <- x.train.ml[,idx.feautres]\n",
    "x.test.label <- x.test.ml[,idx.label]\n",
    "x.test.features <- x.test.ml[,idx.feautres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "8bc5b98d-1ad0-4af8-af78-5380a020b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth <- seq(4, 8, 1)\n",
    "eta <- c(0.01, 0.05, 0.1, 0.2, 0.3)\n",
    "\n",
    "fc <- xgb.forecast(x.train.label, x.train.features, x.test.label, x.test.features,\n",
    "                   max_depth=max_depth, eta=eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "6c647d3b-012b-4735-8f8f-bb8734273b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94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\nrkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l <- tail(x.train.label, h*1)\n",
    "x <- index(l)\n",
    "x <- append(x, tail(x,1)+1:h.gbm)\n",
    "y <- as.numeric(l)\n",
    "y <- append(y, as.numeric(x.test.label))\n",
    "plot(x, y, type='l', col='darkblue')\n",
    "\n",
    "x <- tail(x, h.gbm+1)\n",
    "y <- append(tail(as.numeric(l),1), fc$pred)\n",
    "lines(x, y, col='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1fdc20e3-2f75-4b3d-850a-7328597bd995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAMAAAC323mdAAAC91BMVEUAAAABAQECAgIDAwME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\nBcAMggXAjP8Hiqi3FLZGsZ0AAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance_matrix <- xgb.importance(model=fc$model)\n",
    "xgb.plot.importance(importance_matrix, xlab = \"Feature Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f7498c-0875-4708-98cf-94eb0b74c3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
