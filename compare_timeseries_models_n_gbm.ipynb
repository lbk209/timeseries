{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403b7c49-b1e4-4567-b300-d0cf4343f1ef",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589d964f-db11-4ee9-b31e-43a56aa2ed1c",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c83acee-3f1c-4594-883d-7c9aa7615e83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: xts\n",
      "\n",
      "Loading required package: zoo\n",
      "\n",
      "\n",
      "Attaching package: ‘zoo’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n",
      "\n",
      "Loading required package: TTR\n",
      "\n",
      "Registered S3 method overwritten by 'quantmod':\n",
      "  method            from\n",
      "  as.zoo.data.frame zoo \n",
      "\n",
      "Loading required package: parallel\n",
      "\n",
      "\n",
      "Attaching package: ‘rugarch’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    sigma\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(quantmod)\n",
    "library(forecast)\n",
    "library(rugarch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f76fd154-b6aa-4ba4-aac9-d547d3227669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Rcpp\n",
      "\n",
      "Loading required package: rlang\n",
      "\n",
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:xts’:\n",
      "\n",
      "    first, last\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Loading required package: BoomSpikeSlab\n",
      "\n",
      "Loading required package: Boom\n",
      "\n",
      "Loading required package: MASS\n",
      "\n",
      "\n",
      "Attaching package: ‘MASS’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    select\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘Boom’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    rWishart\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘BoomSpikeSlab’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    knots\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘bsts’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:BoomSpikeSlab’:\n",
      "\n",
      "    SuggestBurn\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘xgboost’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    slice\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(prophet)\n",
    "library(dplyr)\n",
    "\n",
    "library(bsts)\n",
    "\n",
    "library(xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a36dd52-ad96-4245-9985-ef4ee04f7323",
   "metadata": {},
   "source": [
    "### user's defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c1cae5f-cb19-423f-9f75-23355f2b58d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path <- '~/works/utils/r'\n",
    "source(paste(path, \"myutils.r\", sep='/'))\n",
    "source(paste(path, \"myarimagarch.r\", sep='/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1ca76d8-f191-41d9-b2f7-320cad9fd35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new.get_result <- function(x, group, group.col='Models',\n",
    "                          errors=c('rmse','mape') # unconditional forecast\n",
    "                          #errors=c('rmse.mean','mape.mean') # daily forecast\n",
    "                          ) {\n",
    "    y <- my.get_result(x, group, errors=errors, group.col=group.col)\n",
    "    colnames(y) <- c('rmse','mape',group.col)\n",
    "    return(y)\n",
    "}\n",
    "\n",
    "\n",
    "new.plot_errors <- function(x, group.col='Models', ...) {\n",
    "    my.plot_errors(x, metrics=c('rmse'), group.col=group.col, ...)\n",
    "}\n",
    "\n",
    "# forecast only at h\n",
    "new.forecast <- function(x, h, forecastfunction, ...) {\n",
    "    fc <- forecastfunction(x, h, ...)\n",
    "    fc <- list(method = paste(\"Forecasting on\", h, sep=' '), mean=fc$mean[h])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81965efe-0310-4a8f-bab8-f7d92d9d839f",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b7c1c3-673b-420b-9e3c-c94ac7936b24",
   "metadata": {},
   "source": [
    "### S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae10fdf1-3592-4ea5-8ae2-d5917a507e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start <- '1991-01-01'\n",
    "train_end <- '2019-12-31'\n",
    "\n",
    "test_start <- '2020-01-01'\n",
    "test_end <- '2020-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee333ae3-056f-4986-aef5-64e8a03fcc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'^GSPC'"
      ],
      "text/latex": [
       "'\\textasciicircum{}GSPC'"
      ],
      "text/markdown": [
       "'^GSPC'"
      ],
      "text/plain": [
       "[1] \"^GSPC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from <- train_start\n",
    "to <- test_end\n",
    "getSymbols(\"^GSPC\", from=from, to=to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "214a3960-5dd7-47be-90ef-2e258d043250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spx <- GSPC\n",
    "colnames(spx) <- c('o','h','l','c','v','a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019dcc7f-aabe-4e1a-bced-ba8dcc21036b",
   "metadata": {},
   "source": [
    "### Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8becee7d-33dc-4db2-bab9-71e87158d6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookahead <- 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afb9af71-95b5-4285-93a0-0e5913510963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               logret\n",
       "1991-01-31 0.05216129\n",
       "1991-02-01 0.06360416\n",
       "1991-02-04 0.08173788\n",
       "1991-02-05 0.10755822\n",
       "1991-02-06 0.12847341\n",
       "1991-02-07 0.13502311"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spx.ret <- diff(log(spx$a), lookahead)\n",
    "spx.ret <- na.omit(spx.ret)\n",
    "colnames(spx.ret) <- 'logret'\n",
    "head(spx.ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "651c6501-6ff3-4d97-a129-65e3ee317cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train <- window(spx.ret, end=as.Date(train_end))\n",
    "test <- window(spx.ret, start=as.Date(test_start), end=as.Date(test_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf7c574-fcaf-41e8-a22e-97b2caadd84a",
   "metadata": {},
   "source": [
    "## CV Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ad305fe-7f89-4186-a651-1873d64ef6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR <- 252\n",
    "\n",
    "#hori <- floor(YEAR/2)\n",
    "#hori <- floor(YEAR/6)\n",
    "hori <- floor(YEAR/12)\n",
    "\n",
    "#peri <- floor(hori/2)\n",
    "#peri <- hori*2\n",
    "peri <- hori\n",
    "\n",
    "#wind <- 5*YEAR\n",
    "#wind <- 7*YEAR\n",
    "wind <- 9*YEAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f16cf2d-16cb-45ad-adb3-4dfc8bcfda22",
   "metadata": {},
   "source": [
    "### testing\n",
    "- rerun Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6af023f6-9782-43de-ad8a-60f12ef422a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start <- '1991-01-01'\n",
    "#train_end <- '2000-12-31'\n",
    "train_end <- '2000-07-01'\n",
    "#train_end <- '1997-12-31'\n",
    "train <- window(spx.ret, start=as.Date(train_start), end=as.Date(train_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "493d63b9-0a03-4771-9aa1-53e0d58166f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"number of iterations: 238\"\n"
     ]
    }
   ],
   "source": [
    "n <- (nrow(train) - wind - hori)/floor(peri)\n",
    "print(paste('number of iterations: ', round(n), sep=''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a0b3d6-8fa4-4911-9127-b372ec88ba57",
   "metadata": {},
   "source": [
    "## Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f87d6209-3593-4659-b754-eef50734902f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x <- RSI(spx$a)\n",
    "trainx <- merge(train, x, join='left', fill=NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "063c43c3-688b-49ac-a6e2-89690219b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use close instead of adjusted to make consistent with \"un-adjusted\" high & low\n",
    "x <- BBands(spx[,c('h','l','c')])\n",
    "x <- x$pctB\n",
    "trainx <- merge(trainx, x, join='left', fill=NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff082501-d546-4510-bf61-43cfec923f72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x <- MACD(spx$a)\n",
    "x <- x$macd - x$signal\n",
    "trainx <- merge(trainx, x, join='left', fill=NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "befa6d49-0a1c-4bc7-8083-45ac91a02823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    y      rsi    bbands        macd\n",
       "1991-02-19 0.10602550 72.59254 0.8419486 -0.03641515\n",
       "1991-02-20 0.09798126 66.25313 0.7706927 -0.18551057\n",
       "1991-02-21 0.10585688 66.00481 0.7330987 -0.30953562\n",
       "1991-02-22 0.10194779 66.54491 0.7402938 -0.39546732\n",
       "1991-02-25 0.09259647 67.84742 0.7305630 -0.43573971\n",
       "1991-02-26 0.07655978 60.80133 0.6379610 -0.55105032"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                    y      rsi    bbands       macd\n",
       "2019-12-23 0.03808252 76.15462 0.9680588 0.15430304\n",
       "2019-12-24 0.03571448 75.83204 0.9028770 0.14089335\n",
       "2019-12-26 0.03335029 78.41506 0.9189083 0.14916039\n",
       "2019-12-27 0.03119111 78.43159 0.8946206 0.13732115\n",
       "2019-12-30 0.02122778 68.77901 0.7837726 0.07574999\n",
       "2019-12-31 0.02818876 70.74366 0.7500170 0.04243151"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colnames(trainx) <- c('y','rsi','bbands','macd')\n",
    "trainx <- na.omit(trainx)\n",
    "head(trainx)\n",
    "tail(trainx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5049d74b-5700-4b0c-af48-c2d74dc6d9cd",
   "metadata": {},
   "source": [
    "# Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9653be84-20b9-4aad-b230-55cfa4fc581c",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2842860f-ca3a-4757-9d7e-a0f608b8b9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast <- function(x, h, xreg=NULL, xreg.msize=NULL) {\n",
    "    \n",
    "    check.ds <- function(x) {\n",
    "        d <- try(as.POSIXct(x$ds, format = \"%Y-%m-%d\"), silent=T)\n",
    "        if ((sum(is.na(d))>0) | (is.element(\"try-error\", class(d))))  {\n",
    "            #print(\"That wasn't correct!\")\n",
    "            x$ds <- seq(as.Date('1901-01-01'), length.out=length(x$ds), by=1)\n",
    "        }\n",
    "        return(x)\n",
    "    }\n",
    "    \n",
    "    model <- prophet()\n",
    "\n",
    "    if (!is.null(xreg)) {\n",
    "        ### convert data for prophet\n",
    "        #x <- ifelse(is.null(dim(x)), data.frame(x), x) # not works\n",
    "        if (is.null(dim(x))) {x <- data.frame(x)}\n",
    "        colnames(x) <- 'y'\n",
    "        x.train <- cbind(x, xreg)\n",
    "        x.train <- as.data.frame(x.train)\n",
    "        x.train <- cbind(ds=rownames(x.train), x.train)\n",
    "        rownames(x.train) <- NULL\n",
    "        x.train <- check.ds(x.train)\n",
    "\n",
    "        ### add regressors before fitting\n",
    "        for (c in colnames(xreg)) {\n",
    "            model <- add_regressor(model, c)\n",
    "        }\n",
    "\n",
    "        ### fit: must run after add_regressor and before make_future_dataframe\n",
    "        model <- fit.prophet(model, x.train)\n",
    "\n",
    "        ### prepare future ds\n",
    "        future <- make_future_dataframe(model, periods=h)\n",
    "\n",
    "        # regessor assumption for future\n",
    "        if (is.null(xreg.msize)) {\n",
    "            xreg.m <- xreg # calc mean for future with all the xreg\n",
    "        } else {\n",
    "            # calc mean for future with xreg of length xreg.mszie\n",
    "            xreg.m <- tail(xreg, n=xreg.msize)\n",
    "        }\n",
    "        \n",
    "        if (is.null(dim(xreg))) {\n",
    "            xreg.h <- mean(xreg.m)\n",
    "        } else {\n",
    "            xreg.h <- colMeans(xreg.m)  \n",
    "        }\n",
    "\n",
    "        # rbind history & future of xreg\n",
    "        xreg.all <- data.frame(xreg)\n",
    "        xreg.coln <- colnames(xreg.all) # save name for the case of single xreg\n",
    "\n",
    "        xreg.h <- data.frame(xreg.h)\n",
    "        colnames(xreg.h) <- colnames(NA)\n",
    "        xreg.h <- t(xreg.h)\n",
    "        xreg.h <- as.ts(xreg.h[rep(seq_len(nrow(xreg.h)), h), ])\n",
    "        xreg.h <- data.frame(xreg.h) # convert to frame for the case of single xreg\n",
    "        \n",
    "        # update future\n",
    "        if ((dim(xreg.h)[2]==1) & (dim(xreg.h)[1]==length(xreg.coln))) {\n",
    "            xreg.h <- t(xreg.h) # the case of h==1\n",
    "        }\n",
    "        colnames(xreg.h) <- xreg.coln # match name to rbind\n",
    "        #xreg.all <- rbind(xreg.all, xreg.h)\n",
    "        xreg.all <- rbind(as.matrix(xreg.all), xreg.h) \n",
    "        xreg.all <- data.frame(xreg.all, row.names = NULL) \n",
    "        xreg.all$ds <- future$ds\n",
    "        future <- xreg.all\n",
    "\n",
    "    } else {\n",
    "        x.train <- data.frame(ds=index(x), y=as.numeric(x))\n",
    "        x.train <- check.ds(x.train)\n",
    "        model <- fit.prophet(model, x.train)\n",
    "        future <- make_future_dataframe(model, periods=h)\n",
    "    }\n",
    "\n",
    "    fc <- predict(model, future)\n",
    "    fc <- list(method = \"Prophet Forecasting\", mean=tail(fc$yhat, h),\n",
    "               model=model, pred=fc) # save model & pred result as well\n",
    "    return(fc)\n",
    "} \n",
    "\n",
    "prophet.forecast <- cv.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58748625-2a70-41e8-8e78-59a2a1b18b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast.2 <- function(x, h, ...) {\n",
    "    new.forecast(x, h, cv.forecast, ...)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e0fb38-d451-44d8-8834-ba4d69d19781",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dd96713-bac0-45e7-acee-91b3db181205",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "10 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "20 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "30 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "40 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "50 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "60 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "70 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "80 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "90 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m01.1 <- my.tsCV(train, cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                        silent=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ac8981d-15bf-408c-9638-7b4754cbf984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-01-24\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m01.1\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c1ddd0-be96-456c-878f-5386005d6092",
   "metadata": {},
   "source": [
    "## Additional regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5003bce6-1677-46e3-a84f-18b57b7872bc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "10 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "20 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "30 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "40 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "50 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "60 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "70 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "80 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "90 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m01.2 <- my.tsCV(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          xreg=trainx[,2:4],\n",
    "                          silent=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2d5fe22-e405-4131-96d3-1cf18723f552",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "10 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "20 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "30 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "40 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "50 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "60 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "70 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "80 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "90 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m01.3 <- my.tsCV(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          xreg=trainx[,3], \n",
    "                          silent=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ba326e3-2a59-4a52-ab62-c7b71ccb9ea8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "10 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "20 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "30 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "40 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "50 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "60 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "70 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "80 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "90 % done.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m01.4 <- my.tsCV(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                         xreg=trainx[,2:4],\n",
    "                         xreg.msize=hori)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfe1cb3-5728-4fd8-a0ef-2593535940f5",
   "metadata": {},
   "source": [
    "## Compare Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "729703b7-0e13-4ac8-9014-dbab6d2d5acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my.figsize(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88224355-62cb-4480-b79c-b2791413a8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94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\nrkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- new.get_result(result.m01.1, '1.Prophet')\n",
    "errors.2 <- new.get_result(result.m01.2, '2.Prophet with Regressors')\n",
    "errors.3 <- new.get_result(result.m01.3, '3.Prophet with 1 Regressor')\n",
    "errors.4 <- new.get_result(result.m01.4, '4.Prophet with Regressor (2)')\n",
    "\n",
    "x <- errors.1\n",
    "x <- rbind(x, errors.2)\n",
    "x <- rbind(x, errors.3)\n",
    "x <- rbind(x, errors.4)\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8351dcbc-33db-44ea-a47d-550e48cc6e6c",
   "metadata": {},
   "source": [
    "### save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b27ae32-b956-4e94-9aec-d07bfd72a72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- result.m01.1\n",
    "write.csv(x, file = \"prophet_result_m0101.csv\")\n",
    "x <- result.m01.2\n",
    "write.csv(x, file = \"prophet_result_m0102.csv\")\n",
    "x <- result.m01.3\n",
    "write.csv(x, file = \"prophet_result_m0103.csv\")\n",
    "x <- result.m01.4\n",
    "write.csv(x, file = \"prophet_result_m0104.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c5f45-45d6-4303-82e4-1a2f9d7fbd8c",
   "metadata": {},
   "source": [
    "### load result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2e2b68b-2e54-484a-9d72-6d74422bd9c6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.m01.1 <- read.csv(file = 'prophet_result_m0101.csv')\n",
    "result.m01.2 <- read.csv(file = 'prophet_result_m0102.csv')\n",
    "result.m01.3 <- read.csv(file = 'prophet_result_m0103.csv')\n",
    "result.m01.4 <- read.csv(file = 'prophet_result_m0104.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7cb8d98e-9491-400a-abd5-6a4694dfe9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m01 <- result.m01.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d38357-ca19-4a00-a9f3-88f56e5a4726",
   "metadata": {},
   "source": [
    "# BSTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b1a082-dca7-457f-a151-90f7518efe7a",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92d8cf60-d4b2-4d74-b586-01285de500da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast <- function(x, h, xreg=NULL, xreg.msize=NULL, expected.model.size=0,\n",
    "                        model=NULL, niter=1000, ...) \n",
    "{\n",
    "    if (!is.null(xreg)) {\n",
    "        ### set params for fitting\n",
    "        # organize data for fitting\n",
    "        if (is.null(dim(x))) {x <- data.frame(x)}\n",
    "        colnames(x) <- 'y'\n",
    "        x.train <- cbind(x, xreg)\n",
    "        x.train <- as.data.frame(x.train)\n",
    "        \n",
    "        if (is.null(model)) {\n",
    "            n <- ncol(x.train)\n",
    "            if ((expected.model.size < 1) | (expected.model.size > n)) {\n",
    "                expected.model.size <- n\n",
    "            }\n",
    "            ss <- AddSemilocalLinearTrend(list(), x.train$y)\n",
    "            model <- bsts(y ~ .,\n",
    "                          state.specification = ss,\n",
    "                          niter = niter,\n",
    "                          data = x.train,\n",
    "                          expected.model.size = expected.model.size)  # Passed to SpikeSlabPrior.\n",
    "            olddata <- NULL\n",
    "        } else {\n",
    "            olddata <- x.train\n",
    "        }\n",
    "        \n",
    "        ### set params for prediction\n",
    "        # regessor assumption for future\n",
    "        if (is.null(xreg.msize)) {\n",
    "            xreg.m <- xreg # calc mean for future with all the xreg\n",
    "        } else {\n",
    "            # calc mean for future with xreg of length xreg.mszie\n",
    "            xreg.m <- tail(xreg, n=xreg.msize)\n",
    "        }\n",
    "\n",
    "        if (is.null(dim(xreg))) {\n",
    "            xreg.h <- mean(xreg.m)\n",
    "        } else {\n",
    "            xreg.h <- colMeans(xreg.m)  \n",
    "        }\n",
    "\n",
    "        xreg.all <- data.frame(xreg)\n",
    "        xreg.coln <- colnames(xreg.all) # save name for the case of single xreg\n",
    "        xreg.h <- data.frame(xreg.h)\n",
    "        colnames(xreg.h) <- colnames(NA)\n",
    "        xreg.h <- t(xreg.h)\n",
    "        xreg.h <- as.ts(xreg.h[rep(seq_len(nrow(xreg.h)), h), ])\n",
    "        xreg.h <- data.frame(xreg.h) # convert to frame for the case of single xreg\n",
    "        \n",
    "        if ((dim(xreg.h)[2]==1) & (dim(xreg.h)[1]==length(xreg.coln))) {\n",
    "            xreg.h <- t(xreg.h) # the case of h==1\n",
    "        } else {\n",
    "            xreg.h <- as.ts(xreg.h) # convert to ts as xreg is ts\n",
    "        }\n",
    "        \n",
    "        colnames(xreg.h) <- xreg.coln # match name to rbind\n",
    "        \n",
    "    } else {\n",
    "        if (is.null(model)) {\n",
    "            ss <- AddSemilocalLinearTrend(list(), x)\n",
    "            model <- bsts(x, state.specification = ss, niter=niter, ...)\n",
    "            olddata <- NULL\n",
    "        } else {\n",
    "            olddata <- x\n",
    "        }\n",
    "        xreg.h <- NULL\n",
    "    }\n",
    "    # predict\n",
    "    fc <- predict(model, horizon=h, newdata=xreg.h, olddata=olddata)\n",
    "    fc$model <- model\n",
    "    return(fc)\n",
    "}\n",
    "\n",
    "bsts.forecast <- cv.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55107914-5b42-493c-b20b-c6b5d0d9b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast.2 <- function(x, h, ...) {\n",
    "    new.forecast(x, h, cv.forecast, ping=0, ...)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d8fc5f-8e48-4ea2-b707-e1f062d6b634",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0bae75e-ad34-40a9-aceb-7542fa7c13fd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n",
      "20 % done.\n",
      "\n",
      "30 % done.\n",
      "\n",
      "40 % done.\n",
      "\n",
      "50 % done.\n",
      "\n",
      "60 % done.\n",
      "\n",
      "70 % done.\n",
      "\n",
      "80 % done.\n",
      "\n",
      "90 % done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m02.1 <- my.tsCV(train, cv.forecast.2, h=hori, window=wind, step=peri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "602a90d7-2081-46eb-8cf8-ca09307501bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-01-24\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m02.1\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b296acaf-74d0-4185-b130-b6512bbf03be",
   "metadata": {},
   "source": [
    "## Regression with spike and slab priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ecce414-f5fc-4f70-9f89-4908c5fe4e9a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:50:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:50:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:50:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:50:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:51:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:51:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:51:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:51:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:51:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:51:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:51:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:51:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:51:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:51:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:51:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:51:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:51:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:51:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:51:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:51:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:52:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:52:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:52:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:52:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:52:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:52:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:52:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:52:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:52:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:52:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:52:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:52:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:52:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:52:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:52:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:52:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:52:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:53:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:53:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:53:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:53:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:53:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:53:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:53:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:53:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:53:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:53:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:53:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:53:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:53:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:53:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:53:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:53:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:54:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:54:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:54:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:54:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:54:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:54:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:54:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:54:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:54:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:54:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:54:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:54:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:54:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:54:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:54:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:54:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:54:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:55:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:55:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:55:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:55:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:55:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:55:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:55:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:55:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:55:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:55:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:55:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:55:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:55:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:55:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:55:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:55:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:55:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:56:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:56:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:56:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:56:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:56:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:56:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:56:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:56:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:56:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:56:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:56:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:56:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:56:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:56:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:56:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:56:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:57:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:57:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:57:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:57:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:57:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:57:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:57:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:57:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:57:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:57:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:57:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:57:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:57:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:57:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:57:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:57:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:57:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:58:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:58:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:58:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:58:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:58:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:58:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:58:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:58:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:58:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:58:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:58:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:58:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:58:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:58:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:58:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:58:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:59:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:59:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:59:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:59:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:59:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:59:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:59:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Mon Sep 26 23:59:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Mon Sep 26 23:59:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Mon Sep 26 23:59:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Mon Sep 26 23:59:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Mon Sep 26 23:59:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Mon Sep 26 23:59:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Mon Sep 26 23:59:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Mon Sep 26 23:59:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Mon Sep 26 23:59:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Mon Sep 26 23:59:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:00:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:00:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:00:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:00:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:00:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:00:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:00:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:00:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:00:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:00:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:00:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:00:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:00:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:00:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:00:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:00:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:01:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:01:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:01:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:01:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:01:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:01:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:01:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:01:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:01:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:01:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:01:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:01:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:01:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:01:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:01:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:01:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:01:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:02:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:02:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:02:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:02:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:02:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:02:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:02:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:02:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:02:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:02:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:02:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:02:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:02:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:02:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:02:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:02:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:03:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:03:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:03:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:03:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:03:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:03:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:03:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:03:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:03:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:03:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:03:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:03:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:03:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:03:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:03:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:03:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:03:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:04:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:04:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:04:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:04:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:04:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:04:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:04:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:04:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:04:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:04:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:04:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:04:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:04:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:04:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:04:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:04:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:05:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:05:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:05:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:05:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:05:15 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:05:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:05:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:05:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:05:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:05:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:05:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:05:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:05:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:05:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:05:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:05:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:05:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:06:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:06:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:06:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:06:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:06:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:06:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:06:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:06:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:06:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:06:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:06:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:06:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:06:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:06:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:06:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:06:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:06:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:07:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:07:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:07:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:07:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:07:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:07:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:07:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:07:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:07:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:07:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:07:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:07:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:07:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:07:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:07:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:07:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:08:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:08:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:08:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:08:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:08:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:08:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:08:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:08:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:08:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:08:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:08:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:08:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:08:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:08:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:08:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:08:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:09:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:09:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:09:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:09:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:09:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:09:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:09:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:09:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:09:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:09:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:09:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:09:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:09:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:09:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:09:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:09:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:09:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:10:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:10:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:10:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:10:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:10:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:10:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:10:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:10:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:10:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:10:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:10:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:10:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:10:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:10:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:10:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:10:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:10:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:11:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:11:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:11:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:11:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:11:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:11:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:11:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:11:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:11:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:11:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:11:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:11:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:11:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:11:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:11:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:11:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:12:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:12:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:12:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:12:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:12:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:12:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:12:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:12:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:12:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:12:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:12:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:12:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:12:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:12:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:12:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:12:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:12:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:13:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:13:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:13:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:13:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:13:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:13:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:13:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:13:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:13:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:13:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:13:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:13:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:13:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:13:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:13:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:13:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:14:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:14:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:14:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:14:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:14:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:14:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:14:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:14:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:14:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:14:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:14:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:14:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:14:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:14:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:14:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:14:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:14:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:15:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:15:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:15:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:15:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:15:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:15:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:15:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:15:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:15:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:15:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:15:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:15:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:15:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:15:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:15:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:15:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:15:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:16:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:16:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:16:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:16:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:16:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:16:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:16:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:16:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:16:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:16:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:16:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:16:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:16:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:16:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:16:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:16:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:17:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:17:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:17:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:17:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:17:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:17:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:17:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:17:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:17:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:17:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:17:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:17:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:17:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:17:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:17:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:17:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:17:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:18:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:18:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:18:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:18:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:18:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:18:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:18:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:18:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:18:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:18:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:18:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:18:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:18:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:18:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:18:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:18:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:19:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:19:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:19:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:19:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:19:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:19:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:19:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:19:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:19:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:19:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:19:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:19:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:19:43 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:19:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:19:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:19:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:19:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:20:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:20:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:20:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:20:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:20:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:20:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:20:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:20:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:20:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:20:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:20:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:20:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:20:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:20:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:20:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:20:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:20:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:21:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:21:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:21:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:21:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:21:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:21:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:21:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:21:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:21:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:21:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:21:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:21:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:21:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:21:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:21:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:21:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:22:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:22:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:22:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:22:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:22:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:22:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:22:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:22:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:22:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:22:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:22:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:22:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:22:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:22:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:22:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:22:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:22:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:23:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:23:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:23:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:23:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:23:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:23:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:23:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:23:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:23:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:23:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:23:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:23:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:23:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:23:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:23:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:23:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:23:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:24:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:24:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:24:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:24:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:24:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:24:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:24:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:24:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:24:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:24:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:24:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:24:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:24:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:24:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:24:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:24:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:25:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:25:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:25:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:25:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:25:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:25:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:25:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:25:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:25:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:25:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:25:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:25:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:25:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:25:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:25:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:25:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:25:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:26:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:26:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:26:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:26:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:26:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:26:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:26:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:26:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:26:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:26:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:26:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:26:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:26:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:26:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:26:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:26:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:27:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:27:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:27:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:27:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:27:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:27:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:27:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:27:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:27:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:27:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:27:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:27:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:27:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:27:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:27:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:27:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:27:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:28:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:28:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:28:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:28:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:28:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:28:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:28:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:28:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:28:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:28:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:28:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:28:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:28:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:28:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:28:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:28:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:28:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:29:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:29:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:29:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:29:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:29:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:29:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:29:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:29:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:29:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:29:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:29:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:29:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:29:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:29:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:29:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:29:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:30:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:30:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:30:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:30:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:30:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:30:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:30:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:30:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:30:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:30:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:30:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:30:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:30:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:30:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:30:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:30:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:31:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:31:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:31:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:31:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:31:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:31:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:31:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:31:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:31:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:31:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:31:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:31:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:31:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:31:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:31:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:31:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:31:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:32:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:32:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:32:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:32:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:32:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:32:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:32:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:32:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:32:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:32:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:32:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:32:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:32:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:32:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:32:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:32:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:32:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:33:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:33:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:33:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:33:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:33:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:33:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:33:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:33:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:33:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:33:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:33:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:33:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:33:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:33:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:33:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:33:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:34:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:34:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:34:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:34:11 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:34:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:34:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:34:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:34:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:34:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:34:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:34:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:34:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:34:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:34:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:34:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:34:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:34:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:35:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:35:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:35:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:35:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:35:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:35:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:35:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:35:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:35:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:35:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:35:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:35:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:35:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:35:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:35:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:35:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:36:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:36:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:36:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:36:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:36:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:36:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:36:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:36:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:36:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:36:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:36:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:36:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:36:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:36:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:36:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:36:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:36:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:37:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:37:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:37:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:37:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:37:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:37:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:37:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:37:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:37:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:37:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:37:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:37:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:37:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:37:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:37:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:37:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:37:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:38:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:38:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:38:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:38:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:38:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:38:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:38:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:38:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:38:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:38:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:38:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:38:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:38:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:38:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:38:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:38:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:39:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:39:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:39:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:39:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:39:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:39:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:39:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:39:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:39:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:39:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:39:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:39:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:39:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:39:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:39:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:39:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:39:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:40:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:40:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:40:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:40:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:40:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:40:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:40:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:40:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:40:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:40:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:40:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:40:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:40:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:40:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:40:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:40:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:41:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:41:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:41:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:41:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:41:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:41:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:41:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:41:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:41:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:41:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:41:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:41:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:41:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:41:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:41:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:41:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:41:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:42:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:42:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:42:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:42:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:42:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:42:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:42:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:42:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:42:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:42:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:42:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:42:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:42:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:42:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:42:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:42:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:42:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:43:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:43:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:43:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:43:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:43:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:43:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:43:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:43:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:43:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:43:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:43:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:43:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:43:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:43:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:43:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:43:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:44:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:44:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:44:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:44:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:44:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:44:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:44:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:44:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:44:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:44:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:44:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:44:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:44:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:44:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:44:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:44:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:44:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:45:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:45:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:45:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:45:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:45:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:45:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:45:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:45:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:45:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:45:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:45:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:45:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:45:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:45:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:45:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:45:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:45:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:46:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:46:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:46:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:46:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:46:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:46:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:46:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:46:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:46:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:46:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:46:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:46:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:46:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:46:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:46:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:46:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:47:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:47:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:47:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:47:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:47:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:47:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:47:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:47:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:47:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:47:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:47:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:47:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:47:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:47:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:47:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:47:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:47:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:48:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:48:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:48:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:48:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:48:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:48:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:48:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:48:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:48:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:48:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:48:38 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:48:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:48:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:48:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:48:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:48:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:48:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:49:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:49:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:49:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:49:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:49:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:49:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:49:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:49:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:49:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:49:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:49:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:49:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:49:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:49:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:49:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:49:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:50:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:50:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:50:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:50:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:50:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:50:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:50:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:50:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:50:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:50:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:50:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:50:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:50:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:50:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:50:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:50:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:50:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:51:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:51:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:51:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:51:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:51:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:51:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:51:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:51:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:51:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:51:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:51:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:51:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:51:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:51:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:51:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:51:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:52:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:52:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:52:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:52:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:52:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:52:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:52:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:52:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:52:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:52:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:52:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:52:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:52:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:52:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:52:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:52:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:52:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:53:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:53:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:53:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:53:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:53:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:53:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:53:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:53:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:53:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:53:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:53:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:53:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:53:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:53:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:53:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:53:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:54:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:54:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:54:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:54:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:54:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:54:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:54:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:54:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:54:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:54:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:54:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:54:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:54:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:54:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:54:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:54:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:54:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:55:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:55:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:55:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:55:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:55:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:55:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:55:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:55:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:55:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:55:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:55:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:55:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:55:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:55:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:55:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:55:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:55:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:56:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:56:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:56:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:56:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:56:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:56:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:56:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:56:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:56:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:56:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:56:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:56:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:56:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:56:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:56:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:56:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:57:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:57:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:57:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:57:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:57:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:57:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:57:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:57:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:57:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:57:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:57:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:57:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:57:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:57:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:57:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:57:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:57:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:58:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:58:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:58:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:58:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:58:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:58:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:58:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:58:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:58:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:58:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:58:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:58:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:58:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:58:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:58:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:58:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:59:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:59:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:59:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:59:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:59:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:59:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:59:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 00:59:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 00:59:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 00:59:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 00:59:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 00:59:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 00:59:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 00:59:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 00:59:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 00:59:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 00:59:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:00:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:00:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:00:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:00:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:00:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:00:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:00:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:00:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:00:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:00:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:00:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:00:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:00:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:00:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:00:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:00:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:00:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:01:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:01:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:01:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:01:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:01:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:01:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:01:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:01:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:01:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:01:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:01:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:01:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:01:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:01:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:01:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:01:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:02:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:02:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:02:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:02:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:02:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:02:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:02:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:02:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:02:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:02:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:02:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:02:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:02:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:02:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:02:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:02:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:02:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:03:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:03:05 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:03:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:03:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:03:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:03:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:03:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:03:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:03:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:03:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:03:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:03:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:03:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:03:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:03:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:03:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:03:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:04:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:04:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:04:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:04:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:04:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:04:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:04:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:04:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:04:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:04:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:04:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:04:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:04:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:04:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:04:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:04:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:05:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:05:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:05:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:05:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:05:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:05:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:05:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:05:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:05:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:05:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:05:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:05:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:05:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:05:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:05:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:05:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:05:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:06:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:06:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:06:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:06:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:06:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:06:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:06:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:06:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:06:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:06:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:06:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:06:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:06:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:06:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:06:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:06:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:07:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:07:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:07:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:07:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:07:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:07:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:07:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:07:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:07:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:07:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:07:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:07:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:07:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:07:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:07:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:07:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:07:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:08:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:08:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:08:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:08:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:08:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:08:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:08:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:08:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:08:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:08:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:08:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:08:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:08:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:08:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:08:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:08:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:08:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:09:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:09:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:09:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:09:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:09:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:09:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:09:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:09:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:09:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:09:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:09:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:09:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:09:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:09:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:09:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:09:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:10:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:10:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:10:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:10:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:10:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:10:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:10:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:10:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:10:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:10:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:10:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:10:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:10:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:10:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:10:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:10:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:10:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:11:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:11:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:11:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:11:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:11:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:11:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:11:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:11:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:11:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:11:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:11:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:11:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:11:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:11:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:11:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:11:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:12:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:12:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:12:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:12:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:12:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:12:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:12:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:12:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:12:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:12:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:12:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:12:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:12:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:12:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:12:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:12:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:12:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:13:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:13:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:13:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:13:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:13:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:13:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:13:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:13:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:13:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:13:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:13:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:13:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:13:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:13:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:13:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:13:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:14:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:14:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:14:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:14:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:14:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:14:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:14:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:14:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:14:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:14:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:14:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:14:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:14:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:14:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:14:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:14:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:14:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:15:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:15:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:15:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:15:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:15:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:15:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:15:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:15:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:15:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:15:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:15:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:15:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:15:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:15:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:15:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:15:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:16:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:16:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:16:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:16:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:16:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:16:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:16:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:16:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:16:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:16:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:16:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:16:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:16:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:16:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:16:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:16:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:16:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:17:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:17:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:17:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:17:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:17:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:17:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:17:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:17:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:17:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:17:34 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:17:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:17:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:17:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:17:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:17:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:17:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:17:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:18:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:18:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:18:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:18:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:18:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:18:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:18:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:18:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:18:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:18:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:18:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:18:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:18:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:18:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:18:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:18:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:19:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:19:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:19:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:19:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:19:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:19:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:19:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:19:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:19:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:19:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:19:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:19:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:19:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:19:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:19:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:19:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:19:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:20:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:20:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:20:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:20:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:20:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:20:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:20:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:20:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:20:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:20:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:20:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:20:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:20:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:20:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:20:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:20:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:21:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:21:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:21:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:21:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:21:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:21:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:21:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:21:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:21:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:21:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:21:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:21:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:21:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:21:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:21:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:21:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:21:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:22:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:22:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:22:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:22:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:22:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:22:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:22:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:22:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:22:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:22:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:22:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:22:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:22:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:22:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:22:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:22:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:23:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:23:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:23:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:23:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:23:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:23:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:23:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:23:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:23:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:23:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:23:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:23:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:23:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:23:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:23:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:23:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:23:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:24:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:24:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:24:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:24:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:24:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:24:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:24:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:24:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:24:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:24:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:24:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:24:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:24:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:24:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:24:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:24:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:25:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:25:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:25:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:25:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:25:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:25:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:25:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:25:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:25:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:25:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:25:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:25:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:25:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:25:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:25:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:25:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:25:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:26:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:26:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:26:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:26:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:26:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:26:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:26:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:26:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:26:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:26:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:26:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:26:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:26:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:26:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:26:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:26:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:26:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:27:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:27:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:27:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:27:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:27:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:27:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:27:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:27:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:27:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:27:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:27:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:27:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:27:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:27:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:27:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:27:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:28:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:28:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:28:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:28:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:28:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:28:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:28:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:28:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:28:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:28:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:28:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:28:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:28:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:28:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:28:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:28:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:28:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:29:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:29:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:29:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:29:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:29:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:29:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:29:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:29:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:29:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:29:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:29:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:29:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:29:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:29:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:29:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:29:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:29:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:30:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:30:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:30:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:30:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:30:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:30:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:30:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:30:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:30:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:30:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:30:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:30:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:30:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:30:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:30:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:30:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:31:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:31:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:31:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:31:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:31:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:31:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:31:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:31:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:31:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:31:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:31:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:31:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:31:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:31:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:31:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:31:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:31:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:32:00 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:32:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:32:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:32:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:32:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:32:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:32:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:32:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:32:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:32:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:32:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:32:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:32:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:32:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:32:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:32:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:32:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:33:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:33:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:33:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:33:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:33:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:33:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:33:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:33:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:33:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:33:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:33:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:33:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:33:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:33:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:33:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:33:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:34:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:34:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:34:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:34:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:34:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:34:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:34:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:34:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:34:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:34:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:34:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:34:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:34:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:34:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:34:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:34:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:34:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:35:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:35:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:35:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:35:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:35:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:35:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:35:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:35:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:35:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:35:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:35:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:35:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:35:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:35:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:35:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:35:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:35:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:36:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:36:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:36:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:36:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:36:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:36:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:36:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:36:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:36:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:36:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:36:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:36:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:36:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:36:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:36:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:36:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:37:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:37:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:37:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:37:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:37:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:37:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:37:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:37:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:37:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:37:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:37:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:37:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:37:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:37:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:37:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:37:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:37:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:38:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:38:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:38:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:38:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:38:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:38:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:38:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:38:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:38:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:38:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:38:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:38:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:38:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:38:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:38:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:38:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:39:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:39:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:39:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:39:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:39:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:39:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:39:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:39:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:39:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:39:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:39:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:39:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:39:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:39:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:39:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:39:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:39:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:40:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:40:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:40:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:40:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:40:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:40:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:40:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:40:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:40:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:40:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:40:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:40:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:40:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:40:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:40:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:40:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:40:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:41:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:41:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:41:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:41:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:41:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:41:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:41:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:41:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:41:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:41:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:41:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:41:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:41:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:41:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:41:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:41:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:41:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:42:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:42:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:42:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:42:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:42:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:42:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:42:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:42:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:42:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:42:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:42:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:42:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:42:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:42:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:42:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:42:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:43:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:43:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:43:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:43:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:43:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:43:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:43:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:43:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:43:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:43:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:43:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:43:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:43:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:43:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:43:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:43:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:43:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:44:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:44:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:44:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:44:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:44:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:44:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:44:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:44:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:44:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:44:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:44:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:44:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:44:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:44:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:44:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:44:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:44:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:45:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:45:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:45:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:45:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:45:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:45:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:45:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:45:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:45:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:45:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:45:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:45:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:45:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:45:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:45:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:45:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:46:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:46:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:46:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:46:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:46:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:46:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:46:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:46:26 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:46:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:46:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:46:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:46:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:46:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:46:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:46:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:46:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:46:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:47:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:47:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:47:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:47:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:47:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:47:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:47:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:47:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:47:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:47:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:47:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:47:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:47:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:47:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:47:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:47:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:48:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:48:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:48:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:48:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:48:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:48:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:48:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:48:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:48:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:48:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:48:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:48:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:48:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:48:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:48:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:48:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:48:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:49:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:49:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:49:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:49:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:49:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:49:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:49:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:49:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:49:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:49:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:49:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:49:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:49:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:49:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:49:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:49:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:49:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:50:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:50:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:50:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:50:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:50:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:50:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:50:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:50:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:50:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:50:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:50:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:50:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:50:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:50:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:50:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:50:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:51:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:51:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:51:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:51:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:51:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:51:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:51:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:51:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:51:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:51:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:51:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:51:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:51:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:51:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:51:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:51:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:51:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:52:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:52:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:52:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:52:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:52:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:52:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:52:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:52:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:52:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:52:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:52:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:52:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:52:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:52:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:52:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:52:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:52:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:53:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:53:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:53:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:53:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:53:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:53:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:53:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:53:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:53:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:53:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:53:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:53:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:53:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:53:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:53:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:53:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:54:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:54:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:54:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:54:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:54:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:54:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:54:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:54:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:54:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:54:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:54:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:54:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:54:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:54:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:54:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:54:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:54:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:55:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:55:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:55:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:55:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:55:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:55:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:55:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:55:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:55:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:55:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:55:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:55:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:55:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:55:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:55:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:55:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:55:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:56:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:56:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:56:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:56:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:56:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:56:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:56:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:56:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:56:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:56:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:56:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:56:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:56:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:56:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:56:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:56:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:57:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:57:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:57:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:57:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:57:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:57:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:57:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:57:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:57:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:57:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:57:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:57:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:57:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:57:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:57:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:57:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:57:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:58:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:58:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:58:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:58:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:58:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:58:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:58:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:58:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:58:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:58:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:58:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:58:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:58:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:58:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:58:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:58:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:58:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:59:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:59:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:59:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:59:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:59:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:59:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 01:59:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 01:59:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 01:59:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 01:59:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 01:59:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 01:59:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 01:59:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 01:59:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 01:59:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 01:59:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:00:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:00:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:00:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:00:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:00:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:00:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:00:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:00:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:00:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:00:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:00:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:00:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:00:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:00:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:00:52 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:00:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:01:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:01:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:01:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:01:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:01:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:01:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:01:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:01:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:01:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:01:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:01:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:01:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:01:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:01:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:01:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:01:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:01:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:02:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:02:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:02:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:02:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:02:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:02:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:02:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:02:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:02:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:02:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:02:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:02:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:02:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:02:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:02:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:02:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:02:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:03:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:03:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:03:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:03:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:03:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:03:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:03:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:03:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:03:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:03:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:03:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:03:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:03:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:03:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:03:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:03:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:03:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:04:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:04:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:04:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:04:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:04:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:04:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:04:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:04:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:04:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:04:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:04:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:04:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:04:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:04:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:04:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:04:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:05:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:05:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:05:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:05:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:05:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:05:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:05:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:05:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:05:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:05:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:05:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:05:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:05:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:05:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:05:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:05:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:05:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:06:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:06:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:06:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:06:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:06:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:06:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:06:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:06:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:06:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:06:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:06:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:06:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:06:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:06:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:06:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:06:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:07:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:07:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:07:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:07:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:07:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:07:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:07:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:07:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:07:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:07:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:07:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:07:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:07:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:07:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:07:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:07:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:07:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:08:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:08:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:08:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:08:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:08:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:08:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:08:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:08:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:08:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:08:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:08:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:08:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:08:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:08:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:08:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:08:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:08:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:09:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:09:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:09:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:09:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:09:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:09:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:09:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:09:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:09:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:09:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:09:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:09:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:09:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:09:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:09:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:09:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:10:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:10:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:10:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:10:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:10:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:10:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:10:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:10:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:10:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:10:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:10:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:10:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:10:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:10:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:10:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:10:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:10:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:11:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:11:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:11:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:11:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:11:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:11:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:11:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:11:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:11:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:11:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:11:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:11:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:11:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:11:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:11:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:11:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:11:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:12:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:12:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:12:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:12:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:12:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:12:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:12:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:12:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:12:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:12:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:12:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:12:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:12:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:12:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:12:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:12:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:13:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:13:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:13:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:13:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:13:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:13:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:13:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:13:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:13:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:13:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:13:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:13:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:13:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:13:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:13:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:13:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:13:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:14:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:14:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:14:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:14:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:14:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:14:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:14:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:14:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:14:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:14:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:14:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:14:41 2022 =-=-=-=-=\n"
     ]
    }
   ],
   "source": [
    "result.m02.2 <- my.tsCV(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                        xreg=trainx[,2:4], \n",
    "                        silent=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb72044a-8da0-45cc-8d68-0119fe090cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-02-09\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m02.2\n",
    "from <- x[!is.na(x[,'forecast_start']),][,1][1]\n",
    "from <- index(trainx[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc2e74d7-8d59-4a62-be63-137bc65d7e26",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:14:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:14:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:14:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:14:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:14:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:15:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:15:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:15:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:15:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:15:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:15:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:15:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:15:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:15:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:15:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:15:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:15:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:15:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:15:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:15:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:15:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:16:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:16:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:16:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:16:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:16:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:16:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:16:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:16:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:16:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:16:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:16:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:16:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:16:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:16:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:16:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:16:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:16:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:17:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:17:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:17:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:17:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:17:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:17:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:17:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:17:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:17:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:17:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:17:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:17:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:17:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:17:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:17:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:17:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:18:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:18:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:18:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:18:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:18:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:18:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:18:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:18:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:18:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:18:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:18:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:18:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:18:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:18:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:18:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:18:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:18:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:19:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:19:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:19:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:19:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:19:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:19:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:19:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:19:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:19:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:19:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:19:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:19:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:19:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:19:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:19:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:19:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:19:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:20:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:20:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:20:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:20:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:20:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:20:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:20:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:20:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:20:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:20:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:20:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:20:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:20:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:20:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:20:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:20:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:21:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:21:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:21:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:21:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:21:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:21:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:21:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:21:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:21:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:21:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:21:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:21:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:21:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:21:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:21:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:21:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:21:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:22:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:22:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:22:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:22:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:22:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:22:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:22:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:22:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:22:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:22:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:22:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:22:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:22:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:22:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:22:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:22:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:22:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:23:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:23:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:23:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:23:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:23:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:23:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:23:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:23:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:23:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:23:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:23:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:23:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:23:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:23:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:23:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:23:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:24:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:24:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:24:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:24:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:24:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:24:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:24:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:24:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:24:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:24:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:24:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:24:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:24:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:24:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:24:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:24:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:24:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:25:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:25:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:25:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:25:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:25:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:25:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:25:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:25:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:25:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:25:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:25:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:25:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:25:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:25:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:25:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:25:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:25:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:26:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:26:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:26:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:26:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:26:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:26:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:26:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:26:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:26:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:26:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:26:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:26:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:26:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:26:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:26:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:26:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:27:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:27:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:27:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:27:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:27:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:27:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:27:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:27:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:27:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:27:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:27:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:27:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:27:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:27:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:27:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:27:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:27:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:28:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:28:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:28:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:28:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:28:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:28:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:28:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:28:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:28:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:28:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:28:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:28:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:28:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:28:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:28:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:28:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:29:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:29:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:29:07 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:29:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:29:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:29:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:29:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:29:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:29:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:29:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:29:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:29:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:29:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:29:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:29:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:29:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:29:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:30:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:30:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:30:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:30:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:30:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:30:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:30:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:30:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:30:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:30:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:30:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:30:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:30:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:30:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:30:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:30:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:30:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:31:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:31:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:31:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:31:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:31:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:31:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:31:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:31:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:31:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:31:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:31:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:31:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:31:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:31:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:31:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:31:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:32:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:32:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:32:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:32:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:32:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:32:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:32:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:32:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:32:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:32:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:32:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:32:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:32:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:32:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:32:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:32:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:32:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:33:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:33:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:33:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:33:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:33:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:33:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:33:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:33:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:33:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:33:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:33:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:33:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:33:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:33:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:33:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:33:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:34:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:34:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:34:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:34:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:34:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:34:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:34:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:34:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:34:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:34:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:34:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:34:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:34:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:34:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:34:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:34:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:34:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:35:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:35:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:35:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:35:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:35:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:35:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:35:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:35:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:35:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:35:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:35:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:35:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:35:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:35:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:35:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:35:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:35:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:36:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:36:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:36:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:36:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:36:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:36:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:36:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:36:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:36:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:36:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:36:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:36:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:36:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:36:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:36:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:36:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:37:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:37:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:37:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:37:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:37:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:37:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:37:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:37:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:37:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:37:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:37:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:37:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:37:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:37:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:37:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:37:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:37:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:38:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:38:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:38:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:38:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:38:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:38:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:38:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:38:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:38:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:38:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:38:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:38:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:38:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:38:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:38:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:38:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:38:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:39:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:39:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:39:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:39:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:39:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:39:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:39:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:39:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:39:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:39:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:39:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:39:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:39:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:39:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:39:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:39:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:40:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:40:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:40:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:40:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:40:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:40:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:40:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:40:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:40:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:40:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:40:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:40:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:40:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:40:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:40:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:40:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:40:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:41:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:41:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:41:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:41:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:41:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:41:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:41:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:41:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:41:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:41:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:41:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:41:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:41:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:41:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:41:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:41:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:41:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:42:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:42:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:42:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:42:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:42:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:42:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:42:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:42:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:42:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:42:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:42:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:42:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:42:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:42:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:42:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:42:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:43:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:43:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:43:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:43:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:43:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:43:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:43:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:43:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:43:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:43:32 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:43:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:43:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:43:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:43:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:43:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:43:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:43:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:44:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:44:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:44:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:44:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:44:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:44:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:44:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:44:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:44:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:44:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:44:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:44:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:44:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:44:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:44:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:44:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:44:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:45:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:45:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:45:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:45:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:45:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:45:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:45:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:45:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:45:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:45:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:45:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:45:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:45:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:45:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:45:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:45:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:46:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:46:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:46:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:46:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:46:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:46:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:46:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:46:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:46:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:46:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:46:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:46:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:46:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:46:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:46:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:46:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:46:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:47:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:47:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:47:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:47:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:47:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:47:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:47:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:47:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:47:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:47:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:47:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:47:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:47:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:47:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:47:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:47:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:48:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:48:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:48:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:48:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:48:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:48:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:48:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:48:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:48:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:48:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:48:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:48:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:48:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:48:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:48:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:48:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:48:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:49:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:49:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:49:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:49:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:49:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:49:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:49:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:49:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:49:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:49:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:49:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:49:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:49:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:49:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:49:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:49:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:49:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:50:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:50:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:50:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:50:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:50:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:50:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:50:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:50:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:50:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:50:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:50:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:50:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:50:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:50:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:50:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:50:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:50:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:51:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:51:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:51:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:51:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:51:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:51:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:51:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:51:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:51:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:51:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:51:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:51:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:51:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:51:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:51:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:51:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:52:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:52:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:52:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:52:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:52:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:52:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:52:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:52:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:52:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:52:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:52:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:52:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:52:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:52:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:52:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:52:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:52:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:53:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:53:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:53:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:53:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:53:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:53:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:53:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:53:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:53:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:53:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:53:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:53:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:53:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:53:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:53:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:53:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:54:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:54:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:54:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:54:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:54:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:54:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:54:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:54:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:54:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:54:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:54:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:54:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:54:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:54:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:54:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:54:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:54:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:55:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:55:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:55:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:55:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:55:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:55:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:55:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:55:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:55:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:55:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:55:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:55:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:55:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:55:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:55:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:55:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:55:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:56:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:56:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:56:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:56:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:56:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:56:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:56:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:56:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:56:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:56:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:56:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:56:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:56:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:56:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:56:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:56:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:57:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:57:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:57:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:57:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:57:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:57:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:57:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:57:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:57:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:57:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:57:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:57:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:57:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:57:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:57:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:57:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:57:58 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:58:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:58:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:58:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:58:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:58:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:58:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:58:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:58:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:58:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:58:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:58:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:58:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:58:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:58:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:58:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:58:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:58:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:59:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:59:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:59:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:59:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:59:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:59:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 02:59:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 02:59:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 02:59:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 02:59:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 02:59:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 02:59:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 02:59:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 02:59:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 02:59:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 02:59:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:00:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:00:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:00:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:00:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:00:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:00:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:00:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:00:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:00:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:00:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:00:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:00:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:00:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:00:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:00:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:00:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:00:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:01:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:01:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:01:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:01:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:01:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:01:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:01:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:01:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:01:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:01:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:01:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:01:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:01:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:01:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:01:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:01:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:02:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:02:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:02:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:02:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:02:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:02:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:02:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:02:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:02:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:02:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:02:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:02:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:02:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:02:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:02:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:02:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:02:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:03:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:03:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:03:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:03:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:03:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:03:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:03:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:03:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:03:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:03:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:03:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:03:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:03:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:03:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:03:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:03:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:03:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:04:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:04:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:04:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:04:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:04:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:04:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:04:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:04:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:04:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:04:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:04:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:04:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:04:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:04:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:04:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:04:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:05:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:05:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:05:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:05:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:05:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:05:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:05:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:05:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:05:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:05:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:05:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:05:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:05:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:05:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:05:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:05:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:05:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:06:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:06:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:06:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:06:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:06:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:06:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:06:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:06:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:06:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:06:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:06:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:06:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:06:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:06:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:06:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:06:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:06:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:07:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:07:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:07:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:07:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:07:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:07:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:07:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:07:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:07:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:07:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:07:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:07:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:07:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:07:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:07:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:07:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:08:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:08:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:08:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:08:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:08:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:08:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:08:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:08:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:08:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:08:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:08:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:08:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:08:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:08:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:08:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:08:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:08:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:09:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:09:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:09:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:09:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:09:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:09:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:09:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:09:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:09:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:09:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:09:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:09:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:09:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:09:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:09:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:09:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:10:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:10:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:10:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:10:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:10:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:10:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:10:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:10:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:10:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:10:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:10:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:10:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:10:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:10:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:10:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:10:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:10:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:11:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:11:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:11:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:11:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:11:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:11:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:11:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:11:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:11:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:11:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:11:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:11:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:11:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:11:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:11:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:11:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:11:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:12:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:12:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:12:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:12:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:12:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:12:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:12:24 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:12:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:12:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:12:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:12:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:12:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:12:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:12:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:12:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:12:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:13:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:13:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:13:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:13:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:13:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:13:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:13:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:13:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:13:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:13:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:13:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:13:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:13:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:13:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:13:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:13:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:13:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:14:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:14:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:14:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:14:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:14:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:14:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:14:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:14:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:14:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:14:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:14:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:14:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:14:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:14:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:14:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:14:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:15:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:15:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:15:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:15:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:15:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:15:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:15:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:15:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:15:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:15:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:15:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:15:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:15:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:15:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:15:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:15:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:15:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:16:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:16:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:16:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:16:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:16:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:16:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:16:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:16:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:16:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:16:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:16:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:16:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:16:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:16:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:16:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:16:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:17:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:17:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:17:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:17:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:17:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:17:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:17:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:17:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:17:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:17:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:17:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:17:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:17:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:17:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:17:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:17:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:17:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:18:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:18:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:18:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:18:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:18:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:18:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:18:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:18:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:18:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:18:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:18:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:18:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:18:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:18:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:18:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:18:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:18:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:19:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:19:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:19:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:19:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:19:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:19:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:19:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:19:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:19:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:19:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:19:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:19:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:19:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:19:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:19:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:19:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:20:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:20:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:20:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:20:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:20:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:20:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:20:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:20:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:20:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:20:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:20:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:20:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:20:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:20:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:20:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:20:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:20:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:21:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:21:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:21:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:21:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:21:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:21:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:21:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:21:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:21:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:21:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:21:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:21:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:21:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:21:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:21:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:21:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:21:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:22:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:22:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:22:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:22:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:22:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:22:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:22:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:22:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:22:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:22:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:22:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:22:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:22:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:22:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:22:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:22:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:23:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:23:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:23:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:23:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:23:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:23:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:23:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:23:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:23:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:23:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:23:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:23:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:23:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:23:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:23:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:23:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:23:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:24:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:24:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:24:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:24:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:24:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:24:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:24:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:24:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:24:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:24:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:24:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:24:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:24:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:24:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:24:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:24:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:25:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:25:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:25:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:25:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:25:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:25:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:25:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:25:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:25:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:25:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:25:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:25:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:25:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:25:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:25:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:25:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:25:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:26:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:26:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:26:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:26:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:26:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:26:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:26:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:26:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:26:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:26:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:26:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:26:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:26:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:26:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:26:51 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:26:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:26:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:27:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:27:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:27:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:27:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:27:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:27:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:27:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:27:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:27:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:27:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:27:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:27:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:27:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:27:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:27:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:27:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:28:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:28:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:28:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:28:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:28:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:28:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:28:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:28:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:28:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:28:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:28:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:28:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:28:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:28:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:28:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:28:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:28:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:29:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:29:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:29:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:29:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:29:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:29:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:29:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:29:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:29:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:29:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:29:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:29:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:29:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:29:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:29:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:29:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:29:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:30:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:30:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:30:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:30:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:30:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:30:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:30:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:30:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:30:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:30:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:30:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:30:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:30:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:30:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:30:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:30:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:31:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:31:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:31:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:31:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:31:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:31:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:31:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:31:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:31:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:31:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:31:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:31:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:31:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:31:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:31:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:31:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:31:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:32:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:32:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:32:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:32:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:32:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:32:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:32:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:32:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:32:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:32:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:32:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:32:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:32:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:32:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:32:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:32:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:32:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:33:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:33:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:33:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:33:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:33:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:33:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:33:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:33:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:33:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:33:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:33:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:33:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:33:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:33:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:33:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:33:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:34:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:34:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:34:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:34:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:34:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:34:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:34:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:34:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:34:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:34:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:34:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:34:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:34:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:34:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:34:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:34:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:34:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:35:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:35:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:35:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:35:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:35:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:35:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:35:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:35:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:35:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:35:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:35:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:35:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:35:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:35:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:35:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:35:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:36:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:36:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:36:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:36:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:36:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:36:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:36:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:36:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:36:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:36:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:36:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:36:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:36:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:36:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:36:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:36:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:36:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:37:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:37:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:37:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:37:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:37:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:37:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:37:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:37:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:37:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:37:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:37:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:37:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:37:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:37:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:37:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:37:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:37:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:38:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:38:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:38:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:38:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:38:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:38:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:38:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:38:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:38:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:38:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:38:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:38:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:38:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:38:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:38:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:38:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:39:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:39:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:39:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:39:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:39:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:39:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:39:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:39:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:39:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:39:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:39:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:39:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:39:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:39:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:39:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:39:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:39:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:40:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:40:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:40:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:40:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:40:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:40:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:40:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:40:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:40:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:40:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:40:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:40:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:40:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:40:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:40:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:40:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:41:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:41:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:41:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:41:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:41:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:41:19 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:41:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:41:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:41:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:41:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:41:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:41:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:41:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:41:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:41:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:41:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:41:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:42:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:42:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:42:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:42:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:42:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:42:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:42:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:42:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:42:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:42:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:42:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:42:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:42:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:42:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:42:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:42:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:43:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:43:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:43:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:43:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:43:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:43:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:43:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:43:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:43:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:43:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:43:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:43:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:43:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:43:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:43:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:43:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:43:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:44:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:44:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:44:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:44:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:44:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:44:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:44:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:44:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:44:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:44:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:44:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:44:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:44:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:44:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:44:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:44:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:45:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:45:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:45:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:45:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:45:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:45:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:45:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:45:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:45:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:45:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:45:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:45:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:45:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:45:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:45:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:45:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:45:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:46:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:46:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:46:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:46:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:46:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:46:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:46:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:46:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:46:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:46:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:46:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:46:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:46:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:46:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:46:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:46:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:46:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:47:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:47:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:47:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:47:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:47:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:47:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:47:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:47:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:47:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:47:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:47:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:47:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:47:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:47:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:47:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:47:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:48:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:48:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:48:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:48:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:48:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:48:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:48:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:48:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:48:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:48:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:48:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:48:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:48:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:48:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:48:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:48:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:48:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:49:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:49:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:49:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:49:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:49:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:49:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:49:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:49:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:49:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:49:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:49:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:49:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:49:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:49:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:49:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:49:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:50:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:50:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:50:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:50:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:50:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:50:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:50:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:50:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:50:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:50:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:50:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:50:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:50:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:50:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:50:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:50:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:50:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:51:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:51:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:51:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:51:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:51:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:51:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:51:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:51:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:51:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:51:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:51:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:51:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:51:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:51:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:51:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:51:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:51:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:52:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:52:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:52:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:52:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:52:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:52:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:52:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:52:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:52:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:52:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:52:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:52:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:52:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:52:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:52:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:52:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:53:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:53:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:53:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:53:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:53:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:53:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:53:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:53:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:53:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:53:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:53:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:53:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:53:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:53:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:53:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:53:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:53:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:54:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:54:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:54:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:54:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:54:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:54:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:54:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:54:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:54:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:54:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:54:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:54:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:54:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:54:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:54:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:54:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:55:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:55:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:55:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:55:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:55:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:55:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:55:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:55:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:55:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:55:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:55:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:55:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:55:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:55:47 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:55:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:55:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:55:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:56:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:56:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:56:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:56:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:56:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:56:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:56:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:56:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:56:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:56:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:56:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:56:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:56:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:56:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:56:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:56:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:56:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:57:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:57:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:57:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:57:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:57:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:57:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:57:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:57:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:57:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:57:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:57:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:57:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:57:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:57:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:57:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:57:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:58:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:58:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:58:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:58:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:58:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:58:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:58:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:58:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:58:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:58:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:58:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:58:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:58:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:58:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:58:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:58:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:58:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:59:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:59:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:59:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:59:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:59:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:59:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:59:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 03:59:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 03:59:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 03:59:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 03:59:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 03:59:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 03:59:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 03:59:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 03:59:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 03:59:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 03:59:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:00:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:00:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:00:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:00:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:00:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:00:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:00:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:00:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:00:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:00:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:00:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:00:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:00:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:00:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:00:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:00:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:01:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:01:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:01:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:01:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:01:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:01:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:01:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:01:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:01:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:01:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:01:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:01:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:01:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:01:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:01:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:01:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:01:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:02:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:02:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:02:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:02:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:02:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:02:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:02:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:02:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:02:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:02:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:02:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:02:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:02:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:02:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:02:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:02:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:03:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:03:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:03:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:03:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:03:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:03:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:03:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:03:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:03:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:03:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:03:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:03:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:03:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:03:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:03:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:03:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:03:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:04:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:04:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:04:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:04:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:04:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:04:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:04:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:04:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:04:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:04:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:04:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:04:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:04:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:04:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:04:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:04:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:04:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:05:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:05:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:05:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:05:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:05:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:05:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:05:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:05:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:05:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:05:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:05:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:05:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:05:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:05:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:05:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:05:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:06:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:06:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:06:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:06:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:06:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:06:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:06:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:06:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:06:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:06:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:06:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:06:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:06:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:06:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:06:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:06:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:06:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:07:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:07:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:07:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:07:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:07:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:07:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:07:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:07:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:07:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:07:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:07:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:07:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:07:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:07:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:07:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:07:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:07:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:08:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:08:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:08:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:08:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:08:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:08:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:08:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:08:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:08:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:08:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:08:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:08:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:08:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:08:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:08:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:08:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:08:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:09:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:09:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:09:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:09:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:09:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:09:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:09:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:09:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:09:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:09:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:09:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:09:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:09:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:09:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:09:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:09:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:10:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:10:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:10:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:10:12 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:10:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:10:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:10:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:10:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:10:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:10:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:10:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:10:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:10:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:10:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:10:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:10:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:10:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:11:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:11:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:11:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:11:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:11:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:11:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:11:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:11:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:11:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:11:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:11:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:11:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:11:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:11:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:11:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:11:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:12:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:12:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:12:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:12:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:12:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:12:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:12:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:12:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:12:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:12:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:12:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:12:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:12:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:12:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:12:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:12:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:12:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:13:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:13:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:13:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:13:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:13:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:13:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:13:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:13:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:13:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:13:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:13:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:13:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:13:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:13:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:13:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:13:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:14:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:14:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:14:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:14:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:14:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:14:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:14:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:14:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:14:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:14:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:14:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:14:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:14:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:14:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:14:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:14:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:14:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:15:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:15:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:15:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:15:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:15:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:15:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:15:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:15:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:15:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:15:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:15:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:15:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:15:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:15:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:15:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:15:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:15:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:16:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:16:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:16:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:16:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:16:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:16:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:16:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:16:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:16:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:16:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:16:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:16:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:16:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:16:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:16:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:16:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:17:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:17:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:17:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:17:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:17:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:17:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:17:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:17:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:17:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:17:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:17:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:17:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:17:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:17:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:17:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:17:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:17:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:18:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:18:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:18:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:18:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:18:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:18:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:18:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:18:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:18:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:18:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:18:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:18:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:18:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:18:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:18:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:18:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:18:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:19:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:19:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:19:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:19:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:19:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:19:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:19:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:19:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:19:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:19:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:19:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:19:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:19:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:19:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:19:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:19:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:20:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:20:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:20:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:20:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:20:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:20:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:20:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:20:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:20:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:20:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:20:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:20:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:20:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:20:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:20:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:20:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:20:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:21:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:21:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:21:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:21:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:21:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:21:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:21:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:21:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:21:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:21:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:21:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:21:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:21:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:21:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:21:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:21:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:22:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:22:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:22:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:22:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:22:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:22:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:22:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:22:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:22:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:22:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:22:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:22:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:22:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:22:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:22:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:22:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:22:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:23:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:23:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:23:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:23:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:23:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:23:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:23:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:23:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:23:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:23:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:23:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:23:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:23:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:23:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:23:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:23:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:23:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:24:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:24:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:24:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:24:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:24:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:24:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:24:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:24:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:24:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:24:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:24:38 2022 =-=-=-=-=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:24:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:24:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:24:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:24:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:24:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:25:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:25:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:25:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:25:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:25:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:25:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:25:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:25:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:25:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:25:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:25:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:25:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:25:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:25:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:25:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:25:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:25:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:26:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:26:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:26:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:26:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:26:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:26:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:26:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:26:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:26:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:26:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:26:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:26:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:26:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:26:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:26:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:26:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:26:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:27:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:27:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:27:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:27:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:27:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:27:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:27:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:27:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:27:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:27:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:27:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:27:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:27:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:27:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:27:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:27:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:28:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:28:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:28:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:28:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:28:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:28:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:28:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:28:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:28:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:28:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:28:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:28:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:28:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:28:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:28:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:28:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:28:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:29:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:29:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:29:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:29:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:29:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:29:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:29:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:29:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:29:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:29:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:29:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:29:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:29:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:29:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:29:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:29:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:30:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:30:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:30:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:30:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:30:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:30:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:30:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:30:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:30:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:30:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:30:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:30:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:30:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:30:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:30:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:30:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:30:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:31:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:31:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:31:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:31:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:31:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:31:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:31:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:31:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:31:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:31:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:31:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:31:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:31:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:31:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:31:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:31:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:31:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:32:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:32:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:32:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:32:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:32:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:32:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:32:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:32:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:32:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:32:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:32:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:32:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:32:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:32:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:32:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:32:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:33:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:33:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:33:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:33:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:33:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:33:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:33:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:33:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:33:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:33:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:33:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:33:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:33:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:33:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:33:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:33:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:33:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:34:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:34:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:34:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:34:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:34:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:34:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:34:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:34:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:34:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:34:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:34:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:34:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:34:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:34:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:34:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:34:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:35:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:35:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:35:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:35:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:35:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:35:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:35:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:35:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:35:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:35:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:35:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:35:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:35:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:35:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:35:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:35:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:35:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:36:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:36:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:36:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:36:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:36:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:36:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:36:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:36:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:36:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:36:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:36:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:36:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:36:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:36:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:36:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:36:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:36:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:37:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:37:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:37:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:37:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:37:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:37:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:37:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:37:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:37:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:37:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:37:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:37:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:37:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:37:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:37:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Tue Sep 27 04:37:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Tue Sep 27 04:38:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Tue Sep 27 04:38:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Tue Sep 27 04:38:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Tue Sep 27 04:38:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Tue Sep 27 04:38:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Tue Sep 27 04:38:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Tue Sep 27 04:38:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Tue Sep 27 04:38:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Tue Sep 27 04:38:29 2022 =-=-=-=-=\n"
     ]
    }
   ],
   "source": [
    "result.m02.3 <- my.tsCV(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                        xreg=trainx[,2:4], silent=F,\n",
    "                        xreg.msize=hori)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc65fefd-60b9-4ab4-a840-d24018cef2fc",
   "metadata": {},
   "source": [
    "## Compare Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58355e11-c950-44f5-b241-665c8d6aa2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my.figsize(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f874535-9c29-405a-add4-9bbce090b23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94\nAAAgAElEQVR4nOzdeVxU1f/H8TMzLLKvsgioGK4oSrhvpIkLmqnlnlu2uORSampqmFsWFpim\nuZRrqWXpzyV3M7XcUtMUSXADwQ2RYYcZZn5/TM2XAHFAhhHu6/noD+6559z5jHnHeXPPPVem\n1WoFAAAAAEB65KYuAAAAAABgGgRCAAAAAJAoAiEAAAAASBSBEAAAAAAkikAIAAAAABJFIAQA\nAAAAiSIQAgAAAIBEEQgBAAAAQKLMTF1A2UhLS1Or1aauAuXE2tra3Nw8LS1No9GYuhagIpHJ\nZPb29mq1OiMjw9S1ABWMpaVllSpVMjMzVSqVqWtBOXFycjJ1CUB5qCSBUKPR5OXlmboKlB+5\nXJ6Xl0cgBEpEJpPJ5XIhBB+YQElptVq5XK7Vajl9AFQyTBkFAAAAAIkiEAIAAACARBEIAQAA\nAECiCIQAAAAAIFEEQgAAAACQKAIhAAAAAEiUcR87kZ6evnLlyjNnzqjV6oYNG44ePdrNza1A\nn/j4+DVr1kRHR2s0Gl9f32HDhtWrV8/AsQAAAACAUjPuFcLIyMi4uLi5c+dGREQoFIo5c+YU\neHCcSqWaOXOmnZ1deHh4RESEu7v77Nmzs7KyDBkLAAAAAHgaRgyESUlJp0+fHj9+vJ+fn7e3\n98SJExMSEi5cuJC/T2ZmZq9evUaNGuXl5eXp6dm3b9/MzMy7d+8aMhYAAAAA8DSMGAhjYmIs\nLCx8fX11m7a2tj4+PjExMfn7ODg49O7d28rKSgiRlpa2Y8cOb29vb29vQ8YCAAAAAJ6GEe8h\nTE1NtbOzk8lk+hYHBwelUlm4p0ajefXVV9Vqtb+//7x588zNzZ849uTJkx9//LF+86OPPmrU\nqJFx3geeOXK5XAjh4OBg6kKACsnc3NzJycnUVQAVjO47iY2NjbW1talrAYCyZNxFZfInOiGE\nVqstsptcLl+8eHFKSsqOHTtmzJixaNGiJ45Vq9VpaWn6zby8PF1IgBTo/m7wfxwoHZlMxukD\nlI5MJivw/QQAKjojBkJHR8fU1FStVqv/6FQqlY/7tbSPj4+Pj0+DBg2GDh165MgRV1fX4se2\nbdv28OHD+k2lUvnw4UOjvRU8W+zs7CwtLR89esQ6Q0CJyGQyFxeX3Nzc1NRUU9cCVDBWVlY2\nNjbp6ek5OTmmrgXlxNXV1dQlAOXBiL8krlOnjkqlio2N1W0qlcr4+HjdIyX0Lly48NZbb2Vn\nZ/9TjVwuk8m0Wq0hYwEAAAAAT8OIgdDJyalNmzZLliyJjY2Nj4///PPP/fz8/P39hRAHDhzY\nuXOnEMLPzy8nJ2fx4sXx8fF3795dvXp1dnb2888/X8xYAAAAAECZkD3uvr4ykZmZuWrVqhMn\nTmg0msDAwFGjRummfYaHh6emps6dO1cIcevWrXXr1v399995eXk1atQYPHhwQEBAMWOLpFQq\nVSqV8d4Inim6KaPJyclMGQVKhCmjQKnppoympaUxZVQ6mDIKiTBuICw3BEJJIRACpUMgBEqN\nQChBBEJIBAvNAQAAAIBEEQgBAAAAQKIIhAAAAAAgUQRCAAAAAJAoAiEAAAAASBSBEAAAAAAk\nikAIAAAAABJlZuoCAAAAnmlXr149ePBgcnKyu7t7aGiol5eXqSsCgDJDIAQAAHisvXv3RkZG\n6jd37Ngxe/bsoKAgE5YEAGWIKaMAAABFe/jw4fLly/O3qFSqRYsWqVQqU5UEAGWLQAgAAFC0\nv/76Kycnp0Djo0ePYmNjTVIPAJQ5AiEAAEDRHnclUK1Wl3MlAGAkBEIAAICi1atXr3CjhYXF\nc889V/7FAIAxEAgBAACK5uPj88orrxRofPPNN62trU1SDwCUOVYZBQAAeKyRI0d6e3vv37//\n/v373t7eL7/8cuvWrU1dFACUGZlWqzV1DWVAqVSy3pd02NnZWVpaJicnazQaU9cCVCQymczF\nxSU3Nzc1NdXUtQAVjJWVlY2NTVpaWuE1ZlBZubq6mroEoDwwZRQAAAAAJIpACAAAAAASRSAE\nAAAAAIkiEAIAAACARBEIAQAAAECiCIQAAAAAIFEEQgAAAACQKAIhAAAAAEgUgRAAAAAAJIpA\nCAAAAAASRSAEAAAAAIkiEAIAAACARBEIAQAAAECiCIQAAAAAIFEEQgAAAACQKAIhAAAAAEiU\nmakLAACUh5s3b27cuPHatWs2NjZNmzbt37+/lZWVqYsCAAAmRiAEgMrvxo0bEyZMyM3N1W3G\nxsZeuHAhPDzczIx/BQAAkDSmjAJA5bds2TJ9GtS5cuXKvn37TFUPAAB4RhAIAaCS02q10dHR\nhdujoqLKvxgAAPBMIRACQCUnk8nk8iI+7ZkvCgAACIQAUPk1a9bMwEYAACApBEIAqPxGjx7t\n7Oycv+WFF15o27atqeoBAADPCOYLAUDl5+LisnLlyu3bt8fFxVlaWjZt2rR9+/amLgoAAJge\ngRAAJMHW1nbIkCEuLi65ubmpqammLgcAADwTmDIKAAAAABJFIAQAAAAAiSIQAgAAAIBEEQgB\nAAAAQKIIhAAAAAAgUQRCAAAAAJAoAiEAAAAASBSBEAAAAAAkikAIAAAAABJFIAQAAAAAiSIQ\nAgAAAIBEEQgBAAAAQKIIhAAAAAAgUQRCAAAAAJAoAiEAAAAASBSBEAAAAAAkikAIAAAAABJF\nIAQAAAAAiSIQAgAAAIBEEQgBAAAAQKIIhAAAAAAgUQRCAAAAAJAoM1MXAAAA8Kx79OhRXFyc\ng4ODhYWFqWsBgLLEFUIAAIAn2Ldv35AhQ86dO2fqQgCgjBEIAQAAAECiCIQAAAAAIFEEQgAA\nAACQKAIhAAAAAEgUgRAAAAAAJIpACAAAAAASRSAEAAAAAIniwfSoSLKysrZs2XLq1Kn09PRa\ntWoNHjy4Tp06pi4KAAAAqKgIhKgwNBrNrFmzLl26pNt88ODBuXPnPv300/r165u2MAAAAKCC\nYsooKoxDhw7p06COSqVaunSpqeoBAAAAKrpKcoVQJpPJZDJTVwHjio6OLtx4/fp1tVptbm5e\n/vUAFY7uc5IPTKAU9GcNpw+ASqaSBEIrKysbGxtTVwHjsrOzK9wol8udnZ0VCkX51wNUUGZm\nZo6OjqauAqhgzMzMhBBVqlTh9AFQyVSSQJiZmalSqUxdBYyrUaNGmzdvLtAYFBSUmppqknqA\nCkcmk7m4uKhUKs4aoKR0XzOys7MfPXpk6lpQTlxdXU1dAlAeuIcQFUZQUFBoaGj+Ficnp3Hj\nxpmqHgAAAKCiqyRXCCER48ePb9as2R9//JGRkVGjRo2XXnrJ1tbW1EUBAAAAFRWBEBVMq1at\nOnfubGlpmZycrNFoTF0OAAAAUIExZRQAAAAAJIpACAAAAAASRSAEAAAAAIkiEAIAAACARBEI\nAQAAAECiCIQAAAAAIFEEQgAAAACQKAIhAAAAAEgUD6ZHxZOVlZWTk8NT6QEAAICnxBVCVDzz\n58/v2LFjcnKyqQsBAAAAKjYCIQAAAABIFIEQAAAAACSKQAgAAAAAEkUgBAAAAACJIhACAAAA\ngEQRCAEAAABAogiEAAAAACBRBEIAAAAAkCgCIQBIRXp6etOmTd977z1TFwIAAJ4VBEIAAAAA\nkCgCIQAAAABIFIEQAAAAACSKQAgAAAAAEkUgBAAAAACJIhACAAAAgEQRCAEAAABAogiEAAAA\nACBRBEIAAAAAkCgCIQAAAABIFIEQAAAAACSKQAgAAAAAEkUgBAAAAACJIhACAAAAgEQRCAEA\nAABAogiEAAAAACBRBEIAAAAAkCgCIQAAAABIFIEQAAAAACSKQAgAAAAAEkUgBAAAAACJIhAC\nAAAAgEQRCAEAAABAogiEAAAAACBRBEIAAAAAkCgCIQAAAABIFIEQAAAAACSKQAgAAAAAEkUg\nBAAAAACJIhACAAAAgEQRCAEAAABAogiEAAAAACBRBEIAAAAAkCgCIQAAAABIFIEQAAAAACSK\nQAgAAAAAEkUgBAAAAACJIhACAAAAgEQRCAEAAABAogiEAAAAACBRBEIAAAAAkCgCIQAAAABI\nFIEQAAAAACSKQAgAAAAAEkUgBAAAAACJIhACAAAAgEQRCAEAAABAogiEAAAAACBRBEIAAAAA\nkCgCIQAAAABIFIEQAAAAACSKQAgAAAAAEkUgBAAAAACJIhACAAAAgESZGfXo6enpK1euPHPm\njFqtbtiw4ejRo93c3Ap3S0hIiIiIiI2N3b59e0nHAgAAAABKx7hXCCMjI+Pi4ubOnRsREaFQ\nKObMmaPRaAr0OXbs2AcffODt7V2KsQAAAACAUjNiIExKSjp9+vT48eP9/Py8vb0nTpyYkJBw\n4cKFAt1UKtWiRYtatmxZirEAAAAAgFIz4pTRmJgYCwsLX19f3aatra2Pj09MTExgYGD+bh07\ndhRCXLt2rURj1Wp1Zmamvr9Go5HJZMZ7L3gGyWQy/qcDJaI7ZTh3gFLQnzWcPgAqGSMGwtTU\nVDs7u/yfmw4ODkqlskzGHjt2bMqUKfrNZcuWNW/evCyqRgUgl8uFEA4ODi4uLqauBahILCws\nhBAymYxzBygpc3NzIYSVlRWnD4BKxriLyhT4LZpWqy2rsW5ubp06ddJv2tvb5+TklKpGVDy6\nvwwqlYr/6UCJ6E4ZrVbLuQOUlG4hg7y8PE4f6bC0tDR1CUB5MGIgdHR0TE1N1Wq1+minVCqd\nnJzKZKy/v//ChQv1m0qlMi0trexqxzNNFwgzMjL4pAZKJCMjQwih1Wr5wARKSq1WCyFyc3M5\nfaSDrxmQCCMuKlOnTh2VShUbG6vbVCqV8fHx9erVM/ZYAAAAAIAhjBgInZyc2rRps2TJktjY\n2Pj4+M8//9zPz8/f318IceDAgZ07d+q6PXr0KCkpSff7tqSkpKSkpOzs7GLGAgAAAADKhHHv\nIXznnXdWrVo1c+ZMjUYTGBg4ceJE3RTQP//8MzU19aWXXhJCTJky5f79+7r+r7/+uhDijTfe\n6Nmz5+PGAgAAAADKhHEDobW19YQJEyZMmFCgPf8CoatXry7RWAAAAABAmTDilFEAAAAAwLOM\nQAgAAAAAEkUgBAAAAACJIhACAAAAgEQRCAEAAABAogiEAAAAACBRBEIAAAAAkCgCIQAAAABI\nFIEQAAAAACSKQAgAAAAAEkUgBAAAAACJIhACAAAAgEQRCAEAAABAogiEAAAAACBRBEIAAAAA\nkCgCIQAAAABIFIEQAAAAACSKQAgAAAAAEkUgBAAAAACJIhACAAAAgEQRCAEAAABAogiEAAAA\nACBRBEIAAAAAkCgCIQAAAABIFIEQAAAAACSKQAgAAAAAEkUgBAAAAACJIhACAAAAgEQRCAEA\nAABAogiEAAAAACBRBEIAAAAAkCgCIQAAAABIFIEQAAAAACSKQAgAAAAAEkUgBAAAAACJIhAC\nAAAAgEQRCAEAAABAogiEAAAAACBRBEIAAAAAkCgCIQAAAABIFIEQAAAAACSKQAgAAAAAEkUg\nBAAAAACJIhACAAAAgEQRCAEAAABAogiEAAAAACBRBEIAAAAAkCgCIQAAAABIFIEQAAAAACSK\nQAgAAAAAEkUgBAAAAACJIhACAAAAgEQRCAEAAABAogiEAAAAACBRBEIAAAAAkCgCIQAAAABI\nFIEQAAAAACSKQAgAAAAAEkUgBAAAAACJIhACAAAAgEQRCAEAAABAogiEAAAAACBRBEIAAAAA\nkCgCIQAAAABIFIEQAAAAACSKQAgAAAAAEkUgBAAAAACJIhACAAAAgEQRCAEAAABAogiEAAAA\nACBRBEIAAAAAkCgCIQAAAABIFIEQAAAAACSKQAgAAAAAEmVm6gIAAEC5+u2335RKpamrqGCi\noqKEEH/88UdycrKpa6lgPD09AwMDTV0FgMciEAIAICEJCQlz5841dRUV1a5du0xdQsUjl8u3\nbdtmaWlp6kIAFI1ACACAhOTm5gohbDwDHet0M3UtqPwe/rU5O/m6Wq0mEALPLAIhAACSU8XJ\n16VBH1NXgcov9fov2cnXTV0FgOKwqAwAAAAASBSBEAAAAAAkyqApo+np6Xv27Nm3b9/58+cf\nPHiQkpLi6OhYtWrVJk2adO3atVu3bra2tsYuFAAAAABQtp5whTA7Ozs8PNzX17dfv34bNmxQ\nqVS1a9cOCQmpXbu2SqXauHFjv379fH19Fy1alJ2dXT4VAwAAAADKRHFXCG/cuNGnT5+LFy/2\n7dt32LBhwcHB1tbW+TtkZGT8+uuv69atmzp16nfffffjjz/6+voauWAAAAAAQNkoLhAGBQU1\nadLk0qVL9evXL7KDjY1NaGhoaGjolStXxo4dGxQUZKqntZqZmcnl3A8pFTKZTAhhbm7OGtZA\niajVaiGETCbj3JEyc3NzU5cAybG0tORjB3hmFRcIx44dO3v2bIVC8cSj1K9f/8CBA2FhYWVX\nWMnI5XICodSYmZmZmfHcFKAE9J/nnDtSxv99lD/+yQaeZcWdnHPnzs2/mZWVdfbs2YSEhBdf\nfNHV1VWtVuc/txUKxbx584xV5pPk5uaqVCpTvTrKmVarFUJkZWVlZGSYuhagIsnMzBRCaLVa\nzh0py8rKMnUJkJwK+pljZWVl6hKA8mDoVbXw8HAPD4927doNGDAgNjZWCBEWFvb666/n5eUZ\nszwAAAAAgLEYdPl+9erV77//fs+ePUNDQ0eNGqVrrFu37qefflqnTp1p06YZs0IAKIJGo6mg\nv3I2Id0VQrVanZaWZupaKhiFQlFgWTUAACoHgwLh0qVLR40atXz58uzsbH0gHDp0aHR09IYN\nGwiEAMrfJ5988uuvv5q6igrpjz/+6Nu3r6mrqGBkMtnMmTPbtGlj6kIAAChjBgXC6OjoRYsW\nFW4PDg6OjIws65IA4Mnu3LkjZCL1OZmpC0HlZ54urO5q7969a+pCAAAoewYFQnNz8yLvQb93\n7x6rVwMwFa0QMSNZtg5G5/SXptZ33DAPAKicDFpUpnnz5pGRkTk5OfkbU1JSwsPDW7ZsaZzC\nAAAAAADGZVAgDAsLO3r0aIMGDd577z0hxMqVK4cPH16zZs2///77ww8/NHKFAAAAQCUxe/Zs\nmUzm5uZW5CPT3nzzTZlM1rZt29IdfMCAAba2tob0bNu2bb169Ur3KqhkDAqE7du337dvn6Oj\n4/Lly4UQa9asWbduXd26dQ8cOMAd9gAAAIDh5HJ5cnLynj17CrRnZ2f/8MMPFhYWJqkKkmXo\n7TcdO3Y8e/ZsUlJSfHy8TCarUaOGk5OTUSsDAAAAKh+5XN6iRYu1a9f27Nkzf/uOHTsyMjKa\nNm1qqsIgTYY+mF7H1dU1MDCwSZMmpEEAAACgFNRqda9evXbv3v3w4cP87evXr+/QoUOBK4R7\n9uxp3769nZ2dlZVVw4YNP//8c61Wq9ul1WrnzJnj4+NTpUqVRo0abd26VSb7z+Lbv/32W0hI\niL29vZWVVWBg4DfffFNkPXfu3HnzzTdr1KhRpUoVDw+PV155JTo6ukzfMZ5pxV0hNHBiMX9j\nAAAAAMP17t176tSpmzZteuedd3Qt9+/f37dv34oVK1atWqVQKHSN27dv79OnT9u2bdeuXWtn\nZ7d169ZJkyYlJibqHggXHh4eFhY2cODAESNGPHz4MCwsLC/vf0siHzlypHPnzq1bt964caOV\nldVPP/00cuTI5OTkyZMnFyimT58+N2/enDdvnq+vb2Ji4ieffBIcHHzjxg1ra+ty+cOAiRUX\nCF1dXcutDmn666+/PvjggyJvKcYTDRo0yNQlVDzBwcHTp083dRUAAEidl5dXx44d165dqw+E\nmzZtMjc379u378qVK/Xdpk+f7u3tfeDAAUtLSyFE586dk5KSvvjii+nTpzs7Oy9evNjf3//b\nb7/VXRhs3759zZo19RcYJ0+e7O3tvW/fPt3YkJCQxMTEefPmjR071srKSv8SqampJ0+enDp1\n6siRI3Utbdq02bx5c0pKCoFQIooLhMePHy9+cEZGRmJiYpnWIy3x8fEqlcrTqoqDOc9Sg9Fd\nTU2/efOmqasAAABCCDF8+PDXXnvt8uXL/v7+Qoj169f36tXLzs5O3yExMTE6Ovqtt97SJTqd\n7t27b9u27eTJk40aNUpMTHzllVf000SrVavWtGnTixcvCiGSkpLOnj07evRorVabnZ2t6xAa\nGrpjx46zZ8/mX8XU2tra1dV18+bNISEhHTp0kMvlvr6+/PpYUp4qh5w8eXLo0KEJCQllVY00\njajp3b2am6mrQOXX+cgpU5cAAAD+0bt3bzs7u7Vr14aHh0dFRZ07d27+/Pn5O+i+Y3t7e+dv\nrFatmhDizp07VatWFUK4ubkV2KsLhPHx8UKI5cuX654RUPiwemZmZj///HO/fv06derk7Ozc\nqVOnXr169evXTz9tFZWeoYFw9+7dmzZtiouL02g0upa8vLzLly/n/40FAAAAAENYW1v37dt3\n48aNCxcuXL9+vaenZ0hISP4Oukt/ubm5+Rt1K8rIZDL90jL56e8h1I0dMWLEW2+9VaCPn59f\ngZZmzZrFxsYePXp07969e/bs+f7775cuXXr48GG+50uEQYFw8+bNAwcONDMz8/DwuH37drVq\n1ZRKZUZGRocOHSZNmmTsEgEAAIDKZ9iwYd98883x48c3b948aNCgAhflfHx8xL/X+vRu374t\nhPD29tZdIbx3717+vfp7Q6pXry6E0Gg0LVu2NKQShULRoUOHDh06fPLJJytWrBg1atSWLVuG\nDh1a6reGCsSgx04sWrQoNDQ0OTk5Pj7e0tLy0KFDKSkpy5cvNzMzCw4ONnaJAAAAQOXTrl27\nWrVqhYeH37p1q3D6cnd3b9So0a5du7KysvSN27dvt7a2btWqVc2aNV1dXQ8dOqSfvhcdHa2b\nLyqEcHZ2bt68+fbt21NSUvRj169fP3PmTLVanf9V/vjjjwEDBty/f1/fortQmb8FlZtBgfDq\n1atjxozJf5OrmZnZqFGjGjduPHXqVKPVBgAAAFRaMpls6NChu3fvbty4cUBAQOEOH3/88aNH\nj0JCQn788cedO3cOGjRoz549s2bNsre3l8vlo0ePvnLlSp8+fbZu3bps2bKuXbsGBQXpx376\n6aeZmZnt2rXbsGHD/v37Z82a9cYbbyQmJpqZ/WeGoJeX1969e0NCQr755psDBw5s2rTptdde\ns7S0fOmll4z+/vFsMCgQyuVy/fpFFhYWaWlpup979uz5008/Gas0AAAAoFIbOnSoLhYWubd7\n9+4///yzXC4fNmxY3759o6Ojv/nmm2nTpun2hoWFTZs27dSpU4MHD/7qq68iIyNbt26tv+cw\nODj48OHDnp6eY8eOffnll3/88cc5c+asWrWqwEt4enoePXq0du3aM2bM6NGjx6RJk9zc3I4e\nPVq3bl3jvWs8Uwy6h7BevXpr1qwJCQkxNzevVq3akSNHmjVrJoR4+PChPhwCAAA8ax7d/uvs\nTx/ciz2ep85x9moU0P2D6k1efsrOqfdjt88OMLOwHhSZpGs5v2P2nzs+KtDNs/6LXScdzM1M\n+Xa8U5Ev9+LYbdUDe5X2naGimj179uzZs/Wbvr6++jmfOidPnsy/2aVLly5duhR5KIVC8fHH\nH3/88cf6ll69ekVGRuo327Ztu3///iLH5n+8XEBAwNatW0vwHlC5GBQIJ0yYMGjQoLS0tL17\n93bp0mXWrFm3b992cXFZsWJF48aNjV0iAABAKaTei/n5k3ZV7N2Ces83t7KP/X39oS97vzjm\npyJjmKGdtdrf1r2Zl5tlZvG/Z3arspQymbz10BX5O1o7egkhzCys2wwreE0mMerAzT+22lWt\nVVbvFABKzaBAOHDgQLlcHhcXJ4SYPXv2lStXvvjiCyGEj4/P4sWLjVsgAABAqfy58yONRt3t\n/V+tHTyFELWaD9wxN+j095OqN3lZ/HsvTEk7/31s1YPrJ6s16PQw7ry+MTdTaV7Frk67NwrX\nIDezKNCem6U8/39h9V4Y7eRdxD1jAFDODLqHUAjRv3//KVOmCCGcnJz279+fkJBw5cqVa9eu\nNW3a1JjlAQAAlIZWkxf35w6fgO66gCeEkMkVfq2Hpz24nnz7Quk6Z6Yk/vHD+wHdP7B1qZF/\neG6W0tzK3sDCzm2bqclTPd97XinfGACUKUMD4Z07d5YsWaLfNDc3//7775OSkoxTFQAAwFNJ\nS7qhyk5z9v7PvS0u1QOFEMnxBQOhgZ1PbBxj4+wT0G1ageG5WUrzKv8EwrzcLPF4KYlRfx/5\n6vlecy2sHUv2fgDAOAwKhH///ffzzz8/efJkfUtmZmZYWFhQUFBsbKzRagMAACilLOUdIUQV\ne/f8jVXs3YQQmco7peh848z38Rd2thn+tVxhXmC4KkupUeccXT3k23GO68dYfzfR9dSmCeqc\njMJVnds+y7aqb5GTSwHAJAwKhNOmTbO1tc2/GFGNGjWioqJsbGz0694CAAA8O/JU2UIIhZlF\n/kaFmaV+V4k652Qkn/xuXINO46v6Ni/8WrmZKakPrsnNLFoPXdFh9FYv/y5Rh744uLTgCqUp\niVG3zm9r2GWyTK54yncHAGXFoEVljh07Fh4ernvUhF79+vWnTJkyc+ZM4xQGAABQegrzKkKI\nPHVO/kZdujMztypp59Nb3jWztH6+V9E3/nWd8otcbmbl4KHbrBn0isLMMua3NXeif/Gs10Hf\nLfqXZeaWtrVaDHq6dwYAZcmgK4QZGRmWlpaF283MzDIyipgOAQAAYFrWjtWEEFnKu/kbdVND\nrZ28StQ54fL+2BMbWgxYrBVaVU66Kiddk6cWQqhy0nWh0cbJW58GdXyb9RP/vf9Qo1HfOLPF\nu1E3c0vbMnuTAPDUDLpCGBgYuG7dugEDBsjl/wuQGRkZX331VZMmTYxWGwAAQCnZuvpaWDsl\n3Tqbv/HBjdNCCJcaQSXqHH34S6HVHio0BXTjWDufgO6dxu9SZaUKIfIvNKrKyQ8lPVYAACAA\nSURBVBBCmFn+71mFD66dzE5P8mrY7enfGgCUIYMC4axZs3r06NGgQYOQkBB3d/fs7Ozbt2/v\n3LkzJSVl9+7dxi4RAACgpGQyec2gV66d2JCedNPWtaYQIk+VffXY107eAY6e9UvU2b/ze77N\nB+Tv/9eeT+7FHOs0fpeljXOW8u6WKd7eDbt1Gr9T3yH2tzVCJvOo017fcv/a70IIl+r8Jl3S\n0tLSjHFYOzs7YxwWEmFQIOzWrdvOnTunT5++dOlSfWPjxo03bNjQtWtXo9UGAABQek1e+jDu\n/PY9izo0eHGCuaXN1WOrMx7e6vzeft3euD93HF7Wp3n/zxu8OL74znZVa9lVrZX/yLG/r5Up\nzNxrt9Vt1usw5sqhJfsjutYI6qNR5948++Pdv4/Uf3Gcg0c9/RDlnWghhF3V58rnvQOAgQwK\nhEKI0NDQ0NDQBw8e3L59Wwjh4+Pj6upqzMIAAACeio2zT+i0439sff/8jjBtntqlxvOd39v/\nv1VetBqtJk+r0RjUuVgtBkQ6eNSNOfb1mR+maPJUjp4NWg9dUbf9W/n7ZKcnyWRybiCEIWJi\nYqKiol5+ueAsZcAYDA2EmZmZSqXS09OzatWq2dnZW7ZsefDgQc+ePevUqWPU+gAA4kam+CZe\nXE4TKo2oaS0GeonWTk/bOTFbvH1RWMrF1qb/ab+dLRbGiKsZIryBaGxfxMBixgLPHgePui++\n839F7qoe2GvEaq2BnQtoM2x1m2Gr9Zsymbx+h7H1O4wtZkincTsMOTIghNi4cePRo0dfeOEF\nBwcHU9eCys+gVUajo6N9fX3XrVsnhFCr1R07dhw+fPiUKVMaN2589uzZJw4HAJReQrZ477K4\nnSVG+IiJtYSNQnz0t/g9+ak6a4WIuC5yNAXbd90Toy+KR6ri6nncWABAGdFoNEKIvLw8UxcC\nSTAoEM6YMcPDw6N///5CiC1btpw4cWLlypXXrl0LDAycP3++kSsEAGnbcFvkacVn/uIld/Gi\nq1hQT/haixW3hPYpOu+5L66ki+f/+4vnqDTx1S3xZg0xzKe4eoocCwAAKiaDpoweP348IiLC\n19dXCPF///d/AQEBb775phDinXfeef/9941bIABImUYrTjwSLZyEs/k/LXKZ6FxVfHVLXM8Q\nz9mUpvPDXLHqlhjoJe7liNh8z5J1NBdfNBS1rMX+B4+t53FjAQAG02g0169f12geO9UiPT1d\nCHHt2rWkpKTH9XF3d2dCKcqEQYEwJSXF09NTCKHRaA4dOvTGG2/o2qtWrVrMX1MAwNO6myOy\n8kQt6/80+tkIIcT1zIKB0MDOS26IqpaifzXxxY3/9KxW5cn1PG4sAMBgO3fujIyMfGK34q+7\nPPfcc6tXry6mA2AggwKhu7v79evXO3To8MsvvyQnJ3fr9s8zVePj411cXIxZHgBIW7JKCCGc\nzP/T6GguhBAPC93pZ0jnXx+KE4/EFw2FmazExTzNWADAv5RKpRCig5uLl5UBv4kryk+376am\nppZpUZAugwJh586dZ86cGRMTs3nz5po1a7Zr104Icf/+/cWLF7dp08bIFQKAhOVqhBDC7L/3\ne5vLhRBCVWiu0RM7p6nFlzdFb09Rt+QL3z/NWABAIaGebq1dH79kdLH2331Q5I3kQCkYtKjM\n3Llza9as+cknn2RmZm7dulWhUAghxo8fHxcX9+GHHxq5QlQelx487PPjTo/FK50+X95uw/c7\nY66XuvORW7e7bdnutWS1++IVbTd8v+ny3/k/Fvddv/Xidz+6RHzlEvFVyKafTiTcEQbvBZ4t\nFkVlP13wsyj0Af7Ezl/dEpZyMbzYNWMe52nGAgBM6u+//27ZsqWZ2WMvBTVt2lT2L0dHx2bN\nmn377bf6vWq1esGCBQ0bNrSzs7O1tfX391+4cKHuHshXX31VVpThw4cXPxDPDoMCoaen54kT\nJ5RKZWJiYlBQkK5x8uTJV65cadiwoTHLQ+UR+yjlxe+2Xk1O+ah9q2VdOtpbWvTbtnvHYzJh\n8Z13x94I/X57Snb2zDbN57ZvbalQjNi9/+Pfz+j2bo2O6bV1R2pO7scvtPn4hTbJWdldN287\ne/e+IXuBZ45ueZgCz4FIzhVCCFeLknU+qxQHH4gxNYVWK7LyRFaeyNMKIURW3j+hsRhPMxYA\nYFJbtmzp0KFD3bp1i+82fPjw+Pj4+Pj43377rWPHjkOGDDlz5p8vVzNmzPjyyy8/+eST2NjY\n2NjYGTNmLFy4cO7cuUKIpUuXxsTExMTEbNu2TQixb98+3eann35a/EA8Owx9ML0Qwt7+P08o\nbtqU5xGjBOb/dlqt0R4c2MfD1kYI0a9BnVbrNk/95fhLtWsVvhup+M4fHj1Rw8H+8OBXrczM\nhBAjGvsHffPd4jPnprduJhNi5q+/e9raHnntVRtzcyHEQP+6DVdtmPnr73v69xJP2gs8czyr\nCFszcfW/63n+nS6EELVtStZ5x12hFSLs74KjXj4jWjiKufWKK+NEcunHAgBMKicn5+TJk+fO\nnct/0a8wGxsbb29vIYS3t/f8+fMXLVoUFRXVrFkzIcSBAwdee+217t2763oOGjTIxcVFq9UK\nITw8PHSNKSkpQojq1av7+fnpj1nMQDw7ShAIgVLL02p3xd7o9lxNXcATQihksiEN6085fOzi\n/QeN3aoa3rlRVdcRjf1rOthb/TvtwVwub1HNY8OlK5kqVUau6qYy9a3ARrq8J4Sws7AY7F8v\n8sz55OxsdZ6mmL3OVUp5YzdgRDIh2jmLg0niXo5wtxRCiFyN2PtA1LIW1a1K1vmVauIF1//0\n35IoLqWKufWE3ZP+LXiasQAAkxo6dKgQ4ty5cwb2z83NXbFihb29fadOnXQtAQEBW7du7d+/\n//PPP69r6dKliyGHKvVAlCf+IUd5uJmSmpab28jtP18om7hXFUL8dT+pQCB8Yud3ghrn36UV\nIirpobedrY25eUp2jhCiikKRv4OPvZ1Gq72SlFzTwb6YvW28qz39OwXK3mve4vdkMTlK9PYQ\nVRRiz31xL0csrP/P3hOPxEdXxagaopfHEzp7WgpPy/8ceb+5UMhEQ7t/Ni+nibgsIYSIShNC\niNOPRGK2EEI0cXjyWACAwW7evCmEmHLhytMcxEKpLJtq/rVy5cq1a9cKITIzM52dndevX+/l\n5aXbFRERMWbMmObNm1evXr1Nmzbt2rXr1auXm5vbE49Z6oEoTwRClIe7GRlCCHfr/zweraq1\nlRDiTnpm6Trn5OXdz8hMTM/46tzFvx48XPdSFyGEh62Ng6XF8duJ+cf+ceeeEOJBZlZLL89i\n9j7lewSMpaqFiPAXq+LE+tsiTytq24iF9UXjf+fwa7VCoxUarUGdi3cwSey+97/NH/5db+mD\n2gXTIADgKdja2gohatvaOJiX8qv4hZTUYlaIKZ3+/fuHhYUJITIzM8+cOTNixIj58+e//fbb\nQggnJ6dNmzYtWbLk2LFjv//+e2Rk5Pjx41etWjVkyJDij1nqgShPBEKUh2x1nhDCQvGfRYws\nFQohRE6eunSdf7udGLpluxCiur3d5l6hoc/VFEIoZLI3mjT87NS58QeOTGwWaKFQrL14+cDN\nOCGESqMpfm+Zv2ugzHhbiY8esxhAa2exv6WhnQt4r5Z4r9b/Nif4igm+hpZUYCwAwGCurq5C\niLeeq17qx070Pv6H1qbQneRPx8HBQX/7X0BAwP379z/88ENdINRxdXXt3bt37969w8PD3333\n3dGjRw8cONCQXFrqgSgfBq0yCjylKma6OJeXvzE7L08IUaXQx4GBnRu7uf7Yp8eKbi+29PJ8\n9addHx49oWsPa9tyRID/6j8vNVi53m/5mpMJd+e0ayWEsDU3f+JeAAAACCG0Wq1arRZCxMXF\nDRw48NatW/n3tm/fPiMjIy0trZgjlHogyplB0dzc3NzSsuj5QjKZzN7evkmTJpMnT+7QoUOZ\n1obKw9PWRghxN+M/s0PvpmcIIbxsCz7k2sDOLlZW3f18hRDDGjXwsbf99OQfPWvXaurpbqFQ\nLO/acV5wqxspqZ62Nl52tl+evSCEqOloL4Qofi8AAEAlc/fuXbVa/fDhQyHE7du3hRCOjo62\ntrZff/11enr6hAkTdN0yMjJ0e7Ozs8+ePRsREdG/f38hhJeXV1RUVI8ePRYsWNC4cWONRnP+\n/PnJkyeHhIQ4ORV3hbPUA1HODAqEo0ePPnXq1OnTpxs0aFC3bl2ZTHb16tVLly61bdu2evXq\n9+/fP378+N69e3fv3t21a1djV4yKqKaDvVMVy/P/fdzfmTv3hBCBHlVL1PlBZtb2q9eauFdt\n5umu39vaq9pn4tylBw+b/tvoYmXlYvXPGoxH4m47W1Wp4/y/j57i9wIAAFQaLVu21F+m8/Hx\nEUJERERMnDjxwIEDSUlJ+kC4du1a3aIylpaWNWrUGDdu3NSpU4UQCoXiyJEj8+bNmzRpUkJC\ngkKhqFGjxrBhw959993iX7fUA1HODAqEL7300o4dO37//fdWrVrpG0+cODFs2LDIyMigoCCl\nUtm5c+f58+cTCFEkuUzWq47fd5ejbylTazjYCyGy1XlrL0Y1qupaz8W5RJ2VObnvHfy1hZfn\n/gG95bJ/HmH4y614IUR1BzshxNt7Dh2LTzg/crDutsOL95N+jr0x+vkAhUz2xL0AAACVjG5R\n08I2b96s//mPP/4o5ghOTk6fffbZZ599Vkyfpk2bFn7AoCEDYXIGBcKpU6fOmzcvfxoUQrRq\n1WratGmTJk06cuSIg4PDxIkT33zzTeMUicpgRpvmO2Kud9687Z2gxjbm5msuXo5LTdvd72Xd\n3l2xN/pv2/1px3ZjgxoX39nB0uL9lk3n/36606af+tT1s1QojscnfH/laotqHi9U9xZCvFzn\nufV/RXX//v+GNaqflJn12elzPvZ2H7Rurnuh4vcCAACUj8UxN76+EV+6sY9UaseyrQYSZlAg\nvHz5sru7e+H2atWqnTlzRveztbW1jGsseDxvO9tfBr/ywZHf5h4/pdZqmri77e73cnB1b91e\njVabp9Vq/v3FUvGdZ7Vt4efk+NX5iwt+O52ryathb/9hu5bjgproLhiGPldzfc+ui06eHb//\niLW5eZdaNRYEt3a2+ueh88XvBQAAMLbatWvb29srtVplwStq/8jKylKr1ba2to/7dl3FxqZB\ngwZGLBFSYlAgrFq16urVqzt16lTgL+WmTZtsbGyEEGq1esWKFfXq1TNKjags6jg7be3To8hd\nPWvXyn5/nIGdhRAD/esO9H/swvp969XuW6926fYCAAAYVatWrf7v//6vmA6zZs06fvz4unXr\nnJ0L3lkDlDmDAuHIkSPnzJkTFRUVEhLi6ekpk8kePHhw5MiR06dPjxs3TgjRr1+/PXv2bNq0\nycjVAgAAAADKjEGBMCwszMzMbOnSpREREfpGBweHd999d+HChUKI4ODgvn37DhgwwFhlAgAA\nAADKmkGBUC6Xz5o1a+bMmbdu3bp//75Wq3VxcfH19VUoFLoO+vVqAQAAADwNa2trMzOzKlVY\n4wDlwaBAqJOcnHzp0qU7d+7I5XJvb293d3c7OzvjVQYAAABI0DvvvDNgwABra2tTFwJJMCgQ\najSaSZMmffnllyqVSt9oY2MTFhY2ZcoUo9UGAAAASI6dnR3XXVBuDAqEn3/+eWRkZJ8+fUJD\nQ6tVq6bVam/fvv3TTz+9//777u7uQ4cONXaVAAAAAIAyZ1AgXLNmzdtvv/3VV1/lb3zrrbcG\nDBiwePFiAiEAABXLo793pVw7aOoqUPlpVJmmLgHAExgUCK9duxYZGVm4fdCgQawsCgBAhaPJ\nyxV5uaauAkDRjh49eurUqUmTJsnlclPXgsrPoL9kZmZmaWlphdtzc3P1C40CAAAAeHoHDhz4\n+eeflUqlqQuBJBh0hTAwMHDx4sU9evSwsLDQN2ZlZUVGRj7//PNGqw0AABhFFSdfG89AU1eB\nyi8t7rfc9HumrqKi0mq1pi4BkmBQIJw+fXqPHj1q167dtWtXb2/v3Nzc+Pj4Xbt2paSk7N27\n19glAgCAsmXjGegV/IGpq0Dld2PXOAIh8IwzKBCGhob+9NNP06dPX7lypb4xICBgw4YNnTp1\nMlptAAAAQGWTkZHx66+/5uXlPa7D3bt3hRD79++3sbF5XJ86derUrVvXKPVBYgx9MH2vXr16\n9eqVmJiYkJAgk8l8fHzc3d2NWhkAAABQ+ezcuXPFihVP7FZ8H09Pz++++67sioJ0GRoIdapV\nq1atWjUjlQIAAABUerm5uUKI+63kWR6y0h3Be69GrVaXaVGQruICYb169Qw5RHR0dBkVAwAA\nAEhCah25sl4pA6Hn4cdON63Ezp49GxISkpSUxNM4ylZxf5quhim3WgEAAACUSGJi4uDBg93c\n3BwcHIKDg0+fPl24T9OmTWX/cnR0bNas2bfffqvfq1arFyxY0LBhQzs7O1tbW39//4ULF2o0\nGiHEq6++KivK8OHDix9YCgcPHuzQoUOBNJi/cplM5uLi0qlTp5MnT5buJaSpuCuEx48fL7c6\nAAAAAJS5l19+2draev/+/ba2trNmzerRo8eNGzcKL1czfPjwuXPnCiGUSuX69euHDBlSp06d\nZs2aCSFmzJixcePGlStXNm3aVKvVHj58eMyYMTk5OWFhYUuXLl24cKEQ4tKlS7179963b1+t\nWrWEEPb29sUPLMUbOXjwYJ8+fQq36ysXQty7d++zzz4LCQm5ePGir69vKV5FT6VSmZubP80R\nnrUXepzirhC+/vrrWVlZBh4oKytr5MiRZVESAAAAgDKQnJxcs2bNlStXNmnSxM/P75NPPnnw\n4MGlS5cK97SxsfH29vb29vb3958/f75MJouKitLtOnDgwGuvvda9e3d3d3cPD49BgwZt2bKl\nRYsWQggPDw8/Pz8/Pz9vb28hRPXq1XWbbm5uxQ/Mr0aNGuvXr9f9PGPGDJlMduvWLd1mcHDw\n/PnzhRDZ2dnHjx8v8gEH+sq9vb2DgoJ0h9q9e7du77179/r37+/o6Oji4tK5c+fLly/r2s+f\nP9+yZUtbW9ugoKDDhw/LZLLz58+rVCqZTLZmzRpfX9/XX3+9mOFr166tX7++lZWVh4fHmDFj\nsrOzH9d47969gQMHVqtWzcXF5cUXX7x48aIQovALFTm2fBQXCA8fPtyiRYsjR4488SjHjh1r\n2bLloUOHyqwuAAAAoDLSPXHe8qHWOqGU/8nyhIETL52dnX/44Qf9AyoSEhLkcrmXl1cxQ3Jz\nc5cvX25vb69PXwEBAVu3bj137py+T5cuXbp27frEVzdwYEhIyNGjR3U///LLLw0bNtRtZmdn\nnzp1qkuXLkKI48ePu7m51a5d+4kvqlAoFAqFftGdwYMHCyGuX79++/bt5s2bd+rUKTMzMycn\np1u3bvXr17979+6mTZumTZsmhDA3Nzc3N5fJZMuXL9+2bduXX375uOHXr19//fXXly5dmp6e\nfvr06TNnzkRERBTZKIR4+eWXU1NTz58/f+vWrSZNmgQHBz98+LDACz1ubPkobsro2bNnBw4c\n2KFDh+Dg4GHDhoWEhOiiv15CQsKhQ4fWrVt3+PDhkJCQw4cPG7laAPgfmVY0mcMaazA6mRTX\nbgBgRFevXhVC+Ox6qg8XZbaypEOSk5NHjhw5fvz4Al/pdVauXLl27VohRGZmprOz8/r16/W5\nMSIiYsyYMc2bN69evXqbNm3atWvXq1cv3TXA4hk4MCQkZNasWUKI9PT0y5cvL1iw4Ndffx0y\nZMiJEyfs7Oyef/55IcTBgwcNef55enr6Rx99lJmZ2aNHDyHE5cuXDx06dPfuXWdnZyHEnDlz\nvvzyy127drm5ud27dy8sLMzW1rZOnTrjxo0bOnSo7ghyubxnz55NmjQpZnj16tW1Wq2Tk5NC\noahevfrJkycVCsXJkycLN54/f/7UqVOXLl3SPbFv7ty5y5cv37Fjx4gRI/K/UFRUVOGxT3yz\nZaW4QOji4rJ3797vvvvuo48+0l3KrFq1qu6GVKVS+eDBg/v37wshateuvXHjxoEDB7LgD4By\npsjSmroEAABKRpfHHjWU57iU8ghVT2rsLa1LNCQ6Ovqll17q1KnTZ599VmSH/v37627ty8zM\nPHPmzIgRI+bPn//2228LIZycnDZt2rRkyZJjx479/vvvkZGR48ePX7Vq1ZAhQ4p/UQMHdurU\nadCgQXfv3v3zzz8DAwM7duwYGRkphDhy5EhISIguYhw4cGDy5MlFvoo+ygohMjIy/P39t2/f\n7ufnJ4SIiYkRQnh4eOTvf/369ezsbIVCUaNGDV1LgVms+uuQjxvet2/fsWPHtmjRQnfNcODA\ngfXq1WvRokXhxmvXrslkMv0VWmtray8vr2vXrhV4oSLHFv9nW4aeEOHkcvlrr70WHR199OjR\nGTNmtGjRwtbWNjk52c7OrkWLFjNnzjx27NiVK1cGDx5MGgQAAACeSLegy8MgeUJXRen+y6si\nLC0tDX/FQ4cOtW3bdsKECcuXL3/cl3YHBwfd7X8BAQEjR46cNGnShx9+mL+Dq6tr7969w8PD\no6KiRo8ePXr0aAOfhfjEgS4uLoGBgceOHfvll1+Cg4Pr16+fkpKSmJh45MgR3XzR5OTkCxcu\nvPjii0Uev3///n/++eeff/559OhRJyenMWPGhIaG6nbJZDIhRGZmpjafadOmabVa3a783fT0\nf7aPGy6TyZYuXXr9+vUhQ4acPXs2ICDg+++/L7JRdxzdJGH9z/qXy/9CjxtbDgx6ML1CoWjX\nrl27du2MXQ0AlIBMJDXjV1EwOstkYRdbykXSAcDkjh8/3q9fv2+//daQu/70tFqtLrbFxcVN\nnTp14cKF+utpQoj27dtHRkampaU5OTk97gglGti5c+djx46dPHlSt2ZpmzZt9u3bd/r06c2b\nNwshDh065O/v/7hJqrooq/v5iy++eOutt1544YUGDRqIfy/B/fnnn61atdJ1uH79eq1atapV\nq6ZWqxMSEnRXa4t8FEcxw9Vq9aNHj3x8fEaNGjVq1KiJEycuW7asT58+hRsXL16s1Wqjo6Mb\nNWokhEhPT09ISCh8J2SRB+zXr9/j/mzLlkGBEACeQVohbvUuvxn2kCynvzR2saYuAgBKJSsr\na9iwYRMnTmzYsOHt27d1jU5OTjY2Nl9//XV6evqECRN0jRkZGboO2dnZZ8+ejYiI6N+/vxDC\ny8srKiqqR48eCxYsaNy4sUajOX/+/OTJk0NCQopJgyUdGBISMnbs2Js3b+qiV7t27SIjI+vU\nqePp6SmEOHDggCE3EAohXnvttW3btg0cOPD06dOWlpYNGjTo2LHj5MmTN2/e7OHhsXr16smT\nJ1+7dq1169YODg4LFixYtGjR7du3ly9fXuTRHjd89+7ds2fP3r59e2BgoG7V1ueee27dunWF\nGxs3bty6detp06atXbvW0tJy+vTp9vb2vXr1KvBCRY415P2WCQKh6WXl5aWqWBgDRsfNdgAA\nSM3vv/9+/fr1Dz/8MP/8zyVLlrzzzjsHDhxISkrSB8K1a9fq7sSztLSsUaPGuHHjpk6dKoRQ\nKBRHjhyZN2/epEmTEhISdLfeDRs27N133y3+pUs0sE2bNnFxcUFBQVZWVkKIdu3aTZ48WX/T\n4MGDB3Vrfhriq6++atiw4dSpU3U3In777bcTJkxo1KiRWq0OCAjYs2eP7p7A7du3jxs3rmrV\nqoGBgWFhYZ07dy5yMm2Rw19//fWEhIRXX331zp07jo6O3bp1++yzzxwcHAo3CiE2b948bty4\nWrVqWVpatmjR4tixY7qHNOZX5AENfL9PT5Z/SmvFpVQqVSqVqasosZ9//vmLL74wdRWQkBo1\naqxYscLUVZSN8ePH/x1z9dwCUz7IFRLh9Jem1nd5b7755iuvvGLqWsrAjRs3Ro8e7dKgj1fw\nB6auBZXfjV3j0uJP/Pjjj4Ufg/7sc3V1LfNjpqWlCSHWr1+/Zs2a2GFmynqyJw4pUqOFKi+L\nqvrbzOzs7MqsRMlQq9UajcbCwkIIcfLkyVatWimVysJRTQq4QggAAACUH92aIn7rnm6CWNWy\nKUaatFqtv79/69atIyIisrKyPvrooxdeeEGaaVAQCAEAAIDy1Lx584sXLxYzTe/atWspKSkB\nAQHm5o+dCKNbpASlI5PJtm7dqnsko5WV1QsvvLB69WpTF2UyBELT6+DmUs/e1tRVoPL7+lqc\nqUsAAACibt264eHhxXSYNWvW8ePHw8LCdM9DhzE0atTol19+MXUVzwQCoem1cnHqXq3oVXSB\nMrT+xm1TlwAAAIBni3EDYXp6+sqVK8+cOaNWqxs2bDh69OjCzw95XJ/4+Pg1a9ZER0drNBpf\nX99hw4bVq1fPqNUCAAAAgKQY95nOkZGRcXFxc+fOjYiIUCgUc+bM0WgKPtu3yD4qlWrmzJl2\ndnbh4eERERHu7u6zZ8/OysoyarUAAACAyXl4eNjb21fEpVlRERkxECYlJZ0+fXr8+PF+fn7e\n3t4TJ05MSEi4cOGCIX0yMzN79eo1atQoLy8vT0/Pvn37ZmZm3r1713jVAgAAAM+CMWPG/PDD\nD5aWlqYuBJJQgkCYlZV1/PjxLVu2JCUlCSHU6icslRsTE2NhYeHr66vbtLW19fHxiYmJMaSP\ng4ND7969dQ+mTEtL27Fjh7e3t7e3t+HVAgAAABWRTCbTPR8PKAeG3kMYHh4+b9681NRUIcSJ\nEydcXV3DwsLu3LmzatUqhUJR5JDU1FQ7Ozvdg1Z0HBwclEql4X00Gs2rr76qVqv9/f3nzZuX\nf+HduLi4/OsCtW/fvvDdic++YpYSBoxBJpPpfs9SCcjlxp3xDhRgbm5eOU4frjmg/FlZWVWO\n0weolAwKhKtXr37//fd79uwZGho6atQoXWPdunU//fTTOnXqTJs27XEDO1WUbAAAIABJREFU\n8yc9IUSRj1sppo9cLl+8eHFKSsqOHTtmzJixaNEi/Vzqa9euLVmyRN+zfv36+suMFQj/KqOc\nyeXySnNDAoEQ5czCwqJynD58L0f5s7a2rhynD1ApGRQIly5dOmrUqOXLl2dnZ+sD4dChQ6Oj\nozds2PC4QOjo6JiamqrVavWRT6lUOjk5laiPj4+Pj49PgwYNhg4deuTIke7du+vaGzduvGzZ\nsvzdClx7rBBYJgflTKPRVMQzpUh5eXmmLgHSkp2dXTlOn/T0dFOXAMlJTU2tiB/aDg4Opnrp\nzZs3Hzp0aNmyZcwmQzkwKBBGR0cvWrSocHtwcHBkZOTjRtWpU0elUsXGxtauXVsIoVQq4+Pj\nCzw64nF9Lly48OWXX37xxRdVqlQRQsjlcplMlv/iobOzc/PmzfWbSqVSpVIZ8l6eKRXxwxEV\nmlarrYhnSpGKnHEAGE9eXl7lOH2euAQAUOZUKlXlOH3KzeXLl2NjY9PS0ngwPcqBQXOuzM3N\ni7yWde/evf9v787jY7r+P45/ZibJZI+sIhsi1lgSa+xbolXU0varVC1F0VIUX1o7rWpRlFaL\n2qo/uqkq0jaiitZOUEttRSSCiCyyTpL5/XG/nW+aTfg2Gcl9PR/+yJx7zr3nJnNj3jnnnlvM\n3y2cnZ1bt269bNmyS5cuRUdHv//++wEBAYGBgSISERHx/fffF1MnICAgMzNz6dKl0dHRcXFx\nq1evzsjIaNy48aOeJgAAAAAgvxKNEDZv3nzJkiVdunTJW5iYmLhgwYKQkJBiGo4ePXrVqlXT\npk3Lzc0NDg4eN26cMjU0KioqOTm5R48eRdWxs7ObM2fO+vXrp0yZkpOTU7Vq1RkzZnh5ef0P\nZwoAAPAo7l47fuK7mfHXjmZnpjq416jdfkTtdsM12v8sqnfz/O6TO+bdiz6Zm2NwrFyrXuhr\nNVq8IH/dC/PnkS/PRn6QdPNcbnaWvXv1gFaD6nYarbNgEQEAj4sSBcKZM2d27ty5Xr16Tzzx\nhIisXLny448/3rp1a1pa2scff1xMQ1tb27Fjx44dOzZf+aRJkx5YRwmBJToJAACA0nH78oEf\nFnS0dfau/8RES2uHa8e+ObBxVMqdy82eWyAi0Se/j1zey8UvKOjpmRqt7sqhTXtXv5gS/2dQ\n9+kicuan9w9/OaFGyAtBPWboLKxiz0Ue+WrSncsHOo762tynBXOKjY398ssvc3Nzi6pw6dIl\nEfnkk0+KWYCwfv36+UZrgEdTokDYrl27H3/8cdKkSStWrBCRtWvXikjz5s3fe++91q1bl24H\nAQAAzOfYljd1Vjbd3vjNxrGyiNRqO+z7t5qd//mjJs+8o9VaHNvypr1btW6T9+usbJStW2c2\nOPPjoqBu00Sj+WPvSgd3/3ZDP1MGDD1rd7gX8/vVY99kpd2zsnV+wIFRce3evfu77757YLWf\nfvqpmK2HDh0iEOIfUdLnEHbq1OnYsWPx8fHR0dEajaZq1ar51gsFAAB4DIUv6JibndV60MpD\nm8fdvnzAwtLGs07HkH4f2Dh5itGYkXq30FZarYWVbSURqREyoHa74UoaFBGNRuvuH3L32vGs\n1Ht6e9dabYfZu1VX0qCIaHWWHjVaXvx1XXZWmoXeTmdprdHqJM8Ttiz19hqtTsuUUXVTxgZ9\nOky39276aHu4/O1QFS6uduzYsbCwsPj4eNU+eiozM7NVq1aDBw8eM2ZMoRUmTZp0/vz5bdu2\n5XuwX/FK+t1MS0u7efOmm5tbcHBwnTp1tm3btnDhwgsXLpT8SAAAAGVPZ2GVei9635oh9ULH\n9XnrfMsXP74e9d2vG14WkfTkW5vGuRf6b/u8/6ySUKvtUP8W/fPuMPnWRWt7N729q0ajrRc6\n1i/o6f9uMxrvxfxu5+JrobcTkfpdJiTGnj25/a305FtZ6UnXjm+5evybuh1ftbCyLbvzx+PK\nwtbVytH70f7JX7ewlsTZs2e7d+/u4uLi5OTUvn373377rWCdpk2bav5SqVKlZs2aff7556at\n2dnZ8+bNq1+/voODg729fWBg4Pz585VY++yzz2oKM3jw4OIbPoJdu3Z17NgxXxrM23ONRuPq\n6hoaGnrw4MFHO8RjbvLkyZUrV1bSYGxs7AsvvODh4aH8WA8fPiwi8+bNi46OLuYxEIUq6WMn\n2rdvP378+ClTpmRnZ3fq1OnAgQMiMn369P379zdp0uThTwcAAKBsaFITotu+tL5KnY4iYtfE\n59JvT8Se2yVGo97O5YnXIwptoyS6gq4e/Sr2bETTZ+ZrNP/9VJqTnZmRfCv1Xsz5nz9MuHGq\n/fD/U8prtHxRa6H/dd3Q41uni4hGo23Y7c3GPef8w+cHFC0zMzM0NDQ0NPTAgQM6nW7u3Lld\nu3a9ceOGg4NDvpqDBw+eO3euiCQlJW3YsOHFF1+sVatWs2bNRGTq1KkbN25cuXJl06ZNjUbj\n7t27X3nllczMzJkzZy5fvnz+/Pki8vvvv/fu3fvHH3/09/cXEUdHx+IbPsK57Nq1q0+fPgXL\nTT0XkVu3bi1atCgsLOzUqVPVq1d/hKOYGAyGsnkOZAkPdPXq1RUrVpiybs+ePW1tbX/66Sd7\ne/vp06d37979zz//tLOzmzVr1tChQ4cNG1bwR1yUEo0QTp061dPTs2/fviLyxRdfHDhwYOXK\nlZcvXw4ODn777bdLeCQAAACz0Fnoq9TuYHpp5+ydk5WebUjXWlh51Qst9J9HjZYF9xN9ase+\nNYN9G3av/+SkvOW3Luz78t9Vd7zT6tbF/Z1e+aZak2eU8rgLe39dP8yzdofQMdueeD2iXujY\nUzvfObmDz04oO8nJya+//vqHH35Yu3btgICAqVOnJicnX7lypWBNOzs7Hx8fHx+fwMDAt99+\nW6PRnD17VtkUERExYMCAbt26Va5c2dPTs3///l988UWLFi1ExNPTMyAgICAgwMfHR0T8/PyU\nlx4eHsU3zKtq1aobNmxQvp46dapGo7l27Zrysn379krcyMjI2L9/f2hoaDE99/HxadKkibKr\nHTt2KFtv3brVt2/fSpUqubq6dunS5cyZM0r5iRMnQkJC7O3tmzRpsnv3bo1Gc+LECYPBoNFo\n1q5dW7169ZdeeqmY5uvWratbt66NjY2np+crr7ySkZFRVOGtW7f69evn5eXl6urauXPnU6dO\niUjBAxXaNq+PP/64WbNmwcHBIpKQkFCtWrWVK1cGBQUFBAS8++67d+7c+f333+WvoJh3gPeB\nShQI9+/fP3nyZCVkf/fddw0bNhw+fLi/v//o0aOV0UkAAIDHlt7BLe+NfBqNTkSMxoebt3bu\n5w8jl/f0adit0yvf5B0eFBEXv6DQMdvaDP7UvUbLyGU9j215U9n//rVDHCvX7DzmO99GPbzq\nhTbv+36djq+c+G5m8q2L/8RpAQ/m7u4+ceJEZbAoISFhyZIlderUqVOnTjFNsrKyVqxY4ejo\naEpfDRs2/Prrr48fP26q88QTTzz55JMPPHoJG4aFhe3du1f5+ueff65fv77yMiMj49ChQ8pj\nDvbv3+/h4VGzZs0HHlSn0+l0uuzsbOXlCy+8ICJXrly5ceNG8+bNQ0ND09LSMjMzu3btWrdu\n3bi4uE2bNk2ZMkVELC0tLS0tNRrNihUrvv322w8//LCo5leuXHnppZeWL19+//79w4cPHzly\nZPHixYUWikjPnj2Tk5NPnDhx7dq1oKCg9u3b3717N9+Bimqb108//RQWFqZ87eLi8tVXX9Wu\nXVt5GRMTo9Vqvb29RUSj0XTu3DkiovC5D4Uq0ZTRxMTEKlWqiEhubm5kZOSwYcOUcnd39/j4\n+JIfDPjfnbh1Z+7+g8fibqcZsv0rOQ0Lqv9So0DdX//N77l2492DR0/djs/Ozanp4vxq40bP\nB9Y2fQT4+vzFD4+d/OPuvazcnGpOjgPq1x3VuKFe9xCz8AEAFUoJFpVRHP5i/JmIJQ27TmnS\nZ54UWK3B2t7Nt1EPEanZ5qWjLn6ndr5TtXFvvZ1ryp0rDZ96I2969Kobei5y2e3LBxwrP/hz\nLSqqrKwsEUm5/psh9faj7SHXkJZtWdK1IUUkJyfH1tY2KyurXbt2kZGRhT7NYuXKlevWrROR\ntLQ0FxeXDRs2KAFDRBYvXvzKK680b97cz8+vdevWbdu27dWrlzIGWLwSNgwLC5s+fbqI3L9/\n/8yZM/Pmzfvll19efPHFAwcOODg4NG7cWER27dpV6PBgPvfv3589e3ZaWlr37t1F5MyZM5GR\nkXFxcS4uLiIyZ86cDz/8cPv27R4eHrdu3Zo5c6a9vX2tWrXGjBkzcOBAZQ9arfbpp58OCgoq\nprmfn5/RaHR2dtbpdH5+fgcPHtTpdAcPHixYeOLEiUOHDv3++++VK1cWkblz565YsWLbtm1D\nhgzJe6CzZ88WbJvv1M6cOTNt2rSCp5yQkDB06NDXXntNGaQVkYYNG37yyScP/F6ZlOidVLly\n5StXrnTs2PHnn39OSEjo2rWrUh4dHe3q6lrygwH/o0OxcV02bfFysB/fvLGDleW3f1we89PP\nVxKT3unQWkR2XPrzuW93NPJwm9a6uU6j+eLchSE7fvozKfnNVs1EZOmRE5N/3t+vXu2prZtb\naXU/X4t+4+f9h2Jubur1lLlPCygTl1Jl/Q25eF/Sc8XLWrp5yFMeov3rc21UsmyKkSupkm0U\nHxvp5Smd3MT0ofeXu7I1Tq6nS7ZRPPUS5i49K4ulShd5Q0WSnnxr84QqhW5y8qzd563zytfH\nvp16dtcHrQZ+Urvdy3nrZKTcvnpsi2vVxu7Vm5sKK9dsc/qH9xKiTymTTnOzs/I2yc3OFJHc\nnL8VQm0uX74sInd///J/2Uly9kP8RVun00VFRcXFxS1durRjx46HDh2qVKlSvjp9+/ZVbu1L\nS0s7cuTIkCFD3n777REjRoiIs7Pzpk2bli1btm/fvt9++23JkiWvvfbaqlWrXnzxxeKPW8KG\noaGh/fv3j4uLi4qKCg4O7tSpk7Isyp49e8LCwpRVZCIiIiZOnFjoUUxRVkRSU1MDAwO3bt0a\nEBAgIhcvXhQRT0/PvPWvXLmSkZGh0+mqVq2qlOSbxWoahyyq+XPPPffqq6+2aNFCGTPs169f\nnTp1WrRoUbDw8uXLGo3GNJRna2vr7e2tvAHyHqjQtnkPmpycnJWV5ebmlu/cz58/36NHj9DQ\n0EWLFpkKXV1dH2rQrkSBsEuXLtOmTbt48eLmzZurVavWtm1bEbl9+/bSpUt5DiHK0vS9v9lY\nWPzywrMedrYiMqRhYOsNX3xy4tTcdi0ttNoZew9UdXLc/cKzNhYWIjKkUWCTNf+39MjxN1o1\n04h8evJM9UpOa7p3UT7itvPzPhN/99sLl+9lZDpbs/w3KrqzKTLpnLhZyrNeYquTfXflgz/l\nZoYMryoicvCezPxDatjJAB/RauTneHn3ksRlygveIiLf3JRPrkknNxngIxYaOZEkq67JuRSZ\nXsu85wT870qyqEzs2YhTO+aF9PsgXxoUEa2F/tCm1zxqtHxy0s+mYcDYc5EiYu9a1bFyTSsb\np5gzPzY1vvffrWd3iYhbtWalcTooL2rWrHnw4EH34MG27sVN3SzGjb3vONk+3BSnunXr1q1b\nt23btp6enhs3bhw9enS+Ck5OTkqIEpGGDRvevn17xowZSiBUuLm59e7du3fv3gsWLBg/fvyo\nUaP69etnYfHgNPHAhq6ursHBwfv27Tt69Gj79u3r1q2bmJgYGxu7Z88e5f66hISEkydPdu7c\nudD9m6JscnJyaGjoK6+88tRT//lzv/L0hbS0NBsbm7xN1q9fr/nbNPK/DfubRlCLai4iy5cv\nnzx58o4dO7Zv3/7OO+9s3LjxX//6V8FCJc3mfUaI0Wg0HS7vgQrdYb6D5utnZGRk3759Z82a\nle+n+VDPnJASBsK5c+eeOXPm3XffdXd3Dw8PV0YwX3vttevXrz/UDYtAl81bsnJyP3qi08TI\nvYdi46wtLDr4eb8f2r6yna1RJCE9vdBWOq22kl4vIv3r1XmpoYWSBkVEq9E09/I8cetOYkam\ni431kEaB1Zwcbf76/WKp1bbw8vzs93NpBoOdpaW1hU6X87frw87KUqfRMGUUqrA2WvRaWVJf\nnC1FRLp6yKunZdsteclPdBpZEy2eelkcKHrtf7a+fEq+jpX+3qIR2XFbquhlcsB/BgwbOcrV\ndNmXIPezxf4hJiwBjyFlUZliKuTmZh/4fLS1vZvOyubCvtV5N3nVC7N3rdrwqTeivp8T/l77\nak2e1Vrob13Ye+XIZo8aLavU7aTRaIN7zTm0aWzEkqdqtRtmYWUbc+anC/s/rd6sr4tvo1I+\nMzzWlCxkVyXIsWqbR9tD7G+LdboS3QQbGRk5YsSIkydP2tnZiYhOp9NoNCV5hqHRaFRuw7t+\n/frkyZPnz59vGk8TkXbt2i1ZsiQlJaWYJ5M/VMMuXbrs27fv4MGDypqlrVu3/vHHHw8fPrx5\n82blLAIDA4uapJo3yn7wwQcvv/xyhw4d6tWrJ38NwUVFRbVs+Z9loq5cueLv7+/l5ZWdnR0T\nE6NMsyxqVZSimmdnZ9+7d8/X13fkyJEjR44cN27cRx991KdPn4KFS5cuNRqN58+fb9CggYjc\nv38/Jiam4J2Qhe4wbyB0dHS0srK6c+eOqWT//v3/+te/Pv/884L3ZMbHx7u7uxd6RoUq0f/l\nVapUOXDgQHJysq2trSnNT5w4ccmSJfmGUIHiWWl1V+4lvRy+a2qr5qs83A7fvDXo+x8zcnK+\n6dP9dmpa1Q8/LbRVLRfnU8MGiMjghvXybbp0L9HVxsbFxlqr0Yxu8rf/X40iZ+Pv+jjY21la\nisi4ZsEv7Yh458CRoQ0D9RYWP1+L3vrH5ZGNG9o+zBR8wGwmnRWDUcb7y4qrcjZF9Fpp5CSv\nVBMXSzGKJGcX3kon/8lsnd2kq/Y/aVBENCJ17eVSqtzPFkdL6eohnvr/pEERsdBIPXv56Y5k\n5oq1Vqw0kqOVvH9NsdGKVsOUUahBVlpi8q0LIvLr+uH5NnV+9Vt716rBPWc7Vq55/uePor6f\nk5udZe9WrXHPOfXCxilDgvU6v2bj6Hl215J9nw7Kzc12cPNv3HNOvhVKgVLVpEmT1NTUwYMH\nz54929ra+oMPPrh//74SIT799NP79++PHTtWqZmamnrjxg0RycjIOHbs2OLFi5VHDHh7eytP\nMpw3b16jRo1yc3NPnDgxceLEsLCwYtLgwzYMCwt79dVXr169qkSvtm3bLlmypFatWso6JhER\nESW5gVBEBgwY8O233/br1+/w4cN6vb5evXqdOnWaOHHi5s2bPT09V69ePXHixMuXL7dq1crJ\nyWnevHkLFy68cePGihUrCt1bUc137Ngxa9asrVu3BgcHK8t71qhRY/369QULGzVq1KpVqylT\npqxbt06v17/xxhuOjo69evXKd6BC2+arExgYePr0aeXBG+np6YMGDRo3blz9+vWVn5qIODs7\nK7H/1KlTgYGBJfl2KR7io7CdnV1qaqrpUZJKEE9MTCw4BRkoikYjN1Luf9otrL2fj4j0drDf\nWN1v99Voo4iztX5n3/yXh8KuiGezfPPHpcir0W+1b6XNM/KXmZNzOzUt9n7qx8dPnb5zd32P\nJ5Ty/oF1rHS6kT9Ezt53UES0Gs3kkKYz2ob8w2cIlBILjcRmyMLLMsBHJtaQc/flnYuSlStz\nass9gzx/rPBWPjayppGIyJMF/qoakyFOFuJoKRqR3n//055R5GqauFuJtVZE5Fkvee+S/F+M\ndPUQK62cSJL9CfJ05f8GSODx1mX8D/lKQl5YHvLC8pK0tbZ3G7L6AWMpNUIG1AgZUNTW6s3+\nVb1Z/nlfQJmpVKlSRETElClT2rZtm52d3aBBgx07digjVBEREfHx8aZAuG7dOuVOPL1eX7Vq\n1TFjxkyePFlEdDrdnj173nrrrQkTJsTExCi33g0aNGj8+PHFH/qhGrZu3fr69etNmjRRJme2\nbdt24sSJppsGd+3apaz5WRIff/xx/fr1J0+erNyI+Pnnn48dO7ZBgwbZ2dkNGzYMDw9XBrS2\nbt06ZswYd3f34ODgmTNndunSJd8j7xWFNn/ppZdiYmKeffbZmzdvVqpUqWvXrosWLXJycipY\nKCKbN28eM2aMv7+/Xq9v0aLFvn37lIc05lXoDvPV6dKlS0REhDI59rfffrty5cqMGTNmzJhh\nqrBs2bLRo0cbjcbIyEhlkZ4SKlEgvHjx4rBhww4cOGAwGApuLcmgM2Ci1+na+fmYXnrZ26Vn\nZ6cbsm0tLTpV9S35fsIvXx2+M+KpGtVeb944b/mvN2Kf+mKriPg5Omzu9dRTNaop5fujY0b9\nsLudr/fQRvVtLC1+uHz1vYNHrSx0b7TkRg6UBxqN3MmSfwdII0cRkbYuElFJTiSJUcTRQubX\nLbyVdRGZbe9dOZ4kQ/3+Nu5nyJV7BonPkm235EqavPHXhJZQN7HUyPtXZF20iIhGpJ+3DHqI\nqxUAYEb169ffvn17wXJlNqbi6NGjxezB2dl50aJFBSNKXsqj5x+hocLKyur+/fuml82bN8+7\nt0IfnKgo2HN3d/dbt26ZXnp6en7xxRcFG7Zp0+bYsWNWVlYiojztXZk+anpeRTHNNRpNvjCm\nKLTQ19d369atBTuQ90BF7TCvkSNHLl68+MSJE8HBwZ07dy4qgn333Xfp6en9+vUrZlf5lCgQ\njhgx4sSJE88++6yXl1dJ7hwFiuFqY5P3I6hOqxWR3If8s8LHx09NiNzbq1aNtd27aP9+42wj\nD7dv+nSPT0+PvBr97JbtE1s0mdOuZa7RODw8MsDZ6es+3ZX6nar6Zuca5+4/9FydmgHOjHKj\nPLDUSsM8f1N0s5LMXMnKFb1WGjs9xH4OJcqCy9LCWf7l9bfy0yky5ZyISGW9zKwlLf6az3M6\nWd6/Ig0dpZuHWGnlcKJsjhUrrfT3/h9PCADULCspOv3OuUdra8wxiLAIwqMzGo2BgYGtWrVa\nvHhxenr67NmzO3ToUHDg7rFSrVq1UaNGTZ06defOnUXVMRgMs2fPnjZtmvLkyRIqUbo7fPjw\nV199ZXraBFAaSrKojGLS7n3LjkZNCmkyp12rgosoudrYdAuoLiKDGtTzdbR/7+DRp2v6u9pY\n/5mY9O+QpnnTY6dqvh8dP3koNo5AiPLByeJvA3rK4F/uQ87R2HZLProqbVxkSoDku35q2Mmc\n2pJkkGNJMuMP6estL/mKUWThZfG2ljm1/1O/sZPkGmV9tLR3FW/r/+F8AECllAUaY3998LhZ\nMTQOD34MIIqi0Wi+/vpr5dl9NjY2HTp0WL169YObmdu7777bqlWrDz744LXXXiu0wtSpU729\nvU3TgEuoRIHQ3t6+4H2NwD+rJIvKiMjMvQc+PHbywyc6Dm1UP2+dO2npWy9cDqrs3qxKZVNh\nK2+vRXL89zt3W3h7ikhWTk7eJpk5OQULgfKnJIvKKD6+JltuyvNeMsQvfxoUEScLCXEWEXnC\nQzz0sjlGWjuLo6XczJTn3f5WP9hJtsbJ2RQCIQA8grCwsPT0dNPCHAXt27fvxo0bvXv3trYu\n8tdsvufU4WE1aNDg559/NncvHo5erz92rIhVA0RE5L333nuE3ZYoEA4aNGjt2rXvvPPOIxwA\nKKGSLCoTeTX63YNH3w9tly8NioiVTvf6rl9aeFf56fnepmHAn69Fi4ifk0OAcyUnvVXEn9fn\ndTCatu6+Gi0iTTwrC1CulWRRGRFZGy3f3pRx/vLU3/+onGiQ/QlS005q2/+3sL6DfCnyZ5rU\ndRARyf77pxZDrohINjeQA8Cj8PDwGDZsWDEVoqOjb9y4MWDAABcXlzLrFVSrRIHw7bfffuaZ\nZ1q2bNmmTRtXV9d8W6dMmVIKHYPqWOl0xS8qk52bO27XHlcbGxsLi7WnzuTd1Lman5+jw79D\nmr792+HQTVv61A7Q63T7o2O+PHehhZdnBz8frUYzo03IhMi9Pb/eNqRhoK2lxa4/r687dea5\nOjUberiV8pkBpawki8ocT5JNMfJKtfxpUEQstfLRVanrIAvr/XcY8ESSiIiHXrytxU4nR5Nk\nuPx36/EkEflbgAQAAOVTiQLhkiVLtm3bJn+twJMPgRBlIykz82JCooiM+mF3vk1f9u7m5+gw\nvU2LAOdKH584Ne/Xw1m5OVUdHWe0DRnTJEgZEny1SaPKdrbLjkYN2xmRnWusXslxRtuQfCuU\nAuWSheYBi8rkGGX5n+JkIXqthN/+26bGTlJZL897y8YbMuGMtHUVS42cTpE98VLPQYKdRCMy\nyFc+uipTz0tXD9Fr5Vii/HBH2ruKv22pnhYAACgDJQqEixcv7tq165QpU1hlFP+j75/rma9k\nSWj7JaHtS9LW1cYm499jiq/TL7B2v8DaRW19tk7NZ+vULGorUGHdz5EbGSIiiwss2z2rllTW\ny0Af8baW72/JxhuSbZTKehnkK709/zMk2MtTnC3l2zh575LkGKWKtQzykee88u8KAPAPady4\ncUpKymO+6CUqjBKlu7t37y5atKhu3SKmJAEAStu8AosHjK4uo6uXqK2ThfwU8oA6nd2kc9HT\np9u7Svv89wsAAEpJ7969e/fube5eQC2KeGbx3zVo0ODu3bul3RUAAAAAQFkq0Qjh8uXLJ0+e\nvGjRoiZNmpR2hwAAAIAK6aEeFw6UjRIFwokTJ16/fr1p06b29vYFVxm9evXqP98vAAAAAEAp\nK1Eg1Gq1AQEBNWuyGgcAAAAAVBwlCoS//PJLafcDAAAAAFDGHryoTFZWVrNmzbZv314GvQEA\nAAAAlJkHB0IrK6vY2NhLly6VQW8AAAAAAGWmRI+d+OSTT1avXv3tt99mZ2eXdocAAAAAAGWj\nRPcQLliwQKfT9enTx8LCwt3d3crKKu9WVhkFAAAAgPKoRIEwOzvdHkZQAAAgAElEQVTb2dm5\nc+fOpd0bAAAAAECZKVEg/PXXX0u7HwAAAACAMlaiewgBAAAAABUPgRAAAAAAVIpACAAAAAAq\nRSAEAAAAAJUiEAIAAACASpVolVGUqluZmeeT75u7F6j4cs3dAQAAADxuCITmpNVqReTTK9Gf\nXok2d1+gChqNxtxdAAAAwGOEQGhOISEhPXv2NBgM5u5IORMVFRUbG9u5c2e9Xm/uvpQnOp2u\nSZMm5u4FAAAAHiMEQnOqVKnSqFGjzN2L8ufdd9+NjY0dOnSoi4uLufsCAOWSIfX2/RuHzd0L\nVHw5mUnm7gKAByAQAgCgIsrdCsnX9idf22/uvkAtdDqdubsAoEgEQgAAVMTX13fEiBH37t0z\nd0fKmYsXL544caJNmzZeXl7m7ks54+3tbW1tbe5eACgSgRAAABXRarW9e/c2dy/Kn+++++7E\niROhoaEhISHm7gsA/JN4DiEAAAAAqBSBEAAAAABUiimjAMorjYj//+WYuxeo+KySzd0DAABK\nDYEQQLnk4eFx4cIF59O55u4I1MLd3d3cXQAA4J9HIARQLk2ZMiU+Pt7cvShn0tLSXnnlleDg\n4LFjx5q7L+WMtbV1pUqVzN0LAAD+eQRCAOWShYWFp6enuXtRzqSmpoqIXq/nWwcAABQsKgMA\nAAAAKkUgBAAAAACVIhACAAAAgEoRCAEAAABApQiEAAAAAKBSBEIAAAAAUCkCIQAAAACoFIEQ\nAAAAAFSKQAgAAAAAKkUgBAAAAACVIhACAAAAgEoRCAEAAABApQiEAAAAAKBSBEIAAAAAUCkC\nIQAAAACoFIEQAAAAAFSKQAgAAAAAKkUgBAAAAACVIhACAAAAgEoRCAEAAABApQiEAAAAAKBS\nBEIAAAAAUCkCIQAAAACoFIEQAAAAAFSKQAgAAAAAKkUgBAAAAACVsjB3B/4Z1tbW1tbW5u4F\nyohGoxEROzs7BwcHc/cFKH80Gg3XDvCwLCwsRMTKyorLB0AFU0ECocFgyMnJMXcvUEaMRqOI\nZGZmZmRkmLsvQHmSlZWlfMG1Azys3NxcEcnOzubyUQ+9Xm/uLgBloYIEwpycHIPBYO5eoExl\nZ2fzQwceinLJGI1Grh3gYSmBMDc3l8sHQAXDPYQAAAAAoFIEQgAAAABQKQIhAAAAAKgUgRAA\nAAAAVIpACAAAAAAqRSAEAAAAAJUiEAIAAACAShEIAQAAAEClCIQAAAAAoFIEQgAAAABQKQIh\nAAAAAKgUgRAAAAAAVIpACAAAAAAqRSAEAAAAAJUiEAIAAACAShEIAQAAAEClCIQAAAAAoFIE\nQgAAAABQKQIhAAAAAKgUgRAAAAAAVIpACAAAAAAqRSAEAAAAAJUiEAIAAACAShEIAQAAAECl\nCIQAAAAAoFIEQgAAAABQKQIhAAAAAKgUgRAAAAAAVIpACAAAAAAqRSAEAAAAAJUiEAIAAACA\nShEIAQAAAEClCIQAAAAAoFIEQgAAAABQKQIhAAAAAKgUgRAAAAAAVIpACAAAAAAqRSAEAAAA\nAJUiEAIAAACAShEIAQAAAEClCIQAAAAAoFIEQgAAAABQKQIhAAAAAKgUgRAAAAAAVIpACAAA\nAAAqRSAEAAAAAJUiEAIAAACAShEIAQAAAEClCIQAAAAAoFIEQgAAAABQKQIhAAAAAKgUgRAA\nAAAAVIpACAAAAAAqRSAEAAAAAJUiEAIAAACAShEIAQAAAEClCIQAAAAAoFIEQgAAAABQKQIh\nAAAAAKgUgRAAAAAAVIpACAAAAAAqRSAEAAAAAJUiEAIAAACAShEIAQAAAEClCIQAAAAAoFIE\nQgAAAABQKQIhAAAAAKgUgRAAAAAAVIpACAAAAAAqRSAEAAAAAJUiEAIAAACAShEIAQAAAECl\nCIQAAAAAoFIEQgAAAABQKQIhAAAAAKiURanu/f79+ytXrjxy5Eh2dnb9+vVHjRrl4eFR8jox\nMTGLFy++dOnS1q1bS7WfAAAAAKBCpTtCuGTJkuvXr8+dO3fx4sU6nW7OnDm5ubklrLNv3743\n33zTx8enVHsIAAAAAKpVioEwPj7+8OHDr732WkBAgI+Pz7hx42JiYk6ePFnCOgaDYeHChSEh\nIaXXQwAAAABQs1IMhBcvXrSysqpevbry0t7e3tfX9+LFiyWs06lTJ3d399LrHgAAAACoXCne\nQ5icnOzg4KDRaEwlTk5OSUlJD1unUGfOnPnss89MLwcPHmxKlajwlDeMnZ2dg4ODufsClD8a\njYZrB3hYFhYWImJlZcXlA6CCKd1FZfImPRExGo2PVqeg27dv79q1y/SyT58+er3+kfqI8kd5\nz1haWvJDBx5KVlaWiGg0Gq4d4GFptVoR0el0XD4AKphSDISVKlVKTk42Go2myJeUlOTs7Pyw\ndQrVtm3b3bt3m17m5OTcvXv3n+s7HmvKskNJSUk6nc7cfQHKk9TUVBExGo38wgQelsFgEJH0\n9HQuH/VwdXU1dxeAslCKgbBWrVoGg+HSpUs1a9YUkaSkpOjo6Dp16jxsnUJZWFg4OjqaXiYl\nJeXk5PzTZ4DHmtFoLOF4MgCFcslw7QCPwHTVcPkAqGBKcVEZZ2fn1q1bL1u27NKlS9HR0e+/\n/35AQEBgYKCIREREfP/998XXuXfvXnx8fEpKiojEx8fHx8dnZGSUXm8BAAAAQG1K9x7C0aNH\nr1q1atq0abm5ucHBwePGjVOmhkZFRSUnJ/fo0aOYOpMmTbp9+7ayn5deeklEhg0b9vTTT5dq\nhwEAAABAPUo3ENra2o4dO3bs2LH5yidNmvTAOqtXry7VvgEAAACAypXilFEAAAAAwOOMQAgA\nAAAAKkUgBAAAAACVIhACAAAAgEoRCAEAAABApQiEAAAAAKBSBEIAAAAAUCkCIQAAAACoFIEQ\nAAAAAFSKQAgAAAAAKkUgBAAAAACVIhACAAAAgEoRCAEAAABApQiEAAAAAKBSBEIAAAAAUCkC\nIQAAAACoFIEQAAAAAFSKQAgAAAAAKkUgBAAAAACVIhACAAAAgEoRCAEAAABApQiEAAAAAKBS\nBEIAAAAAUCkCIQAAAACoFIEQAAAAAFSKQAgAAAAAKkUgBAAAAACVIhACAAAAgEoRCAEAAABA\npQiEAAAAAKBSBEIAAAAAUCkCIQAAAACoFIEQAAAAAFSKQAgAAAAAKkUgBAAAAACVIhACAAAA\ngEoRCAEAAABApQiEAAAAAKBSFubuAPDQunTpUr9+fTs7O3N3BAAAACjfCIQof9q1a6fX6xMS\nEnJzc83dFwAAAKAcY8ooAAAAAKgUgRAAAAAAVIopowAAAA/wxBNPtGrVysnJydwdAYB/GIEQ\nAADgAZydnX18fFJSUjIzM83dFwD4JzFlFAAAAABUikAIAAAAACpFIAQAAAAAlSIQAgAAAIBK\nEQgBAAAAQKUIhAAAAACgUgRCAAAAAFApAiEAAAAAqBSBEAAAAABUikAIAAAAACpFIAQAAAAA\nlSIQAgAAAIBKEQgBAAAAQKUIhAAAAACgUgRCAAAAAFApAiEAAAAAqBSBEAAAAABUikAIAAAA\nACpFIAQAAAAAlSIQAgAAAIBKEQgBAAAAQKUIhAAAAACgUhbm7gAAoIzo9fo333zTzc3N3B0B\nAACPCwIhAKiFpaVlnz59srKykpOTzd0XAADwWGDKKAAAAACoFCOEKGeSkpKOHj2akZFRpUqV\nGjVqmLs7AAAAQDlGIER58ssvv3zwwQepqanKy9atW0+ZMsXS0tK8vQIAAADKKaaMotyIjo5+\n//33TWlQRH799dd169aZr0cAAABA+UYgRLmxe/fuzMzMfIXh4eFGo9Es/QEAAADKOwIhyo3E\nxMSChWlpaVlZWWXfGQAAAKACIBCi3KhSpUrBQldXV71eX/adAQAAACoAAiHKjSeeeMLFxSVf\nYf/+/c3SGQAAAKAC0FSM+68MBoNWS7it+P7444+33nrrwoULImJjYzNkyJBBgwaZu1NAeaLT\n6YxGY25urrk7ApQzGo1Gq9Xm5uZWjA9OKAmdTmfuLgBloYIEwuTkZIPBYO5eoIzcv38/MzPT\nycnJwoLnpgAPQaPRuLi4GAyG5ORkc/cFKGdsbGxsbW1TUlK4cV09XF1dzd0FoCxUkM/TRqOx\nYiRblISnp6der09ISGCUA3gE/MIEHoHpquHyAVDBMM0SAAAAAFSKQAgAAAAAKkUgBAAAAACV\nIhACAAAAgEoRCAEAAABApQiEAAAAAKBSBEIAAAAAUCkCIQAAAACoFIEQAAAAAFSKQAgAAAAA\nKkUgBAAAAACVIhACAAAAgEoRCAEAAABApQiEAAAAAKBSBEIAAAAAUCkCIQAAAACoFIEQAAAA\nAFTKwtwdAB5Oamrq2bNnMzIyKleu7O3tbe7uAAAAAOUYgRDlycGDB5csWZKYmKi8DA0NHTdu\nnIUFb2MAAADgUTBlFOVGXFzcu+++a0qDIrJr166NGzeasUsAAABAuUYgRLkRERGRnp6er3DH\njh1Go9Es/QEAAADKOwIhyo2EhISChSkpKVlZWWXfGQAAAKACIBCi3KhcuXLBwkqVKun1+rLv\nDAAAAFABEAhRbnTp0sXJySlfYd++fc3SGQAAAKACIBCi3HBxcZk5c6aPj4/y0tLS8vnnn+/V\nq5d5ewUAAACUX5qKsSBHUlKSwWAwdy9QFnJychISEjIzM52dne3s7MzdHaA80Wg0rq6uWVlZ\nycnJ5u4LUM7Y2NjY2dmlpKRkZmaauy8oI25ububuAlAWeIAbyhmdTufv76/X6xMSEnJzc83d\nHQAAAKAcY8ooAAAAAKgUgRAAAAAAVIpACAAAAAAqRSAEAAAAAJUiEAIAAACAShEIAQAAAECl\nCIQAAAAAoFIEQgAAAABQKQIhAAAAAKgUgRAAAAAAVIpACAAAAAAqRSAEAAAAAJUiEAIAAACA\nShEIAQAAAEClCIQAAAAAoFIEQgAAAABQKQIhAAAAAKgUgRAAAAAAVIpACAAAAAAqRSAEAAAA\nAJUiEAIAAACAShEIAQAAAEClCIQAAAAAoFIEQgAAAABQKY3RaDR3H4CHs2XLlvPnz48ePdrR\n0dHcfQHKk4yMjPfff9/f3//55583d1+AcubQoUORkZF9+vSpU6eOufsCAP8kRghR/hw6dGjL\nli0ZGRnm7ghQzhgMhi1btvz222/m7ghQ/ly4cGHLli0xMTHm7ggA/MMIhAAAAACgUgRCAAAA\nAFApAiEAAAAAqBSLygAAAACASjFCCAAAAAAqRSAEAAAAAJUiEAJARXbp0qX+/ftzdwCQD5eG\nwWAYP3789u3bi6qwdu3auXPnqvlbBKiEhbk7ANWJiYlZvHjxpUuXtm7dWmiF119//dKlS8rX\ntra2Xl5eTz/9dIcOHZSSnJycLVu2/PLLL7dv3xYRd3f3jh07PvPMMxqNZv78+YU+YK1Tp07j\nxo0rpmFpnCbKu4SEhLVr10ZFRRkMhurVqw8ZMqRWrVr56pSL9+rJkycbNGiQr23enouIg4OD\nv7//gAEDateu/QiHgKpER0evXbv2/Pnzubm51atXHzRoUMEHtXNplAvr1q2rVKlS9+7dpYjf\neAMHDnz99de3bdvWs2dPc3cWQCkiEKJM7du3b/Xq1cHBwXn/xy2oc+fOL7zwgoikpaXt3r17\n8eLF3t7eNWvWFJHPPvtsz549o0ePDggIMBqNp06dWrFihcFg6Nev34gRIwYNGiQi165dmzdv\n3uzZsz09PUXE1ta2+IZlceYob9566y29Xj979mwbG5uNGzfOnTt31apV1tbW+ao9/u/VqKio\nVq1aFSw39VxEEhMTt27dOn369GXLllWuXPkRjmKSk5Oj0+n+lz08bgdCXgaDYdq0aUFBQQsW\nLNBqtV988cWsWbPWrl1rY2OTryaXRj6P26Vx+/bt8PDwhQsXKi+L+o3Xr1+/ZcuWdenSpeCP\nGECFQSBEmTIYDAsXLrx8+fKePXuKqWZtbe3m5qZ8/eKLL3777bfR0dHKJ4moqKgOHTo0bdpU\n2dq+fXsHBwfla2dnZ+WL1NRUEXF3d69SpYppn8U0BPJJSUmpXLnygAEDvL29RWTw4MFDhw69\nfv16wUFCM75Xhw4d+sILL3Tq1ElEPvvss6+++mr16tUeHh4i8sYbbwQHB//rX//Kyso6d+7c\nqFGjCjbP23M3N7fx48f369fv6NGj3bp1E5HExMSVK1ceP35cp9PVqFFj2LBhfn5+InLlypWP\nPvro+vXr3t7eQ4YMmTZt2pIlS6pWrdq7d+/XXntt8+bN9erVe/3114tqHhkZ+c0339y+fdvW\n1rZly5ZDhw61srIqtDAxMXHVqlW///57dnZ29erVhw0bVq1atZycnHwHKrTtw/2w8TDS0tJ6\n9er15JNPKvHgueee2717d1xcXPXq1fPV5NJ4zC+N8PDwmjVr+vv7S7G/8Vq0aLFy5co9e/Z0\n7dr1we8PAOUT9xCiTHXq1Mnd3b3k9bOzs8PDw21tbRs1aqSUVKtW7bfffrt8+bKpTuPGjRs3\nbvzAXT1yQ6iQg4PD5MmTlc9GInL37l2NRuPi4lJMk7J/rwYFBZ05c0b5+vTp01WrVlVeZmVl\nXbhwQal/7tw5JycnLy+vBx5Uq9VqtdqcnBzl5aJFi0Rk1apVa9eurVWr1vTp0zMzMw0Gw6xZ\ns3x9fTds2DBx4sT169eLiE6n0+l0Go0mPDz8zTffHDlyZFHN4+LiPvjggxEjRnz55ZeLFi26\nePHitm3bCi0Ukbfeeis9PX3p0qWffvqpv7//G2+8kZKSku9ARbVF6XFycurdu7eSBlNSUrZt\n2+bj4+Pj41NMEy6Nx/PSOHHiRFBQkPJ1Mb/xNBpNw4YNo6KiHviNAlB+MUKIx9EPP/wQGRkp\nIpmZmfb29uPHj3d1dVU2DRs2bMWKFRMmTHB3d69bt25gYGBISIiTk9MD9/nIDaFyKSkpy5Yt\n69Gjh2nQIC8zvleDgoI+//xzEcnIyLh+/fqLL774+++/d+zY8Y8//rCxsalRo4aIREVFmT6F\nFyMjI2PTpk2ZmZnNmjUTkevXr588eXLDhg3K8MsLL7ywY8eOI0eOODk5JSYm9uvXz9ra2tvb\nu3v37osXL1b2oNFomjdvrow2FNXc3d3daDTa29trtVp3d/eFCxdqtdo//vijYOGVK1cuXLiw\nfPnySpUqKXvYuXPnoUOHQkND8x4oOjq6YNsHniz+d7m5uc8++2x2dnZgYOBbb71laWlZsA6X\nhrKHx/bSuH79et++fQuecsHfeNWqVfvxxx8f+L0CUH4RCPE4atu2rXJPSGZm5sWLF5cuXfri\niy8++eSTImJvbz9p0qQRI0acOXPm/Pnz27ZtW7ly5ejRozt27Fj8Ph+5IdTsxo0bc+fODQoK\nGjp0aKEVzPheDQoKWrhw4b179/78809/f/+GDRsqgwCnT58OCgpSlsqIiorq3bt3oUcxfV4X\nkYyMDD8/v6lTpyrT82JjY0Vk4MCBeevHxcVlZWUpny+VknwTaE2DLUU1b926dbdu3SZOnFiz\nZs2goKB27dr5+PjUqlWrYOHNmzc1Go1pvEKv17u6usbFxeU7UKFti//e4h+h1WqXLl2amJi4\nbdu2qVOnLly40M7OLl8dLg2Tx/DSSEtLy87OdnR0zHfuhf7Gc3R0TE5OLvR7BaBiIBDicWRn\nZ2e6b6RatWpJSUmff/658klC4ejo2LJly5YtWw4ZMmT16tUrVqxo165dSW6jf+SGUKGTJ0++\n9957/fv3V+4dKpQZ36sODg41atQ4e/bsxYsX69ev7+vrm5qampCQcPr06bCwMBFJSUn5888/\nixoGMX1eT0tLmz59+lNPPWW6NUv5xPz111/nu+lo9+7deZdkzLc8o2mYqKjmIjJixIhnnnnm\nyJEjR44c+eqrryZMmNCmTZuChQUXjTQajabCvAcqdIcP+M7in+Dr6+vr61uvXr2BAwfu2bOn\n4DXCpWFSXi6NkvzGA1AhMbsG5YDRaMzNzRWRO3fuLFiwQFlw3CQwMDAjIyM9Pb2YPTxyQ6jW\n2bNn33vvvQkTJjzUZ6Myfq8q90qdPn26fv36IlK3bt3jx49fvHgxODhYRE6dOuXn51fUTDzl\n83qVKlVq1Kjx8ssvr1mzJjo6WtmkjDNcuXLFVFkZgnBxccnJybl7965SeOHChUL3XFTznJyc\npKQkNze3rl27zpgx46mnntq5c2ehhV5eXkaj8caNG0rzjIyMhISEvIuLKAptW9Q3Fv+IkydP\nvvzyyxkZGcpLrVar0WhK8pw6Lo1impf9pWFra2thYZF33K+Y33jJyckFxxIBVCQEQpSpe/fu\nxcfHp6SkiEh8fHx8fLzywSIiIuL77783VcvIyFC23rx5c9++fd99953yp01XV9fo6Oi5c+ce\nPnz4zp07t2/fPnDgwNq1a4OCguzt7Ys57iM3hDplZWUtWbLk6aef9vPzi//LY/heDQ4OPnny\n5LVr15QHwQUGBm7bts3Ly0tZqjEqKsq0aETxOnTo0KRJkwULFhgMBhHx9fVt2LDhmjVr4uPj\nc3JywsPDx4wZc+/evTp16tja2n711VeZmZkxMTHh4eGF7q2o5rt37x4/fvylS5eMRmNiYuL1\n69c9PT0LLaxevXqdOnXWr1+flJSUlpa2bt06GxubkJCQfAcqtG1JzhePLCAgIDMzc+nSpdHR\n0XFxcatXr87IyFCWaeHSKF+Xhp+f39WrV5Wvi/mNJyJXr15VlkIFUFExZRRlatKkSaa/7770\n0ksiMmzYsKeffjoqKio5OblHjx7KpsjISOUWDktLSw8Pj+7duz/zzDMiotVq582b9+WXX65Z\ns+bu3btardbDw6NTp04PfGbuIzeEOp07dy4uLu7zzz9XlqZQjBgxolu3bo/Ve7Vu3bp37twJ\nCAhQZqDVq1dvzZo1pjujoqKilIUNS+KVV14ZPXr0unXrhg8fLiITJkxYtWrV6NGjc3Nzq1Wr\nNmvWLOWT9NSpU1euXDlgwAB/f/9+/frNmDGj0HVcCm0eGhp69+7d+fPn37t3z87OrkmTJkOH\nDrW1tS1YKCL//ve/P/nkk+HDh1taWtauXXv+/PnKk+jyKnSHJTxfPBo7O7s5c+asX79+ypQp\nOTk5VatWnTFjhjLwxaVRvi6N4ODgqKgoZXJsMb/xlOc9Frr8DIAKo0QzPQAAEJGcnByj0Whh\nYSEif/zxx6RJkzZv3lzw8yigNuXu0rh9+/bIkSMXLlyoLExalIMHDy5btmz16tU8mB6owJgy\nCgAoEaPROHr06A8//DA1NfXevXubNm1q0KDB4/yRFygb5fHS8PDw6Nq162effVZMnZycnM2b\nN/ft25c0CFRsjBACAErq2rVrK1euvHjxopWVVYMGDYYNG2Z6uBygZuXx0jAYDP/+9787depk\nmuibz7p1665fvz59+vSCq5sCqEgIhAAAAACgUkwZBQAAAACVIhACAAAAgEoRCAEAAABApQiE\nAAAAAKBSBEIAeHzNmjVLo9F4eHgYDIaCW4cPH67RaNq0afNoO3/++eft7e1LUrNNmzZ16tR5\ntKMAAIDHGYEQAB5rWq02ISEhPDw8X3lGRsZXX31lZWVlll4BAICKgUAIAI81rVYbEhKybt26\nfOXbtm1LTU1t3LixOToFAAAqCAIhADzWsrOze/XqtWPHjrt37+Yt37BhQ8eOHfONEIaHh7dr\n187BwcHGxqZ+/frvv/++6WGzRqNxzpw5vr6+1tbWDRo0+Prrr/M9bPrXX38NCwtzdHS0sbEJ\nDg5es2ZNof25efPm8OHDq1atam1t7enp+cwzz5w/f/4fPWMAAFB2CIQA8Ljr3bt3dnb2pk2b\nTCW3b9/+8ccfn3/++aysLFPh1q1bu3XrJiLr1q377rvvWrVqNWHChEmTJilbFyxYMHPmzLZt\n237//fdTp06dOXPmiRMnTG337NnTsWNHg8GwcePGbdu2hYSEDB06dOHChQU706dPn+3bt8+Y\nMWPnzp0LFy68cOFC+/bt09LSSuvkAQBAadKY/ngMAHjczJo1a/bs2enp6T169Lh3797Ro0eV\n8qVLl77xxhu3bt0KCwuzsLDYv3+/iNStWzc1NfXixYt6vV6ppoS3mzdvuri4+Pj4ODs7nz59\nWhkYjI2NrVatmpWV1f3790WkadOmCQkJ586dM7Xt2bPnL7/8cvPmTRsbmzZt2sTHx58/fz45\nOdnJyWny5Mnz589Xqv3555+bN28eNGiQl5dXGX9zAADA/44RQgAoBwYPHnzs2LEzZ84oLzds\n2NCrVy8HBwdThdjY2PPnz3ft2tWU6ESkW7duBoPh4MGD0dHRsbGxnTp1Mk0T9fLyatq0qfJ1\nfHz8sWPHnnzySaPRmPGXp556Kikp6dixY3m7YWtr6+bmtnnz5sjIyNzcXBGpXr36G2+8QRoE\nAKCcIhACQDnQu3dvBwcHZWmZs2fPHj9+fODAgXkrxMTEiIiPj0/eQiWn3bx5My4uTkQ8PDwK\nbhWR6OhoEVmxYoVNHiNHjjTt1sTCwmLnzp0ajSY0NNTd3b1v376bNm3Kycn5h88WAACUFQtz\ndwAA8GC2trbPPffcxo0b58+fv2HDhipVqoSFheWtoAz95b2lUESUmwI0msLvDjAFOaXtkCFD\nXn755Xx1AgIC8pU0a9bs0qVLe/fu/eGHH8LDw7/88svly5fv3r0778gkAAAoLwiEAFA+DBo0\naM2aNfv379+8eXP//v11Ol3erb6+vvLXWJ/JjRs3RMTHx8fd3V1Ebt26lXfr1atXlS/8/PxE\nJDc3NyQkpCQ90el0HTt27Nix47vvvvvJJ5+MHDnyiy++yDdiCQAAygWmjAJA+dC2bVt/f/8F\nCxZcu3atYPqqXLlygwYNtm/fnp6ebircunWrra1ty5Ytq1Wr5ubmZrrxT0TOnz9/6tQp5WsX\nF5fmzZtv3bo1MTHR1HbDhg3Tpk3Lzs7Oe5SjR48+//zzt/zxdUMAAAGUSURBVG/fNpUoA5V5\nSwAAQDlCIASA8kGj0QwcOHDHjh2NGjVq2LBhwQrvvPPOvXv3wsLCvvnmm++//75///7h4eHT\np093dHTUarWjRo06d+5cnz59vv76648++ujJJ59s0qSJqe17772XlpbWtm3bzz777Keffpo+\nffqwYcNiY2MtLP42kcTb2/uHH34ICwtbs2ZNRETEpk2bBgwYoNfre/ToUernDwAASgFTRgGg\n3Bg4cODs2bOLmpzZrVu3nTt3vv3224MGDcrOzq5Xr96aNWuGDBmibJ05c6bBYFi3bl14eHjt\n2rWXLFmyZ8+eqKgoZWv79u137949Z86cV1991WAwVK9efc6cOaZnGJpUqVJl7969c+bMmTp1\nakJCgqura/Pmzffu3Vu7du3SO2sAAFB6eA4hAAAAAKgUU0YBAAAAQKUIhAAAAACgUgRCAAAA\nAFApAiEAAAAAqBSBEAAAAABUikAIAAAAACpFIAQAAAAAlSIQAgAAAIBKEQgBAAAAQKUIhAAA\nAACgUgRCAAAAAFCp/wemoMO+1E4JJwAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- new.get_result(result.m02.1, '1.BSTS')\n",
    "errors.2 <- new.get_result(result.m02.2, '2.BSTS w/ Regressors')\n",
    "errors.3 <- new.get_result(result.m02.3, '3.BSTS w/ Regressors (2)')\n",
    "\n",
    "#x <- errors.1\n",
    "x <- rbind(errors.1, errors.2)\n",
    "x <- rbind(x, errors.3)\n",
    "\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "78dcd688-1d13-455f-a104-9ce887522de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m02 <- result.m02.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18309db-511c-4dca-aae2-184266480211",
   "metadata": {},
   "source": [
    "### save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90ba8638-887a-4a67-868c-d3612e3556db",
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- result.m02.1\n",
    "write.csv(x, file = \"bsts_result_m0201.csv\")\n",
    "x <- result.m02.2\n",
    "write.csv(x, file = \"bsts_result_m0202.csv\")\n",
    "x <- result.m02.3\n",
    "write.csv(x, file = \"bsts_result_m0203.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d128253-162e-4222-b582-fb0ee3ef80e7",
   "metadata": {},
   "source": [
    "### load result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bb1bd39-9ed6-4fb6-8abe-4d35c9b83632",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.m02.1 <- read.csv(file = 'bsts_result_m0201.csv')\n",
    "result.m02.2 <- read.csv(file = 'bsts_result_m0202.csv')\n",
    "result.m02.3 <- read.csv(file = 'bsts_result_m0203.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69617942-9647-4c39-9fab-68b25004a5f6",
   "metadata": {},
   "source": [
    "# ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714a4470-8e12-439a-b2ef-3b3e4d106e65",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1649827c-2f89-40f9-939c-5a35daceab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast <- function(x, h, xreg=NULL, xreg.msize=NULL, order=NULL) {\n",
    "    \n",
    "    if (!is.null(xreg)) {\n",
    "        \n",
    "        if (is.null(xreg.msize)) {\n",
    "            xreg.m <- xreg # calc mean for future with all the xreg\n",
    "        } else {\n",
    "            # calc mean for future with xreg of length xreg.mszie\n",
    "            xreg.m <- tail(xreg, n=xreg.msize)\n",
    "        }\n",
    "        \n",
    "        if (is.null(dim(xreg))) {\n",
    "            xreg.h <- mean(xreg.m)\n",
    "        } else {\n",
    "            xreg.h <- colMeans(xreg.m)  \n",
    "        }\n",
    "        \n",
    "        xreg.h <- data.frame(xreg.h)\n",
    "        colnames(xreg.h) <- colnames(NA)\n",
    "        #colnames(xreg.h) <- colnames(xreg) # error with multiple xreg\n",
    "        xreg.h <- t(xreg.h)\n",
    "        xreg.h <- as.ts(xreg.h[rep(seq_len(nrow(xreg.h)), h), ])\n",
    "        \n",
    "        ## added for single day forecast\n",
    "        xreg.coln <- colnames(xreg)\n",
    "        xreg.h <- data.frame(xreg.h) # convert to frame for the case of single xreg\n",
    "        if ((dim(xreg.h)[2]==1) & (dim(xreg.h)[1]==length(xreg.coln))) {\n",
    "            xreg.h <- t(xreg.h) # the case of h==1\n",
    "        } else {\n",
    "            xreg.h <- as.ts(xreg.h) # convert to ts as xreg is ts\n",
    "        }\n",
    "        \n",
    "    } else {\n",
    "        xreg.h <- NULL\n",
    "    }\n",
    "    if (is.null(order)) {\n",
    "        fc <- forecast(auto.arima(x, trace=TRUE, ic='aicc', seasonal=FALSE, \n",
    "                                  xreg=xreg, \n",
    "                                  #lambda=\"auto\" # not for negative value\n",
    "                                  ), h=h, xreg=xreg.h)\n",
    "    } else {\n",
    "        fc <- forecast(Arima(x, order=order, seasonal=FALSE, \n",
    "                                  xreg=xreg, \n",
    "                                  ), h=h, xreg=xreg.h)\n",
    "    }\n",
    "    return(fc)\n",
    "}\n",
    "\n",
    "arima.forecast <- cv.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1de1569-7395-4fe7-99a4-f041baf77365",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast.2 <- function(x, h, ...) {\n",
    "    new.forecast(x, h, cv.forecast, ...)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0145d7-e293-4fdd-8dbb-f62c0d26e658",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b05b4a06-7253-42c9-b6f0-28b182f99b79",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -8729.901\n",
      " ARIMA(1,0,0) with non-zero mean : -13486.9\n",
      " ARIMA(0,0,1) with non-zero mean : -10820.55\n",
      " ARIMA(0,0,0) with zero mean     : -8407.697\n",
      " ARIMA(2,0,0) with non-zero mean : -13491.63\n",
      " ARIMA(3,0,0) with non-zero mean : -13491.75\n",
      " ARIMA(4,0,0) with non-zero mean : -13496.44\n",
      " ARIMA(5,0,0) with non-zero mean : -13502.01\n",
      " ARIMA(5,0,1) with non-zero mean : -13509.96\n",
      " ARIMA(4,0,1) with non-zero mean : -13504.29\n",
      " ARIMA(5,0,2) with non-zero mean : -13507.99\n",
      " ARIMA(4,0,2) with non-zero mean : -13508.66\n",
      " ARIMA(5,0,1) with zero mean     : -13497.02\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,1) with non-zero mean : -13497.21\n",
      "\n",
      " Best model: ARIMA(5,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -13377.54\n",
      " ARIMA(1,1,0) with drift         : -13378.28\n",
      " ARIMA(0,1,1) with drift         : -13376.14\n",
      " ARIMA(0,1,0)                    : -13379.49\n",
      " ARIMA(1,1,1) with drift         : -13377.51\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -13388.23\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -13351.94\n",
      " ARIMA(0,1,0) with drift         : -13329.65\n",
      " ARIMA(1,1,0) with drift         : -13329.34\n",
      " ARIMA(0,1,1) with drift         : -13328.48\n",
      " ARIMA(0,1,0)                    : -13331.64\n",
      " ARIMA(1,1,2) with drift         : -13333.18\n",
      " ARIMA(2,1,1) with drift         : -13367.24\n",
      " ARIMA(1,1,1) with drift         : -13327.34\n",
      " ARIMA(2,1,0) with drift         : -13329.21\n",
      " ARIMA(3,1,1) with drift         : -13330.64\n",
      " ARIMA(3,1,0) with drift         : -13332.29\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1)                    : -13368.81\n",
      " ARIMA(1,1,1)                    : -13329.32\n",
      " ARIMA(2,1,0)                    : -13331.19\n",
      " ARIMA(3,1,1)                    : -13332.67\n",
      " ARIMA(2,1,2)                    : -13353.95\n",
      " ARIMA(1,1,0)                    : -13331.32\n",
      " ARIMA(1,1,2)                    : -13348.06\n",
      " ARIMA(3,1,0)                    : -13334.28\n",
      " ARIMA(3,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,1)                    : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -13393.73\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -13234.71\n",
      " ARIMA(1,1,0) with drift         : -13232.87\n",
      " ARIMA(0,1,1) with drift         : -13233.97\n",
      " ARIMA(0,1,0)                    : -13236.7\n",
      " ARIMA(1,1,1) with drift         : -13231.87\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -13245.39\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13263.35\n",
      " ARIMA(0,0,0) with non-zero mean : -8706.059\n",
      " ARIMA(1,0,0) with non-zero mean : -13255.84\n",
      " ARIMA(0,0,1) with non-zero mean : -10773.99\n",
      " ARIMA(0,0,0) with zero mean     : -8448.555\n",
      " ARIMA(1,0,2) with non-zero mean : -13260.91\n",
      " ARIMA(2,0,1) with non-zero mean : -13259.89\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -13259.02\n",
      " ARIMA(1,0,1) with non-zero mean : -13262.92\n",
      " ARIMA(1,0,3) with non-zero mean : -13261.08\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -13255.47\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13263\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13234.55\n",
      " ARIMA(0,0,0) with non-zero mean : -8691.834\n",
      " ARIMA(1,0,0) with non-zero mean : -13229.55\n",
      " ARIMA(0,0,1) with non-zero mean : -10751.25\n",
      " ARIMA(0,0,0) with zero mean     : -8433.02\n",
      " ARIMA(1,0,2) with non-zero mean : -13235.37\n",
      " ARIMA(0,0,2) with non-zero mean : -11866.88\n",
      " ARIMA(1,0,1) with non-zero mean : -13237.32\n",
      " ARIMA(2,0,1) with non-zero mean : -13225.93\n",
      " ARIMA(2,0,0) with non-zero mean : -13237.39\n",
      " ARIMA(3,0,0) with non-zero mean : -13234.61\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(2,0,0) with zero mean     : -13228.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,0) with non-zero mean : -13235.12\n",
      "\n",
      " Best model: ARIMA(2,0,0) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13226.64\n",
      " ARIMA(0,0,0) with non-zero mean : -8693.681\n",
      " ARIMA(1,0,0) with non-zero mean : -13220.86\n",
      " ARIMA(0,0,1) with non-zero mean : -10750.64\n",
      " ARIMA(0,0,0) with zero mean     : -8430.203\n",
      " ARIMA(1,0,2) with non-zero mean : -13226.25\n",
      " ARIMA(2,0,1) with non-zero mean : -13226.06\n",
      " ARIMA(3,0,2) with non-zero mean : -13309.63\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -13307.61\n",
      " ARIMA(2,0,3) with non-zero mean : -13226.59\n",
      " ARIMA(4,0,1) with non-zero mean : -13224.04\n",
      " ARIMA(4,0,3) with non-zero mean : -13224.26\n",
      " ARIMA(3,0,2) with zero mean     : -13300.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,2) with non-zero mean : -13225.89\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13223.46\n",
      " ARIMA(0,0,0) with non-zero mean : -8692.073\n",
      " ARIMA(1,0,0) with non-zero mean : -13216.09\n",
      " ARIMA(0,0,1) with non-zero mean : -10746.36\n",
      " ARIMA(0,0,0) with zero mean     : -8438.64\n",
      " ARIMA(1,0,2) with non-zero mean : -13219.99\n",
      " ARIMA(2,0,1) with non-zero mean : -13219.26\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -13218.58\n",
      " ARIMA(1,0,1) with non-zero mean : -13221.81\n",
      " ARIMA(1,0,3) with non-zero mean : -13219.71\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -13215.75\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13222.6\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -8686.987\n",
      " ARIMA(1,0,0) with non-zero mean : -13209.96\n",
      " ARIMA(0,0,1) with non-zero mean : -10738.7\n",
      " ARIMA(0,0,0) with zero mean     : -8426.26\n",
      " ARIMA(2,0,0) with non-zero mean : -13214.47\n",
      " ARIMA(3,0,0) with non-zero mean : -13211.74\n",
      " ARIMA(2,0,1) with non-zero mean : -13212.45\n",
      " ARIMA(1,0,1) with non-zero mean : -13215.28\n",
      " ARIMA(1,0,2) with non-zero mean : -13213.51\n",
      " ARIMA(0,0,2) with non-zero mean : -11840.92\n",
      " ARIMA(1,0,1) with zero mean     : -13207.44\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -13213.63\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13183.35\n",
      " ARIMA(0,0,0) with non-zero mean : -8605.008\n",
      " ARIMA(1,0,0) with non-zero mean : -13178.74\n",
      " ARIMA(0,0,1) with non-zero mean : -10671.87\n",
      " ARIMA(0,0,0) with zero mean     : -8372.744\n",
      " ARIMA(1,0,2) with non-zero mean : -13181.28\n",
      " ARIMA(2,0,1) with non-zero mean : -13180.26\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -13179.48\n",
      " ARIMA(1,0,1) with non-zero mean : -13183.22\n",
      " ARIMA(1,0,3) with non-zero mean : -13180.78\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -13173.21\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13183.36\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13157.75\n",
      " ARIMA(0,0,0) with non-zero mean : -8599.633\n",
      " ARIMA(1,0,0) with non-zero mean : -13156.4\n",
      " ARIMA(0,0,1) with non-zero mean : -10657.5\n",
      " ARIMA(0,0,0) with zero mean     : -8371.167\n",
      " ARIMA(1,0,2) with non-zero mean : -13159.03\n",
      " ARIMA(0,0,2) with non-zero mean : -11765.46\n",
      " ARIMA(1,0,1) with non-zero mean : -13161.04\n",
      " ARIMA(2,0,1) with non-zero mean : -13159.02\n",
      " ARIMA(2,0,0) with non-zero mean : -13160.94\n",
      " ARIMA(1,0,1) with zero mean     : -13153.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -13157.39\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13118.41\n",
      " ARIMA(0,0,0) with non-zero mean : -8582.353\n",
      " ARIMA(1,0,0) with non-zero mean : -13116.65\n",
      " ARIMA(0,0,1) with non-zero mean : -10629.58\n",
      " ARIMA(0,0,0) with zero mean     : -8368.258\n",
      " ARIMA(1,0,2) with non-zero mean : -13119.21\n",
      " ARIMA(0,0,2) with non-zero mean : -11723.45\n",
      " ARIMA(1,0,1) with non-zero mean : -13121.15\n",
      " ARIMA(2,0,1) with non-zero mean : -13118.75\n",
      " ARIMA(2,0,0) with non-zero mean : -13120.42\n",
      " ARIMA(1,0,1) with zero mean     : -13115.91\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -13113.39\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13071.29\n",
      " ARIMA(0,0,0) with non-zero mean : -8638.881\n",
      " ARIMA(1,0,0) with non-zero mean : -13070.54\n",
      " ARIMA(0,0,1) with non-zero mean : -10684.56\n",
      " ARIMA(0,0,0) with zero mean     : -8450.488\n",
      " ARIMA(1,0,2) with non-zero mean : -13073.57\n",
      " ARIMA(0,0,2) with non-zero mean : -11760.84\n",
      " ARIMA(1,0,1) with non-zero mean : -13074.77\n",
      " ARIMA(2,0,1) with non-zero mean : -13072.43\n",
      " ARIMA(2,0,0) with non-zero mean : -13073.94\n",
      " ARIMA(1,0,1) with zero mean     : -13068.78\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -13073.39\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13020.07\n",
      " ARIMA(0,0,0) with non-zero mean : -8626.698\n",
      " ARIMA(1,0,0) with non-zero mean : -13019.34\n",
      " ARIMA(0,0,1) with non-zero mean : -10666.27\n",
      " ARIMA(0,0,0) with zero mean     : -8430.999\n",
      " ARIMA(1,0,2) with non-zero mean : -13022.74\n",
      " ARIMA(0,0,2) with non-zero mean : -11728.64\n",
      " ARIMA(1,0,1) with non-zero mean : -13023.48\n",
      " ARIMA(2,0,1) with non-zero mean : -13021.47\n",
      " ARIMA(2,0,0) with non-zero mean : -13022.39\n",
      " ARIMA(1,0,1) with zero mean     : -13018.08\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -13022.46\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12895.32\n",
      " ARIMA(1,1,0) with drift         : -12892.39\n",
      " ARIMA(0,1,1) with drift         : -12893.4\n",
      " ARIMA(0,1,0)                    : -12897.3\n",
      " ARIMA(1,1,1) with drift         : -12891.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12905.83\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12860.21\n",
      " ARIMA(0,1,0) with drift         : -12826.47\n",
      " ARIMA(1,1,0) with drift         : -12823.83\n",
      " ARIMA(0,1,1) with drift         : -12824.58\n",
      " ARIMA(0,1,0)                    : -12828.46\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : -12831.77\n",
      " ARIMA(3,1,2) with drift         : -12826.3\n",
      " ARIMA(2,1,3) with drift         : -12865.48\n",
      " ARIMA(1,1,3) with drift         : -12829.73\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : -12864.1\n",
      " ARIMA(1,1,4) with drift         : -12827.86\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -12866.89\n",
      " ARIMA(1,1,3)                    : -12831.68\n",
      " ARIMA(2,1,2)                    : -12861.71\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : -12865.52\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,4)                    : -12829.85\n",
      " ARIMA(3,1,2)                    : -12828.31\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3)                    : -12840.65\n",
      "\n",
      " Best model: ARIMA(1,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -8273.531\n",
      " ARIMA(1,0,0) with non-zero mean : -12881.86\n",
      " ARIMA(0,0,1) with non-zero mean : -10351.3\n",
      " ARIMA(0,0,0) with zero mean     : -8122.831\n",
      " ARIMA(2,0,0) with non-zero mean : -12882.19\n",
      " ARIMA(3,0,0) with non-zero mean : -12880.27\n",
      " ARIMA(2,0,1) with non-zero mean : -12880.5\n",
      " ARIMA(1,0,1) with non-zero mean : -12883.25\n",
      " ARIMA(1,0,2) with non-zero mean : -12881.73\n",
      " ARIMA(0,0,2) with non-zero mean : -11451.56\n",
      " ARIMA(1,0,1) with zero mean     : -12879.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -12882.2\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12871.42\n",
      " ARIMA(0,0,0) with non-zero mean : -8262.48\n",
      " ARIMA(1,0,0) with non-zero mean : -12871.81\n",
      " ARIMA(0,0,1) with non-zero mean : -10340.93\n",
      " ARIMA(0,0,0) with zero mean     : -8109.969\n",
      " ARIMA(2,0,0) with non-zero mean : -12874.6\n",
      " ARIMA(3,0,0) with non-zero mean : -12872.38\n",
      " ARIMA(2,0,1) with non-zero mean : -12873.19\n",
      " ARIMA(1,0,1) with non-zero mean : -12874.05\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(2,0,0) with zero mean     : -12871.34\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,0) with non-zero mean : -12872.16\n",
      "\n",
      " Best model: ARIMA(2,0,0) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12770.64\n",
      " ARIMA(1,1,0) with drift         : -12768.42\n",
      " ARIMA(0,1,1) with drift         : -12768.88\n",
      " ARIMA(0,1,0)                    : -12772.63\n",
      " ARIMA(1,1,1) with drift         : -12767.46\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12781.1\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12763.47\n",
      " ARIMA(1,1,0) with drift         : -12760.68\n",
      " ARIMA(0,1,1) with drift         : -12761.67\n",
      " ARIMA(0,1,0)                    : -12765.47\n",
      " ARIMA(1,1,1) with drift         : -12759.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12773.95\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12720.9\n",
      " ARIMA(1,1,0) with drift         : -12718.16\n",
      " ARIMA(0,1,1) with drift         : -12719.09\n",
      " ARIMA(0,1,0)                    : -12722.86\n",
      " ARIMA(1,1,1) with drift         : -12716.81\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12731.32\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12666.53\n",
      " ARIMA(1,1,0) with drift         : -12663.76\n",
      " ARIMA(0,1,1) with drift         : -12664.79\n",
      " ARIMA(0,1,0)                    : -12668.52\n",
      " ARIMA(1,1,1) with drift         : -12662.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12676.95\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12648.97\n",
      " ARIMA(1,1,0) with drift         : -12646.42\n",
      " ARIMA(0,1,1) with drift         : -12647.47\n",
      " ARIMA(0,1,0)                    : -12650.97\n",
      " ARIMA(1,1,1) with drift         : -12645.43\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12659.4\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12632.45\n",
      " ARIMA(0,1,0) with drift         : -12633.22\n",
      " ARIMA(1,1,0) with drift         : -12630.63\n",
      " ARIMA(0,1,1) with drift         : -12631.67\n",
      " ARIMA(0,1,0)                    : -12635.23\n",
      " ARIMA(1,1,1) with drift         : -12629.76\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12643.64\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12619.17\n",
      " ARIMA(1,1,0) with drift         : -12616.45\n",
      " ARIMA(0,1,1) with drift         : -12617.47\n",
      " ARIMA(0,1,0)                    : -12621.17\n",
      " ARIMA(1,1,1) with drift         : -12615.73\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12629.58\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12599.68\n",
      " ARIMA(1,1,0) with drift         : -12597.63\n",
      " ARIMA(0,1,1) with drift         : -12597.91\n",
      " ARIMA(0,1,0)                    : -12601.68\n",
      " ARIMA(1,1,1) with drift         : -12597.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12610.08\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12585.52\n",
      " ARIMA(1,1,0) with drift         : -12583.61\n",
      " ARIMA(0,1,1) with drift         : -12583.79\n",
      " ARIMA(0,1,0)                    : -12587.53\n",
      " ARIMA(1,1,1) with drift         : -12582.95\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12595.92\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12575.75\n",
      " ARIMA(1,1,0) with drift         : -12573.03\n",
      " ARIMA(0,1,1) with drift         : -12574\n",
      " ARIMA(0,1,0)                    : -12577.75\n",
      " ARIMA(1,1,1) with drift         : -12572.21\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12586.14\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12556.22\n",
      " ARIMA(0,1,0) with drift         : -12555.96\n",
      " ARIMA(1,1,0) with drift         : -12553.13\n",
      " ARIMA(0,1,1) with drift         : -12554.03\n",
      " ARIMA(0,1,0)                    : -12557.96\n",
      " ARIMA(1,1,1) with drift         : -12552.09\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12566.34\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12536.16\n",
      " ARIMA(0,1,0) with drift         : -12534.17\n",
      " ARIMA(1,1,0) with drift         : -12531.56\n",
      " ARIMA(0,1,1) with drift         : -12532.27\n",
      " ARIMA(0,1,0)                    : -12536.16\n",
      " ARIMA(1,1,1) with drift         : -12530.62\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12544.53\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12493.21\n",
      " ARIMA(0,1,0) with drift         : -12492.02\n",
      " ARIMA(1,1,0) with drift         : -12489.42\n",
      " ARIMA(0,1,1) with drift         : -12490.39\n",
      " ARIMA(0,1,0)                    : -12494.01\n",
      " ARIMA(1,1,1) with drift         : -12488.94\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12502.36\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12363.39\n",
      " ARIMA(1,1,0) with drift         : -12361.92\n",
      " ARIMA(0,1,1) with drift         : -12362.83\n",
      " ARIMA(0,1,0)                    : -12365.4\n",
      " ARIMA(1,1,1) with drift         : -12361.31\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12373.69\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12316.14\n",
      " ARIMA(0,1,0) with drift         : -12318.09\n",
      " ARIMA(1,1,0) with drift         : -12316.48\n",
      " ARIMA(0,1,1) with drift         : -12317.45\n",
      " ARIMA(0,1,0)                    : -12320.08\n",
      " ARIMA(1,1,1) with drift         : -12315.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12328.35\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12249.54\n",
      " ARIMA(0,1,0) with drift         : -12252.65\n",
      " ARIMA(1,1,0) with drift         : -12251.38\n",
      " ARIMA(0,1,1) with drift         : -12252.12\n",
      " ARIMA(0,1,0)                    : -12254.65\n",
      " ARIMA(1,1,1) with drift         : -12249.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12262.9\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12188.61\n",
      " ARIMA(0,1,0) with drift         : -12192.2\n",
      " ARIMA(1,1,0) with drift         : -12190.99\n",
      " ARIMA(0,1,1) with drift         : -12191.78\n",
      " ARIMA(0,1,0)                    : -12194.2\n",
      " ARIMA(1,1,1) with drift         : -12189.56\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12202.42\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12173.86\n",
      " ARIMA(0,1,0) with drift         : -12177.26\n",
      " ARIMA(1,1,0) with drift         : -12175.8\n",
      " ARIMA(0,1,1) with drift         : -12176.9\n",
      " ARIMA(0,1,0)                    : -12179.26\n",
      " ARIMA(1,1,1) with drift         : -12174.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12187.48\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12149.5\n",
      " ARIMA(0,1,0) with drift         : -12153.1\n",
      " ARIMA(1,1,0) with drift         : -12151.82\n",
      " ARIMA(0,1,1) with drift         : -12152.63\n",
      " ARIMA(0,1,0)                    : -12155.1\n",
      " ARIMA(1,1,1) with drift         : -12150.29\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12163.3\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12128.62\n",
      " ARIMA(1,1,0) with drift         : -12127.02\n",
      " ARIMA(0,1,1) with drift         : -12127.98\n",
      " ARIMA(0,1,0)                    : -12130.62\n",
      " ARIMA(1,1,1) with drift         : -12125.41\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12138.81\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12094.83\n",
      " ARIMA(1,1,0) with drift         : -12093.74\n",
      " ARIMA(0,1,1) with drift         : -12093.52\n",
      " ARIMA(0,1,0)                    : -12096.83\n",
      " ARIMA(1,1,1) with drift         : -12091.74\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12105.01\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12082.79\n",
      " ARIMA(0,1,0) with drift         : -12069.6\n",
      " ARIMA(1,1,0) with drift         : -12068.53\n",
      " ARIMA(0,1,1) with drift         : -12068.08\n",
      " ARIMA(0,1,0)                    : -12071.6\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : -12069.65\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -12085.65\n",
      " ARIMA(1,1,3) with drift         : -12069.73\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : -12083.73\n",
      " ARIMA(1,1,4) with drift         : -12068.47\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -12087.68\n",
      " ARIMA(1,1,3)                    : -12071.71\n",
      " ARIMA(2,1,2)                    : -12068.25\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : -12085.75\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,4)                    : -12070.48\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(1,1,3)                    : -12081.21\n",
      "\n",
      " Best model: ARIMA(1,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12082.77\n",
      " ARIMA(0,1,0) with drift         : -12062.29\n",
      " ARIMA(1,1,0) with drift         : -12059.83\n",
      " ARIMA(0,1,1) with drift         : -12060.73\n",
      " ARIMA(0,1,0)                    : -12064.29\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -12058.07\n",
      " ARIMA(1,1,3) with drift         : -12062.87\n",
      " ARIMA(3,1,1) with drift         : -12071.37\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12093.41\n",
      "\n",
      " Best model: ARIMA(2,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12051.59\n",
      " ARIMA(0,1,0) with drift         : -12056.79\n",
      " ARIMA(1,1,0) with drift         : -12054.21\n",
      " ARIMA(0,1,1) with drift         : -12055.13\n",
      " ARIMA(0,1,0)                    : -12058.79\n",
      " ARIMA(1,1,1) with drift         : -12052.52\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12066.95\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12040.97\n",
      " ARIMA(0,1,0) with drift         : -12045.69\n",
      " ARIMA(1,1,0) with drift         : -12043.05\n",
      " ARIMA(0,1,1) with drift         : -12043.96\n",
      " ARIMA(0,1,0)                    : -12047.7\n",
      " ARIMA(1,1,1) with drift         : -12041.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12055.85\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12035.51\n",
      " ARIMA(1,1,0) with drift         : -12032.9\n",
      " ARIMA(0,1,1) with drift         : -12033.73\n",
      " ARIMA(0,1,0)                    : -12037.51\n",
      " ARIMA(1,1,1) with drift         : -12030.9\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12045.67\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12023.14\n",
      " ARIMA(0,1,0) with drift         : -12028.48\n",
      " ARIMA(1,1,0) with drift         : -12025.73\n",
      " ARIMA(0,1,1) with drift         : -12026.67\n",
      " ARIMA(0,1,0)                    : -12030.49\n",
      " ARIMA(1,1,1) with drift         : -12023.73\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12038.64\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12061.44\n",
      " ARIMA(0,1,0) with drift         : -12023.42\n",
      " ARIMA(1,1,0) with drift         : -12020.51\n",
      " ARIMA(0,1,1) with drift         : -12021.52\n",
      " ARIMA(0,1,0)                    : -12025.42\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : -12021.41\n",
      " ARIMA(3,1,2) with drift         : -12033.17\n",
      " ARIMA(2,1,3) with drift         : -12067.9\n",
      " ARIMA(1,1,3) with drift         : -12035.78\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : -12066.17\n",
      " ARIMA(1,1,4) with drift         : -12034.04\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -12069.61\n",
      " ARIMA(1,1,3)                    : -12037.79\n",
      " ARIMA(2,1,2)                    : -12021.24\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : -12067.88\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,4)                    : -12036.05\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(1,1,3)                    : -12046.92\n",
      "\n",
      " Best model: ARIMA(1,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12015.63\n",
      " ARIMA(0,1,0) with drift         : -12021.2\n",
      " ARIMA(1,1,0) with drift         : -12018.3\n",
      " ARIMA(0,1,1) with drift         : -12019.28\n",
      " ARIMA(0,1,0)                    : -12023.2\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12031.34\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12019.53\n",
      " ARIMA(1,1,0) with drift         : -12016.78\n",
      " ARIMA(0,1,1) with drift         : -12017.59\n",
      " ARIMA(0,1,0)                    : -12021.53\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12029.68\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12017.38\n",
      " ARIMA(1,1,0) with drift         : -12014.64\n",
      " ARIMA(0,1,1) with drift         : -12015.43\n",
      " ARIMA(0,1,0)                    : -12019.38\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12027.53\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12013.54\n",
      " ARIMA(1,1,0) with drift         : -12010.62\n",
      " ARIMA(0,1,1) with drift         : -12011.59\n",
      " ARIMA(0,1,0)                    : -12015.55\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12023.69\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12010.11\n",
      " ARIMA(1,1,0) with drift         : -12007.44\n",
      " ARIMA(0,1,1) with drift         : -12008.17\n",
      " ARIMA(0,1,0)                    : -12012.11\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12020.25\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12001.03\n",
      " ARIMA(1,1,0) with drift         : -11998.11\n",
      " ARIMA(0,1,1) with drift         : -11999.06\n",
      " ARIMA(0,1,0)                    : -12003.03\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12011.17\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11991.51\n",
      " ARIMA(0,1,0) with drift         : -11995.98\n",
      " ARIMA(1,1,0) with drift         : -11993.05\n",
      " ARIMA(0,1,1) with drift         : -11994.03\n",
      " ARIMA(0,1,0)                    : -11997.99\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12006.12\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11996.07\n",
      " ARIMA(1,1,0) with drift         : -11993.21\n",
      " ARIMA(0,1,1) with drift         : -11994.15\n",
      " ARIMA(0,1,0)                    : -11998.07\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12006.21\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11996.85\n",
      " ARIMA(1,1,0) with drift         : -11994.15\n",
      " ARIMA(0,1,1) with drift         : -11994.92\n",
      " ARIMA(0,1,0)                    : -11998.85\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12006.98\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12016.73\n",
      " ARIMA(0,1,0) with drift         : -11995.59\n",
      " ARIMA(1,1,0) with drift         : -11992.68\n",
      " ARIMA(0,1,1) with drift         : -11993.67\n",
      " ARIMA(0,1,0)                    : -11997.59\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12006.39\n",
      " ARIMA(3,1,1) with drift         : -12004.19\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12027.23\n",
      "\n",
      " Best model: ARIMA(2,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12012.2\n",
      " ARIMA(0,1,0) with drift         : -11990.52\n",
      " ARIMA(1,1,0) with drift         : -11987.63\n",
      " ARIMA(0,1,1) with drift         : -11988.63\n",
      " ARIMA(0,1,0)                    : -11992.52\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12001.17\n",
      " ARIMA(3,1,1) with drift         : -11999.02\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12022.54\n",
      "\n",
      " Best model: ARIMA(2,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12043.99\n",
      " ARIMA(0,1,0) with drift         : -11987.17\n",
      " ARIMA(1,1,0) with drift         : -11984.55\n",
      " ARIMA(0,1,1) with drift         : -11985.26\n",
      " ARIMA(0,1,0)                    : -11989.17\n",
      " ARIMA(1,1,2) with drift         : -12023.86\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11982.54\n",
      " ARIMA(1,1,3) with drift         : -11995.32\n",
      " ARIMA(3,1,1) with drift         : -11994.67\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12006.86\n",
      "\n",
      " Best model: ARIMA(1,1,3) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11981.5\n",
      " ARIMA(1,1,0) with drift         : -11979.09\n",
      " ARIMA(0,1,1) with drift         : -11979.6\n",
      " ARIMA(0,1,0)                    : -11983.5\n",
      " ARIMA(1,1,1) with drift         : -11977.09\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11991.63\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11978.9\n",
      " ARIMA(1,1,0) with drift         : -11976.01\n",
      " ARIMA(0,1,1) with drift         : -11977.01\n",
      " ARIMA(0,1,0)                    : -11980.91\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11989.03\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11981.39\n",
      " ARIMA(1,1,0) with drift         : -11978.69\n",
      " ARIMA(0,1,1) with drift         : -11979.53\n",
      " ARIMA(0,1,0)                    : -11983.39\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11991.52\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11986.98\n",
      " ARIMA(1,1,0) with drift         : -11984.6\n",
      " ARIMA(0,1,1) with drift         : -11985.09\n",
      " ARIMA(0,1,0)                    : -11988.99\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11997.12\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11992.9\n",
      " ARIMA(1,1,0) with drift         : -11989.96\n",
      " ARIMA(0,1,1) with drift         : -11990.96\n",
      " ARIMA(0,1,0)                    : -11994.9\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12003.04\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12013.09\n",
      " ARIMA(0,1,0) with drift         : -11992.3\n",
      " ARIMA(1,1,0) with drift         : -11989.52\n",
      " ARIMA(0,1,1) with drift         : -11990.35\n",
      " ARIMA(0,1,0)                    : -11994.3\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12002.95\n",
      " ARIMA(3,1,1) with drift         : -12001.79\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12024.89\n",
      "\n",
      " Best model: ARIMA(2,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11988.37\n",
      " ARIMA(1,1,0) with drift         : -11985.73\n",
      " ARIMA(0,1,1) with drift         : -11986.38\n",
      " ARIMA(0,1,0)                    : -11990.37\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11998.5\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11987.63\n",
      " ARIMA(1,1,0) with drift         : -11984.66\n",
      " ARIMA(0,1,1) with drift         : -11985.63\n",
      " ARIMA(0,1,0)                    : -11989.63\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11997.77\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12008.82\n",
      " ARIMA(0,1,0) with drift         : -11994.44\n",
      " ARIMA(1,1,0) with drift         : -11992.07\n",
      " ARIMA(0,1,1) with drift         : -11992.44\n",
      " ARIMA(0,1,0)                    : -11996.43\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : -11991.26\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12004.44\n",
      " ARIMA(3,1,1) with drift         : -12005.12\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(3,1,1) with drift         : -12014.85\n",
      "\n",
      " Best model: ARIMA(3,1,1) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12059.59\n",
      " ARIMA(0,1,0) with drift         : -12000.97\n",
      " ARIMA(1,1,0) with drift         : -11998.47\n",
      " ARIMA(0,1,1) with drift         : -11998.97\n",
      " ARIMA(0,1,0)                    : -12002.96\n",
      " ARIMA(1,1,2) with drift         : -12039.27\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12008.38\n",
      " ARIMA(3,1,1) with drift         : -12007.62\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -12061.58\n",
      " ARIMA(1,1,2)                    : -12041.15\n",
      " ARIMA(2,1,1)                    : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(1,1,1)                    : Inf\n",
      " ARIMA(1,1,3)                    : -12010.39\n",
      " ARIMA(3,1,1)                    : -12009.59\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(1,1,3)                    : -12023.37\n",
      "\n",
      " Best model: ARIMA(1,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12004.31\n",
      " ARIMA(1,1,0) with drift         : -12001.41\n",
      " ARIMA(0,1,1) with drift         : -12002.33\n",
      " ARIMA(0,1,0)                    : -12006.31\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12014.45\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12001.45\n",
      " ARIMA(1,1,0) with drift         : -11998.66\n",
      " ARIMA(0,1,1) with drift         : -11999.47\n",
      " ARIMA(0,1,0)                    : -12003.45\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12011.58\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11997.55\n",
      " ARIMA(1,1,0) with drift         : -11995.35\n",
      " ARIMA(0,1,1) with drift         : -11995.58\n",
      " ARIMA(0,1,0)                    : -11999.55\n",
      " ARIMA(1,1,1) with drift         : -11996.94\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12007.69\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12000.21\n",
      " ARIMA(1,1,0) with drift         : -11997.28\n",
      " ARIMA(0,1,1) with drift         : -11998.26\n",
      " ARIMA(0,1,0)                    : -12002.22\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12010.35\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12023.7\n",
      " ARIMA(0,1,0) with drift         : -12005.68\n",
      " ARIMA(1,1,0) with drift         : -12003.47\n",
      " ARIMA(0,1,1) with drift         : -12003.75\n",
      " ARIMA(0,1,0)                    : -12007.68\n",
      " ARIMA(1,1,2) with drift         : -12005.34\n",
      " ARIMA(2,1,1) with drift         : -12003.68\n",
      " ARIMA(3,1,2) with drift         : -12015.1\n",
      " ARIMA(2,1,3) with drift         : -12015.95\n",
      " ARIMA(1,1,1) with drift         : -12032.52\n",
      " ARIMA(0,1,2) with drift         : -12004.11\n",
      " ARIMA(2,1,0) with drift         : -12003.5\n",
      " ARIMA(1,1,1)                    : -12034.31\n",
      " ARIMA(0,1,1)                    : -12005.76\n",
      " ARIMA(1,1,0)                    : -12005.48\n",
      " ARIMA(2,1,1)                    : -12005.7\n",
      " ARIMA(1,1,2)                    : -12035.81\n",
      " ARIMA(0,1,2)                    : -12006.11\n",
      " ARIMA(2,1,2)                    : -12025.67\n",
      " ARIMA(1,1,3)                    : -12006.67\n",
      " ARIMA(0,1,3)                    : -12007.76\n",
      " ARIMA(2,1,3)                    : -12017.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,1)                    : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -12028.35\n",
      "\n",
      " Best model: ARIMA(2,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12046.07\n",
      " ARIMA(0,1,0) with drift         : -12011.57\n",
      " ARIMA(1,1,0) with drift         : -12009.1\n",
      " ARIMA(0,1,1) with drift         : -12009.67\n",
      " ARIMA(0,1,0)                    : -12013.57\n",
      " ARIMA(1,1,2) with drift         : -12038.51\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12020.19\n",
      " ARIMA(3,1,1) with drift         : -12017.76\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -12048.07\n",
      " ARIMA(1,1,2)                    : -12040.13\n",
      " ARIMA(2,1,1)                    : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(1,1,1)                    : Inf\n",
      " ARIMA(1,1,3)                    : -12022.21\n",
      " ARIMA(3,1,1)                    : -12019.74\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(1,1,3)                    : -12034.44\n",
      "\n",
      " Best model: ARIMA(1,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12018.83\n",
      " ARIMA(1,1,0) with drift         : -12015.98\n",
      " ARIMA(0,1,1) with drift         : -12016.99\n",
      " ARIMA(0,1,0)                    : -12020.83\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12028.97\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12024.85\n",
      " ARIMA(1,1,0) with drift         : -12022.27\n",
      " ARIMA(0,1,1) with drift         : -12022.98\n",
      " ARIMA(0,1,0)                    : -12026.85\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12035\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12098.61\n",
      " ARIMA(0,1,0) with drift         : -12045.53\n",
      " ARIMA(1,1,0) with drift         : -12043.15\n",
      " ARIMA(0,1,1) with drift         : -12043.76\n",
      " ARIMA(0,1,0)                    : -12047.51\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : -12073.39\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12054.62\n",
      " ARIMA(3,1,1) with drift         : -12044.52\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -12065.34\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(1,1,3) with drift         : -12066.73\n",
      "\n",
      " Best model: ARIMA(1,1,3) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12144.36\n",
      " ARIMA(0,0,0) with non-zero mean : -7379.697\n",
      " ARIMA(1,0,0) with non-zero mean : -12138.61\n",
      " ARIMA(0,0,1) with non-zero mean : -9450.926\n",
      " ARIMA(0,0,0) with zero mean     : -7370.04\n",
      " ARIMA(1,0,2) with non-zero mean : -12135.74\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12143.93\n",
      " ARIMA(1,0,1) with non-zero mean : -12137.74\n",
      " ARIMA(1,0,3) with non-zero mean : -12133.76\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -12146.18\n",
      " ARIMA(1,0,2) with zero mean     : -12137.45\n",
      " ARIMA(2,0,1) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -12145.78\n",
      " ARIMA(1,0,1) with zero mean     : -12139.45\n",
      " ARIMA(1,0,3) with zero mean     : -12135.48\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12147.75\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12147.26\n",
      " ARIMA(0,0,0) with non-zero mean : -7401.445\n",
      " ARIMA(1,0,0) with non-zero mean : -12140.99\n",
      " ARIMA(0,0,1) with non-zero mean : -9469.226\n",
      " ARIMA(0,0,0) with zero mean     : -7394.298\n",
      " ARIMA(1,0,2) with non-zero mean : -12138.1\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -12195.99\n",
      " ARIMA(3,0,1) with non-zero mean : -12147.37\n",
      " ARIMA(4,0,2) with non-zero mean : -12145.28\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,1) with non-zero mean : -12147.34\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -12195.39\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,1) with non-zero mean : -12148.48\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12157.48\n",
      " ARIMA(0,0,0) with non-zero mean : -7410.828\n",
      " ARIMA(1,0,0) with non-zero mean : -12147.29\n",
      " ARIMA(0,0,1) with non-zero mean : -9478.417\n",
      " ARIMA(0,0,0) with zero mean     : -7404.159\n",
      " ARIMA(1,0,2) with non-zero mean : -12144.29\n",
      " ARIMA(2,0,1) with non-zero mean : -12154.72\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(1,0,1) with non-zero mean : -12146.3\n",
      " ARIMA(1,0,3) with non-zero mean : -12142.28\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -12159.07\n",
      " ARIMA(1,0,2) with zero mean     : -12145.95\n",
      " ARIMA(2,0,1) with zero mean     : -12156.33\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -12158.89\n",
      " ARIMA(1,0,1) with zero mean     : -12147.96\n",
      " ARIMA(1,0,3) with zero mean     : -12143.94\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12157.53\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12176.38\n",
      " ARIMA(0,0,0) with non-zero mean : -7415.23\n",
      " ARIMA(1,0,0) with non-zero mean : -12168.98\n",
      " ARIMA(0,0,1) with non-zero mean : -9487.159\n",
      " ARIMA(0,0,0) with zero mean     : -7406.617\n",
      " ARIMA(1,0,2) with non-zero mean : -12166.19\n",
      " ARIMA(2,0,1) with non-zero mean : -12172.69\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(1,0,1) with non-zero mean : -12168.2\n",
      " ARIMA(1,0,3) with non-zero mean : -12164.18\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12174.04\n",
      " ARIMA(2,0,2) with zero mean     : -12178.13\n",
      " ARIMA(1,0,2) with zero mean     : -12167.84\n",
      " ARIMA(2,0,1) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -12178.04\n",
      " ARIMA(1,0,1) with zero mean     : -12169.85\n",
      " ARIMA(1,0,3) with zero mean     : -12165.83\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -12175.41\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12178.54\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12191.2\n",
      " ARIMA(0,0,0) with non-zero mean : -7418.218\n",
      " ARIMA(1,0,0) with non-zero mean : -12177.16\n",
      " ARIMA(0,0,1) with non-zero mean : -9490.666\n",
      " ARIMA(0,0,0) with zero mean     : -7409.668\n",
      " ARIMA(1,0,2) with non-zero mean : -12174.36\n",
      " ARIMA(2,0,1) with non-zero mean : -12187.67\n",
      " ARIMA(3,0,2) with non-zero mean : -12192.93\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -12199.74\n",
      " ARIMA(4,0,1) with non-zero mean : -12195.36\n",
      " ARIMA(5,0,2) with non-zero mean : -12202.29\n",
      " ARIMA(5,0,1) with non-zero mean : -12201.86\n",
      " ARIMA(5,0,3) with non-zero mean : -12200.54\n",
      " ARIMA(4,0,3) with non-zero mean : -12197.97\n",
      " ARIMA(5,0,2) with zero mean     : -12203.38\n",
      " ARIMA(4,0,2) with zero mean     : -12201.32\n",
      " ARIMA(5,0,1) with zero mean     : -12203.33\n",
      " ARIMA(5,0,3) with zero mean     : -12202\n",
      " ARIMA(4,0,1) with zero mean     : -12196.89\n",
      " ARIMA(4,0,3) with zero mean     : -12199.44\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,2) with zero mean     : -12194.79\n",
      "\n",
      " Best model: ARIMA(5,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12230.95\n",
      " ARIMA(0,0,0) with non-zero mean : -7432.886\n",
      " ARIMA(1,0,0) with non-zero mean : -12217.68\n",
      " ARIMA(0,0,1) with non-zero mean : -9511.6\n",
      " ARIMA(0,0,0) with zero mean     : -7420.807\n",
      " ARIMA(1,0,2) with non-zero mean : -12215.37\n",
      " ARIMA(2,0,1) with non-zero mean : -12225.89\n",
      " ARIMA(3,0,2) with non-zero mean : -12228.34\n",
      " ARIMA(2,0,3) with non-zero mean : -12230.77\n",
      " ARIMA(1,0,1) with non-zero mean : -12217.34\n",
      " ARIMA(1,0,3) with non-zero mean : -12213.4\n",
      " ARIMA(3,0,1) with non-zero mean : -12229.7\n",
      " ARIMA(3,0,3) with non-zero mean : -12227.59\n",
      " ARIMA(2,0,2) with zero mean     : -12232.43\n",
      " ARIMA(1,0,2) with zero mean     : -12216.89\n",
      " ARIMA(2,0,1) with zero mean     : -12227.44\n",
      " ARIMA(3,0,2) with zero mean     : -12229.35\n",
      " ARIMA(2,0,3) with zero mean     : -12232.29\n",
      " ARIMA(1,0,1) with zero mean     : -12218.86\n",
      " ARIMA(1,0,3) with zero mean     : -12214.92\n",
      " ARIMA(3,0,1) with zero mean     : -12231.19\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12227.28\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12256.5\n",
      " ARIMA(0,0,0) with non-zero mean : -7445.42\n",
      " ARIMA(1,0,0) with non-zero mean : -12257.49\n",
      " ARIMA(0,0,1) with non-zero mean : -9535.569\n",
      " ARIMA(0,0,0) with zero mean     : -7434.489\n",
      " ARIMA(2,0,0) with non-zero mean : -12258.72\n",
      " ARIMA(3,0,0) with non-zero mean : -12256.04\n",
      " ARIMA(2,0,1) with non-zero mean : -12256.73\n",
      " ARIMA(1,0,1) with non-zero mean : -12258.14\n",
      " ARIMA(3,0,1) with non-zero mean : -12262.6\n",
      " ARIMA(4,0,1) with non-zero mean : -12265.56\n",
      " ARIMA(4,0,0) with non-zero mean : -12253.08\n",
      " ARIMA(5,0,1) with non-zero mean : -12257.65\n",
      " ARIMA(4,0,2) with non-zero mean : -12266.8\n",
      " ARIMA(3,0,2) with non-zero mean : -12306.42\n",
      " ARIMA(3,0,3) with non-zero mean : -12267.78\n",
      " ARIMA(2,0,3) with non-zero mean : -12256.89\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -12308.34\n",
      " ARIMA(2,0,2) with zero mean     : -12257.99\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -12268.17\n",
      " ARIMA(3,0,3) with zero mean     : -12269.37\n",
      " ARIMA(2,0,1) with zero mean     : -12258.26\n",
      " ARIMA(2,0,3) with zero mean     : -12258.42\n",
      " ARIMA(4,0,1) with zero mean     : -12267.17\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,1) with zero mean     : -12267.77\n",
      "\n",
      " Best model: ARIMA(4,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12267.03\n",
      " ARIMA(0,0,0) with non-zero mean : -7448.715\n",
      " ARIMA(1,0,0) with non-zero mean : -12270.76\n",
      " ARIMA(0,0,1) with non-zero mean : -9539.854\n",
      " ARIMA(0,0,0) with zero mean     : -7436.768\n",
      " ARIMA(2,0,0) with non-zero mean : -12271.22\n",
      " ARIMA(3,0,0) with non-zero mean : -12269.75\n",
      " ARIMA(2,0,1) with non-zero mean : -12279.57\n",
      " ARIMA(1,0,1) with non-zero mean : -12271.36\n",
      " ARIMA(3,0,1) with non-zero mean : -12277.62\n",
      " ARIMA(1,0,2) with non-zero mean : -12269.4\n",
      " ARIMA(3,0,2) with non-zero mean : -12277.69\n",
      " ARIMA(2,0,1) with zero mean     : -12271.86\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with non-zero mean : -12276.5\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12284.93\n",
      " ARIMA(0,0,0) with non-zero mean : -7471.436\n",
      " ARIMA(1,0,0) with non-zero mean : -12282\n",
      " ARIMA(0,0,1) with non-zero mean : -9557.207\n",
      " ARIMA(0,0,0) with zero mean     : -7461.747\n",
      " ARIMA(1,0,2) with non-zero mean : -12280.56\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -12291.07\n",
      " ARIMA(3,0,1) with non-zero mean : -12291.38\n",
      " ARIMA(3,0,0) with non-zero mean : -12279.73\n",
      " ARIMA(4,0,1) with non-zero mean : -12289.84\n",
      " ARIMA(2,0,0) with non-zero mean : -12282.65\n",
      " ARIMA(4,0,0) with non-zero mean : -12276.77\n",
      " ARIMA(4,0,2) with non-zero mean : -12288.12\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -12289.07\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12288.43\n",
      " ARIMA(0,0,0) with non-zero mean : -7491.792\n",
      " ARIMA(1,0,0) with non-zero mean : -12281.96\n",
      " ARIMA(0,0,1) with non-zero mean : -9570.926\n",
      " ARIMA(0,0,0) with zero mean     : -7486.785\n",
      " ARIMA(1,0,2) with non-zero mean : -12280.72\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -12278.07\n",
      " ARIMA(2,0,3) with non-zero mean : -12287.42\n",
      " ARIMA(1,0,1) with non-zero mean : -12282.58\n",
      " ARIMA(1,0,3) with non-zero mean : -12278.8\n",
      " ARIMA(3,0,1) with non-zero mean : -12291.64\n",
      " ARIMA(3,0,0) with non-zero mean : -12279.17\n",
      " ARIMA(4,0,1) with non-zero mean : -12289.74\n",
      " ARIMA(2,0,0) with non-zero mean : -12281.9\n",
      " ARIMA(4,0,0) with non-zero mean : -12276.18\n",
      " ARIMA(4,0,2) with non-zero mean : -12287.82\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -12289.87\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12285.11\n",
      " ARIMA(0,0,0) with non-zero mean : -7496.174\n",
      " ARIMA(1,0,0) with non-zero mean : -12281.29\n",
      " ARIMA(0,0,1) with non-zero mean : -9575.749\n",
      " ARIMA(0,0,0) with zero mean     : -7491.335\n",
      " ARIMA(1,0,2) with non-zero mean : -12279.85\n",
      " ARIMA(2,0,1) with non-zero mean : -12280.01\n",
      " ARIMA(3,0,2) with non-zero mean : -12290.63\n",
      " ARIMA(3,0,1) with non-zero mean : -12291.52\n",
      " ARIMA(3,0,0) with non-zero mean : -12279.18\n",
      " ARIMA(4,0,1) with non-zero mean : -12286.39\n",
      " ARIMA(2,0,0) with non-zero mean : -12282.04\n",
      " ARIMA(4,0,0) with non-zero mean : -12276.54\n",
      " ARIMA(4,0,2) with non-zero mean : -12293.13\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12289.1\n",
      " ARIMA(5,0,1) with non-zero mean : -12281.77\n",
      " ARIMA(5,0,3) with non-zero mean : -12288.54\n",
      " ARIMA(4,0,2) with zero mean     : -12294.75\n",
      " ARIMA(3,0,2) with zero mean     : -12292.38\n",
      " ARIMA(4,0,1) with zero mean     : -12288.01\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,1) with zero mean     : -12293.2\n",
      " ARIMA(3,0,3) with zero mean     : -12290.83\n",
      " ARIMA(5,0,1) with zero mean     : -12283.48\n",
      " ARIMA(5,0,3) with zero mean     : -12290.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,2) with zero mean     : -12297.18\n",
      "\n",
      " Best model: ARIMA(4,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12288.25\n",
      " ARIMA(0,0,0) with non-zero mean : -7487.697\n",
      " ARIMA(1,0,0) with non-zero mean : -12283.46\n",
      " ARIMA(0,0,1) with non-zero mean : -9569.537\n",
      " ARIMA(0,0,0) with zero mean     : -7481.002\n",
      " ARIMA(1,0,2) with non-zero mean : -12282.02\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12287.41\n",
      " ARIMA(1,0,1) with non-zero mean : -12283.88\n",
      " ARIMA(1,0,3) with non-zero mean : -12280.08\n",
      " ARIMA(3,0,1) with non-zero mean : -12291.9\n",
      " ARIMA(3,0,0) with non-zero mean : -12281.24\n",
      " ARIMA(4,0,1) with non-zero mean : -12283.79\n",
      " ARIMA(2,0,0) with non-zero mean : -12284.01\n",
      " ARIMA(4,0,0) with non-zero mean : -12279.07\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -12293\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12304.9\n",
      " ARIMA(0,0,0) with non-zero mean : -7489.45\n",
      " ARIMA(1,0,0) with non-zero mean : -12294.5\n",
      " ARIMA(0,0,1) with non-zero mean : -9570.78\n",
      " ARIMA(0,0,0) with zero mean     : -7482.208\n",
      " ARIMA(1,0,2) with non-zero mean : -12292.56\n",
      " ARIMA(2,0,1) with non-zero mean : -12299.81\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12303.87\n",
      " ARIMA(1,0,1) with non-zero mean : -12294.41\n",
      " ARIMA(1,0,3) with non-zero mean : -12290.57\n",
      " ARIMA(3,0,1) with non-zero mean : -12303.05\n",
      " ARIMA(3,0,3) with non-zero mean : -12300.62\n",
      " ARIMA(2,0,2) with zero mean     : -12306.73\n",
      " ARIMA(1,0,2) with zero mean     : -12294.33\n",
      " ARIMA(2,0,1) with zero mean     : -12301.66\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -12305.7\n",
      " ARIMA(1,0,1) with zero mean     : -12296.18\n",
      " ARIMA(1,0,3) with zero mean     : -12292.33\n",
      " ARIMA(3,0,1) with zero mean     : -12304.74\n",
      " ARIMA(3,0,3) with zero mean     : -12302.28\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12305.7\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12296.47\n",
      " ARIMA(0,0,0) with non-zero mean : -7512.433\n",
      " ARIMA(1,0,0) with non-zero mean : -12293.41\n",
      " ARIMA(0,0,1) with non-zero mean : -9590.106\n",
      " ARIMA(0,0,0) with zero mean     : -7507.644\n",
      " ARIMA(1,0,2) with non-zero mean : -12291.22\n",
      " ARIMA(2,0,1) with non-zero mean : -12290.49\n",
      " ARIMA(3,0,2) with non-zero mean : -12349.06\n",
      " ARIMA(3,0,1) with non-zero mean : -12288.8\n",
      " ARIMA(4,0,2) with non-zero mean : -12302.23\n",
      " ARIMA(3,0,3) with non-zero mean : -12348.81\n",
      " ARIMA(2,0,3) with non-zero mean : -12290.13\n",
      " ARIMA(4,0,1) with non-zero mean : -12303.48\n",
      " ARIMA(4,0,3) with non-zero mean : -12301.4\n",
      " ARIMA(3,0,2) with zero mean     : -12350.91\n",
      " ARIMA(2,0,2) with zero mean     : -12291.96\n",
      " ARIMA(3,0,1) with zero mean     : -12304.11\n",
      " ARIMA(4,0,2) with zero mean     : -12304.06\n",
      " ARIMA(3,0,3) with zero mean     : -12350.67\n",
      " ARIMA(2,0,1) with zero mean     : -12292.34\n",
      " ARIMA(2,0,3) with zero mean     : -12291.95\n",
      " ARIMA(4,0,1) with zero mean     : -12305.28\n",
      " ARIMA(4,0,3) with zero mean     : -12303.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,1) with zero mean     : -12302.9\n",
      "\n",
      " Best model: ARIMA(4,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12294.73\n",
      " ARIMA(0,0,0) with non-zero mean : -7523.726\n",
      " ARIMA(1,0,0) with non-zero mean : -12282.66\n",
      " ARIMA(0,0,1) with non-zero mean : -9599.263\n",
      " ARIMA(0,0,0) with zero mean     : -7518.565\n",
      " ARIMA(1,0,2) with non-zero mean : -12280.27\n",
      " ARIMA(2,0,1) with non-zero mean : -12290.51\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12293.89\n",
      " ARIMA(1,0,1) with non-zero mean : -12282.22\n",
      " ARIMA(1,0,3) with non-zero mean : -12278.26\n",
      " ARIMA(3,0,1) with non-zero mean : -12292.79\n",
      " ARIMA(3,0,3) with non-zero mean : -12290.64\n",
      " ARIMA(2,0,2) with zero mean     : -12296.31\n",
      " ARIMA(1,0,2) with zero mean     : -12281.96\n",
      " ARIMA(2,0,1) with zero mean     : -12292.13\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -12295.48\n",
      " ARIMA(1,0,1) with zero mean     : -12283.92\n",
      " ARIMA(1,0,3) with zero mean     : -12279.96\n",
      " ARIMA(3,0,1) with zero mean     : -12294.58\n",
      " ARIMA(3,0,3) with zero mean     : -12292.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12292.19\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12310.49\n",
      " ARIMA(0,0,0) with non-zero mean : -7579.667\n",
      " ARIMA(1,0,0) with non-zero mean : -12312.78\n",
      " ARIMA(0,0,1) with non-zero mean : -9644.894\n",
      " ARIMA(0,0,0) with zero mean     : -7568.096\n",
      " ARIMA(2,0,0) with non-zero mean : -12313.95\n",
      " ARIMA(3,0,0) with non-zero mean : -12311.6\n",
      " ARIMA(2,0,1) with non-zero mean : -12311.94\n",
      " ARIMA(1,0,1) with non-zero mean : -12311.83\n",
      " ARIMA(3,0,1) with non-zero mean : -12308.85\n",
      " ARIMA(2,0,0) with zero mean     : -12315.33\n",
      " ARIMA(1,0,0) with zero mean     : -12314.23\n",
      " ARIMA(3,0,0) with zero mean     : -12312.98\n",
      " ARIMA(2,0,1) with zero mean     : -12313.26\n",
      " ARIMA(1,0,1) with zero mean     : -12313.27\n",
      " ARIMA(3,0,1) with zero mean     : -12310.2\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,0) with zero mean     : -12312.02\n",
      "\n",
      " Best model: ARIMA(2,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -7575.447\n",
      " ARIMA(1,0,0) with non-zero mean : -12376.55\n",
      " ARIMA(0,0,1) with non-zero mean : -9658.299\n",
      " ARIMA(0,0,0) with zero mean     : -7561.632\n",
      " ARIMA(2,0,0) with non-zero mean : -12375.94\n",
      " ARIMA(1,0,1) with non-zero mean : -12375.92\n",
      " ARIMA(2,0,1) with non-zero mean : -12393.48\n",
      " ARIMA(3,0,1) with non-zero mean : -12385.09\n",
      " ARIMA(1,0,2) with non-zero mean : -12374.8\n",
      " ARIMA(3,0,0) with non-zero mean : -12373.92\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -12395.1\n",
      " ARIMA(1,0,1) with zero mean     : -12377.4\n",
      " ARIMA(2,0,0) with zero mean     : -12377.45\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(2,0,2) with zero mean     : Inf\n",
      " ARIMA(1,0,0) with zero mean     : -12378.05\n",
      " ARIMA(1,0,2) with zero mean     : -12376.26\n",
      " ARIMA(3,0,0) with zero mean     : -12375.41\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with zero mean     : -12385.55\n",
      "\n",
      " Best model: ARIMA(2,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12383.96\n",
      " ARIMA(0,0,0) with non-zero mean : -7636.592\n",
      " ARIMA(1,0,0) with non-zero mean : -12385.34\n",
      " ARIMA(0,0,1) with non-zero mean : -9698.714\n",
      " ARIMA(0,0,0) with zero mean     : -7631.109\n",
      " ARIMA(2,0,0) with non-zero mean : -12387.27\n",
      " ARIMA(3,0,0) with non-zero mean : -12385.41\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(1,0,1) with non-zero mean : -12383.83\n",
      " ARIMA(3,0,1) with non-zero mean : -12396.18\n",
      " ARIMA(4,0,1) with non-zero mean : -12382.81\n",
      " ARIMA(3,0,2) with non-zero mean : -12395.78\n",
      " ARIMA(4,0,0) with non-zero mean : -12384.08\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -12389.8\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12386.98\n",
      " ARIMA(0,0,0) with non-zero mean : -7665.854\n",
      " ARIMA(1,0,0) with non-zero mean : -12379.12\n",
      " ARIMA(0,0,1) with non-zero mean : -9722.335\n",
      " ARIMA(0,0,0) with zero mean     : -7662.672\n",
      " ARIMA(1,0,2) with non-zero mean : -12376.91\n",
      " ARIMA(2,0,1) with non-zero mean : -12385.12\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12385.91\n",
      " ARIMA(1,0,1) with non-zero mean : -12377.7\n",
      " ARIMA(1,0,3) with non-zero mean : -12375.44\n",
      " ARIMA(3,0,1) with non-zero mean : -12385.99\n",
      " ARIMA(3,0,3) with non-zero mean : -12396.33\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -12394.71\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -12398.09\n",
      " ARIMA(2,0,3) with zero mean     : -12387.69\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -12388.8\n",
      " ARIMA(2,0,4) with zero mean     : -12377.08\n",
      " ARIMA(4,0,2) with zero mean     : -12396.46\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with zero mean     : -12397.04\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12372.1\n",
      " ARIMA(0,0,0) with non-zero mean : -7638.056\n",
      " ARIMA(1,0,0) with non-zero mean : -12367.87\n",
      " ARIMA(0,0,1) with non-zero mean : -9696.992\n",
      " ARIMA(0,0,0) with zero mean     : -7638.917\n",
      " ARIMA(1,0,2) with non-zero mean : -12365.83\n",
      " ARIMA(2,0,1) with non-zero mean : -12370.39\n",
      " ARIMA(3,0,2) with non-zero mean : -12376.09\n",
      " ARIMA(3,0,1) with non-zero mean : -12376.91\n",
      " ARIMA(3,0,0) with non-zero mean : -12364.17\n",
      " ARIMA(4,0,1) with non-zero mean : -12371.52\n",
      " ARIMA(2,0,0) with non-zero mean : -12365.48\n",
      " ARIMA(4,0,0) with non-zero mean : -12363.21\n",
      " ARIMA(4,0,2) with non-zero mean : -12384.24\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,1) with non-zero mean : -12363.16\n",
      " ARIMA(5,0,3) with non-zero mean : -12358.93\n",
      " ARIMA(4,0,2) with zero mean     : -12386.23\n",
      " ARIMA(3,0,2) with zero mean     : -12377.81\n",
      " ARIMA(4,0,1) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -12399.98\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -12386.19\n",
      "\n",
      " Best model: ARIMA(4,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12382.29\n",
      " ARIMA(0,0,0) with non-zero mean : -7629.492\n",
      " ARIMA(1,0,0) with non-zero mean : -12385.42\n",
      " ARIMA(0,0,1) with non-zero mean : -9699.086\n",
      " ARIMA(0,0,0) with zero mean     : -7630.842\n",
      " ARIMA(2,0,0) with non-zero mean : -12384.88\n",
      " ARIMA(1,0,1) with non-zero mean : -12384.14\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(1,0,0) with zero mean     : -12387.41\n",
      " ARIMA(2,0,0) with zero mean     : -12386.87\n",
      " ARIMA(1,0,1) with zero mean     : -12386.14\n",
      " ARIMA(0,0,1) with zero mean     : -9700.538\n",
      " ARIMA(2,0,1) with zero mean     : -12384.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,0) with zero mean     : -12386.2\n",
      "\n",
      " Best model: ARIMA(1,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12379.96\n",
      " ARIMA(0,0,0) with non-zero mean : -7632.211\n",
      " ARIMA(1,0,0) with non-zero mean : -12374.22\n",
      " ARIMA(0,0,1) with non-zero mean : -9700.155\n",
      " ARIMA(0,0,0) with zero mean     : -7634.093\n",
      " ARIMA(1,0,2) with non-zero mean : -12371.66\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -12387.1\n",
      " ARIMA(3,0,1) with non-zero mean : -12370.64\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12375.05\n",
      " ARIMA(2,0,3) with non-zero mean : -12382.17\n",
      " ARIMA(4,0,1) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -12424.22\n",
      " ARIMA(5,0,3) with non-zero mean : -12430.73\n",
      " ARIMA(5,0,2) with non-zero mean : -12370.49\n",
      " ARIMA(5,0,4) with non-zero mean : -12414.34\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : -12412.76\n",
      "\n",
      " Best model: ARIMA(5,0,4) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12372.17\n",
      " ARIMA(0,0,0) with non-zero mean : -7632.978\n",
      " ARIMA(1,0,0) with non-zero mean : -12362.63\n",
      " ARIMA(0,0,1) with non-zero mean : -9696.85\n",
      " ARIMA(0,0,0) with zero mean     : -7634.852\n",
      " ARIMA(1,0,2) with non-zero mean : -12359.87\n",
      " ARIMA(2,0,1) with non-zero mean : -12370.59\n",
      " ARIMA(3,0,2) with non-zero mean : -12380.13\n",
      " ARIMA(3,0,1) with non-zero mean : -12365.23\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12378.26\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,1) with non-zero mean : -12369.57\n",
      " ARIMA(4,0,3) with non-zero mean : -12413.15\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -12404.7\n",
      " ARIMA(3,0,4) with non-zero mean : -12380.06\n",
      " ARIMA(5,0,2) with non-zero mean : -12357.86\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -12415.18\n",
      " ARIMA(3,0,3) with zero mean     : -12380.26\n",
      " ARIMA(4,0,2) with zero mean     : -12379.48\n",
      " ARIMA(5,0,3) with zero mean     : -12402.01\n",
      " ARIMA(4,0,4) with zero mean     : -12404.73\n",
      " ARIMA(3,0,2) with zero mean     : -12382.14\n",
      " ARIMA(3,0,4) with zero mean     : -12382.08\n",
      " ARIMA(5,0,2) with zero mean     : -12359.88\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -12381.67\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12370.68\n",
      " ARIMA(0,0,0) with non-zero mean : -7632.239\n",
      " ARIMA(1,0,0) with non-zero mean : -12374.84\n",
      " ARIMA(0,0,1) with non-zero mean : -9694.237\n",
      " ARIMA(0,0,0) with zero mean     : -7634.062\n",
      " ARIMA(2,0,0) with non-zero mean : -12372.61\n",
      " ARIMA(1,0,1) with non-zero mean : -12373.2\n",
      " ARIMA(2,0,1) with non-zero mean : -12370.81\n",
      " ARIMA(1,0,0) with zero mean     : -12376.82\n",
      " ARIMA(2,0,0) with zero mean     : -12374.6\n",
      " ARIMA(1,0,1) with zero mean     : -12375.19\n",
      " ARIMA(0,0,1) with zero mean     : -9696.14\n",
      " ARIMA(2,0,1) with zero mean     : -12372.8\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,0) with zero mean     : -12374.11\n",
      "\n",
      " Best model: ARIMA(1,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12380.54\n",
      " ARIMA(0,0,0) with non-zero mean : -7616.551\n",
      " ARIMA(1,0,0) with non-zero mean : -12374.77\n",
      " ARIMA(0,0,1) with non-zero mean : -9683.817\n",
      " ARIMA(0,0,0) with zero mean     : -7618.513\n",
      " ARIMA(1,0,2) with non-zero mean : -12371.59\n",
      " ARIMA(2,0,1) with non-zero mean : -12379.25\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(1,0,1) with non-zero mean : -12373.11\n",
      " ARIMA(1,0,3) with non-zero mean : -12370.14\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12386.46\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -12385\n",
      " ARIMA(2,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -12393.23\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : -12407.97\n",
      " ARIMA(3,0,5) with non-zero mean : -12418.55\n",
      " ARIMA(2,0,5) with non-zero mean : -12380.2\n",
      " ARIMA(3,0,5) with zero mean     : -12420.47\n",
      " ARIMA(2,0,5) with zero mean     : -12382.22\n",
      " ARIMA(3,0,4) with zero mean     : -12391.04\n",
      " ARIMA(4,0,5) with zero mean     : -12409.98\n",
      " ARIMA(2,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : -12395\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with zero mean     : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -12394.39\n",
      "\n",
      " Best model: ARIMA(3,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -7593.37\n",
      " ARIMA(1,0,0) with non-zero mean : -12357.29\n",
      " ARIMA(0,0,1) with non-zero mean : -9659.48\n",
      " ARIMA(0,0,0) with zero mean     : -7594.572\n",
      " ARIMA(2,0,0) with non-zero mean : -12355.13\n",
      " ARIMA(1,0,1) with non-zero mean : -12355.44\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(1,0,0) with zero mean     : -12359.26\n",
      " ARIMA(2,0,0) with zero mean     : -12357.09\n",
      " ARIMA(1,0,1) with zero mean     : -12357.41\n",
      " ARIMA(0,0,1) with zero mean     : -9660.873\n",
      " ARIMA(2,0,1) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,0) with zero mean     : -12357.88\n",
      "\n",
      " Best model: ARIMA(1,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12358.85\n",
      " ARIMA(0,0,0) with non-zero mean : -7612.88\n",
      " ARIMA(1,0,0) with non-zero mean : -12352.73\n",
      " ARIMA(0,0,1) with non-zero mean : -9667.962\n",
      " ARIMA(0,0,0) with zero mean     : -7614.768\n",
      " ARIMA(1,0,2) with non-zero mean : -12349.17\n",
      " ARIMA(2,0,1) with non-zero mean : -12359.18\n",
      " ARIMA(1,0,1) with non-zero mean : -12350.72\n",
      " ARIMA(2,0,0) with non-zero mean : -12349.76\n",
      " ARIMA(3,0,1) with non-zero mean : -12352.18\n",
      " ARIMA(3,0,0) with non-zero mean : -12348.2\n",
      " ARIMA(3,0,2) with non-zero mean : -12402.73\n",
      " ARIMA(4,0,2) with non-zero mean : -12357.4\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,1) with non-zero mean : -12353.57\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -12403.67\n",
      " ARIMA(2,0,2) with zero mean     : -12360.86\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -12359.45\n",
      " ARIMA(3,0,3) with zero mean     : -12405.32\n",
      " ARIMA(2,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -12404.75\n",
      " ARIMA(2,0,4) with zero mean     : -12351.32\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -12360.99\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12245.28\n",
      " ARIMA(0,0,0) with non-zero mean : -7579.394\n",
      " ARIMA(1,0,0) with non-zero mean : -12250.31\n",
      " ARIMA(0,0,1) with non-zero mean : -9614.418\n",
      " ARIMA(0,0,0) with zero mean     : -7580.618\n",
      " ARIMA(2,0,0) with non-zero mean : -12248.88\n",
      " ARIMA(1,0,1) with non-zero mean : -12248.42\n",
      " ARIMA(2,0,1) with non-zero mean : -12247.28\n",
      " ARIMA(1,0,0) with zero mean     : -12252.25\n",
      " ARIMA(2,0,0) with zero mean     : -12250.84\n",
      " ARIMA(1,0,1) with zero mean     : -12250.37\n",
      " ARIMA(0,0,1) with zero mean     : -9615.668\n",
      " ARIMA(2,0,1) with zero mean     : -12249.09\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,0) with zero mean     : -12249.31\n",
      "\n",
      " Best model: ARIMA(1,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11918.13\n",
      " ARIMA(0,0,0) with non-zero mean : -7093.706\n",
      " ARIMA(1,0,0) with non-zero mean : -11917.05\n",
      " ARIMA(0,0,1) with non-zero mean : -9189.946\n",
      " ARIMA(0,0,0) with zero mean     : -7089.844\n",
      " ARIMA(1,0,2) with non-zero mean : -11919.1\n",
      " ARIMA(0,0,2) with non-zero mean : -10255.34\n",
      " ARIMA(1,0,1) with non-zero mean : -11919.47\n",
      " ARIMA(2,0,1) with non-zero mean : -11926.69\n",
      " ARIMA(2,0,0) with non-zero mean : -11918.19\n",
      " ARIMA(3,0,1) with non-zero mean : -11918.52\n",
      " ARIMA(3,0,0) with non-zero mean : -11918.52\n",
      " ARIMA(3,0,2) with non-zero mean : -11964.9\n",
      " ARIMA(4,0,2) with non-zero mean : -11921.13\n",
      " ARIMA(3,0,3) with non-zero mean : -11919.65\n",
      " ARIMA(2,0,3) with non-zero mean : -11921.89\n",
      " ARIMA(4,0,1) with non-zero mean : -11922.48\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11965.73\n",
      " ARIMA(2,0,2) with zero mean     : -11919.78\n",
      " ARIMA(3,0,1) with zero mean     : -11920.19\n",
      " ARIMA(4,0,2) with zero mean     : -11922.77\n",
      " ARIMA(3,0,3) with zero mean     : -11921.72\n",
      " ARIMA(2,0,1) with zero mean     : -11928.33\n",
      " ARIMA(2,0,3) with zero mean     : -11923.53\n",
      " ARIMA(4,0,1) with zero mean     : -11924.09\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11982.88\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11592.45\n",
      " ARIMA(0,1,0) with drift         : -11555.24\n",
      " ARIMA(1,1,0) with drift         : -11572.02\n",
      " ARIMA(0,1,1) with drift         : -11577.1\n",
      " ARIMA(0,1,0)                    : -11557.22\n",
      " ARIMA(1,1,2) with drift         : -11589.93\n",
      " ARIMA(2,1,1) with drift         : -11592.45\n",
      " ARIMA(1,1,1) with drift         : -11581.25\n",
      " ARIMA(2,1,0) with drift         : -11591.47\n",
      " ARIMA(3,1,1) with drift         : -11590.91\n",
      " ARIMA(3,1,0) with drift         : -11592.77\n",
      " ARIMA(4,1,0) with drift         : -11594.37\n",
      " ARIMA(5,1,0) with drift         : -11597.15\n",
      " ARIMA(5,1,1) with drift         : -11624.61\n",
      " ARIMA(4,1,1) with drift         : -11595.39\n",
      " ARIMA(5,1,2) with drift         : -11634.3\n",
      " ARIMA(4,1,2) with drift         : -11650.69\n",
      " ARIMA(3,1,2) with drift         : -11589.14\n",
      " ARIMA(4,1,3) with drift         : -11594.46\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(5,1,3) with drift         : -11642.34\n",
      " ARIMA(4,1,2)                    : -11652.57\n",
      " ARIMA(3,1,2)                    : -11591.12\n",
      " ARIMA(4,1,1)                    : -11597.4\n",
      " ARIMA(5,1,2)                    : -11636.3\n",
      " ARIMA(4,1,3)                    : -11596.53\n",
      " ARIMA(3,1,1)                    : -11592.9\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(5,1,1)                    : Inf\n",
      " ARIMA(5,1,3)                    : -11644.74\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(5,1,3)                    : Inf\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(5,1,2)                    : Inf\n",
      " ARIMA(5,1,2) with drift         : Inf\n",
      " ARIMA(5,1,1) with drift         : -11640.1\n",
      "\n",
      " Best model: ARIMA(5,1,1) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11415.47\n",
      " ARIMA(0,1,0) with drift         : -11362.54\n",
      " ARIMA(1,1,0) with drift         : -11389.78\n",
      " ARIMA(0,1,1) with drift         : -11394.48\n",
      " ARIMA(0,1,0)                    : -11364.55\n",
      " ARIMA(1,1,2) with drift         : -11409.16\n",
      " ARIMA(2,1,1) with drift         : -11412.81\n",
      " ARIMA(3,1,2) with drift         : -11412.71\n",
      " ARIMA(2,1,3) with drift         : -11413.64\n",
      " ARIMA(1,1,1) with drift         : -11398.6\n",
      " ARIMA(1,1,3) with drift         : -11410.51\n",
      " ARIMA(3,1,1) with drift         : -11412.09\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11417.47\n",
      " ARIMA(1,1,2)                    : -11411.16\n",
      " ARIMA(2,1,1)                    : -11414.81\n",
      " ARIMA(3,1,2)                    : -11414.69\n",
      " ARIMA(2,1,3)                    : -11415.64\n",
      " ARIMA(1,1,1)                    : -11400.6\n",
      " ARIMA(1,1,3)                    : -11412.52\n",
      " ARIMA(3,1,1)                    : -11414.08\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11425.36\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11353.65\n",
      " ARIMA(0,1,0) with drift         : -11294.89\n",
      " ARIMA(1,1,0) with drift         : -11324.01\n",
      " ARIMA(0,1,1) with drift         : -11330.99\n",
      " ARIMA(0,1,0)                    : -11296.89\n",
      " ARIMA(1,1,2) with drift         : -11345.36\n",
      " ARIMA(2,1,1) with drift         : -11350.29\n",
      " ARIMA(3,1,2) with drift         : -11350.17\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11334.27\n",
      " ARIMA(1,1,3) with drift         : -11347.22\n",
      " ARIMA(3,1,1) with drift         : -11349.78\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11355.66\n",
      " ARIMA(1,1,2)                    : -11347.37\n",
      " ARIMA(2,1,1)                    : -11352.3\n",
      " ARIMA(3,1,2)                    : -11352.16\n",
      " ARIMA(2,1,3)                    : -11353.71\n",
      " ARIMA(1,1,1)                    : -11336.27\n",
      " ARIMA(1,1,3)                    : -11349.22\n",
      " ARIMA(3,1,1)                    : -11351.79\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11365.31\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11320.7\n",
      " ARIMA(0,1,0) with drift         : -11261.92\n",
      " ARIMA(1,1,0) with drift         : -11289.31\n",
      " ARIMA(0,1,1) with drift         : -11296.15\n",
      " ARIMA(0,1,0)                    : -11263.9\n",
      " ARIMA(1,1,2) with drift         : -11312.32\n",
      " ARIMA(2,1,1) with drift         : -11317.17\n",
      " ARIMA(3,1,2) with drift         : -11317.32\n",
      " ARIMA(2,1,3) with drift         : -11318.7\n",
      " ARIMA(1,1,1) with drift         : -11299.93\n",
      " ARIMA(1,1,3) with drift         : -11314.09\n",
      " ARIMA(3,1,1) with drift         : -11316.82\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11322.69\n",
      " ARIMA(1,1,2)                    : -11314.3\n",
      " ARIMA(2,1,1)                    : -11319.15\n",
      " ARIMA(3,1,2)                    : -11319.28\n",
      " ARIMA(2,1,3)                    : -11320.61\n",
      " ARIMA(1,1,1)                    : -11301.9\n",
      " ARIMA(1,1,3)                    : -11316.07\n",
      " ARIMA(3,1,1)                    : -11318.8\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11331.48\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11266.31\n",
      " ARIMA(0,1,0) with drift         : -11205.21\n",
      " ARIMA(1,1,0) with drift         : -11233.03\n",
      " ARIMA(0,1,1) with drift         : -11240.17\n",
      " ARIMA(0,1,0)                    : -11207.21\n",
      " ARIMA(1,1,2) with drift         : -11254.87\n",
      " ARIMA(2,1,1) with drift         : -11261.21\n",
      " ARIMA(3,1,2) with drift         : -11262.81\n",
      " ARIMA(2,1,3) with drift         : -11264.32\n",
      " ARIMA(1,1,1) with drift         : -11242.56\n",
      " ARIMA(1,1,3) with drift         : -11258.05\n",
      " ARIMA(3,1,1) with drift         : -11262.14\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11268.32\n",
      " ARIMA(1,1,2)                    : -11256.88\n",
      " ARIMA(2,1,1)                    : -11263.21\n",
      " ARIMA(3,1,2)                    : -11264.84\n",
      " ARIMA(2,1,3)                    : -11266.33\n",
      " ARIMA(1,1,1)                    : -11244.57\n",
      " ARIMA(1,1,3)                    : -11260.06\n",
      " ARIMA(3,1,1)                    : -11264.14\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11277.31\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11262.05\n",
      " ARIMA(0,1,0) with drift         : -11192.23\n",
      " ARIMA(1,1,0) with drift         : -11226.71\n",
      " ARIMA(0,1,1) with drift         : -11231.46\n",
      " ARIMA(0,1,0)                    : -11194.21\n",
      " ARIMA(1,1,2) with drift         : -11247.34\n",
      " ARIMA(2,1,1) with drift         : -11252.98\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11305.6\n",
      " ARIMA(1,1,3) with drift         : -11251.68\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : -11261.91\n",
      " ARIMA(1,1,4) with drift         : -11257.86\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11307.46\n",
      " ARIMA(1,1,3)                    : -11253.67\n",
      " ARIMA(2,1,2)                    : -11264.03\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : -11263.89\n",
      " ARIMA(1,1,2)                    : -11249.32\n",
      " ARIMA(1,1,4)                    : -11259.86\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,4)                    : -11294.48\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4)                    : -11267.25\n",
      "\n",
      " Best model: ARIMA(1,1,4)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11328.07\n",
      " ARIMA(0,0,0) with non-zero mean : -6737.816\n",
      " ARIMA(1,0,0) with non-zero mean : -11296.4\n",
      " ARIMA(0,0,1) with non-zero mean : -8758.488\n",
      " ARIMA(0,0,0) with zero mean     : -6726.062\n",
      " ARIMA(1,0,2) with non-zero mean : -11320.74\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11400.22\n",
      " ARIMA(3,0,1) with non-zero mean : -11334.05\n",
      " ARIMA(4,0,2) with non-zero mean : -11349.24\n",
      " ARIMA(3,0,3) with non-zero mean : -11349.61\n",
      " ARIMA(2,0,3) with non-zero mean : -11343.52\n",
      " ARIMA(4,0,1) with non-zero mean : -11346.17\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11401.72\n",
      " ARIMA(2,0,2) with zero mean     : -11329.9\n",
      " ARIMA(3,0,1) with zero mean     : -11335.87\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11351.36\n",
      " ARIMA(2,0,1) with zero mean     : -11314.01\n",
      " ARIMA(2,0,3) with zero mean     : -11345.27\n",
      " ARIMA(4,0,1) with zero mean     : -11347.94\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11350.88\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11324.39\n",
      " ARIMA(0,0,0) with non-zero mean : -6739.838\n",
      " ARIMA(1,0,0) with non-zero mean : -11291.47\n",
      " ARIMA(0,0,1) with non-zero mean : -8753.561\n",
      " ARIMA(0,0,0) with zero mean     : -6728.901\n",
      " ARIMA(1,0,2) with non-zero mean : -11317.24\n",
      " ARIMA(2,0,1) with non-zero mean : -11314.87\n",
      " ARIMA(3,0,2) with non-zero mean : -11397.8\n",
      " ARIMA(3,0,1) with non-zero mean : -11330.92\n",
      " ARIMA(4,0,2) with non-zero mean : -11345.12\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11338.13\n",
      " ARIMA(4,0,1) with non-zero mean : -11342.03\n",
      " ARIMA(4,0,3) with non-zero mean : -11399.92\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11398.25\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11401.72\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11346.63\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11399.42\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11405.72\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11314.12\n",
      " ARIMA(0,0,0) with non-zero mean : -6723.367\n",
      " ARIMA(1,0,0) with non-zero mean : -11283.77\n",
      " ARIMA(0,0,1) with non-zero mean : -8741.907\n",
      " ARIMA(0,0,0) with zero mean     : -6711.968\n",
      " ARIMA(1,0,2) with non-zero mean : -11307.4\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11381.18\n",
      " ARIMA(3,0,1) with non-zero mean : -11320.77\n",
      " ARIMA(4,0,2) with non-zero mean : -11332\n",
      " ARIMA(3,0,3) with non-zero mean : -11332.98\n",
      " ARIMA(2,0,3) with non-zero mean : -11328.13\n",
      " ARIMA(4,0,1) with non-zero mean : -11331.31\n",
      " ARIMA(4,0,3) with non-zero mean : -11383.32\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11382.31\n",
      " ARIMA(3,0,4) with non-zero mean : -11359.17\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11384.72\n",
      " ARIMA(3,0,3) with zero mean     : -11334.68\n",
      " ARIMA(4,0,2) with zero mean     : -11333.85\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11382.66\n",
      " ARIMA(3,0,4) with zero mean     : -11360.21\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with zero mean     : -11440.78\n",
      " ARIMA(5,0,5) with zero mean     : -11456.27\n",
      " ARIMA(4,0,5) with zero mean     : Inf\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,5) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11396.91\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11305.83\n",
      " ARIMA(0,0,0) with non-zero mean : -6670.167\n",
      " ARIMA(1,0,0) with non-zero mean : -11278.25\n",
      " ARIMA(0,0,1) with non-zero mean : -8697.836\n",
      " ARIMA(0,0,0) with zero mean     : -6663.345\n",
      " ARIMA(1,0,2) with non-zero mean : -11300.93\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11382.19\n",
      " ARIMA(3,0,1) with non-zero mean : -11312.28\n",
      " ARIMA(4,0,2) with non-zero mean : -11324.03\n",
      " ARIMA(3,0,3) with non-zero mean : -11324.58\n",
      " ARIMA(2,0,3) with non-zero mean : -11320.3\n",
      " ARIMA(4,0,1) with non-zero mean : -11323.14\n",
      " ARIMA(4,0,3) with non-zero mean : -11382.62\n",
      " ARIMA(5,0,3) with non-zero mean : -11391.42\n",
      " ARIMA(5,0,2) with non-zero mean : -11375.24\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11388.66\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11299.77\n",
      " ARIMA(0,0,0) with non-zero mean : -6664.974\n",
      " ARIMA(1,0,0) with non-zero mean : -11273.07\n",
      " ARIMA(0,0,1) with non-zero mean : -8693.479\n",
      " ARIMA(0,0,0) with zero mean     : -6658.911\n",
      " ARIMA(1,0,2) with non-zero mean : -11295.08\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11384.49\n",
      " ARIMA(3,0,1) with non-zero mean : -11305.45\n",
      " ARIMA(4,0,2) with non-zero mean : -11318.63\n",
      " ARIMA(3,0,3) with non-zero mean : -11318.26\n",
      " ARIMA(2,0,3) with non-zero mean : -11313.84\n",
      " ARIMA(4,0,1) with non-zero mean : -11316.33\n",
      " ARIMA(4,0,3) with non-zero mean : -11379.31\n",
      " ARIMA(3,0,2) with zero mean     : -11386.24\n",
      " ARIMA(2,0,2) with zero mean     : -11301.64\n",
      " ARIMA(3,0,1) with zero mean     : -11307.33\n",
      " ARIMA(4,0,2) with zero mean     : -11320.49\n",
      " ARIMA(3,0,3) with zero mean     : -11320.1\n",
      " ARIMA(2,0,1) with zero mean     : -11294.37\n",
      " ARIMA(2,0,3) with zero mean     : -11315.67\n",
      " ARIMA(4,0,1) with zero mean     : -11318.18\n",
      " ARIMA(4,0,3) with zero mean     : -11381.1\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11385.3\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11310.13\n",
      " ARIMA(0,0,0) with non-zero mean : -6682.719\n",
      " ARIMA(1,0,0) with non-zero mean : -11283.7\n",
      " ARIMA(0,0,1) with non-zero mean : -8709.728\n",
      " ARIMA(0,0,0) with zero mean     : -6679.951\n",
      " ARIMA(1,0,2) with non-zero mean : -11305.28\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11394.4\n",
      " ARIMA(3,0,1) with non-zero mean : -11315.74\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11324.19\n",
      " ARIMA(4,0,1) with non-zero mean : -11326.94\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : -11394.4\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11318.53\n",
      " ARIMA(0,0,0) with non-zero mean : -6684.289\n",
      " ARIMA(1,0,0) with non-zero mean : -11291.02\n",
      " ARIMA(0,0,1) with non-zero mean : -8709.777\n",
      " ARIMA(0,0,0) with zero mean     : -6682.252\n",
      " ARIMA(1,0,2) with non-zero mean : -11313.56\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11407.09\n",
      " ARIMA(3,0,1) with non-zero mean : -11326.07\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -11411.55\n",
      " ARIMA(2,0,3) with non-zero mean : -11332.96\n",
      " ARIMA(4,0,3) with non-zero mean : -11406.01\n",
      " ARIMA(3,0,4) with non-zero mean : -11393.61\n",
      " ARIMA(2,0,4) with non-zero mean : -11372\n",
      " ARIMA(4,0,4) with non-zero mean : -11408.79\n",
      " ARIMA(3,0,3) with zero mean     : -11413.52\n",
      " ARIMA(2,0,3) with zero mean     : -11334.9\n",
      " ARIMA(3,0,2) with zero mean     : -11409.07\n",
      " ARIMA(4,0,3) with zero mean     : -11407.69\n",
      " ARIMA(3,0,4) with zero mean     : -11393.81\n",
      " ARIMA(2,0,2) with zero mean     : -11320.49\n",
      " ARIMA(2,0,4) with zero mean     : -11373.96\n",
      " ARIMA(4,0,2) with zero mean     : -11342.57\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11404.21\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11332.95\n",
      " ARIMA(0,0,0) with non-zero mean : -6690.754\n",
      " ARIMA(1,0,0) with non-zero mean : -11305.57\n",
      " ARIMA(0,0,1) with non-zero mean : -8717.595\n",
      " ARIMA(0,0,0) with zero mean     : -6690.452\n",
      " ARIMA(1,0,2) with non-zero mean : -11328.33\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11416.47\n",
      " ARIMA(3,0,1) with non-zero mean : -11342.34\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -11418.63\n",
      " ARIMA(2,0,3) with non-zero mean : -11348.62\n",
      " ARIMA(4,0,3) with non-zero mean : -11414.74\n",
      " ARIMA(3,0,4) with non-zero mean : -11416.61\n",
      " ARIMA(2,0,4) with non-zero mean : -11388.3\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11420.66\n",
      " ARIMA(2,0,3) with zero mean     : -11350.61\n",
      " ARIMA(3,0,2) with zero mean     : -11418.51\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -11418.65\n",
      " ARIMA(2,0,2) with zero mean     : -11334.95\n",
      " ARIMA(2,0,4) with zero mean     : -11390.32\n",
      " ARIMA(4,0,2) with zero mean     : -11357.1\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11415.5\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11356.17\n",
      " ARIMA(0,0,0) with non-zero mean : -6690.499\n",
      " ARIMA(1,0,0) with non-zero mean : -11329.91\n",
      " ARIMA(0,0,1) with non-zero mean : -8719.031\n",
      " ARIMA(0,0,0) with zero mean     : -6690.897\n",
      " ARIMA(1,0,2) with non-zero mean : -11352.13\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11428.68\n",
      " ARIMA(3,0,1) with non-zero mean : -11362.48\n",
      " ARIMA(4,0,2) with non-zero mean : -11375.33\n",
      " ARIMA(3,0,3) with non-zero mean : -11375.66\n",
      " ARIMA(2,0,3) with non-zero mean : -11371.34\n",
      " ARIMA(4,0,1) with non-zero mean : -11374.63\n",
      " ARIMA(4,0,3) with non-zero mean : -11431.51\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11412.53\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11433.45\n",
      " ARIMA(3,0,3) with zero mean     : -11377.55\n",
      " ARIMA(4,0,2) with zero mean     : -11376.63\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11430.46\n",
      " ARIMA(3,0,4) with zero mean     : -11376.2\n",
      " ARIMA(5,0,2) with zero mean     : -11414.43\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -11432.83\n",
      "\n",
      " Best model: ARIMA(4,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11368.76\n",
      " ARIMA(0,0,0) with non-zero mean : -6688.274\n",
      " ARIMA(1,0,0) with non-zero mean : -11342.11\n",
      " ARIMA(0,0,1) with non-zero mean : -8719.819\n",
      " ARIMA(0,0,0) with zero mean     : -6687.667\n",
      " ARIMA(1,0,2) with non-zero mean : -11363.98\n",
      " ARIMA(2,0,1) with non-zero mean : -11362.28\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11383.19\n",
      " ARIMA(1,0,3) with non-zero mean : -11385.67\n",
      " ARIMA(0,0,3) with non-zero mean : -10195.6\n",
      " ARIMA(1,0,4) with non-zero mean : -11384.18\n",
      " ARIMA(0,0,2) with non-zero mean : -9651.636\n",
      " ARIMA(0,0,4) with non-zero mean : -10619.64\n",
      " ARIMA(2,0,4) with non-zero mean : -11413.52\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11423.72\n",
      " ARIMA(1,0,5) with non-zero mean : -11388.13\n",
      " ARIMA(3,0,5) with non-zero mean : -11416.08\n",
      " ARIMA(2,0,5) with zero mean     : -11425.66\n",
      " ARIMA(1,0,5) with zero mean     : -11390.15\n",
      " ARIMA(2,0,4) with zero mean     : -11415.42\n",
      " ARIMA(3,0,5) with zero mean     : -11418.12\n",
      " ARIMA(1,0,4) with zero mean     : -11386.19\n",
      " ARIMA(3,0,4) with zero mean     : -11485.51\n",
      " ARIMA(3,0,3) with zero mean     : -11390.06\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -11385.19\n",
      " ARIMA(4,0,3) with zero mean     : -11445.33\n",
      " ARIMA(4,0,5) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,5) with zero mean     : -11430.84\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11379.91\n",
      " ARIMA(0,0,0) with non-zero mean : -6735.304\n",
      " ARIMA(1,0,0) with non-zero mean : -11354.43\n",
      " ARIMA(0,0,1) with non-zero mean : -8758.988\n",
      " ARIMA(0,0,0) with zero mean     : -6737.172\n",
      " ARIMA(1,0,2) with non-zero mean : -11375.63\n",
      " ARIMA(2,0,1) with non-zero mean : -11373.84\n",
      " ARIMA(3,0,2) with non-zero mean : -11461.55\n",
      " ARIMA(3,0,1) with non-zero mean : -11386.02\n",
      " ARIMA(4,0,2) with non-zero mean : -11400.26\n",
      " ARIMA(3,0,3) with non-zero mean : -11400.01\n",
      " ARIMA(2,0,3) with non-zero mean : -11395.61\n",
      " ARIMA(4,0,1) with non-zero mean : -11398.44\n",
      " ARIMA(4,0,3) with non-zero mean : -11457.4\n",
      " ARIMA(3,0,2) with zero mean     : -11463.57\n",
      " ARIMA(2,0,2) with zero mean     : -11381.74\n",
      " ARIMA(3,0,1) with zero mean     : -11388.02\n",
      " ARIMA(4,0,2) with zero mean     : -11402.26\n",
      " ARIMA(3,0,3) with zero mean     : -11402.03\n",
      " ARIMA(2,0,1) with zero mean     : -11375.86\n",
      " ARIMA(2,0,3) with zero mean     : -11397.63\n",
      " ARIMA(4,0,1) with zero mean     : -11400.45\n",
      " ARIMA(4,0,3) with zero mean     : -11459.4\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11399.38\n",
      "\n",
      " Best model: ARIMA(4,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11418.83\n",
      " ARIMA(0,0,0) with non-zero mean : -6770.192\n",
      " ARIMA(1,0,0) with non-zero mean : -11389.52\n",
      " ARIMA(0,0,1) with non-zero mean : -8798.915\n",
      " ARIMA(0,0,0) with zero mean     : -6772.157\n",
      " ARIMA(1,0,2) with non-zero mean : -11413.24\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11497.24\n",
      " ARIMA(3,0,1) with non-zero mean : -11425.94\n",
      " ARIMA(4,0,2) with non-zero mean : -11440.64\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11432.73\n",
      " ARIMA(4,0,1) with non-zero mean : -11439.86\n",
      " ARIMA(4,0,3) with non-zero mean : -11482.5\n",
      " ARIMA(3,0,2) with zero mean     : -11499.25\n",
      " ARIMA(2,0,2) with zero mean     : -11420.85\n",
      " ARIMA(3,0,1) with zero mean     : -11427.95\n",
      " ARIMA(4,0,2) with zero mean     : -11442.65\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -11434.74\n",
      " ARIMA(4,0,1) with zero mean     : -11441.87\n",
      " ARIMA(4,0,3) with zero mean     : -11484.67\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11438.64\n",
      "\n",
      " Best model: ARIMA(4,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11414.32\n",
      " ARIMA(0,0,0) with non-zero mean : -6776.125\n",
      " ARIMA(1,0,0) with non-zero mean : -11387.21\n",
      " ARIMA(0,0,1) with non-zero mean : -8799.227\n",
      " ARIMA(0,0,0) with zero mean     : -6777.222\n",
      " ARIMA(1,0,2) with non-zero mean : -11409.82\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11486.69\n",
      " ARIMA(3,0,1) with non-zero mean : -11419.62\n",
      " ARIMA(4,0,2) with non-zero mean : -11432.54\n",
      " ARIMA(3,0,3) with non-zero mean : -11432.11\n",
      " ARIMA(2,0,3) with non-zero mean : -11428.57\n",
      " ARIMA(4,0,1) with non-zero mean : -11432.22\n",
      " ARIMA(4,0,3) with non-zero mean : -11426.07\n",
      " ARIMA(3,0,2) with zero mean     : -11488.4\n",
      " ARIMA(2,0,2) with zero mean     : -11416.24\n",
      " ARIMA(3,0,1) with zero mean     : -11421.53\n",
      " ARIMA(4,0,2) with zero mean     : -11434.45\n",
      " ARIMA(3,0,3) with zero mean     : -11434.02\n",
      " ARIMA(2,0,1) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -11430.48\n",
      " ARIMA(4,0,1) with zero mean     : -11434.15\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11433.84\n",
      "\n",
      " Best model: ARIMA(4,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11396.28\n",
      " ARIMA(0,0,0) with non-zero mean : -6767.655\n",
      " ARIMA(1,0,0) with non-zero mean : -11366.24\n",
      " ARIMA(0,0,1) with non-zero mean : -8786.68\n",
      " ARIMA(0,0,0) with zero mean     : -6768.269\n",
      " ARIMA(1,0,2) with non-zero mean : -11391.4\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11410.85\n",
      " ARIMA(1,0,3) with non-zero mean : -11413.2\n",
      " ARIMA(0,0,3) with non-zero mean : -10241.8\n",
      " ARIMA(1,0,4) with non-zero mean : -11411.5\n",
      " ARIMA(0,0,2) with non-zero mean : -9706.747\n",
      " ARIMA(0,0,4) with non-zero mean : -10664.67\n",
      " ARIMA(2,0,4) with non-zero mean : -11450.27\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11458.58\n",
      " ARIMA(1,0,5) with non-zero mean : -11415.38\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with zero mean     : -11460.53\n",
      " ARIMA(1,0,5) with zero mean     : -11417.36\n",
      " ARIMA(2,0,4) with zero mean     : -11452.21\n",
      " ARIMA(3,0,5) with zero mean     : -11458.99\n",
      " ARIMA(1,0,4) with zero mean     : -11413.48\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,5) with zero mean     : -11459.53\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11379.85\n",
      " ARIMA(0,0,0) with non-zero mean : -6769.06\n",
      " ARIMA(1,0,0) with non-zero mean : -11350.52\n",
      " ARIMA(0,0,1) with non-zero mean : -8784.121\n",
      " ARIMA(0,0,0) with zero mean     : -6770.196\n",
      " ARIMA(1,0,2) with non-zero mean : -11374.77\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11440.14\n",
      " ARIMA(3,0,1) with non-zero mean : -11385.46\n",
      " ARIMA(4,0,2) with non-zero mean : -11398.72\n",
      " ARIMA(3,0,3) with non-zero mean : -11399.1\n",
      " ARIMA(2,0,3) with non-zero mean : -11395.62\n",
      " ARIMA(4,0,1) with non-zero mean : -11397.24\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11442.2\n",
      " ARIMA(2,0,2) with zero mean     : -11381.87\n",
      " ARIMA(3,0,1) with zero mean     : -11387.48\n",
      " ARIMA(4,0,2) with zero mean     : -11400.7\n",
      " ARIMA(3,0,3) with zero mean     : -11401.11\n",
      " ARIMA(2,0,1) with zero mean     : -11375.84\n",
      " ARIMA(2,0,3) with zero mean     : -11397.63\n",
      " ARIMA(4,0,1) with zero mean     : -11399.24\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11400.25\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11368.58\n",
      " ARIMA(0,0,0) with non-zero mean : -6755.177\n",
      " ARIMA(1,0,0) with non-zero mean : -11340.91\n",
      " ARIMA(0,0,1) with non-zero mean : -8775.252\n",
      " ARIMA(0,0,0) with zero mean     : -6756.647\n",
      " ARIMA(1,0,2) with non-zero mean : -11363.4\n",
      " ARIMA(2,0,1) with non-zero mean : -11362.12\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11383.49\n",
      " ARIMA(1,0,3) with non-zero mean : -11385.66\n",
      " ARIMA(0,0,3) with non-zero mean : -10228.52\n",
      " ARIMA(1,0,4) with non-zero mean : -11383.84\n",
      " ARIMA(0,0,2) with non-zero mean : -9695.095\n",
      " ARIMA(0,0,4) with non-zero mean : -10649.52\n",
      " ARIMA(2,0,4) with non-zero mean : -11413.73\n",
      " ARIMA(3,0,4) with non-zero mean : -11467.64\n",
      " ARIMA(3,0,3) with non-zero mean : -11386.95\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : -11449.17\n",
      " ARIMA(2,0,5) with non-zero mean : -11419.96\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -11459.53\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11424.77\n",
      "\n",
      " Best model: ARIMA(2,0,5) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11384.56\n",
      " ARIMA(0,0,0) with non-zero mean : -6817.572\n",
      " ARIMA(1,0,0) with non-zero mean : -11356.29\n",
      " ARIMA(0,0,1) with non-zero mean : -8815.3\n",
      " ARIMA(0,0,0) with zero mean     : -6819.524\n",
      " ARIMA(1,0,2) with non-zero mean : -11378.77\n",
      " ARIMA(2,0,1) with non-zero mean : -11376.91\n",
      " ARIMA(3,0,2) with non-zero mean : -11457.48\n",
      " ARIMA(3,0,1) with non-zero mean : -11390.32\n",
      " ARIMA(4,0,2) with non-zero mean : -11401.89\n",
      " ARIMA(3,0,3) with non-zero mean : -11402.85\n",
      " ARIMA(2,0,3) with non-zero mean : -11397.85\n",
      " ARIMA(4,0,1) with non-zero mean : -11401.42\n",
      " ARIMA(4,0,3) with non-zero mean : -11408.13\n",
      " ARIMA(3,0,2) with zero mean     : -11459.44\n",
      " ARIMA(2,0,2) with zero mean     : -11386.54\n",
      " ARIMA(3,0,1) with zero mean     : -11392.27\n",
      " ARIMA(4,0,2) with zero mean     : -11403.82\n",
      " ARIMA(3,0,3) with zero mean     : -11404.78\n",
      " ARIMA(2,0,1) with zero mean     : -11378.84\n",
      " ARIMA(2,0,3) with zero mean     : -11399.82\n",
      " ARIMA(4,0,1) with zero mean     : -11403.36\n",
      " ARIMA(4,0,3) with zero mean     : -11401.82\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -11429.81\n",
      "\n",
      " Best model: ARIMA(4,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11412.64\n",
      " ARIMA(0,0,0) with non-zero mean : -6848.389\n",
      " ARIMA(1,0,0) with non-zero mean : -11381.79\n",
      " ARIMA(0,0,1) with non-zero mean : -8850.215\n",
      " ARIMA(0,0,0) with zero mean     : -6849.878\n",
      " ARIMA(1,0,2) with non-zero mean : -11405.42\n",
      " ARIMA(2,0,1) with non-zero mean : -11408.53\n",
      " ARIMA(3,0,2) with non-zero mean : -11426.53\n",
      " ARIMA(3,0,1) with non-zero mean : -11419.05\n",
      " ARIMA(4,0,2) with non-zero mean : -11428.85\n",
      " ARIMA(4,0,1) with non-zero mean : -11428.66\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -11427.82\n",
      " ARIMA(5,0,1) with non-zero mean : -11459.29\n",
      " ARIMA(5,0,0) with non-zero mean : -11427.85\n",
      " ARIMA(4,0,0) with non-zero mean : -11430.59\n",
      " ARIMA(5,0,1) with zero mean     : -11461.27\n",
      " ARIMA(4,0,1) with zero mean     : -11430.65\n",
      " ARIMA(5,0,0) with zero mean     : -11429.84\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,0) with zero mean     : -11432.58\n",
      " ARIMA(4,0,2) with zero mean     : -11431.03\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,1) with zero mean     : -11456.59\n",
      "\n",
      " Best model: ARIMA(5,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11417.39\n",
      " ARIMA(0,0,0) with non-zero mean : -6856.506\n",
      " ARIMA(1,0,0) with non-zero mean : -11388.09\n",
      " ARIMA(0,0,1) with non-zero mean : -8862.562\n",
      " ARIMA(0,0,0) with zero mean     : -6858.168\n",
      " ARIMA(1,0,2) with non-zero mean : -11413.18\n",
      " ARIMA(2,0,1) with non-zero mean : -11411.51\n",
      " ARIMA(3,0,2) with non-zero mean : -11436.07\n",
      " ARIMA(3,0,1) with non-zero mean : -11423.64\n",
      " ARIMA(4,0,2) with non-zero mean : -11435.75\n",
      " ARIMA(3,0,3) with non-zero mean : -11435.89\n",
      " ARIMA(2,0,3) with non-zero mean : -11430.71\n",
      " ARIMA(4,0,1) with non-zero mean : -11434.25\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11438.08\n",
      " ARIMA(2,0,2) with zero mean     : -11419.4\n",
      " ARIMA(3,0,1) with zero mean     : -11425.65\n",
      " ARIMA(4,0,2) with zero mean     : -11437.77\n",
      " ARIMA(3,0,3) with zero mean     : -11437.9\n",
      " ARIMA(2,0,1) with zero mean     : -11413.52\n",
      " ARIMA(2,0,3) with zero mean     : -11432.72\n",
      " ARIMA(4,0,1) with zero mean     : -11436.26\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11434.82\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11423.12\n",
      " ARIMA(0,0,0) with non-zero mean : -6855.742\n",
      " ARIMA(1,0,0) with non-zero mean : -11392.02\n",
      " ARIMA(0,0,1) with non-zero mean : -8862.21\n",
      " ARIMA(0,0,0) with zero mean     : -6857.312\n",
      " ARIMA(1,0,2) with non-zero mean : -11417.26\n",
      " ARIMA(2,0,1) with non-zero mean : -11416.16\n",
      " ARIMA(3,0,2) with non-zero mean : -11493.1\n",
      " ARIMA(3,0,1) with non-zero mean : -11428.28\n",
      " ARIMA(4,0,2) with non-zero mean : -11437.52\n",
      " ARIMA(3,0,3) with non-zero mean : -11438.52\n",
      " ARIMA(2,0,3) with non-zero mean : -11434.97\n",
      " ARIMA(4,0,1) with non-zero mean : -11437.01\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11495.07\n",
      " ARIMA(2,0,2) with zero mean     : -11425.08\n",
      " ARIMA(3,0,1) with zero mean     : -11430.27\n",
      " ARIMA(4,0,2) with zero mean     : -11439.6\n",
      " ARIMA(3,0,3) with zero mean     : -11440.51\n",
      " ARIMA(2,0,1) with zero mean     : -11418.15\n",
      " ARIMA(2,0,3) with zero mean     : -11436.96\n",
      " ARIMA(4,0,1) with zero mean     : -11438.99\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11438.77\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11430.97\n",
      " ARIMA(0,0,0) with non-zero mean : -6848.48\n",
      " ARIMA(1,0,0) with non-zero mean : -11402.64\n",
      " ARIMA(0,0,1) with non-zero mean : -8856.769\n",
      " ARIMA(0,0,0) with zero mean     : -6849.649\n",
      " ARIMA(1,0,2) with non-zero mean : -11427.39\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11502.31\n",
      " ARIMA(3,0,1) with non-zero mean : -11437.26\n",
      " ARIMA(4,0,2) with non-zero mean : -11447.51\n",
      " ARIMA(3,0,3) with non-zero mean : -11448.73\n",
      " ARIMA(2,0,3) with non-zero mean : -11443.78\n",
      " ARIMA(4,0,1) with non-zero mean : -11446.63\n",
      " ARIMA(4,0,3) with non-zero mean : -11509.92\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -11446.8\n",
      " ARIMA(5,0,2) with non-zero mean : -11447.79\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11511.9\n",
      " ARIMA(3,0,3) with zero mean     : -11450.67\n",
      " ARIMA(4,0,2) with zero mean     : -11449.59\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11504.14\n",
      " ARIMA(3,0,4) with zero mean     : -11448.79\n",
      " ARIMA(5,0,2) with zero mean     : -11449.75\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11448.04\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11440.69\n",
      " ARIMA(0,0,0) with non-zero mean : -6856.218\n",
      " ARIMA(1,0,0) with non-zero mean : -11411.42\n",
      " ARIMA(0,0,1) with non-zero mean : -8866.494\n",
      " ARIMA(0,0,0) with zero mean     : -6856.027\n",
      " ARIMA(1,0,2) with non-zero mean : -11436.86\n",
      " ARIMA(2,0,1) with non-zero mean : -11435.31\n",
      " ARIMA(3,0,2) with non-zero mean : -11514.58\n",
      " ARIMA(3,0,1) with non-zero mean : -11446.49\n",
      " ARIMA(4,0,2) with non-zero mean : -11454.49\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11453.31\n",
      " ARIMA(4,0,1) with non-zero mean : -11454.65\n",
      " ARIMA(4,0,3) with non-zero mean : -11488.67\n",
      " ARIMA(3,0,2) with zero mean     : -11516.38\n",
      " ARIMA(2,0,2) with zero mean     : -11442.63\n",
      " ARIMA(3,0,1) with zero mean     : -11448.44\n",
      " ARIMA(4,0,2) with zero mean     : -11456.57\n",
      " ARIMA(3,0,3) with zero mean     : -11457.42\n",
      " ARIMA(2,0,1) with zero mean     : -11437.26\n",
      " ARIMA(2,0,3) with zero mean     : -11455.25\n",
      " ARIMA(4,0,1) with zero mean     : -11456.59\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -11493.26\n",
      "\n",
      " Best model: ARIMA(4,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11441.76\n",
      " ARIMA(0,0,0) with non-zero mean : -6867.168\n",
      " ARIMA(1,0,0) with non-zero mean : -11412.83\n",
      " ARIMA(0,0,1) with non-zero mean : -8874.459\n",
      " ARIMA(0,0,0) with zero mean     : -6868.118\n",
      " ARIMA(1,0,2) with non-zero mean : -11438.26\n",
      " ARIMA(2,0,1) with non-zero mean : -11439.57\n",
      " ARIMA(3,0,2) with non-zero mean : -11460.46\n",
      " ARIMA(3,0,1) with non-zero mean : -11452.45\n",
      " ARIMA(4,0,2) with non-zero mean : -11460.15\n",
      " ARIMA(3,0,3) with non-zero mean : -11460.42\n",
      " ARIMA(2,0,3) with non-zero mean : -11457.03\n",
      " ARIMA(4,0,1) with non-zero mean : -11460.67\n",
      " ARIMA(4,0,0) with non-zero mean : -11462.52\n",
      " ARIMA(3,0,0) with non-zero mean : -11445.99\n",
      " ARIMA(5,0,0) with non-zero mean : -11460.51\n",
      " ARIMA(5,0,1) with non-zero mean : -11490.28\n",
      " ARIMA(5,0,2) with non-zero mean : -11489.45\n",
      " ARIMA(5,0,1) with zero mean     : -11492.28\n",
      " ARIMA(4,0,1) with zero mean     : -11462.63\n",
      " ARIMA(5,0,0) with zero mean     : -11462.47\n",
      " ARIMA(5,0,2) with zero mean     : -11491.47\n",
      " ARIMA(4,0,0) with zero mean     : -11464.49\n",
      " ARIMA(4,0,2) with zero mean     : -11462.11\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,1) with zero mean     : -11489.3\n",
      "\n",
      " Best model: ARIMA(5,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11450.16\n",
      " ARIMA(0,0,0) with non-zero mean : -6876.022\n",
      " ARIMA(1,0,0) with non-zero mean : -11420.01\n",
      " ARIMA(0,0,1) with non-zero mean : -8882.957\n",
      " ARIMA(0,0,0) with zero mean     : -6875.829\n",
      " ARIMA(1,0,2) with non-zero mean : -11445.95\n",
      " ARIMA(2,0,1) with non-zero mean : -11444.35\n",
      " ARIMA(3,0,2) with non-zero mean : -11466.46\n",
      " ARIMA(3,0,1) with non-zero mean : -11456.16\n",
      " ARIMA(4,0,2) with non-zero mean : -11465.03\n",
      " ARIMA(3,0,3) with non-zero mean : -11466.1\n",
      " ARIMA(2,0,3) with non-zero mean : -11463.41\n",
      " ARIMA(4,0,1) with non-zero mean : -11464.87\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11468.34\n",
      " ARIMA(2,0,2) with zero mean     : -11452.05\n",
      " ARIMA(3,0,1) with zero mean     : -11458.07\n",
      " ARIMA(4,0,2) with zero mean     : -11466.92\n",
      " ARIMA(3,0,3) with zero mean     : -11468.01\n",
      " ARIMA(2,0,1) with zero mean     : -11446.24\n",
      " ARIMA(2,0,3) with zero mean     : -11465.3\n",
      " ARIMA(4,0,1) with zero mean     : -11466.76\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11467.86\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11459.35\n",
      " ARIMA(0,0,0) with non-zero mean : -6885.081\n",
      " ARIMA(1,0,0) with non-zero mean : -11430.32\n",
      " ARIMA(0,0,1) with non-zero mean : -8894.963\n",
      " ARIMA(0,0,0) with zero mean     : -6883.912\n",
      " ARIMA(1,0,2) with non-zero mean : -11455.26\n",
      " ARIMA(2,0,1) with non-zero mean : -11453.41\n",
      " ARIMA(3,0,2) with non-zero mean : -11478.09\n",
      " ARIMA(3,0,1) with non-zero mean : -11465.83\n",
      " ARIMA(4,0,2) with non-zero mean : -11476.69\n",
      " ARIMA(3,0,3) with non-zero mean : -11477.8\n",
      " ARIMA(2,0,3) with non-zero mean : -11472.47\n",
      " ARIMA(4,0,1) with non-zero mean : -11475.17\n",
      " ARIMA(4,0,3) with non-zero mean : -11529.99\n",
      " ARIMA(5,0,3) with non-zero mean : -11474.61\n",
      " ARIMA(4,0,4) with non-zero mean : -11559.37\n",
      " ARIMA(3,0,4) with non-zero mean : -11492.22\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : -11504.37\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,4) with non-zero mean : -11508.64\n",
      "\n",
      " Best model: ARIMA(4,0,4) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11473.67\n",
      " ARIMA(0,0,0) with non-zero mean : -6904.305\n",
      " ARIMA(1,0,0) with non-zero mean : -11442.86\n",
      " ARIMA(0,0,1) with non-zero mean : -8909.573\n",
      " ARIMA(0,0,0) with zero mean     : -6902.564\n",
      " ARIMA(1,0,2) with non-zero mean : -11467.87\n",
      " ARIMA(2,0,1) with non-zero mean : -11468.18\n",
      " ARIMA(3,0,2) with non-zero mean : -11488.61\n",
      " ARIMA(3,0,1) with non-zero mean : -11478.94\n",
      " ARIMA(4,0,2) with non-zero mean : -11488.89\n",
      " ARIMA(4,0,1) with non-zero mean : -11488.23\n",
      " ARIMA(5,0,2) with non-zero mean : -11530.04\n",
      " ARIMA(5,0,1) with non-zero mean : -11514.48\n",
      " ARIMA(5,0,3) with non-zero mean : -11533.06\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,1) with non-zero mean : -11515.81\n",
      "\n",
      " Best model: ARIMA(5,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11497.17\n",
      " ARIMA(0,0,0) with non-zero mean : -7026.856\n",
      " ARIMA(1,0,0) with non-zero mean : -11463.53\n",
      " ARIMA(0,0,1) with non-zero mean : -8998.064\n",
      " ARIMA(0,0,0) with zero mean     : -7018.215\n",
      " ARIMA(1,0,2) with non-zero mean : -11490.08\n",
      " ARIMA(2,0,1) with non-zero mean : -11479.81\n",
      " ARIMA(3,0,2) with non-zero mean : -11511.03\n",
      " ARIMA(3,0,1) with non-zero mean : -11502\n",
      " ARIMA(4,0,2) with non-zero mean : -11515.83\n",
      " ARIMA(4,0,1) with non-zero mean : -11517.05\n",
      " ARIMA(4,0,0) with non-zero mean : -11516.32\n",
      " ARIMA(5,0,1) with non-zero mean : -11532.81\n",
      " ARIMA(5,0,0) with non-zero mean : -11533.61\n",
      " ARIMA(5,0,0) with zero mean     : -11534.97\n",
      " ARIMA(4,0,0) with zero mean     : -11517.84\n",
      " ARIMA(5,0,1) with zero mean     : -11534.17\n",
      " ARIMA(4,0,1) with zero mean     : -11518.5\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,0) with zero mean     : -11510.2\n",
      "\n",
      " Best model: ARIMA(5,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11522.36\n",
      " ARIMA(0,0,0) with non-zero mean : -6976.397\n",
      " ARIMA(1,0,0) with non-zero mean : -11483.5\n",
      " ARIMA(0,0,1) with non-zero mean : -8955.384\n",
      " ARIMA(0,0,0) with zero mean     : -6973.519\n",
      " ARIMA(1,0,2) with non-zero mean : -11518.05\n",
      " ARIMA(2,0,1) with non-zero mean : -11502.5\n",
      " ARIMA(3,0,2) with non-zero mean : -11539.76\n",
      " ARIMA(3,0,1) with non-zero mean : -11532\n",
      " ARIMA(4,0,2) with non-zero mean : -11540.01\n",
      " ARIMA(4,0,1) with non-zero mean : -11541.17\n",
      " ARIMA(4,0,0) with non-zero mean : -11542.91\n",
      " ARIMA(3,0,0) with non-zero mean : -11523.24\n",
      " ARIMA(5,0,0) with non-zero mean : -11548.94\n",
      " ARIMA(5,0,1) with non-zero mean : -11560.19\n",
      " ARIMA(5,0,2) with non-zero mean : -11558.2\n",
      " ARIMA(5,0,1) with zero mean     : -11562.08\n",
      " ARIMA(4,0,1) with zero mean     : -11543.1\n",
      " ARIMA(5,0,0) with zero mean     : -11550.92\n",
      " ARIMA(5,0,2) with zero mean     : -11560.09\n",
      " ARIMA(4,0,0) with zero mean     : -11544.85\n",
      " ARIMA(4,0,2) with zero mean     : -11541.94\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,1) with zero mean     : -11573.33\n",
      "\n",
      " Best model: ARIMA(5,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11485.88\n",
      " ARIMA(0,0,0) with non-zero mean : -7008.245\n",
      " ARIMA(1,0,0) with non-zero mean : -11447.22\n",
      " ARIMA(0,0,1) with non-zero mean : -8956.127\n",
      " ARIMA(0,0,0) with zero mean     : -7003.898\n",
      " ARIMA(1,0,2) with non-zero mean : -11483.16\n",
      " ARIMA(2,0,1) with non-zero mean : -11482.32\n",
      " ARIMA(3,0,2) with non-zero mean : -11506.05\n",
      " ARIMA(3,0,1) with non-zero mean : -11491.58\n",
      " ARIMA(4,0,2) with non-zero mean : -11505.48\n",
      " ARIMA(3,0,3) with non-zero mean : -11505.8\n",
      " ARIMA(2,0,3) with non-zero mean : -11498.3\n",
      " ARIMA(4,0,1) with non-zero mean : -11502.45\n",
      " ARIMA(4,0,3) with non-zero mean : -11520.2\n",
      " ARIMA(5,0,3) with non-zero mean : -11529.58\n",
      " ARIMA(5,0,2) with non-zero mean : -11525.97\n",
      " ARIMA(5,0,4) with non-zero mean : -11582.08\n",
      " ARIMA(4,0,4) with non-zero mean : -11531.68\n",
      " ARIMA(5,0,5) with non-zero mean : -11565.09\n",
      " ARIMA(4,0,5) with non-zero mean : -11538.66\n",
      " ARIMA(5,0,4) with zero mean     : -11583.66\n",
      " ARIMA(4,0,4) with zero mean     : -11533.24\n",
      " ARIMA(5,0,3) with zero mean     : -11531.52\n",
      " ARIMA(5,0,5) with zero mean     : -11566.72\n",
      " ARIMA(4,0,3) with zero mean     : -11521.86\n",
      " ARIMA(4,0,5) with zero mean     : -11540.44\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,5) with zero mean     : Inf\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with zero mean     : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11532.83\n",
      "\n",
      " Best model: ARIMA(5,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11484.53\n",
      " ARIMA(0,0,0) with non-zero mean : -7045.561\n",
      " ARIMA(1,0,0) with non-zero mean : -11444.21\n",
      " ARIMA(0,0,1) with non-zero mean : -8986.409\n",
      " ARIMA(0,0,0) with zero mean     : -7038.631\n",
      " ARIMA(1,0,2) with non-zero mean : -11482.13\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11504.12\n",
      " ARIMA(3,0,1) with non-zero mean : -11491.11\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11494.91\n",
      " ARIMA(4,0,1) with non-zero mean : -11499.35\n",
      " ARIMA(4,0,3) with non-zero mean : -11526.26\n",
      " ARIMA(5,0,3) with non-zero mean : -11517.71\n",
      " ARIMA(4,0,4) with non-zero mean : -11527.82\n",
      " ARIMA(3,0,4) with non-zero mean : -11575.39\n",
      " ARIMA(2,0,4) with non-zero mean : -11528.58\n",
      " ARIMA(3,0,5) with non-zero mean : -11562.18\n",
      " ARIMA(2,0,5) with non-zero mean : -11534.69\n",
      " ARIMA(4,0,5) with non-zero mean : -11524.81\n",
      " ARIMA(3,0,4) with zero mean     : -11577.89\n",
      " ARIMA(2,0,4) with zero mean     : -11530.23\n",
      " ARIMA(3,0,3) with zero mean     : -11566.83\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with zero mean     : -11564.21\n",
      " ARIMA(2,0,3) with zero mean     : -11496.61\n",
      " ARIMA(2,0,5) with zero mean     : -11536.4\n",
      " ARIMA(4,0,3) with zero mean     : -11527.89\n",
      " ARIMA(4,0,5) with zero mean     : -11526.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with zero mean     : -11533.26\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11512.55\n",
      " ARIMA(0,0,0) with non-zero mean : -7061.255\n",
      " ARIMA(1,0,0) with non-zero mean : -11465.68\n",
      " ARIMA(0,0,1) with non-zero mean : -9005.312\n",
      " ARIMA(0,0,0) with zero mean     : -7056.084\n",
      " ARIMA(1,0,2) with non-zero mean : -11505.82\n",
      " ARIMA(2,0,1) with non-zero mean : -11507.85\n",
      " ARIMA(3,0,2) with non-zero mean : -11529.8\n",
      " ARIMA(3,0,1) with non-zero mean : -11518.26\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -11528.69\n",
      " ARIMA(2,0,3) with non-zero mean : -11525.98\n",
      " ARIMA(4,0,1) with non-zero mean : -11526.77\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11531.71\n",
      " ARIMA(2,0,2) with zero mean     : -11514.51\n",
      " ARIMA(3,0,1) with zero mean     : -11520.21\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11530.61\n",
      " ARIMA(2,0,1) with zero mean     : -11509.79\n",
      " ARIMA(2,0,3) with zero mean     : -11527.91\n",
      " ARIMA(4,0,1) with zero mean     : -11528.68\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11531.16\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11482.71\n",
      " ARIMA(0,0,0) with non-zero mean : -7055.949\n",
      " ARIMA(1,0,0) with non-zero mean : -11440.36\n",
      " ARIMA(0,0,1) with non-zero mean : -8999.116\n",
      " ARIMA(0,0,0) with zero mean     : -7050.65\n",
      " ARIMA(1,0,2) with non-zero mean : -11479.36\n",
      " ARIMA(2,0,1) with non-zero mean : -11479.16\n",
      " ARIMA(3,0,2) with non-zero mean : -11504.84\n",
      " ARIMA(3,0,1) with non-zero mean : -11490.33\n",
      " ARIMA(4,0,2) with non-zero mean : -11502.25\n",
      " ARIMA(3,0,3) with non-zero mean : -11503.38\n",
      " ARIMA(2,0,3) with non-zero mean : -11497.76\n",
      " ARIMA(4,0,1) with non-zero mean : -11502.16\n",
      " ARIMA(4,0,3) with non-zero mean : -11506.83\n",
      " ARIMA(5,0,3) with non-zero mean : -11536.13\n",
      " ARIMA(5,0,2) with non-zero mean : -11529.28\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11522.49\n",
      " ARIMA(5,0,3) with zero mean     : -11537.82\n",
      " ARIMA(4,0,3) with zero mean     : -11507.84\n",
      " ARIMA(5,0,2) with zero mean     : -11530.86\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11503.86\n",
      " ARIMA(4,0,4) with zero mean     : -11523.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with zero mean     : -11537.58\n",
      "\n",
      " Best model: ARIMA(5,0,3) with zero mean     \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11490.37\n",
      " ARIMA(0,0,0) with non-zero mean : -7047.452\n",
      " ARIMA(1,0,0) with non-zero mean : -11444.65\n",
      " ARIMA(0,0,1) with non-zero mean : -8991.749\n",
      " ARIMA(0,0,0) with zero mean     : -7039.512\n",
      " ARIMA(1,0,2) with non-zero mean : -11484.88\n",
      " ARIMA(2,0,1) with non-zero mean : -11485.48\n",
      " ARIMA(3,0,2) with non-zero mean : -11509.2\n",
      " ARIMA(3,0,1) with non-zero mean : -11496.02\n",
      " ARIMA(4,0,2) with non-zero mean : -11507.8\n",
      " ARIMA(3,0,3) with non-zero mean : -11507.44\n",
      " ARIMA(2,0,3) with non-zero mean : -11503.08\n",
      " ARIMA(4,0,1) with non-zero mean : -11507.8\n",
      " ARIMA(4,0,3) with non-zero mean : -11548.82\n",
      " ARIMA(5,0,3) with non-zero mean : -11539.74\n",
      " ARIMA(4,0,4) with non-zero mean : -11525.75\n",
      " ARIMA(3,0,4) with non-zero mean : -11542.99\n",
      " ARIMA(5,0,2) with non-zero mean : -11530.54\n",
      " ARIMA(5,0,4) with non-zero mean : -11540.45\n",
      " ARIMA(4,0,3) with zero mean     : -11550.67\n",
      " ARIMA(3,0,3) with zero mean     : -11509.09\n",
      " ARIMA(4,0,2) with zero mean     : -11509.38\n",
      " ARIMA(5,0,3) with zero mean     : -11540.95\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11510.85\n",
      " ARIMA(3,0,4) with zero mean     : -11544.76\n",
      " ARIMA(5,0,2) with zero mean     : -11532.19\n",
      " ARIMA(5,0,4) with zero mean     : -11579.37\n",
      " ARIMA(5,0,5) with zero mean     : -11543.06\n",
      " ARIMA(4,0,5) with zero mean     : -11592.29\n",
      " ARIMA(3,0,5) with zero mean     : -11545.3\n",
      " ARIMA(4,0,5) with non-zero mean : -11590.86\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,5) with zero mean     : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with zero mean     : -11578.88\n",
      "\n",
      " Best model: ARIMA(5,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11508.12\n",
      " ARIMA(0,0,0) with non-zero mean : -7087.399\n",
      " ARIMA(1,0,0) with non-zero mean : -11462.71\n",
      " ARIMA(0,0,1) with non-zero mean : -9025.635\n",
      " ARIMA(0,0,0) with zero mean     : -7072.381\n",
      " ARIMA(1,0,2) with non-zero mean : -11504.23\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11528.6\n",
      " ARIMA(3,0,1) with non-zero mean : -11515.45\n",
      " ARIMA(4,0,2) with non-zero mean : -11526.53\n",
      " ARIMA(3,0,3) with non-zero mean : -11527.53\n",
      " ARIMA(2,0,3) with non-zero mean : -11520.4\n",
      " ARIMA(4,0,1) with non-zero mean : -11523.82\n",
      " ARIMA(4,0,3) with non-zero mean : -11542.11\n",
      " ARIMA(5,0,3) with non-zero mean : -11554.06\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : -11602.43\n",
      " ARIMA(4,0,4) with non-zero mean : -11549.88\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : -11557.33\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,4) with non-zero mean : -11602.48\n",
      "\n",
      " Best model: ARIMA(5,0,4) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11526.79\n",
      " ARIMA(0,0,0) with non-zero mean : -7092.398\n",
      " ARIMA(1,0,0) with non-zero mean : -11484.3\n",
      " ARIMA(0,0,1) with non-zero mean : -9043.673\n",
      " ARIMA(0,0,0) with zero mean     : -7075.856\n",
      " ARIMA(1,0,2) with non-zero mean : -11524.41\n",
      " ARIMA(2,0,1) with non-zero mean : -11524.82\n",
      " ARIMA(3,0,2) with non-zero mean : -11552.34\n",
      " ARIMA(3,0,1) with non-zero mean : -11541.36\n",
      " ARIMA(4,0,2) with non-zero mean : -11552.16\n",
      " ARIMA(3,0,3) with non-zero mean : -11552.84\n",
      " ARIMA(2,0,3) with non-zero mean : -11543.3\n",
      " ARIMA(4,0,3) with non-zero mean : -11554.74\n",
      " ARIMA(5,0,3) with non-zero mean : -11575.93\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -11577.43\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11553.65\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with zero mean     : -11571.37\n",
      "\n",
      " Best model: ARIMA(5,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11547.91\n",
      " ARIMA(0,0,0) with non-zero mean : -7107.758\n",
      " ARIMA(1,0,0) with non-zero mean : -11504.77\n",
      " ARIMA(0,0,1) with non-zero mean : -9060.209\n",
      " ARIMA(0,0,0) with zero mean     : -7094.49\n",
      " ARIMA(1,0,2) with non-zero mean : -11544.18\n",
      " ARIMA(2,0,1) with non-zero mean : -11542.64\n",
      " ARIMA(3,0,2) with non-zero mean : -11570.25\n",
      " ARIMA(3,0,1) with non-zero mean : -11554.96\n",
      " ARIMA(4,0,2) with non-zero mean : -11567.73\n",
      " ARIMA(3,0,3) with non-zero mean : -11568.73\n",
      " ARIMA(2,0,3) with non-zero mean : -11562.27\n",
      " ARIMA(4,0,1) with non-zero mean : -11563.92\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11571.9\n",
      " ARIMA(2,0,2) with zero mean     : -11549.64\n",
      " ARIMA(3,0,1) with zero mean     : -11556.68\n",
      " ARIMA(4,0,2) with zero mean     : -11569.38\n",
      " ARIMA(3,0,3) with zero mean     : -11570.38\n",
      " ARIMA(2,0,1) with zero mean     : -11544.33\n",
      " ARIMA(2,0,3) with zero mean     : -11563.9\n",
      " ARIMA(4,0,1) with zero mean     : -11565.55\n",
      " ARIMA(4,0,3) with zero mean     : -11629.13\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : -11626\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11570.11\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11556.06\n",
      " ARIMA(0,0,0) with non-zero mean : -7115.878\n",
      " ARIMA(1,0,0) with non-zero mean : -11512.93\n",
      " ARIMA(0,0,1) with non-zero mean : -9071.081\n",
      " ARIMA(0,0,0) with zero mean     : -7107.797\n",
      " ARIMA(1,0,2) with non-zero mean : -11552.01\n",
      " ARIMA(2,0,1) with non-zero mean : -11550.3\n",
      " ARIMA(3,0,2) with non-zero mean : -11577.24\n",
      " ARIMA(3,0,1) with non-zero mean : -11562.77\n",
      " ARIMA(4,0,2) with non-zero mean : -11575.26\n",
      " ARIMA(3,0,3) with non-zero mean : -11575.39\n",
      " ARIMA(2,0,3) with non-zero mean : -11569.65\n",
      " ARIMA(4,0,1) with non-zero mean : -11572.43\n",
      " ARIMA(4,0,3) with non-zero mean : -11632.57\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11572.78\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11634.31\n",
      " ARIMA(3,0,3) with zero mean     : -11577.2\n",
      " ARIMA(4,0,2) with zero mean     : -11577.1\n",
      " ARIMA(5,0,3) with zero mean     : -11596.63\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11579.07\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : -11574.61\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -11598.87\n",
      "\n",
      " Best model: ARIMA(5,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11550.76\n",
      " ARIMA(0,0,0) with non-zero mean : -7126.439\n",
      " ARIMA(1,0,0) with non-zero mean : -11509.95\n",
      " ARIMA(0,0,1) with non-zero mean : -9081.564\n",
      " ARIMA(0,0,0) with zero mean     : -7121.931\n",
      " ARIMA(1,0,2) with non-zero mean : -11547.26\n",
      " ARIMA(2,0,1) with non-zero mean : -11545.45\n",
      " ARIMA(3,0,2) with non-zero mean : -11615.83\n",
      " ARIMA(3,0,1) with non-zero mean : -11557.98\n",
      " ARIMA(4,0,2) with non-zero mean : -11570.85\n",
      " ARIMA(3,0,3) with non-zero mean : -11570.56\n",
      " ARIMA(2,0,3) with non-zero mean : -11564.49\n",
      " ARIMA(4,0,1) with non-zero mean : -11567.12\n",
      " ARIMA(4,0,3) with non-zero mean : -11624.41\n",
      " ARIMA(5,0,3) with non-zero mean : -11590.89\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -11596.23\n",
      " ARIMA(5,0,2) with non-zero mean : -11567.64\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11635.38\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11572.65\n",
      " ARIMA(5,0,3) with zero mean     : -11592.65\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11617.52\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : -11569.6\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : -11638.66\n",
      "\n",
      " Best model: ARIMA(4,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11545.12\n",
      " ARIMA(0,0,0) with non-zero mean : -7119.86\n",
      " ARIMA(1,0,0) with non-zero mean : -11506.09\n",
      " ARIMA(0,0,1) with non-zero mean : -9075.953\n",
      " ARIMA(0,0,0) with zero mean     : -7114.27\n",
      " ARIMA(1,0,2) with non-zero mean : -11541.95\n",
      " ARIMA(2,0,1) with non-zero mean : -11540.33\n",
      " ARIMA(3,0,2) with non-zero mean : -11606\n",
      " ARIMA(3,0,1) with non-zero mean : -11553.66\n",
      " ARIMA(4,0,2) with non-zero mean : -11563.55\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11558.54\n",
      " ARIMA(4,0,1) with non-zero mean : -11561.29\n",
      " ARIMA(4,0,3) with non-zero mean : -11618.61\n",
      " ARIMA(5,0,3) with non-zero mean : -11617\n",
      " ARIMA(4,0,4) with non-zero mean : -11627.13\n",
      " ARIMA(3,0,4) with non-zero mean : -11578.07\n",
      " ARIMA(5,0,4) with non-zero mean : -11649.58\n",
      " ARIMA(5,0,5) with non-zero mean : -11575.81\n",
      " ARIMA(4,0,5) with non-zero mean : -11587.7\n",
      " ARIMA(5,0,4) with zero mean     : -11623.15\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with zero mean     : -11631.44\n",
      "\n",
      " Best model: ARIMA(5,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11546.6\n",
      " ARIMA(0,0,0) with non-zero mean : -7114.313\n",
      " ARIMA(1,0,0) with non-zero mean : -11507.8\n",
      " ARIMA(0,0,1) with non-zero mean : -9072.376\n",
      " ARIMA(0,0,0) with zero mean     : -7106.949\n",
      " ARIMA(1,0,2) with non-zero mean : -11543.3\n",
      " ARIMA(2,0,1) with non-zero mean : -11541.55\n",
      " ARIMA(3,0,2) with non-zero mean : -11566.73\n",
      " ARIMA(3,0,1) with non-zero mean : -11554.22\n",
      " ARIMA(4,0,2) with non-zero mean : -11564.63\n",
      " ARIMA(3,0,3) with non-zero mean : -11565.27\n",
      " ARIMA(2,0,3) with non-zero mean : -11558.99\n",
      " ARIMA(4,0,1) with non-zero mean : -11562.35\n",
      " ARIMA(4,0,3) with non-zero mean : -11613.32\n",
      " ARIMA(5,0,3) with non-zero mean : -11628.52\n",
      " ARIMA(5,0,2) with non-zero mean : -11620.28\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11619.37\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : -11634.67\n",
      "\n",
      " Best model: ARIMA(5,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11551.54\n",
      " ARIMA(0,0,0) with non-zero mean : -7118.416\n",
      " ARIMA(1,0,0) with non-zero mean : -11511.29\n",
      " ARIMA(0,0,1) with non-zero mean : -9078.301\n",
      " ARIMA(0,0,0) with zero mean     : -7111.373\n",
      " ARIMA(1,0,2) with non-zero mean : -11547.03\n",
      " ARIMA(2,0,1) with non-zero mean : -11545.53\n",
      " ARIMA(3,0,2) with non-zero mean : -11615.2\n",
      " ARIMA(3,0,1) with non-zero mean : -11557.44\n",
      " ARIMA(4,0,2) with non-zero mean : -11568.29\n",
      " ARIMA(3,0,3) with non-zero mean : -11568.78\n",
      " ARIMA(2,0,3) with non-zero mean : -11563.36\n",
      " ARIMA(4,0,1) with non-zero mean : -11564.77\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11617.02\n",
      " ARIMA(2,0,2) with zero mean     : -11553.27\n",
      " ARIMA(3,0,1) with zero mean     : -11559.16\n",
      " ARIMA(4,0,2) with zero mean     : -11569.97\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -11547.24\n",
      " ARIMA(2,0,3) with zero mean     : -11565.04\n",
      " ARIMA(4,0,1) with zero mean     : -11566.45\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11620.7\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11554.01\n",
      " ARIMA(0,0,0) with non-zero mean : -7116.973\n",
      " ARIMA(1,0,0) with non-zero mean : -11514.16\n",
      " ARIMA(0,0,1) with non-zero mean : -9078.843\n",
      " ARIMA(0,0,0) with zero mean     : -7110.575\n",
      " ARIMA(1,0,2) with non-zero mean : -11549.31\n",
      " ARIMA(2,0,1) with non-zero mean : -11547.38\n",
      " ARIMA(3,0,2) with non-zero mean : -11617.37\n",
      " ARIMA(3,0,1) with non-zero mean : -11560.2\n",
      " ARIMA(4,0,2) with non-zero mean : -11570.91\n",
      " ARIMA(3,0,3) with non-zero mean : -11632.39\n",
      " ARIMA(2,0,3) with non-zero mean : -11565.17\n",
      " ARIMA(4,0,3) with non-zero mean : -11630.52\n",
      " ARIMA(3,0,4) with non-zero mean : -11585.25\n",
      " ARIMA(2,0,4) with non-zero mean : -11587.21\n",
      " ARIMA(4,0,4) with non-zero mean : -11628.73\n",
      " ARIMA(3,0,3) with zero mean     : -11634.27\n",
      " ARIMA(2,0,3) with zero mean     : -11566.99\n",
      " ARIMA(3,0,2) with zero mean     : -11619.19\n",
      " ARIMA(4,0,3) with zero mean     : -11632.5\n",
      " ARIMA(3,0,4) with zero mean     : -11625.88\n",
      " ARIMA(2,0,2) with zero mean     : -11555.88\n",
      " ARIMA(2,0,4) with zero mean     : -11588.91\n",
      " ARIMA(4,0,2) with zero mean     : -11572.75\n",
      " ARIMA(4,0,4) with zero mean     : -11630.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -11628.23\n",
      "\n",
      " Best model: ARIMA(3,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11551.34\n",
      " ARIMA(0,0,0) with non-zero mean : -7106.605\n",
      " ARIMA(1,0,0) with non-zero mean : -11513.4\n",
      " ARIMA(0,0,1) with non-zero mean : -9071.249\n",
      " ARIMA(0,0,0) with zero mean     : -7102.428\n",
      " ARIMA(1,0,2) with non-zero mean : -11547.63\n",
      " ARIMA(2,0,1) with non-zero mean : -11545.49\n",
      " ARIMA(3,0,2) with non-zero mean : -11617.89\n",
      " ARIMA(3,0,1) with non-zero mean : -11557.32\n",
      " ARIMA(4,0,2) with non-zero mean : -11568.4\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11562.84\n",
      " ARIMA(4,0,1) with non-zero mean : -11564.69\n",
      " ARIMA(4,0,3) with non-zero mean : -11630.55\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11636.38\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : -11589.82\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : -11638.05\n",
      " ARIMA(3,0,4) with zero mean     : -11633.51\n",
      " ARIMA(4,0,3) with zero mean     : -11632.3\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,5) with zero mean     : -11591.73\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,5) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,4) with zero mean     : -11590.88\n",
      "\n",
      " Best model: ARIMA(4,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11548.17\n",
      " ARIMA(0,0,0) with non-zero mean : -7106.547\n",
      " ARIMA(1,0,0) with non-zero mean : -11510.72\n",
      " ARIMA(0,0,1) with non-zero mean : -9069.574\n",
      " ARIMA(0,0,0) with zero mean     : -7102.552\n",
      " ARIMA(1,0,2) with non-zero mean : -11544.52\n",
      " ARIMA(2,0,1) with non-zero mean : -11542.44\n",
      " ARIMA(3,0,2) with non-zero mean : -11617.49\n",
      " ARIMA(3,0,1) with non-zero mean : -11553.85\n",
      " ARIMA(4,0,2) with non-zero mean : -11565.16\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11559.85\n",
      " ARIMA(4,0,1) with non-zero mean : -11561.4\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11619.37\n",
      " ARIMA(2,0,2) with zero mean     : -11550.07\n",
      " ARIMA(3,0,1) with zero mean     : -11555.75\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -11544.33\n",
      " ARIMA(2,0,3) with zero mean     : -11561.72\n",
      " ARIMA(4,0,1) with zero mean     : -11563.27\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11619.52\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11546.07\n",
      " ARIMA(0,0,0) with non-zero mean : -7112.958\n",
      " ARIMA(1,0,0) with non-zero mean : -11508.98\n",
      " ARIMA(0,0,1) with non-zero mean : -9075.459\n",
      " ARIMA(0,0,0) with zero mean     : -7109.358\n",
      " ARIMA(1,0,2) with non-zero mean : -11542.43\n",
      " ARIMA(2,0,1) with non-zero mean : -11540.32\n",
      " ARIMA(3,0,2) with non-zero mean : -11617.21\n",
      " ARIMA(3,0,1) with non-zero mean : -11551.7\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11557.75\n",
      " ARIMA(4,0,1) with non-zero mean : -11559.25\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11618.96\n",
      " ARIMA(2,0,2) with zero mean     : -11547.9\n",
      " ARIMA(3,0,1) with zero mean     : -11553.51\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -11542.14\n",
      " ARIMA(2,0,3) with zero mean     : -11559.55\n",
      " ARIMA(4,0,1) with zero mean     : -11561.06\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11619.15\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11546.69\n",
      " ARIMA(0,0,0) with non-zero mean : -7110.009\n",
      " ARIMA(1,0,0) with non-zero mean : -11509.7\n",
      " ARIMA(0,0,1) with non-zero mean : -9073.832\n",
      " ARIMA(0,0,0) with zero mean     : -7105.975\n",
      " ARIMA(1,0,2) with non-zero mean : -11542.96\n",
      " ARIMA(2,0,1) with non-zero mean : -11540.83\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11558.31\n",
      " ARIMA(1,0,3) with non-zero mean : -11560.89\n",
      " ARIMA(0,0,3) with non-zero mean : -10457.85\n",
      " ARIMA(1,0,4) with non-zero mean : -11559.83\n",
      " ARIMA(0,0,2) with non-zero mean : -9950.234\n",
      " ARIMA(0,0,4) with non-zero mean : -10869.46\n",
      " ARIMA(2,0,4) with non-zero mean : -11584.44\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11592.16\n",
      " ARIMA(1,0,5) with non-zero mean : -11564.19\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with zero mean     : -11594.02\n",
      " ARIMA(1,0,5) with zero mean     : -11566.03\n",
      " ARIMA(2,0,4) with zero mean     : -11586.28\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(1,0,4) with zero mean     : -11561.65\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,5) with zero mean     : -11593.87\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11547.96\n",
      " ARIMA(0,0,0) with non-zero mean : -7112.272\n",
      " ARIMA(1,0,0) with non-zero mean : -11510.05\n",
      " ARIMA(0,0,1) with non-zero mean : -9074.982\n",
      " ARIMA(0,0,0) with zero mean     : -7106.199\n",
      " ARIMA(1,0,2) with non-zero mean : -11544.13\n",
      " ARIMA(2,0,1) with non-zero mean : -11542.04\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11559.77\n",
      " ARIMA(1,0,3) with non-zero mean : -11562.34\n",
      " ARIMA(0,0,3) with non-zero mean : -10457.36\n",
      " ARIMA(1,0,4) with non-zero mean : -11561.29\n",
      " ARIMA(0,0,2) with non-zero mean : -9949.54\n",
      " ARIMA(0,0,4) with non-zero mean : -10868.67\n",
      " ARIMA(2,0,4) with non-zero mean : -11586.17\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11593.93\n",
      " ARIMA(1,0,5) with non-zero mean : -11565.7\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with zero mean     : -11595.61\n",
      " ARIMA(1,0,5) with zero mean     : -11567.42\n",
      " ARIMA(2,0,4) with zero mean     : -11587.81\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(1,0,4) with zero mean     : -11562.99\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,5) with zero mean     : -11595.61\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11551.98\n",
      " ARIMA(0,0,0) with non-zero mean : -7114.245\n",
      " ARIMA(1,0,0) with non-zero mean : -11513.27\n",
      " ARIMA(0,0,1) with non-zero mean : -9076.409\n",
      " ARIMA(0,0,0) with zero mean     : -7108.062\n",
      " ARIMA(1,0,2) with non-zero mean : -11548.07\n",
      " ARIMA(2,0,1) with non-zero mean : -11545.97\n",
      " ARIMA(3,0,2) with non-zero mean : -11621.92\n",
      " ARIMA(3,0,1) with non-zero mean : -11557.83\n",
      " ARIMA(4,0,2) with non-zero mean : -11569.14\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11563.49\n",
      " ARIMA(4,0,1) with non-zero mean : -11565.27\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : -11623.02\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11549.82\n",
      " ARIMA(0,0,0) with non-zero mean : -7108.307\n",
      " ARIMA(1,0,0) with non-zero mean : -11511.15\n",
      " ARIMA(0,0,1) with non-zero mean : -9070.413\n",
      " ARIMA(0,0,0) with zero mean     : -7098.131\n",
      " ARIMA(1,0,2) with non-zero mean : -11546.06\n",
      " ARIMA(2,0,1) with non-zero mean : -11543.98\n",
      " ARIMA(3,0,2) with non-zero mean : -11620.06\n",
      " ARIMA(3,0,1) with non-zero mean : -11555.65\n",
      " ARIMA(4,0,2) with non-zero mean : -11567.5\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11561.41\n",
      " ARIMA(4,0,1) with non-zero mean : -11563.26\n",
      " ARIMA(4,0,3) with non-zero mean : -11630.88\n",
      " ARIMA(5,0,3) with non-zero mean : -11623.84\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11631.65\n",
      " ARIMA(5,0,1) with non-zero mean : -11590.51\n",
      " ARIMA(5,0,2) with zero mean     : -11633.39\n",
      " ARIMA(4,0,2) with zero mean     : -11569.12\n",
      " ARIMA(5,0,1) with zero mean     : -11592.07\n",
      " ARIMA(5,0,3) with zero mean     : -11636.77\n",
      " ARIMA(4,0,3) with zero mean     : -11632.71\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with zero mean     : -11591.97\n",
      "\n",
      " Best model: ARIMA(5,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11546.59\n",
      " ARIMA(0,0,0) with non-zero mean : -7108.494\n",
      " ARIMA(1,0,0) with non-zero mean : -11507.88\n",
      " ARIMA(0,0,1) with non-zero mean : -9068.035\n",
      " ARIMA(0,0,0) with zero mean     : -7100.783\n",
      " ARIMA(1,0,2) with non-zero mean : -11542.94\n",
      " ARIMA(2,0,1) with non-zero mean : -11541.28\n",
      " ARIMA(3,0,2) with non-zero mean : -11614.15\n",
      " ARIMA(3,0,1) with non-zero mean : -11552.61\n",
      " ARIMA(4,0,2) with non-zero mean : -11630.6\n",
      " ARIMA(4,0,1) with non-zero mean : -11560.2\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,1) with non-zero mean : -11587.56\n",
      " ARIMA(5,0,3) with non-zero mean : -11634.25\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : -11635.68\n",
      "\n",
      " Best model: ARIMA(5,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11543.12\n",
      " ARIMA(0,0,0) with non-zero mean : -7104.029\n",
      " ARIMA(1,0,0) with non-zero mean : -11504.2\n",
      " ARIMA(0,0,1) with non-zero mean : -9062.16\n",
      " ARIMA(0,0,0) with zero mean     : -7093.004\n",
      " ARIMA(1,0,2) with non-zero mean : -11538.94\n",
      " ARIMA(2,0,1) with non-zero mean : -11537.27\n",
      " ARIMA(3,0,2) with non-zero mean : -11611.29\n",
      " ARIMA(3,0,1) with non-zero mean : -11548.77\n",
      " ARIMA(4,0,2) with non-zero mean : -11560.94\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11554.65\n",
      " ARIMA(4,0,1) with non-zero mean : -11556.15\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11612.56\n",
      " ARIMA(2,0,2) with zero mean     : -11544.66\n",
      " ARIMA(3,0,1) with zero mean     : -11550.31\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -11538.8\n",
      " ARIMA(2,0,3) with zero mean     : -11556.13\n",
      " ARIMA(4,0,1) with zero mean     : -11557.64\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11614.8\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11541.63\n",
      " ARIMA(0,0,0) with non-zero mean : -7104.001\n",
      " ARIMA(1,0,0) with non-zero mean : -11503.56\n",
      " ARIMA(0,0,1) with non-zero mean : -9064.192\n",
      " ARIMA(0,0,0) with zero mean     : -7092.129\n",
      " ARIMA(1,0,2) with non-zero mean : -11538.1\n",
      " ARIMA(2,0,1) with non-zero mean : -11536.04\n",
      " ARIMA(3,0,2) with non-zero mean : -11611.74\n",
      " ARIMA(3,0,1) with non-zero mean : -11547.4\n",
      " ARIMA(4,0,2) with non-zero mean : -11558.95\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11553.51\n",
      " ARIMA(4,0,1) with non-zero mean : -11555.88\n",
      " ARIMA(4,0,3) with non-zero mean : -11629.28\n",
      " ARIMA(5,0,3) with non-zero mean : -11628.64\n",
      " ARIMA(4,0,4) with non-zero mean : -11616.24\n",
      " ARIMA(3,0,4) with non-zero mean : -11583.02\n",
      " ARIMA(5,0,2) with non-zero mean : -11610.32\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11619.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with non-zero mean : -11580.32\n",
      "\n",
      " Best model: ARIMA(4,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11542.31\n",
      " ARIMA(0,0,0) with non-zero mean : -7104.746\n",
      " ARIMA(1,0,0) with non-zero mean : -11503.98\n",
      " ARIMA(0,0,1) with non-zero mean : -9064.626\n",
      " ARIMA(0,0,0) with zero mean     : -7093.767\n",
      " ARIMA(1,0,2) with non-zero mean : -11538.59\n",
      " ARIMA(2,0,1) with non-zero mean : -11536.52\n",
      " ARIMA(3,0,2) with non-zero mean : -11610.53\n",
      " ARIMA(3,0,1) with non-zero mean : -11548.59\n",
      " ARIMA(4,0,2) with non-zero mean : -11560.71\n",
      " ARIMA(3,0,3) with non-zero mean : -11625.57\n",
      " ARIMA(2,0,3) with non-zero mean : -11554\n",
      " ARIMA(4,0,3) with non-zero mean : -11622.92\n",
      " ARIMA(3,0,4) with non-zero mean : -11580.38\n",
      " ARIMA(2,0,4) with non-zero mean : -11581.82\n",
      " ARIMA(4,0,4) with non-zero mean : -11621.31\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -11627.63\n",
      "\n",
      " Best model: ARIMA(4,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11539.47\n",
      " ARIMA(0,0,0) with non-zero mean : -7102.276\n",
      " ARIMA(1,0,0) with non-zero mean : -11501.5\n",
      " ARIMA(0,0,1) with non-zero mean : -9062.581\n",
      " ARIMA(0,0,0) with zero mean     : -7090.135\n",
      " ARIMA(1,0,2) with non-zero mean : -11535.92\n",
      " ARIMA(2,0,1) with non-zero mean : -11533.8\n",
      " ARIMA(3,0,2) with non-zero mean : -11606.73\n",
      " ARIMA(3,0,1) with non-zero mean : -11545.4\n",
      " ARIMA(4,0,2) with non-zero mean : -11558.05\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11551.07\n",
      " ARIMA(4,0,1) with non-zero mean : -11553.3\n",
      " ARIMA(4,0,3) with non-zero mean : -11619.69\n",
      " ARIMA(5,0,3) with non-zero mean : -11619.9\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11625.96\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : -11583\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : -11627.36\n",
      " ARIMA(3,0,4) with zero mean     : -11622.97\n",
      " ARIMA(4,0,3) with zero mean     : -11621.42\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,5) with zero mean     : -11584.58\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -11621.32\n",
      " ARIMA(5,0,5) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -11626.69\n",
      "\n",
      " Best model: ARIMA(3,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11543\n",
      " ARIMA(0,0,0) with non-zero mean : -7109.443\n",
      " ARIMA(1,0,0) with non-zero mean : -11504.54\n",
      " ARIMA(0,0,1) with non-zero mean : -9066.509\n",
      " ARIMA(0,0,0) with zero mean     : -7097.631\n",
      " ARIMA(1,0,2) with non-zero mean : -11539.42\n",
      " ARIMA(2,0,1) with non-zero mean : -11537.33\n",
      " ARIMA(3,0,2) with non-zero mean : -11607.85\n",
      " ARIMA(3,0,1) with non-zero mean : -11549.09\n",
      " ARIMA(4,0,2) with non-zero mean : -11561.32\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11554.41\n",
      " ARIMA(4,0,1) with non-zero mean : -11556.82\n",
      " ARIMA(4,0,3) with non-zero mean : -11619.75\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11627.91\n",
      " ARIMA(3,0,4) with non-zero mean : -11576.49\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : -11586.89\n",
      " ARIMA(3,0,5) with non-zero mean : -11634.43\n",
      " ARIMA(2,0,5) with non-zero mean : -11590.8\n",
      " ARIMA(2,0,4) with non-zero mean : -11582.07\n",
      " ARIMA(3,0,5) with zero mean     : -11635\n",
      " ARIMA(2,0,5) with zero mean     : -11592.46\n",
      " ARIMA(3,0,4) with zero mean     : -11624.41\n",
      " ARIMA(4,0,5) with zero mean     : -11588.56\n",
      " ARIMA(2,0,4) with zero mean     : -11583.67\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -11629.23\n",
      "\n",
      " Best model: ARIMA(3,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11489.56\n",
      " ARIMA(0,1,0) with drift         : -11407.73\n",
      " ARIMA(1,1,0) with drift         : -11459.08\n",
      " ARIMA(0,1,1) with drift         : -11469.07\n",
      " ARIMA(0,1,0)                    : -11409.73\n",
      " ARIMA(1,1,2) with drift         : -11476.07\n",
      " ARIMA(2,1,1) with drift         : -11481.59\n",
      " ARIMA(3,1,2) with drift         : -11545.27\n",
      " ARIMA(3,1,1) with drift         : -11482.08\n",
      " ARIMA(4,1,2) with drift         : -11551.58\n",
      " ARIMA(4,1,1) with drift         : -11484.96\n",
      " ARIMA(5,1,2) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11548.26\n",
      " ARIMA(5,1,1) with drift         : -11492.25\n",
      " ARIMA(5,1,3) with drift         : -11514.51\n",
      " ARIMA(4,1,2)                    : -11553.38\n",
      " ARIMA(3,1,2)                    : -11547.18\n",
      " ARIMA(4,1,1)                    : -11486.97\n",
      " ARIMA(5,1,2)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(3,1,1)                    : -11484.09\n",
      " ARIMA(3,1,3)                    : -11550.27\n",
      " ARIMA(5,1,1)                    : -11494.27\n",
      " ARIMA(5,1,3)                    : -11516.53\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11568.56\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11488.51\n",
      " ARIMA(0,1,0) with drift         : -11406.48\n",
      " ARIMA(1,1,0) with drift         : -11458.08\n",
      " ARIMA(0,1,1) with drift         : -11467.77\n",
      " ARIMA(0,1,0)                    : -11408.49\n",
      " ARIMA(1,1,2) with drift         : -11474.57\n",
      " ARIMA(2,1,1) with drift         : -11479.9\n",
      " ARIMA(3,1,2) with drift         : -11548.76\n",
      " ARIMA(3,1,1) with drift         : -11480.84\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11550.62\n",
      " ARIMA(2,1,3) with drift         : -11554.97\n",
      " ARIMA(1,1,3) with drift         : -11477.58\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11486.33\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11556.97\n",
      " ARIMA(1,1,3)                    : -11479.59\n",
      " ARIMA(2,1,2)                    : -11490.52\n",
      " ARIMA(3,1,3)                    : -11552.63\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11476.58\n",
      " ARIMA(1,1,4)                    : -11488.34\n",
      " ARIMA(3,1,2)                    : -11550.73\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11567.3\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11539.15\n",
      " ARIMA(0,0,0) with non-zero mean : -7107.673\n",
      " ARIMA(1,0,0) with non-zero mean : -11500.94\n",
      " ARIMA(0,0,1) with non-zero mean : -9065.001\n",
      " ARIMA(0,0,0) with zero mean     : -7096.296\n",
      " ARIMA(1,0,2) with non-zero mean : -11535.64\n",
      " ARIMA(2,0,1) with non-zero mean : -11533.93\n",
      " ARIMA(3,0,2) with non-zero mean : -11608.97\n",
      " ARIMA(3,0,1) with non-zero mean : -11545.34\n",
      " ARIMA(4,0,2) with non-zero mean : -11558.35\n",
      " ARIMA(3,0,3) with non-zero mean : -11559.27\n",
      " ARIMA(2,0,3) with non-zero mean : -11551.85\n",
      " ARIMA(4,0,1) with non-zero mean : -11553.66\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11610.6\n",
      " ARIMA(2,0,2) with zero mean     : -11540.78\n",
      " ARIMA(3,0,1) with zero mean     : -11546.94\n",
      " ARIMA(4,0,2) with zero mean     : -11559.91\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -11535.53\n",
      " ARIMA(2,0,3) with zero mean     : -11553.4\n",
      " ARIMA(4,0,1) with zero mean     : -11555.22\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11611.22\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11484.71\n",
      " ARIMA(0,1,0) with drift         : -11402.92\n",
      " ARIMA(1,1,0) with drift         : -11453.72\n",
      " ARIMA(0,1,1) with drift         : -11463.3\n",
      " ARIMA(0,1,0)                    : -11404.93\n",
      " ARIMA(1,1,2) with drift         : -11470.24\n",
      " ARIMA(2,1,1) with drift         : -11475.7\n",
      " ARIMA(3,1,2) with drift         : -11537.52\n",
      " ARIMA(3,1,1) with drift         : -11476.24\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11479.22\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2) with drift         : -11549.01\n",
      "\n",
      " Best model: ARIMA(3,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11541.88\n",
      " ARIMA(0,0,0) with non-zero mean : -7110.457\n",
      " ARIMA(1,0,0) with non-zero mean : -11504.25\n",
      " ARIMA(0,0,1) with non-zero mean : -9071.053\n",
      " ARIMA(0,0,0) with zero mean     : -7095.669\n",
      " ARIMA(1,0,2) with non-zero mean : -11537.67\n",
      " ARIMA(2,0,1) with non-zero mean : -11535.9\n",
      " ARIMA(3,0,2) with non-zero mean : -11610.43\n",
      " ARIMA(3,0,1) with non-zero mean : -11547.99\n",
      " ARIMA(4,0,2) with non-zero mean : -11561.34\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11554.77\n",
      " ARIMA(4,0,1) with non-zero mean : -11556.7\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11611.69\n",
      " ARIMA(2,0,2) with zero mean     : -11543.41\n",
      " ARIMA(3,0,1) with zero mean     : -11549.52\n",
      " ARIMA(4,0,2) with zero mean     : -11562.84\n",
      " ARIMA(3,0,3) with zero mean     : -11563.17\n",
      " ARIMA(2,0,1) with zero mean     : -11537.42\n",
      " ARIMA(2,0,3) with zero mean     : -11556.22\n",
      " ARIMA(4,0,1) with zero mean     : -11558.16\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11614.18\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11489.65\n",
      " ARIMA(0,1,0) with drift         : -11408.33\n",
      " ARIMA(1,1,0) with drift         : -11457.28\n",
      " ARIMA(0,1,1) with drift         : -11467.04\n",
      " ARIMA(0,1,0)                    : -11410.33\n",
      " ARIMA(1,1,2) with drift         : -11474.81\n",
      " ARIMA(2,1,1) with drift         : -11480.57\n",
      " ARIMA(3,1,2) with drift         : -11549.16\n",
      " ARIMA(3,1,1) with drift         : -11481.79\n",
      " ARIMA(4,1,2) with drift         : -11541.63\n",
      " ARIMA(3,1,3) with drift         : -11548.71\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11551.15\n",
      " ARIMA(2,1,2)                    : -11491.66\n",
      " ARIMA(3,1,1)                    : -11483.8\n",
      " ARIMA(4,1,2)                    : -11543.55\n",
      " ARIMA(3,1,3)                    : -11550.71\n",
      " ARIMA(2,1,1)                    : -11482.57\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11566.72\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11491.43\n",
      " ARIMA(0,1,0) with drift         : -11409.56\n",
      " ARIMA(1,1,0) with drift         : -11458.85\n",
      " ARIMA(0,1,1) with drift         : -11467.94\n",
      " ARIMA(0,1,0)                    : -11411.56\n",
      " ARIMA(1,1,2) with drift         : -11476.06\n",
      " ARIMA(2,1,1) with drift         : -11481.97\n",
      " ARIMA(3,1,2) with drift         : -11552.28\n",
      " ARIMA(3,1,1) with drift         : -11482.84\n",
      " ARIMA(4,1,2) with drift         : -11551.35\n",
      " ARIMA(3,1,3) with drift         : -11551.43\n",
      " ARIMA(2,1,3) with drift         : -11554.61\n",
      " ARIMA(1,1,3) with drift         : -11479.29\n",
      " ARIMA(2,1,4) with drift         : -11548.45\n",
      " ARIMA(1,1,4) with drift         : -11487.19\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11556.62\n",
      " ARIMA(1,1,3)                    : -11481.3\n",
      " ARIMA(2,1,2)                    : -11493.44\n",
      " ARIMA(3,1,3)                    : -11553.42\n",
      " ARIMA(2,1,4)                    : -11550.41\n",
      " ARIMA(1,1,2)                    : -11478.06\n",
      " ARIMA(1,1,4)                    : -11489.19\n",
      " ARIMA(3,1,2)                    : -11554.25\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : -11567.05\n",
      "\n",
      " Best model: ARIMA(2,1,3) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11488.75\n",
      " ARIMA(0,1,0) with drift         : -11408.4\n",
      " ARIMA(1,1,0) with drift         : -11457.15\n",
      " ARIMA(0,1,1) with drift         : -11466.65\n",
      " ARIMA(0,1,0)                    : -11410.4\n",
      " ARIMA(1,1,2) with drift         : -11474.23\n",
      " ARIMA(2,1,1) with drift         : -11479.83\n",
      " ARIMA(3,1,2) with drift         : -11552.95\n",
      " ARIMA(3,1,1) with drift         : -11480.15\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11553.93\n",
      " ARIMA(1,1,3) with drift         : -11477.19\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11485.58\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11555.94\n",
      " ARIMA(1,1,3)                    : -11479.19\n",
      " ARIMA(2,1,2)                    : -11490.76\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11476.23\n",
      " ARIMA(1,1,4)                    : -11487.59\n",
      " ARIMA(3,1,2)                    : -11554.95\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11566.29\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11487.92\n",
      " ARIMA(0,1,0) with drift         : -11407.66\n",
      " ARIMA(1,1,0) with drift         : -11456.44\n",
      " ARIMA(0,1,1) with drift         : -11466.09\n",
      " ARIMA(0,1,0)                    : -11409.66\n",
      " ARIMA(1,1,2) with drift         : -11473.69\n",
      " ARIMA(2,1,1) with drift         : -11479.01\n",
      " ARIMA(3,1,2) with drift         : -11553.48\n",
      " ARIMA(3,1,1) with drift         : -11479.31\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11482.74\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11555.47\n",
      " ARIMA(2,1,2)                    : -11489.93\n",
      " ARIMA(3,1,1)                    : -11481.31\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11481.01\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11565.76\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11488.54\n",
      " ARIMA(0,1,0) with drift         : -11407.27\n",
      " ARIMA(1,1,0) with drift         : -11456.51\n",
      " ARIMA(0,1,1) with drift         : -11465.84\n",
      " ARIMA(0,1,0)                    : -11409.28\n",
      " ARIMA(1,1,2) with drift         : -11473.84\n",
      " ARIMA(2,1,1) with drift         : -11479.38\n",
      " ARIMA(3,1,2) with drift         : -11550.57\n",
      " ARIMA(3,1,1) with drift         : -11479.9\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11549.41\n",
      " ARIMA(2,1,3) with drift         : -11551.1\n",
      " ARIMA(1,1,3) with drift         : -11476.99\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11484.53\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11553.11\n",
      " ARIMA(1,1,3)                    : -11478.99\n",
      " ARIMA(2,1,2)                    : -11490.55\n",
      " ARIMA(3,1,3)                    : -11551.39\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11475.85\n",
      " ARIMA(1,1,4)                    : -11486.54\n",
      " ARIMA(3,1,2)                    : -11552.52\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11565.82\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11483.48\n",
      " ARIMA(0,1,0) with drift         : -11402.7\n",
      " ARIMA(1,1,0) with drift         : -11451.73\n",
      " ARIMA(0,1,1) with drift         : -11461.1\n",
      " ARIMA(0,1,0)                    : -11404.7\n",
      " ARIMA(1,1,2) with drift         : -11468.25\n",
      " ARIMA(2,1,1) with drift         : -11474.04\n",
      " ARIMA(3,1,2) with drift         : -11536.83\n",
      " ARIMA(3,1,1) with drift         : -11474.56\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11549\n",
      " ARIMA(1,1,3) with drift         : -11471.67\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11480.23\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11550.98\n",
      " ARIMA(1,1,3)                    : -11473.67\n",
      " ARIMA(2,1,2)                    : -11485.48\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11470.26\n",
      " ARIMA(1,1,4)                    : -11482.24\n",
      " ARIMA(3,1,2)                    : -11548.92\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11561.42\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11482.57\n",
      " ARIMA(0,1,0) with drift         : -11400.37\n",
      " ARIMA(1,1,0) with drift         : -11450.16\n",
      " ARIMA(0,1,1) with drift         : -11458.84\n",
      " ARIMA(0,1,0)                    : -11402.37\n",
      " ARIMA(1,1,2) with drift         : -11465.69\n",
      " ARIMA(2,1,1) with drift         : -11472.97\n",
      " ARIMA(3,1,2) with drift         : -11540.16\n",
      " ARIMA(3,1,1) with drift         : -11473.79\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11539.88\n",
      " ARIMA(2,1,3) with drift         : -11537.05\n",
      " ARIMA(4,1,1) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11542.16\n",
      " ARIMA(2,1,2)                    : -11484.58\n",
      " ARIMA(3,1,1)                    : -11475.8\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11541.9\n",
      " ARIMA(2,1,1)                    : -11474.98\n",
      " ARIMA(2,1,3)                    : -11538.99\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11558.63\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11479.35\n",
      " ARIMA(0,1,0) with drift         : -11399.67\n",
      " ARIMA(1,1,0) with drift         : -11448.3\n",
      " ARIMA(0,1,1) with drift         : -11457.52\n",
      " ARIMA(0,1,0)                    : -11401.67\n",
      " ARIMA(1,1,2) with drift         : -11464.19\n",
      " ARIMA(2,1,1) with drift         : -11469.55\n",
      " ARIMA(3,1,2) with drift         : -11543.91\n",
      " ARIMA(3,1,1) with drift         : -11470.27\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11545.94\n",
      " ARIMA(2,1,2)                    : -11481.36\n",
      " ARIMA(3,1,1)                    : -11472.28\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11471.56\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11557.18\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11470.5\n",
      " ARIMA(0,1,0) with drift         : -11391.25\n",
      " ARIMA(1,1,0) with drift         : -11440.04\n",
      " ARIMA(0,1,1) with drift         : -11449.27\n",
      " ARIMA(0,1,0)                    : -11393.26\n",
      " ARIMA(1,1,2) with drift         : -11455.74\n",
      " ARIMA(2,1,1) with drift         : -11461.2\n",
      " ARIMA(3,1,2) with drift         : -11525.03\n",
      " ARIMA(3,1,1) with drift         : -11462.98\n",
      " ARIMA(4,1,2) with drift         : -11520.54\n",
      " ARIMA(3,1,3) with drift         : -11524.95\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11466.16\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11526.97\n",
      " ARIMA(2,1,2)                    : -11472.51\n",
      " ARIMA(3,1,1)                    : -11464.99\n",
      " ARIMA(4,1,2)                    : -11522.35\n",
      " ARIMA(3,1,3)                    : -11526.95\n",
      " ARIMA(2,1,1)                    : -11463.21\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : -11468.17\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11548.01\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11465.7\n",
      " ARIMA(0,1,0) with drift         : -11387.82\n",
      " ARIMA(1,1,0) with drift         : -11435.95\n",
      " ARIMA(0,1,1) with drift         : -11445.09\n",
      " ARIMA(0,1,0)                    : -11389.82\n",
      " ARIMA(1,1,2) with drift         : -11451.65\n",
      " ARIMA(2,1,1) with drift         : -11456.63\n",
      " ARIMA(3,1,2) with drift         : -11531.51\n",
      " ARIMA(3,1,1) with drift         : -11456.91\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11459.7\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11533.52\n",
      " ARIMA(2,1,2)                    : -11467.71\n",
      " ARIMA(3,1,1)                    : -11458.92\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11458.63\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11543.83\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11463.12\n",
      " ARIMA(0,1,0) with drift         : -11386.02\n",
      " ARIMA(1,1,0) with drift         : -11433.6\n",
      " ARIMA(0,1,1) with drift         : -11442.58\n",
      " ARIMA(0,1,0)                    : -11388.03\n",
      " ARIMA(1,1,2) with drift         : -11448.94\n",
      " ARIMA(2,1,1) with drift         : -11453.81\n",
      " ARIMA(3,1,2) with drift         : -11525.39\n",
      " ARIMA(3,1,1) with drift         : -11454.66\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11524.52\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11457.02\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11527.4\n",
      " ARIMA(2,1,2)                    : -11465.13\n",
      " ARIMA(3,1,1)                    : -11456.67\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11526.53\n",
      " ARIMA(2,1,1)                    : -11455.82\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : -11459.03\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11541.25\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11458.77\n",
      " ARIMA(0,1,0) with drift         : -11381.36\n",
      " ARIMA(1,1,0) with drift         : -11429.64\n",
      " ARIMA(0,1,1) with drift         : -11438.35\n",
      " ARIMA(0,1,0)                    : -11383.36\n",
      " ARIMA(1,1,2) with drift         : -11444.64\n",
      " ARIMA(2,1,1) with drift         : -11449.51\n",
      " ARIMA(3,1,2) with drift         : -11523.98\n",
      " ARIMA(3,1,1) with drift         : -11449.86\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11522.53\n",
      " ARIMA(2,1,3) with drift         : -11515.81\n",
      " ARIMA(4,1,1) with drift         : -11452.53\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11525.99\n",
      " ARIMA(2,1,2)                    : -11460.78\n",
      " ARIMA(3,1,1)                    : -11451.87\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11524.55\n",
      " ARIMA(2,1,1)                    : -11451.52\n",
      " ARIMA(2,1,3)                    : -11526.75\n",
      " ARIMA(1,1,3)                    : -11449.44\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11446.65\n",
      " ARIMA(1,1,4)                    : -11457.35\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : -11537.12\n",
      "\n",
      " Best model: ARIMA(2,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11461.71\n",
      " ARIMA(0,1,0) with drift         : -11383.29\n",
      " ARIMA(1,1,0) with drift         : -11431.95\n",
      " ARIMA(0,1,1) with drift         : -11440.93\n",
      " ARIMA(0,1,0)                    : -11385.29\n",
      " ARIMA(1,1,2) with drift         : -11446.83\n",
      " ARIMA(2,1,1) with drift         : -11452.16\n",
      " ARIMA(3,1,2) with drift         : -11524.45\n",
      " ARIMA(3,1,1) with drift         : -11453.21\n",
      " ARIMA(4,1,2) with drift         : -11516.21\n",
      " ARIMA(3,1,3) with drift         : -11523.63\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11456.45\n",
      " ARIMA(4,1,3) with drift         : -11557.15\n",
      " ARIMA(5,1,3) with drift         : -11485.61\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(5,1,2) with drift         : Inf\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(4,1,3)                    : -11558.96\n",
      " ARIMA(3,1,3)                    : -11525.63\n",
      " ARIMA(4,1,2)                    : -11518.15\n",
      " ARIMA(5,1,3)                    : -11487.74\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11526.44\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(5,1,2)                    : Inf\n",
      " ARIMA(5,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11539.94\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11464.63\n",
      " ARIMA(0,1,0) with drift         : -11385.89\n",
      " ARIMA(1,1,0) with drift         : -11435.55\n",
      " ARIMA(0,1,1) with drift         : -11444.16\n",
      " ARIMA(0,1,0)                    : -11387.89\n",
      " ARIMA(1,1,2) with drift         : -11450.41\n",
      " ARIMA(2,1,1) with drift         : -11455.3\n",
      " ARIMA(3,1,2) with drift         : -11527.35\n",
      " ARIMA(3,1,1) with drift         : -11455.78\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11529.4\n",
      " ARIMA(1,1,3) with drift         : -11453.12\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11460.64\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11531.41\n",
      " ARIMA(1,1,3)                    : -11455.13\n",
      " ARIMA(2,1,2)                    : -11466.63\n",
      " ARIMA(3,1,3)                    : -11528.15\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11452.43\n",
      " ARIMA(1,1,4)                    : -11462.65\n",
      " ARIMA(3,1,2)                    : -11529.33\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : -11541.1\n",
      "\n",
      " Best model: ARIMA(2,1,3) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11467.17\n",
      " ARIMA(0,1,0) with drift         : -11390.13\n",
      " ARIMA(1,1,0) with drift         : -11438.99\n",
      " ARIMA(0,1,1) with drift         : -11447.86\n",
      " ARIMA(0,1,0)                    : -11392.14\n",
      " ARIMA(1,1,2) with drift         : -11453.3\n",
      " ARIMA(2,1,1) with drift         : -11458.1\n",
      " ARIMA(3,1,2) with drift         : -11528.67\n",
      " ARIMA(3,1,1) with drift         : -11458.43\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11527.28\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11461.22\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11530.68\n",
      " ARIMA(2,1,2)                    : -11469.17\n",
      " ARIMA(3,1,1)                    : -11460.44\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11529.3\n",
      " ARIMA(2,1,1)                    : -11460.11\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : -11463.24\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11544.53\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11457.26\n",
      " ARIMA(0,1,0) with drift         : -11383.29\n",
      " ARIMA(1,1,0) with drift         : -11430.38\n",
      " ARIMA(0,1,1) with drift         : -11438.84\n",
      " ARIMA(0,1,0)                    : -11385.28\n",
      " ARIMA(1,1,2) with drift         : -11444.28\n",
      " ARIMA(2,1,1) with drift         : -11448.59\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11522.67\n",
      " ARIMA(1,1,3) with drift         : -11446.31\n",
      " ARIMA(3,1,3) with drift         : -11520.59\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11454.56\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11524.67\n",
      " ARIMA(1,1,3)                    : -11448.3\n",
      " ARIMA(2,1,2)                    : -11459.25\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11446.27\n",
      " ARIMA(1,1,4)                    : -11456.53\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : -11535.62\n",
      "\n",
      " Best model: ARIMA(2,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11426.76\n",
      " ARIMA(0,1,0) with drift         : -11358.01\n",
      " ARIMA(1,1,0) with drift         : -11402.29\n",
      " ARIMA(0,1,1) with drift         : -11410.68\n",
      " ARIMA(0,1,0)                    : -11360.01\n",
      " ARIMA(1,1,2) with drift         : -11416.65\n",
      " ARIMA(2,1,1) with drift         : -11420.05\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11411.29\n",
      " ARIMA(1,1,3) with drift         : -11417.46\n",
      " ARIMA(3,1,1) with drift         : -11419.14\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11428.77\n",
      " ARIMA(1,1,2)                    : -11418.66\n",
      " ARIMA(2,1,1)                    : -11422.06\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(1,1,1)                    : -11413.29\n",
      " ARIMA(1,1,3)                    : -11419.46\n",
      " ARIMA(3,1,1)                    : -11421.15\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11438.63\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11419.96\n",
      " ARIMA(0,1,0) with drift         : -11350.92\n",
      " ARIMA(1,1,0) with drift         : -11394.9\n",
      " ARIMA(0,1,1) with drift         : -11403.11\n",
      " ARIMA(0,1,0)                    : -11352.92\n",
      " ARIMA(1,1,2) with drift         : -11408.89\n",
      " ARIMA(2,1,1) with drift         : -11412.58\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11403.44\n",
      " ARIMA(1,1,3) with drift         : -11410.03\n",
      " ARIMA(3,1,1) with drift         : -11411.93\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11421.97\n",
      " ARIMA(1,1,2)                    : -11410.89\n",
      " ARIMA(2,1,1)                    : -11414.58\n",
      " ARIMA(3,1,2)                    : -11484.89\n",
      " ARIMA(3,1,1)                    : -11413.93\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : -11417.69\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11497.38\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11416.52\n",
      " ARIMA(0,1,0) with drift         : -11347.64\n",
      " ARIMA(1,1,0) with drift         : -11391.62\n",
      " ARIMA(0,1,1) with drift         : -11399.55\n",
      " ARIMA(0,1,0)                    : -11349.64\n",
      " ARIMA(1,1,2) with drift         : -11405.39\n",
      " ARIMA(2,1,1) with drift         : -11409.03\n",
      " ARIMA(3,1,2) with drift         : -11479.96\n",
      " ARIMA(3,1,1) with drift         : -11408.41\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11481.73\n",
      " ARIMA(1,1,3) with drift         : -11406.63\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11414.79\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11483.74\n",
      " ARIMA(1,1,3)                    : -11408.63\n",
      " ARIMA(2,1,2)                    : -11418.53\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11407.41\n",
      " ARIMA(1,1,4)                    : -11416.8\n",
      " ARIMA(3,1,2)                    : -11481.98\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : -11494.17\n",
      "\n",
      " Best model: ARIMA(2,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11407.96\n",
      " ARIMA(0,1,0) with drift         : -11338.46\n",
      " ARIMA(1,1,0) with drift         : -11382.61\n",
      " ARIMA(0,1,1) with drift         : -11390.38\n",
      " ARIMA(0,1,0)                    : -11340.46\n",
      " ARIMA(1,1,2) with drift         : -11396.61\n",
      " ARIMA(2,1,1) with drift         : -11400.55\n",
      " ARIMA(3,1,2) with drift         : -11471.9\n",
      " ARIMA(3,1,1) with drift         : -11399.74\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11470.53\n",
      " ARIMA(4,1,1) with drift         : -11403.38\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11473.9\n",
      " ARIMA(2,1,2)                    : -11409.97\n",
      " ARIMA(3,1,1)                    : -11401.75\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11402.56\n",
      " ARIMA(2,1,3)                    : -11472.5\n",
      " ARIMA(4,1,1)                    : -11405.4\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11484.35\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11396.17\n",
      " ARIMA(0,1,0) with drift         : -11328.02\n",
      " ARIMA(1,1,0) with drift         : -11371.4\n",
      " ARIMA(0,1,1) with drift         : -11379.49\n",
      " ARIMA(0,1,0)                    : -11330.02\n",
      " ARIMA(1,1,2) with drift         : -11385.91\n",
      " ARIMA(2,1,1) with drift         : -11389.47\n",
      " ARIMA(3,1,2) with drift         : -11458.66\n",
      " ARIMA(3,1,1) with drift         : -11388.42\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11458.39\n",
      " ARIMA(4,1,1) with drift         : -11391.51\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11460.67\n",
      " ARIMA(2,1,2)                    : -11398.17\n",
      " ARIMA(3,1,1)                    : -11390.41\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11391.47\n",
      " ARIMA(2,1,3)                    : -11460.41\n",
      " ARIMA(4,1,1)                    : -11393.51\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11472.04\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11384.39\n",
      " ARIMA(0,1,0) with drift         : -11316.01\n",
      " ARIMA(1,1,0) with drift         : -11360.76\n",
      " ARIMA(0,1,1) with drift         : -11368.5\n",
      " ARIMA(0,1,0)                    : -11318.01\n",
      " ARIMA(1,1,2) with drift         : -11375.04\n",
      " ARIMA(2,1,1) with drift         : -11378.36\n",
      " ARIMA(3,1,2) with drift         : -11443.48\n",
      " ARIMA(3,1,1) with drift         : -11377.21\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11445.13\n",
      " ARIMA(2,1,3) with drift         : -11446.41\n",
      " ARIMA(1,1,3) with drift         : -11375.64\n",
      " ARIMA(2,1,4) with drift         : -11438.15\n",
      " ARIMA(1,1,4) with drift         : -11381.98\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11440.96\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3) with drift         : -11458.24\n",
      "\n",
      " Best model: ARIMA(2,1,3) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11382.84\n",
      " ARIMA(0,1,0) with drift         : -11314.2\n",
      " ARIMA(1,1,0) with drift         : -11359.08\n",
      " ARIMA(0,1,1) with drift         : -11366.52\n",
      " ARIMA(0,1,0)                    : -11316.21\n",
      " ARIMA(1,1,2) with drift         : -11373.79\n",
      " ARIMA(2,1,1) with drift         : -11377.02\n",
      " ARIMA(3,1,2) with drift         : -11443.18\n",
      " ARIMA(3,1,1) with drift         : -11375.83\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11441.2\n",
      " ARIMA(2,1,3) with drift         : -11440.68\n",
      " ARIMA(4,1,1) with drift         : -11378.62\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11445.18\n",
      " ARIMA(2,1,2)                    : -11384.85\n",
      " ARIMA(3,1,1)                    : -11377.84\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11443.21\n",
      " ARIMA(2,1,1)                    : -11379.03\n",
      " ARIMA(2,1,3)                    : -11442.69\n",
      " ARIMA(4,1,1)                    : -11380.64\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11457.01\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11385.06\n",
      " ARIMA(0,1,0) with drift         : -11317.34\n",
      " ARIMA(1,1,0) with drift         : -11361\n",
      " ARIMA(0,1,1) with drift         : -11369.29\n",
      " ARIMA(0,1,0)                    : -11319.34\n",
      " ARIMA(1,1,2) with drift         : -11375.57\n",
      " ARIMA(2,1,1) with drift         : -11378.89\n",
      " ARIMA(3,1,2) with drift         : -11447.76\n",
      " ARIMA(3,1,1) with drift         : -11377.8\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11380.61\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11449.77\n",
      " ARIMA(2,1,2)                    : -11387.06\n",
      " ARIMA(3,1,1)                    : -11379.81\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11380.9\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : -11382.62\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11460.04\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11381.42\n",
      " ARIMA(0,1,0) with drift         : -11314.33\n",
      " ARIMA(1,1,0) with drift         : -11358.1\n",
      " ARIMA(0,1,1) with drift         : -11366.38\n",
      " ARIMA(0,1,0)                    : -11316.34\n",
      " ARIMA(1,1,2) with drift         : -11372.29\n",
      " ARIMA(2,1,1) with drift         : -11375.63\n",
      " ARIMA(3,1,2) with drift         : -11437\n",
      " ARIMA(3,1,1) with drift         : -11375\n",
      " ARIMA(4,1,2) with drift         : -11443.02\n",
      " ARIMA(4,1,1) with drift         : -11377.67\n",
      " ARIMA(5,1,2) with drift         : -11383.28\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(5,1,1) with drift         : -11384.28\n",
      " ARIMA(5,1,3) with drift         : -11460.66\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(5,1,3)                    : -11406.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : -11455.43\n",
      "\n",
      " Best model: ARIMA(3,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11376\n",
      " ARIMA(0,1,0) with drift         : -11310.81\n",
      " ARIMA(1,1,0) with drift         : -11353.5\n",
      " ARIMA(0,1,1) with drift         : -11361.68\n",
      " ARIMA(0,1,0)                    : -11312.81\n",
      " ARIMA(1,1,2) with drift         : -11367.66\n",
      " ARIMA(2,1,1) with drift         : -11370.74\n",
      " ARIMA(3,1,2) with drift         : -11435.23\n",
      " ARIMA(3,1,1) with drift         : -11369.84\n",
      " ARIMA(4,1,2) with drift         : -11435.36\n",
      " ARIMA(4,1,1) with drift         : -11372.57\n",
      " ARIMA(5,1,2) with drift         : -11379.67\n",
      " ARIMA(4,1,3) with drift         : -11462.93\n",
      " ARIMA(3,1,3) with drift         : -11437.7\n",
      " ARIMA(5,1,3) with drift         : -11450.93\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(5,1,4) with drift         : -11457.04\n",
      " ARIMA(4,1,3)                    : -11464.8\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(4,1,2)                    : -11437.24\n",
      " ARIMA(5,1,3)                    : -11452.91\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11437.19\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(5,1,2)                    : -11381.68\n",
      " ARIMA(5,1,4)                    : -11458.98\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(5,1,4)                    : Inf\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(5,1,3)                    : Inf\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11451.79\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11377.46\n",
      " ARIMA(0,1,0) with drift         : -11311.79\n",
      " ARIMA(1,1,0) with drift         : -11353.83\n",
      " ARIMA(0,1,1) with drift         : -11361.84\n",
      " ARIMA(0,1,0)                    : -11313.79\n",
      " ARIMA(1,1,2) with drift         : -11367.56\n",
      " ARIMA(2,1,1) with drift         : -11372.91\n",
      " ARIMA(3,1,2) with drift         : -11421.85\n",
      " ARIMA(3,1,1) with drift         : -11371.51\n",
      " ARIMA(4,1,2) with drift         : -11441.18\n",
      " ARIMA(4,1,1) with drift         : -11374.72\n",
      " ARIMA(5,1,2) with drift         : -11382.23\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11422.45\n",
      " ARIMA(5,1,1) with drift         : -11383.49\n",
      " ARIMA(5,1,3) with drift         : -11452.79\n",
      " ARIMA(5,1,4) with drift         : -11453.95\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(5,1,5) with drift         : Inf\n",
      " ARIMA(4,1,5) with drift         : Inf\n",
      " ARIMA(5,1,4)                    : -11456\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(5,1,3)                    : -11454.45\n",
      " ARIMA(5,1,5)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(4,1,5)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,1,4)                    : Inf\n",
      " ARIMA(5,1,3)                    : Inf\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : -11449.4\n",
      "\n",
      " Best model: ARIMA(3,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11401.14\n",
      " ARIMA(0,1,0) with drift         : -11333.59\n",
      " ARIMA(1,1,0) with drift         : -11375.37\n",
      " ARIMA(0,1,1) with drift         : -11383.32\n",
      " ARIMA(0,1,0)                    : -11335.6\n",
      " ARIMA(1,1,2) with drift         : -11388.38\n",
      " ARIMA(2,1,1) with drift         : -11397.14\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11436.48\n",
      " ARIMA(1,1,3) with drift         : -11388.8\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11395.96\n",
      " ARIMA(3,1,4) with drift         : -11404.42\n",
      " ARIMA(2,1,3)                    : -11438.39\n",
      " ARIMA(1,1,3)                    : -11390.8\n",
      " ARIMA(2,1,2)                    : -11403.15\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11390.39\n",
      " ARIMA(1,1,4)                    : -11397.97\n",
      " ARIMA(3,1,2)                    : -11399.44\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11409.43\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11414.62\n",
      " ARIMA(0,1,0) with drift         : -11349.66\n",
      " ARIMA(1,1,0) with drift         : -11391.07\n",
      " ARIMA(0,1,1) with drift         : -11398.77\n",
      " ARIMA(0,1,0)                    : -11351.66\n",
      " ARIMA(1,1,2) with drift         : -11404.51\n",
      " ARIMA(2,1,1) with drift         : -11408.59\n",
      " ARIMA(3,1,2) with drift         : -11474.76\n",
      " ARIMA(3,1,1) with drift         : -11407.28\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11474.66\n",
      " ARIMA(2,1,3) with drift         : -11475\n",
      " ARIMA(1,1,3) with drift         : -11405.01\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11411.68\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11476.95\n",
      " ARIMA(1,1,3)                    : -11407\n",
      " ARIMA(2,1,2)                    : -11416.63\n",
      " ARIMA(3,1,3)                    : -11476.66\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11406.51\n",
      " ARIMA(1,1,4)                    : -11413.69\n",
      " ARIMA(3,1,2)                    : -11476.73\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : -11489.85\n",
      "\n",
      " Best model: ARIMA(3,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11417\n",
      " ARIMA(0,1,0) with drift         : -11350.81\n",
      " ARIMA(1,1,0) with drift         : -11393.43\n",
      " ARIMA(0,1,1) with drift         : -11401.37\n",
      " ARIMA(0,1,0)                    : -11352.81\n",
      " ARIMA(1,1,2) with drift         : -11408.15\n",
      " ARIMA(2,1,1) with drift         : -11411.62\n",
      " ARIMA(3,1,2) with drift         : -11478.61\n",
      " ARIMA(3,1,1) with drift         : -11410.14\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11477.88\n",
      " ARIMA(2,1,3) with drift         : -11480.64\n",
      " ARIMA(1,1,3) with drift         : -11408.04\n",
      " ARIMA(2,1,4) with drift         : -11470.54\n",
      " ARIMA(1,1,4) with drift         : -11413.2\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11482.64\n",
      " ARIMA(1,1,3)                    : -11410.05\n",
      " ARIMA(2,1,2)                    : -11419\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : -11472.55\n",
      " ARIMA(1,1,2)                    : -11410.17\n",
      " ARIMA(1,1,4)                    : -11415.2\n",
      " ARIMA(3,1,2)                    : -11480.59\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11494.28\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11428.15\n",
      " ARIMA(0,1,0) with drift         : -11363.82\n",
      " ARIMA(1,1,0) with drift         : -11405.04\n",
      " ARIMA(0,1,1) with drift         : -11413.13\n",
      " ARIMA(0,1,0)                    : -11365.82\n",
      " ARIMA(1,1,2) with drift         : -11419.24\n",
      " ARIMA(2,1,1) with drift         : -11423.1\n",
      " ARIMA(3,1,2) with drift         : -11485.43\n",
      " ARIMA(3,1,1) with drift         : -11421.44\n",
      " ARIMA(4,1,2) with drift         : -11470.37\n",
      " ARIMA(3,1,3) with drift         : -11484.77\n",
      " ARIMA(2,1,3) with drift         : -11487.17\n",
      " ARIMA(1,1,3) with drift         : -11419.2\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11425.26\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11489.13\n",
      " ARIMA(1,1,3)                    : -11421.2\n",
      " ARIMA(2,1,2)                    : -11430.16\n",
      " ARIMA(3,1,3)                    : -11486.74\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11421.24\n",
      " ARIMA(1,1,4)                    : -11427.26\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11439.42\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11445.44\n",
      " ARIMA(0,1,0) with drift         : -11379.2\n",
      " ARIMA(1,1,0) with drift         : -11421.84\n",
      " ARIMA(0,1,1) with drift         : -11429.11\n",
      " ARIMA(0,1,0)                    : -11381.2\n",
      " ARIMA(1,1,2) with drift         : -11437.71\n",
      " ARIMA(2,1,1) with drift         : -11440.18\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11507.1\n",
      " ARIMA(1,1,3) with drift         : -11437.5\n",
      " ARIMA(3,1,3) with drift         : -11506.37\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11443.66\n",
      " ARIMA(3,1,4) with drift         : -11533.54\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(3,1,5) with drift         : -11472.61\n",
      " ARIMA(2,1,5) with drift         : -11477.81\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(4,1,5) with drift         : -11542.91\n",
      " ARIMA(5,1,5) with drift         : Inf\n",
      " ARIMA(5,1,4) with drift         : -11515.88\n",
      " ARIMA(4,1,5)                    : -11544.81\n",
      " ARIMA(3,1,5)                    : -11474.62\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(5,1,5)                    : Inf\n",
      " ARIMA(3,1,4)                    : -11533.75\n",
      " ARIMA(5,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,5)                    : Inf\n",
      " ARIMA(4,1,5) with drift         : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,5) with drift         : -11486.28\n",
      "\n",
      " Best model: ARIMA(2,1,5) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11460.12\n",
      " ARIMA(0,1,0) with drift         : -11392.48\n",
      " ARIMA(1,1,0) with drift         : -11436.18\n",
      " ARIMA(0,1,1) with drift         : -11443.02\n",
      " ARIMA(0,1,0)                    : -11394.47\n",
      " ARIMA(1,1,2) with drift         : -11452\n",
      " ARIMA(2,1,1) with drift         : -11454.69\n",
      " ARIMA(3,1,2) with drift         : -11512.45\n",
      " ARIMA(3,1,1) with drift         : -11453.12\n",
      " ARIMA(4,1,2) with drift         : -11538.32\n",
      " ARIMA(4,1,1) with drift         : -11454.98\n",
      " ARIMA(5,1,2) with drift         : -11480.96\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11519.43\n",
      " ARIMA(5,1,1) with drift         : -11465.65\n",
      " ARIMA(5,1,3) with drift         : -11541.25\n",
      " ARIMA(5,1,4) with drift         : -11546.31\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(5,1,5) with drift         : Inf\n",
      " ARIMA(4,1,5) with drift         : Inf\n",
      " ARIMA(5,1,4)                    : -11548.31\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(5,1,3)                    : -11543.22\n",
      " ARIMA(5,1,5)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(4,1,5)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,1,4)                    : Inf\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(5,1,3)                    : Inf\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : -11520.63\n",
      "\n",
      " Best model: ARIMA(3,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11473.66\n",
      " ARIMA(0,1,0) with drift         : -11405.4\n",
      " ARIMA(1,1,0) with drift         : -11449.03\n",
      " ARIMA(0,1,1) with drift         : -11457.36\n",
      " ARIMA(0,1,0)                    : -11407.4\n",
      " ARIMA(1,1,2) with drift         : -11465.21\n",
      " ARIMA(2,1,1) with drift         : -11468.1\n",
      " ARIMA(3,1,2) with drift         : -11522.67\n",
      " ARIMA(3,1,1) with drift         : -11466.94\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11523.94\n",
      " ARIMA(2,1,3) with drift         : -11530.31\n",
      " ARIMA(1,1,3) with drift         : -11464.92\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11469.99\n",
      " ARIMA(3,1,4) with drift         : -11553.79\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(3,1,5) with drift         : -11506.29\n",
      " ARIMA(2,1,5) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(4,1,5) with drift         : Inf\n",
      " ARIMA(3,1,4)                    : -11555.37\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11525.89\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(3,1,5)                    : -11508.29\n",
      " ARIMA(2,1,3)                    : -11532.31\n",
      " ARIMA(2,1,5)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(4,1,5)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(3,1,5)                    : -11517.89\n",
      "\n",
      " Best model: ARIMA(3,1,5)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11563.65\n",
      " ARIMA(0,0,0) with non-zero mean : -7092.942\n",
      " ARIMA(1,0,0) with non-zero mean : -11532.35\n",
      " ARIMA(0,0,1) with non-zero mean : -9062.662\n",
      " ARIMA(0,0,0) with zero mean     : -7069.286\n",
      " ARIMA(1,0,2) with non-zero mean : -11561.12\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11629.33\n",
      " ARIMA(3,0,1) with non-zero mean : -11567.62\n",
      " ARIMA(4,0,2) with non-zero mean : -11577.15\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11570.59\n",
      " ARIMA(4,0,1) with non-zero mean : -11573.86\n",
      " ARIMA(4,0,3) with non-zero mean : -11639.6\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11626.91\n",
      " ARIMA(5,0,4) with non-zero mean : -11629.53\n",
      " ARIMA(4,0,3) with zero mean     : -11641.48\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11643.49\n",
      " ARIMA(3,0,2) with zero mean     : -11630.38\n",
      " ARIMA(4,0,1) with zero mean     : -11575.2\n",
      " ARIMA(5,0,2) with zero mean     : -11627.71\n",
      " ARIMA(3,0,1) with zero mean     : -11569\n",
      " ARIMA(5,0,1) with zero mean     : -11604.21\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11634.59\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11531.84\n",
      " ARIMA(0,1,0) with drift         : -11462.99\n",
      " ARIMA(1,1,0) with drift         : -11505.42\n",
      " ARIMA(0,1,1) with drift         : -11513.88\n",
      " ARIMA(0,1,0)                    : -11464.99\n",
      " ARIMA(1,1,2) with drift         : -11520.31\n",
      " ARIMA(2,1,1) with drift         : -11524.07\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11514.74\n",
      " ARIMA(1,1,3) with drift         : -11521.21\n",
      " ARIMA(3,1,1) with drift         : -11523.29\n",
      " ARIMA(3,1,3) with drift         : -11595.73\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : -11603.16\n",
      " ARIMA(4,1,1) with drift         : -11525.22\n",
      " ARIMA(5,1,2) with drift         : -11560.26\n",
      " ARIMA(5,1,1) with drift         : -11535.35\n",
      " ARIMA(5,1,3) with drift         : -11560.94\n",
      " ARIMA(4,1,2)                    : -11605.05\n",
      " ARIMA(3,1,2)                    : -11599.29\n",
      " ARIMA(4,1,1)                    : -11527.23\n",
      " ARIMA(5,1,2)                    : -11562.29\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(3,1,1)                    : -11525.3\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(5,1,1)                    : -11537.37\n",
      " ARIMA(5,1,3)                    : -11562.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(5,1,3)                    : Inf\n",
      " ARIMA(5,1,2)                    : -11574.41\n",
      "\n",
      " Best model: ARIMA(5,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11540.3\n",
      " ARIMA(0,1,0) with drift         : -11469.86\n",
      " ARIMA(1,1,0) with drift         : -11512.62\n",
      " ARIMA(0,1,1) with drift         : -11521.01\n",
      " ARIMA(0,1,0)                    : -11471.86\n",
      " ARIMA(1,1,2) with drift         : -11527.97\n",
      " ARIMA(2,1,1) with drift         : -11531.89\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11522.06\n",
      " ARIMA(1,1,3) with drift         : -11529.09\n",
      " ARIMA(3,1,1) with drift         : -11531.68\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11542.31\n",
      " ARIMA(1,1,2)                    : -11529.98\n",
      " ARIMA(2,1,1)                    : -11533.89\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(1,1,1)                    : -11524.06\n",
      " ARIMA(1,1,3)                    : -11531.09\n",
      " ARIMA(3,1,1)                    : -11533.69\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11551.54\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11545.43\n",
      " ARIMA(0,1,0) with drift         : -11476.22\n",
      " ARIMA(1,1,0) with drift         : -11519.24\n",
      " ARIMA(0,1,1) with drift         : -11527.35\n",
      " ARIMA(0,1,0)                    : -11478.22\n",
      " ARIMA(1,1,2) with drift         : -11535.3\n",
      " ARIMA(2,1,1) with drift         : -11538.4\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11606.01\n",
      " ARIMA(1,1,3) with drift         : -11536.07\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11543.1\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11608.02\n",
      " ARIMA(1,1,3)                    : -11538.06\n",
      " ARIMA(2,1,2)                    : -11547.44\n",
      " ARIMA(3,1,3)                    : -11608.56\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(4,1,2)                    : -11548.72\n",
      " ARIMA(4,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(2,1,2)                    : -11557.99\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11626.41\n",
      " ARIMA(0,0,0) with non-zero mean : -7180.606\n",
      " ARIMA(1,0,0) with non-zero mean : -11595.23\n",
      " ARIMA(0,0,1) with non-zero mean : -9148.012\n",
      " ARIMA(0,0,0) with zero mean     : -7147.407\n",
      " ARIMA(1,0,2) with non-zero mean : -11622.24\n",
      " ARIMA(2,0,1) with non-zero mean : -11605.97\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11635.32\n",
      " ARIMA(1,0,3) with non-zero mean : -11637.31\n",
      " ARIMA(0,0,3) with non-zero mean : -10542.52\n",
      " ARIMA(1,0,4) with non-zero mean : -11636.59\n",
      " ARIMA(0,0,2) with non-zero mean : -10038.07\n",
      " ARIMA(0,0,4) with non-zero mean : -10971.87\n",
      " ARIMA(2,0,4) with non-zero mean : -11663.67\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11674.55\n",
      " ARIMA(1,0,5) with non-zero mean : -11642.38\n",
      " ARIMA(3,0,5) with non-zero mean : -11671.84\n",
      " ARIMA(2,0,5) with zero mean     : -11675.29\n",
      " ARIMA(1,0,5) with zero mean     : -11643.28\n",
      " ARIMA(2,0,4) with zero mean     : -11664.18\n",
      " ARIMA(3,0,5) with zero mean     : -11672.8\n",
      " ARIMA(1,0,4) with zero mean     : -11637.4\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,5) with zero mean     : -11676.74\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11637.1\n",
      " ARIMA(0,0,0) with non-zero mean : -7183.094\n",
      " ARIMA(1,0,0) with non-zero mean : -11607.12\n",
      " ARIMA(0,0,1) with non-zero mean : -9156.432\n",
      " ARIMA(0,0,0) with zero mean     : -7151.929\n",
      " ARIMA(1,0,2) with non-zero mean : -11633.92\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11646.52\n",
      " ARIMA(1,0,3) with non-zero mean : -11649.07\n",
      " ARIMA(0,0,3) with non-zero mean : -10551.96\n",
      " ARIMA(1,0,4) with non-zero mean : -11648.28\n",
      " ARIMA(0,0,2) with non-zero mean : -10047.3\n",
      " ARIMA(0,0,4) with non-zero mean : -10983.71\n",
      " ARIMA(2,0,4) with non-zero mean : -11680.57\n",
      " ARIMA(3,0,4) with non-zero mean : -11756.89\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11689.65\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11690\n",
      "\n",
      " Best model: ARIMA(2,0,5) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11726.86\n",
      " ARIMA(0,0,0) with non-zero mean : -7219.871\n",
      " ARIMA(1,0,0) with non-zero mean : -11704.34\n",
      " ARIMA(0,0,1) with non-zero mean : -9202.304\n",
      " ARIMA(0,0,0) with zero mean     : -7181.348\n",
      " ARIMA(1,0,2) with non-zero mean : -11725.28\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11821.89\n",
      " ARIMA(3,0,1) with non-zero mean : -11737.16\n",
      " ARIMA(4,0,2) with non-zero mean : -11746.45\n",
      " ARIMA(3,0,3) with non-zero mean : -11841.21\n",
      " ARIMA(2,0,3) with non-zero mean : -11736.78\n",
      " ARIMA(4,0,3) with non-zero mean : -11883.48\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11882.26\n",
      " ARIMA(3,0,4) with non-zero mean : -11841.53\n",
      " ARIMA(5,0,2) with non-zero mean : -11819.23\n",
      " ARIMA(5,0,4) with non-zero mean : -11834.07\n",
      " ARIMA(4,0,3) with zero mean     : -11883.42\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,1) with non-zero mean : -11727.48\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12048.88\n",
      " ARIMA(0,0,0) with non-zero mean : -7798.523\n",
      " ARIMA(1,0,0) with non-zero mean : -12046.89\n",
      " ARIMA(0,0,1) with non-zero mean : -9695.57\n",
      " ARIMA(0,0,0) with zero mean     : -7706.469\n",
      " ARIMA(1,0,2) with non-zero mean : -12050.93\n",
      " ARIMA(0,0,2) with non-zero mean : -10590.18\n",
      " ARIMA(1,0,1) with non-zero mean : -12052.27\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(2,0,0) with non-zero mean : -12051.33\n",
      " ARIMA(1,0,1) with zero mean     : -12048.87\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -12021.88\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12434.36\n",
      " ARIMA(0,0,0) with non-zero mean : -7980.504\n",
      " ARIMA(1,0,0) with non-zero mean : -12372.67\n",
      " ARIMA(0,0,1) with non-zero mean : -9941.412\n",
      " ARIMA(0,0,0) with zero mean     : -7857.589\n",
      " ARIMA(1,0,2) with non-zero mean : -12376.41\n",
      " ARIMA(2,0,1) with non-zero mean : -12436.06\n",
      " ARIMA(1,0,1) with non-zero mean : -12377.95\n",
      " ARIMA(2,0,0) with non-zero mean : -12437.96\n",
      " ARIMA(3,0,0) with non-zero mean : -12435.15\n",
      " ARIMA(3,0,1) with non-zero mean : -12454.73\n",
      " ARIMA(4,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -12464.93\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12537.98\n",
      " ARIMA(2,0,3) with non-zero mean : -12436.37\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -12558.88\n",
      " ARIMA(2,0,4) with non-zero mean : -12437.89\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : -12482.54\n",
      " ARIMA(2,0,5) with non-zero mean : -12443.38\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -12558.06\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : -12501.26\n",
      "\n",
      " Best model: ARIMA(3,0,5) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12731.55\n",
      " ARIMA(0,0,0) with non-zero mean : -8064.913\n",
      " ARIMA(1,0,0) with non-zero mean : -12677.97\n",
      " ARIMA(0,0,1) with non-zero mean : -10058.9\n",
      " ARIMA(0,0,0) with zero mean     : -7927.111\n",
      " ARIMA(1,0,2) with non-zero mean : -12680.87\n",
      " ARIMA(2,0,1) with non-zero mean : -12729.28\n",
      " ARIMA(3,0,2) with non-zero mean : -12759.62\n",
      " ARIMA(3,0,1) with non-zero mean : -12730.55\n",
      " ARIMA(4,0,2) with non-zero mean : -12811.44\n",
      " ARIMA(4,0,1) with non-zero mean : -12738.03\n",
      " ARIMA(5,0,2) with non-zero mean : -12780.21\n",
      " ARIMA(4,0,3) with non-zero mean : -12809.91\n",
      " ARIMA(3,0,3) with non-zero mean : -12761.06\n",
      " ARIMA(5,0,1) with non-zero mean : -12747.6\n",
      " ARIMA(5,0,3) with non-zero mean : -12832.04\n",
      " ARIMA(5,0,4) with non-zero mean : -12815.29\n",
      " ARIMA(4,0,4) with non-zero mean : -12808.46\n",
      " ARIMA(5,0,3) with zero mean     : -12788.39\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -12735.86\n",
      "\n",
      " Best model: ARIMA(5,0,3) with zero mean     \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12838.17\n",
      " ARIMA(0,0,0) with non-zero mean : -8091.392\n",
      " ARIMA(1,0,0) with non-zero mean : -12837.14\n",
      " ARIMA(0,0,1) with non-zero mean : -10097.45\n",
      " ARIMA(0,0,0) with zero mean     : -7938.12\n",
      " ARIMA(1,0,2) with non-zero mean : -12838.32\n",
      " ARIMA(0,0,2) with non-zero mean : -11279.5\n",
      " ARIMA(1,0,1) with non-zero mean : -12837.52\n",
      " ARIMA(1,0,3) with non-zero mean : -12836.31\n",
      " ARIMA(0,0,3) with non-zero mean : -11685.67\n",
      " ARIMA(2,0,1) with non-zero mean : -12838.94\n",
      " ARIMA(2,0,0) with non-zero mean : -12838.65\n",
      " ARIMA(3,0,1) with non-zero mean : -12842.45\n",
      " ARIMA(3,0,0) with non-zero mean : -12841.35\n",
      " ARIMA(4,0,1) with non-zero mean : -12840.34\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,0) with non-zero mean : -12838.9\n",
      " ARIMA(4,0,2) with non-zero mean : -12861.04\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -12898.44\n",
      " ARIMA(3,0,3) with non-zero mean : -12879.27\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -12896.67\n",
      " ARIMA(3,0,4) with non-zero mean : -12878.13\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -12852.41\n",
      "\n",
      " Best model: ARIMA(4,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12927.14\n",
      " ARIMA(0,0,0) with non-zero mean : -8198.192\n",
      " ARIMA(1,0,0) with non-zero mean : -12908.82\n",
      " ARIMA(0,0,1) with non-zero mean : -10141.79\n",
      " ARIMA(0,0,0) with zero mean     : -8024.557\n",
      " ARIMA(1,0,2) with non-zero mean : -12911.9\n",
      " ARIMA(2,0,1) with non-zero mean : -12929.13\n",
      " ARIMA(1,0,1) with non-zero mean : -12908.74\n",
      " ARIMA(2,0,0) with non-zero mean : -12908.7\n",
      " ARIMA(3,0,1) with non-zero mean : -12938.63\n",
      " ARIMA(3,0,0) with non-zero mean : -12936.86\n",
      " ARIMA(4,0,1) with non-zero mean : -12933.76\n",
      " ARIMA(3,0,2) with non-zero mean : -12952.1\n",
      " ARIMA(4,0,2) with non-zero mean : -12950.34\n",
      " ARIMA(3,0,3) with non-zero mean : -12953.03\n",
      " ARIMA(2,0,3) with non-zero mean : -12926.06\n",
      " ARIMA(4,0,3) with non-zero mean : -13011.78\n",
      " ARIMA(5,0,3) with non-zero mean : -12957.38\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -12955.51\n",
      " ARIMA(5,0,2) with non-zero mean : -12958.24\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -12944\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -12921.65\n",
      "\n",
      " Best model: ARIMA(3,0,4) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13034.35\n",
      " ARIMA(0,0,0) with non-zero mean : -8419.008\n",
      " ARIMA(1,0,0) with non-zero mean : -13034.07\n",
      " ARIMA(0,0,1) with non-zero mean : -10368.77\n",
      " ARIMA(0,0,0) with zero mean     : -8212.474\n",
      " ARIMA(1,0,2) with non-zero mean : -13036.71\n",
      " ARIMA(0,0,2) with non-zero mean : -11525.41\n",
      " ARIMA(1,0,1) with non-zero mean : -13033.75\n",
      " ARIMA(1,0,3) with non-zero mean : -13035.61\n",
      " ARIMA(0,0,3) with non-zero mean : -11936.39\n",
      " ARIMA(2,0,1) with non-zero mean : -13032.6\n",
      " ARIMA(2,0,3) with non-zero mean : -13034.24\n",
      " ARIMA(1,0,2) with zero mean     : -13032.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,2) with non-zero mean : -13022.48\n",
      "\n",
      " Best model: ARIMA(1,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13141.92\n",
      " ARIMA(0,0,0) with non-zero mean : -8600.267\n",
      " ARIMA(1,0,0) with non-zero mean : -13132.96\n",
      " ARIMA(0,0,1) with non-zero mean : -10567.03\n",
      " ARIMA(0,0,0) with zero mean     : -8417.529\n",
      " ARIMA(1,0,2) with non-zero mean : -13135.69\n",
      " ARIMA(2,0,1) with non-zero mean : -13143.46\n",
      " ARIMA(1,0,1) with non-zero mean : -13131.3\n",
      " ARIMA(2,0,0) with non-zero mean : -13130.87\n",
      " ARIMA(3,0,1) with non-zero mean : -13141.06\n",
      " ARIMA(3,0,0) with non-zero mean : -13135.48\n",
      " ARIMA(3,0,2) with non-zero mean : -13139.83\n",
      " ARIMA(2,0,1) with zero mean     : -13139.77\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with non-zero mean : -13135.84\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13193.12\n",
      " ARIMA(0,0,0) with non-zero mean : -8651.976\n",
      " ARIMA(1,0,0) with non-zero mean : -13170.43\n",
      " ARIMA(0,0,1) with non-zero mean : -10600.05\n",
      " ARIMA(0,0,0) with zero mean     : -8478.609\n",
      " ARIMA(1,0,2) with non-zero mean : -13174.57\n",
      " ARIMA(2,0,1) with non-zero mean : -13191\n",
      " ARIMA(3,0,2) with non-zero mean : -13202.7\n",
      " ARIMA(3,0,1) with non-zero mean : -13192.86\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -13200.6\n",
      " ARIMA(2,0,3) with non-zero mean : -13191.28\n",
      " ARIMA(4,0,1) with non-zero mean : -13191.15\n",
      " ARIMA(4,0,3) with non-zero mean : -13218.39\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -13200.58\n",
      " ARIMA(5,0,2) with non-zero mean : -13252.64\n",
      " ARIMA(5,0,1) with non-zero mean : -13189.33\n",
      " ARIMA(5,0,2) with zero mean     : -13248.74\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -13185.97\n",
      "\n",
      " Best model: ARIMA(3,0,4) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13224.59\n",
      " ARIMA(0,0,0) with non-zero mean : -8659.661\n",
      " ARIMA(1,0,0) with non-zero mean : -13222\n",
      " ARIMA(0,0,1) with non-zero mean : -10646.41\n",
      " ARIMA(0,0,0) with zero mean     : -8488.456\n",
      " ARIMA(1,0,2) with non-zero mean : -13223.63\n",
      " ARIMA(2,0,1) with non-zero mean : -13221.42\n",
      " ARIMA(3,0,2) with non-zero mean : -13234.74\n",
      " ARIMA(3,0,1) with non-zero mean : -13224.58\n",
      " ARIMA(4,0,2) with non-zero mean : -13224.71\n",
      " ARIMA(3,0,3) with non-zero mean : -13233.34\n",
      " ARIMA(2,0,3) with non-zero mean : -13222.66\n",
      " ARIMA(4,0,1) with non-zero mean : -13223.65\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -13227.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : -13241.51\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13264.36\n",
      " ARIMA(0,0,0) with non-zero mean : -8704.311\n",
      " ARIMA(1,0,0) with non-zero mean : -13253.56\n",
      " ARIMA(0,0,1) with non-zero mean : -10687.09\n",
      " ARIMA(0,0,0) with zero mean     : -8526.564\n",
      " ARIMA(1,0,2) with non-zero mean : -13254.11\n",
      " ARIMA(2,0,1) with non-zero mean : -13262.34\n",
      " ARIMA(3,0,2) with non-zero mean : -13271.99\n",
      " ARIMA(3,0,1) with non-zero mean : -13272.92\n",
      " ARIMA(3,0,0) with non-zero mean : -13267.33\n",
      " ARIMA(4,0,1) with non-zero mean : -13266.58\n",
      " ARIMA(2,0,0) with non-zero mean : -13264.86\n",
      " ARIMA(4,0,0) with non-zero mean : -13267.59\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,1) with zero mean     : -13268.9\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -13257.04\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13286.09\n",
      " ARIMA(0,0,0) with non-zero mean : -8799.759\n",
      " ARIMA(1,0,0) with non-zero mean : -13281.32\n",
      " ARIMA(0,0,1) with non-zero mean : -10765\n",
      " ARIMA(0,0,0) with zero mean     : -8632.875\n",
      " ARIMA(1,0,2) with non-zero mean : -13281.08\n",
      " ARIMA(2,0,1) with non-zero mean : -13284.31\n",
      " ARIMA(3,0,2) with non-zero mean : -13294.12\n",
      " ARIMA(3,0,1) with non-zero mean : -13296\n",
      " ARIMA(3,0,0) with non-zero mean : -13287.48\n",
      " ARIMA(4,0,1) with non-zero mean : -13292.11\n",
      " ARIMA(2,0,0) with non-zero mean : -13286.29\n",
      " ARIMA(4,0,0) with non-zero mean : -13285.57\n",
      " ARIMA(4,0,2) with non-zero mean : -13307.77\n",
      " ARIMA(5,0,2) with non-zero mean : -13333.7\n",
      " ARIMA(5,0,1) with non-zero mean : -13288.79\n",
      " ARIMA(5,0,3) with non-zero mean : -13381.08\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -13370.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -13298.7\n",
      "\n",
      " Best model: ARIMA(4,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13315.22\n",
      " ARIMA(0,0,0) with non-zero mean : -8818.601\n",
      " ARIMA(1,0,0) with non-zero mean : -13308.47\n",
      " ARIMA(0,0,1) with non-zero mean : -10784.96\n",
      " ARIMA(0,0,0) with zero mean     : -8656.278\n",
      " ARIMA(1,0,2) with non-zero mean : -13308.69\n",
      " ARIMA(2,0,1) with non-zero mean : -13316.57\n",
      " ARIMA(1,0,1) with non-zero mean : -13306.78\n",
      " ARIMA(2,0,0) with non-zero mean : -13305.83\n",
      " ARIMA(3,0,1) with non-zero mean : -13313.95\n",
      " ARIMA(3,0,0) with non-zero mean : -13307.08\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -13312.98\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with non-zero mean : -13315.59\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13294.52\n",
      " ARIMA(0,0,0) with non-zero mean : -8751.451\n",
      " ARIMA(1,0,0) with non-zero mean : -13289.34\n",
      " ARIMA(0,0,1) with non-zero mean : -10730.44\n",
      " ARIMA(0,0,0) with zero mean     : -8614.585\n",
      " ARIMA(1,0,2) with non-zero mean : -13289.61\n",
      " ARIMA(2,0,1) with non-zero mean : -13295.78\n",
      " ARIMA(1,0,1) with non-zero mean : -13287.61\n",
      " ARIMA(2,0,0) with non-zero mean : -13286.67\n",
      " ARIMA(3,0,1) with non-zero mean : -13288.61\n",
      " ARIMA(3,0,0) with non-zero mean : -13288.71\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -13293.98\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with non-zero mean : -13296.56\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13281.55\n",
      " ARIMA(0,0,0) with non-zero mean : -8730.333\n",
      " ARIMA(1,0,0) with non-zero mean : -13273.79\n",
      " ARIMA(0,0,1) with non-zero mean : -10715.07\n",
      " ARIMA(0,0,0) with zero mean     : -8603.515\n",
      " ARIMA(1,0,2) with non-zero mean : -13273.78\n",
      " ARIMA(2,0,1) with non-zero mean : -13279.31\n",
      " ARIMA(3,0,2) with non-zero mean : -13289.56\n",
      " ARIMA(3,0,1) with non-zero mean : -13288.08\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -13288.21\n",
      " ARIMA(2,0,3) with non-zero mean : -13279.63\n",
      " ARIMA(4,0,1) with non-zero mean : -13289.48\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -13287.32\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : -13277.09\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13244.45\n",
      " ARIMA(0,0,0) with non-zero mean : -8638.893\n",
      " ARIMA(1,0,0) with non-zero mean : -13241.32\n",
      " ARIMA(0,0,1) with non-zero mean : -10627.38\n",
      " ARIMA(0,0,0) with zero mean     : -8538.471\n",
      " ARIMA(1,0,2) with non-zero mean : -13241.96\n",
      " ARIMA(2,0,1) with non-zero mean : -13242.56\n",
      " ARIMA(3,0,2) with non-zero mean : -13242.28\n",
      " ARIMA(2,0,3) with non-zero mean : -13242.54\n",
      " ARIMA(1,0,1) with non-zero mean : -13239.47\n",
      " ARIMA(1,0,3) with non-zero mean : -13239.97\n",
      " ARIMA(3,0,1) with non-zero mean : -13242.75\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -13243.81\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13247.7\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13202.85\n",
      " ARIMA(0,0,0) with non-zero mean : -8591.905\n",
      " ARIMA(1,0,0) with non-zero mean : -13201\n",
      " ARIMA(0,0,1) with non-zero mean : -10586.47\n",
      " ARIMA(0,0,0) with zero mean     : -8489.949\n",
      " ARIMA(1,0,2) with non-zero mean : -13201.67\n",
      " ARIMA(2,0,1) with non-zero mean : -13200.09\n",
      " ARIMA(3,0,2) with non-zero mean : -13249.76\n",
      " ARIMA(3,0,1) with non-zero mean : -13215.09\n",
      " ARIMA(4,0,2) with non-zero mean : -13220.25\n",
      " ARIMA(3,0,3) with non-zero mean : -13213.48\n",
      " ARIMA(2,0,3) with non-zero mean : -13200.89\n",
      " ARIMA(4,0,1) with non-zero mean : -13210.99\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -13248.67\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -13219.49\n",
      "\n",
      " Best model: ARIMA(4,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13217.65\n",
      " ARIMA(0,0,0) with non-zero mean : -8600.973\n",
      " ARIMA(1,0,0) with non-zero mean : -13216.62\n",
      " ARIMA(0,0,1) with non-zero mean : -10599.03\n",
      " ARIMA(0,0,0) with zero mean     : -8478.971\n",
      " ARIMA(1,0,2) with non-zero mean : -13217.71\n",
      " ARIMA(0,0,2) with non-zero mean : -11739.39\n",
      " ARIMA(1,0,1) with non-zero mean : -13214.72\n",
      " ARIMA(1,0,3) with non-zero mean : -13215.7\n",
      " ARIMA(0,0,3) with non-zero mean : -12182.37\n",
      " ARIMA(2,0,1) with non-zero mean : -13218.8\n",
      " ARIMA(2,0,0) with non-zero mean : -13214.1\n",
      " ARIMA(3,0,1) with non-zero mean : -13230.16\n",
      " ARIMA(3,0,0) with non-zero mean : -13218.76\n",
      " ARIMA(4,0,1) with non-zero mean : -13222.52\n",
      " ARIMA(3,0,2) with non-zero mean : -13230.85\n",
      " ARIMA(4,0,2) with non-zero mean : -13234.85\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -13233.84\n",
      " ARIMA(3,0,3) with non-zero mean : -13229.16\n",
      " ARIMA(5,0,1) with non-zero mean : -13223.37\n",
      " ARIMA(5,0,3) with non-zero mean : -13293.72\n",
      " ARIMA(5,0,4) with non-zero mean : -13262.21\n",
      " ARIMA(4,0,4) with non-zero mean : -13229.1\n",
      " ARIMA(5,0,3) with zero mean     : -13290.35\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -13234.4\n",
      "\n",
      " Best model: ARIMA(4,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13229.23\n",
      " ARIMA(0,0,0) with non-zero mean : -8638.204\n",
      " ARIMA(1,0,0) with non-zero mean : -13222.89\n",
      " ARIMA(0,0,1) with non-zero mean : -10628.86\n",
      " ARIMA(0,0,0) with zero mean     : -8523.826\n",
      " ARIMA(1,0,2) with non-zero mean : -13223.89\n",
      " ARIMA(2,0,1) with non-zero mean : -13230.19\n",
      " ARIMA(1,0,1) with non-zero mean : -13220.98\n",
      " ARIMA(2,0,0) with non-zero mean : -13220.28\n",
      " ARIMA(3,0,1) with non-zero mean : -13227.34\n",
      " ARIMA(3,0,0) with non-zero mean : -13222.97\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -13228.25\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with non-zero mean : -13228.97\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13225.78\n",
      " ARIMA(0,0,0) with non-zero mean : -8640.479\n",
      " ARIMA(1,0,0) with non-zero mean : -13222.35\n",
      " ARIMA(0,0,1) with non-zero mean : -10630.57\n",
      " ARIMA(0,0,0) with zero mean     : -8526.609\n",
      " ARIMA(1,0,2) with non-zero mean : -13223.83\n",
      " ARIMA(2,0,1) with non-zero mean : -13223.03\n",
      " ARIMA(3,0,2) with non-zero mean : -13251.14\n",
      " ARIMA(3,0,1) with non-zero mean : -13231.06\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -13249.33\n",
      " ARIMA(2,0,3) with non-zero mean : -13237.37\n",
      " ARIMA(4,0,1) with non-zero mean : -13228.66\n",
      " ARIMA(4,0,3) with non-zero mean : -13312.69\n",
      " ARIMA(5,0,3) with non-zero mean : -13240.06\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -13225.83\n",
      " ARIMA(5,0,2) with non-zero mean : -13241.89\n",
      " ARIMA(5,0,4) with non-zero mean : -13272.13\n",
      " ARIMA(4,0,3) with zero mean     : -13226.4\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -13240.64\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13273.5\n",
      " ARIMA(0,0,0) with non-zero mean : -8726.392\n",
      " ARIMA(1,0,0) with non-zero mean : -13268.27\n",
      " ARIMA(0,0,1) with non-zero mean : -10693.44\n",
      " ARIMA(0,0,0) with zero mean     : -8598.523\n",
      " ARIMA(1,0,2) with non-zero mean : -13269.54\n",
      " ARIMA(2,0,1) with non-zero mean : -13270.56\n",
      " ARIMA(3,0,2) with non-zero mean : -13290.67\n",
      " ARIMA(3,0,1) with non-zero mean : -13275.6\n",
      " ARIMA(4,0,2) with non-zero mean : -13337.17\n",
      " ARIMA(4,0,1) with non-zero mean : -13273.2\n",
      " ARIMA(5,0,2) with non-zero mean : -13320.19\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -13322.75\n",
      " ARIMA(5,0,1) with non-zero mean : -13288.19\n",
      " ARIMA(5,0,3) with non-zero mean : -13339.1\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -13330.91\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,1) with non-zero mean : -13260.9\n",
      "\n",
      " Best model: ARIMA(5,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13330.8\n",
      " ARIMA(0,0,0) with non-zero mean : -8763.678\n",
      " ARIMA(1,0,0) with non-zero mean : -13327.64\n",
      " ARIMA(0,0,1) with non-zero mean : -10748.55\n",
      " ARIMA(0,0,0) with zero mean     : -8614.882\n",
      " ARIMA(1,0,2) with non-zero mean : -13328.81\n",
      " ARIMA(2,0,1) with non-zero mean : -13325.66\n",
      " ARIMA(3,0,2) with non-zero mean : -13359.55\n",
      " ARIMA(3,0,1) with non-zero mean : -13338.61\n",
      " ARIMA(4,0,2) with non-zero mean : -13350.39\n",
      " ARIMA(3,0,3) with non-zero mean : -13339.44\n",
      " ARIMA(2,0,3) with non-zero mean : -13328.85\n",
      " ARIMA(4,0,1) with non-zero mean : -13346.18\n",
      " ARIMA(4,0,3) with non-zero mean : -13351.1\n",
      " ARIMA(3,0,2) with zero mean     : -13351.9\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -13344.81\n",
      "\n",
      " Best model: ARIMA(4,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13380.83\n",
      " ARIMA(0,0,0) with non-zero mean : -8778.684\n",
      " ARIMA(1,0,0) with non-zero mean : -13373.4\n",
      " ARIMA(0,0,1) with non-zero mean : -10763.15\n",
      " ARIMA(0,0,0) with zero mean     : -8621.15\n",
      " ARIMA(1,0,2) with non-zero mean : -13374.03\n",
      " ARIMA(2,0,1) with non-zero mean : -13379.57\n",
      " ARIMA(3,0,2) with non-zero mean : -13384\n",
      " ARIMA(3,0,1) with non-zero mean : -13385.76\n",
      " ARIMA(3,0,0) with non-zero mean : -13372.9\n",
      " ARIMA(4,0,1) with non-zero mean : -13374.4\n",
      " ARIMA(2,0,0) with non-zero mean : -13370.69\n",
      " ARIMA(4,0,0) with non-zero mean : -13374.31\n",
      " ARIMA(4,0,2) with non-zero mean : -13396.01\n",
      " ARIMA(5,0,2) with non-zero mean : -13400.34\n",
      " ARIMA(5,0,1) with non-zero mean : -13377.97\n",
      " ARIMA(5,0,3) with non-zero mean : -13399.47\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with zero mean     : -13397.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,2) with non-zero mean : -13433.95\n",
      "\n",
      " Best model: ARIMA(5,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13389.44\n",
      " ARIMA(0,0,0) with non-zero mean : -8785.203\n",
      " ARIMA(1,0,0) with non-zero mean : -13383.45\n",
      " ARIMA(0,0,1) with non-zero mean : -10766.55\n",
      " ARIMA(0,0,0) with zero mean     : -8638.774\n",
      " ARIMA(1,0,2) with non-zero mean : -13384.41\n",
      " ARIMA(2,0,1) with non-zero mean : -13386.49\n",
      " ARIMA(3,0,2) with non-zero mean : -13397.52\n",
      " ARIMA(3,0,1) with non-zero mean : -13398.73\n",
      " ARIMA(3,0,0) with non-zero mean : -13387.59\n",
      " ARIMA(4,0,1) with non-zero mean : -13394.72\n",
      " ARIMA(2,0,0) with non-zero mean : -13385.51\n",
      " ARIMA(4,0,0) with non-zero mean : -13385.26\n",
      " ARIMA(4,0,2) with non-zero mean : -13394.06\n",
      " ARIMA(3,0,1) with zero mean     : -13394.67\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -13389.26\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -8817.258\n",
      " ARIMA(1,0,0) with non-zero mean : -13394.02\n",
      " ARIMA(0,0,1) with non-zero mean : -10796.54\n",
      " ARIMA(0,0,0) with zero mean     : -8668.423\n",
      " ARIMA(2,0,0) with non-zero mean : -13393.41\n",
      " ARIMA(1,0,1) with non-zero mean : -13392.02\n",
      " ARIMA(2,0,1) with non-zero mean : -13394.62\n",
      " ARIMA(3,0,1) with non-zero mean : -13399.28\n",
      " ARIMA(3,0,0) with non-zero mean : -13396.73\n",
      " ARIMA(4,0,1) with non-zero mean : -13397.52\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,0) with non-zero mean : -13394.6\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,1) with zero mean     : -13396.56\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -13399.41\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13412.76\n",
      " ARIMA(0,0,0) with non-zero mean : -8835.11\n",
      " ARIMA(1,0,0) with non-zero mean : -13400.98\n",
      " ARIMA(0,0,1) with non-zero mean : -10816.87\n",
      " ARIMA(0,0,0) with zero mean     : -8697.246\n",
      " ARIMA(1,0,2) with non-zero mean : -13402.43\n",
      " ARIMA(2,0,1) with non-zero mean : -13412.29\n",
      " ARIMA(3,0,2) with non-zero mean : -13425.78\n",
      " ARIMA(3,0,1) with non-zero mean : -13408.73\n",
      " ARIMA(4,0,2) with non-zero mean : -13405.3\n",
      " ARIMA(3,0,3) with non-zero mean : -13423.77\n",
      " ARIMA(2,0,3) with non-zero mean : -13411.32\n",
      " ARIMA(4,0,1) with non-zero mean : -13407.09\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -13401.33\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : -13426.43\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13413.99\n",
      " ARIMA(0,0,0) with non-zero mean : -8828.503\n",
      " ARIMA(1,0,0) with non-zero mean : -13410.06\n",
      " ARIMA(0,0,1) with non-zero mean : -10816.85\n",
      " ARIMA(0,0,0) with zero mean     : -8687.243\n",
      " ARIMA(1,0,2) with non-zero mean : -13411.45\n",
      " ARIMA(2,0,1) with non-zero mean : -13412.62\n",
      " ARIMA(3,0,2) with non-zero mean : -13422.23\n",
      " ARIMA(3,0,1) with non-zero mean : -13421.45\n",
      " ARIMA(4,0,2) with non-zero mean : -13418.8\n",
      " ARIMA(3,0,3) with non-zero mean : -13420.35\n",
      " ARIMA(2,0,3) with non-zero mean : -13412.3\n",
      " ARIMA(4,0,1) with non-zero mean : -13420.7\n",
      " ARIMA(4,0,3) with non-zero mean : -13460.7\n",
      " ARIMA(5,0,3) with non-zero mean : -13470.28\n",
      " ARIMA(5,0,2) with non-zero mean : -13454.11\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -13477.53\n",
      " ARIMA(3,0,4) with non-zero mean : -13444.65\n",
      " ARIMA(4,0,5) with non-zero mean : -13473.31\n",
      " ARIMA(3,0,5) with non-zero mean : -13443.48\n",
      " ARIMA(5,0,5) with non-zero mean : -13473.76\n",
      " ARIMA(4,0,4) with zero mean     : -13466.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,4) with non-zero mean : -13490.15\n",
      "\n",
      " Best model: ARIMA(4,0,4) with non-zero mean \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m03.1 <- my.tsCV(train, cv.forecast.2, h=hori, window=wind, step=peri, \n",
    "                        silent=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4247b4e2-a191-4310-9df8-ee11224a71a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-01-24\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m03.1\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3603b7c1-1626-4d08-a2f0-35ea2db6d2db",
   "metadata": {},
   "source": [
    "## Regression with ARIMA errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad1a4e08-fca6-4a5b-b997-cf9d1e3cbe00",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14728.24\n",
      " Regression with ARIMA(0,1,0) errors : -14705.76\n",
      " Regression with ARIMA(1,1,0) errors : -14703.21\n",
      " Regression with ARIMA(0,1,1) errors : -14703.85\n",
      " Regression with ARIMA(0,1,0) errors : -14707.74\n",
      " Regression with ARIMA(1,1,2) errors : -14755.07\n",
      " Regression with ARIMA(0,1,2) errors : -14703.58\n",
      " Regression with ARIMA(1,1,1) errors : -14701.2\n",
      " Regression with ARIMA(1,1,3) errors : -14756.2\n",
      " Regression with ARIMA(0,1,3) errors : -14715.69\n",
      " Regression with ARIMA(2,1,3) errors : -14743.68\n",
      " Regression with ARIMA(1,1,4) errors : -14754.84\n",
      " Regression with ARIMA(0,1,4) errors : -14713.96\n",
      " Regression with ARIMA(2,1,4) errors : -14742.53\n",
      " Regression with ARIMA(1,1,3) errors : -14757.92\n",
      " Regression with ARIMA(0,1,3) errors : -14717.66\n",
      " Regression with ARIMA(1,1,2) errors : -14756.77\n",
      " Regression with ARIMA(2,1,3) errors : -14745.4\n",
      " Regression with ARIMA(1,1,4) errors : -14756.51\n",
      " Regression with ARIMA(0,1,2) errors : -14705.55\n",
      " Regression with ARIMA(0,1,4) errors : -14715.93\n",
      " Regression with ARIMA(2,1,2) errors : -14729.97\n",
      " Regression with ARIMA(2,1,4) errors : -14744.25\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14726.99\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14688.58\n",
      " Regression with ARIMA(1,1,0) errors : -14687.3\n",
      " Regression with ARIMA(0,1,1) errors : -14686.7\n",
      " Regression with ARIMA(0,1,0) errors : -14690.58\n",
      " Regression with ARIMA(1,1,1) errors : -14685.35\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14699.9\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14648.88\n",
      " Regression with ARIMA(1,1,0) errors : -14646.36\n",
      " Regression with ARIMA(0,1,1) errors : -14647.06\n",
      " Regression with ARIMA(0,1,0) errors : -14650.88\n",
      " Regression with ARIMA(1,1,1) errors : -14644.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14660.19\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14557.56\n",
      " Regression with ARIMA(1,1,0) errors : -14555.41\n",
      " Regression with ARIMA(0,1,1) errors : -14555.93\n",
      " Regression with ARIMA(0,1,0) errors : -14559.56\n",
      " Regression with ARIMA(1,1,1) errors : -14553.98\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14568.83\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14466.15\n",
      " Regression with ARIMA(1,1,0) errors : -14464.59\n",
      " Regression with ARIMA(0,1,1) errors : -14465.14\n",
      " Regression with ARIMA(0,1,0) errors : -14468.15\n",
      " Regression with ARIMA(1,1,1) errors : -14463.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14477.38\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14431.62\n",
      " Regression with ARIMA(1,1,0) errors : -14429.42\n",
      " Regression with ARIMA(0,1,1) errors : -14430.5\n",
      " Regression with ARIMA(0,1,0) errors : -14433.63\n",
      " Regression with ARIMA(1,1,1) errors : -14428.06\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14442.84\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14487.01\n",
      " Regression with ARIMA(0,1,0) errors : -14420.66\n",
      " Regression with ARIMA(1,1,0) errors : -14418.52\n",
      " Regression with ARIMA(0,1,1) errors : -14419.3\n",
      " Regression with ARIMA(0,1,0) errors : -14422.67\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14487.4\n",
      " Regression with ARIMA(1,1,1) errors : -14416.73\n",
      " Regression with ARIMA(2,1,0) errors : -14420.92\n",
      " Regression with ARIMA(3,1,1) errors : -14426\n",
      " Regression with ARIMA(3,1,0) errors : -14427.6\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14489.16\n",
      " Regression with ARIMA(1,1,1) errors : -14418.75\n",
      " Regression with ARIMA(2,1,0) errors : -14422.93\n",
      " Regression with ARIMA(3,1,1) errors : -14427.99\n",
      " Regression with ARIMA(2,1,2) errors : -14488.71\n",
      " Regression with ARIMA(1,1,0) errors : -14420.53\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -14429.61\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -14440.44\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14445.76\n",
      " Regression with ARIMA(0,1,0) errors : -14415.25\n",
      " Regression with ARIMA(1,1,0) errors : -14413.72\n",
      " Regression with ARIMA(0,1,1) errors : -14413.85\n",
      " Regression with ARIMA(0,1,0) errors : -14417.26\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14433.81\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14468.58\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14468.82\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14469.94\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14471.73\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14470.6\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14426.46\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14421.25\n",
      " Regression with ARIMA(1,1,0) errors : -14418.78\n",
      " Regression with ARIMA(0,1,1) errors : -14419.77\n",
      " Regression with ARIMA(0,1,0) errors : -14423.26\n",
      " Regression with ARIMA(1,1,1) errors : -14417.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14432.47\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14414.4\n",
      " Regression with ARIMA(1,1,0) errors : -14411.72\n",
      " Regression with ARIMA(0,1,1) errors : -14412.71\n",
      " Regression with ARIMA(0,1,0) errors : -14416.41\n",
      " Regression with ARIMA(1,1,1) errors : -14410.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14425.61\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14371.6\n",
      " Regression with ARIMA(1,1,0) errors : -14369.53\n",
      " Regression with ARIMA(0,1,1) errors : -14370.05\n",
      " Regression with ARIMA(0,1,0) errors : -14373.59\n",
      " Regression with ARIMA(1,1,1) errors : -14368.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14382.78\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14319.68\n",
      " Regression with ARIMA(0,1,0) errors : -14316.26\n",
      " Regression with ARIMA(1,1,0) errors : -14313.77\n",
      " Regression with ARIMA(0,1,1) errors : -14314.65\n",
      " Regression with ARIMA(0,1,0) errors : -14318.23\n",
      " Regression with ARIMA(1,1,2) errors : -14385.93\n",
      " Regression with ARIMA(0,1,2) errors : -14319.04\n",
      " Regression with ARIMA(1,1,1) errors : -14312.24\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14327.45\n",
      " Regression with ARIMA(2,1,1) errors : -14356.37\n",
      " Regression with ARIMA(2,1,3) errors : -14367.96\n",
      " Regression with ARIMA(1,1,2) errors : -14387.45\n",
      " Regression with ARIMA(0,1,2) errors : -14321.01\n",
      " Regression with ARIMA(1,1,1) errors : -14314.22\n",
      " Regression with ARIMA(2,1,2) errors : -14321.64\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(0,1,1) errors : -14316.62\n",
      " Regression with ARIMA(0,1,3) errors : -14329.42\n",
      " Regression with ARIMA(2,1,1) errors : -14358.04\n",
      " Regression with ARIMA(2,1,3) errors : -14369.57\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14338.56\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14254.7\n",
      " Regression with ARIMA(1,1,0) errors : -14252.25\n",
      " Regression with ARIMA(0,1,1) errors : -14252.87\n",
      " Regression with ARIMA(0,1,0) errors : -14256.7\n",
      " Regression with ARIMA(1,1,1) errors : -14250.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14265.84\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14249.15\n",
      " Regression with ARIMA(1,1,0) errors : -14246.58\n",
      " Regression with ARIMA(0,1,1) errors : -14247.46\n",
      " Regression with ARIMA(0,1,0) errors : -14251.14\n",
      " Regression with ARIMA(1,1,1) errors : -14245.11\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14260.28\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14341.48\n",
      " Regression with ARIMA(0,0,0) errors : -10840.14\n",
      " Regression with ARIMA(1,0,0) errors : -14339.73\n",
      " Regression with ARIMA(0,0,1) errors : -12569.99\n",
      " Regression with ARIMA(0,0,0) errors : -9528.814\n",
      " Regression with ARIMA(1,0,2) errors : -14343.89\n",
      " Regression with ARIMA(0,0,2) errors : -13424.35\n",
      " Regression with ARIMA(1,0,1) errors : -14345.89\n",
      " Regression with ARIMA(2,0,1) errors : -14342.88\n",
      " Regression with ARIMA(2,0,0) errors : -14344.83\n",
      " Regression with ARIMA(1,0,1) errors : -14199.07\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14344.44\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14131.23\n",
      " Regression with ARIMA(1,1,0) errors : -14129.6\n",
      " Regression with ARIMA(0,1,1) errors : -14129.22\n",
      " Regression with ARIMA(0,1,0) errors : -14133.21\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14142.29\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14104.7\n",
      " Regression with ARIMA(1,1,0) errors : -14102.15\n",
      " Regression with ARIMA(0,1,1) errors : -14102.72\n",
      " Regression with ARIMA(0,1,0) errors : -14106.71\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14115.78\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14094.76\n",
      " Regression with ARIMA(1,1,0) errors : -14092.35\n",
      " Regression with ARIMA(0,1,1) errors : -14092.76\n",
      " Regression with ARIMA(0,1,0) errors : -14096.76\n",
      " Regression with ARIMA(1,1,1) errors : -14091.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14105.82\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14158.82\n",
      " Regression with ARIMA(0,1,0) errors : -14086.53\n",
      " Regression with ARIMA(1,1,0) errors : -14083.63\n",
      " Regression with ARIMA(0,1,1) errors : -14084.57\n",
      " Regression with ARIMA(0,1,0) errors : -14088.54\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14155.6\n",
      " Regression with ARIMA(3,1,2) errors : -14153.06\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : -14177.73\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14178.44\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14179.86\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14181.4\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14179.99\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14166.32\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14097.6\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14074.57\n",
      " Regression with ARIMA(1,1,0) errors : -14071.57\n",
      " Regression with ARIMA(0,1,1) errors : -14072.57\n",
      " Regression with ARIMA(0,1,0) errors : -14076.57\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14085.63\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14156.68\n",
      " Regression with ARIMA(0,0,0) errors : -10543.02\n",
      " Regression with ARIMA(1,0,0) errors : -14157.58\n",
      " Regression with ARIMA(0,0,1) errors : -12288.52\n",
      " Regression with ARIMA(0,0,0) errors : -9161.948\n",
      " Regression with ARIMA(2,0,0) errors : -14160.85\n",
      " Regression with ARIMA(3,0,0) errors : -14159.41\n",
      " Regression with ARIMA(2,0,1) errors : -14158.76\n",
      " Regression with ARIMA(1,0,1) errors : -14161.58\n",
      " Regression with ARIMA(1,0,2) errors : -14159.57\n",
      " Regression with ARIMA(0,0,2) errors : -13166.06\n",
      " Regression with ARIMA(1,0,1) errors : -14036.84\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14160.49\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14097.59\n",
      " Regression with ARIMA(0,0,0) errors : -10474.05\n",
      " Regression with ARIMA(1,0,0) errors : -14096.1\n",
      " Regression with ARIMA(0,0,1) errors : -12234.47\n",
      " Regression with ARIMA(0,0,0) errors : -9152.683\n",
      " Regression with ARIMA(1,0,2) errors : -14099.35\n",
      " Regression with ARIMA(0,0,2) errors : -13115.29\n",
      " Regression with ARIMA(1,0,1) errors : -14101.37\n",
      " Regression with ARIMA(2,0,1) errors : -14098.29\n",
      " Regression with ARIMA(2,0,0) errors : -14100.36\n",
      " Regression with ARIMA(1,0,1) errors : -13962.68\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14100.49\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13956.34\n",
      " Regression with ARIMA(1,1,0) errors : -13954.24\n",
      " Regression with ARIMA(0,1,1) errors : -13954.58\n",
      " Regression with ARIMA(0,1,0) errors : -13958.35\n",
      " Regression with ARIMA(1,1,1) errors : -13952.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13967.35\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13942.25\n",
      " Regression with ARIMA(1,1,0) errors : -13939.51\n",
      " Regression with ARIMA(0,1,1) errors : -13940.54\n",
      " Regression with ARIMA(0,1,0) errors : -13944.26\n",
      " Regression with ARIMA(1,1,1) errors : -13938.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13953.25\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14057.56\n",
      " Regression with ARIMA(0,0,0) errors : -10451.94\n",
      " Regression with ARIMA(1,0,0) errors : -14055.02\n",
      " Regression with ARIMA(0,0,1) errors : -12212.26\n",
      " Regression with ARIMA(0,0,0) errors : -9125.585\n",
      " Regression with ARIMA(1,0,2) errors : -14059.61\n",
      " Regression with ARIMA(0,0,2) errors : -13092.48\n",
      " Regression with ARIMA(1,0,1) errors : -14061.59\n",
      " Regression with ARIMA(2,0,1) errors : -14058.81\n",
      " Regression with ARIMA(2,0,0) errors : -14060.82\n",
      " Regression with ARIMA(1,0,1) errors : -13926.65\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14060.43\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14049.73\n",
      " Regression with ARIMA(0,0,0) errors : -10463.36\n",
      " Regression with ARIMA(1,0,0) errors : -14047.15\n",
      " Regression with ARIMA(0,0,1) errors : -12215.94\n",
      " Regression with ARIMA(0,0,0) errors : -9113.651\n",
      " Regression with ARIMA(1,0,2) errors : -14050.93\n",
      " Regression with ARIMA(0,0,2) errors : -13088.83\n",
      " Regression with ARIMA(1,0,1) errors : -14052.85\n",
      " Regression with ARIMA(2,0,1) errors : -14049.93\n",
      " Regression with ARIMA(2,0,0) errors : -14051.82\n",
      " Regression with ARIMA(1,0,1) errors : -13912.48\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14051.09\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13911.02\n",
      " Regression with ARIMA(1,1,0) errors : -13908.48\n",
      " Regression with ARIMA(0,1,1) errors : -13909.2\n",
      " Regression with ARIMA(0,1,0) errors : -13913.03\n",
      " Regression with ARIMA(1,1,1) errors : -13907.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13922.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13900.07\n",
      " Regression with ARIMA(1,1,0) errors : -13897.25\n",
      " Regression with ARIMA(0,1,1) errors : -13898.14\n",
      " Regression with ARIMA(0,1,0) errors : -13902.07\n",
      " Regression with ARIMA(1,1,1) errors : -13896.05\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13911.05\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13876.42\n",
      " Regression with ARIMA(0,1,0) errors : -13873.69\n",
      " Regression with ARIMA(1,1,0) errors : -13870.8\n",
      " Regression with ARIMA(0,1,1) errors : -13871.79\n",
      " Regression with ARIMA(0,1,0) errors : -13875.69\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -13951.7\n",
      " Regression with ARIMA(1,1,1) errors : -13869.75\n",
      " Regression with ARIMA(2,1,0) errors : -13877.74\n",
      " Regression with ARIMA(3,1,1) errors : -13879.69\n",
      " Regression with ARIMA(3,1,0) errors : -13878.26\n",
      " Regression with ARIMA(3,1,2) errors : -13880.96\n",
      " Regression with ARIMA(2,1,1) errors : -13953.47\n",
      " Regression with ARIMA(1,1,1) errors : -13871.73\n",
      " Regression with ARIMA(2,1,0) errors : -13879.75\n",
      " Regression with ARIMA(3,1,1) errors : -13881.7\n",
      " Regression with ARIMA(2,1,2) errors : -13878.44\n",
      " Regression with ARIMA(1,1,0) errors : -13872.8\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -13880.27\n",
      " Regression with ARIMA(3,1,2) errors : -13883\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -13906.38\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13861.23\n",
      " Regression with ARIMA(1,1,0) errors : -13858.29\n",
      " Regression with ARIMA(0,1,1) errors : -13859.25\n",
      " Regression with ARIMA(0,1,0) errors : -13863.23\n",
      " Regression with ARIMA(1,1,1) errors : -13857.3\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13872.19\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13896.9\n",
      " Regression with ARIMA(0,0,0) errors : -10196.26\n",
      " Regression with ARIMA(1,0,0) errors : -13893.1\n",
      " Regression with ARIMA(0,0,1) errors : -11966.99\n",
      " Regression with ARIMA(0,0,0) errors : -8742.913\n",
      " Regression with ARIMA(1,0,2) errors : -13897.42\n",
      " Regression with ARIMA(0,0,2) errors : -12878.36\n",
      " Regression with ARIMA(1,0,1) errors : -13899.18\n",
      " Regression with ARIMA(2,0,1) errors : -13896.32\n",
      " Regression with ARIMA(2,0,0) errors : -13897.97\n",
      " Regression with ARIMA(1,0,1) errors : -13775.62\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13898.36\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13779.66\n",
      " Regression with ARIMA(0,0,0) errors : -10097.98\n",
      " Regression with ARIMA(1,0,0) errors : -13771.91\n",
      " Regression with ARIMA(0,0,1) errors : -11865.72\n",
      " Regression with ARIMA(0,0,0) errors : -8710.896\n",
      " Regression with ARIMA(1,0,2) errors : -13777.93\n",
      " Regression with ARIMA(2,0,1) errors : -13777.15\n",
      " Regression with ARIMA(3,0,2) errors : -13783.79\n",
      " Regression with ARIMA(3,0,1) errors : -13778.18\n",
      " Regression with ARIMA(4,0,2) errors : -13782.79\n",
      " Regression with ARIMA(3,0,3) errors : -13790.74\n",
      " Regression with ARIMA(2,0,3) errors : -13778.27\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13781.06\n",
      " Regression with ARIMA(2,0,4) errors : -13781.18\n",
      " Regression with ARIMA(4,0,4) errors : -13783.64\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,3) errors : -13791.61\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13736.94\n",
      " Regression with ARIMA(0,0,0) errors : -10002.66\n",
      " Regression with ARIMA(1,0,0) errors : -13730.41\n",
      " Regression with ARIMA(0,0,1) errors : -11778.89\n",
      " Regression with ARIMA(0,0,0) errors : -8620.765\n",
      " Regression with ARIMA(1,0,2) errors : -13736.26\n",
      " Regression with ARIMA(2,0,1) errors : -13735.25\n",
      " Regression with ARIMA(3,0,2) errors : -13738.48\n",
      " Regression with ARIMA(3,0,1) errors : -13735.53\n",
      " Regression with ARIMA(4,0,2) errors : -13732.51\n",
      " Regression with ARIMA(3,0,3) errors : -13747.21\n",
      " Regression with ARIMA(2,0,3) errors : -13735.02\n",
      " Regression with ARIMA(4,0,3) errors : -13743.42\n",
      " Regression with ARIMA(3,0,4) errors : -13736.01\n",
      " Regression with ARIMA(2,0,4) errors : -13737.88\n",
      " Regression with ARIMA(4,0,4) errors : -13742.31\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,3) errors : -13748.29\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13671.5\n",
      " Regression with ARIMA(0,0,0) errors : -9894.943\n",
      " Regression with ARIMA(1,0,0) errors : -13665.86\n",
      " Regression with ARIMA(0,0,1) errors : -11694.71\n",
      " Regression with ARIMA(0,0,0) errors : -8560.227\n",
      " Regression with ARIMA(1,0,2) errors : -13672.38\n",
      " Regression with ARIMA(0,0,2) errors : -12612.9\n",
      " Regression with ARIMA(1,0,1) errors : -13674.2\n",
      " Regression with ARIMA(2,0,1) errors : -13671.58\n",
      " Regression with ARIMA(2,0,0) errors : -13673.48\n",
      " Regression with ARIMA(1,0,1) errors : -13559.42\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13673.28\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13629.1\n",
      " Regression with ARIMA(0,0,0) errors : -9878.792\n",
      " Regression with ARIMA(1,0,0) errors : -13624.85\n",
      " Regression with ARIMA(0,0,1) errors : -11666.73\n",
      " Regression with ARIMA(0,0,0) errors : -8556.701\n",
      " Regression with ARIMA(1,0,2) errors : -13629.96\n",
      " Regression with ARIMA(0,0,2) errors : -12579.75\n",
      " Regression with ARIMA(1,0,1) errors : -13631.19\n",
      " Regression with ARIMA(2,0,1) errors : -13629.28\n",
      " Regression with ARIMA(2,0,0) errors : -13630.88\n",
      " Regression with ARIMA(1,0,1) errors : -13512.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13630.37\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13611.31\n",
      " Regression with ARIMA(0,0,0) errors : -9870.771\n",
      " Regression with ARIMA(1,0,0) errors : -13607.01\n",
      " Regression with ARIMA(0,0,1) errors : -11652.28\n",
      " Regression with ARIMA(0,0,0) errors : -8549.922\n",
      " Regression with ARIMA(1,0,2) errors : -13611.78\n",
      " Regression with ARIMA(0,0,2) errors : -12567.48\n",
      " Regression with ARIMA(1,0,1) errors : -13612.86\n",
      " Regression with ARIMA(2,0,1) errors : -13620.17\n",
      " Regression with ARIMA(2,0,0) errors : -13612.21\n",
      " Regression with ARIMA(3,0,1) errors : -13610.14\n",
      " Regression with ARIMA(3,0,0) errors : -13609.99\n",
      " Regression with ARIMA(3,0,2) errors : -13609.53\n",
      " Regression with ARIMA(2,0,1) errors : -13511.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13612.06\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13585.71\n",
      " Regression with ARIMA(0,0,0) errors : -9844.615\n",
      " Regression with ARIMA(1,0,0) errors : -13581.02\n",
      " Regression with ARIMA(0,0,1) errors : -11622.06\n",
      " Regression with ARIMA(0,0,0) errors : -8510.432\n",
      " Regression with ARIMA(1,0,2) errors : -13586.32\n",
      " Regression with ARIMA(0,0,2) errors : -12543.41\n",
      " Regression with ARIMA(1,0,1) errors : -13587.02\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -13586.54\n",
      " Regression with ARIMA(1,0,1) errors : -13475.64\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13585.99\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13574.71\n",
      " Regression with ARIMA(0,0,0) errors : -9826.549\n",
      " Regression with ARIMA(1,0,0) errors : -13570.27\n",
      " Regression with ARIMA(0,0,1) errors : -11609.5\n",
      " Regression with ARIMA(0,0,0) errors : -8481.914\n",
      " Regression with ARIMA(1,0,2) errors : -13575.26\n",
      " Regression with ARIMA(0,0,2) errors : -12534.01\n",
      " Regression with ARIMA(1,0,1) errors : -13576.15\n",
      " Regression with ARIMA(2,0,1) errors : -13583.87\n",
      " Regression with ARIMA(2,0,0) errors : -13575.76\n",
      " Regression with ARIMA(3,0,1) errors : -13573.56\n",
      " Regression with ARIMA(3,0,0) errors : -13574.15\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13575.33\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13420.85\n",
      " Regression with ARIMA(1,1,0) errors : -13418.28\n",
      " Regression with ARIMA(0,1,1) errors : -13419.05\n",
      " Regression with ARIMA(0,1,0) errors : -13422.86\n",
      " Regression with ARIMA(1,1,1) errors : -13416.27\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13431.63\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13406.54\n",
      " Regression with ARIMA(1,1,0) errors : -13403.97\n",
      " Regression with ARIMA(0,1,1) errors : -13404.69\n",
      " Regression with ARIMA(0,1,0) errors : -13408.55\n",
      " Regression with ARIMA(1,1,1) errors : -13401.96\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13417.31\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13398.85\n",
      " Regression with ARIMA(1,1,0) errors : -13397.03\n",
      " Regression with ARIMA(0,1,1) errors : -13396.96\n",
      " Regression with ARIMA(0,1,0) errors : -13400.86\n",
      " Regression with ARIMA(1,1,1) errors : -13395.03\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13409.61\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13388.05\n",
      " Regression with ARIMA(1,1,0) errors : -13385.34\n",
      " Regression with ARIMA(0,1,1) errors : -13386.18\n",
      " Regression with ARIMA(0,1,0) errors : -13390.05\n",
      " Regression with ARIMA(1,1,1) errors : -13383.59\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13398.81\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13385.45\n",
      " Regression with ARIMA(1,1,0) errors : -13382.92\n",
      " Regression with ARIMA(0,1,1) errors : -13383.57\n",
      " Regression with ARIMA(0,1,0) errors : -13387.46\n",
      " Regression with ARIMA(1,1,1) errors : -13380.91\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13396.21\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13381.56\n",
      " Regression with ARIMA(1,1,0) errors : -13380.11\n",
      " Regression with ARIMA(0,1,1) errors : -13379.6\n",
      " Regression with ARIMA(0,1,0) errors : -13383.57\n",
      " Regression with ARIMA(1,1,1) errors : -13378.27\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13392.32\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13382.25\n",
      " Regression with ARIMA(1,1,0) errors : -13380.87\n",
      " Regression with ARIMA(0,1,1) errors : -13380.28\n",
      " Regression with ARIMA(0,1,0) errors : -13384.26\n",
      " Regression with ARIMA(1,1,1) errors : -13379.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13393.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13380.14\n",
      " Regression with ARIMA(1,1,0) errors : -13377.47\n",
      " Regression with ARIMA(0,1,1) errors : -13378.15\n",
      " Regression with ARIMA(0,1,0) errors : -13382.15\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.9\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13378.91\n",
      " Regression with ARIMA(1,1,0) errors : -13377.73\n",
      " Regression with ARIMA(0,1,1) errors : -13376.9\n",
      " Regression with ARIMA(0,1,0) errors : -13380.91\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13389.66\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13379.35\n",
      " Regression with ARIMA(1,1,0) errors : -13377.78\n",
      " Regression with ARIMA(0,1,1) errors : -13377.34\n",
      " Regression with ARIMA(0,1,0) errors : -13381.35\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.1\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13379.9\n",
      " Regression with ARIMA(1,1,0) errors : -13377.2\n",
      " Regression with ARIMA(0,1,1) errors : -13377.89\n",
      " Regression with ARIMA(0,1,0) errors : -13381.91\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.66\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13381.25\n",
      " Regression with ARIMA(1,1,0) errors : -13378.41\n",
      " Regression with ARIMA(0,1,1) errors : -13379.25\n",
      " Regression with ARIMA(0,1,0) errors : -13383.26\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13392.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13376.01\n",
      " Regression with ARIMA(1,1,0) errors : -13373.65\n",
      " Regression with ARIMA(0,1,1) errors : -13374\n",
      " Regression with ARIMA(0,1,0) errors : -13378.02\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13386.77\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13369.58\n",
      " Regression with ARIMA(1,1,0) errors : -13366.83\n",
      " Regression with ARIMA(0,1,1) errors : -13367.57\n",
      " Regression with ARIMA(0,1,0) errors : -13371.59\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13380.33\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13497.89\n",
      " Regression with ARIMA(0,0,0) errors : -9950.123\n",
      " Regression with ARIMA(1,0,0) errors : -13493.27\n",
      " Regression with ARIMA(0,0,1) errors : -11642.05\n",
      " Regression with ARIMA(0,0,0) errors : -8458.864\n",
      " Regression with ARIMA(1,0,2) errors : -13494.53\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -13496.04\n",
      " Regression with ARIMA(1,0,1) errors : -13495.7\n",
      " Regression with ARIMA(1,0,3) errors : -13492.7\n",
      " Regression with ARIMA(3,0,1) errors : -13497.36\n",
      " Regression with ARIMA(3,0,3) errors : -13498.01\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13507.72\n",
      " Regression with ARIMA(2,0,4) errors : -13500.47\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13500.7\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13506.03\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13499.98\n",
      " Regression with ARIMA(0,0,0) errors : -9960.775\n",
      " Regression with ARIMA(1,0,0) errors : -13495.47\n",
      " Regression with ARIMA(0,0,1) errors : -11645.81\n",
      " Regression with ARIMA(0,0,0) errors : -8453.629\n",
      " Regression with ARIMA(1,0,2) errors : -13496.49\n",
      " Regression with ARIMA(2,0,1) errors : -13507.19\n",
      " Regression with ARIMA(1,0,1) errors : -13497.52\n",
      " Regression with ARIMA(2,0,0) errors : -13496.74\n",
      " Regression with ARIMA(3,0,1) errors : -13497.31\n",
      " Regression with ARIMA(3,0,0) errors : -13495.2\n",
      " Regression with ARIMA(3,0,2) errors : -13495.71\n",
      " Regression with ARIMA(2,0,1) errors : -13378.82\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13506.74\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13497.77\n",
      " Regression with ARIMA(0,0,0) errors : -9958.269\n",
      " Regression with ARIMA(1,0,0) errors : -13494.31\n",
      " Regression with ARIMA(0,0,1) errors : -11644.45\n",
      " Regression with ARIMA(0,0,0) errors : -8449.905\n",
      " Regression with ARIMA(1,0,2) errors : -13495.3\n",
      " Regression with ARIMA(2,0,1) errors : -13507.9\n",
      " Regression with ARIMA(1,0,1) errors : -13496.33\n",
      " Regression with ARIMA(2,0,0) errors : -13495.6\n",
      " Regression with ARIMA(3,0,1) errors : -13496.54\n",
      " Regression with ARIMA(3,0,0) errors : -13493.75\n",
      " Regression with ARIMA(3,0,2) errors : -13495.71\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13508.08\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13493.96\n",
      " Regression with ARIMA(0,0,0) errors : -9977.205\n",
      " Regression with ARIMA(1,0,0) errors : -13489.97\n",
      " Regression with ARIMA(0,0,1) errors : -11647.24\n",
      " Regression with ARIMA(0,0,0) errors : -8450.876\n",
      " Regression with ARIMA(1,0,2) errors : -13490.98\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13488.95\n",
      " Regression with ARIMA(2,0,3) errors : -13487.5\n",
      " Regression with ARIMA(1,0,1) errors : -13492.01\n",
      " Regression with ARIMA(1,0,3) errors : -13489.23\n",
      " Regression with ARIMA(3,0,1) errors : -13492.37\n",
      " Regression with ARIMA(3,0,3) errors : -13486.94\n",
      " Regression with ARIMA(2,0,2) errors : -13356.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.62\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.03\n",
      " Regression with ARIMA(0,0,0) errors : -10035.28\n",
      " Regression with ARIMA(1,0,0) errors : -13487.39\n",
      " Regression with ARIMA(0,0,1) errors : -11673.35\n",
      " Regression with ARIMA(0,0,0) errors : -8457.324\n",
      " Regression with ARIMA(1,0,2) errors : -13488\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13489.24\n",
      " Regression with ARIMA(2,0,3) errors : -13489.21\n",
      " Regression with ARIMA(1,0,1) errors : -13488.93\n",
      " Regression with ARIMA(1,0,3) errors : -13486.24\n",
      " Regression with ARIMA(3,0,1) errors : -13491.09\n",
      " Regression with ARIMA(3,0,0) errors : -13487.21\n",
      " Regression with ARIMA(4,0,1) errors : -13487.57\n",
      " Regression with ARIMA(2,0,0) errors : -13488.97\n",
      " Regression with ARIMA(4,0,0) errors : -13485.19\n",
      " Regression with ARIMA(4,0,2) errors : -13498.14\n",
      " Regression with ARIMA(5,0,2) errors : -13499.05\n",
      " Regression with ARIMA(5,0,1) errors : -13492.88\n",
      " Regression with ARIMA(5,0,3) errors : -13497.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13501.63\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.2\n",
      " Regression with ARIMA(0,0,0) errors : -10019.33\n",
      " Regression with ARIMA(1,0,0) errors : -13487.57\n",
      " Regression with ARIMA(0,0,1) errors : -11667.27\n",
      " Regression with ARIMA(0,0,0) errors : -8455.887\n",
      " Regression with ARIMA(1,0,2) errors : -13488.56\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13489.44\n",
      " Regression with ARIMA(2,0,3) errors : -13490.16\n",
      " Regression with ARIMA(1,0,1) errors : -13489.31\n",
      " Regression with ARIMA(1,0,3) errors : -13486.85\n",
      " Regression with ARIMA(3,0,1) errors : -13491.32\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13350.82\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.68\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13489.2\n",
      " Regression with ARIMA(0,0,0) errors : -10028.88\n",
      " Regression with ARIMA(1,0,0) errors : -13485\n",
      " Regression with ARIMA(0,0,1) errors : -11673.96\n",
      " Regression with ARIMA(0,0,0) errors : -8443.256\n",
      " Regression with ARIMA(1,0,2) errors : -13486.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -13487.2\n",
      " Regression with ARIMA(1,0,1) errors : -13487.01\n",
      " Regression with ARIMA(1,0,3) errors : -13484.63\n",
      " Regression with ARIMA(3,0,1) errors : -13491.48\n",
      " Regression with ARIMA(3,0,0) errors : -13487\n",
      " Regression with ARIMA(4,0,1) errors : -13489.1\n",
      " Regression with ARIMA(2,0,0) errors : -13486.23\n",
      " Regression with ARIMA(4,0,0) errors : -13484.88\n",
      " Regression with ARIMA(4,0,2) errors : -13500.18\n",
      " Regression with ARIMA(5,0,2) errors : -13502.09\n",
      " Regression with ARIMA(5,0,1) errors : -13494.32\n",
      " Regression with ARIMA(5,0,3) errors : -13500.12\n",
      " Regression with ARIMA(4,0,3) errors : -13500.55\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13500.88\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492\n",
      " Regression with ARIMA(0,0,0) errors : -10028.08\n",
      " Regression with ARIMA(1,0,0) errors : -13487.35\n",
      " Regression with ARIMA(0,0,1) errors : -11679.14\n",
      " Regression with ARIMA(0,0,0) errors : -8442.705\n",
      " Regression with ARIMA(1,0,2) errors : -13488.66\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13487.58\n",
      " Regression with ARIMA(2,0,3) errors : -13489.99\n",
      " Regression with ARIMA(1,0,1) errors : -13489.51\n",
      " Regression with ARIMA(1,0,3) errors : -13487.09\n",
      " Regression with ARIMA(3,0,1) errors : -13489.86\n",
      " Regression with ARIMA(3,0,3) errors : -13482.34\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.71\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13496.48\n",
      " Regression with ARIMA(0,0,0) errors : -10046.87\n",
      " Regression with ARIMA(1,0,0) errors : -13491.11\n",
      " Regression with ARIMA(0,0,1) errors : -11686.59\n",
      " Regression with ARIMA(0,0,0) errors : -8439.819\n",
      " Regression with ARIMA(1,0,2) errors : -13492.36\n",
      " Regression with ARIMA(2,0,1) errors : -13506.72\n",
      " Regression with ARIMA(1,0,1) errors : -13493.26\n",
      " Regression with ARIMA(2,0,0) errors : -13492.87\n",
      " Regression with ARIMA(3,0,1) errors : -13494.79\n",
      " Regression with ARIMA(3,0,0) errors : -13491.08\n",
      " Regression with ARIMA(3,0,2) errors : -13506.27\n",
      " Regression with ARIMA(2,0,1) errors : -13358.47\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13505.42\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.02\n",
      " Regression with ARIMA(0,0,0) errors : -10051.63\n",
      " Regression with ARIMA(1,0,0) errors : -13487.72\n",
      " Regression with ARIMA(0,0,1) errors : -11688.79\n",
      " Regression with ARIMA(0,0,0) errors : -8460.12\n",
      " Regression with ARIMA(1,0,2) errors : -13489\n",
      " Regression with ARIMA(2,0,1) errors : -13501\n",
      " Regression with ARIMA(1,0,1) errors : -13489.93\n",
      " Regression with ARIMA(2,0,0) errors : -13489.16\n",
      " Regression with ARIMA(3,0,1) errors : -13490.72\n",
      " Regression with ARIMA(3,0,0) errors : -13487.43\n",
      " Regression with ARIMA(3,0,2) errors : -13488.68\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13501.14\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13500.43\n",
      " Regression with ARIMA(0,0,0) errors : -10047.97\n",
      " Regression with ARIMA(1,0,0) errors : -13495.4\n",
      " Regression with ARIMA(0,0,1) errors : -11686.73\n",
      " Regression with ARIMA(0,0,0) errors : -8459.472\n",
      " Regression with ARIMA(1,0,2) errors : -13496.66\n",
      " Regression with ARIMA(2,0,1) errors : -13510.38\n",
      " Regression with ARIMA(1,0,1) errors : -13497.58\n",
      " Regression with ARIMA(2,0,0) errors : -13497.07\n",
      " Regression with ARIMA(3,0,1) errors : -13498.19\n",
      " Regression with ARIMA(3,0,0) errors : -13495.29\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13509.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10051.61\n",
      " Regression with ARIMA(1,0,0) errors : -13499.36\n",
      " Regression with ARIMA(0,0,1) errors : -11694.33\n",
      " Regression with ARIMA(0,0,0) errors : -8454.72\n",
      " Regression with ARIMA(2,0,0) errors : -13501.93\n",
      " Regression with ARIMA(3,0,0) errors : -13500.22\n",
      " Regression with ARIMA(2,0,1) errors : -13512.21\n",
      " Regression with ARIMA(1,0,1) errors : -13501.76\n",
      " Regression with ARIMA(3,0,1) errors : -13503.01\n",
      " Regression with ARIMA(1,0,2) errors : -13500.7\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13514.04\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13505.3\n",
      " Regression with ARIMA(0,0,0) errors : -10067.87\n",
      " Regression with ARIMA(1,0,0) errors : -13500.56\n",
      " Regression with ARIMA(0,0,1) errors : -11703.92\n",
      " Regression with ARIMA(0,0,0) errors : -8459.352\n",
      " Regression with ARIMA(1,0,2) errors : -13501.48\n",
      " Regression with ARIMA(2,0,1) errors : -13513.92\n",
      " Regression with ARIMA(1,0,1) errors : -13502.47\n",
      " Regression with ARIMA(2,0,0) errors : -13501.76\n",
      " Regression with ARIMA(3,0,1) errors : -13504.22\n",
      " Regression with ARIMA(3,0,0) errors : -13499.98\n",
      " Regression with ARIMA(3,0,2) errors : -13502.51\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13509.66\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13504.43\n",
      " Regression with ARIMA(0,0,0) errors : -10066.73\n",
      " Regression with ARIMA(1,0,0) errors : -13500.34\n",
      " Regression with ARIMA(0,0,1) errors : -11703.9\n",
      " Regression with ARIMA(0,0,0) errors : -8459.982\n",
      " Regression with ARIMA(1,0,2) errors : -13501.46\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13502.1\n",
      " Regression with ARIMA(2,0,3) errors : -13502.47\n",
      " Regression with ARIMA(1,0,1) errors : -13502.43\n",
      " Regression with ARIMA(1,0,3) errors : -13499.75\n",
      " Regression with ARIMA(3,0,1) errors : -13504.38\n",
      " Regression with ARIMA(3,0,3) errors : -13511.67\n",
      " Regression with ARIMA(4,0,3) errors : -13502.32\n",
      " Regression with ARIMA(3,0,4) errors : -13513.38\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -13510.29\n",
      " Regression with ARIMA(3,0,5) errors : -13505.27\n",
      " Regression with ARIMA(2,0,5) errors : -13506.32\n",
      " Regression with ARIMA(4,0,5) errors : -13507.77\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13512.15\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13504.84\n",
      " Regression with ARIMA(0,0,0) errors : -10082.23\n",
      " Regression with ARIMA(1,0,0) errors : -13499.69\n",
      " Regression with ARIMA(0,0,1) errors : -11711.37\n",
      " Regression with ARIMA(0,0,0) errors : -8482.428\n",
      " Regression with ARIMA(1,0,2) errors : -13500.44\n",
      " Regression with ARIMA(2,0,1) errors : -13506.21\n",
      " Regression with ARIMA(1,0,1) errors : -13501.67\n",
      " Regression with ARIMA(2,0,0) errors : -13507.48\n",
      " Regression with ARIMA(3,0,0) errors : -13505.43\n",
      " Regression with ARIMA(3,0,1) errors : -13508.06\n",
      " Regression with ARIMA(4,0,1) errors : -13504.51\n",
      " Regression with ARIMA(3,0,2) errors : -13507\n",
      " Regression with ARIMA(4,0,0) errors : -13503.26\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -13503.39\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13511.77\n",
      " Regression with ARIMA(0,0,0) errors : -10089.38\n",
      " Regression with ARIMA(1,0,0) errors : -13508.45\n",
      " Regression with ARIMA(0,0,1) errors : -11717.82\n",
      " Regression with ARIMA(0,0,0) errors : -8486.146\n",
      " Regression with ARIMA(1,0,2) errors : -13508.73\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13508.14\n",
      " Regression with ARIMA(2,0,3) errors : -13509.84\n",
      " Regression with ARIMA(1,0,1) errors : -13509.99\n",
      " Regression with ARIMA(1,0,3) errors : -13507.09\n",
      " Regression with ARIMA(3,0,1) errors : -13509.92\n",
      " Regression with ARIMA(3,0,3) errors : -13517.49\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13519.73\n",
      " Regression with ARIMA(2,0,4) errors : -13513.32\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13514.28\n",
      " Regression with ARIMA(4,0,5) errors : -13514.96\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13520.01\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13510.51\n",
      " Regression with ARIMA(0,0,0) errors : -10105.18\n",
      " Regression with ARIMA(1,0,0) errors : -13507.88\n",
      " Regression with ARIMA(0,0,1) errors : -11721.86\n",
      " Regression with ARIMA(0,0,0) errors : -8493.114\n",
      " Regression with ARIMA(1,0,2) errors : -13508.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13516.56\n",
      " Regression with ARIMA(3,0,1) errors : -13506.85\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13515.63\n",
      " Regression with ARIMA(2,0,3) errors : -13508.55\n",
      " Regression with ARIMA(4,0,1) errors : -13509.07\n",
      " Regression with ARIMA(4,0,3) errors : -13513.32\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13519.6\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13508.31\n",
      " Regression with ARIMA(0,0,0) errors : -10126.55\n",
      " Regression with ARIMA(1,0,0) errors : -13507.44\n",
      " Regression with ARIMA(0,0,1) errors : -11732.75\n",
      " Regression with ARIMA(0,0,0) errors : -8479.726\n",
      " Regression with ARIMA(1,0,2) errors : -13507.67\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13508.26\n",
      " Regression with ARIMA(2,0,3) errors : -13506.52\n",
      " Regression with ARIMA(1,0,1) errors : -13508.92\n",
      " Regression with ARIMA(0,0,2) errors : -12538.44\n",
      " Regression with ARIMA(2,0,0) errors : -13508.97\n",
      " Regression with ARIMA(3,0,0) errors : -13506.81\n",
      " Regression with ARIMA(3,0,1) errors : -13510.29\n",
      " Regression with ARIMA(4,0,1) errors : -13507.38\n",
      " Regression with ARIMA(4,0,0) errors : -13504.51\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -13510.44\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10215.23\n",
      " Regression with ARIMA(1,0,0) errors : -13503.24\n",
      " Regression with ARIMA(0,0,1) errors : -11765.85\n",
      " Regression with ARIMA(0,0,0) errors : -8496.584\n",
      " Regression with ARIMA(2,0,0) errors : -13503.84\n",
      " Regression with ARIMA(3,0,0) errors : -13502.9\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13504.35\n",
      " Regression with ARIMA(1,0,2) errors : -13503.03\n",
      " Regression with ARIMA(0,0,2) errors : -12548.3\n",
      " Regression with ARIMA(1,0,1) errors : -13380.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13503.51\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10218.34\n",
      " Regression with ARIMA(1,0,0) errors : -13503.41\n",
      " Regression with ARIMA(0,0,1) errors : -11768.16\n",
      " Regression with ARIMA(0,0,0) errors : -8499.03\n",
      " Regression with ARIMA(2,0,0) errors : -13503.77\n",
      " Regression with ARIMA(3,0,0) errors : -13502.7\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13504.25\n",
      " Regression with ARIMA(1,0,2) errors : -13502.87\n",
      " Regression with ARIMA(0,0,2) errors : -12542.4\n",
      " Regression with ARIMA(1,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13503.42\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13509.32\n",
      " Regression with ARIMA(0,0,0) errors : -10219.25\n",
      " Regression with ARIMA(1,0,0) errors : -13507.76\n",
      " Regression with ARIMA(0,0,1) errors : -11765.04\n",
      " Regression with ARIMA(0,0,0) errors : -8502.109\n",
      " Regression with ARIMA(1,0,2) errors : -13506.99\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13502.83\n",
      " Regression with ARIMA(2,0,3) errors : -13507.36\n",
      " Regression with ARIMA(1,0,1) errors : -13508.29\n",
      " Regression with ARIMA(1,0,3) errors : -13505.45\n",
      " Regression with ARIMA(3,0,1) errors : -13506.88\n",
      " Regression with ARIMA(3,0,3) errors : -13513.93\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13514.85\n",
      " Regression with ARIMA(2,0,4) errors : -13509.02\n",
      " Regression with ARIMA(4,0,4) errors : -13512.96\n",
      " Regression with ARIMA(3,0,5) errors : -13508.01\n",
      " Regression with ARIMA(2,0,5) errors : -13510.83\n",
      " Regression with ARIMA(4,0,5) errors : -13505.08\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13517.28\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10222.58\n",
      " Regression with ARIMA(1,0,0) errors : -13506.49\n",
      " Regression with ARIMA(0,0,1) errors : -11761.77\n",
      " Regression with ARIMA(0,0,0) errors : -8501.931\n",
      " Regression with ARIMA(2,0,0) errors : -13505.83\n",
      " Regression with ARIMA(1,0,1) errors : -13506.71\n",
      " Regression with ARIMA(2,0,1) errors : -13516.88\n",
      " Regression with ARIMA(3,0,1) errors : -13512.26\n",
      " Regression with ARIMA(1,0,2) errors : -13505.56\n",
      " Regression with ARIMA(3,0,0) errors : -13505.02\n",
      " Regression with ARIMA(3,0,2) errors : -13499.27\n",
      " Regression with ARIMA(2,0,1) errors : -13367.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13503.41\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13512.51\n",
      " Regression with ARIMA(0,0,0) errors : -10227.27\n",
      " Regression with ARIMA(1,0,0) errors : -13513.98\n",
      " Regression with ARIMA(0,0,1) errors : -11762.97\n",
      " Regression with ARIMA(0,0,0) errors : -8502.27\n",
      " Regression with ARIMA(2,0,0) errors : -13514.25\n",
      " Regression with ARIMA(3,0,0) errors : -13513.04\n",
      " Regression with ARIMA(2,0,1) errors : -13512.24\n",
      " Regression with ARIMA(1,0,1) errors : -13514.02\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -13380.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,0) errors : -13511.98\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13526.34\n",
      " Regression with ARIMA(0,0,0) errors : -10223.66\n",
      " Regression with ARIMA(1,0,0) errors : -13526.45\n",
      " Regression with ARIMA(0,0,1) errors : -11757.01\n",
      " Regression with ARIMA(0,0,0) errors : -8519.276\n",
      " Regression with ARIMA(2,0,0) errors : -13525.32\n",
      " Regression with ARIMA(1,0,1) errors : -13526.23\n",
      " Regression with ARIMA(2,0,1) errors : -13535.26\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13525.01\n",
      " Regression with ARIMA(3,0,0) errors : -13523.41\n",
      " Regression with ARIMA(3,0,2) errors : -13520.69\n",
      " Regression with ARIMA(2,0,1) errors : -13408.03\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13521.31\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10227.11\n",
      " Regression with ARIMA(1,0,0) errors : -13535.83\n",
      " Regression with ARIMA(0,0,1) errors : -11776.31\n",
      " Regression with ARIMA(0,0,0) errors : -8558.409\n",
      " Regression with ARIMA(2,0,0) errors : -13535.04\n",
      " Regression with ARIMA(1,0,1) errors : -13535.63\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13535.07\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10239.17\n",
      " Regression with ARIMA(1,0,0) errors : -13532.83\n",
      " Regression with ARIMA(0,0,1) errors : -11782.72\n",
      " Regression with ARIMA(0,0,0) errors : -8566.374\n",
      " Regression with ARIMA(2,0,0) errors : -13533.02\n",
      " Regression with ARIMA(3,0,0) errors : -13531.58\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13532.77\n",
      " Regression with ARIMA(3,0,1) errors : -13532.73\n",
      " Regression with ARIMA(2,0,0) errors : -13415.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,0) errors : -13531.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13539.55\n",
      " Regression with ARIMA(0,0,0) errors : -10238.93\n",
      " Regression with ARIMA(1,0,0) errors : -13540.07\n",
      " Regression with ARIMA(0,0,1) errors : -11784.97\n",
      " Regression with ARIMA(0,0,0) errors : -8571.174\n",
      " Regression with ARIMA(2,0,0) errors : -13539.5\n",
      " Regression with ARIMA(1,0,1) errors : -13540.16\n",
      " Regression with ARIMA(2,0,1) errors : -13549.2\n",
      " Regression with ARIMA(3,0,1) errors : -13539.61\n",
      " Regression with ARIMA(1,0,2) errors : -13539.06\n",
      " Regression with ARIMA(3,0,0) errors : -13537.64\n",
      " Regression with ARIMA(3,0,2) errors : -13537.96\n",
      " Regression with ARIMA(2,0,1) errors : -13400.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13550.1\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13537.09\n",
      " Regression with ARIMA(0,0,0) errors : -10239.99\n",
      " Regression with ARIMA(1,0,0) errors : -13540.98\n",
      " Regression with ARIMA(0,0,1) errors : -11788.21\n",
      " Regression with ARIMA(0,0,0) errors : -8584.355\n",
      " Regression with ARIMA(2,0,0) errors : -13540.68\n",
      " Regression with ARIMA(1,0,1) errors : -13540.96\n",
      " Regression with ARIMA(2,0,1) errors : -13550.79\n",
      " Regression with ARIMA(3,0,1) errors : -13544.63\n",
      " Regression with ARIMA(1,0,2) errors : -13539.89\n",
      " Regression with ARIMA(3,0,0) errors : -13538.95\n",
      " Regression with ARIMA(3,0,2) errors : -13543.48\n",
      " Regression with ARIMA(2,0,1) errors : -13423.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : -13541.93\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13563.2\n",
      " Regression with ARIMA(0,0,0) errors : -10221.42\n",
      " Regression with ARIMA(1,0,0) errors : -13558.89\n",
      " Regression with ARIMA(0,0,1) errors : -11783.59\n",
      " Regression with ARIMA(0,0,0) errors : -8587.344\n",
      " Regression with ARIMA(1,0,2) errors : -13557.75\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13560.36\n",
      " Regression with ARIMA(2,0,3) errors : -13561.2\n",
      " Regression with ARIMA(1,0,1) errors : -13558.83\n",
      " Regression with ARIMA(1,0,3) errors : -13556.36\n",
      " Regression with ARIMA(3,0,1) errors : -13562.66\n",
      " Regression with ARIMA(3,0,3) errors : -13569.83\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13571.17\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -13563.95\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13566.38\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13567.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13570.4\n",
      " Regression with ARIMA(0,0,0) errors : -10190.39\n",
      " Regression with ARIMA(1,0,0) errors : -13568.75\n",
      " Regression with ARIMA(0,0,1) errors : -11771.15\n",
      " Regression with ARIMA(0,0,0) errors : -8593.643\n",
      " Regression with ARIMA(1,0,2) errors : -13567.8\n",
      " Regression with ARIMA(2,0,1) errors : -13578.25\n",
      " Regression with ARIMA(1,0,1) errors : -13568.87\n",
      " Regression with ARIMA(2,0,0) errors : -13567.98\n",
      " Regression with ARIMA(3,0,1) errors : -13566.18\n",
      " Regression with ARIMA(3,0,0) errors : -13566.18\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : -13449.02\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13568.25\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13634.9\n",
      " Regression with ARIMA(0,0,0) errors : -10190.23\n",
      " Regression with ARIMA(1,0,0) errors : -13630.94\n",
      " Regression with ARIMA(0,0,1) errors : -11790.6\n",
      " Regression with ARIMA(0,0,0) errors : -8611.59\n",
      " Regression with ARIMA(1,0,2) errors : -13631.17\n",
      " Regression with ARIMA(2,0,1) errors : -13641.72\n",
      " Regression with ARIMA(1,0,1) errors : -13631.97\n",
      " Regression with ARIMA(2,0,0) errors : -13632.33\n",
      " Regression with ARIMA(3,0,1) errors : -13630.61\n",
      " Regression with ARIMA(3,0,0) errors : -13630.85\n",
      " Regression with ARIMA(3,0,2) errors : -13642.1\n",
      " Regression with ARIMA(4,0,2) errors : -13636.63\n",
      " Regression with ARIMA(3,0,3) errors : -13640.47\n",
      " Regression with ARIMA(2,0,3) errors : -13632.93\n",
      " Regression with ARIMA(4,0,1) errors : -13631.33\n",
      " Regression with ARIMA(4,0,3) errors : -13636.07\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13640.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13645.23\n",
      " Regression with ARIMA(0,0,0) errors : -10202.47\n",
      " Regression with ARIMA(1,0,0) errors : -13645.74\n",
      " Regression with ARIMA(0,0,1) errors : -11804.3\n",
      " Regression with ARIMA(0,0,0) errors : -8622.517\n",
      " Regression with ARIMA(2,0,0) errors : -13646.54\n",
      " Regression with ARIMA(3,0,0) errors : -13646.95\n",
      " Regression with ARIMA(4,0,0) errors : -13644.57\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -13646.54\n",
      " Regression with ARIMA(3,0,0) errors : -13536.11\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,0) errors : -13645.14\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13662.78\n",
      " Regression with ARIMA(0,0,0) errors : -10203.12\n",
      " Regression with ARIMA(1,0,0) errors : -13661.7\n",
      " Regression with ARIMA(0,0,1) errors : -11801.53\n",
      " Regression with ARIMA(0,0,0) errors : -8623.09\n",
      " Regression with ARIMA(1,0,2) errors : -13661.65\n",
      " Regression with ARIMA(2,0,1) errors : -13670.27\n",
      " Regression with ARIMA(1,0,1) errors : -13662.54\n",
      " Regression with ARIMA(2,0,0) errors : -13662.03\n",
      " Regression with ARIMA(3,0,1) errors : -13660.85\n",
      " Regression with ARIMA(3,0,0) errors : -13660.75\n",
      " Regression with ARIMA(3,0,2) errors : -13668.59\n",
      " Regression with ARIMA(2,0,1) errors : -13554.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13669.89\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13665.71\n",
      " Regression with ARIMA(0,0,0) errors : -10188.87\n",
      " Regression with ARIMA(1,0,0) errors : -13663.7\n",
      " Regression with ARIMA(0,0,1) errors : -11795.42\n",
      " Regression with ARIMA(0,0,0) errors : -8643.892\n",
      " Regression with ARIMA(1,0,2) errors : -13663.8\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13660.35\n",
      " Regression with ARIMA(2,0,3) errors : -13663.69\n",
      " Regression with ARIMA(1,0,1) errors : -13664.64\n",
      " Regression with ARIMA(1,0,3) errors : -13662.17\n",
      " Regression with ARIMA(3,0,1) errors : -13664.67\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13565.22\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13665.83\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13656.64\n",
      " Regression with ARIMA(0,0,0) errors : -10191.97\n",
      " Regression with ARIMA(1,0,0) errors : -13653.06\n",
      " Regression with ARIMA(0,0,1) errors : -11788.05\n",
      " Regression with ARIMA(0,0,0) errors : -8651.602\n",
      " Regression with ARIMA(1,0,2) errors : -13653.54\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13653.21\n",
      " Regression with ARIMA(2,0,3) errors : -13654.62\n",
      " Regression with ARIMA(1,0,1) errors : -13654.33\n",
      " Regression with ARIMA(1,0,3) errors : -13651.95\n",
      " Regression with ARIMA(3,0,1) errors : -13655.42\n",
      " Regression with ARIMA(3,0,3) errors : -13661.07\n",
      " Regression with ARIMA(4,0,3) errors : -13648.86\n",
      " Regression with ARIMA(3,0,4) errors : -13662.96\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13661.06\n",
      " Regression with ARIMA(4,0,5) errors : -13659.57\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13659.73\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13649.41\n",
      " Regression with ARIMA(0,0,0) errors : -10167.99\n",
      " Regression with ARIMA(1,0,0) errors : -13648.99\n",
      " Regression with ARIMA(0,0,1) errors : -11774.26\n",
      " Regression with ARIMA(0,0,0) errors : -8653.868\n",
      " Regression with ARIMA(1,0,2) errors : -13649.56\n",
      " Regression with ARIMA(0,0,2) errors : -12612.9\n",
      " Regression with ARIMA(1,0,1) errors : -13650.24\n",
      " Regression with ARIMA(2,0,1) errors : -13660.4\n",
      " Regression with ARIMA(2,0,0) errors : -13649.71\n",
      " Regression with ARIMA(3,0,1) errors : -13651.41\n",
      " Regression with ARIMA(3,0,0) errors : -13648.4\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13661.18\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13655.63\n",
      " Regression with ARIMA(0,0,0) errors : -10165.57\n",
      " Regression with ARIMA(1,0,0) errors : -13654.18\n",
      " Regression with ARIMA(0,0,1) errors : -11773.14\n",
      " Regression with ARIMA(0,0,0) errors : -8656.522\n",
      " Regression with ARIMA(1,0,2) errors : -13654.42\n",
      " Regression with ARIMA(2,0,1) errors : -13665.49\n",
      " Regression with ARIMA(1,0,1) errors : -13655.18\n",
      " Regression with ARIMA(2,0,0) errors : -13654.5\n",
      " Regression with ARIMA(3,0,1) errors : -13655.23\n",
      " Regression with ARIMA(3,0,0) errors : -13653.04\n",
      " Regression with ARIMA(3,0,2) errors : -13653.31\n",
      " Regression with ARIMA(2,0,1) errors : -13554.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13666.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13657.3\n",
      " Regression with ARIMA(0,0,0) errors : -10165.83\n",
      " Regression with ARIMA(1,0,0) errors : -13655.15\n",
      " Regression with ARIMA(0,0,1) errors : -11771.76\n",
      " Regression with ARIMA(0,0,0) errors : -8655.923\n",
      " Regression with ARIMA(1,0,2) errors : -13655.23\n",
      " Regression with ARIMA(2,0,1) errors : -13667.08\n",
      " Regression with ARIMA(1,0,1) errors : -13656.02\n",
      " Regression with ARIMA(2,0,0) errors : -13655.19\n",
      " Regression with ARIMA(3,0,1) errors : -13655.86\n",
      " Regression with ARIMA(3,0,0) errors : -13658.04\n",
      " Regression with ARIMA(3,0,2) errors : -13655.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13666.52\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13655.6\n",
      " Regression with ARIMA(0,0,0) errors : -10159.47\n",
      " Regression with ARIMA(1,0,0) errors : -13654.74\n",
      " Regression with ARIMA(0,0,1) errors : -11765.48\n",
      " Regression with ARIMA(0,0,0) errors : -8662.39\n",
      " Regression with ARIMA(1,0,2) errors : -13655.14\n",
      " Regression with ARIMA(2,0,1) errors : -13671.56\n",
      " Regression with ARIMA(1,0,1) errors : -13655.72\n",
      " Regression with ARIMA(2,0,0) errors : -13656.86\n",
      " Regression with ARIMA(3,0,1) errors : -13656.12\n",
      " Regression with ARIMA(3,0,0) errors : -13655.95\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13665.81\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13656.79\n",
      " Regression with ARIMA(0,0,0) errors : -10173.96\n",
      " Regression with ARIMA(1,0,0) errors : -13652.05\n",
      " Regression with ARIMA(0,0,1) errors : -11777.5\n",
      " Regression with ARIMA(0,0,0) errors : -8700.468\n",
      " Regression with ARIMA(1,0,2) errors : -13652.23\n",
      " Regression with ARIMA(2,0,1) errors : -13668.02\n",
      " Regression with ARIMA(1,0,1) errors : -13652.1\n",
      " Regression with ARIMA(2,0,0) errors : -13652.19\n",
      " Regression with ARIMA(3,0,1) errors : -13656.11\n",
      " Regression with ARIMA(3,0,0) errors : -13652.01\n",
      " Regression with ARIMA(3,0,2) errors : -13662.39\n",
      " Regression with ARIMA(2,0,1) errors : -13548.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13662.69\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13625.68\n",
      " Regression with ARIMA(0,1,0) errors : -13621.46\n",
      " Regression with ARIMA(1,1,0) errors : -13624.34\n",
      " Regression with ARIMA(0,1,1) errors : -13619.6\n",
      " Regression with ARIMA(0,1,0) errors : -13623.47\n",
      " Regression with ARIMA(1,1,2) errors : -13629.17\n",
      " Regression with ARIMA(0,1,2) errors : -13617.77\n",
      " Regression with ARIMA(1,1,1) errors : -13628.01\n",
      " Regression with ARIMA(1,1,3) errors : -13633.78\n",
      " Regression with ARIMA(0,1,3) errors : -13616.46\n",
      " Regression with ARIMA(2,1,3) errors : -13627.37\n",
      " Regression with ARIMA(1,1,4) errors : -13638.05\n",
      " Regression with ARIMA(0,1,4) errors : -13614.88\n",
      " Regression with ARIMA(2,1,4) errors : -13627.68\n",
      " Regression with ARIMA(1,1,5) errors : -13657.04\n",
      " Regression with ARIMA(0,1,5) errors : -13617.4\n",
      " Regression with ARIMA(2,1,5) errors : -13647.25\n",
      " Regression with ARIMA(1,1,5) errors : -13658.92\n",
      " Regression with ARIMA(0,1,5) errors : -13619.42\n",
      " Regression with ARIMA(1,1,4) errors : -13639.93\n",
      " Regression with ARIMA(2,1,5) errors : -13649.14\n",
      " Regression with ARIMA(0,1,4) errors : -13616.89\n",
      " Regression with ARIMA(2,1,4) errors : -13629.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,0) errors : -13628.45\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13669.46\n",
      " Regression with ARIMA(0,1,0) errors : -13667.96\n",
      " Regression with ARIMA(1,1,0) errors : -13665.88\n",
      " Regression with ARIMA(0,1,1) errors : -13666.47\n",
      " Regression with ARIMA(0,1,0) errors : -13669.95\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13678.82\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10272.74\n",
      " Regression with ARIMA(1,0,0) errors : -13772.01\n",
      " Regression with ARIMA(0,0,1) errors : -11891.74\n",
      " Regression with ARIMA(0,0,0) errors : -8843.671\n",
      " Regression with ARIMA(2,0,0) errors : -13770.9\n",
      " Regression with ARIMA(1,0,1) errors : -13771.44\n",
      " Regression with ARIMA(2,0,1) errors : -13785.75\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13772.19\n",
      " Regression with ARIMA(3,0,0) errors : -13772.31\n",
      " Regression with ARIMA(3,0,2) errors : -13785.11\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13783.28\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13764.52\n",
      " Regression with ARIMA(0,0,0) errors : -10268.04\n",
      " Regression with ARIMA(1,0,0) errors : -13761.23\n",
      " Regression with ARIMA(0,0,1) errors : -11885.1\n",
      " Regression with ARIMA(0,0,0) errors : -8858.715\n",
      " Regression with ARIMA(1,0,2) errors : -13761.55\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13782.76\n",
      " Regression with ARIMA(3,0,1) errors : -13780.45\n",
      " Regression with ARIMA(4,0,2) errors : -13778.02\n",
      " Regression with ARIMA(3,0,3) errors : -13780.93\n",
      " Regression with ARIMA(2,0,3) errors : -13762.9\n",
      " Regression with ARIMA(4,0,1) errors : -13774.34\n",
      " Regression with ARIMA(4,0,3) errors : -13775.95\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13775.78\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13769.81\n",
      " Regression with ARIMA(0,0,0) errors : -10265.3\n",
      " Regression with ARIMA(1,0,0) errors : -13762.85\n",
      " Regression with ARIMA(0,0,1) errors : -11881.84\n",
      " Regression with ARIMA(0,0,0) errors : -8821.143\n",
      " Regression with ARIMA(1,0,2) errors : -13762.57\n",
      " Regression with ARIMA(2,0,1) errors : -13768.3\n",
      " Regression with ARIMA(3,0,2) errors : -13783.22\n",
      " Regression with ARIMA(3,0,1) errors : -13768.49\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13781.28\n",
      " Regression with ARIMA(2,0,3) errors : -13768.18\n",
      " Regression with ARIMA(4,0,1) errors : -13769.2\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13777.69\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13769.38\n",
      " Regression with ARIMA(0,0,0) errors : -10260.46\n",
      " Regression with ARIMA(1,0,0) errors : -13763.75\n",
      " Regression with ARIMA(0,0,1) errors : -11877.06\n",
      " Regression with ARIMA(0,0,0) errors : -8820.979\n",
      " Regression with ARIMA(1,0,2) errors : -13763.9\n",
      " Regression with ARIMA(2,0,1) errors : -13767.21\n",
      " Regression with ARIMA(3,0,2) errors : -13781.12\n",
      " Regression with ARIMA(3,0,1) errors : -13768.51\n",
      " Regression with ARIMA(4,0,2) errors : -13781.64\n",
      " Regression with ARIMA(4,0,1) errors : -13767.06\n",
      " Regression with ARIMA(5,0,2) errors : -13779.5\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13781.37\n",
      " Regression with ARIMA(5,0,1) errors : -13775.92\n",
      " Regression with ARIMA(5,0,3) errors : -13777.89\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,2) errors : -13774.84\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13730.6\n",
      " Regression with ARIMA(0,0,0) errors : -10252.14\n",
      " Regression with ARIMA(1,0,0) errors : -13734.15\n",
      " Regression with ARIMA(0,0,1) errors : -11865.14\n",
      " Regression with ARIMA(0,0,0) errors : -8811.741\n",
      " Regression with ARIMA(2,0,0) errors : -13732.86\n",
      " Regression with ARIMA(1,0,1) errors : -13733.55\n",
      " Regression with ARIMA(2,0,1) errors : -13745.03\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13733.84\n",
      " Regression with ARIMA(3,0,0) errors : -13732.77\n",
      " Regression with ARIMA(3,0,2) errors : -13730.31\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13733.34\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10248.64\n",
      " Regression with ARIMA(1,0,0) errors : -13726.11\n",
      " Regression with ARIMA(0,0,1) errors : -11859.38\n",
      " Regression with ARIMA(0,0,0) errors : -8814.75\n",
      " Regression with ARIMA(2,0,0) errors : -13726.2\n",
      " Regression with ARIMA(3,0,0) errors : -13726.52\n",
      " Regression with ARIMA(4,0,0) errors : -13725.54\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : -13736.42\n",
      " Regression with ARIMA(1,0,1) errors : -13725.25\n",
      " Regression with ARIMA(1,0,2) errors : -13725.96\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,0) errors : -13725.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10253.6\n",
      " Regression with ARIMA(1,0,0) errors : -13735.62\n",
      " Regression with ARIMA(0,0,1) errors : -11865.12\n",
      " Regression with ARIMA(0,0,0) errors : -8816.856\n",
      " Regression with ARIMA(2,0,0) errors : -13733.87\n",
      " Regression with ARIMA(1,0,1) errors : -13734.66\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13733.14\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13750.01\n",
      " Regression with ARIMA(0,0,0) errors : -10257.06\n",
      " Regression with ARIMA(1,0,0) errors : -13738.28\n",
      " Regression with ARIMA(0,0,1) errors : -11865.9\n",
      " Regression with ARIMA(0,0,0) errors : -8780.029\n",
      " Regression with ARIMA(1,0,2) errors : -13737.34\n",
      " Regression with ARIMA(2,0,1) errors : -13751.1\n",
      " Regression with ARIMA(1,0,1) errors : -13737.18\n",
      " Regression with ARIMA(2,0,0) errors : -13736.6\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,0) errors : -13736.27\n",
      " Regression with ARIMA(3,0,2) errors : -13732.63\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13735.84\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10256.83\n",
      " Regression with ARIMA(1,0,0) errors : -13730.95\n",
      " Regression with ARIMA(0,0,1) errors : -11861.77\n",
      " Regression with ARIMA(0,0,0) errors : -8779.258\n",
      " Regression with ARIMA(2,0,0) errors : -13729.15\n",
      " Regression with ARIMA(1,0,1) errors : -13729.46\n",
      " Regression with ARIMA(2,0,1) errors : -13743.66\n",
      " Regression with ARIMA(3,0,1) errors : -13740.11\n",
      " Regression with ARIMA(1,0,2) errors : -13729.66\n",
      " Regression with ARIMA(3,0,0) errors : -13731.65\n",
      " Regression with ARIMA(3,0,2) errors : -13742.18\n",
      " Regression with ARIMA(2,0,1) errors : -13618.71\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13744.27\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13704.92\n",
      " Regression with ARIMA(0,0,0) errors : -10273.67\n",
      " Regression with ARIMA(1,0,0) errors : -13706.69\n",
      " Regression with ARIMA(0,0,1) errors : -11878.39\n",
      " Regression with ARIMA(0,0,0) errors : -8797.955\n",
      " Regression with ARIMA(2,0,0) errors : -13704.19\n",
      " Regression with ARIMA(1,0,1) errors : -13704.98\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13577.35\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13704.77\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13513.55\n",
      " Regression with ARIMA(0,0,0) errors : -10068.34\n",
      " Regression with ARIMA(1,0,0) errors : -13520.38\n",
      " Regression with ARIMA(0,0,1) errors : -11654.6\n",
      " Regression with ARIMA(0,0,0) errors : -8614.487\n",
      " Regression with ARIMA(2,0,0) errors : -13517.43\n",
      " Regression with ARIMA(1,0,1) errors : -13518.38\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13517.53\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12970.83\n",
      " Regression with ARIMA(0,1,0) errors : -12930.49\n",
      " Regression with ARIMA(1,1,0) errors : -12945.11\n",
      " Regression with ARIMA(0,1,1) errors : -12947.22\n",
      " Regression with ARIMA(0,1,0) errors : -12932.5\n",
      " Regression with ARIMA(1,1,2) errors : -12962.91\n",
      " Regression with ARIMA(2,1,1) errors : -12971.71\n",
      " Regression with ARIMA(1,1,1) errors : -12955.51\n",
      " Regression with ARIMA(2,1,0) errors : -12969.84\n",
      " Regression with ARIMA(3,1,1) errors : -12974.24\n",
      " Regression with ARIMA(3,1,0) errors : -12974.64\n",
      " Regression with ARIMA(4,1,0) errors : -12978.76\n",
      " Regression with ARIMA(5,1,0) errors : -12976.29\n",
      " Regression with ARIMA(4,1,1) errors : -12976.71\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,0) errors : -12980.76\n",
      " Regression with ARIMA(3,1,0) errors : -12976.65\n",
      " Regression with ARIMA(5,1,0) errors : -12978.28\n",
      " Regression with ARIMA(4,1,1) errors : -12978.77\n",
      " Regression with ARIMA(3,1,1) errors : -12976.24\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,1,0) errors : -12980.2\n",
      "\n",
      " Best model: Regression with ARIMA(4,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12722.08\n",
      " Regression with ARIMA(0,1,0) errors : -12682.87\n",
      " Regression with ARIMA(1,1,0) errors : -12702.85\n",
      " Regression with ARIMA(0,1,1) errors : -12708.6\n",
      " Regression with ARIMA(0,1,0) errors : -12684.84\n",
      " Regression with ARIMA(1,1,2) errors : -12720.75\n",
      " Regression with ARIMA(2,1,1) errors : -12722.99\n",
      " Regression with ARIMA(1,1,1) errors : -12711.35\n",
      " Regression with ARIMA(2,1,0) errors : -12720.41\n",
      " Regression with ARIMA(3,1,1) errors : -12722.13\n",
      " Regression with ARIMA(3,1,0) errors : -12724.07\n",
      " Regression with ARIMA(4,1,0) errors : -12721.18\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -12726.05\n",
      " Regression with ARIMA(2,1,0) errors : -12722.38\n",
      " Regression with ARIMA(4,1,0) errors : -12723.17\n",
      " Regression with ARIMA(3,1,1) errors : -12724.11\n",
      " Regression with ARIMA(2,1,1) errors : -12724.96\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,0) errors : -12736.42\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12560.78\n",
      " Regression with ARIMA(0,1,0) errors : -12505.96\n",
      " Regression with ARIMA(1,1,0) errors : -12527.34\n",
      " Regression with ARIMA(0,1,1) errors : -12533.58\n",
      " Regression with ARIMA(0,1,0) errors : -12507.97\n",
      " Regression with ARIMA(1,1,2) errors : -12551.89\n",
      " Regression with ARIMA(2,1,1) errors : -12557.49\n",
      " Regression with ARIMA(3,1,2) errors : -12557.93\n",
      " Regression with ARIMA(2,1,3) errors : -12558.92\n",
      " Regression with ARIMA(1,1,1) errors : -12537.48\n",
      " Regression with ARIMA(1,1,3) errors : -12554.56\n",
      " Regression with ARIMA(3,1,1) errors : -12557.55\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12562.8\n",
      " Regression with ARIMA(1,1,2) errors : -12553.91\n",
      " Regression with ARIMA(2,1,1) errors : -12559.5\n",
      " Regression with ARIMA(3,1,2) errors : -12559.9\n",
      " Regression with ARIMA(2,1,3) errors : -12560.93\n",
      " Regression with ARIMA(1,1,1) errors : -12539.48\n",
      " Regression with ARIMA(1,1,3) errors : -12556.58\n",
      " Regression with ARIMA(3,1,1) errors : -12559.56\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12572.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12525.75\n",
      " Regression with ARIMA(0,1,0) errors : -12472.26\n",
      " Regression with ARIMA(1,1,0) errors : -12494.36\n",
      " Regression with ARIMA(0,1,1) errors : -12499.92\n",
      " Regression with ARIMA(0,1,0) errors : -12474.27\n",
      " Regression with ARIMA(1,1,2) errors : -12516.93\n",
      " Regression with ARIMA(2,1,1) errors : -12522.47\n",
      " Regression with ARIMA(3,1,2) errors : -12522.7\n",
      " Regression with ARIMA(2,1,3) errors : -12523.75\n",
      " Regression with ARIMA(1,1,1) errors : -12502.95\n",
      " Regression with ARIMA(1,1,3) errors : -12520.19\n",
      " Regression with ARIMA(3,1,1) errors : -12522.74\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12527.77\n",
      " Regression with ARIMA(1,1,2) errors : -12518.94\n",
      " Regression with ARIMA(2,1,1) errors : -12524.48\n",
      " Regression with ARIMA(3,1,2) errors : -12524.7\n",
      " Regression with ARIMA(2,1,3) errors : -12525.77\n",
      " Regression with ARIMA(1,1,1) errors : -12504.95\n",
      " Regression with ARIMA(1,1,3) errors : -12522.21\n",
      " Regression with ARIMA(3,1,1) errors : -12524.75\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12537.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12470.37\n",
      " Regression with ARIMA(0,1,0) errors : -12414.35\n",
      " Regression with ARIMA(1,1,0) errors : -12436.58\n",
      " Regression with ARIMA(0,1,1) errors : -12443.12\n",
      " Regression with ARIMA(0,1,0) errors : -12416.35\n",
      " Regression with ARIMA(1,1,2) errors : -12461.95\n",
      " Regression with ARIMA(2,1,1) errors : -12468.01\n",
      " Regression with ARIMA(3,1,2) errors : -12467.45\n",
      " Regression with ARIMA(2,1,3) errors : -12468.34\n",
      " Regression with ARIMA(1,1,1) errors : -12445.63\n",
      " Regression with ARIMA(1,1,3) errors : -12464.82\n",
      " Regression with ARIMA(3,1,1) errors : -12468.7\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12472.37\n",
      " Regression with ARIMA(1,1,2) errors : -12463.95\n",
      " Regression with ARIMA(2,1,1) errors : -12470\n",
      " Regression with ARIMA(3,1,2) errors : -12469.45\n",
      " Regression with ARIMA(2,1,3) errors : -12470.36\n",
      " Regression with ARIMA(1,1,1) errors : -12447.62\n",
      " Regression with ARIMA(1,1,3) errors : -12466.82\n",
      " Regression with ARIMA(3,1,1) errors : -12470.69\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12481.51\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12415.46\n",
      " Regression with ARIMA(0,1,0) errors : -12357.7\n",
      " Regression with ARIMA(1,1,0) errors : -12377.73\n",
      " Regression with ARIMA(0,1,1) errors : -12382.8\n",
      " Regression with ARIMA(0,1,0) errors : -12359.71\n",
      " Regression with ARIMA(1,1,2) errors : -12397.26\n",
      " Regression with ARIMA(2,1,1) errors : -12405.48\n",
      " Regression with ARIMA(3,1,2) errors : -12413.51\n",
      " Regression with ARIMA(2,1,3) errors : -12414.64\n",
      " Regression with ARIMA(1,1,1) errors : -12383.72\n",
      " Regression with ARIMA(1,1,3) errors : -12404.76\n",
      " Regression with ARIMA(3,1,1) errors : -12410.9\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12417.47\n",
      " Regression with ARIMA(1,1,2) errors : -12399.27\n",
      " Regression with ARIMA(2,1,1) errors : -12407.49\n",
      " Regression with ARIMA(3,1,2) errors : -12415.52\n",
      " Regression with ARIMA(2,1,3) errors : -12416.65\n",
      " Regression with ARIMA(1,1,1) errors : -12385.73\n",
      " Regression with ARIMA(1,1,3) errors : -12406.78\n",
      " Regression with ARIMA(3,1,1) errors : -12412.92\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12422.35\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12392.88\n",
      " Regression with ARIMA(0,1,0) errors : -12334.96\n",
      " Regression with ARIMA(1,1,0) errors : -12358.48\n",
      " Regression with ARIMA(0,1,1) errors : -12364.77\n",
      " Regression with ARIMA(0,1,0) errors : -12336.95\n",
      " Regression with ARIMA(1,1,2) errors : -12380.24\n",
      " Regression with ARIMA(2,1,1) errors : -12390.33\n",
      " Regression with ARIMA(3,1,2) errors : -12392.56\n",
      " Regression with ARIMA(2,1,3) errors : -12390.88\n",
      " Regression with ARIMA(1,1,1) errors : -12366.94\n",
      " Regression with ARIMA(1,1,3) errors : -12386.73\n",
      " Regression with ARIMA(3,1,1) errors : -12394.33\n",
      " Regression with ARIMA(3,1,0) errors : -12396.28\n",
      " Regression with ARIMA(2,1,0) errors : -12381.04\n",
      " Regression with ARIMA(4,1,0) errors : -12409.24\n",
      " Regression with ARIMA(5,1,0) errors : -12418.87\n",
      " Regression with ARIMA(5,1,1) errors : -12429.22\n",
      " Regression with ARIMA(4,1,1) errors : -12408.98\n",
      " Regression with ARIMA(5,1,2) errors : -12419\n",
      " Regression with ARIMA(4,1,2) errors : -12415.77\n",
      " Regression with ARIMA(5,1,1) errors : -12431.1\n",
      " Regression with ARIMA(4,1,1) errors : -12410.99\n",
      " Regression with ARIMA(5,1,0) errors : -12420.89\n",
      " Regression with ARIMA(5,1,2) errors : -12421.01\n",
      " Regression with ARIMA(4,1,0) errors : -12411.25\n",
      " Regression with ARIMA(4,1,2) errors : -12417.78\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,0) errors : -12408.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12405.22\n",
      " Regression with ARIMA(0,1,0) errors : -12342.22\n",
      " Regression with ARIMA(1,1,0) errors : -12369.17\n",
      " Regression with ARIMA(0,1,1) errors : -12375.11\n",
      " Regression with ARIMA(0,1,0) errors : -12344.23\n",
      " Regression with ARIMA(1,1,2) errors : -12390.01\n",
      " Regression with ARIMA(2,1,1) errors : -12397.17\n",
      " Regression with ARIMA(3,1,2) errors : -12404.33\n",
      " Regression with ARIMA(2,1,3) errors : -12403.26\n",
      " Regression with ARIMA(1,1,1) errors : -12376.7\n",
      " Regression with ARIMA(1,1,3) errors : -12397.27\n",
      " Regression with ARIMA(3,1,1) errors : -12402.52\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12407.23\n",
      " Regression with ARIMA(1,1,2) errors : -12392.02\n",
      " Regression with ARIMA(2,1,1) errors : -12399.19\n",
      " Regression with ARIMA(3,1,2) errors : -12406.34\n",
      " Regression with ARIMA(2,1,3) errors : -12405.28\n",
      " Regression with ARIMA(1,1,1) errors : -12378.71\n",
      " Regression with ARIMA(1,1,3) errors : -12399.28\n",
      " Regression with ARIMA(3,1,1) errors : -12404.53\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12418.09\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12479.1\n",
      " Regression with ARIMA(0,0,0) errors : -8904.547\n",
      " Regression with ARIMA(1,0,0) errors : -12457.86\n",
      " Regression with ARIMA(0,0,1) errors : -10586.67\n",
      " Regression with ARIMA(0,0,0) errors : -7757.971\n",
      " Regression with ARIMA(1,0,2) errors : -12470.62\n",
      " Regression with ARIMA(2,0,1) errors : -12467.78\n",
      " Regression with ARIMA(3,0,2) errors : -12535.04\n",
      " Regression with ARIMA(3,0,1) errors : -12486.22\n",
      " Regression with ARIMA(4,0,2) errors : -12504.23\n",
      " Regression with ARIMA(3,0,3) errors : -12504.59\n",
      " Regression with ARIMA(2,0,3) errors : -12501.85\n",
      " Regression with ARIMA(4,0,1) errors : -12505.69\n",
      " Regression with ARIMA(4,0,3) errors : -12533.86\n",
      " Regression with ARIMA(3,0,2) errors : -12438.48\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12506.31\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12465.71\n",
      " Regression with ARIMA(0,0,0) errors : -8892.805\n",
      " Regression with ARIMA(1,0,0) errors : -12446.23\n",
      " Regression with ARIMA(0,0,1) errors : -10571.36\n",
      " Regression with ARIMA(0,0,0) errors : -7709.597\n",
      " Regression with ARIMA(1,0,2) errors : -12458.34\n",
      " Regression with ARIMA(2,0,1) errors : -12455.94\n",
      " Regression with ARIMA(3,0,2) errors : -12524.46\n",
      " Regression with ARIMA(3,0,1) errors : -12471.77\n",
      " Regression with ARIMA(4,0,2) errors : -12490.22\n",
      " Regression with ARIMA(3,0,3) errors : -12489.3\n",
      " Regression with ARIMA(2,0,3) errors : -12488.4\n",
      " Regression with ARIMA(4,0,1) errors : -12491.45\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12529.33\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12465.29\n",
      " Regression with ARIMA(0,0,0) errors : -8894.651\n",
      " Regression with ARIMA(1,0,0) errors : -12445.35\n",
      " Regression with ARIMA(0,0,1) errors : -10573.51\n",
      " Regression with ARIMA(0,0,0) errors : -7703.577\n",
      " Regression with ARIMA(1,0,2) errors : -12457.79\n",
      " Regression with ARIMA(2,0,1) errors : -12455.34\n",
      " Regression with ARIMA(3,0,2) errors : -12521.44\n",
      " Regression with ARIMA(3,0,1) errors : -12471.75\n",
      " Regression with ARIMA(4,0,2) errors : -12489.95\n",
      " Regression with ARIMA(3,0,3) errors : -12489.87\n",
      " Regression with ARIMA(2,0,3) errors : -12487.74\n",
      " Regression with ARIMA(4,0,1) errors : -12490.93\n",
      " Regression with ARIMA(4,0,3) errors : -12517.07\n",
      " Regression with ARIMA(3,0,2) errors : -12443.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12527.75\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12457.74\n",
      " Regression with ARIMA(0,0,0) errors : -8888.053\n",
      " Regression with ARIMA(1,0,0) errors : -12438.77\n",
      " Regression with ARIMA(0,0,1) errors : -10568.72\n",
      " Regression with ARIMA(0,0,0) errors : -7699.325\n",
      " Regression with ARIMA(1,0,2) errors : -12450.59\n",
      " Regression with ARIMA(2,0,1) errors : -12447.71\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12479.45\n",
      " Regression with ARIMA(1,0,3) errors : -12482.41\n",
      " Regression with ARIMA(0,0,3) errors : -11655.39\n",
      " Regression with ARIMA(1,0,4) errors : -12480.42\n",
      " Regression with ARIMA(0,0,2) errors : -11226.37\n",
      " Regression with ARIMA(0,0,4) errors : -11987.9\n",
      " Regression with ARIMA(2,0,4) errors : -12508.61\n",
      " Regression with ARIMA(3,0,4) errors : -12510.98\n",
      " Regression with ARIMA(3,0,3) errors : -12480.89\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12508.89\n",
      " Regression with ARIMA(2,0,5) errors : -12511.16\n",
      " Regression with ARIMA(1,0,5) errors : -12481.3\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12511.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12454.54\n",
      " Regression with ARIMA(0,0,0) errors : -8881.322\n",
      " Regression with ARIMA(1,0,0) errors : -12434.91\n",
      " Regression with ARIMA(0,0,1) errors : -10562.75\n",
      " Regression with ARIMA(0,0,0) errors : -7707.396\n",
      " Regression with ARIMA(1,0,2) errors : -12446.19\n",
      " Regression with ARIMA(2,0,1) errors : -12444.84\n",
      " Regression with ARIMA(3,0,2) errors : -12469.19\n",
      " Regression with ARIMA(3,0,1) errors : -12458.01\n",
      " Regression with ARIMA(4,0,2) errors : -12484.21\n",
      " Regression with ARIMA(4,0,1) errors : -12483.69\n",
      " Regression with ARIMA(5,0,2) errors : -12502.19\n",
      " Regression with ARIMA(5,0,1) errors : -12498.17\n",
      " Regression with ARIMA(5,0,3) errors : -12504.05\n",
      " Regression with ARIMA(4,0,3) errors : -12482.32\n",
      " Regression with ARIMA(5,0,4) errors : -12490.42\n",
      " Regression with ARIMA(4,0,4) errors : -12481.71\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : -12506.66\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12464.6\n",
      " Regression with ARIMA(0,0,0) errors : -8887.118\n",
      " Regression with ARIMA(1,0,0) errors : -12445.24\n",
      " Regression with ARIMA(0,0,1) errors : -10561.18\n",
      " Regression with ARIMA(0,0,0) errors : -7708.215\n",
      " Regression with ARIMA(1,0,2) errors : -12456.91\n",
      " Regression with ARIMA(2,0,1) errors : -12455.73\n",
      " Regression with ARIMA(3,0,2) errors : -12528.24\n",
      " Regression with ARIMA(3,0,1) errors : -12470.67\n",
      " Regression with ARIMA(4,0,2) errors : -12491.02\n",
      " Regression with ARIMA(3,0,3) errors : -12487.94\n",
      " Regression with ARIMA(2,0,3) errors : -12488.17\n",
      " Regression with ARIMA(4,0,1) errors : -12491.62\n",
      " Regression with ARIMA(4,0,3) errors : -12490.61\n",
      " Regression with ARIMA(3,0,2) errors : -12436.46\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12488.78\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12482.33\n",
      " Regression with ARIMA(0,0,0) errors : -8891.815\n",
      " Regression with ARIMA(1,0,0) errors : -12463.17\n",
      " Regression with ARIMA(0,0,1) errors : -10569.71\n",
      " Regression with ARIMA(0,0,0) errors : -7717.256\n",
      " Regression with ARIMA(1,0,2) errors : -12475.08\n",
      " Regression with ARIMA(2,0,1) errors : -12474.77\n",
      " Regression with ARIMA(3,0,2) errors : -12536.91\n",
      " Regression with ARIMA(3,0,1) errors : -12489.05\n",
      " Regression with ARIMA(4,0,2) errors : -12507.21\n",
      " Regression with ARIMA(3,0,3) errors : -12507.02\n",
      " Regression with ARIMA(2,0,3) errors : -12506.61\n",
      " Regression with ARIMA(4,0,1) errors : -12508.71\n",
      " Regression with ARIMA(4,0,3) errors : -12506.62\n",
      " Regression with ARIMA(3,0,2) errors : -12453.39\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12508.55\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12503.57\n",
      " Regression with ARIMA(0,0,0) errors : -8896.241\n",
      " Regression with ARIMA(1,0,0) errors : -12485.86\n",
      " Regression with ARIMA(0,0,1) errors : -10569.77\n",
      " Regression with ARIMA(0,0,0) errors : -7714.817\n",
      " Regression with ARIMA(1,0,2) errors : -12497.82\n",
      " Regression with ARIMA(2,0,1) errors : -12496.35\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12527.94\n",
      " Regression with ARIMA(1,0,3) errors : -12530.81\n",
      " Regression with ARIMA(0,0,3) errors : -11677.03\n",
      " Regression with ARIMA(1,0,4) errors : -12528.79\n",
      " Regression with ARIMA(0,0,2) errors : -11229.55\n",
      " Regression with ARIMA(0,0,4) errors : -12012.79\n",
      " Regression with ARIMA(2,0,4) errors : -12555.48\n",
      " Regression with ARIMA(3,0,4) errors : -12559.17\n",
      " Regression with ARIMA(3,0,3) errors : -12529.19\n",
      " Regression with ARIMA(4,0,4) errors : -12555.94\n",
      " Regression with ARIMA(3,0,5) errors : -12539.67\n",
      " Regression with ARIMA(2,0,5) errors : -12558.37\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -12560.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12499.29\n",
      " Regression with ARIMA(0,0,0) errors : -8896.211\n",
      " Regression with ARIMA(1,0,0) errors : -12479.6\n",
      " Regression with ARIMA(0,0,1) errors : -10569.06\n",
      " Regression with ARIMA(0,0,0) errors : -7726.249\n",
      " Regression with ARIMA(1,0,2) errors : -12491.43\n",
      " Regression with ARIMA(2,0,1) errors : -12490.08\n",
      " Regression with ARIMA(3,0,2) errors : -12549.65\n",
      " Regression with ARIMA(3,0,1) errors : -12505.95\n",
      " Regression with ARIMA(4,0,2) errors : -12523.02\n",
      " Regression with ARIMA(3,0,3) errors : -12522.73\n",
      " Regression with ARIMA(2,0,3) errors : -12520.84\n",
      " Regression with ARIMA(4,0,1) errors : -12524.79\n",
      " Regression with ARIMA(4,0,3) errors : -12548.68\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12521.78\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12522.71\n",
      " Regression with ARIMA(0,0,0) errors : -8912.717\n",
      " Regression with ARIMA(1,0,0) errors : -12499.7\n",
      " Regression with ARIMA(0,0,1) errors : -10598.43\n",
      " Regression with ARIMA(0,0,0) errors : -7791.064\n",
      " Regression with ARIMA(1,0,2) errors : -12511.99\n",
      " Regression with ARIMA(2,0,1) errors : -12511.69\n",
      " Regression with ARIMA(3,0,2) errors : -12565.33\n",
      " Regression with ARIMA(3,0,1) errors : -12529.16\n",
      " Regression with ARIMA(4,0,2) errors : -12545.66\n",
      " Regression with ARIMA(3,0,3) errors : -12545.28\n",
      " Regression with ARIMA(2,0,3) errors : -12543.96\n",
      " Regression with ARIMA(4,0,1) errors : -12547.58\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12526.08\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.95\n",
      " Regression with ARIMA(0,0,0) errors : -8942.089\n",
      " Regression with ARIMA(1,0,0) errors : -12527.3\n",
      " Regression with ARIMA(0,0,1) errors : -10625.79\n",
      " Regression with ARIMA(0,0,0) errors : -7815.365\n",
      " Regression with ARIMA(1,0,2) errors : -12539.1\n",
      " Regression with ARIMA(2,0,1) errors : -12537.44\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12568.26\n",
      " Regression with ARIMA(1,0,3) errors : -12570.63\n",
      " Regression with ARIMA(0,0,3) errors : -11727.96\n",
      " Regression with ARIMA(1,0,4) errors : -12568.62\n",
      " Regression with ARIMA(0,0,2) errors : -11285.05\n",
      " Regression with ARIMA(0,0,4) errors : -12063.02\n",
      " Regression with ARIMA(2,0,4) errors : -12594.01\n",
      " Regression with ARIMA(3,0,4) errors : -12602.32\n",
      " Regression with ARIMA(3,0,3) errors : -12568.74\n",
      " Regression with ARIMA(4,0,4) errors : -12567.01\n",
      " Regression with ARIMA(3,0,5) errors : -12578.76\n",
      " Regression with ARIMA(2,0,5) errors : -12598.99\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12467.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -12600.43\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12532.16\n",
      " Regression with ARIMA(0,0,0) errors : -8934.83\n",
      " Regression with ARIMA(1,0,0) errors : -12512.55\n",
      " Regression with ARIMA(0,0,1) errors : -10617.82\n",
      " Regression with ARIMA(0,0,0) errors : -7779.834\n",
      " Regression with ARIMA(1,0,2) errors : -12525.18\n",
      " Regression with ARIMA(2,0,1) errors : -12523.58\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12554.76\n",
      " Regression with ARIMA(1,0,3) errors : -12557.17\n",
      " Regression with ARIMA(0,0,3) errors : -11723.56\n",
      " Regression with ARIMA(1,0,4) errors : -12555.2\n",
      " Regression with ARIMA(0,0,2) errors : -11272.84\n",
      " Regression with ARIMA(0,0,4) errors : -12053.22\n",
      " Regression with ARIMA(2,0,4) errors : -12583\n",
      " Regression with ARIMA(3,0,4) errors : -12586.36\n",
      " Regression with ARIMA(3,0,3) errors : -12555.78\n",
      " Regression with ARIMA(4,0,4) errors : -12586.4\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12572.16\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12559.34\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,5) errors : -12569.81\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : -12587.09\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12509.71\n",
      " Regression with ARIMA(0,0,0) errors : -8923.006\n",
      " Regression with ARIMA(1,0,0) errors : -12490.06\n",
      " Regression with ARIMA(0,0,1) errors : -10606.06\n",
      " Regression with ARIMA(0,0,0) errors : -7778.001\n",
      " Regression with ARIMA(1,0,2) errors : -12503.3\n",
      " Regression with ARIMA(2,0,1) errors : -12501.4\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12532.82\n",
      " Regression with ARIMA(1,0,3) errors : -12535.75\n",
      " Regression with ARIMA(0,0,3) errors : -11707.59\n",
      " Regression with ARIMA(1,0,4) errors : -12533.75\n",
      " Regression with ARIMA(0,0,2) errors : -11261.54\n",
      " Regression with ARIMA(0,0,4) errors : -12037.84\n",
      " Regression with ARIMA(2,0,4) errors : -12562.35\n",
      " Regression with ARIMA(3,0,4) errors : -12563.64\n",
      " Regression with ARIMA(3,0,3) errors : -12534.12\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12540.3\n",
      " Regression with ARIMA(2,0,5) errors : -12565.8\n",
      " Regression with ARIMA(1,0,5) errors : -12534.53\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12565.48\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12497.83\n",
      " Regression with ARIMA(0,0,0) errors : -8905.257\n",
      " Regression with ARIMA(1,0,0) errors : -12479.66\n",
      " Regression with ARIMA(0,0,1) errors : -10592.39\n",
      " Regression with ARIMA(0,0,0) errors : -7770.197\n",
      " Regression with ARIMA(1,0,2) errors : -12491.59\n",
      " Regression with ARIMA(2,0,1) errors : -12491.59\n",
      " Regression with ARIMA(3,0,2) errors : -12541.44\n",
      " Regression with ARIMA(3,0,1) errors : -12505.67\n",
      " Regression with ARIMA(4,0,2) errors : -12524.33\n",
      " Regression with ARIMA(3,0,3) errors : -12524.65\n",
      " Regression with ARIMA(2,0,3) errors : -12523.33\n",
      " Regression with ARIMA(4,0,1) errors : -12525.8\n",
      " Regression with ARIMA(4,0,3) errors : -12554.64\n",
      " Regression with ARIMA(5,0,3) errors : -12551.24\n",
      " Regression with ARIMA(4,0,4) errors : -12549.94\n",
      " Regression with ARIMA(3,0,4) errors : -12553.02\n",
      " Regression with ARIMA(5,0,2) errors : -12548.7\n",
      " Regression with ARIMA(5,0,4) errors : -12528.29\n",
      " Regression with ARIMA(4,0,3) errors : -12482.77\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12554.1\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12497.83\n",
      " Regression with ARIMA(0,0,0) errors : -8898.064\n",
      " Regression with ARIMA(1,0,0) errors : -12477.67\n",
      " Regression with ARIMA(0,0,1) errors : -10586.17\n",
      " Regression with ARIMA(0,0,0) errors : -7763.444\n",
      " Regression with ARIMA(1,0,2) errors : -12489.24\n",
      " Regression with ARIMA(2,0,1) errors : -12490.62\n",
      " Regression with ARIMA(3,0,2) errors : -12555.3\n",
      " Regression with ARIMA(3,0,1) errors : -12503.83\n",
      " Regression with ARIMA(4,0,2) errors : -12522.97\n",
      " Regression with ARIMA(3,0,3) errors : -12522.77\n",
      " Regression with ARIMA(2,0,3) errors : -12522.46\n",
      " Regression with ARIMA(4,0,1) errors : -12524.5\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12474.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12523.61\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12513.83\n",
      " Regression with ARIMA(0,0,0) errors : -8943.164\n",
      " Regression with ARIMA(1,0,0) errors : -12488.42\n",
      " Regression with ARIMA(0,0,1) errors : -10621.1\n",
      " Regression with ARIMA(0,0,0) errors : -7868.129\n",
      " Regression with ARIMA(1,0,2) errors : -12499.53\n",
      " Regression with ARIMA(2,0,1) errors : -12510\n",
      " Regression with ARIMA(3,0,2) errors : -12538.21\n",
      " Regression with ARIMA(3,0,1) errors : -12522.06\n",
      " Regression with ARIMA(4,0,2) errors : -12545.22\n",
      " Regression with ARIMA(4,0,1) errors : -12546.86\n",
      " Regression with ARIMA(4,0,0) errors : -12546.27\n",
      " Regression with ARIMA(5,0,1) errors : -12549.63\n",
      " Regression with ARIMA(5,0,0) errors : -12550.19\n",
      " Regression with ARIMA(5,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,0) errors : -12530.49\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12537.41\n",
      " Regression with ARIMA(0,0,0) errors : -8980.404\n",
      " Regression with ARIMA(1,0,0) errors : -12515.87\n",
      " Regression with ARIMA(0,0,1) errors : -10652.29\n",
      " Regression with ARIMA(0,0,0) errors : -7878.327\n",
      " Regression with ARIMA(1,0,2) errors : -12530.48\n",
      " Regression with ARIMA(2,0,1) errors : -12528.68\n",
      " Regression with ARIMA(3,0,2) errors : -12554.48\n",
      " Regression with ARIMA(3,0,1) errors : -12543.44\n",
      " Regression with ARIMA(4,0,2) errors : -12559.77\n",
      " Regression with ARIMA(4,0,1) errors : -12561.17\n",
      " Regression with ARIMA(4,0,0) errors : -12562.64\n",
      " Regression with ARIMA(3,0,0) errors : -12534.45\n",
      " Regression with ARIMA(5,0,0) errors : -12560.32\n",
      " Regression with ARIMA(5,0,1) errors : -12583.89\n",
      " Regression with ARIMA(5,0,2) errors : -12582.7\n",
      " Regression with ARIMA(5,0,1) errors : -12494.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12584.44\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.24\n",
      " Regression with ARIMA(0,0,0) errors : -8985.481\n",
      " Regression with ARIMA(1,0,0) errors : -12523.97\n",
      " Regression with ARIMA(0,0,1) errors : -10655.97\n",
      " Regression with ARIMA(0,0,0) errors : -7884.878\n",
      " Regression with ARIMA(1,0,2) errors : -12538.88\n",
      " Regression with ARIMA(2,0,1) errors : -12537.23\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12566.95\n",
      " Regression with ARIMA(1,0,3) errors : -12569.82\n",
      " Regression with ARIMA(0,0,3) errors : -11754.84\n",
      " Regression with ARIMA(1,0,4) errors : -12567.97\n",
      " Regression with ARIMA(0,0,2) errors : -11299.19\n",
      " Regression with ARIMA(0,0,4) errors : -12073.38\n",
      " Regression with ARIMA(2,0,4) errors : -12592.97\n",
      " Regression with ARIMA(3,0,4) errors : -12597.31\n",
      " Regression with ARIMA(3,0,3) errors : -12567.29\n",
      " Regression with ARIMA(4,0,4) errors : -12596.6\n",
      " Regression with ARIMA(3,0,5) errors : -12570.58\n",
      " Regression with ARIMA(2,0,5) errors : -12597.68\n",
      " Regression with ARIMA(1,0,5) errors : -12568.02\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12597.69\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12546.78\n",
      " Regression with ARIMA(0,0,0) errors : -8970.223\n",
      " Regression with ARIMA(1,0,0) errors : -12525.95\n",
      " Regression with ARIMA(0,0,1) errors : -10649.53\n",
      " Regression with ARIMA(0,0,0) errors : -7878.626\n",
      " Regression with ARIMA(1,0,2) errors : -12540.83\n",
      " Regression with ARIMA(2,0,1) errors : -12539.25\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12568.27\n",
      " Regression with ARIMA(1,0,3) errors : -12571.19\n",
      " Regression with ARIMA(0,0,3) errors : -11751.13\n",
      " Regression with ARIMA(1,0,4) errors : -12569.31\n",
      " Regression with ARIMA(0,0,2) errors : -11296.38\n",
      " Regression with ARIMA(0,0,4) errors : -12067\n",
      " Regression with ARIMA(2,0,4) errors : -12594.34\n",
      " Regression with ARIMA(3,0,4) errors : -12595.54\n",
      " Regression with ARIMA(3,0,3) errors : -12568.5\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12574.84\n",
      " Regression with ARIMA(2,0,5) errors : -12598.8\n",
      " Regression with ARIMA(1,0,5) errors : -12569.08\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12597.59\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.79\n",
      " Regression with ARIMA(0,0,0) errors : -8964.909\n",
      " Regression with ARIMA(1,0,0) errors : -12525.68\n",
      " Regression with ARIMA(0,0,1) errors : -10646.25\n",
      " Regression with ARIMA(0,0,0) errors : -7885.222\n",
      " Regression with ARIMA(1,0,2) errors : -12540.83\n",
      " Regression with ARIMA(2,0,1) errors : -12539.59\n",
      " Regression with ARIMA(3,0,2) errors : -12603.07\n",
      " Regression with ARIMA(3,0,1) errors : -12554.12\n",
      " Regression with ARIMA(4,0,2) errors : -12569.57\n",
      " Regression with ARIMA(3,0,3) errors : -12569.71\n",
      " Regression with ARIMA(2,0,3) errors : -12568.45\n",
      " Regression with ARIMA(4,0,1) errors : -12570.93\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12494.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12570.9\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12548.69\n",
      " Regression with ARIMA(0,0,0) errors : -8959.862\n",
      " Regression with ARIMA(1,0,0) errors : -12529.05\n",
      " Regression with ARIMA(0,0,1) errors : -10643.71\n",
      " Regression with ARIMA(0,0,0) errors : -7886.635\n",
      " Regression with ARIMA(1,0,2) errors : -12544.11\n",
      " Regression with ARIMA(2,0,1) errors : -12544.13\n",
      " Regression with ARIMA(3,0,2) errors : -12571.06\n",
      " Regression with ARIMA(3,0,1) errors : -12561.51\n",
      " Regression with ARIMA(4,0,2) errors : -12576.07\n",
      " Regression with ARIMA(4,0,1) errors : -12578.07\n",
      " Regression with ARIMA(4,0,0) errors : -12579.62\n",
      " Regression with ARIMA(3,0,0) errors : -12551.25\n",
      " Regression with ARIMA(5,0,0) errors : -12579.64\n",
      " Regression with ARIMA(5,0,1) errors : Inf\n",
      " Regression with ARIMA(5,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,0) errors : -12575.23\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12551.97\n",
      " Regression with ARIMA(0,0,0) errors : -8967.683\n",
      " Regression with ARIMA(1,0,0) errors : -12529.69\n",
      " Regression with ARIMA(0,0,1) errors : -10653.67\n",
      " Regression with ARIMA(0,0,0) errors : -7896.484\n",
      " Regression with ARIMA(1,0,2) errors : -12544.97\n",
      " Regression with ARIMA(2,0,1) errors : -12543.7\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12573.37\n",
      " Regression with ARIMA(1,0,3) errors : -12575.68\n",
      " Regression with ARIMA(0,0,3) errors : -11753.95\n",
      " Regression with ARIMA(1,0,4) errors : -12573.8\n",
      " Regression with ARIMA(0,0,2) errors : -11300.67\n",
      " Regression with ARIMA(0,0,4) errors : -12074.69\n",
      " Regression with ARIMA(2,0,4) errors : -12591.45\n",
      " Regression with ARIMA(3,0,4) errors : -12595.99\n",
      " Regression with ARIMA(3,0,3) errors : -12573.8\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12580.86\n",
      " Regression with ARIMA(2,0,5) errors : -12597\n",
      " Regression with ARIMA(1,0,5) errors : -12573.86\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12603.04\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12556.25\n",
      " Regression with ARIMA(0,0,0) errors : -8962.755\n",
      " Regression with ARIMA(1,0,0) errors : -12535.8\n",
      " Regression with ARIMA(0,0,1) errors : -10648.64\n",
      " Regression with ARIMA(0,0,0) errors : -7898.839\n",
      " Regression with ARIMA(1,0,2) errors : -12550.14\n",
      " Regression with ARIMA(2,0,1) errors : -12548.54\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12578.72\n",
      " Regression with ARIMA(1,0,3) errors : -12581.63\n",
      " Regression with ARIMA(0,0,3) errors : -11752.88\n",
      " Regression with ARIMA(1,0,4) errors : -12579.7\n",
      " Regression with ARIMA(0,0,2) errors : -11299.22\n",
      " Regression with ARIMA(0,0,4) errors : -12072.91\n",
      " Regression with ARIMA(2,0,4) errors : -12605.06\n",
      " Regression with ARIMA(3,0,4) errors : -12603.2\n",
      " Regression with ARIMA(2,0,5) errors : -12609.26\n",
      " Regression with ARIMA(1,0,5) errors : -12579.72\n",
      " Regression with ARIMA(3,0,5) errors : -12582.04\n",
      " Regression with ARIMA(2,0,5) errors : -12540.55\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12607.82\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12570.6\n",
      " Regression with ARIMA(0,0,0) errors : -8967.56\n",
      " Regression with ARIMA(1,0,0) errors : -12549.25\n",
      " Regression with ARIMA(0,0,1) errors : -10654.34\n",
      " Regression with ARIMA(0,0,0) errors : -7906.854\n",
      " Regression with ARIMA(1,0,2) errors : -12564.03\n",
      " Regression with ARIMA(2,0,1) errors : -12563.91\n",
      " Regression with ARIMA(3,0,2) errors : -12627.87\n",
      " Regression with ARIMA(3,0,1) errors : -12577.27\n",
      " Regression with ARIMA(4,0,2) errors : -12593.34\n",
      " Regression with ARIMA(3,0,3) errors : -12593.82\n",
      " Regression with ARIMA(2,0,3) errors : -12593.22\n",
      " Regression with ARIMA(4,0,1) errors : -12594.72\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12522.09\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12594.39\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12576.56\n",
      " Regression with ARIMA(0,0,0) errors : -8968.532\n",
      " Regression with ARIMA(1,0,0) errors : -12555.14\n",
      " Regression with ARIMA(0,0,1) errors : -10657.19\n",
      " Regression with ARIMA(0,0,0) errors : -7936.331\n",
      " Regression with ARIMA(1,0,2) errors : -12569.91\n",
      " Regression with ARIMA(2,0,1) errors : -12570.88\n",
      " Regression with ARIMA(3,0,2) errors : -12594.83\n",
      " Regression with ARIMA(3,0,1) errors : -12583.62\n",
      " Regression with ARIMA(4,0,2) errors : -12601.21\n",
      " Regression with ARIMA(4,0,1) errors : -12602.62\n",
      " Regression with ARIMA(4,0,0) errors : -12603.98\n",
      " Regression with ARIMA(3,0,0) errors : -12574.44\n",
      " Regression with ARIMA(5,0,0) errors : -12601.82\n",
      " Regression with ARIMA(5,0,1) errors : -12626.33\n",
      " Regression with ARIMA(5,0,2) errors : -12625.22\n",
      " Regression with ARIMA(5,0,1) errors : -12547.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12620.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12601.85\n",
      " Regression with ARIMA(0,0,0) errors : -9048.224\n",
      " Regression with ARIMA(1,0,0) errors : -12582.93\n",
      " Regression with ARIMA(0,0,1) errors : -10732.82\n",
      " Regression with ARIMA(0,0,0) errors : -8067.123\n",
      " Regression with ARIMA(1,0,2) errors : -12598.44\n",
      " Regression with ARIMA(2,0,1) errors : -12601.12\n",
      " Regression with ARIMA(3,0,2) errors : -12619.05\n",
      " Regression with ARIMA(3,0,1) errors : -12618.74\n",
      " Regression with ARIMA(4,0,2) errors : -12650.56\n",
      " Regression with ARIMA(4,0,1) errors : -12652.27\n",
      " Regression with ARIMA(4,0,0) errors : -12652.06\n",
      " Regression with ARIMA(5,0,1) errors : -12662.55\n",
      " Regression with ARIMA(5,0,0) errors : -12658.45\n",
      " Regression with ARIMA(5,0,2) errors : -12663.08\n",
      " Regression with ARIMA(5,0,3) errors : -12661.14\n",
      " Regression with ARIMA(4,0,3) errors : -12649.44\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -12652.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12607.62\n",
      " Regression with ARIMA(0,0,0) errors : -9029.222\n",
      " Regression with ARIMA(1,0,0) errors : -12581.78\n",
      " Regression with ARIMA(0,0,1) errors : -10679.8\n",
      " Regression with ARIMA(0,0,0) errors : -7988.616\n",
      " Regression with ARIMA(1,0,2) errors : -12606.76\n",
      " Regression with ARIMA(2,0,1) errors : -12606.03\n",
      " Regression with ARIMA(3,0,2) errors : -12633.3\n",
      " Regression with ARIMA(3,0,1) errors : -12616.63\n",
      " Regression with ARIMA(4,0,2) errors : -12637.18\n",
      " Regression with ARIMA(4,0,1) errors : -12639.14\n",
      " Regression with ARIMA(4,0,0) errors : -12638.63\n",
      " Regression with ARIMA(5,0,1) errors : -12657.77\n",
      " Regression with ARIMA(5,0,0) errors : -12639.34\n",
      " Regression with ARIMA(5,0,2) errors : -12656.11\n",
      " Regression with ARIMA(5,0,1) errors : -12576.93\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12665.38\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12515.14\n",
      " Regression with ARIMA(0,1,0) errors : -12443.47\n",
      " Regression with ARIMA(1,1,0) errors : -12487.68\n",
      " Regression with ARIMA(0,1,1) errors : -12495.53\n",
      " Regression with ARIMA(0,1,0) errors : -12445.47\n",
      " Regression with ARIMA(1,1,2) errors : -12499.79\n",
      " Regression with ARIMA(2,1,1) errors : -12505.72\n",
      " Regression with ARIMA(3,1,2) errors : -12545.83\n",
      " Regression with ARIMA(3,1,1) errors : -12512.71\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -12547.75\n",
      " Regression with ARIMA(2,1,2) errors : -12517.15\n",
      " Regression with ARIMA(3,1,1) errors : -12514.72\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -12507.73\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12527.28\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12606.67\n",
      " Regression with ARIMA(0,0,0) errors : -9078.123\n",
      " Regression with ARIMA(1,0,0) errors : -12575.25\n",
      " Regression with ARIMA(0,0,1) errors : -10725.64\n",
      " Regression with ARIMA(0,0,0) errors : -8063.193\n",
      " Regression with ARIMA(1,0,2) errors : -12597.15\n",
      " Regression with ARIMA(2,0,1) errors : -12601.19\n",
      " Regression with ARIMA(3,0,2) errors : -12625.54\n",
      " Regression with ARIMA(3,0,1) errors : -12611.94\n",
      " Regression with ARIMA(4,0,2) errors : -12627.49\n",
      " Regression with ARIMA(4,0,1) errors : -12627.75\n",
      " Regression with ARIMA(4,0,0) errors : -12627.47\n",
      " Regression with ARIMA(5,0,1) errors : -12646.75\n",
      " Regression with ARIMA(5,0,0) errors : -12630.02\n",
      " Regression with ARIMA(5,0,2) errors : -12645.2\n",
      " Regression with ARIMA(5,0,1) errors : -12548.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12650.4\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12592.63\n",
      " Regression with ARIMA(0,0,0) errors : -9082.048\n",
      " Regression with ARIMA(1,0,0) errors : -12566.66\n",
      " Regression with ARIMA(0,0,1) errors : -10726.09\n",
      " Regression with ARIMA(0,0,0) errors : -8059.077\n",
      " Regression with ARIMA(1,0,2) errors : -12588.96\n",
      " Regression with ARIMA(2,0,1) errors : -12589.11\n",
      " Regression with ARIMA(3,0,2) errors : -12638.23\n",
      " Regression with ARIMA(3,0,1) errors : -12600.16\n",
      " Regression with ARIMA(4,0,2) errors : -12617.62\n",
      " Regression with ARIMA(3,0,3) errors : -12618.48\n",
      " Regression with ARIMA(2,0,3) errors : -12614.14\n",
      " Regression with ARIMA(4,0,1) errors : -12616.7\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12548.15\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12652.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12584\n",
      " Regression with ARIMA(0,0,0) errors : -9072.623\n",
      " Regression with ARIMA(1,0,0) errors : -12558.92\n",
      " Regression with ARIMA(0,0,1) errors : -10724.45\n",
      " Regression with ARIMA(0,0,0) errors : -8059.797\n",
      " Regression with ARIMA(1,0,2) errors : -12579.62\n",
      " Regression with ARIMA(2,0,1) errors : -12579.45\n",
      " Regression with ARIMA(3,0,2) errors : -12637.15\n",
      " Regression with ARIMA(3,0,1) errors : -12590.09\n",
      " Regression with ARIMA(4,0,2) errors : -12609.14\n",
      " Regression with ARIMA(3,0,3) errors : -12608.81\n",
      " Regression with ARIMA(2,0,3) errors : -12605.33\n",
      " Regression with ARIMA(4,0,1) errors : -12609.45\n",
      " Regression with ARIMA(4,0,3) errors : -12638.04\n",
      " Regression with ARIMA(5,0,3) errors : -12624.89\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12633.6\n",
      " Regression with ARIMA(5,0,2) errors : -12623.44\n",
      " Regression with ARIMA(5,0,4) errors : -12618.15\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12645.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12597.56\n",
      " Regression with ARIMA(0,0,0) errors : -9087.133\n",
      " Regression with ARIMA(1,0,0) errors : -12572.15\n",
      " Regression with ARIMA(0,0,1) errors : -10736.93\n",
      " Regression with ARIMA(0,0,0) errors : -8079.117\n",
      " Regression with ARIMA(1,0,2) errors : -12594.14\n",
      " Regression with ARIMA(2,0,1) errors : -12593.03\n",
      " Regression with ARIMA(3,0,2) errors : -12658.36\n",
      " Regression with ARIMA(3,0,1) errors : -12603.77\n",
      " Regression with ARIMA(4,0,2) errors : -12622.07\n",
      " Regression with ARIMA(3,0,3) errors : -12622.59\n",
      " Regression with ARIMA(2,0,3) errors : -12619.12\n",
      " Regression with ARIMA(4,0,1) errors : -12620.82\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12548.61\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12655.81\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12610.85\n",
      " Regression with ARIMA(0,0,0) errors : -9095.509\n",
      " Regression with ARIMA(1,0,0) errors : -12584.86\n",
      " Regression with ARIMA(0,0,1) errors : -10749.33\n",
      " Regression with ARIMA(0,0,0) errors : -8097.852\n",
      " Regression with ARIMA(1,0,2) errors : -12606.97\n",
      " Regression with ARIMA(2,0,1) errors : -12608.39\n",
      " Regression with ARIMA(3,0,2) errors : -12658.34\n",
      " Regression with ARIMA(3,0,1) errors : -12619.38\n",
      " Regression with ARIMA(4,0,2) errors : -12636.67\n",
      " Regression with ARIMA(3,0,3) errors : -12637.2\n",
      " Regression with ARIMA(2,0,3) errors : -12634.49\n",
      " Regression with ARIMA(4,0,1) errors : -12636.79\n",
      " Regression with ARIMA(4,0,3) errors : -12679.01\n",
      " Regression with ARIMA(5,0,3) errors : -12665.31\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12669.72\n",
      " Regression with ARIMA(5,0,2) errors : -12665.96\n",
      " Regression with ARIMA(5,0,4) errors : -12644.1\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12661.83\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.42\n",
      " Regression with ARIMA(0,0,0) errors : -9117.955\n",
      " Regression with ARIMA(1,0,0) errors : -12604.61\n",
      " Regression with ARIMA(0,0,1) errors : -10769.78\n",
      " Regression with ARIMA(0,0,0) errors : -8106.906\n",
      " Regression with ARIMA(1,0,2) errors : -12626.91\n",
      " Regression with ARIMA(2,0,1) errors : -12625.67\n",
      " Regression with ARIMA(3,0,2) errors : -12690.09\n",
      " Regression with ARIMA(3,0,1) errors : -12637.43\n",
      " Regression with ARIMA(4,0,2) errors : -12655.81\n",
      " Regression with ARIMA(3,0,3) errors : -12655.49\n",
      " Regression with ARIMA(2,0,3) errors : -12652.79\n",
      " Regression with ARIMA(4,0,1) errors : -12654.8\n",
      " Regression with ARIMA(4,0,3) errors : -12693.24\n",
      " Regression with ARIMA(5,0,3) errors : -12662.02\n",
      " Regression with ARIMA(4,0,4) errors : -12671.03\n",
      " Regression with ARIMA(3,0,4) errors : -12677.48\n",
      " Regression with ARIMA(5,0,2) errors : -12662.99\n",
      " Regression with ARIMA(5,0,4) errors : -12675.56\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12692.59\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12641.13\n",
      " Regression with ARIMA(0,0,0) errors : -9120.512\n",
      " Regression with ARIMA(1,0,0) errors : -12614.69\n",
      " Regression with ARIMA(0,0,1) errors : -10777.29\n",
      " Regression with ARIMA(0,0,0) errors : -8113.97\n",
      " Regression with ARIMA(1,0,2) errors : -12636.3\n",
      " Regression with ARIMA(2,0,1) errors : -12634.97\n",
      " Regression with ARIMA(3,0,2) errors : -12703.57\n",
      " Regression with ARIMA(3,0,1) errors : -12648.05\n",
      " Regression with ARIMA(4,0,2) errors : -12667.51\n",
      " Regression with ARIMA(3,0,3) errors : -12666.81\n",
      " Regression with ARIMA(2,0,3) errors : -12663.2\n",
      " Regression with ARIMA(4,0,1) errors : -12665.98\n",
      " Regression with ARIMA(4,0,3) errors : -12703.17\n",
      " Regression with ARIMA(3,0,2) errors : -12608.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.93\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12643.6\n",
      " Regression with ARIMA(0,0,0) errors : -9119.216\n",
      " Regression with ARIMA(1,0,0) errors : -12616.26\n",
      " Regression with ARIMA(0,0,1) errors : -10777.52\n",
      " Regression with ARIMA(0,0,0) errors : -8101.041\n",
      " Regression with ARIMA(1,0,2) errors : -12637.47\n",
      " Regression with ARIMA(2,0,1) errors : -12640.52\n",
      " Regression with ARIMA(3,0,2) errors : -12680.71\n",
      " Regression with ARIMA(3,0,1) errors : -12652.57\n",
      " Regression with ARIMA(4,0,2) errors : -12672.29\n",
      " Regression with ARIMA(3,0,3) errors : -12671.04\n",
      " Regression with ARIMA(2,0,3) errors : -12668.46\n",
      " Regression with ARIMA(4,0,1) errors : -12671.99\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12605.13\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12704.4\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12641.82\n",
      " Regression with ARIMA(0,0,0) errors : -9125.129\n",
      " Regression with ARIMA(1,0,0) errors : -12617.13\n",
      " Regression with ARIMA(0,0,1) errors : -10783.88\n",
      " Regression with ARIMA(0,0,0) errors : -8122.685\n",
      " Regression with ARIMA(1,0,2) errors : -12638.09\n",
      " Regression with ARIMA(2,0,1) errors : -12636.93\n",
      " Regression with ARIMA(3,0,2) errors : -12695.39\n",
      " Regression with ARIMA(3,0,1) errors : -12649.51\n",
      " Regression with ARIMA(4,0,2) errors : -12667.03\n",
      " Regression with ARIMA(3,0,3) errors : -12667.49\n",
      " Regression with ARIMA(2,0,3) errors : -12664.06\n",
      " Regression with ARIMA(4,0,1) errors : -12666.82\n",
      " Regression with ARIMA(4,0,3) errors : -12707.83\n",
      " Regression with ARIMA(5,0,3) errors : -12686.77\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12686.56\n",
      " Regression with ARIMA(5,0,2) errors : -12685.94\n",
      " Regression with ARIMA(5,0,4) errors : -12670.08\n",
      " Regression with ARIMA(4,0,3) errors : -12637.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12704.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12640.83\n",
      " Regression with ARIMA(0,0,0) errors : -9124.201\n",
      " Regression with ARIMA(1,0,0) errors : -12614.79\n",
      " Regression with ARIMA(0,0,1) errors : -10783.44\n",
      " Regression with ARIMA(0,0,0) errors : -8122.209\n",
      " Regression with ARIMA(1,0,2) errors : -12635.64\n",
      " Regression with ARIMA(2,0,1) errors : -12634.86\n",
      " Regression with ARIMA(3,0,2) errors : -12695.41\n",
      " Regression with ARIMA(3,0,1) errors : -12647.57\n",
      " Regression with ARIMA(4,0,2) errors : -12665.91\n",
      " Regression with ARIMA(3,0,3) errors : -12665.62\n",
      " Regression with ARIMA(2,0,3) errors : -12662.3\n",
      " Regression with ARIMA(4,0,1) errors : -12664.73\n",
      " Regression with ARIMA(4,0,3) errors : -12708.36\n",
      " Regression with ARIMA(5,0,3) errors : -12683.74\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12676.17\n",
      " Regression with ARIMA(4,0,3) errors : -12636.53\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12702.9\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.35\n",
      " Regression with ARIMA(0,0,0) errors : -9121.854\n",
      " Regression with ARIMA(1,0,0) errors : -12613.51\n",
      " Regression with ARIMA(0,0,1) errors : -10782.18\n",
      " Regression with ARIMA(0,0,0) errors : -8117.61\n",
      " Regression with ARIMA(1,0,2) errors : -12633.27\n",
      " Regression with ARIMA(2,0,1) errors : -12632.06\n",
      " Regression with ARIMA(3,0,2) errors : -12698.45\n",
      " Regression with ARIMA(3,0,1) errors : -12643.7\n",
      " Regression with ARIMA(4,0,2) errors : -12660.83\n",
      " Regression with ARIMA(3,0,3) errors : -12661.66\n",
      " Regression with ARIMA(2,0,3) errors : -12658.11\n",
      " Regression with ARIMA(4,0,1) errors : -12659.62\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12597.25\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12700.82\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.09\n",
      " Regression with ARIMA(0,0,0) errors : -9116.676\n",
      " Regression with ARIMA(1,0,0) errors : -12611.67\n",
      " Regression with ARIMA(0,0,1) errors : -10780.74\n",
      " Regression with ARIMA(0,0,0) errors : -8116.581\n",
      " Regression with ARIMA(1,0,2) errors : -12630.99\n",
      " Regression with ARIMA(2,0,1) errors : -12629.63\n",
      " Regression with ARIMA(3,0,2) errors : -12699.18\n",
      " Regression with ARIMA(3,0,1) errors : -12641.18\n",
      " Regression with ARIMA(4,0,2) errors : -12658.75\n",
      " Regression with ARIMA(3,0,3) errors : -12659.44\n",
      " Regression with ARIMA(2,0,3) errors : -12655.65\n",
      " Regression with ARIMA(4,0,1) errors : -12657.53\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12615.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12699.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12639.03\n",
      " Regression with ARIMA(0,0,0) errors : -9117.537\n",
      " Regression with ARIMA(1,0,0) errors : -12615.18\n",
      " Regression with ARIMA(0,0,1) errors : -10783.7\n",
      " Regression with ARIMA(0,0,0) errors : -8118.136\n",
      " Regression with ARIMA(1,0,2) errors : -12634.65\n",
      " Regression with ARIMA(2,0,1) errors : -12633.24\n",
      " Regression with ARIMA(3,0,2) errors : -12699.98\n",
      " Regression with ARIMA(3,0,1) errors : -12645.33\n",
      " Regression with ARIMA(4,0,2) errors : -12662.46\n",
      " Regression with ARIMA(3,0,3) errors : -12663.29\n",
      " Regression with ARIMA(2,0,3) errors : -12659.28\n",
      " Regression with ARIMA(4,0,1) errors : -12661.46\n",
      " Regression with ARIMA(4,0,3) errors : -12704.33\n",
      " Regression with ARIMA(5,0,3) errors : -12680.72\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12676.03\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12672.54\n",
      " Regression with ARIMA(4,0,3) errors : -12599.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12703.36\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.78\n",
      " Regression with ARIMA(0,0,0) errors : -9113.603\n",
      " Regression with ARIMA(1,0,0) errors : -12610.36\n",
      " Regression with ARIMA(0,0,1) errors : -10781.97\n",
      " Regression with ARIMA(0,0,0) errors : -8111.354\n",
      " Regression with ARIMA(1,0,2) errors : -12629.21\n",
      " Regression with ARIMA(2,0,1) errors : -12627.93\n",
      " Regression with ARIMA(3,0,2) errors : -12693.18\n",
      " Regression with ARIMA(3,0,1) errors : -12639.63\n",
      " Regression with ARIMA(4,0,2) errors : -12657.34\n",
      " Regression with ARIMA(3,0,3) errors : -12657.78\n",
      " Regression with ARIMA(2,0,3) errors : -12654.23\n",
      " Regression with ARIMA(4,0,1) errors : -12656.4\n",
      " Regression with ARIMA(4,0,3) errors : -12699.31\n",
      " Regression with ARIMA(5,0,3) errors : -12674.55\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12675.54\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12667.95\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.07\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.46\n",
      " Regression with ARIMA(0,0,0) errors : -9119.245\n",
      " Regression with ARIMA(1,0,0) errors : -12613.96\n",
      " Regression with ARIMA(0,0,1) errors : -10785.81\n",
      " Regression with ARIMA(0,0,0) errors : -8116.382\n",
      " Regression with ARIMA(1,0,2) errors : -12632.76\n",
      " Regression with ARIMA(2,0,1) errors : -12631.28\n",
      " Regression with ARIMA(3,0,2) errors : -12700.56\n",
      " Regression with ARIMA(3,0,1) errors : -12643.51\n",
      " Regression with ARIMA(4,0,2) errors : -12660.35\n",
      " Regression with ARIMA(3,0,3) errors : -12660.75\n",
      " Regression with ARIMA(2,0,3) errors : -12657.34\n",
      " Regression with ARIMA(4,0,1) errors : -12659.28\n",
      " Regression with ARIMA(4,0,3) errors : -12705.25\n",
      " Regression with ARIMA(5,0,3) errors : -12677.25\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12659.26\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12674.2\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12701.28\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.91\n",
      " Regression with ARIMA(0,0,0) errors : -9115.346\n",
      " Regression with ARIMA(1,0,0) errors : -12609.25\n",
      " Regression with ARIMA(0,0,1) errors : -10783.59\n",
      " Regression with ARIMA(0,0,0) errors : -8119.022\n",
      " Regression with ARIMA(1,0,2) errors : -12628.07\n",
      " Regression with ARIMA(2,0,1) errors : -12626.55\n",
      " Regression with ARIMA(3,0,2) errors : -12695.08\n",
      " Regression with ARIMA(3,0,1) errors : -12639.09\n",
      " Regression with ARIMA(4,0,2) errors : -12655.57\n",
      " Regression with ARIMA(3,0,3) errors : -12655.97\n",
      " Regression with ARIMA(2,0,3) errors : -12652.64\n",
      " Regression with ARIMA(4,0,1) errors : -12654.48\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12608.86\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12697.61\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12634.77\n",
      " Regression with ARIMA(0,0,0) errors : -9112.722\n",
      " Regression with ARIMA(1,0,0) errors : -12611.67\n",
      " Regression with ARIMA(0,0,1) errors : -10782.69\n",
      " Regression with ARIMA(0,0,0) errors : -8118.407\n",
      " Regression with ARIMA(1,0,2) errors : -12630.3\n",
      " Regression with ARIMA(2,0,1) errors : -12628.79\n",
      " Regression with ARIMA(3,0,2) errors : -12698.97\n",
      " Regression with ARIMA(3,0,1) errors : -12640.78\n",
      " Regression with ARIMA(4,0,2) errors : -12656.92\n",
      " Regression with ARIMA(3,0,3) errors : -12657.7\n",
      " Regression with ARIMA(2,0,3) errors : -12654.48\n",
      " Regression with ARIMA(4,0,1) errors : -12655.94\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12604.1\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12699.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.36\n",
      " Regression with ARIMA(0,0,0) errors : -9119.25\n",
      " Regression with ARIMA(1,0,0) errors : -12613.66\n",
      " Regression with ARIMA(0,0,1) errors : -10784.04\n",
      " Regression with ARIMA(0,0,0) errors : -8121.82\n",
      " Regression with ARIMA(1,0,2) errors : -12632.84\n",
      " Regression with ARIMA(2,0,1) errors : -12631.38\n",
      " Regression with ARIMA(3,0,2) errors : -12686.69\n",
      " Regression with ARIMA(3,0,1) errors : -12643.65\n",
      " Regression with ARIMA(4,0,2) errors : -12661.74\n",
      " Regression with ARIMA(3,0,3) errors : -12661.05\n",
      " Regression with ARIMA(2,0,3) errors : -12657.15\n",
      " Regression with ARIMA(4,0,1) errors : -12661.45\n",
      " Regression with ARIMA(4,0,3) errors : -12661.55\n",
      " Regression with ARIMA(3,0,2) errors : -12592.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.86\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.03\n",
      " Regression with ARIMA(0,0,0) errors : -9124.803\n",
      " Regression with ARIMA(1,0,0) errors : -12611.58\n",
      " Regression with ARIMA(0,0,1) errors : -10785.79\n",
      " Regression with ARIMA(0,0,0) errors : -8120.735\n",
      " Regression with ARIMA(1,0,2) errors : -12631.26\n",
      " Regression with ARIMA(2,0,1) errors : -12629.83\n",
      " Regression with ARIMA(3,0,2) errors : -12695.7\n",
      " Regression with ARIMA(3,0,1) errors : -12642.68\n",
      " Regression with ARIMA(4,0,2) errors : -12659.94\n",
      " Regression with ARIMA(3,0,3) errors : -12660.68\n",
      " Regression with ARIMA(2,0,3) errors : -12655.54\n",
      " Regression with ARIMA(4,0,1) errors : -12658.46\n",
      " Regression with ARIMA(4,0,3) errors : -12702.36\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12659.16\n",
      " Regression with ARIMA(5,0,2) errors : -12657.49\n",
      " Regression with ARIMA(5,0,4) errors : -12659.7\n",
      " Regression with ARIMA(4,0,3) errors : -12584.34\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.35\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12639.64\n",
      " Regression with ARIMA(0,0,0) errors : -9126.097\n",
      " Regression with ARIMA(1,0,0) errors : -12614.91\n",
      " Regression with ARIMA(0,0,1) errors : -10785.02\n",
      " Regression with ARIMA(0,0,0) errors : -8116.995\n",
      " Regression with ARIMA(1,0,2) errors : -12635.07\n",
      " Regression with ARIMA(2,0,1) errors : -12633.58\n",
      " Regression with ARIMA(3,0,2) errors : -12700.58\n",
      " Regression with ARIMA(3,0,1) errors : -12646.01\n",
      " Regression with ARIMA(4,0,2) errors : -12662.46\n",
      " Regression with ARIMA(3,0,3) errors : -12663.22\n",
      " Regression with ARIMA(2,0,3) errors : -12659.45\n",
      " Regression with ARIMA(4,0,1) errors : -12661.32\n",
      " Regression with ARIMA(4,0,3) errors : -12707.82\n",
      " Regression with ARIMA(5,0,3) errors : -12680.87\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.94\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12674.86\n",
      " Regression with ARIMA(4,0,3) errors : -12602.62\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12703.26\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.76\n",
      " Regression with ARIMA(0,0,0) errors : -9126.664\n",
      " Regression with ARIMA(1,0,0) errors : -12610.17\n",
      " Regression with ARIMA(0,0,1) errors : -10784.22\n",
      " Regression with ARIMA(0,0,0) errors : -8120.924\n",
      " Regression with ARIMA(1,0,2) errors : -12630.62\n",
      " Regression with ARIMA(2,0,1) errors : -12629.52\n",
      " Regression with ARIMA(3,0,2) errors : -12694.59\n",
      " Regression with ARIMA(3,0,1) errors : -12642.09\n",
      " Regression with ARIMA(4,0,2) errors : -12658.44\n",
      " Regression with ARIMA(3,0,3) errors : -12658.75\n",
      " Regression with ARIMA(2,0,3) errors : -12655.04\n",
      " Regression with ARIMA(4,0,1) errors : -12657.14\n",
      " Regression with ARIMA(4,0,3) errors : -12704.19\n",
      " Regression with ARIMA(5,0,3) errors : -12674.9\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.25\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12664.74\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.55\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.01\n",
      " Regression with ARIMA(0,0,0) errors : -9129.67\n",
      " Regression with ARIMA(1,0,0) errors : -12606.43\n",
      " Regression with ARIMA(0,0,1) errors : -10786.26\n",
      " Regression with ARIMA(0,0,0) errors : -8109.689\n",
      " Regression with ARIMA(1,0,2) errors : -12626.33\n",
      " Regression with ARIMA(2,0,1) errors : -12625.7\n",
      " Regression with ARIMA(3,0,2) errors : -12685.15\n",
      " Regression with ARIMA(3,0,1) errors : -12638.15\n",
      " Regression with ARIMA(4,0,2) errors : -12654.36\n",
      " Regression with ARIMA(3,0,3) errors : -12654.53\n",
      " Regression with ARIMA(2,0,3) errors : -12651.32\n",
      " Regression with ARIMA(4,0,1) errors : -12653.1\n",
      " Regression with ARIMA(4,0,3) errors : -12701.37\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12653.24\n",
      " Regression with ARIMA(3,0,4) errors : -12676.54\n",
      " Regression with ARIMA(5,0,2) errors : -12652.64\n",
      " Regression with ARIMA(5,0,4) errors : -12668.09\n",
      " Regression with ARIMA(4,0,3) errors : -12590.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.56\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.77\n",
      " Regression with ARIMA(0,0,0) errors : -9125.562\n",
      " Regression with ARIMA(1,0,0) errors : -12610.64\n",
      " Regression with ARIMA(0,0,1) errors : -10785.7\n",
      " Regression with ARIMA(0,0,0) errors : -8108.179\n",
      " Regression with ARIMA(1,0,2) errors : -12630.51\n",
      " Regression with ARIMA(2,0,1) errors : -12629.36\n",
      " Regression with ARIMA(3,0,2) errors : -12694.15\n",
      " Regression with ARIMA(3,0,1) errors : -12642.13\n",
      " Regression with ARIMA(4,0,2) errors : -12658.37\n",
      " Regression with ARIMA(3,0,3) errors : -12658.83\n",
      " Regression with ARIMA(2,0,3) errors : -12655.24\n",
      " Regression with ARIMA(4,0,1) errors : -12657.12\n",
      " Regression with ARIMA(4,0,3) errors : -12704.42\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12679.15\n",
      " Regression with ARIMA(3,0,4) errors : -12677.56\n",
      " Regression with ARIMA(5,0,2) errors : -12656.96\n",
      " Regression with ARIMA(5,0,4) errors : -12670.89\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12699.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.76\n",
      " Regression with ARIMA(0,0,0) errors : -9119.29\n",
      " Regression with ARIMA(1,0,0) errors : -12609.83\n",
      " Regression with ARIMA(0,0,1) errors : -10782.32\n",
      " Regression with ARIMA(0,0,0) errors : -8104.093\n",
      " Regression with ARIMA(1,0,2) errors : -12629.02\n",
      " Regression with ARIMA(2,0,1) errors : -12627.65\n",
      " Regression with ARIMA(3,0,2) errors : -12693.41\n",
      " Regression with ARIMA(3,0,1) errors : -12640.24\n",
      " Regression with ARIMA(4,0,2) errors : -12657.4\n",
      " Regression with ARIMA(3,0,3) errors : -12657.65\n",
      " Regression with ARIMA(2,0,3) errors : -12654\n",
      " Regression with ARIMA(4,0,1) errors : -12655.98\n",
      " Regression with ARIMA(4,0,3) errors : -12700.63\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12678.52\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12666.19\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.72\n",
      " Regression with ARIMA(0,0,0) errors : -9127.533\n",
      " Regression with ARIMA(1,0,0) errors : -12608.51\n",
      " Regression with ARIMA(0,0,1) errors : -10784.58\n",
      " Regression with ARIMA(0,0,0) errors : -8099.693\n",
      " Regression with ARIMA(1,0,2) errors : -12627.71\n",
      " Regression with ARIMA(2,0,1) errors : -12626.53\n",
      " Regression with ARIMA(3,0,2) errors : -12687.4\n",
      " Regression with ARIMA(3,0,1) errors : -12638.82\n",
      " Regression with ARIMA(4,0,2) errors : -12655.24\n",
      " Regression with ARIMA(3,0,3) errors : -12655.99\n",
      " Regression with ARIMA(2,0,3) errors : -12651.92\n",
      " Regression with ARIMA(4,0,1) errors : -12654.76\n",
      " Regression with ARIMA(4,0,3) errors : -12698.43\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12654.62\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -12611.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12696.67\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.19\n",
      " Regression with ARIMA(0,0,0) errors : -9131.072\n",
      " Regression with ARIMA(1,0,0) errors : -12612.33\n",
      " Regression with ARIMA(0,0,1) errors : -10786.34\n",
      " Regression with ARIMA(0,0,0) errors : -8111.89\n",
      " Regression with ARIMA(1,0,2) errors : -12632.14\n",
      " Regression with ARIMA(2,0,1) errors : -12630.94\n",
      " Regression with ARIMA(3,0,2) errors : -12697.09\n",
      " Regression with ARIMA(3,0,1) errors : -12642.55\n",
      " Regression with ARIMA(4,0,2) errors : -12659.42\n",
      " Regression with ARIMA(3,0,3) errors : -12660.03\n",
      " Regression with ARIMA(2,0,3) errors : -12656.53\n",
      " Regression with ARIMA(4,0,1) errors : -12658.14\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12614.5\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12700.42\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.26\n",
      " Regression with ARIMA(0,0,0) errors : -9126.592\n",
      " Regression with ARIMA(1,0,0) errors : -12609.67\n",
      " Regression with ARIMA(0,0,1) errors : -10781.77\n",
      " Regression with ARIMA(0,0,0) errors : -8113.176\n",
      " Regression with ARIMA(1,0,2) errors : -12629.18\n",
      " Regression with ARIMA(2,0,1) errors : -12627.73\n",
      " Regression with ARIMA(3,0,2) errors : -12692.71\n",
      " Regression with ARIMA(3,0,1) errors : -12639.26\n",
      " Regression with ARIMA(4,0,2) errors : -12656.27\n",
      " Regression with ARIMA(3,0,3) errors : -12657.03\n",
      " Regression with ARIMA(2,0,3) errors : -12652.75\n",
      " Regression with ARIMA(4,0,1) errors : -12654.72\n",
      " Regression with ARIMA(4,0,3) errors : -12699.6\n",
      " Regression with ARIMA(5,0,3) errors : -12672.77\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12668.99\n",
      " Regression with ARIMA(4,0,3) errors : -12626.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12697.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.51\n",
      " Regression with ARIMA(0,0,0) errors : -9120.766\n",
      " Regression with ARIMA(1,0,0) errors : -12607\n",
      " Regression with ARIMA(0,0,1) errors : -10776.09\n",
      " Regression with ARIMA(0,0,0) errors : -8111.103\n",
      " Regression with ARIMA(1,0,2) errors : -12626.77\n",
      " Regression with ARIMA(2,0,1) errors : -12625.53\n",
      " Regression with ARIMA(3,0,2) errors : -12685.73\n",
      " Regression with ARIMA(3,0,1) errors : -12637.75\n",
      " Regression with ARIMA(4,0,2) errors : -12654.14\n",
      " Regression with ARIMA(3,0,3) errors : -12654.51\n",
      " Regression with ARIMA(2,0,3) errors : -12650.91\n",
      " Regression with ARIMA(4,0,1) errors : -12654.37\n",
      " Regression with ARIMA(4,0,3) errors : -12686.13\n",
      " Regression with ARIMA(5,0,3) errors : -12700.25\n",
      " Regression with ARIMA(5,0,2) errors : -12654.47\n",
      " Regression with ARIMA(5,0,4) errors : -12662.71\n",
      " Regression with ARIMA(4,0,4) errors : -12698.47\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : -12673.47\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12629.83\n",
      " Regression with ARIMA(0,0,0) errors : -9123.342\n",
      " Regression with ARIMA(1,0,0) errors : -12606.52\n",
      " Regression with ARIMA(0,0,1) errors : -10778\n",
      " Regression with ARIMA(0,0,0) errors : -8105.722\n",
      " Regression with ARIMA(1,0,2) errors : -12626.01\n",
      " Regression with ARIMA(2,0,1) errors : -12624.6\n",
      " Regression with ARIMA(3,0,2) errors : -12689.93\n",
      " Regression with ARIMA(3,0,1) errors : -12636.27\n",
      " Regression with ARIMA(4,0,2) errors : -12652.8\n",
      " Regression with ARIMA(3,0,3) errors : -12653.27\n",
      " Regression with ARIMA(2,0,3) errors : -12649.98\n",
      " Regression with ARIMA(4,0,1) errors : -12652.27\n",
      " Regression with ARIMA(4,0,3) errors : -12694.07\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12670.15\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12654.04\n",
      " Regression with ARIMA(4,0,3) errors : -12618.5\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.06\n",
      " Regression with ARIMA(0,0,0) errors : -9131.681\n",
      " Regression with ARIMA(1,0,0) errors : -12608.01\n",
      " Regression with ARIMA(0,0,1) errors : -10782.66\n",
      " Regression with ARIMA(0,0,0) errors : -8107.119\n",
      " Regression with ARIMA(1,0,2) errors : -12628.11\n",
      " Regression with ARIMA(2,0,1) errors : -12626.67\n",
      " Regression with ARIMA(3,0,2) errors : -12693.49\n",
      " Regression with ARIMA(3,0,1) errors : -12638.11\n",
      " Regression with ARIMA(4,0,2) errors : -12655.3\n",
      " Regression with ARIMA(3,0,3) errors : -12655.92\n",
      " Regression with ARIMA(2,0,3) errors : -12652.11\n",
      " Regression with ARIMA(4,0,1) errors : -12653.8\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12610.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12696.06\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.24\n",
      " Regression with ARIMA(0,0,0) errors : -9131.239\n",
      " Regression with ARIMA(1,0,0) errors : -12606.95\n",
      " Regression with ARIMA(0,0,1) errors : -10780.44\n",
      " Regression with ARIMA(0,0,0) errors : -8112.5\n",
      " Regression with ARIMA(1,0,2) errors : -12627\n",
      " Regression with ARIMA(2,0,1) errors : -12625.5\n",
      " Regression with ARIMA(3,0,2) errors : -12689.64\n",
      " Regression with ARIMA(3,0,1) errors : -12638.39\n",
      " Regression with ARIMA(4,0,2) errors : -12654.7\n",
      " Regression with ARIMA(3,0,3) errors : -12654.57\n",
      " Regression with ARIMA(2,0,3) errors : -12650.34\n",
      " Regression with ARIMA(4,0,1) errors : -12654\n",
      " Regression with ARIMA(4,0,3) errors : -12691.8\n",
      " Regression with ARIMA(5,0,3) errors : -12674.84\n",
      " Regression with ARIMA(4,0,4) errors : -12670.68\n",
      " Regression with ARIMA(3,0,4) errors : -12676.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12662.77\n",
      " Regression with ARIMA(4,0,3) errors : -12620.21\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.43\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.92\n",
      " Regression with ARIMA(0,0,0) errors : -9128.861\n",
      " Regression with ARIMA(1,0,0) errors : -12610.07\n",
      " Regression with ARIMA(0,0,1) errors : -10783.53\n",
      " Regression with ARIMA(0,0,0) errors : -8110.608\n",
      " Regression with ARIMA(1,0,2) errors : -12629.79\n",
      " Regression with ARIMA(2,0,1) errors : -12628.8\n",
      " Regression with ARIMA(3,0,2) errors : -12690.81\n",
      " Regression with ARIMA(3,0,1) errors : -12640.88\n",
      " Regression with ARIMA(4,0,2) errors : -12657.06\n",
      " Regression with ARIMA(3,0,3) errors : -12657.59\n",
      " Regression with ARIMA(2,0,3) errors : -12654.11\n",
      " Regression with ARIMA(4,0,1) errors : -12656.04\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12597.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12697.96\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12634.62\n",
      " Regression with ARIMA(0,0,0) errors : -9126.781\n",
      " Regression with ARIMA(1,0,0) errors : -12610.65\n",
      " Regression with ARIMA(0,0,1) errors : -10781.97\n",
      " Regression with ARIMA(0,0,0) errors : -8113.142\n",
      " Regression with ARIMA(1,0,2) errors : -12630.54\n",
      " Regression with ARIMA(2,0,1) errors : -12629.23\n",
      " Regression with ARIMA(3,0,2) errors : -12696.42\n",
      " Regression with ARIMA(3,0,1) errors : -12641.18\n",
      " Regression with ARIMA(4,0,2) errors : -12657.47\n",
      " Regression with ARIMA(3,0,3) errors : -12658.27\n",
      " Regression with ARIMA(2,0,3) errors : -12654.69\n",
      " Regression with ARIMA(4,0,1) errors : -12656.72\n",
      " Regression with ARIMA(4,0,3) errors : -12703.68\n",
      " Regression with ARIMA(5,0,3) errors : -12677.09\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12669.72\n",
      " Regression with ARIMA(4,0,3) errors : -12577.74\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.4\n",
      " Regression with ARIMA(0,0,0) errors : -9125.689\n",
      " Regression with ARIMA(1,0,0) errors : -12612.41\n",
      " Regression with ARIMA(0,0,1) errors : -10783.44\n",
      " Regression with ARIMA(0,0,0) errors : -8112.957\n",
      " Regression with ARIMA(1,0,2) errors : -12632.37\n",
      " Regression with ARIMA(2,0,1) errors : -12631.02\n",
      " Regression with ARIMA(3,0,2) errors : -12698.98\n",
      " Regression with ARIMA(3,0,1) errors : -12642.99\n",
      " Regression with ARIMA(4,0,2) errors : -12659.39\n",
      " Regression with ARIMA(3,0,3) errors : -12660.05\n",
      " Regression with ARIMA(2,0,3) errors : -12656.41\n",
      " Regression with ARIMA(4,0,1) errors : -12658.4\n",
      " Regression with ARIMA(4,0,3) errors : -12705.73\n",
      " Regression with ARIMA(5,0,3) errors : -12677.06\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12682.47\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12672.68\n",
      " Regression with ARIMA(4,0,3) errors : -12592.32\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.68\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.3\n",
      " Regression with ARIMA(0,0,0) errors : -9115.868\n",
      " Regression with ARIMA(1,0,0) errors : -12611.51\n",
      " Regression with ARIMA(0,0,1) errors : -10777.8\n",
      " Regression with ARIMA(0,0,0) errors : -8111.841\n",
      " Regression with ARIMA(1,0,2) errors : -12631.09\n",
      " Regression with ARIMA(2,0,1) errors : -12629.64\n",
      " Regression with ARIMA(3,0,2) errors : -12698.43\n",
      " Regression with ARIMA(3,0,1) errors : -12641.39\n",
      " Regression with ARIMA(4,0,2) errors : -12658.34\n",
      " Regression with ARIMA(3,0,3) errors : -12658.92\n",
      " Regression with ARIMA(2,0,3) errors : -12655.53\n",
      " Regression with ARIMA(4,0,1) errors : -12657.54\n",
      " Regression with ARIMA(4,0,3) errors : -12704.55\n",
      " Regression with ARIMA(5,0,3) errors : -12677.45\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12671.36\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.66\n",
      " Regression with ARIMA(0,0,0) errors : -9124.945\n",
      " Regression with ARIMA(1,0,0) errors : -12612.72\n",
      " Regression with ARIMA(0,0,1) errors : -10780.08\n",
      " Regression with ARIMA(0,0,0) errors : -8108.834\n",
      " Regression with ARIMA(1,0,2) errors : -12632.51\n",
      " Regression with ARIMA(2,0,1) errors : -12631.82\n",
      " Regression with ARIMA(3,0,2) errors : -12694.27\n",
      " Regression with ARIMA(3,0,1) errors : -12643.59\n",
      " Regression with ARIMA(4,0,2) errors : -12660.23\n",
      " Regression with ARIMA(3,0,3) errors : -12660.57\n",
      " Regression with ARIMA(2,0,3) errors : -12657.73\n",
      " Regression with ARIMA(4,0,1) errors : -12659.39\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12588.55\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.13\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12627.74\n",
      " Regression with ARIMA(0,0,0) errors : -9117.039\n",
      " Regression with ARIMA(1,0,0) errors : -12604.36\n",
      " Regression with ARIMA(0,0,1) errors : -10772.74\n",
      " Regression with ARIMA(0,0,0) errors : -8100.168\n",
      " Regression with ARIMA(1,0,2) errors : -12624.03\n",
      " Regression with ARIMA(2,0,1) errors : -12622.73\n",
      " Regression with ARIMA(3,0,2) errors : -12688.87\n",
      " Regression with ARIMA(3,0,1) errors : -12635.29\n",
      " Regression with ARIMA(4,0,2) errors : -12652.41\n",
      " Regression with ARIMA(3,0,3) errors : -12652.42\n",
      " Regression with ARIMA(2,0,3) errors : -12648.98\n",
      " Regression with ARIMA(4,0,1) errors : -12651.73\n",
      " Regression with ARIMA(4,0,3) errors : -12695.02\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12668.42\n",
      " Regression with ARIMA(3,0,4) errors : -12666.86\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12662.55\n",
      " Regression with ARIMA(4,0,3) errors : -12583.67\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12692.62\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12629.95\n",
      " Regression with ARIMA(0,0,0) errors : -9111.839\n",
      " Regression with ARIMA(1,0,0) errors : -12606.59\n",
      " Regression with ARIMA(0,0,1) errors : -10768.97\n",
      " Regression with ARIMA(0,0,0) errors : -8094.359\n",
      " Regression with ARIMA(1,0,2) errors : -12626.11\n",
      " Regression with ARIMA(2,0,1) errors : -12624.99\n",
      " Regression with ARIMA(3,0,2) errors : -12691.49\n",
      " Regression with ARIMA(3,0,1) errors : -12636.29\n",
      " Regression with ARIMA(4,0,2) errors : -12654.61\n",
      " Regression with ARIMA(3,0,3) errors : -12655.25\n",
      " Regression with ARIMA(2,0,3) errors : -12651.79\n",
      " Regression with ARIMA(4,0,1) errors : -12653.54\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12606.28\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12694.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12625.86\n",
      " Regression with ARIMA(0,0,0) errors : -9104.057\n",
      " Regression with ARIMA(1,0,0) errors : -12602.52\n",
      " Regression with ARIMA(0,0,1) errors : -10763.32\n",
      " Regression with ARIMA(0,0,0) errors : -8093.859\n",
      " Regression with ARIMA(1,0,2) errors : -12621.83\n",
      " Regression with ARIMA(2,0,1) errors : -12620.75\n",
      " Regression with ARIMA(3,0,2) errors : -12688.22\n",
      " Regression with ARIMA(3,0,1) errors : -12631.52\n",
      " Regression with ARIMA(4,0,2) errors : -12652.06\n",
      " Regression with ARIMA(3,0,3) errors : -12650.46\n",
      " Regression with ARIMA(2,0,3) errors : -12647.56\n",
      " Regression with ARIMA(4,0,1) errors : -12651.23\n",
      " Regression with ARIMA(4,0,3) errors : -12681.28\n",
      " Regression with ARIMA(3,0,2) errors : -12603.68\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12690.63\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12618.91\n",
      " Regression with ARIMA(0,0,0) errors : -9103.363\n",
      " Regression with ARIMA(1,0,0) errors : -12597.31\n",
      " Regression with ARIMA(0,0,1) errors : -10765.68\n",
      " Regression with ARIMA(0,0,0) errors : -8091.292\n",
      " Regression with ARIMA(1,0,2) errors : -12615.19\n",
      " Regression with ARIMA(2,0,1) errors : -12613.85\n",
      " Regression with ARIMA(3,0,2) errors : -12682.31\n",
      " Regression with ARIMA(3,0,1) errors : -12625.35\n",
      " Regression with ARIMA(4,0,2) errors : -12644.79\n",
      " Regression with ARIMA(3,0,3) errors : -12644.37\n",
      " Regression with ARIMA(2,0,3) errors : -12640.45\n",
      " Regression with ARIMA(4,0,1) errors : -12643.65\n",
      " Regression with ARIMA(4,0,3) errors : -12682.08\n",
      " Regression with ARIMA(3,0,2) errors : -12580.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12684.69\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12615.06\n",
      " Regression with ARIMA(0,0,0) errors : -9099.58\n",
      " Regression with ARIMA(1,0,0) errors : -12592.84\n",
      " Regression with ARIMA(0,0,1) errors : -10762.48\n",
      " Regression with ARIMA(0,0,0) errors : -8087.004\n",
      " Regression with ARIMA(1,0,2) errors : -12610.83\n",
      " Regression with ARIMA(2,0,1) errors : -12609.67\n",
      " Regression with ARIMA(3,0,2) errors : -12677.21\n",
      " Regression with ARIMA(3,0,1) errors : -12621.08\n",
      " Regression with ARIMA(4,0,2) errors : -12640.17\n",
      " Regression with ARIMA(3,0,3) errors : -12640.85\n",
      " Regression with ARIMA(2,0,3) errors : -12636.93\n",
      " Regression with ARIMA(4,0,1) errors : -12638.83\n",
      " Regression with ARIMA(4,0,3) errors : -12684.27\n",
      " Regression with ARIMA(5,0,3) errors : -12658.04\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12639.53\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12654.82\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12680.01\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12613.46\n",
      " Regression with ARIMA(0,0,0) errors : -9099.695\n",
      " Regression with ARIMA(1,0,0) errors : -12591.66\n",
      " Regression with ARIMA(0,0,1) errors : -10763.22\n",
      " Regression with ARIMA(0,0,0) errors : -8089.962\n",
      " Regression with ARIMA(1,0,2) errors : -12609.68\n",
      " Regression with ARIMA(2,0,1) errors : -12608.39\n",
      " Regression with ARIMA(3,0,2) errors : -12677.01\n",
      " Regression with ARIMA(3,0,1) errors : -12619.63\n",
      " Regression with ARIMA(4,0,2) errors : -12638.73\n",
      " Regression with ARIMA(3,0,3) errors : -12639.14\n",
      " Regression with ARIMA(2,0,3) errors : -12635.44\n",
      " Regression with ARIMA(4,0,1) errors : -12637.36\n",
      " Regression with ARIMA(4,0,3) errors : -12681.2\n",
      " Regression with ARIMA(5,0,3) errors : -12656.69\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12660.48\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12652.18\n",
      " Regression with ARIMA(4,0,3) errors : -12597.54\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12678.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12615.16\n",
      " Regression with ARIMA(0,0,0) errors : -9100.818\n",
      " Regression with ARIMA(1,0,0) errors : -12593.22\n",
      " Regression with ARIMA(0,0,1) errors : -10765.31\n",
      " Regression with ARIMA(0,0,0) errors : -8091.06\n",
      " Regression with ARIMA(1,0,2) errors : -12611.24\n",
      " Regression with ARIMA(2,0,1) errors : -12609.93\n",
      " Regression with ARIMA(3,0,2) errors : -12679.3\n",
      " Regression with ARIMA(3,0,1) errors : -12621.06\n",
      " Regression with ARIMA(4,0,2) errors : -12639.78\n",
      " Regression with ARIMA(3,0,3) errors : -12640.43\n",
      " Regression with ARIMA(2,0,3) errors : -12636.97\n",
      " Regression with ARIMA(4,0,1) errors : -12638.66\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12594.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12679.67\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12617.12\n",
      " Regression with ARIMA(0,0,0) errors : -9109.583\n",
      " Regression with ARIMA(1,0,0) errors : -12595.07\n",
      " Regression with ARIMA(0,0,1) errors : -10771.08\n",
      " Regression with ARIMA(0,0,0) errors : -8093.37\n",
      " Regression with ARIMA(1,0,2) errors : -12613.21\n",
      " Regression with ARIMA(2,0,1) errors : -12611.88\n",
      " Regression with ARIMA(3,0,2) errors : -12678.72\n",
      " Regression with ARIMA(3,0,1) errors : -12623\n",
      " Regression with ARIMA(4,0,2) errors : -12641.23\n",
      " Regression with ARIMA(3,0,3) errors : -12641.89\n",
      " Regression with ARIMA(2,0,3) errors : -12638.42\n",
      " Regression with ARIMA(4,0,1) errors : -12640.06\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12592.8\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12681.68\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12619.74\n",
      " Regression with ARIMA(0,0,0) errors : -9112.072\n",
      " Regression with ARIMA(1,0,0) errors : -12597.43\n",
      " Regression with ARIMA(0,0,1) errors : -10771.67\n",
      " Regression with ARIMA(0,0,0) errors : -8099.27\n",
      " Regression with ARIMA(1,0,2) errors : -12615.95\n",
      " Regression with ARIMA(2,0,1) errors : -12614.81\n",
      " Regression with ARIMA(3,0,2) errors : -12684.97\n",
      " Regression with ARIMA(3,0,1) errors : -12626.06\n",
      " Regression with ARIMA(4,0,2) errors : -12644.83\n",
      " Regression with ARIMA(3,0,3) errors : -12645.37\n",
      " Regression with ARIMA(2,0,3) errors : -12641.62\n",
      " Regression with ARIMA(4,0,1) errors : -12643.67\n",
      " Regression with ARIMA(4,0,3) errors : -12690.35\n",
      " Regression with ARIMA(5,0,3) errors : -12663.66\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12668.79\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12658.85\n",
      " Regression with ARIMA(4,0,3) errors : -12609.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12685.05\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12619.78\n",
      " Regression with ARIMA(0,0,0) errors : -9111.436\n",
      " Regression with ARIMA(1,0,0) errors : -12596.51\n",
      " Regression with ARIMA(0,0,1) errors : -10769.82\n",
      " Regression with ARIMA(0,0,0) errors : -8099.19\n",
      " Regression with ARIMA(1,0,2) errors : -12615.12\n",
      " Regression with ARIMA(2,0,1) errors : -12615.29\n",
      " Regression with ARIMA(3,0,2) errors : -12677.01\n",
      " Regression with ARIMA(3,0,1) errors : -12626.47\n",
      " Regression with ARIMA(4,0,2) errors : -12646.5\n",
      " Regression with ARIMA(3,0,3) errors : -12647.04\n",
      " Regression with ARIMA(2,0,3) errors : -12642.14\n",
      " Regression with ARIMA(4,0,1) errors : -12644.59\n",
      " Regression with ARIMA(4,0,3) errors : -12686.33\n",
      " Regression with ARIMA(5,0,3) errors : -12661.66\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12668.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12657.53\n",
      " Regression with ARIMA(4,0,3) errors : -12608.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12683.18\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12616.6\n",
      " Regression with ARIMA(0,0,0) errors : -9093.993\n",
      " Regression with ARIMA(1,0,0) errors : -12593.32\n",
      " Regression with ARIMA(0,0,1) errors : -10754.58\n",
      " Regression with ARIMA(0,0,0) errors : -8057.969\n",
      " Regression with ARIMA(1,0,2) errors : -12612.81\n",
      " Regression with ARIMA(2,0,1) errors : -12611.61\n",
      " Regression with ARIMA(3,0,2) errors : -12678.85\n",
      " Regression with ARIMA(3,0,1) errors : -12622.82\n",
      " Regression with ARIMA(4,0,2) errors : -12641.44\n",
      " Regression with ARIMA(3,0,3) errors : -12642.14\n",
      " Regression with ARIMA(2,0,3) errors : -12638.25\n",
      " Regression with ARIMA(4,0,1) errors : -12639.95\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12583.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12680.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12583.96\n",
      " Regression with ARIMA(0,0,0) errors : -9092.613\n",
      " Regression with ARIMA(1,0,0) errors : -12563.7\n",
      " Regression with ARIMA(0,0,1) errors : -10747.78\n",
      " Regression with ARIMA(0,0,0) errors : -8051.218\n",
      " Regression with ARIMA(1,0,2) errors : -12580.28\n",
      " Regression with ARIMA(2,0,1) errors : -12579.03\n",
      " Regression with ARIMA(3,0,2) errors : -12646.7\n",
      " Regression with ARIMA(3,0,1) errors : -12589.65\n",
      " Regression with ARIMA(4,0,2) errors : -12606.27\n",
      " Regression with ARIMA(3,0,3) errors : -12606.89\n",
      " Regression with ARIMA(2,0,3) errors : -12603.05\n",
      " Regression with ARIMA(4,0,1) errors : -12604.75\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12556.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12648.35\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12577.66\n",
      " Regression with ARIMA(0,0,0) errors : -9095.204\n",
      " Regression with ARIMA(1,0,0) errors : -12557.4\n",
      " Regression with ARIMA(0,0,1) errors : -10745.91\n",
      " Regression with ARIMA(0,0,0) errors : -8037.239\n",
      " Regression with ARIMA(1,0,2) errors : -12573.72\n",
      " Regression with ARIMA(2,0,1) errors : -12572.35\n",
      " Regression with ARIMA(3,0,2) errors : -12641.2\n",
      " Regression with ARIMA(3,0,1) errors : -12583.1\n",
      " Regression with ARIMA(4,0,2) errors : -12600.41\n",
      " Regression with ARIMA(3,0,3) errors : -12601.11\n",
      " Regression with ARIMA(2,0,3) errors : -12597.21\n",
      " Regression with ARIMA(4,0,1) errors : -12599.03\n",
      " Regression with ARIMA(4,0,3) errors : -12644.07\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12622.13\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12612.01\n",
      " Regression with ARIMA(4,0,3) errors : -12563.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12642.54\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12575.52\n",
      " Regression with ARIMA(0,0,0) errors : -9101.37\n",
      " Regression with ARIMA(1,0,0) errors : -12554.94\n",
      " Regression with ARIMA(0,0,1) errors : -10747.52\n",
      " Regression with ARIMA(0,0,0) errors : -8033.351\n",
      " Regression with ARIMA(1,0,2) errors : -12571.38\n",
      " Regression with ARIMA(2,0,1) errors : -12570.05\n",
      " Regression with ARIMA(3,0,2) errors : -12638.35\n",
      " Regression with ARIMA(3,0,1) errors : -12581.07\n",
      " Regression with ARIMA(4,0,2) errors : -12598.59\n",
      " Regression with ARIMA(3,0,3) errors : -12599.01\n",
      " Regression with ARIMA(2,0,3) errors : -12595.34\n",
      " Regression with ARIMA(4,0,1) errors : -12597.11\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12519.88\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12639.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12565.83\n",
      " Regression with ARIMA(0,0,0) errors : -9101.364\n",
      " Regression with ARIMA(1,0,0) errors : -12545.42\n",
      " Regression with ARIMA(0,0,1) errors : -10744.99\n",
      " Regression with ARIMA(0,0,0) errors : -8028.435\n",
      " Regression with ARIMA(1,0,2) errors : -12561.69\n",
      " Regression with ARIMA(2,0,1) errors : -12560.33\n",
      " Regression with ARIMA(3,0,2) errors : -12625.38\n",
      " Regression with ARIMA(3,0,1) errors : -12571.55\n",
      " Regression with ARIMA(4,0,2) errors : -12589.48\n",
      " Regression with ARIMA(3,0,3) errors : -12589.91\n",
      " Regression with ARIMA(2,0,3) errors : -12585.25\n",
      " Regression with ARIMA(4,0,1) errors : -12587.54\n",
      " Regression with ARIMA(4,0,3) errors : -12629.39\n",
      " Regression with ARIMA(5,0,3) errors : -12606.27\n",
      " Regression with ARIMA(4,0,4) errors : -12632.75\n",
      " Regression with ARIMA(3,0,4) errors : -12604.33\n",
      " Regression with ARIMA(5,0,4) errors : -12602.45\n",
      " Regression with ARIMA(4,0,5) errors : -12606.94\n",
      " Regression with ARIMA(3,0,5) errors : -12601.51\n",
      " Regression with ARIMA(5,0,5) errors : -12608.1\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12629.36\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12550.88\n",
      " Regression with ARIMA(0,0,0) errors : -9082.974\n",
      " Regression with ARIMA(1,0,0) errors : -12530.87\n",
      " Regression with ARIMA(0,0,1) errors : -10726.19\n",
      " Regression with ARIMA(0,0,0) errors : -7990.949\n",
      " Regression with ARIMA(1,0,2) errors : -12547.22\n",
      " Regression with ARIMA(2,0,1) errors : -12546.03\n",
      " Regression with ARIMA(3,0,2) errors : -12611.03\n",
      " Regression with ARIMA(3,0,1) errors : -12556.14\n",
      " Regression with ARIMA(4,0,2) errors : -12573.38\n",
      " Regression with ARIMA(3,0,3) errors : -12573.93\n",
      " Regression with ARIMA(2,0,3) errors : -12570.37\n",
      " Regression with ARIMA(4,0,1) errors : -12572.13\n",
      " Regression with ARIMA(4,0,3) errors : -12616.54\n",
      " Regression with ARIMA(5,0,3) errors : -12590.07\n",
      " Regression with ARIMA(4,0,4) errors : -12620.02\n",
      " Regression with ARIMA(3,0,4) errors : -12593.33\n",
      " Regression with ARIMA(5,0,4) errors : -12585.19\n",
      " Regression with ARIMA(4,0,5) errors : -12590.96\n",
      " Regression with ARIMA(3,0,5) errors : -12586.08\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12613.46\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12541.98\n",
      " Regression with ARIMA(0,0,0) errors : -9085.693\n",
      " Regression with ARIMA(1,0,0) errors : -12521.52\n",
      " Regression with ARIMA(0,0,1) errors : -10727.61\n",
      " Regression with ARIMA(0,0,0) errors : -7984.545\n",
      " Regression with ARIMA(1,0,2) errors : -12537.92\n",
      " Regression with ARIMA(2,0,1) errors : -12537.24\n",
      " Regression with ARIMA(3,0,2) errors : -12601.89\n",
      " Regression with ARIMA(3,0,1) errors : -12547.19\n",
      " Regression with ARIMA(4,0,2) errors : -12564.24\n",
      " Regression with ARIMA(3,0,3) errors : -12564.26\n",
      " Regression with ARIMA(2,0,3) errors : -12561.62\n",
      " Regression with ARIMA(4,0,1) errors : -12563.37\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12499.3\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12602.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.96\n",
      " Regression with ARIMA(0,0,0) errors : -9090.727\n",
      " Regression with ARIMA(1,0,0) errors : -12524.23\n",
      " Regression with ARIMA(0,0,1) errors : -10729.14\n",
      " Regression with ARIMA(0,0,0) errors : -7988.192\n",
      " Regression with ARIMA(1,0,2) errors : -12541.23\n",
      " Regression with ARIMA(2,0,1) errors : -12541.2\n",
      " Regression with ARIMA(3,0,2) errors : -12596.53\n",
      " Regression with ARIMA(3,0,1) errors : -12551.61\n",
      " Regression with ARIMA(4,0,2) errors : -12568.27\n",
      " Regression with ARIMA(3,0,3) errors : -12568.72\n",
      " Regression with ARIMA(2,0,3) errors : -12565.53\n",
      " Regression with ARIMA(4,0,1) errors : -12567.05\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12496.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12605.49\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12548.88\n",
      " Regression with ARIMA(0,0,0) errors : -9100.305\n",
      " Regression with ARIMA(1,0,0) errors : -12527.5\n",
      " Regression with ARIMA(0,0,1) errors : -10736.35\n",
      " Regression with ARIMA(0,0,0) errors : -7988.759\n",
      " Regression with ARIMA(1,0,2) errors : -12544.66\n",
      " Regression with ARIMA(2,0,1) errors : -12543.65\n",
      " Regression with ARIMA(3,0,2) errors : -12605.4\n",
      " Regression with ARIMA(3,0,1) errors : -12554.44\n",
      " Regression with ARIMA(4,0,2) errors : -12571.11\n",
      " Regression with ARIMA(3,0,3) errors : -12571.91\n",
      " Regression with ARIMA(2,0,3) errors : -12568.5\n",
      " Regression with ARIMA(4,0,1) errors : -12570.06\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12504.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12608.79\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.27\n",
      " Regression with ARIMA(0,0,0) errors : -9095.28\n",
      " Regression with ARIMA(1,0,0) errors : -12526.27\n",
      " Regression with ARIMA(0,0,1) errors : -10733.95\n",
      " Regression with ARIMA(0,0,0) errors : -7985.631\n",
      " Regression with ARIMA(1,0,2) errors : -12543.29\n",
      " Regression with ARIMA(2,0,1) errors : -12541.96\n",
      " Regression with ARIMA(3,0,2) errors : -12605.92\n",
      " Regression with ARIMA(3,0,1) errors : -12552.76\n",
      " Regression with ARIMA(4,0,2) errors : -12569.38\n",
      " Regression with ARIMA(3,0,3) errors : -12569.97\n",
      " Regression with ARIMA(2,0,3) errors : -12566.62\n",
      " Regression with ARIMA(4,0,1) errors : -12568.51\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12514.77\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12607.57\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12551.72\n",
      " Regression with ARIMA(0,0,0) errors : -9094.616\n",
      " Regression with ARIMA(1,0,0) errors : -12527.72\n",
      " Regression with ARIMA(0,0,1) errors : -10731.91\n",
      " Regression with ARIMA(0,0,0) errors : -7984.814\n",
      " Regression with ARIMA(1,0,2) errors : -12544.83\n",
      " Regression with ARIMA(2,0,1) errors : -12545.69\n",
      " Regression with ARIMA(3,0,2) errors : -12599.12\n",
      " Regression with ARIMA(3,0,1) errors : -12556.69\n",
      " Regression with ARIMA(4,0,2) errors : -12574.58\n",
      " Regression with ARIMA(3,0,3) errors : -12572.21\n",
      " Regression with ARIMA(2,0,3) errors : -12570.48\n",
      " Regression with ARIMA(4,0,1) errors : -12574.57\n",
      " Regression with ARIMA(4,0,3) errors : -12602.14\n",
      " Regression with ARIMA(5,0,3) errors : -12593.97\n",
      " Regression with ARIMA(4,0,4) errors : -12614.31\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12592.12\n",
      " Regression with ARIMA(4,0,5) errors : -12613.12\n",
      " Regression with ARIMA(3,0,5) errors : -12593.98\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -12615.97\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.25\n",
      " Regression with ARIMA(0,0,0) errors : -9103.285\n",
      " Regression with ARIMA(1,0,0) errors : -12525.6\n",
      " Regression with ARIMA(0,0,1) errors : -10740.02\n",
      " Regression with ARIMA(0,0,0) errors : -7987.126\n",
      " Regression with ARIMA(1,0,2) errors : -12542.63\n",
      " Regression with ARIMA(2,0,1) errors : -12541.09\n",
      " Regression with ARIMA(3,0,2) errors : -12595.27\n",
      " Regression with ARIMA(3,0,1) errors : -12553.61\n",
      " Regression with ARIMA(4,0,2) errors : -12567.35\n",
      " Regression with ARIMA(3,0,3) errors : -12568.1\n",
      " Regression with ARIMA(2,0,3) errors : -12564.84\n",
      " Regression with ARIMA(4,0,1) errors : -12567.61\n",
      " Regression with ARIMA(4,0,3) errors : -12599.93\n",
      " Regression with ARIMA(5,0,3) errors : -12585.25\n",
      " Regression with ARIMA(4,0,4) errors : -12587.13\n",
      " Regression with ARIMA(3,0,4) errors : -12586.59\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12587.56\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12603.94\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12563.76\n",
      " Regression with ARIMA(0,0,0) errors : -9114.748\n",
      " Regression with ARIMA(1,0,0) errors : -12542.44\n",
      " Regression with ARIMA(0,0,1) errors : -10750.26\n",
      " Regression with ARIMA(0,0,0) errors : -7996.79\n",
      " Regression with ARIMA(1,0,2) errors : -12559.52\n",
      " Regression with ARIMA(2,0,1) errors : -12557.88\n",
      " Regression with ARIMA(3,0,2) errors : -12623.24\n",
      " Regression with ARIMA(3,0,1) errors : -12569.07\n",
      " Regression with ARIMA(4,0,2) errors : -12584.06\n",
      " Regression with ARIMA(3,0,3) errors : -12584.83\n",
      " Regression with ARIMA(2,0,3) errors : -12581.2\n",
      " Regression with ARIMA(4,0,1) errors : -12583.59\n",
      " Regression with ARIMA(4,0,3) errors : -12622.16\n",
      " Regression with ARIMA(3,0,2) errors : -12529.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12623.55\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12571.66\n",
      " Regression with ARIMA(0,0,0) errors : -9119.255\n",
      " Regression with ARIMA(1,0,0) errors : -12550.63\n",
      " Regression with ARIMA(0,0,1) errors : -10754.38\n",
      " Regression with ARIMA(0,0,0) errors : -7999.828\n",
      " Regression with ARIMA(1,0,2) errors : -12567.56\n",
      " Regression with ARIMA(2,0,1) errors : -12565.97\n",
      " Regression with ARIMA(3,0,2) errors : -12623.38\n",
      " Regression with ARIMA(3,0,1) errors : -12577.61\n",
      " Regression with ARIMA(4,0,2) errors : -12592.71\n",
      " Regression with ARIMA(3,0,3) errors : -12593.33\n",
      " Regression with ARIMA(2,0,3) errors : -12589.24\n",
      " Regression with ARIMA(4,0,1) errors : -12591.99\n",
      " Regression with ARIMA(4,0,3) errors : -12628.14\n",
      " Regression with ARIMA(5,0,3) errors : -12611.42\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12608.22\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12601.46\n",
      " Regression with ARIMA(4,0,3) errors : -12518.46\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12632.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12570.69\n",
      " Regression with ARIMA(0,0,0) errors : -9115.278\n",
      " Regression with ARIMA(1,0,0) errors : -12549.82\n",
      " Regression with ARIMA(0,0,1) errors : -10753.47\n",
      " Regression with ARIMA(0,0,0) errors : -8003.712\n",
      " Regression with ARIMA(1,0,2) errors : -12566.64\n",
      " Regression with ARIMA(2,0,1) errors : -12564.99\n",
      " Regression with ARIMA(3,0,2) errors : -12627.12\n",
      " Regression with ARIMA(3,0,1) errors : -12576.67\n",
      " Regression with ARIMA(4,0,2) errors : -12592.86\n",
      " Regression with ARIMA(3,0,3) errors : -12593.53\n",
      " Regression with ARIMA(2,0,3) errors : -12588.09\n",
      " Regression with ARIMA(4,0,1) errors : -12591.37\n",
      " Regression with ARIMA(4,0,3) errors : -12631.06\n",
      " Regression with ARIMA(5,0,3) errors : -12608.52\n",
      " Regression with ARIMA(4,0,4) errors : -12636.78\n",
      " Regression with ARIMA(3,0,4) errors : -12595.05\n",
      " Regression with ARIMA(5,0,4) errors : -12606.13\n",
      " Regression with ARIMA(4,0,5) errors : -12611.46\n",
      " Regression with ARIMA(3,0,5) errors : -12589.1\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12631.52\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12578.38\n",
      " Regression with ARIMA(0,0,0) errors : -9111.17\n",
      " Regression with ARIMA(1,0,0) errors : -12558.92\n",
      " Regression with ARIMA(0,0,1) errors : -10753.78\n",
      " Regression with ARIMA(0,0,0) errors : -8020.573\n",
      " Regression with ARIMA(1,0,2) errors : -12574.68\n",
      " Regression with ARIMA(2,0,1) errors : -12573.05\n",
      " Regression with ARIMA(3,0,2) errors : -12623.18\n",
      " Regression with ARIMA(3,0,1) errors : -12586.14\n",
      " Regression with ARIMA(4,0,2) errors : -12599.85\n",
      " Regression with ARIMA(3,0,3) errors : -12600.52\n",
      " Regression with ARIMA(2,0,3) errors : -12595.7\n",
      " Regression with ARIMA(4,0,1) errors : -12599.55\n",
      " Regression with ARIMA(4,0,3) errors : -12630.95\n",
      " Regression with ARIMA(5,0,3) errors : -12614.41\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12610.87\n",
      " Regression with ARIMA(5,0,2) errors : -12611.96\n",
      " Regression with ARIMA(5,0,4) errors : -12609.33\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12639.79\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12589.89\n",
      " Regression with ARIMA(0,0,0) errors : -9118.887\n",
      " Regression with ARIMA(1,0,0) errors : -12570.44\n",
      " Regression with ARIMA(0,0,1) errors : -10762.54\n",
      " Regression with ARIMA(0,0,0) errors : -8023.134\n",
      " Regression with ARIMA(1,0,2) errors : -12586.06\n",
      " Regression with ARIMA(2,0,1) errors : -12584.58\n",
      " Regression with ARIMA(3,0,2) errors : -12650.24\n",
      " Regression with ARIMA(3,0,1) errors : -12595.09\n",
      " Regression with ARIMA(4,0,2) errors : -12610.13\n",
      " Regression with ARIMA(3,0,3) errors : -12611.25\n",
      " Regression with ARIMA(2,0,3) errors : -12607.47\n",
      " Regression with ARIMA(4,0,1) errors : -12610.04\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12562.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12652.57\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12605.76\n",
      " Regression with ARIMA(0,0,0) errors : -9124.298\n",
      " Regression with ARIMA(1,0,0) errors : -12585.84\n",
      " Regression with ARIMA(0,0,1) errors : -10776.69\n",
      " Regression with ARIMA(0,0,0) errors : -8072.897\n",
      " Regression with ARIMA(1,0,2) errors : -12601.79\n",
      " Regression with ARIMA(2,0,1) errors : -12600.13\n",
      " Regression with ARIMA(3,0,2) errors : -12662.69\n",
      " Regression with ARIMA(3,0,1) errors : -12612.34\n",
      " Regression with ARIMA(4,0,2) errors : -12629.9\n",
      " Regression with ARIMA(3,0,3) errors : -12629.01\n",
      " Regression with ARIMA(2,0,3) errors : -12623.63\n",
      " Regression with ARIMA(4,0,1) errors : -12627.83\n",
      " Regression with ARIMA(4,0,3) errors : -12662.1\n",
      " Regression with ARIMA(3,0,2) errors : -12538.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12668.81\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12617.98\n",
      " Regression with ARIMA(0,0,0) errors : -9103.826\n",
      " Regression with ARIMA(1,0,0) errors : -12597.39\n",
      " Regression with ARIMA(0,0,1) errors : -10769.07\n",
      " Regression with ARIMA(0,0,0) errors : -8071.78\n",
      " Regression with ARIMA(1,0,2) errors : -12613.58\n",
      " Regression with ARIMA(2,0,1) errors : -12612.03\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12634.81\n",
      " Regression with ARIMA(1,0,3) errors : -12637.74\n",
      " Regression with ARIMA(0,0,3) errors : -11857.74\n",
      " Regression with ARIMA(1,0,4) errors : -12635.79\n",
      " Regression with ARIMA(0,0,2) errors : -11425.89\n",
      " Regression with ARIMA(0,0,4) errors : -12183.34\n",
      " Regression with ARIMA(2,0,4) errors : -12660.74\n",
      " Regression with ARIMA(3,0,4) errors : -12661.91\n",
      " Regression with ARIMA(3,0,3) errors : -12639.57\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12664.79\n",
      " Regression with ARIMA(1,0,5) errors : -12637.48\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12662.8\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12648.96\n",
      " Regression with ARIMA(0,0,0) errors : -9121.032\n",
      " Regression with ARIMA(1,0,0) errors : -12628.13\n",
      " Regression with ARIMA(0,0,1) errors : -10785.99\n",
      " Regression with ARIMA(0,0,0) errors : -8086.924\n",
      " Regression with ARIMA(1,0,2) errors : -12643.58\n",
      " Regression with ARIMA(2,0,1) errors : -12645.29\n",
      " Regression with ARIMA(3,0,2) errors : -12693.39\n",
      " Regression with ARIMA(3,0,1) errors : -12657.07\n",
      " Regression with ARIMA(4,0,2) errors : -12674.99\n",
      " Regression with ARIMA(3,0,3) errors : -12674.05\n",
      " Regression with ARIMA(2,0,3) errors : -12670.13\n",
      " Regression with ARIMA(4,0,1) errors : -12673.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12586.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12712.63\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12660.79\n",
      " Regression with ARIMA(0,0,0) errors : -9128.864\n",
      " Regression with ARIMA(1,0,0) errors : -12639.5\n",
      " Regression with ARIMA(0,0,1) errors : -10794.45\n",
      " Regression with ARIMA(0,0,0) errors : -8086.79\n",
      " Regression with ARIMA(1,0,2) errors : -12656.36\n",
      " Regression with ARIMA(2,0,1) errors : -12654.67\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12681.02\n",
      " Regression with ARIMA(1,0,3) errors : -12683.93\n",
      " Regression with ARIMA(0,0,3) errors : -11882.7\n",
      " Regression with ARIMA(1,0,4) errors : -12681.93\n",
      " Regression with ARIMA(0,0,2) errors : -11451.05\n",
      " Regression with ARIMA(0,0,4) errors : -12222.24\n",
      " Regression with ARIMA(2,0,4) errors : -12708.43\n",
      " Regression with ARIMA(3,0,4) errors : -12700.64\n",
      " Regression with ARIMA(2,0,5) errors : -12711.77\n",
      " Regression with ARIMA(1,0,5) errors : -12684.46\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12635.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12712.16\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12663.87\n",
      " Regression with ARIMA(0,0,0) errors : -9125.032\n",
      " Regression with ARIMA(1,0,0) errors : -12642.83\n",
      " Regression with ARIMA(0,0,1) errors : -10795.06\n",
      " Regression with ARIMA(0,0,0) errors : -8088.558\n",
      " Regression with ARIMA(1,0,2) errors : -12659.49\n",
      " Regression with ARIMA(2,0,1) errors : -12657.96\n",
      " Regression with ARIMA(3,0,2) errors : -12717.9\n",
      " Regression with ARIMA(3,0,1) errors : -12671.05\n",
      " Regression with ARIMA(4,0,2) errors : -12688.31\n",
      " Regression with ARIMA(3,0,3) errors : -12688.66\n",
      " Regression with ARIMA(2,0,3) errors : -12684.8\n",
      " Regression with ARIMA(4,0,1) errors : -12687.93\n",
      " Regression with ARIMA(4,0,3) errors : -12724.73\n",
      " Regression with ARIMA(5,0,3) errors : -12705.98\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12706.33\n",
      " Regression with ARIMA(5,0,2) errors : -12704.8\n",
      " Regression with ARIMA(5,0,4) errors : -12707.76\n",
      " Regression with ARIMA(4,0,3) errors : -12626.28\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12711.43\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12675.17\n",
      " Regression with ARIMA(0,0,0) errors : -9127.822\n",
      " Regression with ARIMA(1,0,0) errors : -12652.69\n",
      " Regression with ARIMA(0,0,1) errors : -10797.32\n",
      " Regression with ARIMA(0,0,0) errors : -8122.42\n",
      " Regression with ARIMA(1,0,2) errors : -12669.49\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12695.32\n",
      " Regression with ARIMA(1,0,3) errors : -12697.68\n",
      " Regression with ARIMA(0,0,3) errors : -11885.17\n",
      " Regression with ARIMA(1,0,4) errors : -12695.67\n",
      " Regression with ARIMA(0,0,2) errors : -11454.21\n",
      " Regression with ARIMA(0,0,4) errors : -12223.07\n",
      " Regression with ARIMA(2,0,4) errors : -12724.02\n",
      " Regression with ARIMA(3,0,4) errors : -12727\n",
      " Regression with ARIMA(3,0,3) errors : -12699.87\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12728.15\n",
      " Regression with ARIMA(1,0,5) errors : -12698.24\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12723.48\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12683.94\n",
      " Regression with ARIMA(0,0,0) errors : -9138.188\n",
      " Regression with ARIMA(1,0,0) errors : -12661.92\n",
      " Regression with ARIMA(0,0,1) errors : -10809.04\n",
      " Regression with ARIMA(0,0,0) errors : -8146.342\n",
      " Regression with ARIMA(1,0,2) errors : -12678.66\n",
      " Regression with ARIMA(2,0,1) errors : -12676.73\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12704.85\n",
      " Regression with ARIMA(1,0,3) errors : -12707.91\n",
      " Regression with ARIMA(0,0,3) errors : -11899.86\n",
      " Regression with ARIMA(1,0,4) errors : -12705.92\n",
      " Regression with ARIMA(0,0,2) errors : -11462.84\n",
      " Regression with ARIMA(0,0,4) errors : -12239.61\n",
      " Regression with ARIMA(2,0,4) errors : -12733.61\n",
      " Regression with ARIMA(3,0,4) errors : -12727.8\n",
      " Regression with ARIMA(2,0,5) errors : -12736.88\n",
      " Regression with ARIMA(1,0,5) errors : -12708.11\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12658.61\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12738.19\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12707.9\n",
      " Regression with ARIMA(0,0,0) errors : -9146.696\n",
      " Regression with ARIMA(1,0,0) errors : -12685.85\n",
      " Regression with ARIMA(0,0,1) errors : -10816.31\n",
      " Regression with ARIMA(0,0,0) errors : -8145.991\n",
      " Regression with ARIMA(1,0,2) errors : -12701.98\n",
      " Regression with ARIMA(2,0,1) errors : -12702.83\n",
      " Regression with ARIMA(3,0,2) errors : -12752.59\n",
      " Regression with ARIMA(3,0,1) errors : -12716.78\n",
      " Regression with ARIMA(4,0,2) errors : -12776.93\n",
      " Regression with ARIMA(4,0,1) errors : -12738.81\n",
      " Regression with ARIMA(5,0,2) errors : -12750.69\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -12740.15\n",
      " Regression with ARIMA(5,0,1) errors : -12807.17\n",
      " Regression with ARIMA(5,0,0) errors : -12741.34\n",
      " Regression with ARIMA(4,0,0) errors : -12738.7\n",
      " Regression with ARIMA(5,0,1) errors : -12728.9\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12760.88\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12912.84\n",
      " Regression with ARIMA(0,0,0) errors : -9287.558\n",
      " Regression with ARIMA(1,0,0) errors : -12838.23\n",
      " Regression with ARIMA(0,0,1) errors : -10970.44\n",
      " Regression with ARIMA(0,0,0) errors : -8334.607\n",
      " Regression with ARIMA(1,0,2) errors : -12850.07\n",
      " Regression with ARIMA(2,0,1) errors : -12896.83\n",
      " Regression with ARIMA(3,0,2) errors : -12886.59\n",
      " Regression with ARIMA(2,0,3) errors : -12920.49\n",
      " Regression with ARIMA(1,0,3) errors : -12869.31\n",
      " Regression with ARIMA(3,0,3) errors : -12922.93\n",
      " Regression with ARIMA(4,0,3) errors : -12951.22\n",
      " Regression with ARIMA(4,0,2) errors : -12979.64\n",
      " Regression with ARIMA(4,0,1) errors : -12919.17\n",
      " Regression with ARIMA(5,0,2) errors : -13016.01\n",
      " Regression with ARIMA(5,0,1) errors : -12918.05\n",
      " Regression with ARIMA(5,0,3) errors : -13009.45\n",
      " Regression with ARIMA(5,0,2) errors : -12924.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -12851.52\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13340.53\n",
      " Regression with ARIMA(0,0,0) errors : -9896.247\n",
      " Regression with ARIMA(1,0,0) errors : -13321.04\n",
      " Regression with ARIMA(0,0,1) errors : -11543.52\n",
      " Regression with ARIMA(0,0,0) errors : -8940.049\n",
      " Regression with ARIMA(1,0,2) errors : -13322.44\n",
      " Regression with ARIMA(2,0,1) errors : -13321.63\n",
      " Regression with ARIMA(3,0,2) errors : -13355.77\n",
      " Regression with ARIMA(3,0,1) errors : -13337\n",
      " Regression with ARIMA(4,0,2) errors : -13354.79\n",
      " Regression with ARIMA(3,0,3) errors : -13380.32\n",
      " Regression with ARIMA(2,0,3) errors : -13333.79\n",
      " Regression with ARIMA(4,0,3) errors : -13412.84\n",
      " Regression with ARIMA(5,0,3) errors : -13428.89\n",
      " Regression with ARIMA(5,0,2) errors : -13429.21\n",
      " Regression with ARIMA(5,0,1) errors : -13348.63\n",
      " Regression with ARIMA(4,0,1) errors : -13348.07\n",
      " Regression with ARIMA(5,0,2) errors : -13296.63\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13383.36\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13638.8\n",
      " Regression with ARIMA(0,1,0) errors : -13557.1\n",
      " Regression with ARIMA(1,1,0) errors : -13569.73\n",
      " Regression with ARIMA(0,1,1) errors : -13568.98\n",
      " Regression with ARIMA(0,1,0) errors : -13559.1\n",
      " Regression with ARIMA(1,1,2) errors : -13569.88\n",
      " Regression with ARIMA(2,1,1) errors : -13572.21\n",
      " Regression with ARIMA(3,1,2) errors : -13655.74\n",
      " Regression with ARIMA(3,1,1) errors : -13608.61\n",
      " Regression with ARIMA(4,1,2) errors : -13690.96\n",
      " Regression with ARIMA(4,1,1) errors : -13635.24\n",
      " Regression with ARIMA(5,1,2) errors : -13685.37\n",
      " Regression with ARIMA(4,1,3) errors : -13668.95\n",
      " Regression with ARIMA(3,1,3) errors : -13656.78\n",
      " Regression with ARIMA(5,1,1) errors : -13674.36\n",
      " Regression with ARIMA(5,1,3) errors : -13699.07\n",
      " Regression with ARIMA(5,1,4) errors : -13798\n",
      " Regression with ARIMA(4,1,4) errors : -13766.7\n",
      " Regression with ARIMA(5,1,5) errors : -13796.13\n",
      " Regression with ARIMA(4,1,5) errors : -13791.29\n",
      " Regression with ARIMA(5,1,4) errors : -13800.01\n",
      " Regression with ARIMA(4,1,4) errors : -13768.68\n",
      " Regression with ARIMA(5,1,3) errors : -13701.1\n",
      " Regression with ARIMA(5,1,5) errors : -13798.15\n",
      " Regression with ARIMA(4,1,3) errors : -13669.36\n",
      " Regression with ARIMA(4,1,5) errors : -13793.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,4) errors : -13627.14\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13856.97\n",
      " Regression with ARIMA(0,1,0) errors : -13830.28\n",
      " Regression with ARIMA(1,1,0) errors : -13844.83\n",
      " Regression with ARIMA(0,1,1) errors : -13841.77\n",
      " Regression with ARIMA(0,1,0) errors : -13832.29\n",
      " Regression with ARIMA(1,1,2) errors : -13852.88\n",
      " Regression with ARIMA(2,1,1) errors : -13857.98\n",
      " Regression with ARIMA(1,1,1) errors : -13853.24\n",
      " Regression with ARIMA(2,1,0) errors : -13857.59\n",
      " Regression with ARIMA(3,1,1) errors : -13856.45\n",
      " Regression with ARIMA(3,1,0) errors : -13855.79\n",
      " Regression with ARIMA(3,1,2) errors : -13853.87\n",
      " Regression with ARIMA(2,1,1) errors : -13859.99\n",
      " Regression with ARIMA(1,1,1) errors : -13855.24\n",
      " Regression with ARIMA(2,1,0) errors : -13859.61\n",
      " Regression with ARIMA(3,1,1) errors : -13858.47\n",
      " Regression with ARIMA(2,1,2) errors : -13858.99\n",
      " Regression with ARIMA(1,1,0) errors : -13846.84\n",
      " Regression with ARIMA(1,1,2) errors : -13854.88\n",
      " Regression with ARIMA(3,1,0) errors : -13857.8\n",
      " Regression with ARIMA(3,1,2) errors : -13855.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : -13852.22\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,1) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13947.36\n",
      " Regression with ARIMA(0,1,0) errors : -13900.86\n",
      " Regression with ARIMA(1,1,0) errors : -13932.84\n",
      " Regression with ARIMA(0,1,1) errors : -13911.73\n",
      " Regression with ARIMA(0,1,0) errors : -13902.87\n",
      " Regression with ARIMA(1,1,2) errors : -13939.01\n",
      " Regression with ARIMA(2,1,1) errors : -13943.65\n",
      " Regression with ARIMA(3,1,2) errors : -13959.09\n",
      " Regression with ARIMA(3,1,1) errors : -13956.45\n",
      " Regression with ARIMA(4,1,2) errors : -14000.17\n",
      " Regression with ARIMA(4,1,1) errors : -13952.05\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : -14004.61\n",
      " Regression with ARIMA(3,1,3) errors : -13984.19\n",
      " Regression with ARIMA(5,1,3) errors : -14058.98\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : -14034.52\n",
      " Regression with ARIMA(5,1,3) errors : -14060.9\n",
      " Regression with ARIMA(4,1,3) errors : -14006.63\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : -14002.15\n",
      " Regression with ARIMA(4,1,4) errors : -14036.43\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : -13974.19\n",
      "\n",
      " Best model: Regression with ARIMA(4,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14051.09\n",
      " Regression with ARIMA(0,1,0) errors : -14017.53\n",
      " Regression with ARIMA(1,1,0) errors : -14026.02\n",
      " Regression with ARIMA(0,1,1) errors : -14026.4\n",
      " Regression with ARIMA(0,1,0) errors : -14019.51\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14049.92\n",
      " Regression with ARIMA(3,1,2) errors : -14072.45\n",
      " Regression with ARIMA(3,1,1) errors : -14060.26\n",
      " Regression with ARIMA(4,1,2) errors : -14078.94\n",
      " Regression with ARIMA(4,1,1) errors : -14061.76\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : -14126.2\n",
      " Regression with ARIMA(2,1,3) errors : -14050.56\n",
      " Regression with ARIMA(3,1,4) errors : -14077.3\n",
      " Regression with ARIMA(2,1,4) errors : -14048.58\n",
      " Regression with ARIMA(4,1,4) errors : -14193.59\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14215.31\n",
      " Regression with ARIMA(2,1,5) errors : -14059.26\n",
      " Regression with ARIMA(3,1,5) errors : -14216.42\n",
      " Regression with ARIMA(2,1,5) errors : -14061.28\n",
      " Regression with ARIMA(3,1,4) errors : -14177.43\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14050.61\n",
      " Regression with ARIMA(4,1,4) errors : -14194.71\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -14036.04\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14232.72\n",
      " Regression with ARIMA(0,1,0) errors : -14162.77\n",
      " Regression with ARIMA(1,1,0) errors : -14185.38\n",
      " Regression with ARIMA(0,1,1) errors : -14173.07\n",
      " Regression with ARIMA(0,1,0) errors : -14164.75\n",
      " Regression with ARIMA(1,1,2) errors : -14207.81\n",
      " Regression with ARIMA(2,1,1) errors : -14224.23\n",
      " Regression with ARIMA(3,1,2) errors : -14248.4\n",
      " Regression with ARIMA(3,1,1) errors : -14225.86\n",
      " Regression with ARIMA(4,1,2) errors : -14270.04\n",
      " Regression with ARIMA(4,1,1) errors : -14226.79\n",
      " Regression with ARIMA(5,1,2) errors : -14276.69\n",
      " Regression with ARIMA(5,1,1) errors : -14239.31\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : -14278.66\n",
      " Regression with ARIMA(4,1,2) errors : -14272.05\n",
      " Regression with ARIMA(5,1,1) errors : -14241.32\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : -14228.77\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,1) errors : -14188.43\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14269.51\n",
      " Regression with ARIMA(1,1,0) errors : -14280.67\n",
      " Regression with ARIMA(0,1,1) errors : -14275.99\n",
      " Regression with ARIMA(0,1,0) errors : -14271.49\n",
      " Regression with ARIMA(2,1,0) errors : -14280.26\n",
      " Regression with ARIMA(1,1,1) errors : -14283.64\n",
      " Regression with ARIMA(2,1,1) errors : -14282.63\n",
      " Regression with ARIMA(1,1,2) errors : -14281.81\n",
      " Regression with ARIMA(0,1,2) errors : -14276.35\n",
      " Regression with ARIMA(1,1,1) errors : -14285.62\n",
      " Regression with ARIMA(0,1,1) errors : -14277.97\n",
      " Regression with ARIMA(1,1,0) errors : -14282.66\n",
      " Regression with ARIMA(2,1,1) errors : -14284.63\n",
      " Regression with ARIMA(1,1,2) errors : -14283.8\n",
      " Regression with ARIMA(0,1,2) errors : -14278.33\n",
      " Regression with ARIMA(2,1,0) errors : -14282.25\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14292.77\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14392.52\n",
      " Regression with ARIMA(0,1,0) errors : -14319.87\n",
      " Regression with ARIMA(1,1,0) errors : -14323.95\n",
      " Regression with ARIMA(0,1,1) errors : -14324.28\n",
      " Regression with ARIMA(0,1,0) errors : -14321.88\n",
      " Regression with ARIMA(1,1,2) errors : -14328.67\n",
      " Regression with ARIMA(2,1,1) errors : -14322.2\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14396.05\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14397.58\n",
      " Regression with ARIMA(1,1,4) errors : -14325.55\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14409.11\n",
      " Regression with ARIMA(0,1,5) errors : -14329.22\n",
      " Regression with ARIMA(0,1,4) errors : -14322.36\n",
      " Regression with ARIMA(1,1,5) errors : -14410.56\n",
      " Regression with ARIMA(0,1,5) errors : -14331.23\n",
      " Regression with ARIMA(1,1,4) errors : -14327.56\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(0,1,4) errors : -14324.37\n",
      " Regression with ARIMA(2,1,4) errors : -14399.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,5) errors : -14340.4\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14414.39\n",
      " Regression with ARIMA(0,1,0) errors : -14347.05\n",
      " Regression with ARIMA(1,1,0) errors : -14351.5\n",
      " Regression with ARIMA(0,1,1) errors : -14351.98\n",
      " Regression with ARIMA(0,1,0) errors : -14349.06\n",
      " Regression with ARIMA(1,1,2) errors : -14355.74\n",
      " Regression with ARIMA(2,1,1) errors : -14357.14\n",
      " Regression with ARIMA(3,1,2) errors : -14356.58\n",
      " Regression with ARIMA(2,1,3) errors : -14416.78\n",
      " Regression with ARIMA(1,1,3) errors : -14352.44\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14426.08\n",
      " Regression with ARIMA(1,1,4) errors : -14352.46\n",
      " Regression with ARIMA(3,1,4) errors : -14359.23\n",
      " Regression with ARIMA(2,1,5) errors : -14433.08\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14448.43\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14449.79\n",
      " Regression with ARIMA(2,1,5) errors : -14434.5\n",
      " Regression with ARIMA(3,1,4) errors : -14361.25\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14427.62\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14373.05\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14467.17\n",
      " Regression with ARIMA(0,1,0) errors : -14387.79\n",
      " Regression with ARIMA(1,1,0) errors : -14392.42\n",
      " Regression with ARIMA(0,1,1) errors : -14393.12\n",
      " Regression with ARIMA(0,1,0) errors : -14389.79\n",
      " Regression with ARIMA(1,1,2) errors : -14393.52\n",
      " Regression with ARIMA(2,1,1) errors : -14392.46\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14467.02\n",
      " Regression with ARIMA(1,1,1) errors : -14394.63\n",
      " Regression with ARIMA(1,1,3) errors : -14391.52\n",
      " Regression with ARIMA(3,1,1) errors : -14450.2\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -14468.77\n",
      " Regression with ARIMA(1,1,2) errors : -14395.53\n",
      " Regression with ARIMA(2,1,1) errors : -14394.46\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14468.52\n",
      " Regression with ARIMA(1,1,1) errors : -14396.63\n",
      " Regression with ARIMA(1,1,3) errors : -14393.52\n",
      " Regression with ARIMA(3,1,1) errors : -14452.03\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : -14406.82\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11132.19\n",
      " Regression with ARIMA(1,0,0) errors : -14540.36\n",
      " Regression with ARIMA(0,0,1) errors : -12745.99\n",
      " Regression with ARIMA(0,0,0) errors : -9972.371\n",
      " Regression with ARIMA(2,0,0) errors : -14537.54\n",
      " Regression with ARIMA(1,0,1) errors : -14538.45\n",
      " Regression with ARIMA(2,0,1) errors : -14542.87\n",
      " Regression with ARIMA(3,0,1) errors : -14558.56\n",
      " Regression with ARIMA(3,0,0) errors : -14548.35\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -14559.21\n",
      " Regression with ARIMA(4,0,2) errors : -14555.78\n",
      " Regression with ARIMA(3,0,3) errors : -14558.89\n",
      " Regression with ARIMA(2,0,3) errors : -14545.56\n",
      " Regression with ARIMA(4,0,3) errors : -14553.54\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14560.17\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11151.48\n",
      " Regression with ARIMA(1,0,0) errors : -14551.11\n",
      " Regression with ARIMA(0,0,1) errors : -12768.97\n",
      " Regression with ARIMA(0,0,0) errors : -9991.611\n",
      " Regression with ARIMA(2,0,0) errors : -14548.25\n",
      " Regression with ARIMA(1,0,1) errors : -14549.23\n",
      " Regression with ARIMA(2,0,1) errors : -14552.94\n",
      " Regression with ARIMA(3,0,1) errors : -14567.66\n",
      " Regression with ARIMA(3,0,0) errors : -14558.46\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,0) errors : -14557.43\n",
      " Regression with ARIMA(4,0,2) errors : -14572.3\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -14567.45\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,1) errors : -14571.65\n",
      " Regression with ARIMA(5,0,3) errors : -14591.07\n",
      " Regression with ARIMA(5,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -14588.65\n",
      " Regression with ARIMA(5,0,3) errors : -14466.83\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -14592.39\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14560.15\n",
      " Regression with ARIMA(0,0,0) errors : -11132.88\n",
      " Regression with ARIMA(1,0,0) errors : -14543.96\n",
      " Regression with ARIMA(0,0,1) errors : -12748.49\n",
      " Regression with ARIMA(0,0,0) errors : -9916.669\n",
      " Regression with ARIMA(1,0,2) errors : -14552.05\n",
      " Regression with ARIMA(2,0,1) errors : -14544.14\n",
      " Regression with ARIMA(3,0,2) errors : -14551.85\n",
      " Regression with ARIMA(2,0,3) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -14542.09\n",
      " Regression with ARIMA(1,0,3) errors : -14551.93\n",
      " Regression with ARIMA(3,0,1) errors : -14569.13\n",
      " Regression with ARIMA(3,0,0) errors : -14553.2\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -14542.46\n",
      " Regression with ARIMA(4,0,0) errors : -14553.19\n",
      " Regression with ARIMA(4,0,2) errors : -14568.72\n",
      " Regression with ARIMA(3,0,1) errors : -14400.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -14566.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11155.69\n",
      " Regression with ARIMA(1,0,0) errors : -14548.92\n",
      " Regression with ARIMA(0,0,1) errors : -12768.48\n",
      " Regression with ARIMA(0,0,0) errors : -9907.063\n",
      " Regression with ARIMA(2,0,0) errors : -14546.07\n",
      " Regression with ARIMA(1,0,1) errors : -14546.93\n",
      " Regression with ARIMA(2,0,1) errors : -14550.78\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -14554.96\n",
      " Regression with ARIMA(0,0,2) errors : -13588.57\n",
      " Regression with ARIMA(1,0,3) errors : -14555.05\n",
      " Regression with ARIMA(0,0,3) errors : -13929.67\n",
      " Regression with ARIMA(2,0,3) errors : -14552.73\n",
      " Regression with ARIMA(1,0,4) errors : -14561.38\n",
      " Regression with ARIMA(0,0,4) errors : -14217.43\n",
      " Regression with ARIMA(2,0,4) errors : -14559.98\n",
      " Regression with ARIMA(1,0,5) errors : -14560.36\n",
      " Regression with ARIMA(0,0,5) errors : -14327\n",
      " Regression with ARIMA(2,0,5) errors : -14558.11\n",
      " Regression with ARIMA(1,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,4) errors : -14560.62\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14379.34\n",
      " Regression with ARIMA(1,1,0) errors : -14383.72\n",
      " Regression with ARIMA(0,1,1) errors : -14382.54\n",
      " Regression with ARIMA(0,1,0) errors : -14381.35\n",
      " Regression with ARIMA(2,1,0) errors : -14382.72\n",
      " Regression with ARIMA(1,1,1) errors : -14384.5\n",
      " Regression with ARIMA(2,1,1) errors : -14382.23\n",
      " Regression with ARIMA(1,1,2) errors : -14382.66\n",
      " Regression with ARIMA(0,1,2) errors : -14382.21\n",
      " Regression with ARIMA(1,1,1) errors : -14386.51\n",
      " Regression with ARIMA(0,1,1) errors : -14384.55\n",
      " Regression with ARIMA(1,1,0) errors : -14385.73\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : -14384.54\n",
      " Regression with ARIMA(0,1,2) errors : -14384.22\n",
      " Regression with ARIMA(2,1,0) errors : -14384.73\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14397.22\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14483.22\n",
      " Regression with ARIMA(0,0,0) errors : -11017.35\n",
      " Regression with ARIMA(1,0,0) errors : -14460.22\n",
      " Regression with ARIMA(0,0,1) errors : -12640.36\n",
      " Regression with ARIMA(0,0,0) errors : -9780.733\n",
      " Regression with ARIMA(1,0,2) errors : -14467.99\n",
      " Regression with ARIMA(2,0,1) errors : -14461.13\n",
      " Regression with ARIMA(3,0,2) errors : -14483.56\n",
      " Regression with ARIMA(3,0,1) errors : -14483.17\n",
      " Regression with ARIMA(4,0,2) errors : -14480.81\n",
      " Regression with ARIMA(3,0,3) errors : -14482.96\n",
      " Regression with ARIMA(2,0,3) errors : -14464.37\n",
      " Regression with ARIMA(4,0,1) errors : -14477.63\n",
      " Regression with ARIMA(4,0,3) errors : -14478.99\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14477.22\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14498.8\n",
      " Regression with ARIMA(0,0,0) errors : -11029\n",
      " Regression with ARIMA(1,0,0) errors : -14478.15\n",
      " Regression with ARIMA(0,0,1) errors : -12661.86\n",
      " Regression with ARIMA(0,0,0) errors : -9798.577\n",
      " Regression with ARIMA(1,0,2) errors : -14485.32\n",
      " Regression with ARIMA(2,0,1) errors : -14479.56\n",
      " Regression with ARIMA(3,0,2) errors : -14498.67\n",
      " Regression with ARIMA(2,0,3) errors : -14482.25\n",
      " Regression with ARIMA(1,0,1) errors : -14476.18\n",
      " Regression with ARIMA(1,0,3) errors : -14486.49\n",
      " Regression with ARIMA(3,0,1) errors : -14499.33\n",
      " Regression with ARIMA(3,0,0) errors : -14485.04\n",
      " Regression with ARIMA(4,0,1) errors : -14493.81\n",
      " Regression with ARIMA(2,0,0) errors : -14475.19\n",
      " Regression with ARIMA(4,0,0) errors : -14489\n",
      " Regression with ARIMA(4,0,2) errors : -14497.35\n",
      " Regression with ARIMA(3,0,1) errors : -14328.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -14499.04\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14499.82\n",
      " Regression with ARIMA(0,0,0) errors : -11030.92\n",
      " Regression with ARIMA(1,0,0) errors : -14479.83\n",
      " Regression with ARIMA(0,0,1) errors : -12666.18\n",
      " Regression with ARIMA(0,0,0) errors : -9815.953\n",
      " Regression with ARIMA(1,0,2) errors : -14487.24\n",
      " Regression with ARIMA(2,0,1) errors : -14480.13\n",
      " Regression with ARIMA(3,0,2) errors : -14499.16\n",
      " Regression with ARIMA(2,0,3) errors : -14482.98\n",
      " Regression with ARIMA(1,0,1) errors : -14477.85\n",
      " Regression with ARIMA(1,0,3) errors : -14488.5\n",
      " Regression with ARIMA(3,0,1) errors : -14497.61\n",
      " Regression with ARIMA(3,0,3) errors : -14499.03\n",
      " Regression with ARIMA(2,0,2) errors : -14337.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14481.43\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14520.82\n",
      " Regression with ARIMA(0,0,0) errors : -11039.14\n",
      " Regression with ARIMA(1,0,0) errors : -14493.69\n",
      " Regression with ARIMA(0,0,1) errors : -12672\n",
      " Regression with ARIMA(0,0,0) errors : -9822.197\n",
      " Regression with ARIMA(1,0,2) errors : -14500.76\n",
      " Regression with ARIMA(2,0,1) errors : -14497.56\n",
      " Regression with ARIMA(3,0,2) errors : -14524.84\n",
      " Regression with ARIMA(3,0,1) errors : -14518.61\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -14524.22\n",
      " Regression with ARIMA(2,0,3) errors : -14520.02\n",
      " Regression with ARIMA(4,0,1) errors : -14521.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14510.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14421.28\n",
      " Regression with ARIMA(1,1,0) errors : -14438.68\n",
      " Regression with ARIMA(0,1,1) errors : -14424.25\n",
      " Regression with ARIMA(0,1,0) errors : -14423.29\n",
      " Regression with ARIMA(2,1,0) errors : -14439.8\n",
      " Regression with ARIMA(3,1,0) errors : -14439.79\n",
      " Regression with ARIMA(2,1,1) errors : -14444.89\n",
      " Regression with ARIMA(1,1,1) errors : -14446.77\n",
      " Regression with ARIMA(1,1,2) errors : -14444.79\n",
      " Regression with ARIMA(0,1,2) errors : -14423.33\n",
      " Regression with ARIMA(1,1,1) errors : -14448.78\n",
      " Regression with ARIMA(0,1,1) errors : -14426.26\n",
      " Regression with ARIMA(1,1,0) errors : -14440.69\n",
      " Regression with ARIMA(2,1,1) errors : -14446.9\n",
      " Regression with ARIMA(1,1,2) errors : -14446.8\n",
      " Regression with ARIMA(0,1,2) errors : -14425.34\n",
      " Regression with ARIMA(2,1,0) errors : -14441.81\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14440.01\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14553.28\n",
      " Regression with ARIMA(0,1,0) errors : -14483.96\n",
      " Regression with ARIMA(1,1,0) errors : -14484.77\n",
      " Regression with ARIMA(0,1,1) errors : -14485.54\n",
      " Regression with ARIMA(0,1,0) errors : -14485.96\n",
      " Regression with ARIMA(1,1,2) errors : -14488.25\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14562.68\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14567.68\n",
      " Regression with ARIMA(1,1,4) errors : -14484.21\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14585.28\n",
      " Regression with ARIMA(1,1,5) errors : -14492.24\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14586.81\n",
      " Regression with ARIMA(1,1,5) errors : -14494.25\n",
      " Regression with ARIMA(2,1,4) errors : -14569.27\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : -14485.81\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14504.5\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14595.43\n",
      " Regression with ARIMA(0,1,0) errors : -14527.09\n",
      " Regression with ARIMA(1,1,0) errors : -14529.37\n",
      " Regression with ARIMA(0,1,1) errors : -14529.7\n",
      " Regression with ARIMA(0,1,0) errors : -14529.09\n",
      " Regression with ARIMA(1,1,2) errors : -14533.99\n",
      " Regression with ARIMA(2,1,1) errors : -14543.6\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14601.94\n",
      " Regression with ARIMA(1,1,3) errors : -14532.49\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14605.78\n",
      " Regression with ARIMA(1,1,4) errors : -14530.67\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14537.39\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14607.58\n",
      " Regression with ARIMA(1,1,4) errors : -14532.67\n",
      " Regression with ARIMA(2,1,3) errors : -14603.75\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : -14534.49\n",
      " Regression with ARIMA(1,1,5) errors : -14539.39\n",
      " Regression with ARIMA(3,1,3) errors : -14598.8\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14549.06\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14516.87\n",
      " Regression with ARIMA(1,1,0) errors : -14525.36\n",
      " Regression with ARIMA(0,1,1) errors : -14520.46\n",
      " Regression with ARIMA(0,1,0) errors : -14518.88\n",
      " Regression with ARIMA(2,1,0) errors : -14523.87\n",
      " Regression with ARIMA(1,1,1) errors : -14523.58\n",
      " Regression with ARIMA(2,1,1) errors : -14528.44\n",
      " Regression with ARIMA(3,1,1) errors : -14605.73\n",
      " Regression with ARIMA(3,1,0) errors : -14522.73\n",
      " Regression with ARIMA(4,1,1) errors : -14552.02\n",
      " Regression with ARIMA(3,1,2) errors : -14601.37\n",
      " Regression with ARIMA(4,1,0) errors : -14523.8\n",
      " Regression with ARIMA(4,1,2) errors : -14570.42\n",
      " Regression with ARIMA(3,1,1) errors : -14607.28\n",
      " Regression with ARIMA(2,1,1) errors : -14530.46\n",
      " Regression with ARIMA(3,1,0) errors : -14524.74\n",
      " Regression with ARIMA(4,1,1) errors : -14553.78\n",
      " Regression with ARIMA(3,1,2) errors : -14602.92\n",
      " Regression with ARIMA(2,1,0) errors : -14525.88\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,0) errors : -14525.81\n",
      " Regression with ARIMA(4,1,2) errors : -14572.1\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14535.51\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11250.18\n",
      " Regression with ARIMA(1,0,0) errors : -14656.36\n",
      " Regression with ARIMA(0,0,1) errors : -12862.56\n",
      " Regression with ARIMA(0,0,0) errors : -10027.92\n",
      " Regression with ARIMA(2,0,0) errors : -14654.03\n",
      " Regression with ARIMA(1,0,1) errors : -14654.36\n",
      " Regression with ARIMA(2,0,1) errors : -14660.84\n",
      " Regression with ARIMA(3,0,1) errors : -14661.21\n",
      " Regression with ARIMA(3,0,0) errors : -14664.08\n",
      " Regression with ARIMA(4,0,0) errors : -14664.12\n",
      " Regression with ARIMA(5,0,0) errors : -14670.91\n",
      " Regression with ARIMA(5,0,1) errors : -14674.19\n",
      " Regression with ARIMA(4,0,1) errors : -14674.78\n",
      " Regression with ARIMA(4,0,2) errors : -14678.29\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : -14693.27\n",
      " Regression with ARIMA(5,0,3) errors : -14691.32\n",
      " Regression with ARIMA(4,0,3) errors : -14661.91\n",
      " Regression with ARIMA(5,0,2) errors : -14579.72\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -14701.58\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11249.56\n",
      " Regression with ARIMA(1,0,0) errors : -14656.24\n",
      " Regression with ARIMA(0,0,1) errors : -12864.81\n",
      " Regression with ARIMA(0,0,0) errors : -10027.74\n",
      " Regression with ARIMA(2,0,0) errors : -14657.78\n",
      " Regression with ARIMA(3,0,0) errors : -14666.92\n",
      " Regression with ARIMA(4,0,0) errors : -14666.09\n",
      " Regression with ARIMA(3,0,1) errors : -14664.16\n",
      " Regression with ARIMA(2,0,1) errors : -14658.57\n",
      " Regression with ARIMA(4,0,1) errors : -14666.46\n",
      " Regression with ARIMA(3,0,0) errors : -14546.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,0) errors : -14662.78\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14675.28\n",
      " Regression with ARIMA(0,0,0) errors : -11256.19\n",
      " Regression with ARIMA(1,0,0) errors : -14668.76\n",
      " Regression with ARIMA(0,0,1) errors : -12871.85\n",
      " Regression with ARIMA(0,0,0) errors : -10034.68\n",
      " Regression with ARIMA(1,0,2) errors : -14674.7\n",
      " Regression with ARIMA(2,0,1) errors : -14674.96\n",
      " Regression with ARIMA(3,0,2) errors : -14693.42\n",
      " Regression with ARIMA(3,0,1) errors : -14675.56\n",
      " Regression with ARIMA(4,0,2) errors : -14690.6\n",
      " Regression with ARIMA(3,0,3) errors : -14692.29\n",
      " Regression with ARIMA(2,0,3) errors : -14676.55\n",
      " Regression with ARIMA(4,0,1) errors : -14675.31\n",
      " Regression with ARIMA(4,0,3) errors : -14683.71\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14692.38\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m03.2 <- my.tsCV(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                       silent=F,\n",
    "                       xreg=trainx[,2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e4fa7c88-54f4-4a91-954c-62b4b79f5327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-01-24\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m03.2\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435ab53e-426a-4b91-9d3a-d037e4dd9995",
   "metadata": {},
   "source": [
    "## Regressor mean of smaller period for forecast \n",
    "- Regressor mean for forecast is calculated from the number of latest 'horizon' period\n",
    "- the 1st model used the number of latest 'window' period for the calc of regressor mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "035d6b87-06c6-4440-88ae-98eaf1e6ca7b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14728.24\n",
      " Regression with ARIMA(0,1,0) errors : -14705.76\n",
      " Regression with ARIMA(1,1,0) errors : -14703.21\n",
      " Regression with ARIMA(0,1,1) errors : -14703.85\n",
      " Regression with ARIMA(0,1,0) errors : -14707.74\n",
      " Regression with ARIMA(1,1,2) errors : -14755.07\n",
      " Regression with ARIMA(0,1,2) errors : -14703.58\n",
      " Regression with ARIMA(1,1,1) errors : -14701.2\n",
      " Regression with ARIMA(1,1,3) errors : -14756.2\n",
      " Regression with ARIMA(0,1,3) errors : -14715.69\n",
      " Regression with ARIMA(2,1,3) errors : -14743.68\n",
      " Regression with ARIMA(1,1,4) errors : -14754.84\n",
      " Regression with ARIMA(0,1,4) errors : -14713.96\n",
      " Regression with ARIMA(2,1,4) errors : -14742.53\n",
      " Regression with ARIMA(1,1,3) errors : -14757.92\n",
      " Regression with ARIMA(0,1,3) errors : -14717.66\n",
      " Regression with ARIMA(1,1,2) errors : -14756.77\n",
      " Regression with ARIMA(2,1,3) errors : -14745.4\n",
      " Regression with ARIMA(1,1,4) errors : -14756.51\n",
      " Regression with ARIMA(0,1,2) errors : -14705.55\n",
      " Regression with ARIMA(0,1,4) errors : -14715.93\n",
      " Regression with ARIMA(2,1,2) errors : -14729.97\n",
      " Regression with ARIMA(2,1,4) errors : -14744.25\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14726.99\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14688.58\n",
      " Regression with ARIMA(1,1,0) errors : -14687.3\n",
      " Regression with ARIMA(0,1,1) errors : -14686.7\n",
      " Regression with ARIMA(0,1,0) errors : -14690.58\n",
      " Regression with ARIMA(1,1,1) errors : -14685.35\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14699.9\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14648.88\n",
      " Regression with ARIMA(1,1,0) errors : -14646.36\n",
      " Regression with ARIMA(0,1,1) errors : -14647.06\n",
      " Regression with ARIMA(0,1,0) errors : -14650.88\n",
      " Regression with ARIMA(1,1,1) errors : -14644.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14660.19\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14557.56\n",
      " Regression with ARIMA(1,1,0) errors : -14555.41\n",
      " Regression with ARIMA(0,1,1) errors : -14555.93\n",
      " Regression with ARIMA(0,1,0) errors : -14559.56\n",
      " Regression with ARIMA(1,1,1) errors : -14553.98\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14568.83\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14466.15\n",
      " Regression with ARIMA(1,1,0) errors : -14464.59\n",
      " Regression with ARIMA(0,1,1) errors : -14465.14\n",
      " Regression with ARIMA(0,1,0) errors : -14468.15\n",
      " Regression with ARIMA(1,1,1) errors : -14463.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14477.38\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14431.62\n",
      " Regression with ARIMA(1,1,0) errors : -14429.42\n",
      " Regression with ARIMA(0,1,1) errors : -14430.5\n",
      " Regression with ARIMA(0,1,0) errors : -14433.63\n",
      " Regression with ARIMA(1,1,1) errors : -14428.06\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14442.84\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14487.01\n",
      " Regression with ARIMA(0,1,0) errors : -14420.66\n",
      " Regression with ARIMA(1,1,0) errors : -14418.52\n",
      " Regression with ARIMA(0,1,1) errors : -14419.3\n",
      " Regression with ARIMA(0,1,0) errors : -14422.67\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14487.4\n",
      " Regression with ARIMA(1,1,1) errors : -14416.73\n",
      " Regression with ARIMA(2,1,0) errors : -14420.92\n",
      " Regression with ARIMA(3,1,1) errors : -14426\n",
      " Regression with ARIMA(3,1,0) errors : -14427.6\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14489.16\n",
      " Regression with ARIMA(1,1,1) errors : -14418.75\n",
      " Regression with ARIMA(2,1,0) errors : -14422.93\n",
      " Regression with ARIMA(3,1,1) errors : -14427.99\n",
      " Regression with ARIMA(2,1,2) errors : -14488.71\n",
      " Regression with ARIMA(1,1,0) errors : -14420.53\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -14429.61\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -14440.44\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14445.76\n",
      " Regression with ARIMA(0,1,0) errors : -14415.25\n",
      " Regression with ARIMA(1,1,0) errors : -14413.72\n",
      " Regression with ARIMA(0,1,1) errors : -14413.85\n",
      " Regression with ARIMA(0,1,0) errors : -14417.26\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14433.81\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14468.58\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14468.82\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14469.94\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14471.73\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14470.6\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14426.46\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14421.25\n",
      " Regression with ARIMA(1,1,0) errors : -14418.78\n",
      " Regression with ARIMA(0,1,1) errors : -14419.77\n",
      " Regression with ARIMA(0,1,0) errors : -14423.26\n",
      " Regression with ARIMA(1,1,1) errors : -14417.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14432.47\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14414.4\n",
      " Regression with ARIMA(1,1,0) errors : -14411.72\n",
      " Regression with ARIMA(0,1,1) errors : -14412.71\n",
      " Regression with ARIMA(0,1,0) errors : -14416.41\n",
      " Regression with ARIMA(1,1,1) errors : -14410.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14425.61\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14371.6\n",
      " Regression with ARIMA(1,1,0) errors : -14369.53\n",
      " Regression with ARIMA(0,1,1) errors : -14370.05\n",
      " Regression with ARIMA(0,1,0) errors : -14373.59\n",
      " Regression with ARIMA(1,1,1) errors : -14368.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14382.78\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14319.68\n",
      " Regression with ARIMA(0,1,0) errors : -14316.26\n",
      " Regression with ARIMA(1,1,0) errors : -14313.77\n",
      " Regression with ARIMA(0,1,1) errors : -14314.65\n",
      " Regression with ARIMA(0,1,0) errors : -14318.23\n",
      " Regression with ARIMA(1,1,2) errors : -14385.93\n",
      " Regression with ARIMA(0,1,2) errors : -14319.04\n",
      " Regression with ARIMA(1,1,1) errors : -14312.24\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14327.45\n",
      " Regression with ARIMA(2,1,1) errors : -14356.37\n",
      " Regression with ARIMA(2,1,3) errors : -14367.96\n",
      " Regression with ARIMA(1,1,2) errors : -14387.45\n",
      " Regression with ARIMA(0,1,2) errors : -14321.01\n",
      " Regression with ARIMA(1,1,1) errors : -14314.22\n",
      " Regression with ARIMA(2,1,2) errors : -14321.64\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(0,1,1) errors : -14316.62\n",
      " Regression with ARIMA(0,1,3) errors : -14329.42\n",
      " Regression with ARIMA(2,1,1) errors : -14358.04\n",
      " Regression with ARIMA(2,1,3) errors : -14369.57\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14338.56\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14254.7\n",
      " Regression with ARIMA(1,1,0) errors : -14252.25\n",
      " Regression with ARIMA(0,1,1) errors : -14252.87\n",
      " Regression with ARIMA(0,1,0) errors : -14256.7\n",
      " Regression with ARIMA(1,1,1) errors : -14250.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14265.84\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14249.15\n",
      " Regression with ARIMA(1,1,0) errors : -14246.58\n",
      " Regression with ARIMA(0,1,1) errors : -14247.46\n",
      " Regression with ARIMA(0,1,0) errors : -14251.14\n",
      " Regression with ARIMA(1,1,1) errors : -14245.11\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14260.28\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14341.48\n",
      " Regression with ARIMA(0,0,0) errors : -10840.14\n",
      " Regression with ARIMA(1,0,0) errors : -14339.73\n",
      " Regression with ARIMA(0,0,1) errors : -12569.99\n",
      " Regression with ARIMA(0,0,0) errors : -9528.814\n",
      " Regression with ARIMA(1,0,2) errors : -14343.89\n",
      " Regression with ARIMA(0,0,2) errors : -13424.35\n",
      " Regression with ARIMA(1,0,1) errors : -14345.89\n",
      " Regression with ARIMA(2,0,1) errors : -14342.88\n",
      " Regression with ARIMA(2,0,0) errors : -14344.83\n",
      " Regression with ARIMA(1,0,1) errors : -14199.07\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14344.44\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14131.23\n",
      " Regression with ARIMA(1,1,0) errors : -14129.6\n",
      " Regression with ARIMA(0,1,1) errors : -14129.22\n",
      " Regression with ARIMA(0,1,0) errors : -14133.21\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14142.29\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14104.7\n",
      " Regression with ARIMA(1,1,0) errors : -14102.15\n",
      " Regression with ARIMA(0,1,1) errors : -14102.72\n",
      " Regression with ARIMA(0,1,0) errors : -14106.71\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14115.78\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14094.76\n",
      " Regression with ARIMA(1,1,0) errors : -14092.35\n",
      " Regression with ARIMA(0,1,1) errors : -14092.76\n",
      " Regression with ARIMA(0,1,0) errors : -14096.76\n",
      " Regression with ARIMA(1,1,1) errors : -14091.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14105.82\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14158.82\n",
      " Regression with ARIMA(0,1,0) errors : -14086.53\n",
      " Regression with ARIMA(1,1,0) errors : -14083.63\n",
      " Regression with ARIMA(0,1,1) errors : -14084.57\n",
      " Regression with ARIMA(0,1,0) errors : -14088.54\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14155.6\n",
      " Regression with ARIMA(3,1,2) errors : -14153.06\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : -14177.73\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14178.44\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14179.86\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14181.4\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14179.99\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14166.32\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14097.6\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14074.57\n",
      " Regression with ARIMA(1,1,0) errors : -14071.57\n",
      " Regression with ARIMA(0,1,1) errors : -14072.57\n",
      " Regression with ARIMA(0,1,0) errors : -14076.57\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14085.63\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14156.68\n",
      " Regression with ARIMA(0,0,0) errors : -10543.02\n",
      " Regression with ARIMA(1,0,0) errors : -14157.58\n",
      " Regression with ARIMA(0,0,1) errors : -12288.52\n",
      " Regression with ARIMA(0,0,0) errors : -9161.948\n",
      " Regression with ARIMA(2,0,0) errors : -14160.85\n",
      " Regression with ARIMA(3,0,0) errors : -14159.41\n",
      " Regression with ARIMA(2,0,1) errors : -14158.76\n",
      " Regression with ARIMA(1,0,1) errors : -14161.58\n",
      " Regression with ARIMA(1,0,2) errors : -14159.57\n",
      " Regression with ARIMA(0,0,2) errors : -13166.06\n",
      " Regression with ARIMA(1,0,1) errors : -14036.84\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14160.49\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14097.59\n",
      " Regression with ARIMA(0,0,0) errors : -10474.05\n",
      " Regression with ARIMA(1,0,0) errors : -14096.1\n",
      " Regression with ARIMA(0,0,1) errors : -12234.47\n",
      " Regression with ARIMA(0,0,0) errors : -9152.683\n",
      " Regression with ARIMA(1,0,2) errors : -14099.35\n",
      " Regression with ARIMA(0,0,2) errors : -13115.29\n",
      " Regression with ARIMA(1,0,1) errors : -14101.37\n",
      " Regression with ARIMA(2,0,1) errors : -14098.29\n",
      " Regression with ARIMA(2,0,0) errors : -14100.36\n",
      " Regression with ARIMA(1,0,1) errors : -13962.68\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14100.49\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13956.34\n",
      " Regression with ARIMA(1,1,0) errors : -13954.24\n",
      " Regression with ARIMA(0,1,1) errors : -13954.58\n",
      " Regression with ARIMA(0,1,0) errors : -13958.35\n",
      " Regression with ARIMA(1,1,1) errors : -13952.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13967.35\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13942.25\n",
      " Regression with ARIMA(1,1,0) errors : -13939.51\n",
      " Regression with ARIMA(0,1,1) errors : -13940.54\n",
      " Regression with ARIMA(0,1,0) errors : -13944.26\n",
      " Regression with ARIMA(1,1,1) errors : -13938.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13953.25\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14057.56\n",
      " Regression with ARIMA(0,0,0) errors : -10451.94\n",
      " Regression with ARIMA(1,0,0) errors : -14055.02\n",
      " Regression with ARIMA(0,0,1) errors : -12212.26\n",
      " Regression with ARIMA(0,0,0) errors : -9125.585\n",
      " Regression with ARIMA(1,0,2) errors : -14059.61\n",
      " Regression with ARIMA(0,0,2) errors : -13092.48\n",
      " Regression with ARIMA(1,0,1) errors : -14061.59\n",
      " Regression with ARIMA(2,0,1) errors : -14058.81\n",
      " Regression with ARIMA(2,0,0) errors : -14060.82\n",
      " Regression with ARIMA(1,0,1) errors : -13926.65\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14060.43\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14049.73\n",
      " Regression with ARIMA(0,0,0) errors : -10463.36\n",
      " Regression with ARIMA(1,0,0) errors : -14047.15\n",
      " Regression with ARIMA(0,0,1) errors : -12215.94\n",
      " Regression with ARIMA(0,0,0) errors : -9113.651\n",
      " Regression with ARIMA(1,0,2) errors : -14050.93\n",
      " Regression with ARIMA(0,0,2) errors : -13088.83\n",
      " Regression with ARIMA(1,0,1) errors : -14052.85\n",
      " Regression with ARIMA(2,0,1) errors : -14049.93\n",
      " Regression with ARIMA(2,0,0) errors : -14051.82\n",
      " Regression with ARIMA(1,0,1) errors : -13912.48\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14051.09\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13911.02\n",
      " Regression with ARIMA(1,1,0) errors : -13908.48\n",
      " Regression with ARIMA(0,1,1) errors : -13909.2\n",
      " Regression with ARIMA(0,1,0) errors : -13913.03\n",
      " Regression with ARIMA(1,1,1) errors : -13907.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13922.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13900.07\n",
      " Regression with ARIMA(1,1,0) errors : -13897.25\n",
      " Regression with ARIMA(0,1,1) errors : -13898.14\n",
      " Regression with ARIMA(0,1,0) errors : -13902.07\n",
      " Regression with ARIMA(1,1,1) errors : -13896.05\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13911.05\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13876.42\n",
      " Regression with ARIMA(0,1,0) errors : -13873.69\n",
      " Regression with ARIMA(1,1,0) errors : -13870.8\n",
      " Regression with ARIMA(0,1,1) errors : -13871.79\n",
      " Regression with ARIMA(0,1,0) errors : -13875.69\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -13951.7\n",
      " Regression with ARIMA(1,1,1) errors : -13869.75\n",
      " Regression with ARIMA(2,1,0) errors : -13877.74\n",
      " Regression with ARIMA(3,1,1) errors : -13879.69\n",
      " Regression with ARIMA(3,1,0) errors : -13878.26\n",
      " Regression with ARIMA(3,1,2) errors : -13880.96\n",
      " Regression with ARIMA(2,1,1) errors : -13953.47\n",
      " Regression with ARIMA(1,1,1) errors : -13871.73\n",
      " Regression with ARIMA(2,1,0) errors : -13879.75\n",
      " Regression with ARIMA(3,1,1) errors : -13881.7\n",
      " Regression with ARIMA(2,1,2) errors : -13878.44\n",
      " Regression with ARIMA(1,1,0) errors : -13872.8\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -13880.27\n",
      " Regression with ARIMA(3,1,2) errors : -13883\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -13906.38\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13861.23\n",
      " Regression with ARIMA(1,1,0) errors : -13858.29\n",
      " Regression with ARIMA(0,1,1) errors : -13859.25\n",
      " Regression with ARIMA(0,1,0) errors : -13863.23\n",
      " Regression with ARIMA(1,1,1) errors : -13857.3\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13872.19\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13896.9\n",
      " Regression with ARIMA(0,0,0) errors : -10196.26\n",
      " Regression with ARIMA(1,0,0) errors : -13893.1\n",
      " Regression with ARIMA(0,0,1) errors : -11966.99\n",
      " Regression with ARIMA(0,0,0) errors : -8742.913\n",
      " Regression with ARIMA(1,0,2) errors : -13897.42\n",
      " Regression with ARIMA(0,0,2) errors : -12878.36\n",
      " Regression with ARIMA(1,0,1) errors : -13899.18\n",
      " Regression with ARIMA(2,0,1) errors : -13896.32\n",
      " Regression with ARIMA(2,0,0) errors : -13897.97\n",
      " Regression with ARIMA(1,0,1) errors : -13775.62\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13898.36\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13779.66\n",
      " Regression with ARIMA(0,0,0) errors : -10097.98\n",
      " Regression with ARIMA(1,0,0) errors : -13771.91\n",
      " Regression with ARIMA(0,0,1) errors : -11865.72\n",
      " Regression with ARIMA(0,0,0) errors : -8710.896\n",
      " Regression with ARIMA(1,0,2) errors : -13777.93\n",
      " Regression with ARIMA(2,0,1) errors : -13777.15\n",
      " Regression with ARIMA(3,0,2) errors : -13783.79\n",
      " Regression with ARIMA(3,0,1) errors : -13778.18\n",
      " Regression with ARIMA(4,0,2) errors : -13782.79\n",
      " Regression with ARIMA(3,0,3) errors : -13790.74\n",
      " Regression with ARIMA(2,0,3) errors : -13778.27\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13781.06\n",
      " Regression with ARIMA(2,0,4) errors : -13781.18\n",
      " Regression with ARIMA(4,0,4) errors : -13783.64\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,3) errors : -13791.61\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13736.94\n",
      " Regression with ARIMA(0,0,0) errors : -10002.66\n",
      " Regression with ARIMA(1,0,0) errors : -13730.41\n",
      " Regression with ARIMA(0,0,1) errors : -11778.89\n",
      " Regression with ARIMA(0,0,0) errors : -8620.765\n",
      " Regression with ARIMA(1,0,2) errors : -13736.26\n",
      " Regression with ARIMA(2,0,1) errors : -13735.25\n",
      " Regression with ARIMA(3,0,2) errors : -13738.48\n",
      " Regression with ARIMA(3,0,1) errors : -13735.53\n",
      " Regression with ARIMA(4,0,2) errors : -13732.51\n",
      " Regression with ARIMA(3,0,3) errors : -13747.21\n",
      " Regression with ARIMA(2,0,3) errors : -13735.02\n",
      " Regression with ARIMA(4,0,3) errors : -13743.42\n",
      " Regression with ARIMA(3,0,4) errors : -13736.01\n",
      " Regression with ARIMA(2,0,4) errors : -13737.88\n",
      " Regression with ARIMA(4,0,4) errors : -13742.31\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,3) errors : -13748.29\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13671.5\n",
      " Regression with ARIMA(0,0,0) errors : -9894.943\n",
      " Regression with ARIMA(1,0,0) errors : -13665.86\n",
      " Regression with ARIMA(0,0,1) errors : -11694.71\n",
      " Regression with ARIMA(0,0,0) errors : -8560.227\n",
      " Regression with ARIMA(1,0,2) errors : -13672.38\n",
      " Regression with ARIMA(0,0,2) errors : -12612.9\n",
      " Regression with ARIMA(1,0,1) errors : -13674.2\n",
      " Regression with ARIMA(2,0,1) errors : -13671.58\n",
      " Regression with ARIMA(2,0,0) errors : -13673.48\n",
      " Regression with ARIMA(1,0,1) errors : -13559.42\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13673.28\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13629.1\n",
      " Regression with ARIMA(0,0,0) errors : -9878.792\n",
      " Regression with ARIMA(1,0,0) errors : -13624.85\n",
      " Regression with ARIMA(0,0,1) errors : -11666.73\n",
      " Regression with ARIMA(0,0,0) errors : -8556.701\n",
      " Regression with ARIMA(1,0,2) errors : -13629.96\n",
      " Regression with ARIMA(0,0,2) errors : -12579.75\n",
      " Regression with ARIMA(1,0,1) errors : -13631.19\n",
      " Regression with ARIMA(2,0,1) errors : -13629.28\n",
      " Regression with ARIMA(2,0,0) errors : -13630.88\n",
      " Regression with ARIMA(1,0,1) errors : -13512.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13630.37\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13611.31\n",
      " Regression with ARIMA(0,0,0) errors : -9870.771\n",
      " Regression with ARIMA(1,0,0) errors : -13607.01\n",
      " Regression with ARIMA(0,0,1) errors : -11652.28\n",
      " Regression with ARIMA(0,0,0) errors : -8549.922\n",
      " Regression with ARIMA(1,0,2) errors : -13611.78\n",
      " Regression with ARIMA(0,0,2) errors : -12567.48\n",
      " Regression with ARIMA(1,0,1) errors : -13612.86\n",
      " Regression with ARIMA(2,0,1) errors : -13620.17\n",
      " Regression with ARIMA(2,0,0) errors : -13612.21\n",
      " Regression with ARIMA(3,0,1) errors : -13610.14\n",
      " Regression with ARIMA(3,0,0) errors : -13609.99\n",
      " Regression with ARIMA(3,0,2) errors : -13609.53\n",
      " Regression with ARIMA(2,0,1) errors : -13511.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13612.06\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13585.71\n",
      " Regression with ARIMA(0,0,0) errors : -9844.615\n",
      " Regression with ARIMA(1,0,0) errors : -13581.02\n",
      " Regression with ARIMA(0,0,1) errors : -11622.06\n",
      " Regression with ARIMA(0,0,0) errors : -8510.432\n",
      " Regression with ARIMA(1,0,2) errors : -13586.32\n",
      " Regression with ARIMA(0,0,2) errors : -12543.41\n",
      " Regression with ARIMA(1,0,1) errors : -13587.02\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -13586.54\n",
      " Regression with ARIMA(1,0,1) errors : -13475.64\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13585.99\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13574.71\n",
      " Regression with ARIMA(0,0,0) errors : -9826.549\n",
      " Regression with ARIMA(1,0,0) errors : -13570.27\n",
      " Regression with ARIMA(0,0,1) errors : -11609.5\n",
      " Regression with ARIMA(0,0,0) errors : -8481.914\n",
      " Regression with ARIMA(1,0,2) errors : -13575.26\n",
      " Regression with ARIMA(0,0,2) errors : -12534.01\n",
      " Regression with ARIMA(1,0,1) errors : -13576.15\n",
      " Regression with ARIMA(2,0,1) errors : -13583.87\n",
      " Regression with ARIMA(2,0,0) errors : -13575.76\n",
      " Regression with ARIMA(3,0,1) errors : -13573.56\n",
      " Regression with ARIMA(3,0,0) errors : -13574.15\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13575.33\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13420.85\n",
      " Regression with ARIMA(1,1,0) errors : -13418.28\n",
      " Regression with ARIMA(0,1,1) errors : -13419.05\n",
      " Regression with ARIMA(0,1,0) errors : -13422.86\n",
      " Regression with ARIMA(1,1,1) errors : -13416.27\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13431.63\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13406.54\n",
      " Regression with ARIMA(1,1,0) errors : -13403.97\n",
      " Regression with ARIMA(0,1,1) errors : -13404.69\n",
      " Regression with ARIMA(0,1,0) errors : -13408.55\n",
      " Regression with ARIMA(1,1,1) errors : -13401.96\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13417.31\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13398.85\n",
      " Regression with ARIMA(1,1,0) errors : -13397.03\n",
      " Regression with ARIMA(0,1,1) errors : -13396.96\n",
      " Regression with ARIMA(0,1,0) errors : -13400.86\n",
      " Regression with ARIMA(1,1,1) errors : -13395.03\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13409.61\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13388.05\n",
      " Regression with ARIMA(1,1,0) errors : -13385.34\n",
      " Regression with ARIMA(0,1,1) errors : -13386.18\n",
      " Regression with ARIMA(0,1,0) errors : -13390.05\n",
      " Regression with ARIMA(1,1,1) errors : -13383.59\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13398.81\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13385.45\n",
      " Regression with ARIMA(1,1,0) errors : -13382.92\n",
      " Regression with ARIMA(0,1,1) errors : -13383.57\n",
      " Regression with ARIMA(0,1,0) errors : -13387.46\n",
      " Regression with ARIMA(1,1,1) errors : -13380.91\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13396.21\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13381.56\n",
      " Regression with ARIMA(1,1,0) errors : -13380.11\n",
      " Regression with ARIMA(0,1,1) errors : -13379.6\n",
      " Regression with ARIMA(0,1,0) errors : -13383.57\n",
      " Regression with ARIMA(1,1,1) errors : -13378.27\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13392.32\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13382.25\n",
      " Regression with ARIMA(1,1,0) errors : -13380.87\n",
      " Regression with ARIMA(0,1,1) errors : -13380.28\n",
      " Regression with ARIMA(0,1,0) errors : -13384.26\n",
      " Regression with ARIMA(1,1,1) errors : -13379.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13393.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13380.14\n",
      " Regression with ARIMA(1,1,0) errors : -13377.47\n",
      " Regression with ARIMA(0,1,1) errors : -13378.15\n",
      " Regression with ARIMA(0,1,0) errors : -13382.15\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.9\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13378.91\n",
      " Regression with ARIMA(1,1,0) errors : -13377.73\n",
      " Regression with ARIMA(0,1,1) errors : -13376.9\n",
      " Regression with ARIMA(0,1,0) errors : -13380.91\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13389.66\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13379.35\n",
      " Regression with ARIMA(1,1,0) errors : -13377.78\n",
      " Regression with ARIMA(0,1,1) errors : -13377.34\n",
      " Regression with ARIMA(0,1,0) errors : -13381.35\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.1\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13379.9\n",
      " Regression with ARIMA(1,1,0) errors : -13377.2\n",
      " Regression with ARIMA(0,1,1) errors : -13377.89\n",
      " Regression with ARIMA(0,1,0) errors : -13381.91\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.66\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13381.25\n",
      " Regression with ARIMA(1,1,0) errors : -13378.41\n",
      " Regression with ARIMA(0,1,1) errors : -13379.25\n",
      " Regression with ARIMA(0,1,0) errors : -13383.26\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13392.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13376.01\n",
      " Regression with ARIMA(1,1,0) errors : -13373.65\n",
      " Regression with ARIMA(0,1,1) errors : -13374\n",
      " Regression with ARIMA(0,1,0) errors : -13378.02\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13386.77\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13369.58\n",
      " Regression with ARIMA(1,1,0) errors : -13366.83\n",
      " Regression with ARIMA(0,1,1) errors : -13367.57\n",
      " Regression with ARIMA(0,1,0) errors : -13371.59\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13380.33\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13497.89\n",
      " Regression with ARIMA(0,0,0) errors : -9950.123\n",
      " Regression with ARIMA(1,0,0) errors : -13493.27\n",
      " Regression with ARIMA(0,0,1) errors : -11642.05\n",
      " Regression with ARIMA(0,0,0) errors : -8458.864\n",
      " Regression with ARIMA(1,0,2) errors : -13494.53\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -13496.04\n",
      " Regression with ARIMA(1,0,1) errors : -13495.7\n",
      " Regression with ARIMA(1,0,3) errors : -13492.7\n",
      " Regression with ARIMA(3,0,1) errors : -13497.36\n",
      " Regression with ARIMA(3,0,3) errors : -13498.01\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13507.72\n",
      " Regression with ARIMA(2,0,4) errors : -13500.47\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13500.7\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13506.03\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13499.98\n",
      " Regression with ARIMA(0,0,0) errors : -9960.775\n",
      " Regression with ARIMA(1,0,0) errors : -13495.47\n",
      " Regression with ARIMA(0,0,1) errors : -11645.81\n",
      " Regression with ARIMA(0,0,0) errors : -8453.629\n",
      " Regression with ARIMA(1,0,2) errors : -13496.49\n",
      " Regression with ARIMA(2,0,1) errors : -13507.19\n",
      " Regression with ARIMA(1,0,1) errors : -13497.52\n",
      " Regression with ARIMA(2,0,0) errors : -13496.74\n",
      " Regression with ARIMA(3,0,1) errors : -13497.31\n",
      " Regression with ARIMA(3,0,0) errors : -13495.2\n",
      " Regression with ARIMA(3,0,2) errors : -13495.71\n",
      " Regression with ARIMA(2,0,1) errors : -13378.82\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13506.74\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13497.77\n",
      " Regression with ARIMA(0,0,0) errors : -9958.269\n",
      " Regression with ARIMA(1,0,0) errors : -13494.31\n",
      " Regression with ARIMA(0,0,1) errors : -11644.45\n",
      " Regression with ARIMA(0,0,0) errors : -8449.905\n",
      " Regression with ARIMA(1,0,2) errors : -13495.3\n",
      " Regression with ARIMA(2,0,1) errors : -13507.9\n",
      " Regression with ARIMA(1,0,1) errors : -13496.33\n",
      " Regression with ARIMA(2,0,0) errors : -13495.6\n",
      " Regression with ARIMA(3,0,1) errors : -13496.54\n",
      " Regression with ARIMA(3,0,0) errors : -13493.75\n",
      " Regression with ARIMA(3,0,2) errors : -13495.71\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13508.08\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13493.96\n",
      " Regression with ARIMA(0,0,0) errors : -9977.205\n",
      " Regression with ARIMA(1,0,0) errors : -13489.97\n",
      " Regression with ARIMA(0,0,1) errors : -11647.24\n",
      " Regression with ARIMA(0,0,0) errors : -8450.876\n",
      " Regression with ARIMA(1,0,2) errors : -13490.98\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13488.95\n",
      " Regression with ARIMA(2,0,3) errors : -13487.5\n",
      " Regression with ARIMA(1,0,1) errors : -13492.01\n",
      " Regression with ARIMA(1,0,3) errors : -13489.23\n",
      " Regression with ARIMA(3,0,1) errors : -13492.37\n",
      " Regression with ARIMA(3,0,3) errors : -13486.94\n",
      " Regression with ARIMA(2,0,2) errors : -13356.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.62\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.03\n",
      " Regression with ARIMA(0,0,0) errors : -10035.28\n",
      " Regression with ARIMA(1,0,0) errors : -13487.39\n",
      " Regression with ARIMA(0,0,1) errors : -11673.35\n",
      " Regression with ARIMA(0,0,0) errors : -8457.324\n",
      " Regression with ARIMA(1,0,2) errors : -13488\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13489.24\n",
      " Regression with ARIMA(2,0,3) errors : -13489.21\n",
      " Regression with ARIMA(1,0,1) errors : -13488.93\n",
      " Regression with ARIMA(1,0,3) errors : -13486.24\n",
      " Regression with ARIMA(3,0,1) errors : -13491.09\n",
      " Regression with ARIMA(3,0,0) errors : -13487.21\n",
      " Regression with ARIMA(4,0,1) errors : -13487.57\n",
      " Regression with ARIMA(2,0,0) errors : -13488.97\n",
      " Regression with ARIMA(4,0,0) errors : -13485.19\n",
      " Regression with ARIMA(4,0,2) errors : -13498.14\n",
      " Regression with ARIMA(5,0,2) errors : -13499.05\n",
      " Regression with ARIMA(5,0,1) errors : -13492.88\n",
      " Regression with ARIMA(5,0,3) errors : -13497.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13501.63\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.2\n",
      " Regression with ARIMA(0,0,0) errors : -10019.33\n",
      " Regression with ARIMA(1,0,0) errors : -13487.57\n",
      " Regression with ARIMA(0,0,1) errors : -11667.27\n",
      " Regression with ARIMA(0,0,0) errors : -8455.887\n",
      " Regression with ARIMA(1,0,2) errors : -13488.56\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13489.44\n",
      " Regression with ARIMA(2,0,3) errors : -13490.16\n",
      " Regression with ARIMA(1,0,1) errors : -13489.31\n",
      " Regression with ARIMA(1,0,3) errors : -13486.85\n",
      " Regression with ARIMA(3,0,1) errors : -13491.32\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13350.82\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.68\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13489.2\n",
      " Regression with ARIMA(0,0,0) errors : -10028.88\n",
      " Regression with ARIMA(1,0,0) errors : -13485\n",
      " Regression with ARIMA(0,0,1) errors : -11673.96\n",
      " Regression with ARIMA(0,0,0) errors : -8443.256\n",
      " Regression with ARIMA(1,0,2) errors : -13486.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -13487.2\n",
      " Regression with ARIMA(1,0,1) errors : -13487.01\n",
      " Regression with ARIMA(1,0,3) errors : -13484.63\n",
      " Regression with ARIMA(3,0,1) errors : -13491.48\n",
      " Regression with ARIMA(3,0,0) errors : -13487\n",
      " Regression with ARIMA(4,0,1) errors : -13489.1\n",
      " Regression with ARIMA(2,0,0) errors : -13486.23\n",
      " Regression with ARIMA(4,0,0) errors : -13484.88\n",
      " Regression with ARIMA(4,0,2) errors : -13500.18\n",
      " Regression with ARIMA(5,0,2) errors : -13502.09\n",
      " Regression with ARIMA(5,0,1) errors : -13494.32\n",
      " Regression with ARIMA(5,0,3) errors : -13500.12\n",
      " Regression with ARIMA(4,0,3) errors : -13500.55\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13500.88\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492\n",
      " Regression with ARIMA(0,0,0) errors : -10028.08\n",
      " Regression with ARIMA(1,0,0) errors : -13487.35\n",
      " Regression with ARIMA(0,0,1) errors : -11679.14\n",
      " Regression with ARIMA(0,0,0) errors : -8442.705\n",
      " Regression with ARIMA(1,0,2) errors : -13488.66\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13487.58\n",
      " Regression with ARIMA(2,0,3) errors : -13489.99\n",
      " Regression with ARIMA(1,0,1) errors : -13489.51\n",
      " Regression with ARIMA(1,0,3) errors : -13487.09\n",
      " Regression with ARIMA(3,0,1) errors : -13489.86\n",
      " Regression with ARIMA(3,0,3) errors : -13482.34\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.71\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13496.48\n",
      " Regression with ARIMA(0,0,0) errors : -10046.87\n",
      " Regression with ARIMA(1,0,0) errors : -13491.11\n",
      " Regression with ARIMA(0,0,1) errors : -11686.59\n",
      " Regression with ARIMA(0,0,0) errors : -8439.819\n",
      " Regression with ARIMA(1,0,2) errors : -13492.36\n",
      " Regression with ARIMA(2,0,1) errors : -13506.72\n",
      " Regression with ARIMA(1,0,1) errors : -13493.26\n",
      " Regression with ARIMA(2,0,0) errors : -13492.87\n",
      " Regression with ARIMA(3,0,1) errors : -13494.79\n",
      " Regression with ARIMA(3,0,0) errors : -13491.08\n",
      " Regression with ARIMA(3,0,2) errors : -13506.27\n",
      " Regression with ARIMA(2,0,1) errors : -13358.47\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13505.42\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.02\n",
      " Regression with ARIMA(0,0,0) errors : -10051.63\n",
      " Regression with ARIMA(1,0,0) errors : -13487.72\n",
      " Regression with ARIMA(0,0,1) errors : -11688.79\n",
      " Regression with ARIMA(0,0,0) errors : -8460.12\n",
      " Regression with ARIMA(1,0,2) errors : -13489\n",
      " Regression with ARIMA(2,0,1) errors : -13501\n",
      " Regression with ARIMA(1,0,1) errors : -13489.93\n",
      " Regression with ARIMA(2,0,0) errors : -13489.16\n",
      " Regression with ARIMA(3,0,1) errors : -13490.72\n",
      " Regression with ARIMA(3,0,0) errors : -13487.43\n",
      " Regression with ARIMA(3,0,2) errors : -13488.68\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13501.14\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13500.43\n",
      " Regression with ARIMA(0,0,0) errors : -10047.97\n",
      " Regression with ARIMA(1,0,0) errors : -13495.4\n",
      " Regression with ARIMA(0,0,1) errors : -11686.73\n",
      " Regression with ARIMA(0,0,0) errors : -8459.472\n",
      " Regression with ARIMA(1,0,2) errors : -13496.66\n",
      " Regression with ARIMA(2,0,1) errors : -13510.38\n",
      " Regression with ARIMA(1,0,1) errors : -13497.58\n",
      " Regression with ARIMA(2,0,0) errors : -13497.07\n",
      " Regression with ARIMA(3,0,1) errors : -13498.19\n",
      " Regression with ARIMA(3,0,0) errors : -13495.29\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13509.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10051.61\n",
      " Regression with ARIMA(1,0,0) errors : -13499.36\n",
      " Regression with ARIMA(0,0,1) errors : -11694.33\n",
      " Regression with ARIMA(0,0,0) errors : -8454.72\n",
      " Regression with ARIMA(2,0,0) errors : -13501.93\n",
      " Regression with ARIMA(3,0,0) errors : -13500.22\n",
      " Regression with ARIMA(2,0,1) errors : -13512.21\n",
      " Regression with ARIMA(1,0,1) errors : -13501.76\n",
      " Regression with ARIMA(3,0,1) errors : -13503.01\n",
      " Regression with ARIMA(1,0,2) errors : -13500.7\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13514.04\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13505.3\n",
      " Regression with ARIMA(0,0,0) errors : -10067.87\n",
      " Regression with ARIMA(1,0,0) errors : -13500.56\n",
      " Regression with ARIMA(0,0,1) errors : -11703.92\n",
      " Regression with ARIMA(0,0,0) errors : -8459.352\n",
      " Regression with ARIMA(1,0,2) errors : -13501.48\n",
      " Regression with ARIMA(2,0,1) errors : -13513.92\n",
      " Regression with ARIMA(1,0,1) errors : -13502.47\n",
      " Regression with ARIMA(2,0,0) errors : -13501.76\n",
      " Regression with ARIMA(3,0,1) errors : -13504.22\n",
      " Regression with ARIMA(3,0,0) errors : -13499.98\n",
      " Regression with ARIMA(3,0,2) errors : -13502.51\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13509.66\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13504.43\n",
      " Regression with ARIMA(0,0,0) errors : -10066.73\n",
      " Regression with ARIMA(1,0,0) errors : -13500.34\n",
      " Regression with ARIMA(0,0,1) errors : -11703.9\n",
      " Regression with ARIMA(0,0,0) errors : -8459.982\n",
      " Regression with ARIMA(1,0,2) errors : -13501.46\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13502.1\n",
      " Regression with ARIMA(2,0,3) errors : -13502.47\n",
      " Regression with ARIMA(1,0,1) errors : -13502.43\n",
      " Regression with ARIMA(1,0,3) errors : -13499.75\n",
      " Regression with ARIMA(3,0,1) errors : -13504.38\n",
      " Regression with ARIMA(3,0,3) errors : -13511.67\n",
      " Regression with ARIMA(4,0,3) errors : -13502.32\n",
      " Regression with ARIMA(3,0,4) errors : -13513.38\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -13510.29\n",
      " Regression with ARIMA(3,0,5) errors : -13505.27\n",
      " Regression with ARIMA(2,0,5) errors : -13506.32\n",
      " Regression with ARIMA(4,0,5) errors : -13507.77\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13512.15\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13504.84\n",
      " Regression with ARIMA(0,0,0) errors : -10082.23\n",
      " Regression with ARIMA(1,0,0) errors : -13499.69\n",
      " Regression with ARIMA(0,0,1) errors : -11711.37\n",
      " Regression with ARIMA(0,0,0) errors : -8482.428\n",
      " Regression with ARIMA(1,0,2) errors : -13500.44\n",
      " Regression with ARIMA(2,0,1) errors : -13506.21\n",
      " Regression with ARIMA(1,0,1) errors : -13501.67\n",
      " Regression with ARIMA(2,0,0) errors : -13507.48\n",
      " Regression with ARIMA(3,0,0) errors : -13505.43\n",
      " Regression with ARIMA(3,0,1) errors : -13508.06\n",
      " Regression with ARIMA(4,0,1) errors : -13504.51\n",
      " Regression with ARIMA(3,0,2) errors : -13507\n",
      " Regression with ARIMA(4,0,0) errors : -13503.26\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -13503.39\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13511.77\n",
      " Regression with ARIMA(0,0,0) errors : -10089.38\n",
      " Regression with ARIMA(1,0,0) errors : -13508.45\n",
      " Regression with ARIMA(0,0,1) errors : -11717.82\n",
      " Regression with ARIMA(0,0,0) errors : -8486.146\n",
      " Regression with ARIMA(1,0,2) errors : -13508.73\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13508.14\n",
      " Regression with ARIMA(2,0,3) errors : -13509.84\n",
      " Regression with ARIMA(1,0,1) errors : -13509.99\n",
      " Regression with ARIMA(1,0,3) errors : -13507.09\n",
      " Regression with ARIMA(3,0,1) errors : -13509.92\n",
      " Regression with ARIMA(3,0,3) errors : -13517.49\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13519.73\n",
      " Regression with ARIMA(2,0,4) errors : -13513.32\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13514.28\n",
      " Regression with ARIMA(4,0,5) errors : -13514.96\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13520.01\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13510.51\n",
      " Regression with ARIMA(0,0,0) errors : -10105.18\n",
      " Regression with ARIMA(1,0,0) errors : -13507.88\n",
      " Regression with ARIMA(0,0,1) errors : -11721.86\n",
      " Regression with ARIMA(0,0,0) errors : -8493.114\n",
      " Regression with ARIMA(1,0,2) errors : -13508.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13516.56\n",
      " Regression with ARIMA(3,0,1) errors : -13506.85\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13515.63\n",
      " Regression with ARIMA(2,0,3) errors : -13508.55\n",
      " Regression with ARIMA(4,0,1) errors : -13509.07\n",
      " Regression with ARIMA(4,0,3) errors : -13513.32\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13519.6\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13508.31\n",
      " Regression with ARIMA(0,0,0) errors : -10126.55\n",
      " Regression with ARIMA(1,0,0) errors : -13507.44\n",
      " Regression with ARIMA(0,0,1) errors : -11732.75\n",
      " Regression with ARIMA(0,0,0) errors : -8479.726\n",
      " Regression with ARIMA(1,0,2) errors : -13507.67\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13508.26\n",
      " Regression with ARIMA(2,0,3) errors : -13506.52\n",
      " Regression with ARIMA(1,0,1) errors : -13508.92\n",
      " Regression with ARIMA(0,0,2) errors : -12538.44\n",
      " Regression with ARIMA(2,0,0) errors : -13508.97\n",
      " Regression with ARIMA(3,0,0) errors : -13506.81\n",
      " Regression with ARIMA(3,0,1) errors : -13510.29\n",
      " Regression with ARIMA(4,0,1) errors : -13507.38\n",
      " Regression with ARIMA(4,0,0) errors : -13504.51\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -13510.44\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10215.23\n",
      " Regression with ARIMA(1,0,0) errors : -13503.24\n",
      " Regression with ARIMA(0,0,1) errors : -11765.85\n",
      " Regression with ARIMA(0,0,0) errors : -8496.584\n",
      " Regression with ARIMA(2,0,0) errors : -13503.84\n",
      " Regression with ARIMA(3,0,0) errors : -13502.9\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13504.35\n",
      " Regression with ARIMA(1,0,2) errors : -13503.03\n",
      " Regression with ARIMA(0,0,2) errors : -12548.3\n",
      " Regression with ARIMA(1,0,1) errors : -13380.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13503.51\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10218.34\n",
      " Regression with ARIMA(1,0,0) errors : -13503.41\n",
      " Regression with ARIMA(0,0,1) errors : -11768.16\n",
      " Regression with ARIMA(0,0,0) errors : -8499.03\n",
      " Regression with ARIMA(2,0,0) errors : -13503.77\n",
      " Regression with ARIMA(3,0,0) errors : -13502.7\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13504.25\n",
      " Regression with ARIMA(1,0,2) errors : -13502.87\n",
      " Regression with ARIMA(0,0,2) errors : -12542.4\n",
      " Regression with ARIMA(1,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13503.42\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13509.32\n",
      " Regression with ARIMA(0,0,0) errors : -10219.25\n",
      " Regression with ARIMA(1,0,0) errors : -13507.76\n",
      " Regression with ARIMA(0,0,1) errors : -11765.04\n",
      " Regression with ARIMA(0,0,0) errors : -8502.109\n",
      " Regression with ARIMA(1,0,2) errors : -13506.99\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13502.83\n",
      " Regression with ARIMA(2,0,3) errors : -13507.36\n",
      " Regression with ARIMA(1,0,1) errors : -13508.29\n",
      " Regression with ARIMA(1,0,3) errors : -13505.45\n",
      " Regression with ARIMA(3,0,1) errors : -13506.88\n",
      " Regression with ARIMA(3,0,3) errors : -13513.93\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13514.85\n",
      " Regression with ARIMA(2,0,4) errors : -13509.02\n",
      " Regression with ARIMA(4,0,4) errors : -13512.96\n",
      " Regression with ARIMA(3,0,5) errors : -13508.01\n",
      " Regression with ARIMA(2,0,5) errors : -13510.83\n",
      " Regression with ARIMA(4,0,5) errors : -13505.08\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13517.28\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10222.58\n",
      " Regression with ARIMA(1,0,0) errors : -13506.49\n",
      " Regression with ARIMA(0,0,1) errors : -11761.77\n",
      " Regression with ARIMA(0,0,0) errors : -8501.931\n",
      " Regression with ARIMA(2,0,0) errors : -13505.83\n",
      " Regression with ARIMA(1,0,1) errors : -13506.71\n",
      " Regression with ARIMA(2,0,1) errors : -13516.88\n",
      " Regression with ARIMA(3,0,1) errors : -13512.26\n",
      " Regression with ARIMA(1,0,2) errors : -13505.56\n",
      " Regression with ARIMA(3,0,0) errors : -13505.02\n",
      " Regression with ARIMA(3,0,2) errors : -13499.27\n",
      " Regression with ARIMA(2,0,1) errors : -13367.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13503.41\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13512.51\n",
      " Regression with ARIMA(0,0,0) errors : -10227.27\n",
      " Regression with ARIMA(1,0,0) errors : -13513.98\n",
      " Regression with ARIMA(0,0,1) errors : -11762.97\n",
      " Regression with ARIMA(0,0,0) errors : -8502.27\n",
      " Regression with ARIMA(2,0,0) errors : -13514.25\n",
      " Regression with ARIMA(3,0,0) errors : -13513.04\n",
      " Regression with ARIMA(2,0,1) errors : -13512.24\n",
      " Regression with ARIMA(1,0,1) errors : -13514.02\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -13380.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,0) errors : -13511.98\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13526.34\n",
      " Regression with ARIMA(0,0,0) errors : -10223.66\n",
      " Regression with ARIMA(1,0,0) errors : -13526.45\n",
      " Regression with ARIMA(0,0,1) errors : -11757.01\n",
      " Regression with ARIMA(0,0,0) errors : -8519.276\n",
      " Regression with ARIMA(2,0,0) errors : -13525.32\n",
      " Regression with ARIMA(1,0,1) errors : -13526.23\n",
      " Regression with ARIMA(2,0,1) errors : -13535.26\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13525.01\n",
      " Regression with ARIMA(3,0,0) errors : -13523.41\n",
      " Regression with ARIMA(3,0,2) errors : -13520.69\n",
      " Regression with ARIMA(2,0,1) errors : -13408.03\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13521.31\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10227.11\n",
      " Regression with ARIMA(1,0,0) errors : -13535.83\n",
      " Regression with ARIMA(0,0,1) errors : -11776.31\n",
      " Regression with ARIMA(0,0,0) errors : -8558.409\n",
      " Regression with ARIMA(2,0,0) errors : -13535.04\n",
      " Regression with ARIMA(1,0,1) errors : -13535.63\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13535.07\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10239.17\n",
      " Regression with ARIMA(1,0,0) errors : -13532.83\n",
      " Regression with ARIMA(0,0,1) errors : -11782.72\n",
      " Regression with ARIMA(0,0,0) errors : -8566.374\n",
      " Regression with ARIMA(2,0,0) errors : -13533.02\n",
      " Regression with ARIMA(3,0,0) errors : -13531.58\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13532.77\n",
      " Regression with ARIMA(3,0,1) errors : -13532.73\n",
      " Regression with ARIMA(2,0,0) errors : -13415.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,0) errors : -13531.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13539.55\n",
      " Regression with ARIMA(0,0,0) errors : -10238.93\n",
      " Regression with ARIMA(1,0,0) errors : -13540.07\n",
      " Regression with ARIMA(0,0,1) errors : -11784.97\n",
      " Regression with ARIMA(0,0,0) errors : -8571.174\n",
      " Regression with ARIMA(2,0,0) errors : -13539.5\n",
      " Regression with ARIMA(1,0,1) errors : -13540.16\n",
      " Regression with ARIMA(2,0,1) errors : -13549.2\n",
      " Regression with ARIMA(3,0,1) errors : -13539.61\n",
      " Regression with ARIMA(1,0,2) errors : -13539.06\n",
      " Regression with ARIMA(3,0,0) errors : -13537.64\n",
      " Regression with ARIMA(3,0,2) errors : -13537.96\n",
      " Regression with ARIMA(2,0,1) errors : -13400.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13550.1\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13537.09\n",
      " Regression with ARIMA(0,0,0) errors : -10239.99\n",
      " Regression with ARIMA(1,0,0) errors : -13540.98\n",
      " Regression with ARIMA(0,0,1) errors : -11788.21\n",
      " Regression with ARIMA(0,0,0) errors : -8584.355\n",
      " Regression with ARIMA(2,0,0) errors : -13540.68\n",
      " Regression with ARIMA(1,0,1) errors : -13540.96\n",
      " Regression with ARIMA(2,0,1) errors : -13550.79\n",
      " Regression with ARIMA(3,0,1) errors : -13544.63\n",
      " Regression with ARIMA(1,0,2) errors : -13539.89\n",
      " Regression with ARIMA(3,0,0) errors : -13538.95\n",
      " Regression with ARIMA(3,0,2) errors : -13543.48\n",
      " Regression with ARIMA(2,0,1) errors : -13423.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : -13541.93\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13563.2\n",
      " Regression with ARIMA(0,0,0) errors : -10221.42\n",
      " Regression with ARIMA(1,0,0) errors : -13558.89\n",
      " Regression with ARIMA(0,0,1) errors : -11783.59\n",
      " Regression with ARIMA(0,0,0) errors : -8587.344\n",
      " Regression with ARIMA(1,0,2) errors : -13557.75\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13560.36\n",
      " Regression with ARIMA(2,0,3) errors : -13561.2\n",
      " Regression with ARIMA(1,0,1) errors : -13558.83\n",
      " Regression with ARIMA(1,0,3) errors : -13556.36\n",
      " Regression with ARIMA(3,0,1) errors : -13562.66\n",
      " Regression with ARIMA(3,0,3) errors : -13569.83\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13571.17\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -13563.95\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13566.38\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13567.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13570.4\n",
      " Regression with ARIMA(0,0,0) errors : -10190.39\n",
      " Regression with ARIMA(1,0,0) errors : -13568.75\n",
      " Regression with ARIMA(0,0,1) errors : -11771.15\n",
      " Regression with ARIMA(0,0,0) errors : -8593.643\n",
      " Regression with ARIMA(1,0,2) errors : -13567.8\n",
      " Regression with ARIMA(2,0,1) errors : -13578.25\n",
      " Regression with ARIMA(1,0,1) errors : -13568.87\n",
      " Regression with ARIMA(2,0,0) errors : -13567.98\n",
      " Regression with ARIMA(3,0,1) errors : -13566.18\n",
      " Regression with ARIMA(3,0,0) errors : -13566.18\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : -13449.02\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13568.25\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13634.9\n",
      " Regression with ARIMA(0,0,0) errors : -10190.23\n",
      " Regression with ARIMA(1,0,0) errors : -13630.94\n",
      " Regression with ARIMA(0,0,1) errors : -11790.6\n",
      " Regression with ARIMA(0,0,0) errors : -8611.59\n",
      " Regression with ARIMA(1,0,2) errors : -13631.17\n",
      " Regression with ARIMA(2,0,1) errors : -13641.72\n",
      " Regression with ARIMA(1,0,1) errors : -13631.97\n",
      " Regression with ARIMA(2,0,0) errors : -13632.33\n",
      " Regression with ARIMA(3,0,1) errors : -13630.61\n",
      " Regression with ARIMA(3,0,0) errors : -13630.85\n",
      " Regression with ARIMA(3,0,2) errors : -13642.1\n",
      " Regression with ARIMA(4,0,2) errors : -13636.63\n",
      " Regression with ARIMA(3,0,3) errors : -13640.47\n",
      " Regression with ARIMA(2,0,3) errors : -13632.93\n",
      " Regression with ARIMA(4,0,1) errors : -13631.33\n",
      " Regression with ARIMA(4,0,3) errors : -13636.07\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13640.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13645.23\n",
      " Regression with ARIMA(0,0,0) errors : -10202.47\n",
      " Regression with ARIMA(1,0,0) errors : -13645.74\n",
      " Regression with ARIMA(0,0,1) errors : -11804.3\n",
      " Regression with ARIMA(0,0,0) errors : -8622.517\n",
      " Regression with ARIMA(2,0,0) errors : -13646.54\n",
      " Regression with ARIMA(3,0,0) errors : -13646.95\n",
      " Regression with ARIMA(4,0,0) errors : -13644.57\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -13646.54\n",
      " Regression with ARIMA(3,0,0) errors : -13536.11\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,0) errors : -13645.14\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13662.78\n",
      " Regression with ARIMA(0,0,0) errors : -10203.12\n",
      " Regression with ARIMA(1,0,0) errors : -13661.7\n",
      " Regression with ARIMA(0,0,1) errors : -11801.53\n",
      " Regression with ARIMA(0,0,0) errors : -8623.09\n",
      " Regression with ARIMA(1,0,2) errors : -13661.65\n",
      " Regression with ARIMA(2,0,1) errors : -13670.27\n",
      " Regression with ARIMA(1,0,1) errors : -13662.54\n",
      " Regression with ARIMA(2,0,0) errors : -13662.03\n",
      " Regression with ARIMA(3,0,1) errors : -13660.85\n",
      " Regression with ARIMA(3,0,0) errors : -13660.75\n",
      " Regression with ARIMA(3,0,2) errors : -13668.59\n",
      " Regression with ARIMA(2,0,1) errors : -13554.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13669.89\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13665.71\n",
      " Regression with ARIMA(0,0,0) errors : -10188.87\n",
      " Regression with ARIMA(1,0,0) errors : -13663.7\n",
      " Regression with ARIMA(0,0,1) errors : -11795.42\n",
      " Regression with ARIMA(0,0,0) errors : -8643.892\n",
      " Regression with ARIMA(1,0,2) errors : -13663.8\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13660.35\n",
      " Regression with ARIMA(2,0,3) errors : -13663.69\n",
      " Regression with ARIMA(1,0,1) errors : -13664.64\n",
      " Regression with ARIMA(1,0,3) errors : -13662.17\n",
      " Regression with ARIMA(3,0,1) errors : -13664.67\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13565.22\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13665.83\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13656.64\n",
      " Regression with ARIMA(0,0,0) errors : -10191.97\n",
      " Regression with ARIMA(1,0,0) errors : -13653.06\n",
      " Regression with ARIMA(0,0,1) errors : -11788.05\n",
      " Regression with ARIMA(0,0,0) errors : -8651.602\n",
      " Regression with ARIMA(1,0,2) errors : -13653.54\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13653.21\n",
      " Regression with ARIMA(2,0,3) errors : -13654.62\n",
      " Regression with ARIMA(1,0,1) errors : -13654.33\n",
      " Regression with ARIMA(1,0,3) errors : -13651.95\n",
      " Regression with ARIMA(3,0,1) errors : -13655.42\n",
      " Regression with ARIMA(3,0,3) errors : -13661.07\n",
      " Regression with ARIMA(4,0,3) errors : -13648.86\n",
      " Regression with ARIMA(3,0,4) errors : -13662.96\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13661.06\n",
      " Regression with ARIMA(4,0,5) errors : -13659.57\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13659.73\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13649.41\n",
      " Regression with ARIMA(0,0,0) errors : -10167.99\n",
      " Regression with ARIMA(1,0,0) errors : -13648.99\n",
      " Regression with ARIMA(0,0,1) errors : -11774.26\n",
      " Regression with ARIMA(0,0,0) errors : -8653.868\n",
      " Regression with ARIMA(1,0,2) errors : -13649.56\n",
      " Regression with ARIMA(0,0,2) errors : -12612.9\n",
      " Regression with ARIMA(1,0,1) errors : -13650.24\n",
      " Regression with ARIMA(2,0,1) errors : -13660.4\n",
      " Regression with ARIMA(2,0,0) errors : -13649.71\n",
      " Regression with ARIMA(3,0,1) errors : -13651.41\n",
      " Regression with ARIMA(3,0,0) errors : -13648.4\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13661.18\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13655.63\n",
      " Regression with ARIMA(0,0,0) errors : -10165.57\n",
      " Regression with ARIMA(1,0,0) errors : -13654.18\n",
      " Regression with ARIMA(0,0,1) errors : -11773.14\n",
      " Regression with ARIMA(0,0,0) errors : -8656.522\n",
      " Regression with ARIMA(1,0,2) errors : -13654.42\n",
      " Regression with ARIMA(2,0,1) errors : -13665.49\n",
      " Regression with ARIMA(1,0,1) errors : -13655.18\n",
      " Regression with ARIMA(2,0,0) errors : -13654.5\n",
      " Regression with ARIMA(3,0,1) errors : -13655.23\n",
      " Regression with ARIMA(3,0,0) errors : -13653.04\n",
      " Regression with ARIMA(3,0,2) errors : -13653.31\n",
      " Regression with ARIMA(2,0,1) errors : -13554.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13666.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13657.3\n",
      " Regression with ARIMA(0,0,0) errors : -10165.83\n",
      " Regression with ARIMA(1,0,0) errors : -13655.15\n",
      " Regression with ARIMA(0,0,1) errors : -11771.76\n",
      " Regression with ARIMA(0,0,0) errors : -8655.923\n",
      " Regression with ARIMA(1,0,2) errors : -13655.23\n",
      " Regression with ARIMA(2,0,1) errors : -13667.08\n",
      " Regression with ARIMA(1,0,1) errors : -13656.02\n",
      " Regression with ARIMA(2,0,0) errors : -13655.19\n",
      " Regression with ARIMA(3,0,1) errors : -13655.86\n",
      " Regression with ARIMA(3,0,0) errors : -13658.04\n",
      " Regression with ARIMA(3,0,2) errors : -13655.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13666.52\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13655.6\n",
      " Regression with ARIMA(0,0,0) errors : -10159.47\n",
      " Regression with ARIMA(1,0,0) errors : -13654.74\n",
      " Regression with ARIMA(0,0,1) errors : -11765.48\n",
      " Regression with ARIMA(0,0,0) errors : -8662.39\n",
      " Regression with ARIMA(1,0,2) errors : -13655.14\n",
      " Regression with ARIMA(2,0,1) errors : -13671.56\n",
      " Regression with ARIMA(1,0,1) errors : -13655.72\n",
      " Regression with ARIMA(2,0,0) errors : -13656.86\n",
      " Regression with ARIMA(3,0,1) errors : -13656.12\n",
      " Regression with ARIMA(3,0,0) errors : -13655.95\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13665.81\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13656.79\n",
      " Regression with ARIMA(0,0,0) errors : -10173.96\n",
      " Regression with ARIMA(1,0,0) errors : -13652.05\n",
      " Regression with ARIMA(0,0,1) errors : -11777.5\n",
      " Regression with ARIMA(0,0,0) errors : -8700.468\n",
      " Regression with ARIMA(1,0,2) errors : -13652.23\n",
      " Regression with ARIMA(2,0,1) errors : -13668.02\n",
      " Regression with ARIMA(1,0,1) errors : -13652.1\n",
      " Regression with ARIMA(2,0,0) errors : -13652.19\n",
      " Regression with ARIMA(3,0,1) errors : -13656.11\n",
      " Regression with ARIMA(3,0,0) errors : -13652.01\n",
      " Regression with ARIMA(3,0,2) errors : -13662.39\n",
      " Regression with ARIMA(2,0,1) errors : -13548.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13662.69\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13625.68\n",
      " Regression with ARIMA(0,1,0) errors : -13621.46\n",
      " Regression with ARIMA(1,1,0) errors : -13624.34\n",
      " Regression with ARIMA(0,1,1) errors : -13619.6\n",
      " Regression with ARIMA(0,1,0) errors : -13623.47\n",
      " Regression with ARIMA(1,1,2) errors : -13629.17\n",
      " Regression with ARIMA(0,1,2) errors : -13617.77\n",
      " Regression with ARIMA(1,1,1) errors : -13628.01\n",
      " Regression with ARIMA(1,1,3) errors : -13633.78\n",
      " Regression with ARIMA(0,1,3) errors : -13616.46\n",
      " Regression with ARIMA(2,1,3) errors : -13627.37\n",
      " Regression with ARIMA(1,1,4) errors : -13638.05\n",
      " Regression with ARIMA(0,1,4) errors : -13614.88\n",
      " Regression with ARIMA(2,1,4) errors : -13627.68\n",
      " Regression with ARIMA(1,1,5) errors : -13657.04\n",
      " Regression with ARIMA(0,1,5) errors : -13617.4\n",
      " Regression with ARIMA(2,1,5) errors : -13647.25\n",
      " Regression with ARIMA(1,1,5) errors : -13658.92\n",
      " Regression with ARIMA(0,1,5) errors : -13619.42\n",
      " Regression with ARIMA(1,1,4) errors : -13639.93\n",
      " Regression with ARIMA(2,1,5) errors : -13649.14\n",
      " Regression with ARIMA(0,1,4) errors : -13616.89\n",
      " Regression with ARIMA(2,1,4) errors : -13629.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,0) errors : -13628.45\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13669.46\n",
      " Regression with ARIMA(0,1,0) errors : -13667.96\n",
      " Regression with ARIMA(1,1,0) errors : -13665.88\n",
      " Regression with ARIMA(0,1,1) errors : -13666.47\n",
      " Regression with ARIMA(0,1,0) errors : -13669.95\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13678.82\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10272.74\n",
      " Regression with ARIMA(1,0,0) errors : -13772.01\n",
      " Regression with ARIMA(0,0,1) errors : -11891.74\n",
      " Regression with ARIMA(0,0,0) errors : -8843.671\n",
      " Regression with ARIMA(2,0,0) errors : -13770.9\n",
      " Regression with ARIMA(1,0,1) errors : -13771.44\n",
      " Regression with ARIMA(2,0,1) errors : -13785.75\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13772.19\n",
      " Regression with ARIMA(3,0,0) errors : -13772.31\n",
      " Regression with ARIMA(3,0,2) errors : -13785.11\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13783.28\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13764.52\n",
      " Regression with ARIMA(0,0,0) errors : -10268.04\n",
      " Regression with ARIMA(1,0,0) errors : -13761.23\n",
      " Regression with ARIMA(0,0,1) errors : -11885.1\n",
      " Regression with ARIMA(0,0,0) errors : -8858.715\n",
      " Regression with ARIMA(1,0,2) errors : -13761.55\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13782.76\n",
      " Regression with ARIMA(3,0,1) errors : -13780.45\n",
      " Regression with ARIMA(4,0,2) errors : -13778.02\n",
      " Regression with ARIMA(3,0,3) errors : -13780.93\n",
      " Regression with ARIMA(2,0,3) errors : -13762.9\n",
      " Regression with ARIMA(4,0,1) errors : -13774.34\n",
      " Regression with ARIMA(4,0,3) errors : -13775.95\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13775.78\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13769.81\n",
      " Regression with ARIMA(0,0,0) errors : -10265.3\n",
      " Regression with ARIMA(1,0,0) errors : -13762.85\n",
      " Regression with ARIMA(0,0,1) errors : -11881.84\n",
      " Regression with ARIMA(0,0,0) errors : -8821.143\n",
      " Regression with ARIMA(1,0,2) errors : -13762.57\n",
      " Regression with ARIMA(2,0,1) errors : -13768.3\n",
      " Regression with ARIMA(3,0,2) errors : -13783.22\n",
      " Regression with ARIMA(3,0,1) errors : -13768.49\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13781.28\n",
      " Regression with ARIMA(2,0,3) errors : -13768.18\n",
      " Regression with ARIMA(4,0,1) errors : -13769.2\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13777.69\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13769.38\n",
      " Regression with ARIMA(0,0,0) errors : -10260.46\n",
      " Regression with ARIMA(1,0,0) errors : -13763.75\n",
      " Regression with ARIMA(0,0,1) errors : -11877.06\n",
      " Regression with ARIMA(0,0,0) errors : -8820.979\n",
      " Regression with ARIMA(1,0,2) errors : -13763.9\n",
      " Regression with ARIMA(2,0,1) errors : -13767.21\n",
      " Regression with ARIMA(3,0,2) errors : -13781.12\n",
      " Regression with ARIMA(3,0,1) errors : -13768.51\n",
      " Regression with ARIMA(4,0,2) errors : -13781.64\n",
      " Regression with ARIMA(4,0,1) errors : -13767.06\n",
      " Regression with ARIMA(5,0,2) errors : -13779.5\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13781.37\n",
      " Regression with ARIMA(5,0,1) errors : -13775.92\n",
      " Regression with ARIMA(5,0,3) errors : -13777.89\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,2) errors : -13774.84\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13730.6\n",
      " Regression with ARIMA(0,0,0) errors : -10252.14\n",
      " Regression with ARIMA(1,0,0) errors : -13734.15\n",
      " Regression with ARIMA(0,0,1) errors : -11865.14\n",
      " Regression with ARIMA(0,0,0) errors : -8811.741\n",
      " Regression with ARIMA(2,0,0) errors : -13732.86\n",
      " Regression with ARIMA(1,0,1) errors : -13733.55\n",
      " Regression with ARIMA(2,0,1) errors : -13745.03\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13733.84\n",
      " Regression with ARIMA(3,0,0) errors : -13732.77\n",
      " Regression with ARIMA(3,0,2) errors : -13730.31\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13733.34\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10248.64\n",
      " Regression with ARIMA(1,0,0) errors : -13726.11\n",
      " Regression with ARIMA(0,0,1) errors : -11859.38\n",
      " Regression with ARIMA(0,0,0) errors : -8814.75\n",
      " Regression with ARIMA(2,0,0) errors : -13726.2\n",
      " Regression with ARIMA(3,0,0) errors : -13726.52\n",
      " Regression with ARIMA(4,0,0) errors : -13725.54\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : -13736.42\n",
      " Regression with ARIMA(1,0,1) errors : -13725.25\n",
      " Regression with ARIMA(1,0,2) errors : -13725.96\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,0) errors : -13725.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10253.6\n",
      " Regression with ARIMA(1,0,0) errors : -13735.62\n",
      " Regression with ARIMA(0,0,1) errors : -11865.12\n",
      " Regression with ARIMA(0,0,0) errors : -8816.856\n",
      " Regression with ARIMA(2,0,0) errors : -13733.87\n",
      " Regression with ARIMA(1,0,1) errors : -13734.66\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13733.14\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13750.01\n",
      " Regression with ARIMA(0,0,0) errors : -10257.06\n",
      " Regression with ARIMA(1,0,0) errors : -13738.28\n",
      " Regression with ARIMA(0,0,1) errors : -11865.9\n",
      " Regression with ARIMA(0,0,0) errors : -8780.029\n",
      " Regression with ARIMA(1,0,2) errors : -13737.34\n",
      " Regression with ARIMA(2,0,1) errors : -13751.1\n",
      " Regression with ARIMA(1,0,1) errors : -13737.18\n",
      " Regression with ARIMA(2,0,0) errors : -13736.6\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,0) errors : -13736.27\n",
      " Regression with ARIMA(3,0,2) errors : -13732.63\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13735.84\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10256.83\n",
      " Regression with ARIMA(1,0,0) errors : -13730.95\n",
      " Regression with ARIMA(0,0,1) errors : -11861.77\n",
      " Regression with ARIMA(0,0,0) errors : -8779.258\n",
      " Regression with ARIMA(2,0,0) errors : -13729.15\n",
      " Regression with ARIMA(1,0,1) errors : -13729.46\n",
      " Regression with ARIMA(2,0,1) errors : -13743.66\n",
      " Regression with ARIMA(3,0,1) errors : -13740.11\n",
      " Regression with ARIMA(1,0,2) errors : -13729.66\n",
      " Regression with ARIMA(3,0,0) errors : -13731.65\n",
      " Regression with ARIMA(3,0,2) errors : -13742.18\n",
      " Regression with ARIMA(2,0,1) errors : -13618.71\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13744.27\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13704.92\n",
      " Regression with ARIMA(0,0,0) errors : -10273.67\n",
      " Regression with ARIMA(1,0,0) errors : -13706.69\n",
      " Regression with ARIMA(0,0,1) errors : -11878.39\n",
      " Regression with ARIMA(0,0,0) errors : -8797.955\n",
      " Regression with ARIMA(2,0,0) errors : -13704.19\n",
      " Regression with ARIMA(1,0,1) errors : -13704.98\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13577.35\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13704.77\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13513.55\n",
      " Regression with ARIMA(0,0,0) errors : -10068.34\n",
      " Regression with ARIMA(1,0,0) errors : -13520.38\n",
      " Regression with ARIMA(0,0,1) errors : -11654.6\n",
      " Regression with ARIMA(0,0,0) errors : -8614.487\n",
      " Regression with ARIMA(2,0,0) errors : -13517.43\n",
      " Regression with ARIMA(1,0,1) errors : -13518.38\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13517.53\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12970.83\n",
      " Regression with ARIMA(0,1,0) errors : -12930.49\n",
      " Regression with ARIMA(1,1,0) errors : -12945.11\n",
      " Regression with ARIMA(0,1,1) errors : -12947.22\n",
      " Regression with ARIMA(0,1,0) errors : -12932.5\n",
      " Regression with ARIMA(1,1,2) errors : -12962.91\n",
      " Regression with ARIMA(2,1,1) errors : -12971.71\n",
      " Regression with ARIMA(1,1,1) errors : -12955.51\n",
      " Regression with ARIMA(2,1,0) errors : -12969.84\n",
      " Regression with ARIMA(3,1,1) errors : -12974.24\n",
      " Regression with ARIMA(3,1,0) errors : -12974.64\n",
      " Regression with ARIMA(4,1,0) errors : -12978.76\n",
      " Regression with ARIMA(5,1,0) errors : -12976.29\n",
      " Regression with ARIMA(4,1,1) errors : -12976.71\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,0) errors : -12980.76\n",
      " Regression with ARIMA(3,1,0) errors : -12976.65\n",
      " Regression with ARIMA(5,1,0) errors : -12978.28\n",
      " Regression with ARIMA(4,1,1) errors : -12978.77\n",
      " Regression with ARIMA(3,1,1) errors : -12976.24\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,1,0) errors : -12980.2\n",
      "\n",
      " Best model: Regression with ARIMA(4,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12722.08\n",
      " Regression with ARIMA(0,1,0) errors : -12682.87\n",
      " Regression with ARIMA(1,1,0) errors : -12702.85\n",
      " Regression with ARIMA(0,1,1) errors : -12708.6\n",
      " Regression with ARIMA(0,1,0) errors : -12684.84\n",
      " Regression with ARIMA(1,1,2) errors : -12720.75\n",
      " Regression with ARIMA(2,1,1) errors : -12722.99\n",
      " Regression with ARIMA(1,1,1) errors : -12711.35\n",
      " Regression with ARIMA(2,1,0) errors : -12720.41\n",
      " Regression with ARIMA(3,1,1) errors : -12722.13\n",
      " Regression with ARIMA(3,1,0) errors : -12724.07\n",
      " Regression with ARIMA(4,1,0) errors : -12721.18\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -12726.05\n",
      " Regression with ARIMA(2,1,0) errors : -12722.38\n",
      " Regression with ARIMA(4,1,0) errors : -12723.17\n",
      " Regression with ARIMA(3,1,1) errors : -12724.11\n",
      " Regression with ARIMA(2,1,1) errors : -12724.96\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,0) errors : -12736.42\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12560.78\n",
      " Regression with ARIMA(0,1,0) errors : -12505.96\n",
      " Regression with ARIMA(1,1,0) errors : -12527.34\n",
      " Regression with ARIMA(0,1,1) errors : -12533.58\n",
      " Regression with ARIMA(0,1,0) errors : -12507.97\n",
      " Regression with ARIMA(1,1,2) errors : -12551.89\n",
      " Regression with ARIMA(2,1,1) errors : -12557.49\n",
      " Regression with ARIMA(3,1,2) errors : -12557.93\n",
      " Regression with ARIMA(2,1,3) errors : -12558.92\n",
      " Regression with ARIMA(1,1,1) errors : -12537.48\n",
      " Regression with ARIMA(1,1,3) errors : -12554.56\n",
      " Regression with ARIMA(3,1,1) errors : -12557.55\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12562.8\n",
      " Regression with ARIMA(1,1,2) errors : -12553.91\n",
      " Regression with ARIMA(2,1,1) errors : -12559.5\n",
      " Regression with ARIMA(3,1,2) errors : -12559.9\n",
      " Regression with ARIMA(2,1,3) errors : -12560.93\n",
      " Regression with ARIMA(1,1,1) errors : -12539.48\n",
      " Regression with ARIMA(1,1,3) errors : -12556.58\n",
      " Regression with ARIMA(3,1,1) errors : -12559.56\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12572.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12525.75\n",
      " Regression with ARIMA(0,1,0) errors : -12472.26\n",
      " Regression with ARIMA(1,1,0) errors : -12494.36\n",
      " Regression with ARIMA(0,1,1) errors : -12499.92\n",
      " Regression with ARIMA(0,1,0) errors : -12474.27\n",
      " Regression with ARIMA(1,1,2) errors : -12516.93\n",
      " Regression with ARIMA(2,1,1) errors : -12522.47\n",
      " Regression with ARIMA(3,1,2) errors : -12522.7\n",
      " Regression with ARIMA(2,1,3) errors : -12523.75\n",
      " Regression with ARIMA(1,1,1) errors : -12502.95\n",
      " Regression with ARIMA(1,1,3) errors : -12520.19\n",
      " Regression with ARIMA(3,1,1) errors : -12522.74\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12527.77\n",
      " Regression with ARIMA(1,1,2) errors : -12518.94\n",
      " Regression with ARIMA(2,1,1) errors : -12524.48\n",
      " Regression with ARIMA(3,1,2) errors : -12524.7\n",
      " Regression with ARIMA(2,1,3) errors : -12525.77\n",
      " Regression with ARIMA(1,1,1) errors : -12504.95\n",
      " Regression with ARIMA(1,1,3) errors : -12522.21\n",
      " Regression with ARIMA(3,1,1) errors : -12524.75\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12537.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12470.37\n",
      " Regression with ARIMA(0,1,0) errors : -12414.35\n",
      " Regression with ARIMA(1,1,0) errors : -12436.58\n",
      " Regression with ARIMA(0,1,1) errors : -12443.12\n",
      " Regression with ARIMA(0,1,0) errors : -12416.35\n",
      " Regression with ARIMA(1,1,2) errors : -12461.95\n",
      " Regression with ARIMA(2,1,1) errors : -12468.01\n",
      " Regression with ARIMA(3,1,2) errors : -12467.45\n",
      " Regression with ARIMA(2,1,3) errors : -12468.34\n",
      " Regression with ARIMA(1,1,1) errors : -12445.63\n",
      " Regression with ARIMA(1,1,3) errors : -12464.82\n",
      " Regression with ARIMA(3,1,1) errors : -12468.7\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12472.37\n",
      " Regression with ARIMA(1,1,2) errors : -12463.95\n",
      " Regression with ARIMA(2,1,1) errors : -12470\n",
      " Regression with ARIMA(3,1,2) errors : -12469.45\n",
      " Regression with ARIMA(2,1,3) errors : -12470.36\n",
      " Regression with ARIMA(1,1,1) errors : -12447.62\n",
      " Regression with ARIMA(1,1,3) errors : -12466.82\n",
      " Regression with ARIMA(3,1,1) errors : -12470.69\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12481.51\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12415.46\n",
      " Regression with ARIMA(0,1,0) errors : -12357.7\n",
      " Regression with ARIMA(1,1,0) errors : -12377.73\n",
      " Regression with ARIMA(0,1,1) errors : -12382.8\n",
      " Regression with ARIMA(0,1,0) errors : -12359.71\n",
      " Regression with ARIMA(1,1,2) errors : -12397.26\n",
      " Regression with ARIMA(2,1,1) errors : -12405.48\n",
      " Regression with ARIMA(3,1,2) errors : -12413.51\n",
      " Regression with ARIMA(2,1,3) errors : -12414.64\n",
      " Regression with ARIMA(1,1,1) errors : -12383.72\n",
      " Regression with ARIMA(1,1,3) errors : -12404.76\n",
      " Regression with ARIMA(3,1,1) errors : -12410.9\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12417.47\n",
      " Regression with ARIMA(1,1,2) errors : -12399.27\n",
      " Regression with ARIMA(2,1,1) errors : -12407.49\n",
      " Regression with ARIMA(3,1,2) errors : -12415.52\n",
      " Regression with ARIMA(2,1,3) errors : -12416.65\n",
      " Regression with ARIMA(1,1,1) errors : -12385.73\n",
      " Regression with ARIMA(1,1,3) errors : -12406.78\n",
      " Regression with ARIMA(3,1,1) errors : -12412.92\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12422.35\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12392.88\n",
      " Regression with ARIMA(0,1,0) errors : -12334.96\n",
      " Regression with ARIMA(1,1,0) errors : -12358.48\n",
      " Regression with ARIMA(0,1,1) errors : -12364.77\n",
      " Regression with ARIMA(0,1,0) errors : -12336.95\n",
      " Regression with ARIMA(1,1,2) errors : -12380.24\n",
      " Regression with ARIMA(2,1,1) errors : -12390.33\n",
      " Regression with ARIMA(3,1,2) errors : -12392.56\n",
      " Regression with ARIMA(2,1,3) errors : -12390.88\n",
      " Regression with ARIMA(1,1,1) errors : -12366.94\n",
      " Regression with ARIMA(1,1,3) errors : -12386.73\n",
      " Regression with ARIMA(3,1,1) errors : -12394.33\n",
      " Regression with ARIMA(3,1,0) errors : -12396.28\n",
      " Regression with ARIMA(2,1,0) errors : -12381.04\n",
      " Regression with ARIMA(4,1,0) errors : -12409.24\n",
      " Regression with ARIMA(5,1,0) errors : -12418.87\n",
      " Regression with ARIMA(5,1,1) errors : -12429.22\n",
      " Regression with ARIMA(4,1,1) errors : -12408.98\n",
      " Regression with ARIMA(5,1,2) errors : -12419\n",
      " Regression with ARIMA(4,1,2) errors : -12415.77\n",
      " Regression with ARIMA(5,1,1) errors : -12431.1\n",
      " Regression with ARIMA(4,1,1) errors : -12410.99\n",
      " Regression with ARIMA(5,1,0) errors : -12420.89\n",
      " Regression with ARIMA(5,1,2) errors : -12421.01\n",
      " Regression with ARIMA(4,1,0) errors : -12411.25\n",
      " Regression with ARIMA(4,1,2) errors : -12417.78\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,0) errors : -12408.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12405.22\n",
      " Regression with ARIMA(0,1,0) errors : -12342.22\n",
      " Regression with ARIMA(1,1,0) errors : -12369.17\n",
      " Regression with ARIMA(0,1,1) errors : -12375.11\n",
      " Regression with ARIMA(0,1,0) errors : -12344.23\n",
      " Regression with ARIMA(1,1,2) errors : -12390.01\n",
      " Regression with ARIMA(2,1,1) errors : -12397.17\n",
      " Regression with ARIMA(3,1,2) errors : -12404.33\n",
      " Regression with ARIMA(2,1,3) errors : -12403.26\n",
      " Regression with ARIMA(1,1,1) errors : -12376.7\n",
      " Regression with ARIMA(1,1,3) errors : -12397.27\n",
      " Regression with ARIMA(3,1,1) errors : -12402.52\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12407.23\n",
      " Regression with ARIMA(1,1,2) errors : -12392.02\n",
      " Regression with ARIMA(2,1,1) errors : -12399.19\n",
      " Regression with ARIMA(3,1,2) errors : -12406.34\n",
      " Regression with ARIMA(2,1,3) errors : -12405.28\n",
      " Regression with ARIMA(1,1,1) errors : -12378.71\n",
      " Regression with ARIMA(1,1,3) errors : -12399.28\n",
      " Regression with ARIMA(3,1,1) errors : -12404.53\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12418.09\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12479.1\n",
      " Regression with ARIMA(0,0,0) errors : -8904.547\n",
      " Regression with ARIMA(1,0,0) errors : -12457.86\n",
      " Regression with ARIMA(0,0,1) errors : -10586.67\n",
      " Regression with ARIMA(0,0,0) errors : -7757.971\n",
      " Regression with ARIMA(1,0,2) errors : -12470.62\n",
      " Regression with ARIMA(2,0,1) errors : -12467.78\n",
      " Regression with ARIMA(3,0,2) errors : -12535.04\n",
      " Regression with ARIMA(3,0,1) errors : -12486.22\n",
      " Regression with ARIMA(4,0,2) errors : -12504.23\n",
      " Regression with ARIMA(3,0,3) errors : -12504.59\n",
      " Regression with ARIMA(2,0,3) errors : -12501.85\n",
      " Regression with ARIMA(4,0,1) errors : -12505.69\n",
      " Regression with ARIMA(4,0,3) errors : -12533.86\n",
      " Regression with ARIMA(3,0,2) errors : -12438.48\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12506.31\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12465.71\n",
      " Regression with ARIMA(0,0,0) errors : -8892.805\n",
      " Regression with ARIMA(1,0,0) errors : -12446.23\n",
      " Regression with ARIMA(0,0,1) errors : -10571.36\n",
      " Regression with ARIMA(0,0,0) errors : -7709.597\n",
      " Regression with ARIMA(1,0,2) errors : -12458.34\n",
      " Regression with ARIMA(2,0,1) errors : -12455.94\n",
      " Regression with ARIMA(3,0,2) errors : -12524.46\n",
      " Regression with ARIMA(3,0,1) errors : -12471.77\n",
      " Regression with ARIMA(4,0,2) errors : -12490.22\n",
      " Regression with ARIMA(3,0,3) errors : -12489.3\n",
      " Regression with ARIMA(2,0,3) errors : -12488.4\n",
      " Regression with ARIMA(4,0,1) errors : -12491.45\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12529.33\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12465.29\n",
      " Regression with ARIMA(0,0,0) errors : -8894.651\n",
      " Regression with ARIMA(1,0,0) errors : -12445.35\n",
      " Regression with ARIMA(0,0,1) errors : -10573.51\n",
      " Regression with ARIMA(0,0,0) errors : -7703.577\n",
      " Regression with ARIMA(1,0,2) errors : -12457.79\n",
      " Regression with ARIMA(2,0,1) errors : -12455.34\n",
      " Regression with ARIMA(3,0,2) errors : -12521.44\n",
      " Regression with ARIMA(3,0,1) errors : -12471.75\n",
      " Regression with ARIMA(4,0,2) errors : -12489.95\n",
      " Regression with ARIMA(3,0,3) errors : -12489.87\n",
      " Regression with ARIMA(2,0,3) errors : -12487.74\n",
      " Regression with ARIMA(4,0,1) errors : -12490.93\n",
      " Regression with ARIMA(4,0,3) errors : -12517.07\n",
      " Regression with ARIMA(3,0,2) errors : -12443.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12527.75\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12457.74\n",
      " Regression with ARIMA(0,0,0) errors : -8888.053\n",
      " Regression with ARIMA(1,0,0) errors : -12438.77\n",
      " Regression with ARIMA(0,0,1) errors : -10568.72\n",
      " Regression with ARIMA(0,0,0) errors : -7699.325\n",
      " Regression with ARIMA(1,0,2) errors : -12450.59\n",
      " Regression with ARIMA(2,0,1) errors : -12447.71\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12479.45\n",
      " Regression with ARIMA(1,0,3) errors : -12482.41\n",
      " Regression with ARIMA(0,0,3) errors : -11655.39\n",
      " Regression with ARIMA(1,0,4) errors : -12480.42\n",
      " Regression with ARIMA(0,0,2) errors : -11226.37\n",
      " Regression with ARIMA(0,0,4) errors : -11987.9\n",
      " Regression with ARIMA(2,0,4) errors : -12508.61\n",
      " Regression with ARIMA(3,0,4) errors : -12510.98\n",
      " Regression with ARIMA(3,0,3) errors : -12480.89\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12508.89\n",
      " Regression with ARIMA(2,0,5) errors : -12511.16\n",
      " Regression with ARIMA(1,0,5) errors : -12481.3\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12511.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12454.54\n",
      " Regression with ARIMA(0,0,0) errors : -8881.322\n",
      " Regression with ARIMA(1,0,0) errors : -12434.91\n",
      " Regression with ARIMA(0,0,1) errors : -10562.75\n",
      " Regression with ARIMA(0,0,0) errors : -7707.396\n",
      " Regression with ARIMA(1,0,2) errors : -12446.19\n",
      " Regression with ARIMA(2,0,1) errors : -12444.84\n",
      " Regression with ARIMA(3,0,2) errors : -12469.19\n",
      " Regression with ARIMA(3,0,1) errors : -12458.01\n",
      " Regression with ARIMA(4,0,2) errors : -12484.21\n",
      " Regression with ARIMA(4,0,1) errors : -12483.69\n",
      " Regression with ARIMA(5,0,2) errors : -12502.19\n",
      " Regression with ARIMA(5,0,1) errors : -12498.17\n",
      " Regression with ARIMA(5,0,3) errors : -12504.05\n",
      " Regression with ARIMA(4,0,3) errors : -12482.32\n",
      " Regression with ARIMA(5,0,4) errors : -12490.42\n",
      " Regression with ARIMA(4,0,4) errors : -12481.71\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : -12506.66\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12464.6\n",
      " Regression with ARIMA(0,0,0) errors : -8887.118\n",
      " Regression with ARIMA(1,0,0) errors : -12445.24\n",
      " Regression with ARIMA(0,0,1) errors : -10561.18\n",
      " Regression with ARIMA(0,0,0) errors : -7708.215\n",
      " Regression with ARIMA(1,0,2) errors : -12456.91\n",
      " Regression with ARIMA(2,0,1) errors : -12455.73\n",
      " Regression with ARIMA(3,0,2) errors : -12528.24\n",
      " Regression with ARIMA(3,0,1) errors : -12470.67\n",
      " Regression with ARIMA(4,0,2) errors : -12491.02\n",
      " Regression with ARIMA(3,0,3) errors : -12487.94\n",
      " Regression with ARIMA(2,0,3) errors : -12488.17\n",
      " Regression with ARIMA(4,0,1) errors : -12491.62\n",
      " Regression with ARIMA(4,0,3) errors : -12490.61\n",
      " Regression with ARIMA(3,0,2) errors : -12436.46\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12488.78\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12482.33\n",
      " Regression with ARIMA(0,0,0) errors : -8891.815\n",
      " Regression with ARIMA(1,0,0) errors : -12463.17\n",
      " Regression with ARIMA(0,0,1) errors : -10569.71\n",
      " Regression with ARIMA(0,0,0) errors : -7717.256\n",
      " Regression with ARIMA(1,0,2) errors : -12475.08\n",
      " Regression with ARIMA(2,0,1) errors : -12474.77\n",
      " Regression with ARIMA(3,0,2) errors : -12536.91\n",
      " Regression with ARIMA(3,0,1) errors : -12489.05\n",
      " Regression with ARIMA(4,0,2) errors : -12507.21\n",
      " Regression with ARIMA(3,0,3) errors : -12507.02\n",
      " Regression with ARIMA(2,0,3) errors : -12506.61\n",
      " Regression with ARIMA(4,0,1) errors : -12508.71\n",
      " Regression with ARIMA(4,0,3) errors : -12506.62\n",
      " Regression with ARIMA(3,0,2) errors : -12453.39\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12508.55\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12503.57\n",
      " Regression with ARIMA(0,0,0) errors : -8896.241\n",
      " Regression with ARIMA(1,0,0) errors : -12485.86\n",
      " Regression with ARIMA(0,0,1) errors : -10569.77\n",
      " Regression with ARIMA(0,0,0) errors : -7714.817\n",
      " Regression with ARIMA(1,0,2) errors : -12497.82\n",
      " Regression with ARIMA(2,0,1) errors : -12496.35\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12527.94\n",
      " Regression with ARIMA(1,0,3) errors : -12530.81\n",
      " Regression with ARIMA(0,0,3) errors : -11677.03\n",
      " Regression with ARIMA(1,0,4) errors : -12528.79\n",
      " Regression with ARIMA(0,0,2) errors : -11229.55\n",
      " Regression with ARIMA(0,0,4) errors : -12012.79\n",
      " Regression with ARIMA(2,0,4) errors : -12555.48\n",
      " Regression with ARIMA(3,0,4) errors : -12559.17\n",
      " Regression with ARIMA(3,0,3) errors : -12529.19\n",
      " Regression with ARIMA(4,0,4) errors : -12555.94\n",
      " Regression with ARIMA(3,0,5) errors : -12539.67\n",
      " Regression with ARIMA(2,0,5) errors : -12558.37\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -12560.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12499.29\n",
      " Regression with ARIMA(0,0,0) errors : -8896.211\n",
      " Regression with ARIMA(1,0,0) errors : -12479.6\n",
      " Regression with ARIMA(0,0,1) errors : -10569.06\n",
      " Regression with ARIMA(0,0,0) errors : -7726.249\n",
      " Regression with ARIMA(1,0,2) errors : -12491.43\n",
      " Regression with ARIMA(2,0,1) errors : -12490.08\n",
      " Regression with ARIMA(3,0,2) errors : -12549.65\n",
      " Regression with ARIMA(3,0,1) errors : -12505.95\n",
      " Regression with ARIMA(4,0,2) errors : -12523.02\n",
      " Regression with ARIMA(3,0,3) errors : -12522.73\n",
      " Regression with ARIMA(2,0,3) errors : -12520.84\n",
      " Regression with ARIMA(4,0,1) errors : -12524.79\n",
      " Regression with ARIMA(4,0,3) errors : -12548.68\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12521.78\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12522.71\n",
      " Regression with ARIMA(0,0,0) errors : -8912.717\n",
      " Regression with ARIMA(1,0,0) errors : -12499.7\n",
      " Regression with ARIMA(0,0,1) errors : -10598.43\n",
      " Regression with ARIMA(0,0,0) errors : -7791.064\n",
      " Regression with ARIMA(1,0,2) errors : -12511.99\n",
      " Regression with ARIMA(2,0,1) errors : -12511.69\n",
      " Regression with ARIMA(3,0,2) errors : -12565.33\n",
      " Regression with ARIMA(3,0,1) errors : -12529.16\n",
      " Regression with ARIMA(4,0,2) errors : -12545.66\n",
      " Regression with ARIMA(3,0,3) errors : -12545.28\n",
      " Regression with ARIMA(2,0,3) errors : -12543.96\n",
      " Regression with ARIMA(4,0,1) errors : -12547.58\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12526.08\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.95\n",
      " Regression with ARIMA(0,0,0) errors : -8942.089\n",
      " Regression with ARIMA(1,0,0) errors : -12527.3\n",
      " Regression with ARIMA(0,0,1) errors : -10625.79\n",
      " Regression with ARIMA(0,0,0) errors : -7815.365\n",
      " Regression with ARIMA(1,0,2) errors : -12539.1\n",
      " Regression with ARIMA(2,0,1) errors : -12537.44\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12568.26\n",
      " Regression with ARIMA(1,0,3) errors : -12570.63\n",
      " Regression with ARIMA(0,0,3) errors : -11727.96\n",
      " Regression with ARIMA(1,0,4) errors : -12568.62\n",
      " Regression with ARIMA(0,0,2) errors : -11285.05\n",
      " Regression with ARIMA(0,0,4) errors : -12063.02\n",
      " Regression with ARIMA(2,0,4) errors : -12594.01\n",
      " Regression with ARIMA(3,0,4) errors : -12602.32\n",
      " Regression with ARIMA(3,0,3) errors : -12568.74\n",
      " Regression with ARIMA(4,0,4) errors : -12567.01\n",
      " Regression with ARIMA(3,0,5) errors : -12578.76\n",
      " Regression with ARIMA(2,0,5) errors : -12598.99\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12467.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -12600.43\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12532.16\n",
      " Regression with ARIMA(0,0,0) errors : -8934.83\n",
      " Regression with ARIMA(1,0,0) errors : -12512.55\n",
      " Regression with ARIMA(0,0,1) errors : -10617.82\n",
      " Regression with ARIMA(0,0,0) errors : -7779.834\n",
      " Regression with ARIMA(1,0,2) errors : -12525.18\n",
      " Regression with ARIMA(2,0,1) errors : -12523.58\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12554.76\n",
      " Regression with ARIMA(1,0,3) errors : -12557.17\n",
      " Regression with ARIMA(0,0,3) errors : -11723.56\n",
      " Regression with ARIMA(1,0,4) errors : -12555.2\n",
      " Regression with ARIMA(0,0,2) errors : -11272.84\n",
      " Regression with ARIMA(0,0,4) errors : -12053.22\n",
      " Regression with ARIMA(2,0,4) errors : -12583\n",
      " Regression with ARIMA(3,0,4) errors : -12586.36\n",
      " Regression with ARIMA(3,0,3) errors : -12555.78\n",
      " Regression with ARIMA(4,0,4) errors : -12586.4\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12572.16\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12559.34\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,5) errors : -12569.81\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : -12587.09\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12509.71\n",
      " Regression with ARIMA(0,0,0) errors : -8923.006\n",
      " Regression with ARIMA(1,0,0) errors : -12490.06\n",
      " Regression with ARIMA(0,0,1) errors : -10606.06\n",
      " Regression with ARIMA(0,0,0) errors : -7778.001\n",
      " Regression with ARIMA(1,0,2) errors : -12503.3\n",
      " Regression with ARIMA(2,0,1) errors : -12501.4\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12532.82\n",
      " Regression with ARIMA(1,0,3) errors : -12535.75\n",
      " Regression with ARIMA(0,0,3) errors : -11707.59\n",
      " Regression with ARIMA(1,0,4) errors : -12533.75\n",
      " Regression with ARIMA(0,0,2) errors : -11261.54\n",
      " Regression with ARIMA(0,0,4) errors : -12037.84\n",
      " Regression with ARIMA(2,0,4) errors : -12562.35\n",
      " Regression with ARIMA(3,0,4) errors : -12563.64\n",
      " Regression with ARIMA(3,0,3) errors : -12534.12\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12540.3\n",
      " Regression with ARIMA(2,0,5) errors : -12565.8\n",
      " Regression with ARIMA(1,0,5) errors : -12534.53\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12565.48\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12497.83\n",
      " Regression with ARIMA(0,0,0) errors : -8905.257\n",
      " Regression with ARIMA(1,0,0) errors : -12479.66\n",
      " Regression with ARIMA(0,0,1) errors : -10592.39\n",
      " Regression with ARIMA(0,0,0) errors : -7770.197\n",
      " Regression with ARIMA(1,0,2) errors : -12491.59\n",
      " Regression with ARIMA(2,0,1) errors : -12491.59\n",
      " Regression with ARIMA(3,0,2) errors : -12541.44\n",
      " Regression with ARIMA(3,0,1) errors : -12505.67\n",
      " Regression with ARIMA(4,0,2) errors : -12524.33\n",
      " Regression with ARIMA(3,0,3) errors : -12524.65\n",
      " Regression with ARIMA(2,0,3) errors : -12523.33\n",
      " Regression with ARIMA(4,0,1) errors : -12525.8\n",
      " Regression with ARIMA(4,0,3) errors : -12554.64\n",
      " Regression with ARIMA(5,0,3) errors : -12551.24\n",
      " Regression with ARIMA(4,0,4) errors : -12549.94\n",
      " Regression with ARIMA(3,0,4) errors : -12553.02\n",
      " Regression with ARIMA(5,0,2) errors : -12548.7\n",
      " Regression with ARIMA(5,0,4) errors : -12528.29\n",
      " Regression with ARIMA(4,0,3) errors : -12482.77\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12554.1\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12497.83\n",
      " Regression with ARIMA(0,0,0) errors : -8898.064\n",
      " Regression with ARIMA(1,0,0) errors : -12477.67\n",
      " Regression with ARIMA(0,0,1) errors : -10586.17\n",
      " Regression with ARIMA(0,0,0) errors : -7763.444\n",
      " Regression with ARIMA(1,0,2) errors : -12489.24\n",
      " Regression with ARIMA(2,0,1) errors : -12490.62\n",
      " Regression with ARIMA(3,0,2) errors : -12555.3\n",
      " Regression with ARIMA(3,0,1) errors : -12503.83\n",
      " Regression with ARIMA(4,0,2) errors : -12522.97\n",
      " Regression with ARIMA(3,0,3) errors : -12522.77\n",
      " Regression with ARIMA(2,0,3) errors : -12522.46\n",
      " Regression with ARIMA(4,0,1) errors : -12524.5\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12474.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12523.61\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12513.83\n",
      " Regression with ARIMA(0,0,0) errors : -8943.164\n",
      " Regression with ARIMA(1,0,0) errors : -12488.42\n",
      " Regression with ARIMA(0,0,1) errors : -10621.1\n",
      " Regression with ARIMA(0,0,0) errors : -7868.129\n",
      " Regression with ARIMA(1,0,2) errors : -12499.53\n",
      " Regression with ARIMA(2,0,1) errors : -12510\n",
      " Regression with ARIMA(3,0,2) errors : -12538.21\n",
      " Regression with ARIMA(3,0,1) errors : -12522.06\n",
      " Regression with ARIMA(4,0,2) errors : -12545.22\n",
      " Regression with ARIMA(4,0,1) errors : -12546.86\n",
      " Regression with ARIMA(4,0,0) errors : -12546.27\n",
      " Regression with ARIMA(5,0,1) errors : -12549.63\n",
      " Regression with ARIMA(5,0,0) errors : -12550.19\n",
      " Regression with ARIMA(5,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,0) errors : -12530.49\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12537.41\n",
      " Regression with ARIMA(0,0,0) errors : -8980.404\n",
      " Regression with ARIMA(1,0,0) errors : -12515.87\n",
      " Regression with ARIMA(0,0,1) errors : -10652.29\n",
      " Regression with ARIMA(0,0,0) errors : -7878.327\n",
      " Regression with ARIMA(1,0,2) errors : -12530.48\n",
      " Regression with ARIMA(2,0,1) errors : -12528.68\n",
      " Regression with ARIMA(3,0,2) errors : -12554.48\n",
      " Regression with ARIMA(3,0,1) errors : -12543.44\n",
      " Regression with ARIMA(4,0,2) errors : -12559.77\n",
      " Regression with ARIMA(4,0,1) errors : -12561.17\n",
      " Regression with ARIMA(4,0,0) errors : -12562.64\n",
      " Regression with ARIMA(3,0,0) errors : -12534.45\n",
      " Regression with ARIMA(5,0,0) errors : -12560.32\n",
      " Regression with ARIMA(5,0,1) errors : -12583.89\n",
      " Regression with ARIMA(5,0,2) errors : -12582.7\n",
      " Regression with ARIMA(5,0,1) errors : -12494.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12584.44\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.24\n",
      " Regression with ARIMA(0,0,0) errors : -8985.481\n",
      " Regression with ARIMA(1,0,0) errors : -12523.97\n",
      " Regression with ARIMA(0,0,1) errors : -10655.97\n",
      " Regression with ARIMA(0,0,0) errors : -7884.878\n",
      " Regression with ARIMA(1,0,2) errors : -12538.88\n",
      " Regression with ARIMA(2,0,1) errors : -12537.23\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12566.95\n",
      " Regression with ARIMA(1,0,3) errors : -12569.82\n",
      " Regression with ARIMA(0,0,3) errors : -11754.84\n",
      " Regression with ARIMA(1,0,4) errors : -12567.97\n",
      " Regression with ARIMA(0,0,2) errors : -11299.19\n",
      " Regression with ARIMA(0,0,4) errors : -12073.38\n",
      " Regression with ARIMA(2,0,4) errors : -12592.97\n",
      " Regression with ARIMA(3,0,4) errors : -12597.31\n",
      " Regression with ARIMA(3,0,3) errors : -12567.29\n",
      " Regression with ARIMA(4,0,4) errors : -12596.6\n",
      " Regression with ARIMA(3,0,5) errors : -12570.58\n",
      " Regression with ARIMA(2,0,5) errors : -12597.68\n",
      " Regression with ARIMA(1,0,5) errors : -12568.02\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12597.69\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12546.78\n",
      " Regression with ARIMA(0,0,0) errors : -8970.223\n",
      " Regression with ARIMA(1,0,0) errors : -12525.95\n",
      " Regression with ARIMA(0,0,1) errors : -10649.53\n",
      " Regression with ARIMA(0,0,0) errors : -7878.626\n",
      " Regression with ARIMA(1,0,2) errors : -12540.83\n",
      " Regression with ARIMA(2,0,1) errors : -12539.25\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12568.27\n",
      " Regression with ARIMA(1,0,3) errors : -12571.19\n",
      " Regression with ARIMA(0,0,3) errors : -11751.13\n",
      " Regression with ARIMA(1,0,4) errors : -12569.31\n",
      " Regression with ARIMA(0,0,2) errors : -11296.38\n",
      " Regression with ARIMA(0,0,4) errors : -12067\n",
      " Regression with ARIMA(2,0,4) errors : -12594.34\n",
      " Regression with ARIMA(3,0,4) errors : -12595.54\n",
      " Regression with ARIMA(3,0,3) errors : -12568.5\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12574.84\n",
      " Regression with ARIMA(2,0,5) errors : -12598.8\n",
      " Regression with ARIMA(1,0,5) errors : -12569.08\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12597.59\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.79\n",
      " Regression with ARIMA(0,0,0) errors : -8964.909\n",
      " Regression with ARIMA(1,0,0) errors : -12525.68\n",
      " Regression with ARIMA(0,0,1) errors : -10646.25\n",
      " Regression with ARIMA(0,0,0) errors : -7885.222\n",
      " Regression with ARIMA(1,0,2) errors : -12540.83\n",
      " Regression with ARIMA(2,0,1) errors : -12539.59\n",
      " Regression with ARIMA(3,0,2) errors : -12603.07\n",
      " Regression with ARIMA(3,0,1) errors : -12554.12\n",
      " Regression with ARIMA(4,0,2) errors : -12569.57\n",
      " Regression with ARIMA(3,0,3) errors : -12569.71\n",
      " Regression with ARIMA(2,0,3) errors : -12568.45\n",
      " Regression with ARIMA(4,0,1) errors : -12570.93\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12494.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12570.9\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12548.69\n",
      " Regression with ARIMA(0,0,0) errors : -8959.862\n",
      " Regression with ARIMA(1,0,0) errors : -12529.05\n",
      " Regression with ARIMA(0,0,1) errors : -10643.71\n",
      " Regression with ARIMA(0,0,0) errors : -7886.635\n",
      " Regression with ARIMA(1,0,2) errors : -12544.11\n",
      " Regression with ARIMA(2,0,1) errors : -12544.13\n",
      " Regression with ARIMA(3,0,2) errors : -12571.06\n",
      " Regression with ARIMA(3,0,1) errors : -12561.51\n",
      " Regression with ARIMA(4,0,2) errors : -12576.07\n",
      " Regression with ARIMA(4,0,1) errors : -12578.07\n",
      " Regression with ARIMA(4,0,0) errors : -12579.62\n",
      " Regression with ARIMA(3,0,0) errors : -12551.25\n",
      " Regression with ARIMA(5,0,0) errors : -12579.64\n",
      " Regression with ARIMA(5,0,1) errors : Inf\n",
      " Regression with ARIMA(5,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,0) errors : -12575.23\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12551.97\n",
      " Regression with ARIMA(0,0,0) errors : -8967.683\n",
      " Regression with ARIMA(1,0,0) errors : -12529.69\n",
      " Regression with ARIMA(0,0,1) errors : -10653.67\n",
      " Regression with ARIMA(0,0,0) errors : -7896.484\n",
      " Regression with ARIMA(1,0,2) errors : -12544.97\n",
      " Regression with ARIMA(2,0,1) errors : -12543.7\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12573.37\n",
      " Regression with ARIMA(1,0,3) errors : -12575.68\n",
      " Regression with ARIMA(0,0,3) errors : -11753.95\n",
      " Regression with ARIMA(1,0,4) errors : -12573.8\n",
      " Regression with ARIMA(0,0,2) errors : -11300.67\n",
      " Regression with ARIMA(0,0,4) errors : -12074.69\n",
      " Regression with ARIMA(2,0,4) errors : -12591.45\n",
      " Regression with ARIMA(3,0,4) errors : -12595.99\n",
      " Regression with ARIMA(3,0,3) errors : -12573.8\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12580.86\n",
      " Regression with ARIMA(2,0,5) errors : -12597\n",
      " Regression with ARIMA(1,0,5) errors : -12573.86\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12603.04\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12556.25\n",
      " Regression with ARIMA(0,0,0) errors : -8962.755\n",
      " Regression with ARIMA(1,0,0) errors : -12535.8\n",
      " Regression with ARIMA(0,0,1) errors : -10648.64\n",
      " Regression with ARIMA(0,0,0) errors : -7898.839\n",
      " Regression with ARIMA(1,0,2) errors : -12550.14\n",
      " Regression with ARIMA(2,0,1) errors : -12548.54\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12578.72\n",
      " Regression with ARIMA(1,0,3) errors : -12581.63\n",
      " Regression with ARIMA(0,0,3) errors : -11752.88\n",
      " Regression with ARIMA(1,0,4) errors : -12579.7\n",
      " Regression with ARIMA(0,0,2) errors : -11299.22\n",
      " Regression with ARIMA(0,0,4) errors : -12072.91\n",
      " Regression with ARIMA(2,0,4) errors : -12605.06\n",
      " Regression with ARIMA(3,0,4) errors : -12603.2\n",
      " Regression with ARIMA(2,0,5) errors : -12609.26\n",
      " Regression with ARIMA(1,0,5) errors : -12579.72\n",
      " Regression with ARIMA(3,0,5) errors : -12582.04\n",
      " Regression with ARIMA(2,0,5) errors : -12540.55\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12607.82\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12570.6\n",
      " Regression with ARIMA(0,0,0) errors : -8967.56\n",
      " Regression with ARIMA(1,0,0) errors : -12549.25\n",
      " Regression with ARIMA(0,0,1) errors : -10654.34\n",
      " Regression with ARIMA(0,0,0) errors : -7906.854\n",
      " Regression with ARIMA(1,0,2) errors : -12564.03\n",
      " Regression with ARIMA(2,0,1) errors : -12563.91\n",
      " Regression with ARIMA(3,0,2) errors : -12627.87\n",
      " Regression with ARIMA(3,0,1) errors : -12577.27\n",
      " Regression with ARIMA(4,0,2) errors : -12593.34\n",
      " Regression with ARIMA(3,0,3) errors : -12593.82\n",
      " Regression with ARIMA(2,0,3) errors : -12593.22\n",
      " Regression with ARIMA(4,0,1) errors : -12594.72\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12522.09\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12594.39\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12576.56\n",
      " Regression with ARIMA(0,0,0) errors : -8968.532\n",
      " Regression with ARIMA(1,0,0) errors : -12555.14\n",
      " Regression with ARIMA(0,0,1) errors : -10657.19\n",
      " Regression with ARIMA(0,0,0) errors : -7936.331\n",
      " Regression with ARIMA(1,0,2) errors : -12569.91\n",
      " Regression with ARIMA(2,0,1) errors : -12570.88\n",
      " Regression with ARIMA(3,0,2) errors : -12594.83\n",
      " Regression with ARIMA(3,0,1) errors : -12583.62\n",
      " Regression with ARIMA(4,0,2) errors : -12601.21\n",
      " Regression with ARIMA(4,0,1) errors : -12602.62\n",
      " Regression with ARIMA(4,0,0) errors : -12603.98\n",
      " Regression with ARIMA(3,0,0) errors : -12574.44\n",
      " Regression with ARIMA(5,0,0) errors : -12601.82\n",
      " Regression with ARIMA(5,0,1) errors : -12626.33\n",
      " Regression with ARIMA(5,0,2) errors : -12625.22\n",
      " Regression with ARIMA(5,0,1) errors : -12547.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12620.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12601.85\n",
      " Regression with ARIMA(0,0,0) errors : -9048.224\n",
      " Regression with ARIMA(1,0,0) errors : -12582.93\n",
      " Regression with ARIMA(0,0,1) errors : -10732.82\n",
      " Regression with ARIMA(0,0,0) errors : -8067.123\n",
      " Regression with ARIMA(1,0,2) errors : -12598.44\n",
      " Regression with ARIMA(2,0,1) errors : -12601.12\n",
      " Regression with ARIMA(3,0,2) errors : -12619.05\n",
      " Regression with ARIMA(3,0,1) errors : -12618.74\n",
      " Regression with ARIMA(4,0,2) errors : -12650.56\n",
      " Regression with ARIMA(4,0,1) errors : -12652.27\n",
      " Regression with ARIMA(4,0,0) errors : -12652.06\n",
      " Regression with ARIMA(5,0,1) errors : -12662.55\n",
      " Regression with ARIMA(5,0,0) errors : -12658.45\n",
      " Regression with ARIMA(5,0,2) errors : -12663.08\n",
      " Regression with ARIMA(5,0,3) errors : -12661.14\n",
      " Regression with ARIMA(4,0,3) errors : -12649.44\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -12652.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12607.62\n",
      " Regression with ARIMA(0,0,0) errors : -9029.222\n",
      " Regression with ARIMA(1,0,0) errors : -12581.78\n",
      " Regression with ARIMA(0,0,1) errors : -10679.8\n",
      " Regression with ARIMA(0,0,0) errors : -7988.616\n",
      " Regression with ARIMA(1,0,2) errors : -12606.76\n",
      " Regression with ARIMA(2,0,1) errors : -12606.03\n",
      " Regression with ARIMA(3,0,2) errors : -12633.3\n",
      " Regression with ARIMA(3,0,1) errors : -12616.63\n",
      " Regression with ARIMA(4,0,2) errors : -12637.18\n",
      " Regression with ARIMA(4,0,1) errors : -12639.14\n",
      " Regression with ARIMA(4,0,0) errors : -12638.63\n",
      " Regression with ARIMA(5,0,1) errors : -12657.77\n",
      " Regression with ARIMA(5,0,0) errors : -12639.34\n",
      " Regression with ARIMA(5,0,2) errors : -12656.11\n",
      " Regression with ARIMA(5,0,1) errors : -12576.93\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12665.38\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12515.14\n",
      " Regression with ARIMA(0,1,0) errors : -12443.47\n",
      " Regression with ARIMA(1,1,0) errors : -12487.68\n",
      " Regression with ARIMA(0,1,1) errors : -12495.53\n",
      " Regression with ARIMA(0,1,0) errors : -12445.47\n",
      " Regression with ARIMA(1,1,2) errors : -12499.79\n",
      " Regression with ARIMA(2,1,1) errors : -12505.72\n",
      " Regression with ARIMA(3,1,2) errors : -12545.83\n",
      " Regression with ARIMA(3,1,1) errors : -12512.71\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -12547.75\n",
      " Regression with ARIMA(2,1,2) errors : -12517.15\n",
      " Regression with ARIMA(3,1,1) errors : -12514.72\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -12507.73\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12527.28\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12606.67\n",
      " Regression with ARIMA(0,0,0) errors : -9078.123\n",
      " Regression with ARIMA(1,0,0) errors : -12575.25\n",
      " Regression with ARIMA(0,0,1) errors : -10725.64\n",
      " Regression with ARIMA(0,0,0) errors : -8063.193\n",
      " Regression with ARIMA(1,0,2) errors : -12597.15\n",
      " Regression with ARIMA(2,0,1) errors : -12601.19\n",
      " Regression with ARIMA(3,0,2) errors : -12625.54\n",
      " Regression with ARIMA(3,0,1) errors : -12611.94\n",
      " Regression with ARIMA(4,0,2) errors : -12627.49\n",
      " Regression with ARIMA(4,0,1) errors : -12627.75\n",
      " Regression with ARIMA(4,0,0) errors : -12627.47\n",
      " Regression with ARIMA(5,0,1) errors : -12646.75\n",
      " Regression with ARIMA(5,0,0) errors : -12630.02\n",
      " Regression with ARIMA(5,0,2) errors : -12645.2\n",
      " Regression with ARIMA(5,0,1) errors : -12548.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12650.4\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12592.63\n",
      " Regression with ARIMA(0,0,0) errors : -9082.048\n",
      " Regression with ARIMA(1,0,0) errors : -12566.66\n",
      " Regression with ARIMA(0,0,1) errors : -10726.09\n",
      " Regression with ARIMA(0,0,0) errors : -8059.077\n",
      " Regression with ARIMA(1,0,2) errors : -12588.96\n",
      " Regression with ARIMA(2,0,1) errors : -12589.11\n",
      " Regression with ARIMA(3,0,2) errors : -12638.23\n",
      " Regression with ARIMA(3,0,1) errors : -12600.16\n",
      " Regression with ARIMA(4,0,2) errors : -12617.62\n",
      " Regression with ARIMA(3,0,3) errors : -12618.48\n",
      " Regression with ARIMA(2,0,3) errors : -12614.14\n",
      " Regression with ARIMA(4,0,1) errors : -12616.7\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12548.15\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12652.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12584\n",
      " Regression with ARIMA(0,0,0) errors : -9072.623\n",
      " Regression with ARIMA(1,0,0) errors : -12558.92\n",
      " Regression with ARIMA(0,0,1) errors : -10724.45\n",
      " Regression with ARIMA(0,0,0) errors : -8059.797\n",
      " Regression with ARIMA(1,0,2) errors : -12579.62\n",
      " Regression with ARIMA(2,0,1) errors : -12579.45\n",
      " Regression with ARIMA(3,0,2) errors : -12637.15\n",
      " Regression with ARIMA(3,0,1) errors : -12590.09\n",
      " Regression with ARIMA(4,0,2) errors : -12609.14\n",
      " Regression with ARIMA(3,0,3) errors : -12608.81\n",
      " Regression with ARIMA(2,0,3) errors : -12605.33\n",
      " Regression with ARIMA(4,0,1) errors : -12609.45\n",
      " Regression with ARIMA(4,0,3) errors : -12638.04\n",
      " Regression with ARIMA(5,0,3) errors : -12624.89\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12633.6\n",
      " Regression with ARIMA(5,0,2) errors : -12623.44\n",
      " Regression with ARIMA(5,0,4) errors : -12618.15\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12645.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12597.56\n",
      " Regression with ARIMA(0,0,0) errors : -9087.133\n",
      " Regression with ARIMA(1,0,0) errors : -12572.15\n",
      " Regression with ARIMA(0,0,1) errors : -10736.93\n",
      " Regression with ARIMA(0,0,0) errors : -8079.117\n",
      " Regression with ARIMA(1,0,2) errors : -12594.14\n",
      " Regression with ARIMA(2,0,1) errors : -12593.03\n",
      " Regression with ARIMA(3,0,2) errors : -12658.36\n",
      " Regression with ARIMA(3,0,1) errors : -12603.77\n",
      " Regression with ARIMA(4,0,2) errors : -12622.07\n",
      " Regression with ARIMA(3,0,3) errors : -12622.59\n",
      " Regression with ARIMA(2,0,3) errors : -12619.12\n",
      " Regression with ARIMA(4,0,1) errors : -12620.82\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12548.61\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12655.81\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12610.85\n",
      " Regression with ARIMA(0,0,0) errors : -9095.509\n",
      " Regression with ARIMA(1,0,0) errors : -12584.86\n",
      " Regression with ARIMA(0,0,1) errors : -10749.33\n",
      " Regression with ARIMA(0,0,0) errors : -8097.852\n",
      " Regression with ARIMA(1,0,2) errors : -12606.97\n",
      " Regression with ARIMA(2,0,1) errors : -12608.39\n",
      " Regression with ARIMA(3,0,2) errors : -12658.34\n",
      " Regression with ARIMA(3,0,1) errors : -12619.38\n",
      " Regression with ARIMA(4,0,2) errors : -12636.67\n",
      " Regression with ARIMA(3,0,3) errors : -12637.2\n",
      " Regression with ARIMA(2,0,3) errors : -12634.49\n",
      " Regression with ARIMA(4,0,1) errors : -12636.79\n",
      " Regression with ARIMA(4,0,3) errors : -12679.01\n",
      " Regression with ARIMA(5,0,3) errors : -12665.31\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12669.72\n",
      " Regression with ARIMA(5,0,2) errors : -12665.96\n",
      " Regression with ARIMA(5,0,4) errors : -12644.1\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12661.83\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.42\n",
      " Regression with ARIMA(0,0,0) errors : -9117.955\n",
      " Regression with ARIMA(1,0,0) errors : -12604.61\n",
      " Regression with ARIMA(0,0,1) errors : -10769.78\n",
      " Regression with ARIMA(0,0,0) errors : -8106.906\n",
      " Regression with ARIMA(1,0,2) errors : -12626.91\n",
      " Regression with ARIMA(2,0,1) errors : -12625.67\n",
      " Regression with ARIMA(3,0,2) errors : -12690.09\n",
      " Regression with ARIMA(3,0,1) errors : -12637.43\n",
      " Regression with ARIMA(4,0,2) errors : -12655.81\n",
      " Regression with ARIMA(3,0,3) errors : -12655.49\n",
      " Regression with ARIMA(2,0,3) errors : -12652.79\n",
      " Regression with ARIMA(4,0,1) errors : -12654.8\n",
      " Regression with ARIMA(4,0,3) errors : -12693.24\n",
      " Regression with ARIMA(5,0,3) errors : -12662.02\n",
      " Regression with ARIMA(4,0,4) errors : -12671.03\n",
      " Regression with ARIMA(3,0,4) errors : -12677.48\n",
      " Regression with ARIMA(5,0,2) errors : -12662.99\n",
      " Regression with ARIMA(5,0,4) errors : -12675.56\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12692.59\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12641.13\n",
      " Regression with ARIMA(0,0,0) errors : -9120.512\n",
      " Regression with ARIMA(1,0,0) errors : -12614.69\n",
      " Regression with ARIMA(0,0,1) errors : -10777.29\n",
      " Regression with ARIMA(0,0,0) errors : -8113.97\n",
      " Regression with ARIMA(1,0,2) errors : -12636.3\n",
      " Regression with ARIMA(2,0,1) errors : -12634.97\n",
      " Regression with ARIMA(3,0,2) errors : -12703.57\n",
      " Regression with ARIMA(3,0,1) errors : -12648.05\n",
      " Regression with ARIMA(4,0,2) errors : -12667.51\n",
      " Regression with ARIMA(3,0,3) errors : -12666.81\n",
      " Regression with ARIMA(2,0,3) errors : -12663.2\n",
      " Regression with ARIMA(4,0,1) errors : -12665.98\n",
      " Regression with ARIMA(4,0,3) errors : -12703.17\n",
      " Regression with ARIMA(3,0,2) errors : -12608.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.93\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12643.6\n",
      " Regression with ARIMA(0,0,0) errors : -9119.216\n",
      " Regression with ARIMA(1,0,0) errors : -12616.26\n",
      " Regression with ARIMA(0,0,1) errors : -10777.52\n",
      " Regression with ARIMA(0,0,0) errors : -8101.041\n",
      " Regression with ARIMA(1,0,2) errors : -12637.47\n",
      " Regression with ARIMA(2,0,1) errors : -12640.52\n",
      " Regression with ARIMA(3,0,2) errors : -12680.71\n",
      " Regression with ARIMA(3,0,1) errors : -12652.57\n",
      " Regression with ARIMA(4,0,2) errors : -12672.29\n",
      " Regression with ARIMA(3,0,3) errors : -12671.04\n",
      " Regression with ARIMA(2,0,3) errors : -12668.46\n",
      " Regression with ARIMA(4,0,1) errors : -12671.99\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12605.13\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12704.4\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12641.82\n",
      " Regression with ARIMA(0,0,0) errors : -9125.129\n",
      " Regression with ARIMA(1,0,0) errors : -12617.13\n",
      " Regression with ARIMA(0,0,1) errors : -10783.88\n",
      " Regression with ARIMA(0,0,0) errors : -8122.685\n",
      " Regression with ARIMA(1,0,2) errors : -12638.09\n",
      " Regression with ARIMA(2,0,1) errors : -12636.93\n",
      " Regression with ARIMA(3,0,2) errors : -12695.39\n",
      " Regression with ARIMA(3,0,1) errors : -12649.51\n",
      " Regression with ARIMA(4,0,2) errors : -12667.03\n",
      " Regression with ARIMA(3,0,3) errors : -12667.49\n",
      " Regression with ARIMA(2,0,3) errors : -12664.06\n",
      " Regression with ARIMA(4,0,1) errors : -12666.82\n",
      " Regression with ARIMA(4,0,3) errors : -12707.83\n",
      " Regression with ARIMA(5,0,3) errors : -12686.77\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12686.56\n",
      " Regression with ARIMA(5,0,2) errors : -12685.94\n",
      " Regression with ARIMA(5,0,4) errors : -12670.08\n",
      " Regression with ARIMA(4,0,3) errors : -12637.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12704.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12640.83\n",
      " Regression with ARIMA(0,0,0) errors : -9124.201\n",
      " Regression with ARIMA(1,0,0) errors : -12614.79\n",
      " Regression with ARIMA(0,0,1) errors : -10783.44\n",
      " Regression with ARIMA(0,0,0) errors : -8122.209\n",
      " Regression with ARIMA(1,0,2) errors : -12635.64\n",
      " Regression with ARIMA(2,0,1) errors : -12634.86\n",
      " Regression with ARIMA(3,0,2) errors : -12695.41\n",
      " Regression with ARIMA(3,0,1) errors : -12647.57\n",
      " Regression with ARIMA(4,0,2) errors : -12665.91\n",
      " Regression with ARIMA(3,0,3) errors : -12665.62\n",
      " Regression with ARIMA(2,0,3) errors : -12662.3\n",
      " Regression with ARIMA(4,0,1) errors : -12664.73\n",
      " Regression with ARIMA(4,0,3) errors : -12708.36\n",
      " Regression with ARIMA(5,0,3) errors : -12683.74\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12676.17\n",
      " Regression with ARIMA(4,0,3) errors : -12636.53\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12702.9\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.35\n",
      " Regression with ARIMA(0,0,0) errors : -9121.854\n",
      " Regression with ARIMA(1,0,0) errors : -12613.51\n",
      " Regression with ARIMA(0,0,1) errors : -10782.18\n",
      " Regression with ARIMA(0,0,0) errors : -8117.61\n",
      " Regression with ARIMA(1,0,2) errors : -12633.27\n",
      " Regression with ARIMA(2,0,1) errors : -12632.06\n",
      " Regression with ARIMA(3,0,2) errors : -12698.45\n",
      " Regression with ARIMA(3,0,1) errors : -12643.7\n",
      " Regression with ARIMA(4,0,2) errors : -12660.83\n",
      " Regression with ARIMA(3,0,3) errors : -12661.66\n",
      " Regression with ARIMA(2,0,3) errors : -12658.11\n",
      " Regression with ARIMA(4,0,1) errors : -12659.62\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12597.25\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12700.82\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.09\n",
      " Regression with ARIMA(0,0,0) errors : -9116.676\n",
      " Regression with ARIMA(1,0,0) errors : -12611.67\n",
      " Regression with ARIMA(0,0,1) errors : -10780.74\n",
      " Regression with ARIMA(0,0,0) errors : -8116.581\n",
      " Regression with ARIMA(1,0,2) errors : -12630.99\n",
      " Regression with ARIMA(2,0,1) errors : -12629.63\n",
      " Regression with ARIMA(3,0,2) errors : -12699.18\n",
      " Regression with ARIMA(3,0,1) errors : -12641.18\n",
      " Regression with ARIMA(4,0,2) errors : -12658.75\n",
      " Regression with ARIMA(3,0,3) errors : -12659.44\n",
      " Regression with ARIMA(2,0,3) errors : -12655.65\n",
      " Regression with ARIMA(4,0,1) errors : -12657.53\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12615.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12699.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12639.03\n",
      " Regression with ARIMA(0,0,0) errors : -9117.537\n",
      " Regression with ARIMA(1,0,0) errors : -12615.18\n",
      " Regression with ARIMA(0,0,1) errors : -10783.7\n",
      " Regression with ARIMA(0,0,0) errors : -8118.136\n",
      " Regression with ARIMA(1,0,2) errors : -12634.65\n",
      " Regression with ARIMA(2,0,1) errors : -12633.24\n",
      " Regression with ARIMA(3,0,2) errors : -12699.98\n",
      " Regression with ARIMA(3,0,1) errors : -12645.33\n",
      " Regression with ARIMA(4,0,2) errors : -12662.46\n",
      " Regression with ARIMA(3,0,3) errors : -12663.29\n",
      " Regression with ARIMA(2,0,3) errors : -12659.28\n",
      " Regression with ARIMA(4,0,1) errors : -12661.46\n",
      " Regression with ARIMA(4,0,3) errors : -12704.33\n",
      " Regression with ARIMA(5,0,3) errors : -12680.72\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12676.03\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12672.54\n",
      " Regression with ARIMA(4,0,3) errors : -12599.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12703.36\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.78\n",
      " Regression with ARIMA(0,0,0) errors : -9113.603\n",
      " Regression with ARIMA(1,0,0) errors : -12610.36\n",
      " Regression with ARIMA(0,0,1) errors : -10781.97\n",
      " Regression with ARIMA(0,0,0) errors : -8111.354\n",
      " Regression with ARIMA(1,0,2) errors : -12629.21\n",
      " Regression with ARIMA(2,0,1) errors : -12627.93\n",
      " Regression with ARIMA(3,0,2) errors : -12693.18\n",
      " Regression with ARIMA(3,0,1) errors : -12639.63\n",
      " Regression with ARIMA(4,0,2) errors : -12657.34\n",
      " Regression with ARIMA(3,0,3) errors : -12657.78\n",
      " Regression with ARIMA(2,0,3) errors : -12654.23\n",
      " Regression with ARIMA(4,0,1) errors : -12656.4\n",
      " Regression with ARIMA(4,0,3) errors : -12699.31\n",
      " Regression with ARIMA(5,0,3) errors : -12674.55\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12675.54\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12667.95\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.07\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.46\n",
      " Regression with ARIMA(0,0,0) errors : -9119.245\n",
      " Regression with ARIMA(1,0,0) errors : -12613.96\n",
      " Regression with ARIMA(0,0,1) errors : -10785.81\n",
      " Regression with ARIMA(0,0,0) errors : -8116.382\n",
      " Regression with ARIMA(1,0,2) errors : -12632.76\n",
      " Regression with ARIMA(2,0,1) errors : -12631.28\n",
      " Regression with ARIMA(3,0,2) errors : -12700.56\n",
      " Regression with ARIMA(3,0,1) errors : -12643.51\n",
      " Regression with ARIMA(4,0,2) errors : -12660.35\n",
      " Regression with ARIMA(3,0,3) errors : -12660.75\n",
      " Regression with ARIMA(2,0,3) errors : -12657.34\n",
      " Regression with ARIMA(4,0,1) errors : -12659.28\n",
      " Regression with ARIMA(4,0,3) errors : -12705.25\n",
      " Regression with ARIMA(5,0,3) errors : -12677.25\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12659.26\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12674.2\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12701.28\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.91\n",
      " Regression with ARIMA(0,0,0) errors : -9115.346\n",
      " Regression with ARIMA(1,0,0) errors : -12609.25\n",
      " Regression with ARIMA(0,0,1) errors : -10783.59\n",
      " Regression with ARIMA(0,0,0) errors : -8119.022\n",
      " Regression with ARIMA(1,0,2) errors : -12628.07\n",
      " Regression with ARIMA(2,0,1) errors : -12626.55\n",
      " Regression with ARIMA(3,0,2) errors : -12695.08\n",
      " Regression with ARIMA(3,0,1) errors : -12639.09\n",
      " Regression with ARIMA(4,0,2) errors : -12655.57\n",
      " Regression with ARIMA(3,0,3) errors : -12655.97\n",
      " Regression with ARIMA(2,0,3) errors : -12652.64\n",
      " Regression with ARIMA(4,0,1) errors : -12654.48\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12608.86\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12697.61\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12634.77\n",
      " Regression with ARIMA(0,0,0) errors : -9112.722\n",
      " Regression with ARIMA(1,0,0) errors : -12611.67\n",
      " Regression with ARIMA(0,0,1) errors : -10782.69\n",
      " Regression with ARIMA(0,0,0) errors : -8118.407\n",
      " Regression with ARIMA(1,0,2) errors : -12630.3\n",
      " Regression with ARIMA(2,0,1) errors : -12628.79\n",
      " Regression with ARIMA(3,0,2) errors : -12698.97\n",
      " Regression with ARIMA(3,0,1) errors : -12640.78\n",
      " Regression with ARIMA(4,0,2) errors : -12656.92\n",
      " Regression with ARIMA(3,0,3) errors : -12657.7\n",
      " Regression with ARIMA(2,0,3) errors : -12654.48\n",
      " Regression with ARIMA(4,0,1) errors : -12655.94\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12604.1\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12699.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.36\n",
      " Regression with ARIMA(0,0,0) errors : -9119.25\n",
      " Regression with ARIMA(1,0,0) errors : -12613.66\n",
      " Regression with ARIMA(0,0,1) errors : -10784.04\n",
      " Regression with ARIMA(0,0,0) errors : -8121.82\n",
      " Regression with ARIMA(1,0,2) errors : -12632.84\n",
      " Regression with ARIMA(2,0,1) errors : -12631.38\n",
      " Regression with ARIMA(3,0,2) errors : -12686.69\n",
      " Regression with ARIMA(3,0,1) errors : -12643.65\n",
      " Regression with ARIMA(4,0,2) errors : -12661.74\n",
      " Regression with ARIMA(3,0,3) errors : -12661.05\n",
      " Regression with ARIMA(2,0,3) errors : -12657.15\n",
      " Regression with ARIMA(4,0,1) errors : -12661.45\n",
      " Regression with ARIMA(4,0,3) errors : -12661.55\n",
      " Regression with ARIMA(3,0,2) errors : -12592.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.86\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.03\n",
      " Regression with ARIMA(0,0,0) errors : -9124.803\n",
      " Regression with ARIMA(1,0,0) errors : -12611.58\n",
      " Regression with ARIMA(0,0,1) errors : -10785.79\n",
      " Regression with ARIMA(0,0,0) errors : -8120.735\n",
      " Regression with ARIMA(1,0,2) errors : -12631.26\n",
      " Regression with ARIMA(2,0,1) errors : -12629.83\n",
      " Regression with ARIMA(3,0,2) errors : -12695.7\n",
      " Regression with ARIMA(3,0,1) errors : -12642.68\n",
      " Regression with ARIMA(4,0,2) errors : -12659.94\n",
      " Regression with ARIMA(3,0,3) errors : -12660.68\n",
      " Regression with ARIMA(2,0,3) errors : -12655.54\n",
      " Regression with ARIMA(4,0,1) errors : -12658.46\n",
      " Regression with ARIMA(4,0,3) errors : -12702.36\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12659.16\n",
      " Regression with ARIMA(5,0,2) errors : -12657.49\n",
      " Regression with ARIMA(5,0,4) errors : -12659.7\n",
      " Regression with ARIMA(4,0,3) errors : -12584.34\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.35\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12639.64\n",
      " Regression with ARIMA(0,0,0) errors : -9126.097\n",
      " Regression with ARIMA(1,0,0) errors : -12614.91\n",
      " Regression with ARIMA(0,0,1) errors : -10785.02\n",
      " Regression with ARIMA(0,0,0) errors : -8116.995\n",
      " Regression with ARIMA(1,0,2) errors : -12635.07\n",
      " Regression with ARIMA(2,0,1) errors : -12633.58\n",
      " Regression with ARIMA(3,0,2) errors : -12700.58\n",
      " Regression with ARIMA(3,0,1) errors : -12646.01\n",
      " Regression with ARIMA(4,0,2) errors : -12662.46\n",
      " Regression with ARIMA(3,0,3) errors : -12663.22\n",
      " Regression with ARIMA(2,0,3) errors : -12659.45\n",
      " Regression with ARIMA(4,0,1) errors : -12661.32\n",
      " Regression with ARIMA(4,0,3) errors : -12707.82\n",
      " Regression with ARIMA(5,0,3) errors : -12680.87\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.94\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12674.86\n",
      " Regression with ARIMA(4,0,3) errors : -12602.62\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12703.26\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.76\n",
      " Regression with ARIMA(0,0,0) errors : -9126.664\n",
      " Regression with ARIMA(1,0,0) errors : -12610.17\n",
      " Regression with ARIMA(0,0,1) errors : -10784.22\n",
      " Regression with ARIMA(0,0,0) errors : -8120.924\n",
      " Regression with ARIMA(1,0,2) errors : -12630.62\n",
      " Regression with ARIMA(2,0,1) errors : -12629.52\n",
      " Regression with ARIMA(3,0,2) errors : -12694.59\n",
      " Regression with ARIMA(3,0,1) errors : -12642.09\n",
      " Regression with ARIMA(4,0,2) errors : -12658.44\n",
      " Regression with ARIMA(3,0,3) errors : -12658.75\n",
      " Regression with ARIMA(2,0,3) errors : -12655.04\n",
      " Regression with ARIMA(4,0,1) errors : -12657.14\n",
      " Regression with ARIMA(4,0,3) errors : -12704.19\n",
      " Regression with ARIMA(5,0,3) errors : -12674.9\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.25\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12664.74\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.55\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.01\n",
      " Regression with ARIMA(0,0,0) errors : -9129.67\n",
      " Regression with ARIMA(1,0,0) errors : -12606.43\n",
      " Regression with ARIMA(0,0,1) errors : -10786.26\n",
      " Regression with ARIMA(0,0,0) errors : -8109.689\n",
      " Regression with ARIMA(1,0,2) errors : -12626.33\n",
      " Regression with ARIMA(2,0,1) errors : -12625.7\n",
      " Regression with ARIMA(3,0,2) errors : -12685.15\n",
      " Regression with ARIMA(3,0,1) errors : -12638.15\n",
      " Regression with ARIMA(4,0,2) errors : -12654.36\n",
      " Regression with ARIMA(3,0,3) errors : -12654.53\n",
      " Regression with ARIMA(2,0,3) errors : -12651.32\n",
      " Regression with ARIMA(4,0,1) errors : -12653.1\n",
      " Regression with ARIMA(4,0,3) errors : -12701.37\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12653.24\n",
      " Regression with ARIMA(3,0,4) errors : -12676.54\n",
      " Regression with ARIMA(5,0,2) errors : -12652.64\n",
      " Regression with ARIMA(5,0,4) errors : -12668.09\n",
      " Regression with ARIMA(4,0,3) errors : -12590.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.56\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.77\n",
      " Regression with ARIMA(0,0,0) errors : -9125.562\n",
      " Regression with ARIMA(1,0,0) errors : -12610.64\n",
      " Regression with ARIMA(0,0,1) errors : -10785.7\n",
      " Regression with ARIMA(0,0,0) errors : -8108.179\n",
      " Regression with ARIMA(1,0,2) errors : -12630.51\n",
      " Regression with ARIMA(2,0,1) errors : -12629.36\n",
      " Regression with ARIMA(3,0,2) errors : -12694.15\n",
      " Regression with ARIMA(3,0,1) errors : -12642.13\n",
      " Regression with ARIMA(4,0,2) errors : -12658.37\n",
      " Regression with ARIMA(3,0,3) errors : -12658.83\n",
      " Regression with ARIMA(2,0,3) errors : -12655.24\n",
      " Regression with ARIMA(4,0,1) errors : -12657.12\n",
      " Regression with ARIMA(4,0,3) errors : -12704.42\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12679.15\n",
      " Regression with ARIMA(3,0,4) errors : -12677.56\n",
      " Regression with ARIMA(5,0,2) errors : -12656.96\n",
      " Regression with ARIMA(5,0,4) errors : -12670.89\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12699.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.76\n",
      " Regression with ARIMA(0,0,0) errors : -9119.29\n",
      " Regression with ARIMA(1,0,0) errors : -12609.83\n",
      " Regression with ARIMA(0,0,1) errors : -10782.32\n",
      " Regression with ARIMA(0,0,0) errors : -8104.093\n",
      " Regression with ARIMA(1,0,2) errors : -12629.02\n",
      " Regression with ARIMA(2,0,1) errors : -12627.65\n",
      " Regression with ARIMA(3,0,2) errors : -12693.41\n",
      " Regression with ARIMA(3,0,1) errors : -12640.24\n",
      " Regression with ARIMA(4,0,2) errors : -12657.4\n",
      " Regression with ARIMA(3,0,3) errors : -12657.65\n",
      " Regression with ARIMA(2,0,3) errors : -12654\n",
      " Regression with ARIMA(4,0,1) errors : -12655.98\n",
      " Regression with ARIMA(4,0,3) errors : -12700.63\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12678.52\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12666.19\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.72\n",
      " Regression with ARIMA(0,0,0) errors : -9127.533\n",
      " Regression with ARIMA(1,0,0) errors : -12608.51\n",
      " Regression with ARIMA(0,0,1) errors : -10784.58\n",
      " Regression with ARIMA(0,0,0) errors : -8099.693\n",
      " Regression with ARIMA(1,0,2) errors : -12627.71\n",
      " Regression with ARIMA(2,0,1) errors : -12626.53\n",
      " Regression with ARIMA(3,0,2) errors : -12687.4\n",
      " Regression with ARIMA(3,0,1) errors : -12638.82\n",
      " Regression with ARIMA(4,0,2) errors : -12655.24\n",
      " Regression with ARIMA(3,0,3) errors : -12655.99\n",
      " Regression with ARIMA(2,0,3) errors : -12651.92\n",
      " Regression with ARIMA(4,0,1) errors : -12654.76\n",
      " Regression with ARIMA(4,0,3) errors : -12698.43\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12654.62\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -12611.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12696.67\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.19\n",
      " Regression with ARIMA(0,0,0) errors : -9131.072\n",
      " Regression with ARIMA(1,0,0) errors : -12612.33\n",
      " Regression with ARIMA(0,0,1) errors : -10786.34\n",
      " Regression with ARIMA(0,0,0) errors : -8111.89\n",
      " Regression with ARIMA(1,0,2) errors : -12632.14\n",
      " Regression with ARIMA(2,0,1) errors : -12630.94\n",
      " Regression with ARIMA(3,0,2) errors : -12697.09\n",
      " Regression with ARIMA(3,0,1) errors : -12642.55\n",
      " Regression with ARIMA(4,0,2) errors : -12659.42\n",
      " Regression with ARIMA(3,0,3) errors : -12660.03\n",
      " Regression with ARIMA(2,0,3) errors : -12656.53\n",
      " Regression with ARIMA(4,0,1) errors : -12658.14\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12614.5\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12700.42\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.26\n",
      " Regression with ARIMA(0,0,0) errors : -9126.592\n",
      " Regression with ARIMA(1,0,0) errors : -12609.67\n",
      " Regression with ARIMA(0,0,1) errors : -10781.77\n",
      " Regression with ARIMA(0,0,0) errors : -8113.176\n",
      " Regression with ARIMA(1,0,2) errors : -12629.18\n",
      " Regression with ARIMA(2,0,1) errors : -12627.73\n",
      " Regression with ARIMA(3,0,2) errors : -12692.71\n",
      " Regression with ARIMA(3,0,1) errors : -12639.26\n",
      " Regression with ARIMA(4,0,2) errors : -12656.27\n",
      " Regression with ARIMA(3,0,3) errors : -12657.03\n",
      " Regression with ARIMA(2,0,3) errors : -12652.75\n",
      " Regression with ARIMA(4,0,1) errors : -12654.72\n",
      " Regression with ARIMA(4,0,3) errors : -12699.6\n",
      " Regression with ARIMA(5,0,3) errors : -12672.77\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12668.99\n",
      " Regression with ARIMA(4,0,3) errors : -12626.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12697.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.51\n",
      " Regression with ARIMA(0,0,0) errors : -9120.766\n",
      " Regression with ARIMA(1,0,0) errors : -12607\n",
      " Regression with ARIMA(0,0,1) errors : -10776.09\n",
      " Regression with ARIMA(0,0,0) errors : -8111.103\n",
      " Regression with ARIMA(1,0,2) errors : -12626.77\n",
      " Regression with ARIMA(2,0,1) errors : -12625.53\n",
      " Regression with ARIMA(3,0,2) errors : -12685.73\n",
      " Regression with ARIMA(3,0,1) errors : -12637.75\n",
      " Regression with ARIMA(4,0,2) errors : -12654.14\n",
      " Regression with ARIMA(3,0,3) errors : -12654.51\n",
      " Regression with ARIMA(2,0,3) errors : -12650.91\n",
      " Regression with ARIMA(4,0,1) errors : -12654.37\n",
      " Regression with ARIMA(4,0,3) errors : -12686.13\n",
      " Regression with ARIMA(5,0,3) errors : -12700.25\n",
      " Regression with ARIMA(5,0,2) errors : -12654.47\n",
      " Regression with ARIMA(5,0,4) errors : -12662.71\n",
      " Regression with ARIMA(4,0,4) errors : -12698.47\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : -12673.47\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12629.83\n",
      " Regression with ARIMA(0,0,0) errors : -9123.342\n",
      " Regression with ARIMA(1,0,0) errors : -12606.52\n",
      " Regression with ARIMA(0,0,1) errors : -10778\n",
      " Regression with ARIMA(0,0,0) errors : -8105.722\n",
      " Regression with ARIMA(1,0,2) errors : -12626.01\n",
      " Regression with ARIMA(2,0,1) errors : -12624.6\n",
      " Regression with ARIMA(3,0,2) errors : -12689.93\n",
      " Regression with ARIMA(3,0,1) errors : -12636.27\n",
      " Regression with ARIMA(4,0,2) errors : -12652.8\n",
      " Regression with ARIMA(3,0,3) errors : -12653.27\n",
      " Regression with ARIMA(2,0,3) errors : -12649.98\n",
      " Regression with ARIMA(4,0,1) errors : -12652.27\n",
      " Regression with ARIMA(4,0,3) errors : -12694.07\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12670.15\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12654.04\n",
      " Regression with ARIMA(4,0,3) errors : -12618.5\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.06\n",
      " Regression with ARIMA(0,0,0) errors : -9131.681\n",
      " Regression with ARIMA(1,0,0) errors : -12608.01\n",
      " Regression with ARIMA(0,0,1) errors : -10782.66\n",
      " Regression with ARIMA(0,0,0) errors : -8107.119\n",
      " Regression with ARIMA(1,0,2) errors : -12628.11\n",
      " Regression with ARIMA(2,0,1) errors : -12626.67\n",
      " Regression with ARIMA(3,0,2) errors : -12693.49\n",
      " Regression with ARIMA(3,0,1) errors : -12638.11\n",
      " Regression with ARIMA(4,0,2) errors : -12655.3\n",
      " Regression with ARIMA(3,0,3) errors : -12655.92\n",
      " Regression with ARIMA(2,0,3) errors : -12652.11\n",
      " Regression with ARIMA(4,0,1) errors : -12653.8\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12610.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12696.06\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.24\n",
      " Regression with ARIMA(0,0,0) errors : -9131.239\n",
      " Regression with ARIMA(1,0,0) errors : -12606.95\n",
      " Regression with ARIMA(0,0,1) errors : -10780.44\n",
      " Regression with ARIMA(0,0,0) errors : -8112.5\n",
      " Regression with ARIMA(1,0,2) errors : -12627\n",
      " Regression with ARIMA(2,0,1) errors : -12625.5\n",
      " Regression with ARIMA(3,0,2) errors : -12689.64\n",
      " Regression with ARIMA(3,0,1) errors : -12638.39\n",
      " Regression with ARIMA(4,0,2) errors : -12654.7\n",
      " Regression with ARIMA(3,0,3) errors : -12654.57\n",
      " Regression with ARIMA(2,0,3) errors : -12650.34\n",
      " Regression with ARIMA(4,0,1) errors : -12654\n",
      " Regression with ARIMA(4,0,3) errors : -12691.8\n",
      " Regression with ARIMA(5,0,3) errors : -12674.84\n",
      " Regression with ARIMA(4,0,4) errors : -12670.68\n",
      " Regression with ARIMA(3,0,4) errors : -12676.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12662.77\n",
      " Regression with ARIMA(4,0,3) errors : -12620.21\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.43\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.92\n",
      " Regression with ARIMA(0,0,0) errors : -9128.861\n",
      " Regression with ARIMA(1,0,0) errors : -12610.07\n",
      " Regression with ARIMA(0,0,1) errors : -10783.53\n",
      " Regression with ARIMA(0,0,0) errors : -8110.608\n",
      " Regression with ARIMA(1,0,2) errors : -12629.79\n",
      " Regression with ARIMA(2,0,1) errors : -12628.8\n",
      " Regression with ARIMA(3,0,2) errors : -12690.81\n",
      " Regression with ARIMA(3,0,1) errors : -12640.88\n",
      " Regression with ARIMA(4,0,2) errors : -12657.06\n",
      " Regression with ARIMA(3,0,3) errors : -12657.59\n",
      " Regression with ARIMA(2,0,3) errors : -12654.11\n",
      " Regression with ARIMA(4,0,1) errors : -12656.04\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12597.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12697.96\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12634.62\n",
      " Regression with ARIMA(0,0,0) errors : -9126.781\n",
      " Regression with ARIMA(1,0,0) errors : -12610.65\n",
      " Regression with ARIMA(0,0,1) errors : -10781.97\n",
      " Regression with ARIMA(0,0,0) errors : -8113.142\n",
      " Regression with ARIMA(1,0,2) errors : -12630.54\n",
      " Regression with ARIMA(2,0,1) errors : -12629.23\n",
      " Regression with ARIMA(3,0,2) errors : -12696.42\n",
      " Regression with ARIMA(3,0,1) errors : -12641.18\n",
      " Regression with ARIMA(4,0,2) errors : -12657.47\n",
      " Regression with ARIMA(3,0,3) errors : -12658.27\n",
      " Regression with ARIMA(2,0,3) errors : -12654.69\n",
      " Regression with ARIMA(4,0,1) errors : -12656.72\n",
      " Regression with ARIMA(4,0,3) errors : -12703.68\n",
      " Regression with ARIMA(5,0,3) errors : -12677.09\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12669.72\n",
      " Regression with ARIMA(4,0,3) errors : -12577.74\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.4\n",
      " Regression with ARIMA(0,0,0) errors : -9125.689\n",
      " Regression with ARIMA(1,0,0) errors : -12612.41\n",
      " Regression with ARIMA(0,0,1) errors : -10783.44\n",
      " Regression with ARIMA(0,0,0) errors : -8112.957\n",
      " Regression with ARIMA(1,0,2) errors : -12632.37\n",
      " Regression with ARIMA(2,0,1) errors : -12631.02\n",
      " Regression with ARIMA(3,0,2) errors : -12698.98\n",
      " Regression with ARIMA(3,0,1) errors : -12642.99\n",
      " Regression with ARIMA(4,0,2) errors : -12659.39\n",
      " Regression with ARIMA(3,0,3) errors : -12660.05\n",
      " Regression with ARIMA(2,0,3) errors : -12656.41\n",
      " Regression with ARIMA(4,0,1) errors : -12658.4\n",
      " Regression with ARIMA(4,0,3) errors : -12705.73\n",
      " Regression with ARIMA(5,0,3) errors : -12677.06\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12682.47\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12672.68\n",
      " Regression with ARIMA(4,0,3) errors : -12592.32\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.68\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.3\n",
      " Regression with ARIMA(0,0,0) errors : -9115.868\n",
      " Regression with ARIMA(1,0,0) errors : -12611.51\n",
      " Regression with ARIMA(0,0,1) errors : -10777.8\n",
      " Regression with ARIMA(0,0,0) errors : -8111.841\n",
      " Regression with ARIMA(1,0,2) errors : -12631.09\n",
      " Regression with ARIMA(2,0,1) errors : -12629.64\n",
      " Regression with ARIMA(3,0,2) errors : -12698.43\n",
      " Regression with ARIMA(3,0,1) errors : -12641.39\n",
      " Regression with ARIMA(4,0,2) errors : -12658.34\n",
      " Regression with ARIMA(3,0,3) errors : -12658.92\n",
      " Regression with ARIMA(2,0,3) errors : -12655.53\n",
      " Regression with ARIMA(4,0,1) errors : -12657.54\n",
      " Regression with ARIMA(4,0,3) errors : -12704.55\n",
      " Regression with ARIMA(5,0,3) errors : -12677.45\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12671.36\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.66\n",
      " Regression with ARIMA(0,0,0) errors : -9124.945\n",
      " Regression with ARIMA(1,0,0) errors : -12612.72\n",
      " Regression with ARIMA(0,0,1) errors : -10780.08\n",
      " Regression with ARIMA(0,0,0) errors : -8108.834\n",
      " Regression with ARIMA(1,0,2) errors : -12632.51\n",
      " Regression with ARIMA(2,0,1) errors : -12631.82\n",
      " Regression with ARIMA(3,0,2) errors : -12694.27\n",
      " Regression with ARIMA(3,0,1) errors : -12643.59\n",
      " Regression with ARIMA(4,0,2) errors : -12660.23\n",
      " Regression with ARIMA(3,0,3) errors : -12660.57\n",
      " Regression with ARIMA(2,0,3) errors : -12657.73\n",
      " Regression with ARIMA(4,0,1) errors : -12659.39\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12588.55\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.13\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12627.74\n",
      " Regression with ARIMA(0,0,0) errors : -9117.039\n",
      " Regression with ARIMA(1,0,0) errors : -12604.36\n",
      " Regression with ARIMA(0,0,1) errors : -10772.74\n",
      " Regression with ARIMA(0,0,0) errors : -8100.168\n",
      " Regression with ARIMA(1,0,2) errors : -12624.03\n",
      " Regression with ARIMA(2,0,1) errors : -12622.73\n",
      " Regression with ARIMA(3,0,2) errors : -12688.87\n",
      " Regression with ARIMA(3,0,1) errors : -12635.29\n",
      " Regression with ARIMA(4,0,2) errors : -12652.41\n",
      " Regression with ARIMA(3,0,3) errors : -12652.42\n",
      " Regression with ARIMA(2,0,3) errors : -12648.98\n",
      " Regression with ARIMA(4,0,1) errors : -12651.73\n",
      " Regression with ARIMA(4,0,3) errors : -12695.02\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12668.42\n",
      " Regression with ARIMA(3,0,4) errors : -12666.86\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12662.55\n",
      " Regression with ARIMA(4,0,3) errors : -12583.67\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12692.62\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12629.95\n",
      " Regression with ARIMA(0,0,0) errors : -9111.839\n",
      " Regression with ARIMA(1,0,0) errors : -12606.59\n",
      " Regression with ARIMA(0,0,1) errors : -10768.97\n",
      " Regression with ARIMA(0,0,0) errors : -8094.359\n",
      " Regression with ARIMA(1,0,2) errors : -12626.11\n",
      " Regression with ARIMA(2,0,1) errors : -12624.99\n",
      " Regression with ARIMA(3,0,2) errors : -12691.49\n",
      " Regression with ARIMA(3,0,1) errors : -12636.29\n",
      " Regression with ARIMA(4,0,2) errors : -12654.61\n",
      " Regression with ARIMA(3,0,3) errors : -12655.25\n",
      " Regression with ARIMA(2,0,3) errors : -12651.79\n",
      " Regression with ARIMA(4,0,1) errors : -12653.54\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12606.28\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12694.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12625.86\n",
      " Regression with ARIMA(0,0,0) errors : -9104.057\n",
      " Regression with ARIMA(1,0,0) errors : -12602.52\n",
      " Regression with ARIMA(0,0,1) errors : -10763.32\n",
      " Regression with ARIMA(0,0,0) errors : -8093.859\n",
      " Regression with ARIMA(1,0,2) errors : -12621.83\n",
      " Regression with ARIMA(2,0,1) errors : -12620.75\n",
      " Regression with ARIMA(3,0,2) errors : -12688.22\n",
      " Regression with ARIMA(3,0,1) errors : -12631.52\n",
      " Regression with ARIMA(4,0,2) errors : -12652.06\n",
      " Regression with ARIMA(3,0,3) errors : -12650.46\n",
      " Regression with ARIMA(2,0,3) errors : -12647.56\n",
      " Regression with ARIMA(4,0,1) errors : -12651.23\n",
      " Regression with ARIMA(4,0,3) errors : -12681.28\n",
      " Regression with ARIMA(3,0,2) errors : -12603.68\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12690.63\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12618.91\n",
      " Regression with ARIMA(0,0,0) errors : -9103.363\n",
      " Regression with ARIMA(1,0,0) errors : -12597.31\n",
      " Regression with ARIMA(0,0,1) errors : -10765.68\n",
      " Regression with ARIMA(0,0,0) errors : -8091.292\n",
      " Regression with ARIMA(1,0,2) errors : -12615.19\n",
      " Regression with ARIMA(2,0,1) errors : -12613.85\n",
      " Regression with ARIMA(3,0,2) errors : -12682.31\n",
      " Regression with ARIMA(3,0,1) errors : -12625.35\n",
      " Regression with ARIMA(4,0,2) errors : -12644.79\n",
      " Regression with ARIMA(3,0,3) errors : -12644.37\n",
      " Regression with ARIMA(2,0,3) errors : -12640.45\n",
      " Regression with ARIMA(4,0,1) errors : -12643.65\n",
      " Regression with ARIMA(4,0,3) errors : -12682.08\n",
      " Regression with ARIMA(3,0,2) errors : -12580.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12684.69\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12615.06\n",
      " Regression with ARIMA(0,0,0) errors : -9099.58\n",
      " Regression with ARIMA(1,0,0) errors : -12592.84\n",
      " Regression with ARIMA(0,0,1) errors : -10762.48\n",
      " Regression with ARIMA(0,0,0) errors : -8087.004\n",
      " Regression with ARIMA(1,0,2) errors : -12610.83\n",
      " Regression with ARIMA(2,0,1) errors : -12609.67\n",
      " Regression with ARIMA(3,0,2) errors : -12677.21\n",
      " Regression with ARIMA(3,0,1) errors : -12621.08\n",
      " Regression with ARIMA(4,0,2) errors : -12640.17\n",
      " Regression with ARIMA(3,0,3) errors : -12640.85\n",
      " Regression with ARIMA(2,0,3) errors : -12636.93\n",
      " Regression with ARIMA(4,0,1) errors : -12638.83\n",
      " Regression with ARIMA(4,0,3) errors : -12684.27\n",
      " Regression with ARIMA(5,0,3) errors : -12658.04\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12639.53\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12654.82\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12680.01\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12613.46\n",
      " Regression with ARIMA(0,0,0) errors : -9099.695\n",
      " Regression with ARIMA(1,0,0) errors : -12591.66\n",
      " Regression with ARIMA(0,0,1) errors : -10763.22\n",
      " Regression with ARIMA(0,0,0) errors : -8089.962\n",
      " Regression with ARIMA(1,0,2) errors : -12609.68\n",
      " Regression with ARIMA(2,0,1) errors : -12608.39\n",
      " Regression with ARIMA(3,0,2) errors : -12677.01\n",
      " Regression with ARIMA(3,0,1) errors : -12619.63\n",
      " Regression with ARIMA(4,0,2) errors : -12638.73\n",
      " Regression with ARIMA(3,0,3) errors : -12639.14\n",
      " Regression with ARIMA(2,0,3) errors : -12635.44\n",
      " Regression with ARIMA(4,0,1) errors : -12637.36\n",
      " Regression with ARIMA(4,0,3) errors : -12681.2\n",
      " Regression with ARIMA(5,0,3) errors : -12656.69\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12660.48\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12652.18\n",
      " Regression with ARIMA(4,0,3) errors : -12597.54\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12678.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12615.16\n",
      " Regression with ARIMA(0,0,0) errors : -9100.818\n",
      " Regression with ARIMA(1,0,0) errors : -12593.22\n",
      " Regression with ARIMA(0,0,1) errors : -10765.31\n",
      " Regression with ARIMA(0,0,0) errors : -8091.06\n",
      " Regression with ARIMA(1,0,2) errors : -12611.24\n",
      " Regression with ARIMA(2,0,1) errors : -12609.93\n",
      " Regression with ARIMA(3,0,2) errors : -12679.3\n",
      " Regression with ARIMA(3,0,1) errors : -12621.06\n",
      " Regression with ARIMA(4,0,2) errors : -12639.78\n",
      " Regression with ARIMA(3,0,3) errors : -12640.43\n",
      " Regression with ARIMA(2,0,3) errors : -12636.97\n",
      " Regression with ARIMA(4,0,1) errors : -12638.66\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12594.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12679.67\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12617.12\n",
      " Regression with ARIMA(0,0,0) errors : -9109.583\n",
      " Regression with ARIMA(1,0,0) errors : -12595.07\n",
      " Regression with ARIMA(0,0,1) errors : -10771.08\n",
      " Regression with ARIMA(0,0,0) errors : -8093.37\n",
      " Regression with ARIMA(1,0,2) errors : -12613.21\n",
      " Regression with ARIMA(2,0,1) errors : -12611.88\n",
      " Regression with ARIMA(3,0,2) errors : -12678.72\n",
      " Regression with ARIMA(3,0,1) errors : -12623\n",
      " Regression with ARIMA(4,0,2) errors : -12641.23\n",
      " Regression with ARIMA(3,0,3) errors : -12641.89\n",
      " Regression with ARIMA(2,0,3) errors : -12638.42\n",
      " Regression with ARIMA(4,0,1) errors : -12640.06\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12592.8\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12681.68\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12619.74\n",
      " Regression with ARIMA(0,0,0) errors : -9112.072\n",
      " Regression with ARIMA(1,0,0) errors : -12597.43\n",
      " Regression with ARIMA(0,0,1) errors : -10771.67\n",
      " Regression with ARIMA(0,0,0) errors : -8099.27\n",
      " Regression with ARIMA(1,0,2) errors : -12615.95\n",
      " Regression with ARIMA(2,0,1) errors : -12614.81\n",
      " Regression with ARIMA(3,0,2) errors : -12684.97\n",
      " Regression with ARIMA(3,0,1) errors : -12626.06\n",
      " Regression with ARIMA(4,0,2) errors : -12644.83\n",
      " Regression with ARIMA(3,0,3) errors : -12645.37\n",
      " Regression with ARIMA(2,0,3) errors : -12641.62\n",
      " Regression with ARIMA(4,0,1) errors : -12643.67\n",
      " Regression with ARIMA(4,0,3) errors : -12690.35\n",
      " Regression with ARIMA(5,0,3) errors : -12663.66\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12668.79\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12658.85\n",
      " Regression with ARIMA(4,0,3) errors : -12609.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12685.05\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12619.78\n",
      " Regression with ARIMA(0,0,0) errors : -9111.436\n",
      " Regression with ARIMA(1,0,0) errors : -12596.51\n",
      " Regression with ARIMA(0,0,1) errors : -10769.82\n",
      " Regression with ARIMA(0,0,0) errors : -8099.19\n",
      " Regression with ARIMA(1,0,2) errors : -12615.12\n",
      " Regression with ARIMA(2,0,1) errors : -12615.29\n",
      " Regression with ARIMA(3,0,2) errors : -12677.01\n",
      " Regression with ARIMA(3,0,1) errors : -12626.47\n",
      " Regression with ARIMA(4,0,2) errors : -12646.5\n",
      " Regression with ARIMA(3,0,3) errors : -12647.04\n",
      " Regression with ARIMA(2,0,3) errors : -12642.14\n",
      " Regression with ARIMA(4,0,1) errors : -12644.59\n",
      " Regression with ARIMA(4,0,3) errors : -12686.33\n",
      " Regression with ARIMA(5,0,3) errors : -12661.66\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12668.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12657.53\n",
      " Regression with ARIMA(4,0,3) errors : -12608.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12683.18\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12616.6\n",
      " Regression with ARIMA(0,0,0) errors : -9093.993\n",
      " Regression with ARIMA(1,0,0) errors : -12593.32\n",
      " Regression with ARIMA(0,0,1) errors : -10754.58\n",
      " Regression with ARIMA(0,0,0) errors : -8057.969\n",
      " Regression with ARIMA(1,0,2) errors : -12612.81\n",
      " Regression with ARIMA(2,0,1) errors : -12611.61\n",
      " Regression with ARIMA(3,0,2) errors : -12678.85\n",
      " Regression with ARIMA(3,0,1) errors : -12622.82\n",
      " Regression with ARIMA(4,0,2) errors : -12641.44\n",
      " Regression with ARIMA(3,0,3) errors : -12642.14\n",
      " Regression with ARIMA(2,0,3) errors : -12638.25\n",
      " Regression with ARIMA(4,0,1) errors : -12639.95\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12583.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12680.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12583.96\n",
      " Regression with ARIMA(0,0,0) errors : -9092.613\n",
      " Regression with ARIMA(1,0,0) errors : -12563.7\n",
      " Regression with ARIMA(0,0,1) errors : -10747.78\n",
      " Regression with ARIMA(0,0,0) errors : -8051.218\n",
      " Regression with ARIMA(1,0,2) errors : -12580.28\n",
      " Regression with ARIMA(2,0,1) errors : -12579.03\n",
      " Regression with ARIMA(3,0,2) errors : -12646.7\n",
      " Regression with ARIMA(3,0,1) errors : -12589.65\n",
      " Regression with ARIMA(4,0,2) errors : -12606.27\n",
      " Regression with ARIMA(3,0,3) errors : -12606.89\n",
      " Regression with ARIMA(2,0,3) errors : -12603.05\n",
      " Regression with ARIMA(4,0,1) errors : -12604.75\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12556.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12648.35\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12577.66\n",
      " Regression with ARIMA(0,0,0) errors : -9095.204\n",
      " Regression with ARIMA(1,0,0) errors : -12557.4\n",
      " Regression with ARIMA(0,0,1) errors : -10745.91\n",
      " Regression with ARIMA(0,0,0) errors : -8037.239\n",
      " Regression with ARIMA(1,0,2) errors : -12573.72\n",
      " Regression with ARIMA(2,0,1) errors : -12572.35\n",
      " Regression with ARIMA(3,0,2) errors : -12641.2\n",
      " Regression with ARIMA(3,0,1) errors : -12583.1\n",
      " Regression with ARIMA(4,0,2) errors : -12600.41\n",
      " Regression with ARIMA(3,0,3) errors : -12601.11\n",
      " Regression with ARIMA(2,0,3) errors : -12597.21\n",
      " Regression with ARIMA(4,0,1) errors : -12599.03\n",
      " Regression with ARIMA(4,0,3) errors : -12644.07\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12622.13\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12612.01\n",
      " Regression with ARIMA(4,0,3) errors : -12563.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12642.54\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12575.52\n",
      " Regression with ARIMA(0,0,0) errors : -9101.37\n",
      " Regression with ARIMA(1,0,0) errors : -12554.94\n",
      " Regression with ARIMA(0,0,1) errors : -10747.52\n",
      " Regression with ARIMA(0,0,0) errors : -8033.351\n",
      " Regression with ARIMA(1,0,2) errors : -12571.38\n",
      " Regression with ARIMA(2,0,1) errors : -12570.05\n",
      " Regression with ARIMA(3,0,2) errors : -12638.35\n",
      " Regression with ARIMA(3,0,1) errors : -12581.07\n",
      " Regression with ARIMA(4,0,2) errors : -12598.59\n",
      " Regression with ARIMA(3,0,3) errors : -12599.01\n",
      " Regression with ARIMA(2,0,3) errors : -12595.34\n",
      " Regression with ARIMA(4,0,1) errors : -12597.11\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12519.88\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12639.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12565.83\n",
      " Regression with ARIMA(0,0,0) errors : -9101.364\n",
      " Regression with ARIMA(1,0,0) errors : -12545.42\n",
      " Regression with ARIMA(0,0,1) errors : -10744.99\n",
      " Regression with ARIMA(0,0,0) errors : -8028.435\n",
      " Regression with ARIMA(1,0,2) errors : -12561.69\n",
      " Regression with ARIMA(2,0,1) errors : -12560.33\n",
      " Regression with ARIMA(3,0,2) errors : -12625.38\n",
      " Regression with ARIMA(3,0,1) errors : -12571.55\n",
      " Regression with ARIMA(4,0,2) errors : -12589.48\n",
      " Regression with ARIMA(3,0,3) errors : -12589.91\n",
      " Regression with ARIMA(2,0,3) errors : -12585.25\n",
      " Regression with ARIMA(4,0,1) errors : -12587.54\n",
      " Regression with ARIMA(4,0,3) errors : -12629.39\n",
      " Regression with ARIMA(5,0,3) errors : -12606.27\n",
      " Regression with ARIMA(4,0,4) errors : -12632.75\n",
      " Regression with ARIMA(3,0,4) errors : -12604.33\n",
      " Regression with ARIMA(5,0,4) errors : -12602.45\n",
      " Regression with ARIMA(4,0,5) errors : -12606.94\n",
      " Regression with ARIMA(3,0,5) errors : -12601.51\n",
      " Regression with ARIMA(5,0,5) errors : -12608.1\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12629.36\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12550.88\n",
      " Regression with ARIMA(0,0,0) errors : -9082.974\n",
      " Regression with ARIMA(1,0,0) errors : -12530.87\n",
      " Regression with ARIMA(0,0,1) errors : -10726.19\n",
      " Regression with ARIMA(0,0,0) errors : -7990.949\n",
      " Regression with ARIMA(1,0,2) errors : -12547.22\n",
      " Regression with ARIMA(2,0,1) errors : -12546.03\n",
      " Regression with ARIMA(3,0,2) errors : -12611.03\n",
      " Regression with ARIMA(3,0,1) errors : -12556.14\n",
      " Regression with ARIMA(4,0,2) errors : -12573.38\n",
      " Regression with ARIMA(3,0,3) errors : -12573.93\n",
      " Regression with ARIMA(2,0,3) errors : -12570.37\n",
      " Regression with ARIMA(4,0,1) errors : -12572.13\n",
      " Regression with ARIMA(4,0,3) errors : -12616.54\n",
      " Regression with ARIMA(5,0,3) errors : -12590.07\n",
      " Regression with ARIMA(4,0,4) errors : -12620.02\n",
      " Regression with ARIMA(3,0,4) errors : -12593.33\n",
      " Regression with ARIMA(5,0,4) errors : -12585.19\n",
      " Regression with ARIMA(4,0,5) errors : -12590.96\n",
      " Regression with ARIMA(3,0,5) errors : -12586.08\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12613.46\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12541.98\n",
      " Regression with ARIMA(0,0,0) errors : -9085.693\n",
      " Regression with ARIMA(1,0,0) errors : -12521.52\n",
      " Regression with ARIMA(0,0,1) errors : -10727.61\n",
      " Regression with ARIMA(0,0,0) errors : -7984.545\n",
      " Regression with ARIMA(1,0,2) errors : -12537.92\n",
      " Regression with ARIMA(2,0,1) errors : -12537.24\n",
      " Regression with ARIMA(3,0,2) errors : -12601.89\n",
      " Regression with ARIMA(3,0,1) errors : -12547.19\n",
      " Regression with ARIMA(4,0,2) errors : -12564.24\n",
      " Regression with ARIMA(3,0,3) errors : -12564.26\n",
      " Regression with ARIMA(2,0,3) errors : -12561.62\n",
      " Regression with ARIMA(4,0,1) errors : -12563.37\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12499.3\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12602.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.96\n",
      " Regression with ARIMA(0,0,0) errors : -9090.727\n",
      " Regression with ARIMA(1,0,0) errors : -12524.23\n",
      " Regression with ARIMA(0,0,1) errors : -10729.14\n",
      " Regression with ARIMA(0,0,0) errors : -7988.192\n",
      " Regression with ARIMA(1,0,2) errors : -12541.23\n",
      " Regression with ARIMA(2,0,1) errors : -12541.2\n",
      " Regression with ARIMA(3,0,2) errors : -12596.53\n",
      " Regression with ARIMA(3,0,1) errors : -12551.61\n",
      " Regression with ARIMA(4,0,2) errors : -12568.27\n",
      " Regression with ARIMA(3,0,3) errors : -12568.72\n",
      " Regression with ARIMA(2,0,3) errors : -12565.53\n",
      " Regression with ARIMA(4,0,1) errors : -12567.05\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12496.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12605.49\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12548.88\n",
      " Regression with ARIMA(0,0,0) errors : -9100.305\n",
      " Regression with ARIMA(1,0,0) errors : -12527.5\n",
      " Regression with ARIMA(0,0,1) errors : -10736.35\n",
      " Regression with ARIMA(0,0,0) errors : -7988.759\n",
      " Regression with ARIMA(1,0,2) errors : -12544.66\n",
      " Regression with ARIMA(2,0,1) errors : -12543.65\n",
      " Regression with ARIMA(3,0,2) errors : -12605.4\n",
      " Regression with ARIMA(3,0,1) errors : -12554.44\n",
      " Regression with ARIMA(4,0,2) errors : -12571.11\n",
      " Regression with ARIMA(3,0,3) errors : -12571.91\n",
      " Regression with ARIMA(2,0,3) errors : -12568.5\n",
      " Regression with ARIMA(4,0,1) errors : -12570.06\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12504.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12608.79\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.27\n",
      " Regression with ARIMA(0,0,0) errors : -9095.28\n",
      " Regression with ARIMA(1,0,0) errors : -12526.27\n",
      " Regression with ARIMA(0,0,1) errors : -10733.95\n",
      " Regression with ARIMA(0,0,0) errors : -7985.631\n",
      " Regression with ARIMA(1,0,2) errors : -12543.29\n",
      " Regression with ARIMA(2,0,1) errors : -12541.96\n",
      " Regression with ARIMA(3,0,2) errors : -12605.92\n",
      " Regression with ARIMA(3,0,1) errors : -12552.76\n",
      " Regression with ARIMA(4,0,2) errors : -12569.38\n",
      " Regression with ARIMA(3,0,3) errors : -12569.97\n",
      " Regression with ARIMA(2,0,3) errors : -12566.62\n",
      " Regression with ARIMA(4,0,1) errors : -12568.51\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12514.77\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12607.57\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12551.72\n",
      " Regression with ARIMA(0,0,0) errors : -9094.616\n",
      " Regression with ARIMA(1,0,0) errors : -12527.72\n",
      " Regression with ARIMA(0,0,1) errors : -10731.91\n",
      " Regression with ARIMA(0,0,0) errors : -7984.814\n",
      " Regression with ARIMA(1,0,2) errors : -12544.83\n",
      " Regression with ARIMA(2,0,1) errors : -12545.69\n",
      " Regression with ARIMA(3,0,2) errors : -12599.12\n",
      " Regression with ARIMA(3,0,1) errors : -12556.69\n",
      " Regression with ARIMA(4,0,2) errors : -12574.58\n",
      " Regression with ARIMA(3,0,3) errors : -12572.21\n",
      " Regression with ARIMA(2,0,3) errors : -12570.48\n",
      " Regression with ARIMA(4,0,1) errors : -12574.57\n",
      " Regression with ARIMA(4,0,3) errors : -12602.14\n",
      " Regression with ARIMA(5,0,3) errors : -12593.97\n",
      " Regression with ARIMA(4,0,4) errors : -12614.31\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12592.12\n",
      " Regression with ARIMA(4,0,5) errors : -12613.12\n",
      " Regression with ARIMA(3,0,5) errors : -12593.98\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -12615.97\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.25\n",
      " Regression with ARIMA(0,0,0) errors : -9103.285\n",
      " Regression with ARIMA(1,0,0) errors : -12525.6\n",
      " Regression with ARIMA(0,0,1) errors : -10740.02\n",
      " Regression with ARIMA(0,0,0) errors : -7987.126\n",
      " Regression with ARIMA(1,0,2) errors : -12542.63\n",
      " Regression with ARIMA(2,0,1) errors : -12541.09\n",
      " Regression with ARIMA(3,0,2) errors : -12595.27\n",
      " Regression with ARIMA(3,0,1) errors : -12553.61\n",
      " Regression with ARIMA(4,0,2) errors : -12567.35\n",
      " Regression with ARIMA(3,0,3) errors : -12568.1\n",
      " Regression with ARIMA(2,0,3) errors : -12564.84\n",
      " Regression with ARIMA(4,0,1) errors : -12567.61\n",
      " Regression with ARIMA(4,0,3) errors : -12599.93\n",
      " Regression with ARIMA(5,0,3) errors : -12585.25\n",
      " Regression with ARIMA(4,0,4) errors : -12587.13\n",
      " Regression with ARIMA(3,0,4) errors : -12586.59\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12587.56\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12603.94\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12563.76\n",
      " Regression with ARIMA(0,0,0) errors : -9114.748\n",
      " Regression with ARIMA(1,0,0) errors : -12542.44\n",
      " Regression with ARIMA(0,0,1) errors : -10750.26\n",
      " Regression with ARIMA(0,0,0) errors : -7996.79\n",
      " Regression with ARIMA(1,0,2) errors : -12559.52\n",
      " Regression with ARIMA(2,0,1) errors : -12557.88\n",
      " Regression with ARIMA(3,0,2) errors : -12623.24\n",
      " Regression with ARIMA(3,0,1) errors : -12569.07\n",
      " Regression with ARIMA(4,0,2) errors : -12584.06\n",
      " Regression with ARIMA(3,0,3) errors : -12584.83\n",
      " Regression with ARIMA(2,0,3) errors : -12581.2\n",
      " Regression with ARIMA(4,0,1) errors : -12583.59\n",
      " Regression with ARIMA(4,0,3) errors : -12622.16\n",
      " Regression with ARIMA(3,0,2) errors : -12529.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12623.55\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12571.66\n",
      " Regression with ARIMA(0,0,0) errors : -9119.255\n",
      " Regression with ARIMA(1,0,0) errors : -12550.63\n",
      " Regression with ARIMA(0,0,1) errors : -10754.38\n",
      " Regression with ARIMA(0,0,0) errors : -7999.828\n",
      " Regression with ARIMA(1,0,2) errors : -12567.56\n",
      " Regression with ARIMA(2,0,1) errors : -12565.97\n",
      " Regression with ARIMA(3,0,2) errors : -12623.38\n",
      " Regression with ARIMA(3,0,1) errors : -12577.61\n",
      " Regression with ARIMA(4,0,2) errors : -12592.71\n",
      " Regression with ARIMA(3,0,3) errors : -12593.33\n",
      " Regression with ARIMA(2,0,3) errors : -12589.24\n",
      " Regression with ARIMA(4,0,1) errors : -12591.99\n",
      " Regression with ARIMA(4,0,3) errors : -12628.14\n",
      " Regression with ARIMA(5,0,3) errors : -12611.42\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12608.22\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12601.46\n",
      " Regression with ARIMA(4,0,3) errors : -12518.46\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12632.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12570.69\n",
      " Regression with ARIMA(0,0,0) errors : -9115.278\n",
      " Regression with ARIMA(1,0,0) errors : -12549.82\n",
      " Regression with ARIMA(0,0,1) errors : -10753.47\n",
      " Regression with ARIMA(0,0,0) errors : -8003.712\n",
      " Regression with ARIMA(1,0,2) errors : -12566.64\n",
      " Regression with ARIMA(2,0,1) errors : -12564.99\n",
      " Regression with ARIMA(3,0,2) errors : -12627.12\n",
      " Regression with ARIMA(3,0,1) errors : -12576.67\n",
      " Regression with ARIMA(4,0,2) errors : -12592.86\n",
      " Regression with ARIMA(3,0,3) errors : -12593.53\n",
      " Regression with ARIMA(2,0,3) errors : -12588.09\n",
      " Regression with ARIMA(4,0,1) errors : -12591.37\n",
      " Regression with ARIMA(4,0,3) errors : -12631.06\n",
      " Regression with ARIMA(5,0,3) errors : -12608.52\n",
      " Regression with ARIMA(4,0,4) errors : -12636.78\n",
      " Regression with ARIMA(3,0,4) errors : -12595.05\n",
      " Regression with ARIMA(5,0,4) errors : -12606.13\n",
      " Regression with ARIMA(4,0,5) errors : -12611.46\n",
      " Regression with ARIMA(3,0,5) errors : -12589.1\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12631.52\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12578.38\n",
      " Regression with ARIMA(0,0,0) errors : -9111.17\n",
      " Regression with ARIMA(1,0,0) errors : -12558.92\n",
      " Regression with ARIMA(0,0,1) errors : -10753.78\n",
      " Regression with ARIMA(0,0,0) errors : -8020.573\n",
      " Regression with ARIMA(1,0,2) errors : -12574.68\n",
      " Regression with ARIMA(2,0,1) errors : -12573.05\n",
      " Regression with ARIMA(3,0,2) errors : -12623.18\n",
      " Regression with ARIMA(3,0,1) errors : -12586.14\n",
      " Regression with ARIMA(4,0,2) errors : -12599.85\n",
      " Regression with ARIMA(3,0,3) errors : -12600.52\n",
      " Regression with ARIMA(2,0,3) errors : -12595.7\n",
      " Regression with ARIMA(4,0,1) errors : -12599.55\n",
      " Regression with ARIMA(4,0,3) errors : -12630.95\n",
      " Regression with ARIMA(5,0,3) errors : -12614.41\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12610.87\n",
      " Regression with ARIMA(5,0,2) errors : -12611.96\n",
      " Regression with ARIMA(5,0,4) errors : -12609.33\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12639.79\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12589.89\n",
      " Regression with ARIMA(0,0,0) errors : -9118.887\n",
      " Regression with ARIMA(1,0,0) errors : -12570.44\n",
      " Regression with ARIMA(0,0,1) errors : -10762.54\n",
      " Regression with ARIMA(0,0,0) errors : -8023.134\n",
      " Regression with ARIMA(1,0,2) errors : -12586.06\n",
      " Regression with ARIMA(2,0,1) errors : -12584.58\n",
      " Regression with ARIMA(3,0,2) errors : -12650.24\n",
      " Regression with ARIMA(3,0,1) errors : -12595.09\n",
      " Regression with ARIMA(4,0,2) errors : -12610.13\n",
      " Regression with ARIMA(3,0,3) errors : -12611.25\n",
      " Regression with ARIMA(2,0,3) errors : -12607.47\n",
      " Regression with ARIMA(4,0,1) errors : -12610.04\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12562.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12652.57\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12605.76\n",
      " Regression with ARIMA(0,0,0) errors : -9124.298\n",
      " Regression with ARIMA(1,0,0) errors : -12585.84\n",
      " Regression with ARIMA(0,0,1) errors : -10776.69\n",
      " Regression with ARIMA(0,0,0) errors : -8072.897\n",
      " Regression with ARIMA(1,0,2) errors : -12601.79\n",
      " Regression with ARIMA(2,0,1) errors : -12600.13\n",
      " Regression with ARIMA(3,0,2) errors : -12662.69\n",
      " Regression with ARIMA(3,0,1) errors : -12612.34\n",
      " Regression with ARIMA(4,0,2) errors : -12629.9\n",
      " Regression with ARIMA(3,0,3) errors : -12629.01\n",
      " Regression with ARIMA(2,0,3) errors : -12623.63\n",
      " Regression with ARIMA(4,0,1) errors : -12627.83\n",
      " Regression with ARIMA(4,0,3) errors : -12662.1\n",
      " Regression with ARIMA(3,0,2) errors : -12538.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12668.81\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12617.98\n",
      " Regression with ARIMA(0,0,0) errors : -9103.826\n",
      " Regression with ARIMA(1,0,0) errors : -12597.39\n",
      " Regression with ARIMA(0,0,1) errors : -10769.07\n",
      " Regression with ARIMA(0,0,0) errors : -8071.78\n",
      " Regression with ARIMA(1,0,2) errors : -12613.58\n",
      " Regression with ARIMA(2,0,1) errors : -12612.03\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12634.81\n",
      " Regression with ARIMA(1,0,3) errors : -12637.74\n",
      " Regression with ARIMA(0,0,3) errors : -11857.74\n",
      " Regression with ARIMA(1,0,4) errors : -12635.79\n",
      " Regression with ARIMA(0,0,2) errors : -11425.89\n",
      " Regression with ARIMA(0,0,4) errors : -12183.34\n",
      " Regression with ARIMA(2,0,4) errors : -12660.74\n",
      " Regression with ARIMA(3,0,4) errors : -12661.91\n",
      " Regression with ARIMA(3,0,3) errors : -12639.57\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12664.79\n",
      " Regression with ARIMA(1,0,5) errors : -12637.48\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12662.8\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12648.96\n",
      " Regression with ARIMA(0,0,0) errors : -9121.032\n",
      " Regression with ARIMA(1,0,0) errors : -12628.13\n",
      " Regression with ARIMA(0,0,1) errors : -10785.99\n",
      " Regression with ARIMA(0,0,0) errors : -8086.924\n",
      " Regression with ARIMA(1,0,2) errors : -12643.58\n",
      " Regression with ARIMA(2,0,1) errors : -12645.29\n",
      " Regression with ARIMA(3,0,2) errors : -12693.39\n",
      " Regression with ARIMA(3,0,1) errors : -12657.07\n",
      " Regression with ARIMA(4,0,2) errors : -12674.99\n",
      " Regression with ARIMA(3,0,3) errors : -12674.05\n",
      " Regression with ARIMA(2,0,3) errors : -12670.13\n",
      " Regression with ARIMA(4,0,1) errors : -12673.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12586.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12712.63\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12660.79\n",
      " Regression with ARIMA(0,0,0) errors : -9128.864\n",
      " Regression with ARIMA(1,0,0) errors : -12639.5\n",
      " Regression with ARIMA(0,0,1) errors : -10794.45\n",
      " Regression with ARIMA(0,0,0) errors : -8086.79\n",
      " Regression with ARIMA(1,0,2) errors : -12656.36\n",
      " Regression with ARIMA(2,0,1) errors : -12654.67\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12681.02\n",
      " Regression with ARIMA(1,0,3) errors : -12683.93\n",
      " Regression with ARIMA(0,0,3) errors : -11882.7\n",
      " Regression with ARIMA(1,0,4) errors : -12681.93\n",
      " Regression with ARIMA(0,0,2) errors : -11451.05\n",
      " Regression with ARIMA(0,0,4) errors : -12222.24\n",
      " Regression with ARIMA(2,0,4) errors : -12708.43\n",
      " Regression with ARIMA(3,0,4) errors : -12700.64\n",
      " Regression with ARIMA(2,0,5) errors : -12711.77\n",
      " Regression with ARIMA(1,0,5) errors : -12684.46\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12635.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12712.16\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12663.87\n",
      " Regression with ARIMA(0,0,0) errors : -9125.032\n",
      " Regression with ARIMA(1,0,0) errors : -12642.83\n",
      " Regression with ARIMA(0,0,1) errors : -10795.06\n",
      " Regression with ARIMA(0,0,0) errors : -8088.558\n",
      " Regression with ARIMA(1,0,2) errors : -12659.49\n",
      " Regression with ARIMA(2,0,1) errors : -12657.96\n",
      " Regression with ARIMA(3,0,2) errors : -12717.9\n",
      " Regression with ARIMA(3,0,1) errors : -12671.05\n",
      " Regression with ARIMA(4,0,2) errors : -12688.31\n",
      " Regression with ARIMA(3,0,3) errors : -12688.66\n",
      " Regression with ARIMA(2,0,3) errors : -12684.8\n",
      " Regression with ARIMA(4,0,1) errors : -12687.93\n",
      " Regression with ARIMA(4,0,3) errors : -12724.73\n",
      " Regression with ARIMA(5,0,3) errors : -12705.98\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12706.33\n",
      " Regression with ARIMA(5,0,2) errors : -12704.8\n",
      " Regression with ARIMA(5,0,4) errors : -12707.76\n",
      " Regression with ARIMA(4,0,3) errors : -12626.28\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12711.43\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12675.17\n",
      " Regression with ARIMA(0,0,0) errors : -9127.822\n",
      " Regression with ARIMA(1,0,0) errors : -12652.69\n",
      " Regression with ARIMA(0,0,1) errors : -10797.32\n",
      " Regression with ARIMA(0,0,0) errors : -8122.42\n",
      " Regression with ARIMA(1,0,2) errors : -12669.49\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12695.32\n",
      " Regression with ARIMA(1,0,3) errors : -12697.68\n",
      " Regression with ARIMA(0,0,3) errors : -11885.17\n",
      " Regression with ARIMA(1,0,4) errors : -12695.67\n",
      " Regression with ARIMA(0,0,2) errors : -11454.21\n",
      " Regression with ARIMA(0,0,4) errors : -12223.07\n",
      " Regression with ARIMA(2,0,4) errors : -12724.02\n",
      " Regression with ARIMA(3,0,4) errors : -12727\n",
      " Regression with ARIMA(3,0,3) errors : -12699.87\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12728.15\n",
      " Regression with ARIMA(1,0,5) errors : -12698.24\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12723.48\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12683.94\n",
      " Regression with ARIMA(0,0,0) errors : -9138.188\n",
      " Regression with ARIMA(1,0,0) errors : -12661.92\n",
      " Regression with ARIMA(0,0,1) errors : -10809.04\n",
      " Regression with ARIMA(0,0,0) errors : -8146.342\n",
      " Regression with ARIMA(1,0,2) errors : -12678.66\n",
      " Regression with ARIMA(2,0,1) errors : -12676.73\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12704.85\n",
      " Regression with ARIMA(1,0,3) errors : -12707.91\n",
      " Regression with ARIMA(0,0,3) errors : -11899.86\n",
      " Regression with ARIMA(1,0,4) errors : -12705.92\n",
      " Regression with ARIMA(0,0,2) errors : -11462.84\n",
      " Regression with ARIMA(0,0,4) errors : -12239.61\n",
      " Regression with ARIMA(2,0,4) errors : -12733.61\n",
      " Regression with ARIMA(3,0,4) errors : -12727.8\n",
      " Regression with ARIMA(2,0,5) errors : -12736.88\n",
      " Regression with ARIMA(1,0,5) errors : -12708.11\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12658.61\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12738.19\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12707.9\n",
      " Regression with ARIMA(0,0,0) errors : -9146.696\n",
      " Regression with ARIMA(1,0,0) errors : -12685.85\n",
      " Regression with ARIMA(0,0,1) errors : -10816.31\n",
      " Regression with ARIMA(0,0,0) errors : -8145.991\n",
      " Regression with ARIMA(1,0,2) errors : -12701.98\n",
      " Regression with ARIMA(2,0,1) errors : -12702.83\n",
      " Regression with ARIMA(3,0,2) errors : -12752.59\n",
      " Regression with ARIMA(3,0,1) errors : -12716.78\n",
      " Regression with ARIMA(4,0,2) errors : -12776.93\n",
      " Regression with ARIMA(4,0,1) errors : -12738.81\n",
      " Regression with ARIMA(5,0,2) errors : -12750.69\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -12740.15\n",
      " Regression with ARIMA(5,0,1) errors : -12807.17\n",
      " Regression with ARIMA(5,0,0) errors : -12741.34\n",
      " Regression with ARIMA(4,0,0) errors : -12738.7\n",
      " Regression with ARIMA(5,0,1) errors : -12728.9\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12760.88\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12912.84\n",
      " Regression with ARIMA(0,0,0) errors : -9287.558\n",
      " Regression with ARIMA(1,0,0) errors : -12838.23\n",
      " Regression with ARIMA(0,0,1) errors : -10970.44\n",
      " Regression with ARIMA(0,0,0) errors : -8334.607\n",
      " Regression with ARIMA(1,0,2) errors : -12850.07\n",
      " Regression with ARIMA(2,0,1) errors : -12896.83\n",
      " Regression with ARIMA(3,0,2) errors : -12886.59\n",
      " Regression with ARIMA(2,0,3) errors : -12920.49\n",
      " Regression with ARIMA(1,0,3) errors : -12869.31\n",
      " Regression with ARIMA(3,0,3) errors : -12922.93\n",
      " Regression with ARIMA(4,0,3) errors : -12951.22\n",
      " Regression with ARIMA(4,0,2) errors : -12979.64\n",
      " Regression with ARIMA(4,0,1) errors : -12919.17\n",
      " Regression with ARIMA(5,0,2) errors : -13016.01\n",
      " Regression with ARIMA(5,0,1) errors : -12918.05\n",
      " Regression with ARIMA(5,0,3) errors : -13009.45\n",
      " Regression with ARIMA(5,0,2) errors : -12924.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -12851.52\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13340.53\n",
      " Regression with ARIMA(0,0,0) errors : -9896.247\n",
      " Regression with ARIMA(1,0,0) errors : -13321.04\n",
      " Regression with ARIMA(0,0,1) errors : -11543.52\n",
      " Regression with ARIMA(0,0,0) errors : -8940.049\n",
      " Regression with ARIMA(1,0,2) errors : -13322.44\n",
      " Regression with ARIMA(2,0,1) errors : -13321.63\n",
      " Regression with ARIMA(3,0,2) errors : -13355.77\n",
      " Regression with ARIMA(3,0,1) errors : -13337\n",
      " Regression with ARIMA(4,0,2) errors : -13354.79\n",
      " Regression with ARIMA(3,0,3) errors : -13380.32\n",
      " Regression with ARIMA(2,0,3) errors : -13333.79\n",
      " Regression with ARIMA(4,0,3) errors : -13412.84\n",
      " Regression with ARIMA(5,0,3) errors : -13428.89\n",
      " Regression with ARIMA(5,0,2) errors : -13429.21\n",
      " Regression with ARIMA(5,0,1) errors : -13348.63\n",
      " Regression with ARIMA(4,0,1) errors : -13348.07\n",
      " Regression with ARIMA(5,0,2) errors : -13296.63\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13383.36\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13638.8\n",
      " Regression with ARIMA(0,1,0) errors : -13557.1\n",
      " Regression with ARIMA(1,1,0) errors : -13569.73\n",
      " Regression with ARIMA(0,1,1) errors : -13568.98\n",
      " Regression with ARIMA(0,1,0) errors : -13559.1\n",
      " Regression with ARIMA(1,1,2) errors : -13569.88\n",
      " Regression with ARIMA(2,1,1) errors : -13572.21\n",
      " Regression with ARIMA(3,1,2) errors : -13655.74\n",
      " Regression with ARIMA(3,1,1) errors : -13608.61\n",
      " Regression with ARIMA(4,1,2) errors : -13690.96\n",
      " Regression with ARIMA(4,1,1) errors : -13635.24\n",
      " Regression with ARIMA(5,1,2) errors : -13685.37\n",
      " Regression with ARIMA(4,1,3) errors : -13668.95\n",
      " Regression with ARIMA(3,1,3) errors : -13656.78\n",
      " Regression with ARIMA(5,1,1) errors : -13674.36\n",
      " Regression with ARIMA(5,1,3) errors : -13699.07\n",
      " Regression with ARIMA(5,1,4) errors : -13798\n",
      " Regression with ARIMA(4,1,4) errors : -13766.7\n",
      " Regression with ARIMA(5,1,5) errors : -13796.13\n",
      " Regression with ARIMA(4,1,5) errors : -13791.29\n",
      " Regression with ARIMA(5,1,4) errors : -13800.01\n",
      " Regression with ARIMA(4,1,4) errors : -13768.68\n",
      " Regression with ARIMA(5,1,3) errors : -13701.1\n",
      " Regression with ARIMA(5,1,5) errors : -13798.15\n",
      " Regression with ARIMA(4,1,3) errors : -13669.36\n",
      " Regression with ARIMA(4,1,5) errors : -13793.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,4) errors : -13627.14\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13856.97\n",
      " Regression with ARIMA(0,1,0) errors : -13830.28\n",
      " Regression with ARIMA(1,1,0) errors : -13844.83\n",
      " Regression with ARIMA(0,1,1) errors : -13841.77\n",
      " Regression with ARIMA(0,1,0) errors : -13832.29\n",
      " Regression with ARIMA(1,1,2) errors : -13852.88\n",
      " Regression with ARIMA(2,1,1) errors : -13857.98\n",
      " Regression with ARIMA(1,1,1) errors : -13853.24\n",
      " Regression with ARIMA(2,1,0) errors : -13857.59\n",
      " Regression with ARIMA(3,1,1) errors : -13856.45\n",
      " Regression with ARIMA(3,1,0) errors : -13855.79\n",
      " Regression with ARIMA(3,1,2) errors : -13853.87\n",
      " Regression with ARIMA(2,1,1) errors : -13859.99\n",
      " Regression with ARIMA(1,1,1) errors : -13855.24\n",
      " Regression with ARIMA(2,1,0) errors : -13859.61\n",
      " Regression with ARIMA(3,1,1) errors : -13858.47\n",
      " Regression with ARIMA(2,1,2) errors : -13858.99\n",
      " Regression with ARIMA(1,1,0) errors : -13846.84\n",
      " Regression with ARIMA(1,1,2) errors : -13854.88\n",
      " Regression with ARIMA(3,1,0) errors : -13857.8\n",
      " Regression with ARIMA(3,1,2) errors : -13855.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : -13852.22\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,1) errors \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13947.36\n",
      " Regression with ARIMA(0,1,0) errors : -13900.86\n",
      " Regression with ARIMA(1,1,0) errors : -13932.84\n",
      " Regression with ARIMA(0,1,1) errors : -13911.73\n",
      " Regression with ARIMA(0,1,0) errors : -13902.87\n",
      " Regression with ARIMA(1,1,2) errors : -13939.01\n",
      " Regression with ARIMA(2,1,1) errors : -13943.65\n",
      " Regression with ARIMA(3,1,2) errors : -13959.09\n",
      " Regression with ARIMA(3,1,1) errors : -13956.45\n",
      " Regression with ARIMA(4,1,2) errors : -14000.17\n",
      " Regression with ARIMA(4,1,1) errors : -13952.05\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : -14004.61\n",
      " Regression with ARIMA(3,1,3) errors : -13984.19\n",
      " Regression with ARIMA(5,1,3) errors : -14058.98\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : -14034.52\n",
      " Regression with ARIMA(5,1,3) errors : -14060.9\n",
      " Regression with ARIMA(4,1,3) errors : -14006.63\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : -14002.15\n",
      " Regression with ARIMA(4,1,4) errors : -14036.43\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : -13974.19\n",
      "\n",
      " Best model: Regression with ARIMA(4,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14051.09\n",
      " Regression with ARIMA(0,1,0) errors : -14017.53\n",
      " Regression with ARIMA(1,1,0) errors : -14026.02\n",
      " Regression with ARIMA(0,1,1) errors : -14026.4\n",
      " Regression with ARIMA(0,1,0) errors : -14019.51\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14049.92\n",
      " Regression with ARIMA(3,1,2) errors : -14072.45\n",
      " Regression with ARIMA(3,1,1) errors : -14060.26\n",
      " Regression with ARIMA(4,1,2) errors : -14078.94\n",
      " Regression with ARIMA(4,1,1) errors : -14061.76\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : -14126.2\n",
      " Regression with ARIMA(2,1,3) errors : -14050.56\n",
      " Regression with ARIMA(3,1,4) errors : -14077.3\n",
      " Regression with ARIMA(2,1,4) errors : -14048.58\n",
      " Regression with ARIMA(4,1,4) errors : -14193.59\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14215.31\n",
      " Regression with ARIMA(2,1,5) errors : -14059.26\n",
      " Regression with ARIMA(3,1,5) errors : -14216.42\n",
      " Regression with ARIMA(2,1,5) errors : -14061.28\n",
      " Regression with ARIMA(3,1,4) errors : -14177.43\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14050.61\n",
      " Regression with ARIMA(4,1,4) errors : -14194.71\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -14036.04\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14232.72\n",
      " Regression with ARIMA(0,1,0) errors : -14162.77\n",
      " Regression with ARIMA(1,1,0) errors : -14185.38\n",
      " Regression with ARIMA(0,1,1) errors : -14173.07\n",
      " Regression with ARIMA(0,1,0) errors : -14164.75\n",
      " Regression with ARIMA(1,1,2) errors : -14207.81\n",
      " Regression with ARIMA(2,1,1) errors : -14224.23\n",
      " Regression with ARIMA(3,1,2) errors : -14248.4\n",
      " Regression with ARIMA(3,1,1) errors : -14225.86\n",
      " Regression with ARIMA(4,1,2) errors : -14270.04\n",
      " Regression with ARIMA(4,1,1) errors : -14226.79\n",
      " Regression with ARIMA(5,1,2) errors : -14276.69\n",
      " Regression with ARIMA(5,1,1) errors : -14239.31\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : -14278.66\n",
      " Regression with ARIMA(4,1,2) errors : -14272.05\n",
      " Regression with ARIMA(5,1,1) errors : -14241.32\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : -14228.77\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,1) errors : -14188.43\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14269.51\n",
      " Regression with ARIMA(1,1,0) errors : -14280.67\n",
      " Regression with ARIMA(0,1,1) errors : -14275.99\n",
      " Regression with ARIMA(0,1,0) errors : -14271.49\n",
      " Regression with ARIMA(2,1,0) errors : -14280.26\n",
      " Regression with ARIMA(1,1,1) errors : -14283.64\n",
      " Regression with ARIMA(2,1,1) errors : -14282.63\n",
      " Regression with ARIMA(1,1,2) errors : -14281.81\n",
      " Regression with ARIMA(0,1,2) errors : -14276.35\n",
      " Regression with ARIMA(1,1,1) errors : -14285.62\n",
      " Regression with ARIMA(0,1,1) errors : -14277.97\n",
      " Regression with ARIMA(1,1,0) errors : -14282.66\n",
      " Regression with ARIMA(2,1,1) errors : -14284.63\n",
      " Regression with ARIMA(1,1,2) errors : -14283.8\n",
      " Regression with ARIMA(0,1,2) errors : -14278.33\n",
      " Regression with ARIMA(2,1,0) errors : -14282.25\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14292.77\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14392.52\n",
      " Regression with ARIMA(0,1,0) errors : -14319.87\n",
      " Regression with ARIMA(1,1,0) errors : -14323.95\n",
      " Regression with ARIMA(0,1,1) errors : -14324.28\n",
      " Regression with ARIMA(0,1,0) errors : -14321.88\n",
      " Regression with ARIMA(1,1,2) errors : -14328.67\n",
      " Regression with ARIMA(2,1,1) errors : -14322.2\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14396.05\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14397.58\n",
      " Regression with ARIMA(1,1,4) errors : -14325.55\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14409.11\n",
      " Regression with ARIMA(0,1,5) errors : -14329.22\n",
      " Regression with ARIMA(0,1,4) errors : -14322.36\n",
      " Regression with ARIMA(1,1,5) errors : -14410.56\n",
      " Regression with ARIMA(0,1,5) errors : -14331.23\n",
      " Regression with ARIMA(1,1,4) errors : -14327.56\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(0,1,4) errors : -14324.37\n",
      " Regression with ARIMA(2,1,4) errors : -14399.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,5) errors : -14340.4\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14414.39\n",
      " Regression with ARIMA(0,1,0) errors : -14347.05\n",
      " Regression with ARIMA(1,1,0) errors : -14351.5\n",
      " Regression with ARIMA(0,1,1) errors : -14351.98\n",
      " Regression with ARIMA(0,1,0) errors : -14349.06\n",
      " Regression with ARIMA(1,1,2) errors : -14355.74\n",
      " Regression with ARIMA(2,1,1) errors : -14357.14\n",
      " Regression with ARIMA(3,1,2) errors : -14356.58\n",
      " Regression with ARIMA(2,1,3) errors : -14416.78\n",
      " Regression with ARIMA(1,1,3) errors : -14352.44\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14426.08\n",
      " Regression with ARIMA(1,1,4) errors : -14352.46\n",
      " Regression with ARIMA(3,1,4) errors : -14359.23\n",
      " Regression with ARIMA(2,1,5) errors : -14433.08\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14448.43\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14449.79\n",
      " Regression with ARIMA(2,1,5) errors : -14434.5\n",
      " Regression with ARIMA(3,1,4) errors : -14361.25\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14427.62\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14373.05\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14467.17\n",
      " Regression with ARIMA(0,1,0) errors : -14387.79\n",
      " Regression with ARIMA(1,1,0) errors : -14392.42\n",
      " Regression with ARIMA(0,1,1) errors : -14393.12\n",
      " Regression with ARIMA(0,1,0) errors : -14389.79\n",
      " Regression with ARIMA(1,1,2) errors : -14393.52\n",
      " Regression with ARIMA(2,1,1) errors : -14392.46\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14467.02\n",
      " Regression with ARIMA(1,1,1) errors : -14394.63\n",
      " Regression with ARIMA(1,1,3) errors : -14391.52\n",
      " Regression with ARIMA(3,1,1) errors : -14450.2\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -14468.77\n",
      " Regression with ARIMA(1,1,2) errors : -14395.53\n",
      " Regression with ARIMA(2,1,1) errors : -14394.46\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14468.52\n",
      " Regression with ARIMA(1,1,1) errors : -14396.63\n",
      " Regression with ARIMA(1,1,3) errors : -14393.52\n",
      " Regression with ARIMA(3,1,1) errors : -14452.03\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : -14406.82\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11132.19\n",
      " Regression with ARIMA(1,0,0) errors : -14540.36\n",
      " Regression with ARIMA(0,0,1) errors : -12745.99\n",
      " Regression with ARIMA(0,0,0) errors : -9972.371\n",
      " Regression with ARIMA(2,0,0) errors : -14537.54\n",
      " Regression with ARIMA(1,0,1) errors : -14538.45\n",
      " Regression with ARIMA(2,0,1) errors : -14542.87\n",
      " Regression with ARIMA(3,0,1) errors : -14558.56\n",
      " Regression with ARIMA(3,0,0) errors : -14548.35\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -14559.21\n",
      " Regression with ARIMA(4,0,2) errors : -14555.78\n",
      " Regression with ARIMA(3,0,3) errors : -14558.89\n",
      " Regression with ARIMA(2,0,3) errors : -14545.56\n",
      " Regression with ARIMA(4,0,3) errors : -14553.54\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14560.17\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11151.48\n",
      " Regression with ARIMA(1,0,0) errors : -14551.11\n",
      " Regression with ARIMA(0,0,1) errors : -12768.97\n",
      " Regression with ARIMA(0,0,0) errors : -9991.611\n",
      " Regression with ARIMA(2,0,0) errors : -14548.25\n",
      " Regression with ARIMA(1,0,1) errors : -14549.23\n",
      " Regression with ARIMA(2,0,1) errors : -14552.94\n",
      " Regression with ARIMA(3,0,1) errors : -14567.66\n",
      " Regression with ARIMA(3,0,0) errors : -14558.46\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,0) errors : -14557.43\n",
      " Regression with ARIMA(4,0,2) errors : -14572.3\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -14567.45\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,1) errors : -14571.65\n",
      " Regression with ARIMA(5,0,3) errors : -14591.07\n",
      " Regression with ARIMA(5,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -14588.65\n",
      " Regression with ARIMA(5,0,3) errors : -14466.83\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -14592.39\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14560.15\n",
      " Regression with ARIMA(0,0,0) errors : -11132.88\n",
      " Regression with ARIMA(1,0,0) errors : -14543.96\n",
      " Regression with ARIMA(0,0,1) errors : -12748.49\n",
      " Regression with ARIMA(0,0,0) errors : -9916.669\n",
      " Regression with ARIMA(1,0,2) errors : -14552.05\n",
      " Regression with ARIMA(2,0,1) errors : -14544.14\n",
      " Regression with ARIMA(3,0,2) errors : -14551.85\n",
      " Regression with ARIMA(2,0,3) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -14542.09\n",
      " Regression with ARIMA(1,0,3) errors : -14551.93\n",
      " Regression with ARIMA(3,0,1) errors : -14569.13\n",
      " Regression with ARIMA(3,0,0) errors : -14553.2\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -14542.46\n",
      " Regression with ARIMA(4,0,0) errors : -14553.19\n",
      " Regression with ARIMA(4,0,2) errors : -14568.72\n",
      " Regression with ARIMA(3,0,1) errors : -14400.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -14566.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11155.69\n",
      " Regression with ARIMA(1,0,0) errors : -14548.92\n",
      " Regression with ARIMA(0,0,1) errors : -12768.48\n",
      " Regression with ARIMA(0,0,0) errors : -9907.063\n",
      " Regression with ARIMA(2,0,0) errors : -14546.07\n",
      " Regression with ARIMA(1,0,1) errors : -14546.93\n",
      " Regression with ARIMA(2,0,1) errors : -14550.78\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -14554.96\n",
      " Regression with ARIMA(0,0,2) errors : -13588.57\n",
      " Regression with ARIMA(1,0,3) errors : -14555.05\n",
      " Regression with ARIMA(0,0,3) errors : -13929.67\n",
      " Regression with ARIMA(2,0,3) errors : -14552.73\n",
      " Regression with ARIMA(1,0,4) errors : -14561.38\n",
      " Regression with ARIMA(0,0,4) errors : -14217.43\n",
      " Regression with ARIMA(2,0,4) errors : -14559.98\n",
      " Regression with ARIMA(1,0,5) errors : -14560.36\n",
      " Regression with ARIMA(0,0,5) errors : -14327\n",
      " Regression with ARIMA(2,0,5) errors : -14558.11\n",
      " Regression with ARIMA(1,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,4) errors : -14560.62\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14379.34\n",
      " Regression with ARIMA(1,1,0) errors : -14383.72\n",
      " Regression with ARIMA(0,1,1) errors : -14382.54\n",
      " Regression with ARIMA(0,1,0) errors : -14381.35\n",
      " Regression with ARIMA(2,1,0) errors : -14382.72\n",
      " Regression with ARIMA(1,1,1) errors : -14384.5\n",
      " Regression with ARIMA(2,1,1) errors : -14382.23\n",
      " Regression with ARIMA(1,1,2) errors : -14382.66\n",
      " Regression with ARIMA(0,1,2) errors : -14382.21\n",
      " Regression with ARIMA(1,1,1) errors : -14386.51\n",
      " Regression with ARIMA(0,1,1) errors : -14384.55\n",
      " Regression with ARIMA(1,1,0) errors : -14385.73\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : -14384.54\n",
      " Regression with ARIMA(0,1,2) errors : -14384.22\n",
      " Regression with ARIMA(2,1,0) errors : -14384.73\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14397.22\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14483.22\n",
      " Regression with ARIMA(0,0,0) errors : -11017.35\n",
      " Regression with ARIMA(1,0,0) errors : -14460.22\n",
      " Regression with ARIMA(0,0,1) errors : -12640.36\n",
      " Regression with ARIMA(0,0,0) errors : -9780.733\n",
      " Regression with ARIMA(1,0,2) errors : -14467.99\n",
      " Regression with ARIMA(2,0,1) errors : -14461.13\n",
      " Regression with ARIMA(3,0,2) errors : -14483.56\n",
      " Regression with ARIMA(3,0,1) errors : -14483.17\n",
      " Regression with ARIMA(4,0,2) errors : -14480.81\n",
      " Regression with ARIMA(3,0,3) errors : -14482.96\n",
      " Regression with ARIMA(2,0,3) errors : -14464.37\n",
      " Regression with ARIMA(4,0,1) errors : -14477.63\n",
      " Regression with ARIMA(4,0,3) errors : -14478.99\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14477.22\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14498.8\n",
      " Regression with ARIMA(0,0,0) errors : -11029\n",
      " Regression with ARIMA(1,0,0) errors : -14478.15\n",
      " Regression with ARIMA(0,0,1) errors : -12661.86\n",
      " Regression with ARIMA(0,0,0) errors : -9798.577\n",
      " Regression with ARIMA(1,0,2) errors : -14485.32\n",
      " Regression with ARIMA(2,0,1) errors : -14479.56\n",
      " Regression with ARIMA(3,0,2) errors : -14498.67\n",
      " Regression with ARIMA(2,0,3) errors : -14482.25\n",
      " Regression with ARIMA(1,0,1) errors : -14476.18\n",
      " Regression with ARIMA(1,0,3) errors : -14486.49\n",
      " Regression with ARIMA(3,0,1) errors : -14499.33\n",
      " Regression with ARIMA(3,0,0) errors : -14485.04\n",
      " Regression with ARIMA(4,0,1) errors : -14493.81\n",
      " Regression with ARIMA(2,0,0) errors : -14475.19\n",
      " Regression with ARIMA(4,0,0) errors : -14489\n",
      " Regression with ARIMA(4,0,2) errors : -14497.35\n",
      " Regression with ARIMA(3,0,1) errors : -14328.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -14499.04\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14499.82\n",
      " Regression with ARIMA(0,0,0) errors : -11030.92\n",
      " Regression with ARIMA(1,0,0) errors : -14479.83\n",
      " Regression with ARIMA(0,0,1) errors : -12666.18\n",
      " Regression with ARIMA(0,0,0) errors : -9815.953\n",
      " Regression with ARIMA(1,0,2) errors : -14487.24\n",
      " Regression with ARIMA(2,0,1) errors : -14480.13\n",
      " Regression with ARIMA(3,0,2) errors : -14499.16\n",
      " Regression with ARIMA(2,0,3) errors : -14482.98\n",
      " Regression with ARIMA(1,0,1) errors : -14477.85\n",
      " Regression with ARIMA(1,0,3) errors : -14488.5\n",
      " Regression with ARIMA(3,0,1) errors : -14497.61\n",
      " Regression with ARIMA(3,0,3) errors : -14499.03\n",
      " Regression with ARIMA(2,0,2) errors : -14337.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14481.43\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14520.82\n",
      " Regression with ARIMA(0,0,0) errors : -11039.14\n",
      " Regression with ARIMA(1,0,0) errors : -14493.69\n",
      " Regression with ARIMA(0,0,1) errors : -12672\n",
      " Regression with ARIMA(0,0,0) errors : -9822.197\n",
      " Regression with ARIMA(1,0,2) errors : -14500.76\n",
      " Regression with ARIMA(2,0,1) errors : -14497.56\n",
      " Regression with ARIMA(3,0,2) errors : -14524.84\n",
      " Regression with ARIMA(3,0,1) errors : -14518.61\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -14524.22\n",
      " Regression with ARIMA(2,0,3) errors : -14520.02\n",
      " Regression with ARIMA(4,0,1) errors : -14521.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14510.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14421.28\n",
      " Regression with ARIMA(1,1,0) errors : -14438.68\n",
      " Regression with ARIMA(0,1,1) errors : -14424.25\n",
      " Regression with ARIMA(0,1,0) errors : -14423.29\n",
      " Regression with ARIMA(2,1,0) errors : -14439.8\n",
      " Regression with ARIMA(3,1,0) errors : -14439.79\n",
      " Regression with ARIMA(2,1,1) errors : -14444.89\n",
      " Regression with ARIMA(1,1,1) errors : -14446.77\n",
      " Regression with ARIMA(1,1,2) errors : -14444.79\n",
      " Regression with ARIMA(0,1,2) errors : -14423.33\n",
      " Regression with ARIMA(1,1,1) errors : -14448.78\n",
      " Regression with ARIMA(0,1,1) errors : -14426.26\n",
      " Regression with ARIMA(1,1,0) errors : -14440.69\n",
      " Regression with ARIMA(2,1,1) errors : -14446.9\n",
      " Regression with ARIMA(1,1,2) errors : -14446.8\n",
      " Regression with ARIMA(0,1,2) errors : -14425.34\n",
      " Regression with ARIMA(2,1,0) errors : -14441.81\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14440.01\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14553.28\n",
      " Regression with ARIMA(0,1,0) errors : -14483.96\n",
      " Regression with ARIMA(1,1,0) errors : -14484.77\n",
      " Regression with ARIMA(0,1,1) errors : -14485.54\n",
      " Regression with ARIMA(0,1,0) errors : -14485.96\n",
      " Regression with ARIMA(1,1,2) errors : -14488.25\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14562.68\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14567.68\n",
      " Regression with ARIMA(1,1,4) errors : -14484.21\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14585.28\n",
      " Regression with ARIMA(1,1,5) errors : -14492.24\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14586.81\n",
      " Regression with ARIMA(1,1,5) errors : -14494.25\n",
      " Regression with ARIMA(2,1,4) errors : -14569.27\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : -14485.81\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14504.5\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14595.43\n",
      " Regression with ARIMA(0,1,0) errors : -14527.09\n",
      " Regression with ARIMA(1,1,0) errors : -14529.37\n",
      " Regression with ARIMA(0,1,1) errors : -14529.7\n",
      " Regression with ARIMA(0,1,0) errors : -14529.09\n",
      " Regression with ARIMA(1,1,2) errors : -14533.99\n",
      " Regression with ARIMA(2,1,1) errors : -14543.6\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14601.94\n",
      " Regression with ARIMA(1,1,3) errors : -14532.49\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14605.78\n",
      " Regression with ARIMA(1,1,4) errors : -14530.67\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14537.39\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14607.58\n",
      " Regression with ARIMA(1,1,4) errors : -14532.67\n",
      " Regression with ARIMA(2,1,3) errors : -14603.75\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : -14534.49\n",
      " Regression with ARIMA(1,1,5) errors : -14539.39\n",
      " Regression with ARIMA(3,1,3) errors : -14598.8\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14549.06\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14516.87\n",
      " Regression with ARIMA(1,1,0) errors : -14525.36\n",
      " Regression with ARIMA(0,1,1) errors : -14520.46\n",
      " Regression with ARIMA(0,1,0) errors : -14518.88\n",
      " Regression with ARIMA(2,1,0) errors : -14523.87\n",
      " Regression with ARIMA(1,1,1) errors : -14523.58\n",
      " Regression with ARIMA(2,1,1) errors : -14528.44\n",
      " Regression with ARIMA(3,1,1) errors : -14605.73\n",
      " Regression with ARIMA(3,1,0) errors : -14522.73\n",
      " Regression with ARIMA(4,1,1) errors : -14552.02\n",
      " Regression with ARIMA(3,1,2) errors : -14601.37\n",
      " Regression with ARIMA(4,1,0) errors : -14523.8\n",
      " Regression with ARIMA(4,1,2) errors : -14570.42\n",
      " Regression with ARIMA(3,1,1) errors : -14607.28\n",
      " Regression with ARIMA(2,1,1) errors : -14530.46\n",
      " Regression with ARIMA(3,1,0) errors : -14524.74\n",
      " Regression with ARIMA(4,1,1) errors : -14553.78\n",
      " Regression with ARIMA(3,1,2) errors : -14602.92\n",
      " Regression with ARIMA(2,1,0) errors : -14525.88\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,0) errors : -14525.81\n",
      " Regression with ARIMA(4,1,2) errors : -14572.1\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14535.51\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11250.18\n",
      " Regression with ARIMA(1,0,0) errors : -14656.36\n",
      " Regression with ARIMA(0,0,1) errors : -12862.56\n",
      " Regression with ARIMA(0,0,0) errors : -10027.92\n",
      " Regression with ARIMA(2,0,0) errors : -14654.03\n",
      " Regression with ARIMA(1,0,1) errors : -14654.36\n",
      " Regression with ARIMA(2,0,1) errors : -14660.84\n",
      " Regression with ARIMA(3,0,1) errors : -14661.21\n",
      " Regression with ARIMA(3,0,0) errors : -14664.08\n",
      " Regression with ARIMA(4,0,0) errors : -14664.12\n",
      " Regression with ARIMA(5,0,0) errors : -14670.91\n",
      " Regression with ARIMA(5,0,1) errors : -14674.19\n",
      " Regression with ARIMA(4,0,1) errors : -14674.78\n",
      " Regression with ARIMA(4,0,2) errors : -14678.29\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : -14693.27\n",
      " Regression with ARIMA(5,0,3) errors : -14691.32\n",
      " Regression with ARIMA(4,0,3) errors : -14661.91\n",
      " Regression with ARIMA(5,0,2) errors : -14579.72\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -14701.58\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11249.56\n",
      " Regression with ARIMA(1,0,0) errors : -14656.24\n",
      " Regression with ARIMA(0,0,1) errors : -12864.81\n",
      " Regression with ARIMA(0,0,0) errors : -10027.74\n",
      " Regression with ARIMA(2,0,0) errors : -14657.78\n",
      " Regression with ARIMA(3,0,0) errors : -14666.92\n",
      " Regression with ARIMA(4,0,0) errors : -14666.09\n",
      " Regression with ARIMA(3,0,1) errors : -14664.16\n",
      " Regression with ARIMA(2,0,1) errors : -14658.57\n",
      " Regression with ARIMA(4,0,1) errors : -14666.46\n",
      " Regression with ARIMA(3,0,0) errors : -14546.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,0) errors : -14662.78\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14675.28\n",
      " Regression with ARIMA(0,0,0) errors : -11256.19\n",
      " Regression with ARIMA(1,0,0) errors : -14668.76\n",
      " Regression with ARIMA(0,0,1) errors : -12871.85\n",
      " Regression with ARIMA(0,0,0) errors : -10034.68\n",
      " Regression with ARIMA(1,0,2) errors : -14674.7\n",
      " Regression with ARIMA(2,0,1) errors : -14674.96\n",
      " Regression with ARIMA(3,0,2) errors : -14693.42\n",
      " Regression with ARIMA(3,0,1) errors : -14675.56\n",
      " Regression with ARIMA(4,0,2) errors : -14690.6\n",
      " Regression with ARIMA(3,0,3) errors : -14692.29\n",
      " Regression with ARIMA(2,0,3) errors : -14676.55\n",
      " Regression with ARIMA(4,0,1) errors : -14675.31\n",
      " Regression with ARIMA(4,0,3) errors : -14683.71\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14692.38\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m03.3 <- my.tsCV(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                        xreg.msize=hori,\n",
    "                        xreg=trainx[,2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dfd95132-f6b6-449a-80b4-b9750616bde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-01-24\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m03.3\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53f2b51-a9df-4dbd-bdd6-d77af2fe524f",
   "metadata": {},
   "source": [
    "## Compare Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed9c467c-feac-4461-816b-ac6a0abcae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "my.figsize(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e499e5ce-1237-49e0-a787-a1be8de29cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94\nAAAgAElEQVR4nOzdeXxM9/7H8c9MMhnZRRJrgiBiD6LW2iqxpIpybeWHUr1qaXuvqmpLtGiv\n0lqqte9a2qra11ZbFFVLqRLEGgkiIpN9nfn9Me10ZDMiY5Kc1/Phjznf+Z5zPjOZh5n3Od/z\nPSqDwSAAAAAAAOVR27oAAAAAAIBtEAgBAAAAQKEIhAAAAACgUARCAAAAAFAoAiEAAAAAKBSB\nEAAAAAAUikAIAAAAAApFIAQAAAAAhbK3dQFFIzExMSsry9ZV4AFOTk4ajSYxMVGv19u6FiBv\nKpXKzc0tKysrOTnZ1rUA+dJqtWXKlElJScnMzLR1LXiAh4eHrUsAgMdVSgKhXq/Pzs62dRXI\nSa1WZ2dnEwhRbKlUKrVaLSL8B4LizGAwqNVqg8HABxUAUOQYMgoAAAAACkUgBAAAAACFIhAC\nAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAAAAAolHXvQ5iUlLRkyZLffvstKyur\nQYMGr7zySvny5XP0iYyMXLlyZXh4uF6v9/PzGzp0aJ06dSxcFwAAAABQaNY9Qzh37twbN25M\nmzZtzpw5dnZ277//fo57lGdmZr777ruurq6zZs2aM2dOhQoVpk6dmpqaasm6AAAAAIDHYcVA\nGBsbe+zYsVdffbVWrVo+Pj6vv/56VFTU6dOnzfukpKT06tVr1KhRVapUqVSpUt++fVNSUm7f\nvm3JugAAAACAx2HFQHjp0iUHBwc/Pz/joouLi6+v76VLl8z7uLu7P//8846OjiKSmJi4detW\nHx8fHx8fS9YFAAAAADwOK15DmJCQ4OrqqlKpTC3u7u46nS53T71e/69//SsrK6t+/frTp0/X\naDQPXffo0aMffvihafG9995r2LChdV4HCkmtVouIu7u7rQsBHkKj0Xh4eNi6CiBfxm9DZ2dn\nJycnW9cCAChtrDupjHmiExGDwZBnN7VaPW/evPj4+K1bt77zzjuzZ89+6LpZWVmJiYmmxezs\nbGP8QPFh/Avyd0Hxp1Kp+KCi+FOpVDm+GQEAeHxWDIRly5ZNSEgwGAymLzCdTpffYXhfX19f\nX9969eoNGTLkp59+8vLyKnjdp59+ev/+/aZFnU537949q70UFIarq6tWq71//z6zAaHYUqlU\nnp6eGRkZCQkJtq4FyJejo6Ozs3NSUlJ6erqta8EDvLy8bF0CADwuKx4Ur127dmZmZkREhHFR\np9NFRkYabylhcvr06ZdffjktLe2vatRqlUplMBgsWRcAAAAA8DisGAg9PDzatGnz6aefRkRE\nREZGfvLJJ7Vq1apfv76I7Nu3b9u2bSJSq1at9PT0efPmRUZG3r59e9myZWlpaU2bNi1gXQAA\nAABAkVDld11fkUhJSVm6dOmRI0f0en2TJk1GjRplHPY5a9ashISEadOmicj169dXr1594cKF\n7OzsatWqDRo0qFGjRgWsmyedTpeZmWm9F4JCMA4ZjYuLY8goii2GjKJEMA4ZTUxMZMhoccOQ\nUQClgHUD4RNDICyGCIQo/giEKBEIhMUWgRBAKcDEegAAAACgUARCAAAAAFAoAiEAAAAAKBSB\nEAAAAAAUikAIAAAAAApFIAQAAAAAhbK3dQEAACBfFy9e/P777+Pi4ipUqBAaGlqlShVbVwQA\nKFUIhAAAFFO7d++eO3euaXHr1q1Tp04NCgqyYUkAgFKGIaMAABRH9+7dW7hwoXlLZmbm7Nmz\nMzMzbVUSAKD0IRACAFAc/fHHH+np6Tka79+/HxERYZN6AAClEoEQAIDiKL8zgVlZWU+4EgBA\nKUYgBACgOKpTp07uRgcHh5o1az75YgAApRWBEACA4sjX17dPnz45GkeOHOnk5GSTegAApRKz\njAIAUEyNGDHCx8dn7969MTExPj4+PXv2bN26ta2LAgCUKiqDwWDrGoqATqdj1rXixtXVVavV\nxsXF6fV6W9cC5E2lUnl6emZkZCQkJNi6FiBfjo6Ozs7OiYmJueeYgW15eXnZugQAeFwMGQUA\nAAAAhSIQAgAAAIBCEQgBAAAAQKEIhAAAAACgUARCAAAAAFAoAiEAAAAAKBSBEAAAAAAUikAI\nAAAAAApFIAQAAAAAhSIQAgAAAIBCEQgBAAAAQKEIhAAAAACgUARCAAAAAFAoAiEAAAAAKBSB\nEAAAAAAUikAIAAAAAApFIAQAAAAAhSIQAgAAAIBCEQgBAAAAQKHsbV0AANiGXq8/dOhQZGSk\no6Njw4YN/f39bV0RAADAk0YgBKBEqampEydOvHjxoqll8ODBgwcPtmFJAAAATx5DRgEo0dKl\nS83ToIisW7fuzJkztqoHAADAJgiEAJTowIEDFjYCAACUYgRCAIpjMBhSU1Nzt6ekpDz5YgAA\nAGyIQAhAcVQqVbVq1XK3+/n5PfliAAAAbIhACECJXnrppRwtlStX7t69u02KAQAAsBUCIQAl\natq06dSpU6tXr65Wqx0cHNq0afPhhx86Ojraui4AAIAnittOAFColi1btmrVysXFxWAwJCUl\n2bocAAAAG+AMIQBF02q1ajX/EwIAAIXiZxAAAAAAKBSBEAAAAAAUikAIAAAAAApFIAQAAAAA\nhSIQAgAAAIBCEQgBAAAAQKEIhAAAAACgUARCAAAAAFAoAiEAAAAAKBSBEAAAAAAUikAIAAAA\nAApFIAQAAAAAhbK3dQEonaKios6ePZuSklKlSpWnnnpKpVLZuiIAAAAAOREIUfS2bt26dOnS\nzMxM42LdunU/+OADR0dH21YFAAAAIAeGjKKIXb582TwNisj58+cXL15sw5IAAAAA5IlAiCL2\n888/m6dBox9//FGv19ukHgAAAAD5IRCiiCUlJeVuTE9Pz8rKevLFAAAAACgAgRBFzNfXN3dj\nhQoVHBwcnnwxAAAAAApAIEQR69q1a+XKlXM0Dh8+3CbFAAAAACgAgRBFzNHRcfr06c2aNVOr\n1SLi5eU1fvz49u3b27ouAAAAADmpDAaDrWsoAjqdLvdEJrAtBwcH43WDTCeDYkulUnl6emZk\nZCQkJNi6FiBfjo6Ozs7OiYmJ6enptq4FD/Dy8rJ1CQDwuDhDCGvRarXlypWzdRUAAAAA8kUg\nBAAAAACFIhACAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAAABSK\nQAgAAAAACkUgBAAAAACFIhACAAAAgELZ27oAlE7nzp07efJkSkqKr69vcHCwRqOxdUUAAAAA\nciIQouitXr16/fr1psWNGzd+8skn7u7uNiwJAAAAQG4MGUURO3v2rHkaFJGoqKjPPvvMVvUA\nBYuPj8/IyLB1FQAAALbBGUIUscOHD+duPHLkiF6vV6s5AIFi5Oeff16+fHlMTIxarW7cuPHo\n0aN9fHxsXRQAAMATVUoCoVqttrcvJa+lpMvzZEtmZqaI8DdC8XHkyJEPP/zQ+Fiv1588efKd\nd95ZtGiRq6urbQsDcjMeTeObDgBgDaXkq8XBwcHWJeAvdevW3b59e45GPz8/riFEsbJixYoc\nLXfu3Nm1a9fQoUNtUg9QADs7OxFxcHAgEAIAilwp+WpJS0sznoOCzbVr127Tpk2XL182bxw5\ncmRiYqKtSgJyMBgM169fz91+6dIlPqgohhwdHe3t7dPS0tLT021dCx6g1WptXQIAPC6u6UIR\n02g0M2bM6Natm7u7u0ajCQgImDFjRtOmTW1dF/APlUrl4uKSu53xogAAQGlUBoPB1jUUAZ1O\nxxnC4sbV1VWj0cTHx+v1elvXAuS0cOHCLVu25GicM2dO3bp1bVIPUABHR0dnZ+fExETOEBY3\nXl5eti4BAB4XZwhhRUwrimJr4MCBjo6O5i1NmjQhDQIAAKXh9zoAJVqzZk1qaqp5y6lTp86c\nOWOregAAAGyCQAhAiQ4cOGBhIwAAQClGIASgOAaDIcfpQaOUlJQnXwwAAIANEQgBKI5KpapW\nrVrudj8/vydfDAAAgA0RCAEo0ciRI3O0VKlSpXv37jYpBgAAwFYIhACUqEmTJu+9956fn59a\nrdZqtW3atPnggw9yzDsKAABQ6tnbugAAsI0WLVq0bNnSxcXFYDAkJSXZuhwAAAAb4AwhAEXT\narXcMBMAACgWP4MAAAAAQKEIhAAAAACgUARCAAAAAFAoAiEAAAAAKBSBEACAYu348eMffPDB\npUuXbF0IAKAUIhACAFCsRUREbNq0KTo62taFAABKIQIhAAAAACgUgRAAAAAAFMre1gWgdDp3\n7tzJkydTUlJ8fX2Dg4M1Go2tKwIAAACQE4EQRW/16tXr1683LW7cuPGTTz5xd3e3YUkAAAAA\ncmPIKIrY2bNnzdOgiERFRX322We2qgcAAABAfgiEKGKHDx/O3XjkyBG9Xv/kiwEAAABQAAIh\nilhaWlruxszMzOzs7CdfDAAAAIACEAhRxGrWrJm7sVq1aswrAwAAABQ3BEIUsc6dO+fOhP/+\n979tUgwAAACAAhAIUcQ0Gs2MGTO6devm7u6u0WgCAgJmzJjRtGlTW9cFAAAAICduO4GiV7Zs\n2ddee+3dd9/VaDTx8fFMJwMAAAAUTwRCWMXhw4dPnDiRnJxctWrVHj16uLi42LoiAAAAADkR\nCFH05s+fv3PnTtPitm3b5s+f7+3tbcOSAAAAAOTGNYQoYidOnDBPgyJy//79+fPn26oeAAAA\nAPkhEKKI/fbbb7kbT548yX0IAQAAgOKGQIgilpmZmbtRr9cztQwAAABQ3BAIUcTq1KmTu7Fm\nzZrcmB4AAAAobgiEKGKdOnVq0KCBeYtGoxkzZoyt6gEAAACQH2YZRRFTq9XTpk376quvfv31\n16SkpJo1aw4aNMjf39/WdQEAAADIiUCIoufo6Dhs2LBx48Zptdq4uDiuHgQAAACKJ4aMAgAA\nAIBCEQgBAAAAQKEIhAAAAACgUARCAAAAAFAoAiEAAAAAKBSBEAAAAAAUikAIAAAAAApFIAQA\nAAAAhSIQAlCu1NTU//u///v4449tXQgAAIBt2Nu6AACwmezs7PPnz7u7u9u6EAAAANvgDCEA\nAAAAKBSBEAAAAAAUikAIAAAAAApFIAQAAAAAhSIQAgAAAIBCEQgBAAAAQKEIhAAAAACgUARC\nAAAAAFAoAiEAAAAAKBSBEAAAAAAUikAIAAAAAApFIAQAAAAAhSIQwlr27Nnz6aefJicn27oQ\nAAAAAHkjEMJaDh48uHr16tTUVFsXAgAAACBvBEIAAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgA\nAAAACkUgBAAAAACFIhACAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQ\nAAAAABSKQAgAAAAACkUgBAAAAACFIhACAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgC\nIQAAAAAoFIEQAAAAABTK3qpbT0pKWrJkyW+//ZaVldWgQYNXXnmlfPnyubtFRUXNmTMnIiJi\n8+bNj7ouAAAAAKBwrHuGcO7cuTdu3Jg2bdqcOXPs7Ozef/99vV6fo8/BgwfffvttHx+fQqwL\nAAAAACg0KwbC2NjYY8eOvfrqq7Vq1fLx8Xn99dejoqJOnz6do1tmZubs2bNbtmxZiHUBAAAA\nAIVmxUB46dIlBwcHPz8/46KLi4uvr++lS5dydHvmmWe8vb0Lty4AAAAAoNCseA1hQkKCq6ur\nSqUytbi7u+t0uiJZ98aNGz/++KNpsV27dlxhWNwY/3xardbR0dHWtQB5Mw5EV6lUfEpRnNnZ\n2YmIvb09H1QAQJGz7qQy5olORAwGQ1Gte/ny5U8//dS0WLduXdPpRBQTxr+go6Ojs7OzrWsB\n8mYKhHxKUZwZA6FGo+GDCgAoclYMhGXLlk1ISDAYDKZop9PpPDw8imTdwMDAzz//3LTo6+tr\n4blHPDHGn9pJSUlardbWtQB5S05OFhGDwcB/ICjOsrKyRCQ9PZ0PanHj7u5u6xIA4HFZMRDW\nrl07MzMzIiLC399fRHQ6XWRkZJ06dYpk3XLlyjVv3ty0qNPpMjMzi/oVoAhkZWXxp0GxZfxw\nGgwGPqUozozH1/R6PR9UAECRs+KkMh4eHm3atPn0008jIiIiIyM/+eSTWrVq1a9fX0T27du3\nbds2Y7f79+/HxsYmJiaKSGxsbGxsbFpaWgHrAgAAAACKhHWvIRw7duzSpUvfffddvV7fpEmT\n119/3TgE9Pfff09ISHjuuedEZMKECTExMcb+w4cPF5GXXnqpR48e+a0LAAAAACgS1g2ETk5O\nr7322muvvZajfcKECabHy5Yte6R1AQAAAABFwopDRgEAAAAAxRmBEAAAAAAUikAIAAAAAApF\nIAQAAAAAhSIQAgAAAIBCEQgBAAAAQKEIhAAAAACgUARCAAAAAFAoAiEAAAAAKBSBEAAAAAAU\nikAIAAAAAApFIAQAAAAAhSIQAgAAAIBCEQgBAAAAQKEIhAAAAACgUARCAAAAAFAoAiEAAAAA\nKBSBEAAAAAAUikAIAAAAAApFIAQAAAAAhSIQAgAAAIBCEQgBAAAAQKEIhAAAAACgUARCAAAA\nAFAoAiEAAAAAKBSBEAAAAAAUikAIAAAAAApFIAQAAAAAhSIQAgAAAIBCEQgBAAAAQKEIhAAA\nAACgUARCAAAAAFAoAiEAAAAAKBSBEAAAAAAUikAIAAAAAApFIAQAAAAAhSIQAgAAAIBCEQgB\nAAAAQKEIhAAAAACgUARCAAAAAFAoAiEAAAAAKBSBEAAAAAAUikAIAAAAAApFIAQAAAAAhSIQ\nAgAAAIBCEQgBAAAAQKEIhAAAAACgUARCAAAAAFAoAiEAAAAAKBSBEAAAAAAUikAIAAAAAApF\nIAQAAAAAhSIQAgAAAIBCEQgBAAAAQKEIhAAAAACgUARCAAAAAFAoAiEAAAAAKBSBEAAAAAAU\nikAIAAAAAApFIAQAAAAAhSIQAgAAAIBCEQgBAAAAQKEIhAAAAACgUARCAAAAAFAoAiEAAAAA\nKBSBEAAAAAAUikAIAAAAAApFIAQAAAAAhSIQAgAAAIBCEQgBAAAAQKHsLemUlJS0a9euPXv2\nnDp16u7du/Hx8WXLlvX29m7cuHHXrl27devm4uJi7UIBAAAAAEXrIWcI09LSZs2a5efn169f\nv7Vr12ZmZvr7+4eEhPj7+2dmZq5bt65fv35+fn6zZ89OS0t7MhUDAAAAAIpEQWcIr1692rt3\n7zNnzvTt23fo0KHt27d3cnIy75CcnPzzzz+vXr164sSJX3755bfffuvn52flggEAAAAARaOg\nQBgUFNS4ceOzZ8/WrVs3zw7Ozs6hoaGhoaHnz58fM2ZMUFBQXFycdeoEAAAAABSxgoaMjhkz\nZt++ffmlQXN169bdt2/f6NGji64wAAAAAIB1FXSGcNq0aeaLqampJ06ciIqK6tSpk5eXV1ZW\nlr39P6vb2dlNnz7dWmUCAAAAAIqapbedmDVrVsWKFdu2bTtgwICIiAgRCQsLGz58eHZ2tjXL\nAwAAAABYi0WBcNmyZW+++WaHDh0WLVpkagwICFi7du2sWbOsVhsAAAAAwIosCoQLFiwYNWrU\nli1bhg4damocMmTIhAkT1q5da7XaAAAAAABWZFEgDA8P79OnT+729u3bX716tahLAgAAAAA8\nCRYFQo1Gk5qamrv9zp07Go2mqEsCAAAAADwJFgXC5s2bz507Nz093bwxPj5+1qxZLVu2tE5h\nAAAAAADrsigQhoWFHThwoF69ev/9739FZMmSJcOGDatevfqFCxemTJli5QoBAAAUZOrUqSqV\nqnz58pmZmbmfHTlypEqlevrppwu38QEDBri4uFjS8+mnn65Tp07h9gKgBLEoELZr127Pnj1l\ny5ZduHChiKxcuXL16tUBAQH79u1r06aNlSsEAABQFrVaHRcXt2vXrhztaWlp33zzjYODg02q\nAlAqFXRjenPPPPPMiRMnYmNjIyMjVSpVtWrVPDw8rFoZAACAMqnV6hYtWqxatapHjx7m7Vu3\nbk1OTm7WrJmtCgNQ+lh6Y3ojLy+vJk2aNG7cmDQIAABgJVlZWb169dqxY8e9e/fM29esWdOx\nY8ccZwh37drVrl07V1dXR0fHBg0afPLJJwaDwfiUwWB4//33fX19y5Qp07Bhw40bN6pUKvN1\nf/nll5CQEDc3N0dHxyZNmqxYsSLPem7dujVy5Mhq1aqVKVOmYsWKffr0CQ8PL9JXDMBmCjpD\naOHAcf5HAAAAKFrPP//8xIkT169fP3bsWGNLTEzMnj17Fi9evHTpUjs7O2Pj5s2be/fu/fTT\nT69atcrV1XXjxo3jx4+Pjo6ePXu2iMyaNSssLGzgwIEvvvjivXv3wsLCsrOzTbv46aefOnfu\n3Lp163Xr1jk6Om7atGnEiBFxcXFvvPFGjmJ69+597dq16dOn+/n5RUdHz5w503jvMScnpyfy\nZgCwooICoZeX1xOrAwAAACZVqlR55plnVq1aZQqE69ev12g0ffv2XbJkianbpEmTfHx89u3b\np9VqRaRz586xsbHz58+fNGlSuXLl5s2bV79+/S+++MJ4YrBdu3bVq1c3nWB84403fHx89uzZ\nY1w3JCQkOjp6+vTpY8aMcXR0NO0iISHh6NGjEydOHDFihLGlTZs2GzZsiI+PJxACpUBBgfDQ\noUMFr5ycnBwdHV2k9QAAAEBEZNiwYYMHD/7zzz/r168vImvWrOnVq5erq6upQ3R0dHh4+Msv\nv2xMdEbPPvvsd999d/To0YYNG0ZHR/fp08c0TLRy5crNmjU7c+aMiMTGxp44ceKVV14xGAxp\naWnGDqGhoVu3bj1x4oT5LKZOTk5eXl4bNmwICQnp2LGjWq328/ObNGnSE3gHADwBlk4qk6ej\nR48OGTIkKiqqqKopNI1GY2//WK8FRc749aPVas2PMgLFil6vFxGVSsWnFMWZcXCgvb09H1Sl\nef75511dXVetWjVr1qxz586dPHlyxowZ5h2Mv8F8fHzMGytXriwit27d8vb2FpHy5cvneNYY\nCCMjI0Vk4cKFxjnkc2/WxN7efufOnf369QsODi5XrlxwcHCvXr369etnGrYKoESzNETt2LFj\n/fr1N27cMP5+EpHs7Ow///zT/IiUbZmun0axYjAY+NOg2DKfd8G2lQAF4IOqWE5OTn379l23\nbt3//ve/NWvWVKpUKSQkxLyD8dhrRkaGeaPxc6JSqfL8wJiuITSu++KLL7788ss5+tSqVStH\ny1NPPRUREXHgwIHdu3fv2rXr66+/XrBgwf79+4vP70AAhWZRINywYcPAgQPt7e0rVqx48+bN\nypUr63S65OTkjh07jh8/3tolWiIzMzPPm7fChozfQxkZGaaBKEBxY/xwmg+XAooh46HYrKws\nPqjFjYV3eH8cQ4cOXbFixaFDhzZs2PDCCy/kOCnn6+srf5/rM7l586aI+Pj4GM8Q3rlzx/zZ\na9euGR9UrVpVRPR6fcuWLS2pxM7OrmPHjh07dpw5c+bixYtHjRr11VdfDRkypNAvDUAxYdFt\nJ2bPnh0aGhoXFxcZGanVan/44Yf4+PiFCxfa29u3b9/e2iUCAAAoU9u2bWvUqDFr1qzr16/n\nTl8VKlRo2LDh9u3bU1NTTY2bN292cnJq1apV9erVvby8fvjhB9PwrvDwcON4UREpV65c8+bN\nN2/eHB8fb1p3zZo17777blZWlvlejh8/PmDAgJiYGFOL8USleQuAksuiQHjx4sXRo0ebX8Rs\nb28/atSowMDAiRMnWq02AAAARVOpVEOGDNmxY0dgYGCjRo1yd/jwww/v378fEhLy7bffbtu2\n7YUXXti1a9fkyZPd3NzUavUrr7xy/vz53r17b9y48fPPP+/atWtQUJBp3Y8++iglJaVt27Zr\n167du3fv5MmTX3rppejo6BzzMlSpUmX37t0hISErVqzYt2/f+vXrBw8erNVqn3vuOau/fgDW\nZ1EgVKvVpvmpHBwcEhMTjY979OixadMma5UGAACgeEOGDDHGwjyfffbZZ3fu3KlWq4cOHdq3\nb9/w8PAVK1a89dZbxmfDwsLeeuutX3/9ddCgQYsWLZo7d27r1q1N1xy2b99+//79lSpVGjNm\nTM+ePb/99tv3339/6dKlOXZRqVKlAwcO+Pv7v/POO927dx8/fnz58uUPHDgQEBBgvVcN4InJ\n+4LjHFq2bOnr6/vll19qNJo6deqMGDFiwoQJIrJ58+bBgwcnJSVZv86H0Ol0XENY3MycOfPH\nH3/88ssvy5UrZ+tagLwlJyf36dOnZcuWU6dOtXUtQL62bNmycOHCqVOnWnitF54Y7tgMoBSw\naFKZ11577YUXXkhMTNy9e3eXLl0mT5588+ZNT0/PxYsXBwYGWrtEAAAAAIA1WBQIBw4cqFar\nb9y4ISJTp049f/78/PnzRcTX13fevHnWLRAAoHjXr19funSpabp8pbl7966IrFmzZsuWLbau\nxTYcHBxef/11Dw8PWxcCAKWQpfch7N+/v/GBh4fH3r17o6OjExISatasqdForFYbAAAiIqdP\nnz5+/Litq7CxK1eu2LoEW7pw4QIjZgHAGiwNhLdu3dq4ceO4ceOMixqN5uuvvx45cmSlSpWs\nVhsAACJ/39e0avD0sv5dbV0LnrSYkytv//qZJVMeAAAKwaJZRi9cuNC0adM33njD1JKSkhIW\nFhYUFBQREWG12gAAAAAAVmRRIHzrrbdcXFwOHTpkaqlWrdq5c+ecnZ1N8xoDAAAAAEoWiwLh\nwYMH33777aeeesq8sW7duhMmTDhw4IB1CgMAAAAAWJdFgTA5OVmr1eZut7e3T05OLuqSAAAA\nAABPgkWBsEmTJqtXr9br9eaNycnJixYtaty4sXUKAwAAAABYl0WzjE6ePLl79+716tULCQmp\nUKFCWlrazZs3t23bFh8fv2PHDmuXCAAAoBCJiYnW2Kyrq6s1NgugFLAoEHbr1p7FxwwAACAA\nSURBVG3btm2TJk1asGCBqTEwMHDt2rVduzIDOAAAAACUSJbehzA0NDQ0NPTu3bs3b94UEV9f\nXy8vL2sWBgAAgLxdunTp3LlzPXv2tHUhAEo8SwNhSkqKTqerVKmSt7d3WlraV199dffu3R49\netSuXduq9QEAACCHdevWHThwoEOHDu7u7rauBUDJZtGkMuHh4X5+fqtXrxaRrKysZ555Ztiw\nYRMmTAgMDDxx4oSVKwQAAMADjFP9ZWdn27oQACWeRYHwnXfeqVixYv/+/UXkq6++OnLkyJIl\nSy5fvtykSZMZM2ZYuUIAAAAAgFVYNGT00KFDc+bM8fPzE5EtW7Y0atRo5MiRIjJ27Ng333zT\nugUCAAAojF6vv3LlSo47fplLSkoSkcuXL8fGxubXp0KFCgwoBfBQFgXC+Pj4SpUqiYher//h\nhx9eeuklY7u3t3cB/w0BAACgELZt2zZ37tyHdiv4uHzNmjWXLVtWdEUBKJ0sCoQVKlS4cuVK\nx44df/zxx7i4uG7duhnbIyMjPT09rVkeAACA4uh0OhHpWN6zimOZwm1h083bCQkJRVoUgNLJ\nokDYuXPnd99999KlSxs2bKhevXrbtm1FJCYmZt68eW3atLFyhQAAAEoUWql8ay+Pwq279/Zd\nQ9FWA6CUsmhSmWnTplWvXn3mzJkpKSkbN260s7MTkVdfffXGjRtTpkyxcoUAAACwrgsXLrRs\n2dLe3tIbksXExGi1Wl9f3xwznTZr1kxlxtPTMzg4+OjRo6YOgwcP7tq1q3nnU6dOmW8hKyur\nYsWKKpUqKyvrobsD8PgsCoSVKlU6cuSITqeLjo4OCgoyNr7xxhvnz59v0KCBNcsDAACAdX31\n1VcdO3YMCAiwfJVly5Y9/fTTGRkZ27dvz/HUsGHDIv+2d+/e8uXLh4SEXL16Nc/tlC9ffvny\n5eYtO3fuzD2bTgG7A/CYLD0OJCJubm7mi82aNSvqYgDYwMyZM2/evGnrKmzD+Jvjjz/+GDdu\nnK1rsZkePXqEhITYugoAtpSenn706NGTJ09+8cUXlvTX6/VLliyZMmXK6dOnFy9e3LNnT/Nn\nnZ2dfXx8jI99fHzWrFnj4eGxY8eOsWPH5t5UaGjoF198MXv27DJl/rpacsWKFcHBwevXr7dw\ndwAe0yMEQjyqtLS08PBwg0GhY/jv378vImfPnnV1dbV1LbZRqVKlihUr2rqKh0hLS/vxxx9t\nXYWNJScnX7p0ydZV2Mwvv/xCIAQUbsiQISJy8uRJC/vv3LkzNja2X79+TZs2DQoKunbtWvXq\n1fPrbGdnZ2dnZz7+01xQUNDBgwc3bdr0wgsviEhMTMzu3bu/+OIL80D4SLsD8KgIhFa0bNky\nBjZ88MEHti7BZjQazddff+3o6GjrQh4usZb64gg7W1eBJ80+2RA4Pe+faABs69q1ayIy4fT5\nx9mIg05XNNXk8vnnn/fr18/FxaVx48aBgYFLly6dMWNGnj2TkpLee++9lJSU7t2757e14cOH\nL1++3BgI165d27FjxypVqhRudwAKgUBoRcabxvaqUsHF4ku0UWr8dPfezZS09PT0EhEIAQDF\niouLi4j4uzi7awr5E+J0fILlM8Q8kqtXr+7Zs+fAgQPGxeHDh0+fPn3q1KkajcbYsmTJklWr\nVhkfJycn169ff/PmzbVq1cpvg8OGDZs6deqVK1dq1KixcuXKsLCwR9odgMdEULG6wdV9KpXR\n2roKPGnXklNupqTZugoAQInk5eUlIi/XrFro2048f+i4wdm5SIv6y+LFi/V6/bPPPmtczM7O\nTkpK2rx5c9++fY0t/fv3N4a6hISE4ODg0aNHh4aGFrDBypUrd+nSZcWKFT179rx9+3bPnj3N\nB68+dHcAHhOBEAAAABbJyMhYsWJFWFjYsGHDTI0TJkxYvHixKaG5u7ubzgfOnz//5Zdf7tCh\nQ7169QrY7IgRIyZOnJiUlDRo0CAHB4dH2h2Ax2RRINRoNFpt3ue4VCqVm5tb48aN33jjjY4d\nOxZpbQAAALC627dvZ2Vl3bt3T0SM806XLVvWxcVl+fLlSUlJr732mqnnxo0bdTrd2LFjjecw\njcaNG9ehQ4dLly75+/vn2PLgwYO/++67gQMHHjt2LL8fkyLSvXv3UaNGrVu37ocffjBvf9Td\nASgEi+5D+Morr9SvXz85OblatWqdO3fu0qWLn59fcnJykyZNevToUa9evUOHDgUHB+/evdva\n5QIAAKBotWzZ0tfX96WXXsrOzvb19fX19V22bJmI7Nu3b9u2beY9Fy5c2Lt3b/N4JiLt2rUL\nCAhYvHhxnhtftGjR7du3J06cWEAB9vb2Q4YMqVatWmBg4GPuDsCjsugM4XPPPbd169bDhw+3\natXK1HjkyJGhQ4fOnTs3KChIp9N17tx5xowZXbt2tVqpAAAAKHrGSU1z27BhQ46WgwcP5tnz\n/Pm/JkQ9fvx4jqe8vb3v3LljWly3bp3psXnnjz76yPS4ZcuWxrt2PXR3AB6fRYFw4sSJ06dP\nN0+DItKqVau33npr/PjxP/30k7u7++uvvz5y5EjrFAkAAKA48y5dXX41snDr3s/MKlu01QAo\npSwKhH/++WeFChVyt1euXPm3334zPnZyclKpVEVZGgAAJdn9m3+c2PT2nYhD2Vnp5ao0bPTs\n21Ub93zMzgkxEZunNrJ3cHphbuxD181Iif/i1bznqOw05ruqTXo99kuEtfj7+7u5uekMBp0h\n7w6pqalZWVkuLi75/foq4+xc8DwuAGBkUSD09vZetmxZcHBwjv901q9f7+zsLCJZWVmLFy+u\nU6eOVWoEAKCkSbhzaefMtmXcygc9P0Pj6BZxeM0Pnz3fafSmPGOYpZ0Nhl9Wj8zOSLV3cLJk\nXXsHpzZDl+bYV/S5fdeOb3T1rmGFF40i06pVqy1bthTQYfLkyYcOHVq9enW5cuWeWFUASiWL\nAuGIESPef//9c+fOhYSEVKpUSaVS3b1796effjp27Ni4ceNEpF+/frt27Vq/fr2VqwUAoGT4\nfdt7en1Wtzd/dnKvJCI1mg/cOi3o2NfjqzbuKblO6VjY+cLBpXevHK1cL/jejVOWrKu2d6jd\n9iXzHWWk6k5tCavT4RUPn0bWe+0AgBLEokAYFhZmb2+/YMGCOXPmmBrd3d3/85///O9//xOR\n9u3b9+3bd8CAAdYqEwCAksOgz77x+1bfRs8aQ5qIqNR2tVoPO/bVf+Juni7n27gQnVPio49/\n82ajZ99OvnfdFAgfaUcicvK7d/XZmU2fn26lFw4AKHEsCoRqtXry5Mnvvvvu9evXY2JiDAaD\np6enn5+fnZ2dsYP5DWoAAFC4xNirmWmJ5XwemEDfs2oTEYmLzJnTLOx8ZN1o53K+jbq9dWTd\nK4XbUXz0uQs/LWo5aIGDE7ONlHhOTk729vZlypSxdSEASjyLAqFRXFzc2bNnb926pVarfXx8\nKlSo4Orqar3KAAAooVJ1t0SkjNsD87GVcSsvIim6W4XofPW3ryNPb3v27SNqO02hd3Ry82QX\nb78cg0hRQo0dO3bAgAFOTk4P7woABbIoEOr1+vHjx3/22WeZmZmmRmdn57CwsAkTJlitNgAA\nSqTszDQRsbN3MG+0s9eannqkzunJcUe/HFcv+FVvv+aF3lF89Lnrp75r/X+LVGq7Qr8uFB+u\nrq4clwdQJCwKhJ988sncuXN79+4dGhpauXJlg8Fw8+bNTZs2vfnmmxUqVBgyZIi1qwQAoASx\n05QRkeysdPNGY0Kz1zg+audjX/3HXuvUtFceF/5ZvqPwHz/XaF1qtHihcK8IAFBaWRQIV65c\n+e9//3vRokXmjS+//PKAAQPmzZtHIAQAwJxT2coikqq7bd5oHN7p5FHlkTpH/bk34sjaTmM2\nG8SQmZ4kIvrsLBHJTE9Sq+0t3JFen3X1t698GnbTaF2K6jUCAEoHiwLh5cuX586dm7v9hRde\nYGZRAABycPHyc3DyiL1+wrzx7tVjIuJZLeiROofv/0wMhh8W5LxJ/boxrr6Nnu00bqslO7p7\n+WhaUmyVBt0e94Wh2Dhw4MCvv/46fvx4tVpt61oAlGwWBUJ7e/vExMTc7RkZGaaJRgEAgJFK\npa4e1OfykbVJsddcvKqLSHZm2sWDyz18GpWtVPeROtfv/F+/5g8ce/1j18w7lw4Gv7pd61zO\nwh3FXD4sIp5Vc96FAiXXvn37Dh069NJLL3l4eNi6FgAlm0WBsEmTJvPmzevevbuDwz+Xraem\nps6dO7dp06ZWqw0AgJKq8XNTbpzavGt2x3qdXtNonS8eXJZ873rn/+41Pnvj9637P+/dvP8n\n9Tq9WnBnV+8art41zLcccXiVys6+gv/TluzISHcrXERcvWs+gReOJ8lgMNi6BAAlnkWBcNKk\nSd27d/f39+/atauPj09GRkZkZOT27dvj4+N3795t7RIBAChxnMv5hr516PjGN09tDTNkZ3lW\na9r5v3sr1en419MGvUGfbdDrLer8ODsSEZG0pFiVSs0FhACA3CwKhKGhoZs2bZo0adKSJUtM\njY0aNVq7dm1wcLDVagMAoARzrxjQaeyWPJ+q2qTXi8sMFnbOoc3QZW2GLnukdYPHbbVkyyg+\nkpOTf/755+zs7Pw63L59W0T27t3r7OycX5/atWsHBARYpT4ApYilN6bv1atXr169oqOjo6Ki\nVCqVr69vhQoVHr4aADwBV1NkRaT8mSiZeqnuJAOrSOv8L6opuPPvCbI+Sq4kS5ZBfBylV0V5\nxktUfz/7W7ysj5KIZBGR2i7yoq/U5z5gAIretm3bFi9e/NBuBfepVKnSl19+WXRFASidLA2E\nRpUrV65cubKVSgGAwohKk//+KWU18qKvONnJvrvy3gUJqy2tyz1y56P3JeyC1HSWwT6iVsmP\nsTIzQm6ny6AqIiI/35MPLomfk4ysJiKy7Y68eV7m1Jfa+R6eB4DCycjIEJGYVurUiqqHds6T\nz259VlZWkRYFoHQqKBDWqVPHkk2Eh4cXUTEoFs7evTflwOHDN2+lZ2c38PZ8s2Wz5/xrFK7z\nT9dvzjx6/ExMbJY+27+cx5imgQPqB6hE4tPTK85bkucGv37+2R7+NUQkU6//6OjxtX+cv5WU\n7OPmMrxRg/+2aFrIb0WUbmtvSrZBPq4v5TQiIh09ZfQfsvi6tConuT8xBXdeESkVtTKnvmjV\nIiLdysvLZ2RjtLxQRVQiy2+Ip4PMbSBl1CIiwV7y4u+y/IbMzDlpJAAUiYTaal2dQn71Vdqf\n73BTADBX0L1rvCzzxGrFExBxP77TlxsvxsW/167V512ecdM69Ptux9ZLVwrReUfE1dCvN8en\npb3bpvm0dq21dnYv7tj74eHfRMTJ3n5h12dy/PtXHX+1SuVX1s24+rBtez745djzAbWWhAa3\n9a3yzs+/zPjl2JN5E1CS6A1y5L608Pgr4ImIWiWdveVWulxJfrTOBpFu5WVU9b/SoIjYq6Se\niyRnS7pe7mfK7XRp5fFXGhQRRzvp5C2/6ySRY/AASrbo6OhBgwaVL1/e3d29ffv2x449/As3\nJiZGq9X6+vrmuNCxWbNmKjOenp7BwcFHjx41dRg8eHDXrl3NO586dcp8C1lZWRUrVlSpVOZn\nOPPbXX77NapVq5blb8LjK8TbCBQHBZ0hPHTo0BOrA8XEjF+OZekN3w/sXdHFWUT61avdavWG\niT8ees6/Ru5DlAV3nnLgSDV3t/2D/uVoby8iLwbWD1rx5bzfTk5q/ZSDnd2Ljeqbb0qXnvH+\noV9fbtKwobeXiOy7euPbCxGzO7UbGxQoIv3r1k5Iz/j5xs132jTnJCEecDtdUrOlhtMDjbWc\nRUSupEhN50fr/HzFB54yiFxLEW8HKaOWpCwREc2DB9HKO4hB5HqqNOBKQgAlWM+ePZ2cnPbu\n3evi4jJ58uTu3btfvXq1gOlqRGTZsmVPP/302bNnt2/f3rNnT/Onhg0bNm3aNOPjO3fufPzx\nxyEhIWfOnPHz88u9nfLlyy9fvnzBggWmlp07d+r/noDXkt2ZDB48OCwszLzF/H5pRpmZmRqN\nJr/F/FjYrRBvI1AcFHSGcPjw4ampqRZuKDU1dcSIEUVREmwm22DYHnG1W83qxoAnInYq1f81\nqHs1Xncm5u4jddYbDC8G1p/1TFtjGhQRjVrdonJFXXpGSmZm7l1PPXgkU6+f2ralcXHd2fPu\nWoeRjRuYOnzZs9u+gb1Jg8gpLlNExOPB7+myGhGRe7k+aRZ2ztRLTLqcS5SZEXIlRUZVFxEp\npxFnO/kj4YF1LyaLiMTn8ZEGgJIiLi6uevXqS5Ysady4ca1atWbOnHn37t2zZ88WsIper1+y\nZMmgQYMGDBiQe2IbZ2dnn78FBQWtWbNGRHbs2JHnpkJDQ7/44ou0tDRTy4oVK3JMYl/w7kzc\n3d1rPahq1aoikpmZqVKpVq5c6efnN3z48ByLInLnzp2BAwdWrlzZ09OzU6dOZ86cyb2WiKxa\ntapu3bqOjo4VK1YcPXq0ec2FexuBYqKgM4T79+9v0aLF/PnzO3ToUPBWDh48OHbsWJ1OV5Sl\n4Ym7Fp+QmJHRsPwDw4AbV/AWkT9iYgPLez9SZ+PJPRODyLnYez6uLs65jrGdvxe39Pezc4Pb\nl9VqjS1Ho283r1xRa2cnInqDQa0iCSIfGXoREfsHj20Zz+Nl5jzAbGnnPxLlrfMiIhW0ElZb\nWniIiKhV8mwF+TpaPr0qfSqJRi27Y+R4vIhINjeGBlDEjHec194zOEUVcguqbMl9ni1P5cqV\n++abb0yLUVFRarW6SpUqBayyc+fO2NjYfv36NW3aNCgo6Nq1a9WrV8+vs52dnZ2dXX4z3AQF\nBR08eHDTpk0vvPCCiMTExOzevfuLL75Yv3594XaXm0ajUalUCxcu/O6772rUqJFjUUR69uzp\n6el56tQpZ2fnsLCw9u3bR0REeHp6mne7cuXK8OHD9+3b16FDh6ioqD59+syZM2fSpEmmvRTi\nbQSKiYIC4YkTJwYOHNixY8f27dsPHTo0JCTEx8fHvENUVNQPP/ywevXq/fv3h4SE7N+/38rV\nwrpuJyeLSAWnBwbUeTs5isitpJTCdU7Pzo5JTolOSl508swfd++tfq5L7v2+d/BodXe3FwP/\nGkSqNxhu6BJC/KquOP3nx8dOXLmvK1tG26eO/4cd2rjmGvsBpXPIK/sZg59DrhEQFnau6Szv\nB4guU07oZMoF6V9FhvuKiAzzlcQs2X5Htt0REQlylxd95ZMrUsau6F4PAIiIXLx4UUR8tz/W\nxDC6tEc+Uh8XFzdixIhXX301x0++HD7//PN+/fq5uLg0btw4MDBw6dKlM2bMyLNnUlLSe++9\nl5KS0r179/y2Nnz48OXLlxsD4dq1azt27JgjR1m4uyVLlqxatcq85aOPPho9erSIqNXqHj16\nNG7c2Nhuvnjq1Klff/317NmzxhuqTZs2beHChVu3bn3xxRfNu507d85gMHh4eNjZ2VWtWvXo\n0aN2dvn+52/h2wgUEwUFQk9Pz927d3/55Zfvvfee8Vy5t7e38UpZnU539+7dmJgYEfH391+3\nbt3AgQPV6oIGoKL4S8vKFhEHuwf+jsbTdOnZOQ/sWdj5l5vRoV9tFpGqbq4beoWG1qyeYzvn\n78VtuXh5QZeOdn+fBkzJzDKIfH/1xu937k5t26pcmTLfX7sx/7dTl+/rdvXvVQSvE6WJcXqY\n+w8O2ozLEBHxynX4wMLO7vbS0kNEpEt5Ka+VDVHSxkMCXMReJf+pIcOryu008XQQLwfZfFtE\npKK26F4PAIiIGIPE/QbqdM9CbsH7qN5N6/TwfmbCw8Ofe+654ODgjz/+uIBuV69e3bNnz4ED\nB4yLw4cPnz59+tSpU01X2ZkHs+Tk5Pr162/evLmA+V2GDRs2derUK1eu1KhRY+XKlTmuA3zo\n7kz69++fY11v738GN/n7+5s/ZVq8fPmySqUKCAgwLjo5OVWpUuXy5cs5urVo0WLMmDEtWrRo\n3rx5cHDwwIED85uN38K3ESg+HnIfQrVaPXjw4IEDBx4+fHjPnj2nT5++e/duXFxc2bJla9So\nERgY2KVLl1atWhVwjAQlSBl7Y5x74HhkWna2iJSxz/lRsbBzYHmvb3t3j01N/eFa5L82bX+j\nRdD77VqZr7L41B8uDg796waYWjR2ahFJzMg89uJANwcHEelU3Tdbr59//Pffbt1+qtKD035A\n4SqVERf7v67lM7mQJCLin+s6/oI7x2fKoTjxd5YAl3+ebeAqX4tcTfmn0d1e3P9+/LtO3OzF\nt0xRvRoAMDLORHIvqPC3nSj3u17r8AiHq3744Yf+/ftPnTp17NixBfdcvHixXq9/9tlnjYvZ\n2dlJSUmbN2/u27evscUUzBISEoKDg0ePHh0aGlrABitXrtylS5cVK1b07Nnz9u3bPXv2PHny\npOW7MzFeQ5jfXrRabQGLxjG6pseqvw9Sm7qpVKoFCxZMnDhxx44d27dv//DDD9etW9evX78c\ne7H8bQSKD4tuTG9nZ9e2bdu2bdtauxrYViUXZxG5nfzA6NDbSckiUsXFpXCdPR0dn63lJyJD\nG9bzdXP56OjxHv41mlWqYHw2S6//5vylLjWquTj8c5xPa2fn5uDQwNvTzWyAaLBf1fnHfz97\n9x6BEA9QibQtJ9/Hyp10qaAVEcnQy+67UsNJqjo+WufkbPn8mtR1ldn1/rmB4SmdiEh5rYjI\nx1fkjwRZ2uivyw6vpMjReOlZQdRc4wqgZDt06FC/fv2++OIL0w0h8pORkbFixYqwsLBhw4aZ\nGidMmLB48WJTQjMPZvPnz3/55Zc7dOhQr169AjY7YsSIiRMnJiUlDRo0yHxqUEt295j8/f0N\nBkN4eHjDhg1FJCkpKSoqKsfpRBHJysq6f/++r6/vqFGjRo0a9frrrxsHspr3sfxtBIoVBnni\nH9Xd3TzKaE/djjFv/O3WHRFpUtH7kTrfTUld+vtZ46JJ6yqVReTs3XumlmPRt++lpnapUS3H\nxgMreN9KeuA0Tka2Xv4ekgo8YLCPOKnljXOy6ZbsjJHx5+ROurxS/a9nj9yXrr/+Nbaz4M7O\ndjKgivyRIOP/lO9uy/Y78mGEbL4t9VylibuIyNMecitN3gqXvXflm1sy8byUd5BBXB8CoGRL\nTU0dOnTo66+/3qBBg5t/S05OFpHly5fPmzfPvPPGjRt1Ot3YsWOrmxk3btz+/fsvXbqUe+OD\nBw/u1q3bwIED09PTC6ihe/fuOp1u3bp1xmuUCrc7nU4XkUtmXnObmwsMDGzduvVbb7119+7d\nhISEiRMnurm59eqV8xKV1atXN23a9MSJE3q9/s6dO2fPnq1Zs6aFbyNQzBEI8Q+1StWrdq09\nV65f1/01t35aVvaqM+caenvV8Sz3SJ0d7Oz++/3Pk376RW82BuPH65EiUtX9nzu2HYm6LSKN\nHpyqVET61vG/GHf/+2s3TC3fhl8SkeaVOT2IXLwdZE59qeEka27KwmuiUcn/6kqg21/PGgyi\nN4jeYFHnIT4ysZboRdbdlKU35GqKDPWVD+v8dcKwhYe87S8p2fLpVfk6Sp5yl7kNxM2icRYA\nUGwdPnz4ypUrU6ZM8TWzcuVKEdm3b9+2bdvMOy9cuLB3795eXg98cbdr1y4gICC/G0IsWrTo\n9u3bEydOLKAGe3v7IUOGVKtWLTDwgSnKH2l369at88/FdDVgATZs2KDRaGrUqFGjRo1r164d\nPHjQzc0tR5/hw4ePHDnyX//6l5OTU2BgoK+vb45LBAt4G4Fijp8yeMA7bZpvvXSl84bvxgYF\nOms0K8/8eSMhcUe/v+4Auz3iav/vdnz0TNsxQYEFd3bXOrzZstmMw8eC12/qHVBLa2d3KDLq\n6/MXW1Su2KHqP2dULsTFiUiNsu45yhjWqN6qP871+27Ha82a+JV133v1+sbwS0Ma1q3lUfYJ\nvREoWXwc5b2AvJ9qXU72trS0s4h08pJOOY9Q/KO9p7Qv7AwPAFAsderUyfwKOnMbNmzI0XLw\n4ME8e54/f9744Pjx4zme8vb2vnPnnxFD69atMz027/zRRx+ZHrds2dJY0kN3l+emcstx04sc\ni76+vps3by54LZVKNWXKlClTpuS3iwLeRqCYIxDiAT6uLj8O6vP2T79MO/RrlkHfuEL5Hf16\ntv87wukNhmyDwXTSr+DOk59uUcuj7KJTZz745ViGPruam9uUti3HBTU2v6ngvdQ0tUrlkutm\nEg52djv69Qo7eGTFmT/jUtN83Vyntm35Rosg678BAADYnnFSk1qr8753n6VyXu0BAHkgECKn\n2uU8NvbO+2ZBPfxrpL05zsLOIjKwfsDA+vmfihH5Nv91Pcpo54d0mB/S4SHlAgBQ6jRv3vzM\nmTMFnHG6fPlyfHx8o0aNct99wcQ4SwoAFIxACAAAULwEBATMmjWrgA6TJ08+dOhQWFhYuXI5\nL/IHgEfCpDIAAAAAoFAEQgAAAABQKAIhAABACVOxYkU3NzdnZ2dbFwKgxCMQAgAAlDCjR4/+\n5ptvtFqtrQsBUOI9QiBMTU09dOjQV199FRsbK7lu4QIAAIAnQ6VSOeS6aRMAFIKlgXDWrFkV\nK1Zs27btgAEDIiIiRCQsLGz48OHZ2dnWLA8AAAAAYC0WBcJly5a9+eabHTp0WLRokakxICBg\n7dq1Bc+JDAAAAAAotiwKhAsWLBg1atSWLVuGDh1qahwyZMiECRPWrl1rtdoAAACQhw0bNowc\nOTIzM9PWhQAo8SwKhOHh4X369Mnd3r59+6tXrxZ1SQAAACjIn3/+GRERkZiYaOtCAJR49pZ0\n0mg0qampudvv3Lmj0WiKuiQAAPJw4/t3b3z/rq2rAACgVLHoDGHz5s3nzp2bnp5u3hgfHz9r\n1qyWLVtapzAAAAAAgHVZdIYwLCysU6dO9erV69Kli4gsWbJk0aJFmzdvAqGZXwAAIABJREFU\nTklJMZ9mBgAAAI8vOjr666+/1uv1+XUwTvm+ePHiAm5F2KBBg86dO1ulPgCliEWBsF27dnv2\n7JkwYcLChQtFZOXKlSLSvHnzjz76qE2bNtYtEAAAERFx8XlK6+Zr6yrwpKXGXkiJ+dPWVTxp\n+/fv37Jly0O77d27t4Bnf/31VwIhgIeyKBCKyDPPPHPixInY2NjIyEiVSlWtWjUPDw+rVgYA\ngLlydXqW9e9q6yrwpMWcXKnAQGg8N+jTYbJLlWaF28Ll70YYDIYiLQoPl56e3rp162HDho0b\nN+748eP9+/e/devW9evXvb29bV0aHou1/5rXrl3z8/P7448/GjRo8JibmjBhQnh4+NatW1Uq\nlYWrWHpj+pSUlFu3bnl5eTVp0qROnTpbt26dPXv2xYsXC1sqAPw/e3ceF1X1/3H8zAww7Isg\nIooCgvu+ormLfjPNfcn065amFpaVprlvlZWJa5YbmvpL09TcC1FTS1xRK9NAQhFFRAUEZJnl\n98fUfKdhZhwMHPK+no8ePbz3nnvvZ85cYN5z7z0XAGCJnbO3g3ulJ/tPyBXW7+jy5cvdu3cv\nV66ch4dHu3btfvrpp8eukpaWplQqAwIC1Gq14fymTZvKDHh7e4eHh8fGxuobDBky5Pnnnzds\nHBcXZ7gFlUrl5+cnk8lUKtVjd2duvzohISHWd0KJmDx5coUKFcaPHy+EWL58ecWKFVNSUry9\nvc21P3z48NmzZ59igXhC5t7NW7duDR482NfXV/ezc/r0af2iq1evhoWF2dlZe/qtpHzwwQfJ\nycmLFy+2fhVrHzsRFBS0YcMGIYRKperYsePw4cMnTZrUoEGDc+fOPWGxAAAAsLX8/Pzw8PBy\n5cqdPHny3LlzgYGBXbt2fewDLdasWdO6deuCgoK9e/caLRo+fHjyX77//ntfX9/OnTube1CZ\nr6/v2rVrDefs37+/6M2TFnanN2TIkPi/O3z4sFEboyc3WvkgRyubJSUlrVy58v3339dN3rt3\nr27dul5eXnK52c/bixYtsj4QPsFjJ//hkyqf2oMuy/4TNc29mz179rx58+b3339/7tw5f3//\n7t275+TkCCG2bt3aoUOHGjVqPP1S7e3tZ8+ePX/+fOsfS2NVZp02bZqfn9/AgQOFEFu3bj15\n8uSqVas6deo0ZMiQ999/f8eOHU9eMoAyQHlPW+mg6e9c8QyTl/W/vwCehqysrLfffnvMmDFu\nbm5CiGnTpn355ZeJiYkNGjQwt4pGo1m1atXMmTMvXrz4xRdf9OzZ03Cpi4tL5cqVdf+uXLny\nl19+6eXltW/fvoiIiKKbeuGFFzZv3rxw4UJHR0fdnHXr1oWHh3/11VdW7k7Pw8PD5CnBwsJC\nBweHdevWzZ07t3Xr1uvWrTOc3Lhx4507dyZMmPDDDz/k5+c3bNgwMjKyfv36Rmtt3Lhx/fr1\nH330UVJSkoeHR58+fRYtWqSvWefzzz9v1qxZo0aNhBBt27b96aefZDLZpk2bLl26VK1atSNH\njrRv314IkZCQEBoaGh8f/+qrrx49evTQoUOrV6/+4Ycf3NzcirapWrVq0WrfeOON7777TqFQ\nNGnSJDIysk6dOhZer4VV4uLixo0b98svv9SoUeOTTz7p1KnT+fPn69ata+XqJjvE5Ewre1j/\nErRarVwu37hx46pVq+Lj4318fP7v//4vKipq//79Dx48ePvttydPniyEMFfY5cuXJ0yYcObM\nGa1W26JFixUrVoSEhOi2uXXr1jVr1iQmJhYWFs6bN2/o0KFGR4vJUg3fzcTERF9fX13j+/fv\nBwYGzp8/Xxf8Pvroo6pVq/7yyy8tWrTIz8+PjY09f/785s2bTR6uQogLFy6MGTPml19+qVat\n2tSpU/XzTdbfqlWrBg0a6MZzEULExsa2atUqMTHx6NGjRTu8Z8+e48eP37x589ixY83t3ZBV\ngfDEiRORkZFBQUFCiG+//bZ+/fqjR48WQkRERLz77rvWbAFAWebwQOv3A7eaAIAUlS9ffuLE\nibp/379/f/HixTVr1qxZs6aFVfbv35+enj5gwIDGjRs3adIkKSkpMDDQXGOFQqFQKAyv/zTU\npEmT48eP79ix4+WXXxZCpKWlHTx4cPPmzYaBsFi7K8re3l4mk61cuXLnzp3BwcFGk0KInj17\nent7x8XFubi4zJo1q127dgkJCd7e3obNEhMTR44cGR0d3b59+5SUlL59+0ZGRr733nuGO/r+\n++/1YfXYsWPdu3evXLny559/np2dbbKww4cPBwYGTpkyZezYsebaFK128ODB3t7eiYmJTk5O\n77//fnh4+LVr15ydnYu7ikKh6Nq1a9euXQ8dOnTr1q0hQ4bo1rVy9dTU1KIdMnDgQJO9ZE0P\nG75qmUymUChWrly5f/9+FxeX9u3bd+jQYdmyZYsWLdqzZ0/v3r1HjBjh6+trriv69+/fpEmT\nGzduaLXaESNGDBs27Mcff9Rtc8GCBXv27KlUqdKKFSvGjRvXt29fFxcXw12bLNXw3TRsXK5c\nuW3btuknU1JS5HJ5pUqVhBC6qHn+/Hlzh6VGo+ndu3fbtm1jYmLu3btnGE1N1j9q1Kh33nkn\nMjJS9zXE1q1b27dvr9FoTHa4TCbr1KlTdHR0SQbCjIyMihUr6kqPiYkZNWqUbn758uXT09Ot\n2YKUnUx/4Olgb+sq8LSl5xfYugQAwL9VQUGBEOLhjZ8Kc9KebAuawlyVfTFuXlKr1c7OzgUF\nBbpPqBaeZiGE+OyzzwYMGODq6tqwYcMGDRqsXr1af52kkezs7Dlz5uTm5nbv3t3c1kaOHLl2\n7VpdINy4cWOHDh10H6mLu7tVq1atX7/ecM7HH3/82muvCSHkcnmPHj0aNmyom284GRcXd+rU\nqV9++aVChQpCiHnz5q1cuXL37t0jRowwbHb58mWtVuvl5aVQKKpUqRIbG6tQGN+l+euvv06f\nPt1Cvz0ZwzJ+/fXXmJiY1NTUcuXKCSHmzp27YsWKvXv3DhgwoLir+Pr63rlzZ9asWa6urtWr\nVx8/frw+k1izepUqVYp2SGxsbNGZVvZwUUOGDPHw8BBCtG7dOikpadCgQUKIDh06qNXqP/74\n4+7du+a64tixY46Ojrqk9/LLLw8aNEir1epGWBk6dKju6OrevXtERERSUpLh+VULpT72bbp/\n//4rr7zyxhtv6E+PWxYbG5uUlHTo0CFXV1dXV9e33nrr2LFjukUm6x84cOCECRN27typm9y2\nbduHH36YlpZm7rCsX7/+F198YU0lwspAWKFChcTExA4dOhw5cuT+/ftdu3bVzU9OTrZwmyx0\nPr2aaOsSAADAv8m1a9eEEPd++fqfbCRLVYxxZRQKxYULF1JTU5csWdKhQ4dTp055enqabPnH\nH3989913+g+vI0eOnD9//uzZs+3t//z62zCY5eTk1KlTZ9euXRbGdxk+fPjs2bMTExODg4Oj\noqJmzZpVrN3pDRw40Ghdw9EgQ0NDDRfpJ69duyaTyfT3ejk7O1eqVEnX/4bNWrRo8frrr7do\n0aJ58+bh4eGDBg0yOomalZVVUFDg4+Nj7mX+E/oy4uPjhRB+fn6GSxMTTXzUfOwqeXl5CoWi\natWqujktWrQo1ur9+/cv2iEme8nKHi5Kn6wcHR313xHozo89evTo9u3b5roiLi5uwYIFiYmJ\nGo3m0aNHhYWFarVaN7iL/vXqvvJ49OiR4eqWS7XgypUrL774Ynh4+KeffvrYxjq6Bzfoz3VX\nr15dv8hk/S4uLoMGDYqKiho0aNCJEyeysrL69u3r5ORk7rD09va2/rydVYGwS5cu06dPj4+P\n37JlS2BgYJs2bYQQaWlpS5Ys4TmEwDPgYYj891eK8bkBzwa7HG2D+aYv4gJgW6GhobGxseUb\nDXcub+nSTQtuHvvQw7l4v9hr1apVq1atNm3a+Pn5bdq0yeQtf0KIL774QqPRdOvWTTepVquz\ns7N37drVv39/3Rx9MMvKygoPD3/ttddeeOEFC/v19/f/z3/+s27dup49e6ampvbs2dPwQrvH\n7k7P3D2EOkbnPI0mDR/RoT+bZNhMJpMtX7588uTJ+/bt27t374cffrhp0yaj83K6ZhZeqU7R\nIXMe28awDCFEbm6uk5OT5S08dpUNGzYYVmtUuTV7NNkhRWfqRmF5bA8XZaE8C4Vdv369e/fu\ns2bN2r9/v4ODw+7duw1vOrXmDTJXqjkxMTEDBw6cPXu2uR8Zk/Lz8w0n9ddUW6h/1KhRYWFh\nt27d2rp168CBA3XXCZs7LK1/5oSwcpTRefPmBQYGfvTRR7m5udu3b9edi3zjjTdu3Lgxc+ZM\n63cGAACAx9KdzXCp2NCjWviT/Se3cyx6TaNJMTExISEhuqERhRAKhUImk5l7hmFBQcG6detm\nzZp14S8///xzv379DC9O0wWzkJCQxo0bL126dOLEiZcvX7ZcwyuvvLJt27bNmzcPHjzYwcGh\nWLv7h0JDQ7Va7ZUrV3ST2dnZKSkpRU9bqVSqu3fvBgQEjB07du/eva+99tpnn31m2MDd3d3B\nweHu3btFd6FUKmUyme4yYCFEUlLSk7URf51Pu3Dhgn6OydOD1qzi7++vUqlSUlJ0Mw2fl2DN\n6iY7xORMK3u4uMwVdubMGbVaPWXKFN2BVKynejxBqSdOnBgwYICFL1DMqVy5slarvXHjhm7y\n11//fNqqhfqbNWtWr169r776atu2bcOHDxcWD8v09HTrn5do1RnCihUrnjx5Misry9nZWf8w\njYkTJy5evNjoRC2K+qhBLR/uIZSeZfF/XMiwdrRfAABspUmTJjk5OcOHD58zZ46jo+PSpUuz\ns7N1jwpcu3Ztdnb2m2++qW+8ffv2zMzMiIgIw2sjx48f3759+/j4+KIfnYcMGaK76+n06dMW\nzgV179597NixmzZtiomJMZxfrN1lZmYmJCQYbblq1apFLy411KBBg1atWk2ZMmX9+vVKpfK9\n995zd3fv1auXUbMNGzbMnj17165djRo1unv3rm5kSKM2derU+fnnn/v06WM0397ePiQk5ODB\ng126dMnOzl6+fLl+kbOzc0JCwr1797y9vc21MVS7du2OHTtOnDhxy5Ytfn5+a9asmThx4rVr\n1yx8IDe3SqtWrTw8PD744IOFCxfevHlTP3yllavv27evaIeY7CUre7i4zBVWuXJllUp1/Pjx\n1q1bb926VffokVu3blWpUuWx2yxuqY8ePRo2bNiECRPq1q178+ZN3UwvLy8XF5fU1FSVSnXv\n3j0hhG6Rp6enq6urft2WLVt6e3vPmTMnMjIyNTVV/45brv+VV16ZOXNm+fLldRdpWjgsL126\nZDT8rAXFuNvYxcUlJydHfwpbd1I+IyPD3CXmQojs7OxVq1adOXNGpVLVrVt33Lhx+nFaH9sm\nOTk5KirqypUrGo0mKCho2LBhlge8KrOquTpXdLR0ZzaeSa5P/TmkAAA8AU9Pz+jo6ClTprRp\n00alUtWrV2/fvn26rBUdHZ2enm4YCFeuXNmnTx+jO+Xatm1bo0aNL774YuHChUW3//nnn9et\nW3fy5MkWnpRtZ2c3dOjQmJgYo2ddFGt3mzZt2rRpk9GWf/vtt8d+gNyyZcv48eODg4OVSmWL\nFi2OHz/u7u5u1GbkyJEpKSn9+vW7ffu2p6dn165di94t1qVLl+joaKP7GPUv5PXXX9+5c2eF\nChXmzZu3Z88e3SWCY8aMmTp16s6dO69du2aujZHNmze/+eab9erVU6lU9evXP3DgwGNPz5hb\nZdeuXePHjy9fvnyjRo1mzZrVpUsXk49MNLm6yQ7x8PAw2UvW9PATMFmYn5/fpEmTevXqJZfL\ne/fuvWfPnk6dOjVt2tTcKVAjxSr1p59+SkxMnDlzpuElk8uWLYuIiAgLC7t+/bpuTkBAgBAi\nMjJywoQJ+mZOTk779u177bXX/P39Q0NDP/rooxdeeKGwsDAsLMxc/YGBgUOGDJk4caJ+kBtz\nh6VWq42JiZkxY4aVPWn2kgBD8fHxo0aNOnnypMmnRlrYwvz589PT0yMiInSPJUlNTV26dKnR\noWayjVqtHjVqVMOGDQcMGKB7ZkhsbGxUVJS5C6YzMzPL4BMtFyxYcPTo0e3PNSEQStDki7+d\nSH+wZcsWC9+YlAV5eXm9evXiHkJp0t1DGBYWNnv2bFvX8hjffvvtypUrq4TP9wx93ta14GlL\nOx+VemrFrFmzWrZsaetajJXGCCK6Z0l/+eWXUVFRgS8sdq/a+sm289vGbp5Omq+//nNYGt0z\nBlGqkpKSatSoERsbq3sUYdmnUqk0Go3u0sTY2NiWLVtmZmaWSFRDKbl06VLz5s2vX7+uGwfV\nnF27do0aNeqPP/6w8gffqpMYY8aMiYuL69evn7+/v53V5z3S09NPnz69ePFi3aNFJkyY8N//\n/vfixYuGPyTm2gQHB/fq1ev555/XJcD+/fsfPnw4NTVV9yxEAACAZ15BZvKju7892bpadaEQ\nfNP3VAUGBo4bN27atGn79++3dS2Pp9Vq69Sp06pVq8jIyEePHs2ZM6d9+/akwTIrPz8/OTl5\nxIgRY8eOtZwGCwsL58yZM336dOu/BrIq3Z0+fXrbtm36p01YKT4+3sHBQR/hXF1dAwIC4uPj\nDQOhhTa9e/fWzXz48OHu3bsrV65s+FiPW7duxcbG6iebNm2qewhJmWLlzdx4himVSt34yECZ\nJZfLy/5Rav13kXhWOTg4lP0DtQTpPkLc+tHaIexNkrkZ36eD0vbRRx+1atVq6dKlb7zxhq1r\neQyZTLZ9+3bdc/OcnJzat2+/Zs0aWxcFsz755JP58+f37t37ww8/tNxy2rRplSpVMrzS+7Gs\n+hPr6upa9MbZx8rKynJzczMc89TDwyMzM9P6NhqNpl+/fiqVqk6dOvPnzze8J/jq1asffPCB\nfvKzzz6z5lbRp4xPMHBxcTG8gbgM4msL2NnZlfGjVFgclxwS4ejoWPYP1BLUuXPnR48eWXg+\nwfHjx2/evNm7d28LOflfOvjCv5pSqTx37pytq7BWvXr1jhw5YusqYJXp06dPnz7dmpYff/xx\ncTduVWIZNmxYVFTUY/NoUUZPwDB5t6GFNnK5fMmSJRkZGbt37542bdrChQtdXFx0i2rUqDF1\n6lR9Sz8/v+zs7OKWV9pM3goMScnJyTEcPrsMysvLs3UJsDGVSlUGf38aMXpeEyQoLy+vDB6o\npZdRfX19R40aZaFBcnLyzZs3hwwZUgavkALw72JVIHz//ff79u3bsmXL1q1be3t7Gy2dMmWK\nybU8PT2zsrIMn+eYmZnp5eVVrDYBAQEBAQG1a9ceOnTo0aNH9Y8l9ff3NxzVNzMzswx+rlWr\n1bYuATaWn59fBo9MQ2W8PDwFGo2m7B8GfL+GgoKCMnigSuqkJYBnlVWBcPHixbt37xZCGN62\np2cuEFavXr2wsDAhIUE3cnFmZmZycrLR1Qvm2ly8eHHFihVLly7VXQghl8stPCMVAAAAAPAE\nrAqEkZGRXbt2nTJlSrFGGfXy8nruueeWLVv2xhtvKJXKNWvWhISE6J6QGB0dnZeX9+KLL5pr\nk5ubm5+fv2TJkpdfftne3n7Pnj15eXmNGzd+8hcKAADwrGjcuPHDhw8ZExLAP2dVurt3796n\nn35aq1at4m49IiJi9erV06dP12g0jRo1mjBhgu7S0AsXLmRlZb344ovm2ri4uMydO3fDhg1T\npkxRq9VVq1adOXOmv79/cQsAAAB49vTu3Vs/HjsA/BNWBcJ69erdu3fvCbbu7Oz85ptvFh32\ndNKkSY9towuBT7BTAAAAAIA1rAqEy5cvnzx58qefftqkSZPSLggAAECyrH+WNACUCKsC4cSJ\nE2/cuNG0aVNXV9eio4wmJSWVfF0AAAAAgFJmVSCUy+UhISG6gUABAAAAAM8GqwLhDz/8UNp1\nAAAAAACeMvljWxQUFDRr1mzv3r1PoRoAAAAAwFPz+EDo4OBw69athISEp1ANAAAAAOCpeXwg\nFEJ88cUXa9as2blzp0qlKu2CAAAAAABPh1X3EH7yyScKhaJPnz52dnbly5d3cHAwXMooowAA\nAADwb2RVIFSpVF5eXp06dSrtagAAAAAAT41VgfDHH38s7TrwjIm7c3feidhzqWm5hapgT49R\nDeuObFBHIZPplh69fvOj2LOX0tJVGnVoOa/XGzd4qU4N2V/rbr8Sv+Lcxav3HhRo1IEe7kPq\n1hrXuL5SobDVawEAAACeVVYFQqBYTt1K7fLVDn8317eaN3ZzsN959dr4748kZmR+2P45IcS+\nhD/679zXwNdn+nPNFTLZ1t9+H7Hv+z8ys6a2aiaEWHImbvKRE4Nq15j2XHMHueLI9eT3jpw4\nlXL7q14v2PplAQAAAM8aAiFK3oxjPznZ2f0wuJ+vi7MQYkT9Os99ufWLuEvz2ra0k8tnHjtZ\n1cP98OB+TnZ2QogRDeo0Wfd/S86cf69VM5kQay/+GuTpsa57F90Jw7ZVKv2afm/n79ce5OV7\nOSpt+rIAAACAZw2BECZ02bKjQK357D8dJ8YcO3Ur1dHOrn2VSovC21VwcdYKcf/RI5NrKeRy\nT6VSCPFy7Zoj69vp0qAQQi6TNff3i7tzNyMvv5yT44gGdQI93HVpUAhhL5e38Pfb+MtvuYWF\nLvb2jnYKhVomM9isi4O9QibjklGUvIQcseGmiM8WjzTC31F08xUv+Ar5X0ffhSzxVYpIzBEq\nrajsJHr5iY4+Qn9o/nBP7EoVNx4JlVb4KUXn8qJnBWFv1bjNAAAAZQeBECY4yBWJDzJfPXBo\nWqvmq319Tt++M2zPd3lq9Td9uqfl5FZdsdbkWtXLeV0aNUQIMbx+baNFCQ8yvJ2cyjk5ymWy\niCYNDBdphbicfq+ym6uLvb0QYkKzRiP3RX948swr9eso7eyOXE/edfXa2Mb1ne05VlGiLj8U\nk34TPvain79wVojj98TSP8TtPDG6qhBCxD4Qs66Kai5iSGUhl4kj6eKjBJGaLwZXEkKIb26L\nL66Ljj5iSGVhJxNxmWL1dfHbQzGjum1fEwAAQHHxIRsmyGTi5sPstd06t6tSWQjR2811U1CV\nw0nJWiG8HJX7B/YyuZYu0RX1zdWEmKTk+e1ayQ3O/OWr1Wk5ubeycz4/f+nnu/c2vPgf3fyX\n69R0UCjGHoyZczxWCCGXySaHNZ3ZJqyEXyEQlSyUcrG4rvCyF0KIrr7i9Z/F7jtiZBWhkIl1\nycJPKSLrCKX8z6WvXhLbb4mXKwmZEPvSREWlmBzy5wnDBu4i6ZE4fl9kq4Qrv1QBAMC/CZ9d\nYJpSoWhbpbJ+0t/V5ZFK9ahQ5Wxv17FqgPXbOXAtafT+6BeqBb7dvLHh/B9v3nph6y4hRBV3\nty29XnihWqBu/onklHEHD7cNqPRKg7pO9nYHryV9HHvWwU7xXstmJfCq8CyZdFkUasVbwWJl\nkrj8UCjlooGHeC1QlLMXWiGyVKbXUog/M1snH9FV/mcaFELIhKjlKhJyRLZKuNuLrr7CT/ln\nGhRC2MlEbVfx/V2RrxGOcuEgE2q5MLyy2Uku5DIuGQUAAP86BEKY5u3kZPhxVyGXCyE0Wm2x\nNvL5+UvvxBzrVb1aVPcu8r/dGCga+Pp806d7+qNHMUnJ/Xbsndiiydy2LTVa7egDMSFeHtv7\ndNe171g1QKXRzjtxqn/N0BAvz3/+uvDssJOJW3li4TUxpLKYWE38li0+jBcFGjG3hnhQKF46\nZ3qtyk5iXQMhhHje13hRSp7wsBPu9kImRG+/vy3SCpGUK8o7CEe5EEL08xcfJ4j/SxFdfYWD\nXMRlihP3RY8K/wuQQMm5d/183Lez0q+fVeXnuJWvVqPdmBptR8vkf95WffvK4Yv7PniQfFGj\nLnSvUL12+BvVWgwWf/2+/ePM15djlmbe/k2jKnAtHxTSalitjhEKOwboAgD8D4EQxWPNoDI6\nkw4fX3b2wqSwJnPbtpIVaezt5NQtJEgIMaxe7QB3149jz/YIDfZ2cvwjI/PdsKaG6bFjYMBn\n5y+eupVKIMTfyGTiboF4N0Q0cBdCiDblRLSniMsUWiHc7cSCWqbXcjST2Y7dE+czxStV/nbe\nr1AjHhSK9AKx+45IzBXvhf45P9xH2MvEokSxPlkIIWRCDKokhhXjzDlgpbRrJw9+0sHZq1Ld\n/0y0d3S7fu6bk5vGPbx7rVn/T4QQyRf3xCzvVa5Kw4Y9ZsnkisRTXx1b89+H6X807D5DCPHr\n94tOf/1OtbDBDV+cqbBzuPVbzJltk+5eO9lh3HZbvywAQBlCIETxWDOojBBi1rGTK85dXPGf\nDq80qGvY5m7uo12/X2tYoXyzihX0M1tV8v9UnP/l7r0WlfyEEAVqteEq+Wp10ZmAEELYy0V9\n9/9N+jiIfI0o0AilXDT2KMZ2TmWIT66JFl5igP/f5v/8UEz5TQghKijFrOqihddf87PEokRR\n31108xUOcnE6Q2y5JRzk4uVK//AFAUbO7ZiqcHDq9t5PTu4VhBDV24zaM7/ZlSOfNen7oVxu\nd27HVFefwG6TTygcnHRLd82q9+t3nzbsNl3IZFePrXIrH9z2lY26E4Z+Ndo/SPkl6dw3BbkP\nHJy9HrNjAIBkEAhRPNYMKhOTlPxR7NlF4W2N0qAQwkGhePvQDy0qVfz+pd7604BHricLIap4\nuIV4eXooHaL/uPFBe61+6eGkZCFEE78KAjDiYfe3E3q6k3+a4l3YLHbfEZ8lidblxJQQYXQu\nu5qLmFtDZBaKc5li5lUxsJIYGSC0Qiy8Jio5irk1/mzf2ENotGJDsmjnLSo5/oPXg2fQgU86\naFQFzw1bdWrLhLRrJ+3snfxqdggbtNTJw09otXk590yuJZfbOTh7CiGqhQ2p0Xa0Lg0KIWQy\nefngsHvXzxfkPFC6eldvM8rVJ0iXBoUQcoW9b7WW8T+uVxXk2ilJz+kxAAAgAElEQVRdFPaO\nMrlCGFxwYa90lckVci4ZBQAYIBCieBwUCsuDyqg0mgmHjno7OTnZ2UVd+tVwUafAKlXc3d4N\na/r+T6fDv9rRp0aIUqE4kZzy9W+/t/D3a1+lslwmm9k67J2YYz237x5Rv46zvd2hP26sv/Rr\n/5qh9X19SvmV4RlizaAyOp9fFztui5f8xYgqxmlQCOFhJ8K8hBDiP77CVym2pIjnvIS7vbid\nL17y+Vv7Rh5iV6q4/JBACCMKO4eHd68dXzeiYY9ZrUdE3U089cPql9WFeeHjdz/KurPlnYom\n1/Lwq9Fn/hUhRPU2rxgtyroT7+jqo3T1lsnktcPf/NsyrfZByi8u5QLslC5CiLpd3jm2dujF\nvfOrtx2tsHe8/VtM0vlvanV43c7BuVReKgDg34lAiBKWmZ8ffz9DCDHu4GGjRV/37lbF3W1G\n6xYhXp6fx1364MfTBRp1VXf3mW3CxjdpqDsl+HqTBhVcnJedvTBqf7RKow3ydJ/ZJsxohFLg\nMawZVEYIEZUsdt4WE4LFC38fYCajUJy4L0JdRA3X/82s6ya+FuKPXFHLTQghVJq/rVKoEUII\nVTFPTkISZDn3k9uM3FCxZgchhEuTygk//efWb4eEVqt0Kfeft6NNrqNLdEUlnd1263J0074L\nZLL/3Q2rVuXnZd3JeZBy5ciK+zcvtRv9f7r51Vr+V26n/HH9K+d3zRBCyGTy+t2mNu45t4Rf\nHwDgX45ACBP29O9pNGdxeLvF4e2sWdfbySnv3fGW2wyqU2NQnRrmlvarGdqvZqi5pcDjWTOo\nzPlM8VWKeC3QOA0KIezl4rMkUctNLKz9v9OAcZlCCOGrFJUchYtCnM0Uo8X/lp7PFEL8LUAC\nf1HYKSvWaK+fdPGqpC54pCp8ZOfg7F873PrtJF/ad3zd8ID63es+P8lw/p3fj3+3qLMQwtW7\nasfXvgmo3103P/X3Yz9uGOVXo32Ndq8q7J1u/rz/0v4PFXbKBt2nl8CrAgA8KwiEAJ45drLH\nDCqj1orlfwgPO6GUiwNpf1vU2ENUUIqXKolNN8U7v4o23sJeJn5+KI6mi9puopGHkAkxLEB8\nliSmXRFdfYVSLs5liIN3RTtvEcyVeDBB6eZjeCOfTKYQQmi1GvNrmPDbkRWnvnqzauM+7UZt\nMjw9KIQoV6Vh+PjdeQ/vplyOjlnWs17XyU36fKDVak5EjXCvENpp/Le69v61wzUaVdy3s4Ka\nDXSvwJduAIA/EQgBSE+2WtzME0KIyETjRbOriwpKMbSyqOQo9twRm24KlVZUUIphAaK335+n\nBHv5CS97sTNVfJwg1FpR0VEMqyz6+xtvCrDMikFldE5vfevX6MX1u05p0ucDITO+29XR1Seg\nwYtCiNDWI8+Wq3Jp/4dVG/dWung/vJtY/4X3DNOjf63w32KWpV07SSAEAOgRCAH8O31Q03hO\nRJCICLJqXQ878X3YY9p08hGdzA9l1M5btPO2al+AGdYMKiOEOLdz2uVDS1sN/aJG21cN2+Q9\nTEs6t8O7auPyQc31MyuEtv754Mf3ky/5VmsphNCoCgxX0ajyhRAa9d9mAgAkjkAIAIANWDOo\nzK3L0Zf2fRA2aKlRGhRCyO2Up756w7day+cnHdGfBrz1W4wQwtW7qnuFUAcnj5Rfv2uq/fh/\nSy8fEkL4BDYrjZcDAPiXIhACAGADcjsHy4PKaDSqk5sjHF19FA5Ovx9fY7jIv3ZnV++q9V94\n78KeuQc+bhfYpJ/cTnnn92OJZ7b4VmtZsVZHmUzeqNfcU1+9Gb34heptR9k5OKf8+v3vJ9YG\nNRtYLqCBuT0CACSIQAgAQFlUkJuRded3IcSPG0YbLer0+k5X76qNes5xrxB65chnF/bM1agK\nXH0CG/ecW7vzBN0pwdqd3nBy97t8aPHxtcM0GpWbT3DjnnONRigFAIBACABAaeny1kGjOWGD\nl4cNXm7Nuo6uPiPWPObhltXChlQLG2JuaVCzAUHNBlizLwCAZMkf3wQAAAAA8CwiEAIAAACA\nRBEIAQAAAECiCIQAAAAAIFEEQgAAAACQKAIhAAAAAEgUgRAAAAAAJIpACAAAAAASRSAEAAAA\nAIkiEAIAAACARBEIAQAAAECiCIQAAAAAIFEEQgAAAACQKAIhAAAAAEiUna0LePZ9kXDd2Y5+\nlpyE7FxblwAAAAA8BkGlFHl4eAghou+k27oQ2IZSqXR0dLR1FQAAAIBZBMJSNGrUqPDwcFtX\nYTMbNmw4e/bs+++/7+7ubutabMPLy4tACAAAgLKMQFiK7O3tQ0NDbV2Fzbi5uQkhgoKCypUr\nZ+taAAAAAJjAoDIAAAAAIFEEQgAAAACQKAIhAAAAAEgUgRAAAAAAJIpBZQAI5xuaWsu1tq4C\nT5tMY+sKAACArREIAUlzcHAICAhITk52TiEQSlRwcLCtSwAAADZDIAQkTS6Xr1692tZV2ExO\nTk7fvn3DwsJmz55t61oAAABsgHsIAQAAAECiCIQAAAAAIFEEQgAAAACQKAIhAAAAAEgUgRAA\nAAAAJIpACAAAAAASRSAEAAAAAIkiEAIAAACARBEIAQAAAECiCIQAAAAAIFEEQgAAAACQKDtb\nFwAAgFXy7l/Lvnna1lXgaSvIumnrEgDgWUYgBACUdXK5XAiRdj4q7XyUrWuBbSgUCluXAADP\nJgIhAKCsa9euXUZGRmFhoa0LsY34+Pi4uLjWrVv7+/vbuhbbcHZ2btiwoa2rAIBnE4EQAFDW\nubu7//e//7V1FTbz7bffxsXFhYeHh4WF2boWAMCzhkFlAAAAAECiCIQAAAAAIFEEQgAAAACQ\nKAIhAAAAAEgUgRAAAAAAJIpACAAAAAASRSAEAAAAAIkiEAIAAACARBEIAQAAAECiCIQAAAAA\nIFF2ti6gZDg6Ojo7O9u6CvyNTCYTQri6unp4eNi6FsA0uVyu+z9HKcoyOzs7IYRSqeRABQCU\nuGckEBYUFKhUKltXgb/RarVCiEePHmVnZ9u6FsC03NxcIYRWq+UoRVmmVquFEIWFhRyoZY2X\nl5etSwCAf+oZCYQajUb39xJljVqt5q1BmaU7OLVaLUcpyjLd92v8pQMAlAbuIQQAAAAAiSIQ\nAgAAAIBEEQgBAAAAQKIIhAAAAAAgUQRCAAAAAJAoAiEAAAAASBSBEAAAAAAkikAIAAAAABJF\nIAQAAAAAiSIQAgAAAIBEEQgBAAAAQKIIhAAAAAAgUQRCAAAAAJAoAiEAAAAASBSBEAAAAAAk\nikAIAAAAABJFIAQAAAAAiSIQAgAAAIBEEQgBAAAAQKIIhAAAAAAgUQRCAAAAAJAoAiEAAAAA\nSBSBEAAAAAAkikAIAAAAABJFIAQAAAAAiSIQAgAAAIBEEQgBAAAAQKIIhAAAAAAgUQRCAAAA\nAJAoAiEAAAAASBSBEAAAAAAkikAIAAAAABJFIAQAAAAAiSIQAgAAAIBEEQgBAAAAQKIIhAAA\nAAAgUQRCAAAAAJAoAiEAAAAASBSBEAAAAAAkikAIAAAAABJFIAQAAAAAiSIQAgAAAIBEEQgB\nAAAAQKIIhAAAAAAgUQRCAAAAAJAoAiEAAAAASBSBEAAAAAAkikAIAAAAABJFIAQAAAAAiSIQ\nAgAAAIBEEQgBAAAAQKIIhAAAAAAgUQRCAAAAAJAoAiEAAAAASBSBEAAAAAAkikAIAAAAABJF\nIAQAAAAAiSIQAgAAAIBEEQgBAAAAQKIIhAAAAAAgUQRCAAAAAJAoAiEAAAAASBSBEAAAAAAk\nikAIAAAAABJFIAQAAAAAiSIQAgAAAIBEEQgBAAAAQKIIhAAAAAAgUQRCAAAAAJAoAiEAAAAA\nSBSBEAAAAAAkikAIAAAAABJFIAQAAAAAiSIQAgAAAIBEEQgBAAAAQKIIhAAAAAAgUQRCAAAA\nAJAoAiEAAAAASBSBEAAAAAAkikAIAAAAABJlV6pbz87OXrVq1ZkzZ1QqVd26dceNG+fr62t9\nm5SUlMjIyISEhF27dpVqnQAAAAAgQaV7hnDx4sU3btyYN29eZGSkQqGYO3euRqOxss3x48en\nTp1auXLlUq0QAAAAACSrFANhenr66dOn33jjjZCQkMqVK0+YMCElJeXixYtWtiksLFy4cGFY\nWFjpVQgAAAAAUlaKgTA+Pt7BwSEoKEg36erqGhAQEB8fb2Wbjh07li9fvvTKAwAAAACJK8V7\nCLOystzc3GQymX6Oh4dHZmZmcduYdOTIkUmTJuknP/vss+bNm5dE1SgxcrlcCOHp6enj42Pr\nWgDTlEqlEEIul3OUoixzcHAQQjg5OXGgAgBKXOkOKmOY9IQQWq32ydoU5ebmVqtWLf2ko6Oj\nSqV6ohpRulQqFW8Nyiz9wclRirJM95dRo9FwoJY1dnal+zkKAJ6CUvxF5unpmZWVpdVq9ZEv\nMzPTy8uruG1Matq06caNG/WTmZmZGRkZJVc7SoBucKDs7Gzdd9tAGZSTkyOE0Gg0/AJBWVZY\nWCiEyM/P50AtazhnC+AZUIr3EFavXr2wsDAhIUE3mZmZmZycXLNmzeK2AQAAAACUhlIMhF5e\nXs8999yyZcsSEhKSk5MXLVoUEhJSp04dIUR0dPSePXsst3nw4EF6evrDhw+FEOnp6enp6Xl5\neaVXLQAAAABITele+x4REbF69erp06drNJpGjRpNmDBBd2nohQsXsrKyXnzxRQttJk2alJaW\nptvOyJEjhRCjRo3q0aNHqRYMAAAAANJRuoHQ2dn5zTfffPPNN43mGw4Qaq7NmjVrSrU2AAAA\nAJC4UrxkFAAAAABQlhEIAQAAAECiCIQAAAAAIFEEQgAAAACQKAIhAAAAAEhU6Y4yCilr1qyZ\nl5eXUqm0dSEAAAAATCMQorT07NlTqVTev39fo9HYuhYAAAAAJnDJKAAAAABIFIEQAAAAACSK\nQAgAAAAAEkUgBAAAAACJIhACAAAAgEQRCAEAAABAogiEAAAAACBRBEIAAAAAkCgCIQAAAABI\nFIEQAAAAACSKQAgAAAAAEkUgBAAAAACJIhACAAAAgEQRCAEAAABAogiEAAAAACBRBEIAAAAA\nkCgCIQAAAABIFIEQAAAAACSKQAgAAAAAEkUgBAAAAACJIhACAAAAgEQRCAEAAABAogiEAAAA\nACBRBEIAAAAAkCgCIQAAAABIFIEQAAAAACSKQAgAAAAAEkUgBAAAAACJIhACAAAAgEQRCAEA\nAABAogiEAAAAACBRBEIAAAAAkCgCIQAAAABIFIEQAAAAACSKQAgAAAAAEkUgBAAAAACJIhAC\nAAAAgEQRCAEAAABAouxsXQCeQTk5OZs3bz516lR2dnZwcPDQoUNr1apl66IAAAAAGCMQooSp\n1eoZM2ZcvnxZNxkXFxcXF/fpp5/WqVPHtoUBAAAAMMIloyhhhw4d0qdBveXLl9ukGAAAAAAW\nEAhRwn7//feiM5OSkgoLC59+MQAAAAAsIBCihDk4OBSdqVAoFArF0y8GAAAAgAUEQpSw5s2b\nF53ZtGlTuZyDDQAAAChb+IyOEtaoUaOePXsazvHx8Rk/fryt6gEAAABgDqOMouSNGzeuefPm\nZ86cyc3NrVKlSrdu3ZycnGxdFAAAAABjBEKUiiZNmrRv316pVN6/f1+j0di6HAAAAAAmEAhR\nKs6dO3fmzJlHjx4FBARwhhAAAAAomwiEKHmff/75rl279JO7du1asmSJt7e3DUsCTHJ0dFyw\nYIG7u7utCwEAALANBpVBCYuLizNMg0KI9PT0ZcuW2aoewAI7O7vw8PCGDRvauhAAAADbIBCi\nhJ0+fbrozLNnz3InIQAAAFDWEAhRwgoKCorOVKvVarX66RcDAAAAwAICIUpY9erVi84MCgqy\nt7d/+sUAAAAAsIBAiBIWHh5eq1Yto5mvv/66TYoBAAAAYAGBECVMoVDMmzevT58+/v7+7u7u\njRo1ioyMrFOnjq3rAgAAAGCMx06g5Lm6ujZr1kwul+fm5lapUiUoKMjWFQEAAAAwgUCIkrd6\n9epvvvlGP7lz587IyMhy5crZsCQAAAAARXHJKErYhQsXDNOgEOLOnTvLly+3VT0AAAAAzCEQ\nooSdOnWq6MzTp0/zHEIAAACgrCEQooTl5+cXnclzCAEAAIAyiECIEhYaGlp0ZtWqVXkOIQAA\nAFDWEAhRwjp37lyjRg2jmTyHEAAAACiDFLNnz7Z1DSUgPz+fW9TKCLlc3rp16/z8/IyMDK1W\nW6tWrYkTJ9arV8/WdQEmyGQyZ2dntVpt8lJnoIxwdHQMCgqqW7eui4uLrWvB3zg7O9u6BAD4\np2RardbWNZSAzMzMwsJCW1eBv3Fzc1Mqlffv3yero8ySyWTe3t4FBQVZWVm2rgUwy8nJycXF\n5eHDh3xzUdb4+PjYugQA+Ke4ZBQAAAAAJIpACAAAAAASRSAEAAAAAIkiEAIAAACARBEIAQAA\nAECiCIQAAAAAIFEEQgAAAACQKAIhAAAAAEgUgRAAAAAAJMrO1gWUDDs7O7mccFu2KBQKIYSD\ng4NWq7V1LYBpMplMCCGXy5VKpa1rAcyys7PT/x8AgJL1jPx1kcvlBMKyRvdR287OjkCIMkt3\nlMpkMj5qoyzT/YHTfcsGAEDJekY+AxUUFBQWFtq6CvyNXC5XKBS5ubkajcbWtQCmyWQyR0dH\ntVqdk5Nj61oAs5ycnOzt7fPz8/Pz821dC/7GycnJ1iUAwD/FWTUAAAAAkCgCIQAAAABIFIEQ\nAAAAACSKQAgAAAAAEkUgBAAAAACJIhACAAAAgEQRCAEAAABAogiEAAAAACBRBEIAAAAAkCgC\nIQAAAABIFIEQAAAAACSKQAgAAAAAEkUgBAAAAACJIhACAAAAgEQRCAEAAABAogiEAAAAACBR\nMq1Wa+sa8GzasWPHlStXIiIi3N3dbV0LYFpeXt6iRYuCg4NfeuklW9cCmHXq1KmYmJg+ffrU\nrFnT1rUAAJ41nCFEaTl16tSOHTvy8vJsXQhgVmFh4Y4dO3766SdbFwJY8vvvv+/YsSMlJcXW\nhQAAnkEEQgAAAACQKAIhAAAAAEgUgRAAAAAAJIpBZQAAAABAojhDCAAAAAASRSAEAAAAAIki\nEAIApK6wsPCtt97au3evECIhIeHVV1/t169fZmamrevCP1Xa72ZaWlqPHj2uX7/+zzcVFRU1\nb948buQB8PTZ2boAlAkpKSmRkZEJCQm7du2ypn1mZuaIESM8PT3XrFkjl//va4W33347ISFB\nP+nm5hYcHDxkyJAaNWro5ixatCgrK2v27Nn6xosXLw4ODtavolarR4wYkZGRsXPnToVCYXl3\nKLPu378fFRV14cKFwsLCoKCgESNGVK9e3fIqZe2gMtqvjp+f36pVq6zvh3/osd2YnJwcFRV1\n5coVjUYTFBQ0bNiwxz64nH42af369Z6ent27dxdC7N2718vLa9GiRS4uLubaX7p0ydnZOSQk\n5CnWiCdh7t208MNV3D+IJWXo0KFvv/327t27e/bs+TT3CwAEQojjx4+vWbOmUaNGRT+WmfP9\n99/Xrl37+vXrZ86cadGiheGiTp06DR48WPfvjIyMXbt2zZgxY9myZRUqVCi6HQ8Pj+jo6DFj\nxujnnDt3ruj3oxZ2h7Jp/vz5SqVyzpw5Tk5OmzZtmjdv3urVqx0dHS2sUgYPqvbt2w8aNMhw\njp2d8e9MtVqtDz9FJ82xspnlbiwsLJw+fXrDhg0/+eQTuVy+devW2bNnR0VFOTk5Wdgm/VxU\nWlragQMHFi5cqJt8+PBh1apVXV1dLayya9euZs2aWRkIrSzjH65SgquXwR09MXPvprkfrif4\ng1hSFArFoEGDli1b1qVLF8s/xQBQsjjZAlFYWLhw4cKwsDAr22u12u+++659+/Zt27Y9ePCg\n0VJHR0efv4SEhLz11ltCiLNnz5rcVNOmTY8ePVpQUKCfEx0d3aBBA+t3hzLo4cOHFSpUiIiI\nCA4Orlix4vDhwzMzM2/cuGFhlbJ5ULm4uFT8u/Llywsh1Gp1jx49Dh06NGrUqCVLlhhNCiEy\nMjI++eSTYcOGDR48ePr06UlJSUXXEkLExMS89tpr/fr1Gzp06MqVKw1rtqYbc3Nze/XqNXbs\n2EqVKlWsWLF///65ubmpqan0c7H6WQhx4MCB0NBQ3dnO995779y5c9HR0QMGDEhNTe3Ro8fP\nP/+sa3b79u0ePXrcvn172rRp586dW7NmzVtvvZWXl2eyjclqP/7445deemnw4MEzZ84s+hNh\n/SqJiYkTJ04cMGDAW2+9denSpR49eiQmJlq/uskOMTnTyh42fMd79Ohx9OjR9957b9iwYePH\nj79+/fratWvHjRv33//+95tvvtE1M1dYcnLyzJkzBw0a9NJLL82aNev27dv6bZ44cWLmzJmv\nvvrqK6+8cvjw4aJHkclSDd9Nw0tGLfxwWfMHUdf//fv3Hz9+/NWrV/XzTdb/7rvvrly5Ut/m\n6tWrPXv2TEtLM9nhLVq0UCqVR48etbB3AChxBEKIjh076j5+Wens2bNZWVmtW7fu1KnT+fPn\n09LSLDSWy+VyuVytVptcGhIS4ubmdvLkSd1kZmbm+fPnW7Vq9cS7Q1ng5uY2efLkSpUq6Sbv\n3bsnk8nKlStnYZV/10GlUChkMtmBAwemTp06duxYo0khxPz58x89erRkyZK1a9cGBwe/9957\nDx8+NGqWmpq6dOnSMWPGfP31159++ml8fPzu3bsN9/LYbvTw8Ojdu7fuTMLDhw93795duXLl\nypUrW6icfi7az0KIuLi4hg0b6v794YcfNm7cuHPnzl9//bWnp6fJwt5///3y5cuPGjUqMjLS\nyuKFEJ9++qkQYvXq1VFRUdWrV58xY0Z+fv4TrFJYWDh79uyAgIAvv/xy4sSJGzZs0K1r5eom\nO8RcL1nTw4YvQSaTyeXy/fv3z5gxY926dc7OzlOnTg0NDV25cuX48eM3btyoS2XmumLBggVe\nXl7r1q1bt26do6Ojrnt129y+ffubb765atWqPn36rFy5Mi8vz6jDTZZq+G56eHjoG1v44Xrs\nH0StVvvBBx9Urlx548aNM2bM2L9/v36Ryfq7dOly7Ngx/dcQx48fr1u3rkajMdnhMpmsfv36\nFy5csFAAAJQ4AiGKbf/+/a1bt3Z0dAwODg4KCvruu+/MtczLy1u/fn1+fn6zZs3MtencuXN0\ndLTu30eOHKlXr563t/eT7Q5l0MOHD5ctW/biiy/6+PhYaFY2D6qDBw8O+Dv9hz+ZTNa8efPg\n4GBnZ2ejycTExN9//3348OGenp6Ojo6DBw8uLCw8deqUUbPMzEytVuvq6iqXy8uXL79w4cJ+\n/fqZe0UWulGj0fTp02fw4ME3btyYP3++vb29uY1Y/8KFxPr5xo0bgYGBFvrtyRiWcePGjYsX\nL7766qtubm4ODg6DBw8uKCg4c+bME6xy5cqVjIyMQYMGOTo6VqpUSXffo/Wrm+wQkzOt7OGi\nL7xDhw7Ozs4KhaJ27doODg5t27YVQtSvX1+j0dy5c8dCVyxYsGDcuHFOTk7Ozs7t2rWLj4/X\nX4TcsWNH3dHVrFmz/Px8oy8XLJT6WFb+jtK7evVqWlraSy+95Ojo6Ovra3i/n8n6W7durdFo\nYmNjhRBarfbHH38MDw+3cFgGBgZavp4CAEoc9xCieO7cuXP+/PkFCxboJjt37rx169aXX35Z\nfxvJwYMHY2JidP/Oy8urUqXKtGnTKlasaG6DnTp1+r//+7/U1FQ/P79Dhw4Z3Ur02N2hLLt5\n8+a8efMaNmz4yiuvWGhWZg+qNm3aGK1reJLB39/fcJF+8vbt2zKZTH/yQalUent766/k1Der\nXr16t27dJk6cGBoa2rBhw7Zt25o7uWe5G+Vy+ZIlSzIyMnbv3j1t2rSFCxeaGwqFfjbZz7m5\nuSqVyt3d3dzL/Cf0Zdy6dUsIMXToUMOlJq/vfewqBQUFuhShm2M0ztBjV3/uueeKdojJXrKy\nh4vSfy/g4OCg/7fuq4r8/Pz79++b64rExMTt27enpqZqtdr8/Hy1Wq3RaHQHjP716rZjdN2v\n5VItsPJ3lKG7d+/KZDJfX1/dpH6n5up3dHRs27btoUOH2rZte/ny5dzc3FatWjk4OJg7LN3d\n3bOysqwsBgBKBIEQxXPw4EGtVjtnzhzdpEajycvLi42Nfe6553Rz9J/tcnNzZ8yY8cILLzRt\n2tTCBsuVK9e4ceNDhw61aNHiwYMHLVq0uHbtmvW7Q5l18eLFjz/++OWXX+7WrZvllmX2oNLd\n22ZuL0bn4iycmtNqtTKZzKiZTCYbM2ZM3759z5w5c+bMmW3btr3zzjutW7c2WteabgwICAgI\nCKhdu/bQoUOPHj1qriX9bKGfraHRaIrbxrAMIcT27dsdHBwsb+Gxqxw+fFj/MvXNirVHkx1S\ndKbRloWZHi6q6IpFlxYtLC0tbe7cuYMGDZo1a5adnd3p06fnz59v5TaLMizVHOt/RxkqLCw0\nnNRfU22h/i5dukycOPH+/fsnTpxo06aNUqkUZt6FYrxCACg5BEIUg0ql0p0H6NSpk35mVFTU\nwYMH9R/yDD/bvfrqq8uXL69Xr15AQICFzXbu3HnDhg2PHj1q37694eiC1uwOZdPly5c//vjj\nd955p3HjxpZbPnsHlb+/v1arvXnzZtWqVYUQeXl59+/fLxp41Gp1dna2j49P165du3btunr1\nat0FloZtLHfjxYsXV6xYsXTpUt24o3K5XCaTmXuIGf1srp+dnZ3t7OxMnpOxt7eXyWQqlUo3\nafIeSGvaiL/OpyUmJuqfC6I7s2r5BZpcpVy5cmq1+t69e7pLHH///fdirW6yQ1q2bFl05ujR\no63p4eIyV1h8fLxGo+nbt68uyMXHxxdrm8Ut1frfUUZ8fHy0Wu3du3d1o+/qL++0UH9oaGhg\nYOCxY8dOnDgxdepUYfGwzMrKKqXz1QBgDvcQQjx48CA9PWrDp/EAAAo+SURBVP3hw4dCiPT0\n9PT0dN39+tHR0Xv27DFs+eOPP+bk5HTr1s3XQPfu3S9duqS7PMlI+/btmzRp8sknnxh9pWqk\nWbNmOTk5R48eDQ8P/ye7QxlRUFCwePHiHj16VKlSJf0v/8aDKicn53YR5gZZ0QsKCqpZs+aG\nDRsyMzNzc3PXr1/v5ORUdNDCw4cPv/XWWwkJCVqtNiMj48aNG0bxwEI36oSEhOTn5y9ZsiQ5\nOTk1NXXNmjV5eXm6T7f0s95j+1kIUaVKFd2glEYUCkXFihXPnz8vhMjLy9u3b59+kVKpvH37\ntm6EFXNtDAUEBNSvX3/dunXp6elqtfrAgQPjx49/8OCBhRdobpWaNWs6Oztv27YtPz8/JSXl\nwIEDxVrdZIeYnGllDxeXucJ8fHzUavXly5e1Wu2xY8cuXbokhNBdX/pYxS3Vwg+XuT+IejVr\n1nRzc/vqq6+ys7OTk5P37t2rm2+5ft0l0y4uLrVq1RIWD8ukpKQqVaoUs1MB4B/hDCHEpEmT\n9N9qjxw5UggxatSoHj16XLhwISsr68UXX9S3PHDgQMuWLY2+vKxTp06lSpUOHjyoW9fIa6+9\nFhERsX79+tGjR5srQKFQdOzY8eLFi0FBQYbzn2B3KAt+++231NTUzZs3b968WT9zzJgx3bp1\n+3cdVEePHi06/vtnn31meSRPIcS77777xRdfjB492t7evkaNGgsWLCg69kZ4ePi9e/cWLFjw\n4MEDFxeXJk2aGN3FZKEbdf92cXGZO3fuhg0bpkyZolarq1atOnPmTN3pF/pZ77H9LIRo1KjR\nhQsXjO5j1Bk3btznn39+8uRJT0/PIUOGnD59WpdUn3/++S+//DI2NnbVqlXm2hh55513Vq9e\nHRERodFoAgMDZ8+e7eXlZfkFmltl2rRpq1atGjJkSHBw8KBBg2bOnCmXm/h61+TqJjvE2dnZ\nZC9Z08NPwGRhXl5effr0ef/992UyWcuWLWfMmDF9+vS3335bNyTpYxWrVAs/XOb+IOqbOTg4\nzJo1a+XKlcOHD9c9smLOnDlqtbpGjRrm6vf19W3fvv26dev035uYOyy1Wu2lS5cGDhxY/E4F\ngCdn9voiAACkIC0tbezYsQsXLtQ9irDsU6vVWq1Wd43u1atXJ02atGXLlhKJaiglSUlJ77zz\nztq1a809y0QnNjZ22bJla9as4cH0AJ4mLhkFAEiar69v165dN27caOtCrKLVaiMiIlasWJGT\nk/PgwYOvvvqqXr16pMEyq7Cw8Pbt20uWLHn++ectp0G1Wr1ly5aBAweSBgE8ZQRCAIDUDR8+\nPCMjw+jGy7JJJpNNmTIlLS1txIgR48ePd3Jyevvtt21dFMzasWNHRESEv7//sGHDLLfcuHFj\nuXLlDK/0BoCng0tGAQAAAECiOEMIAAAAABJFIAQAAAAAiSIQAgAAAIBEEQgBAAAAQKIIhAD+\nTWbPni2TyXx9fQsLC4suHT16tEwma9269ZNt/KWXXnJ1dbWmZevWrWvWrPlkewEAACg7CIQA\n/mXkcvn9+/cPHDhgND8vL2/btm0ODg42qQoAAODfiEAI4F9GLpeHhYWtX7/eaP7u3btzcnIa\nN25si6IAAAD+lQiEAP5lVCpVr1699u3bd+/ePcP5X375ZYcOHYzOEB44cKBt27Zubm5OTk51\n69ZdtGiR/uGrWq127ty5AQEBjo6O9erV2759u0wmM1z3xx9/7Ny5s7u7u5OTU6NGjdatW2ey\nntu3b48ePbpq1aqOjo5+fn59+/a9cuVKib5iAACA0vL/7d1fSNNdHMfxsxyJAwtNC22FhiAF\n1oV/sHDIooE1xBQkkdiUQgwvJURMlwPJ0ouCKLoZsoStSJhpmymJDS+8cBVKOTKoUDcV0YrS\ncFOfix/92JPPA8+ffB7H3q+r377nnO2c3X12zm8/AiGA8FNcXBwMBm02m1yZn59/+vRpWVnZ\n6uqqXHQ4HHq9XgjR0dHR3d194sSJ2tray5cvS61tbW0mk0mj0fT09DQ0NJhMppcvX8pjh4aG\ntFptIBDo7Ox8/Phxbm7uhQsX2tvbN0+mpKSkt7e3qanJ6XS2t7e/ffs2Pz9/eXl5qxYPAADw\n6yjkH8sBYPu7evVqc3PzyspKYWHh0tLS6OioVL9161Z9ff3c3JxOp1MqlcPDw0KIw4cPf/v2\nbXJyMjo6WuomhTe/3x8fH69Wq+Pi4sbHx6WNQZ/Pl5KSsnPnzq9fvwohsrKyFhcXJyYm5LFF\nRUXPnz/3+/0xMTF5eXkLCwter/fLly+7d++uq6trbW2Vur1//95utxuNxuTk5P/4ywEAAPi7\n2CEEEJYqKio8Hs/r16+ll1ar9ezZs7GxsXIHn8/n9XpPnz4tJzohhF6vDwQCIyMjU1NTPp/v\n5MmT8jHR5OTkrKws6XphYcHj8RQUFGxsbHz/4cyZM58/f/Z4PKHTUKlUCQkJdrv92bNn6+vr\nQojU1NT6+nrSIAAACAsEQgBhqbi4ODY2VvprmTdv3rx48cJgMIR2mJmZEUKo1erQopTT/H7/\n7OysEGLv3r2bW4UQU1NTQoi7d+/GhKiurpbfVqZUKp1Op0KhOHXqVGJi4rlz52w229ra2i9e\nLQAAwNZQ/t8TAIB/QqVSlZaWdnZ2tra2Wq3WpKQknU4X2kHa+gu9pVAIIR2SVyj++LS8HOSk\nsZWVlVVVVT/1SUtL+6mSnZ397t07t9vd19fncrkePnx4+/btwcHB0J1JAACA7YlACCBcGY1G\ni8UyPDxst9vLy8ujoqJCWw8cOCB+7PXJpqenhRBqtToxMVEIMTc3F9r64cMH6eLgwYNCiPX1\n9dzc3L8yk6ioKK1Wq9Vqr1+/fu/everq6gcPHvy0YwkAALANcWQUQLjSaDSHDh1qa2v7+PHj\n5vS1b9++jIyM3t7elZUVuehwOFQq1fHjx1NSUhISEuQb/4QQXq93bGxMuo6Pj8/JyXE4HJ8+\nfZLHWq3WK1euBIPB0E8ZHR0tKyubn5+XK9JGZWgFAABg2yIQAghXCoXCYDA8efLk2LFjR48e\n3dzh2rVrS0tLOp2uq6urp6envLzc5XI1Njbu2rVrx44dly5dmpiYKCkpefTo0Z07dwoKCjIz\nM+WxN27cWF5e1mg09+/f7+/vb2xsvHjxos/nUyp/d7Bi//79fX19Op3OYrEMDAzYbLbz589H\nR0cXFhZu+foBAAD+NY6MAghjBoOhubn5zw5n6vV6p9PZ0tJiNBqDweCRI0csFktlZaXUajKZ\nAoFAR0eHy+VKT0+/efPm0NDQq1evpNb8/PzBwUGz2VxTUxMIBFJTU81ms/wMQ1lSUpLb7Tab\nzQ0NDYuLi3v27MnJyXG73enp6Vu3agAAgF+F5xACAAAAQITiyCgAAAAARCgCIQAAAABEKAIh\nAAAAAEQoAiEAAAAARCgCIQAAAABEKAIhAAAAAEQoAiEAAAAARCgCIQAAAABEKAIhAAAAAEQo\nAiEAAAAARCgCIQAAAABEqN8A7/I9MqUZXSEAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- new.get_result(result.m03.1, '1. ARIMA')\n",
    "errors.2 <- new.get_result(result.m03.2, '2. ARIMA Errors 2')\n",
    "n <- paste('3. ARIMA Errors (future regressor mean of', hori ,'days)', sep=' ')\n",
    "errors.3 <- new.get_result(result.m03.3, n)\n",
    "\n",
    "x <- rbind(errors.1, errors.2)\n",
    "x <- rbind(x, errors.3)\n",
    "\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b58831-3950-4988-b3bf-3f5313d409f9",
   "metadata": {},
   "source": [
    "### save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab39eccc-4453-4c0e-b430-b46b51c21e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- result.m03.1\n",
    "write.csv(x, file = \"arima_result_m0301.csv\")\n",
    "x <- result.m03.2\n",
    "write.csv(x, file = \"arima_result_m0302.csv\")\n",
    "x <- result.m03.3\n",
    "write.csv(x, file = \"arima_result_m0303.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c35829-53d8-47e0-b381-71b6dfd0d856",
   "metadata": {},
   "source": [
    "### load result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c522e476-b850-4a80-8d6f-4d52ec6b5ae5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.m03.1 <- read.csv(file = 'arima_result_m0301.csv')\n",
    "result.m03.2 <- read.csv(file = 'arima_result_m0302.csv')\n",
    "result.m03.3 <- read.csv(file = 'arima_result_m0303.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9f0a8df7-b56a-46aa-9af5-d6702ae1057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m03 <- result.m03.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88acae2-994b-4716-b170-6ce34970d63e",
   "metadata": {},
   "source": [
    "# ARIMA+GARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748e4290-f9bd-441f-a136-17269a33122d",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f191fab1-f27c-4776-857e-0122f16923dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast <- function(x, h, \n",
    "                        mxreg=NULL, mxreg.msize=NULL, \n",
    "                        vxreg=NULL, vxreg.msize=NULL,\n",
    "                        order=NULL) {\n",
    "    forc <- ag2.forecast(x, h, \n",
    "                         mxreg=mxreg, mxreg.msize=mxreg.msize, \n",
    "                         vxreg=vxreg, vxreg.msize=vxreg.msize, \n",
    "                         out.sample=0, order=order)\n",
    "    if (!is.na(forc)) {\n",
    "        fc <- list(method = \"ARIMA+GARCH Forecasting\", mean=forc@forecast$seriesFor[,1],\n",
    "                   arima.order=forc@users$arima.order)\n",
    "        attr(fc$mean, \"names\") <- NULL\n",
    "        return(fc)\n",
    "    }\n",
    "}\n",
    "\n",
    "agarch.forecast <- cv.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad24908e-79eb-4b66-afa7-325b1c04fd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast.2 <- function(x, h, ...) {\n",
    "    new.forecast(x, h, cv.forecast, ...)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8dd1a8-1213-4b11-be11-ed86fa7e0ac2",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3fc5c70c-df6f-49dd-b5a3-d09dcd858c0e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 % done.\n",
      "\n",
      "30 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in seq.int(r1$year, by = by, length.out = length.out) : \n",
      "  'from' must be a finite number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50 % done.\n",
      "\n",
      "60 % done.\n",
      "\n",
      "70 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n"
     ]
    }
   ],
   "source": [
    "result.m04.1 <- my.tsCV(train, cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                        silent=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4916d16-6a26-4c9c-bb1b-30988b39aa2a",
   "metadata": {},
   "source": [
    "## Regressors for mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce4d19cd-012a-426c-bd7f-9d312c363316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n",
      "20 % done.\n",
      "\n",
      "30 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in seq.int(r1$year, by = by, length.out = length.out) : \n",
      "  'from' must be a finite number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50 % done.\n",
      "\n",
      "60 % done.\n",
      "\n",
      "70 % done.\n",
      "\n",
      "80 % done.\n",
      "\n",
      "90 % done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m04.2 <- my.tsCV(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                        mxreg=trainx[,2:4], silent=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b54ebef-c351-4357-8f97-9c524bd47711",
   "metadata": {},
   "source": [
    "## Regressors for variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "665586fb-e4bf-4356-86fb-2be0133969fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 % done.\n",
      "\n",
      "30 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in seq.int(r1$year, by = by, length.out = length.out) : \n",
      "  'from' must be a finite number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40 % done.\n",
      "\n",
      "50 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60 % done.\n",
      "\n",
      "70 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90 % done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m04.3 <- my.tsCV(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                        vxreg=trainx[,2:4], silent=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26215cf2-deb9-45fa-be1f-ea72448a97b7",
   "metadata": {},
   "source": [
    "## Regressors for both of mean & variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "048f72f1-594f-416e-8dc4-a12ecb877efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n",
      "20 % done.\n",
      "\n",
      "30 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"GARCH model does not converge\"\n",
      "Error in seq.int(r1$year, by = by, length.out = length.out) : \n",
      "  'from' must be a finite number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40 % done.\n",
      "\n",
      "50 % done.\n",
      "\n",
      "60 % done.\n",
      "\n",
      "70 % done.\n",
      "\n",
      "80 % done.\n",
      "\n",
      "90 % done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m04.4 <- my.tsCV(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                        mxreg=trainx[,2:4], vxreg=trainx[,2:4], \n",
    "                        silent=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b4805d3a-1bc0-47e4-95f8-d358940ab858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-02-09\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m04.4\n",
    "from <- x[!is.na(x[,'forecast_start']),][,1][1]\n",
    "from <- index(trainx[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8c970c-798b-4d41-9930-01e336c80952",
   "metadata": {},
   "source": [
    "## Compare Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "624fa65b-7533-4f86-86de-0c335271b0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94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\nNBQKQgAAAAAAAA31N3JokEpCIEkuAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- new.get_result(result.m04.1, '1.AG')\n",
    "errors.2 <- new.get_result(result.m04.2, '2.AG with mxreg')\n",
    "errors.3 <- new.get_result(result.m04.3, '3.AG with vxreg')\n",
    "errors.4 <- new.get_result(result.m04.4, '4.AG with m&v xreg')\n",
    "\n",
    "x <- rbind(errors.1, errors.2)\n",
    "x <- rbind(x, errors.3)\n",
    "x <- rbind(x, errors.4)\n",
    "\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec0491-dff8-4c4b-8965-bcbfbecf1375",
   "metadata": {},
   "source": [
    "### save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4121890e-a78d-4c57-a282-e65c742ce8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- result.m04.1\n",
    "write.csv(x, file = \"agarch_result_m0401.csv\")\n",
    "x <- result.m04.2\n",
    "write.csv(x, file = \"agarch_result_m0402.csv\")\n",
    "x <- result.m04.3\n",
    "write.csv(x, file = \"agarch_result_m0403.csv\")\n",
    "x <- result.m04.4\n",
    "write.csv(x, file = \"agarch_result_m0404.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ddbbe0-2e37-4bbc-b30e-eb93048e1f1a",
   "metadata": {},
   "source": [
    "### load result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "199edcd6-5769-43b7-84e5-7169ce2ca863",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.m04.1 <- read.csv(file = 'agarch_result_m0401.csv')\n",
    "result.m04.2 <- read.csv(file = 'agarch_result_m0402.csv')\n",
    "result.m04.3 <- read.csv(file = 'agarch_result_m0403.csv')\n",
    "result.m04.4 <- read.csv(file = 'agarch_result_m0404.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5ab8b4ec-19dc-42d8-bdcf-2c6d98936fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m04 <- result.m04.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b679ca19-bc28-4b63-a30c-4307392c4bca",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f404eb3-7cf4-4a6f-9bce-53f24d25335e",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "26450ef3-ca0d-435c-b61b-67fabb48a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.eval <- function(\n",
    "    train.label, train.features, test.label, test.features,\n",
    "    nrounds = 1000, early_stopping_rounds = 3,\n",
    "    max_depth = 6, \n",
    "    eta = 0.3, # learning rate\n",
    "    # In linear regression task, this simply corresponds to minimum number of instances needed to be in each node. \n",
    "    # The larger min_child_weight is, the more conservative the algorithm will be. range: [0,?]\n",
    "    #min_child_weight = 1 ,\n",
    "    # Minimum loss reduction required to make a further partition on a leaf node of the tree. \n",
    "    # The larger gamma is, the more conservative the algorithm will be. range: [0,?]\n",
    "    #gamma = 0,\n",
    "    verbose=0,\n",
    "    sample.n=0,\n",
    "    result.error=FALSE\n",
    ") \n",
    "{\n",
    "    if (is.null(dim(test.features))) {\n",
    "        # conver to matrix for the case of 1 day prediction\n",
    "        test.features <- t(test.features)\n",
    "    }\n",
    "    model <- xgboost(data = train.features,\n",
    "                     label = train.label,\n",
    "                     nrounds = nrounds,\n",
    "                     objective = \"reg:squarederror\",\n",
    "                     early_stopping_rounds = early_stopping_rounds,\n",
    "                     max_depth = max_depth,\n",
    "                     eta = eta,\n",
    "                     verbose=verbose)\n",
    "\n",
    "    pred <- predict(model, test.features)\n",
    "    \n",
    "    if (result.error) {\n",
    "        h = length(pred)\n",
    "        idx = 1:h\n",
    "        if ((sample.n>0) & (sample.n<h)) {\n",
    "            idx <- sort(sample(idx, sample.n))\n",
    "        }\n",
    "\n",
    "        # calc errors\n",
    "        rmse <- sqrt((pred[idx] - test.label[idx])^2)\n",
    "        mape <- abs(1 - pred[idx] / test.label[idx])\n",
    "        result <- list(rmse.mean=mean(rmse), rmse.sigma=sd(rmse), \n",
    "                       mape.mean=mean(mape), mape.sigma=sd(mape))\n",
    "        return(result)\n",
    "    } else {\n",
    "        return(pred)\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "xgb.gridsearch <- function(label, features, test.h, hyper_grid, verbose=1) {\n",
    "    len <- length(label)\n",
    "    idx.train <- 1:(len-test.h)\n",
    "    idx.test <- (len-test.h+1):(len)\n",
    "    train.label <- label[idx.train]\n",
    "    train.features <- features[idx.train,]\n",
    "    test.label <- label[idx.test]\n",
    "    test.features <- features[idx.test,]\n",
    "    \n",
    "    xgb_test_rmse <- NULL\n",
    "    xgb_test_mape <- NULL\n",
    "\n",
    "    for (j in 1:nrow(hyper_grid)) {\n",
    "        #set.seed(123)\n",
    "        \n",
    "        errors <- xgb.eval(train.label, train.features, test.label, test.features,\n",
    "                            nrounds = 1000, early_stopping_rounds = 3,\n",
    "                            max_depth = hyper_grid$max_depth[j], \n",
    "                            eta = hyper_grid$eta[j],\n",
    "                            verbose=0, result.error=TRUE)\n",
    "        # calc errors\n",
    "        xgb_test_rmse[j] <- errors$rmse.mean\n",
    "        xgb_test_mape[j] <- errors$mape.mean\n",
    "    }\n",
    "\n",
    "    #ideal hyperparamters\n",
    "    r <- hyper_grid[which.min(xgb_test_rmse), ]\n",
    "    if (verbose>0) {\n",
    "        print(r)\n",
    "    }\n",
    "    return(r)\n",
    "}\n",
    "\n",
    "\n",
    "xgb.tsCV <- function (label, features, max_depth = 6, eta = .25,\n",
    "                      h = 1, window = NULL, initial = 0, step = 1, \n",
    "                      count.freq=0.1, ...) \n",
    "{\n",
    "    y <- as.ts(label)\n",
    "    n <- length(y)\n",
    "    step <- round(step)\n",
    "    step_ind <- seq(step, n - 1L, by = step)\n",
    "\n",
    "    if (initial >= n) \n",
    "        stop(\"initial period too long\")\n",
    "\n",
    "    xreg <- ts(as.matrix(features))\n",
    "    if (NROW(xreg) != length(y)) \n",
    "        stop(\"features must be of the same size as label\")\n",
    "    tsp(xreg) <- tsp(y)\n",
    " \n",
    "    if (is.null(window)) {\n",
    "        indx <- seq(1 + initial, n - 1L)\n",
    "    } else {\n",
    "        indx <- seq(window + initial, n - 1L, by = 1L)\n",
    "    }\n",
    "    indx <- intersect(indx, step_ind)\n",
    "\n",
    "    e.cols <- c('forecast_start', 'forecast_end', \n",
    "                'rmse.mean', 'rmse.sigma', 'mape.mean', 'mape.sigma')\n",
    "    e <- ts(matrix(NA_real_, nrow = floor(n/step), ncol = length(e.cols)))\n",
    "    colnames(e) <- e.cols\n",
    "    \n",
    "    ###\n",
    "    hyper_grid <- expand.grid(max_depth = max_depth, eta = eta)\n",
    "    if (nrow(hyper_grid)>1) {\n",
    "        hyper_grid.flag <- TRUE\n",
    "    } else {\n",
    "        hyper_grid.flag <- FALSE\n",
    "    }\n",
    "    \n",
    "\n",
    "    indx.len <- length(indx)\n",
    "    by <- round(count.freq*indx.len)\n",
    "    by <- max(1, by)\n",
    "    print.when <- seq(0, indx.len, by=by)\n",
    "    \n",
    "    cnt <- 0\n",
    "    \n",
    "    for (i in indx) {\n",
    "        # get new start of subset of y & xreg\n",
    "        if (is.null(window)) {\n",
    "            start <- 1L\n",
    "        } else {\n",
    "            if (i - window >= 0L) {\n",
    "                start <- i - window + 1L\n",
    "            } else {\n",
    "                stop(\"small window\")\n",
    "            }\n",
    "        }\n",
    "        train.label <- subset(y, start=start, end = i)\n",
    "        train.features <- as.matrix(subset(xreg, start=start, end=i))\n",
    "        \n",
    "        # get test data\n",
    "        start <- i+1\n",
    "        end <- i+h\n",
    "        if (end <= nrow(xreg)) {\n",
    "            test.label <- subset(y, start=start, end=end)\n",
    "            test.features <- as.matrix(subset(xreg, start=start, end=end))\n",
    "        } else {\n",
    "            next\n",
    "        }\n",
    "        \n",
    "        # tune hyperparams\n",
    "        if (hyper_grid.flag) {\n",
    "            res <- xgb.gridsearch(train.label, train.features, h, hyper_grid)\n",
    "            max_depth.best <- res$max_depth\n",
    "            eta.best <- res$eta\n",
    "        } else {\n",
    "            max_depth.best <- max_depth\n",
    "            eta.best <- eta\n",
    "        }\n",
    "        \n",
    "        # train model\n",
    "        errors <- xgb.eval(train.label, train.features, test.label, test.features,\n",
    "                    nrounds = 1000, early_stopping_rounds = 3,\n",
    "                    max_depth = max_depth.best,\n",
    "                    eta = eta.best, result.error=TRUE, ...)\n",
    "        # calc errors\n",
    "        e[i/step, ] <- c(start, end, errors$rmse.mean, errors$rmse.sigma, \n",
    "                                     errors$mape.mean, errors$mape.sigma)\n",
    "\n",
    "        cnt <- cnt + 1\n",
    "        if (cnt %in% print.when) {\n",
    "            message(sprintf(\"%0.0f %% done.\", 100*cnt/length(indx)))\n",
    "        }\n",
    "    }\n",
    "    #return(na.omit(e)) # times of NA kept in e as attr(na.action)\n",
    "    return(e)\n",
    "}\n",
    "\n",
    "\n",
    "xgb.tsCV.mean <- function(label, features, cols=c(1,2,3,5), ...) {\n",
    "    e <- xgb.tsCV(label, features, ...)\n",
    "    result <- e[,cols]\n",
    "    colnames(result) <- c('forecast_start', 'forecast_end', 'rmse', 'mape')\n",
    "    return(result)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9ef27a-3429-4873-81bd-39c5a8842043",
   "metadata": {},
   "source": [
    "### set label & features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "41c44a85-e47f-47bb-b011-36242e342e1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             logret_fwd     logret      rsi    bbands        macd\n",
       "1991-02-19 -0.003987479 0.10602550 72.59254 0.8419486 -0.03641515\n",
       "1991-02-20  0.003935860 0.09798126 66.25313 0.7706927 -0.18551057\n",
       "1991-02-21  0.006853764 0.10585688 66.00481 0.7330987 -0.30953562\n",
       "1991-02-22  0.011366830 0.10194779 66.54491 0.7402938 -0.39546732\n",
       "1991-02-25  0.024316594 0.09259647 67.84742 0.7305630 -0.43573971\n",
       "1991-02-26  0.033979664 0.07655978 60.80133 0.6379610 -0.55105032"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "            logret_fwd       logret      rsi    bbands       macd\n",
       "1991-03-20 0.043297723 -0.003987479 52.32729 0.2955472 -0.5878001\n",
       "1991-03-21 0.038451421  0.003935860 50.29479 0.3135024 -0.6182388\n",
       "1991-03-22 0.038123240  0.006853764 51.65309 0.2490278 -0.6049896\n",
       "1991-03-25 0.034364782  0.011366830 55.10298 0.4057512 -0.5386086\n",
       "1991-03-26 0.007808953  0.024316594 62.94322 0.6945332 -0.3702197\n",
       "1991-03-27 0.009730005  0.033979664 61.25189 0.8281562 -0.2741769"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.ml <- merge(lag.xts(trainx$y, -lookahead), trainx, join='left', fill=NA)\n",
    "colnames(train.ml) <- c('logret_fwd', 'logret', 'rsi','bbands','macd')\n",
    "train.ml <- na.omit(train.ml)\n",
    "\n",
    "x <- head(train.ml, lookahead+6)\n",
    "head(x)\n",
    "tail(x)\n",
    "#tail(train.ml)\n",
    "\n",
    "idx.label <- 1\n",
    "idx.feautres <- 2:5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5a72f7-a53b-4172-9753-65db6e1810b9",
   "metadata": {},
   "source": [
    "## Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "df96df9e-dc59-4ec1-89d5-b364e10ca18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"10 % done.\"\n",
      "[1] \"20 % done.\"\n",
      "[1] \"30 % done.\"\n",
      "[1] \"40 % done.\"\n",
      "[1] \"50 % done.\"\n",
      "[1] \"61 % done.\"\n",
      "[1] \"71 % done.\"\n",
      "[1] \"81 % done.\"\n",
      "[1] \"91 % done.\"\n"
     ]
    }
   ],
   "source": [
    "result.m05.1 <- xgb.tsCV.mean(train.ml[,idx.label], train.ml[,idx.feautres], \n",
    "                              h=1, window=wind, step=peri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bc486be0-bde8-476d-9bdb-aaddc7d822d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-02-09\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m05.1\n",
    "from <- x[!is.na(x[,'forecast_start']),][,1][1]\n",
    "from <- index(trainx[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf56a93b-2659-491f-aeb0-639ca5afcc61",
   "metadata": {},
   "source": [
    "## Tuning params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3a5f7df4-0ca0-4beb-9270-5d8804fe7460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "25"
      ],
      "text/latex": [
       "25"
      ],
      "text/markdown": [
       "25"
      ],
      "text/plain": [
       "[1] 25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#max_depth <- seq(4, 8, 1)\n",
    "#eta <- c(0.01, 0.05, 0.1, 0.2, 0.3)\n",
    "\n",
    "max_depth <- seq(4, 8, 1)\n",
    "eta <- c(0.01, 0.05, 0.1, 0.2, 0.3)\n",
    "\n",
    "x <- expand.grid(max_depth = max_depth, eta = eta)\n",
    "nrow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "abe039a1-18cb-4a44-9909-88f34afdb9c4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   max_depth eta\n",
      "21         4 0.3\n",
      "   max_depth eta\n",
      "11         4 0.1\n",
      "   max_depth eta\n",
      "15         8 0.1\n",
      "   max_depth eta\n",
      "21         4 0.3\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "   max_depth eta\n",
      "18         6 0.2\n",
      "   max_depth eta\n",
      "18         6 0.2\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "23         6 0.3\n",
      "  max_depth  eta\n",
      "9         7 0.05\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "   max_depth eta\n",
      "21         4 0.3\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "   max_depth eta\n",
      "23         6 0.3\n",
      "  max_depth  eta\n",
      "8         6 0.05\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "22         5 0.3\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "   max_depth  eta\n",
      "10         8 0.05\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "   max_depth eta\n",
      "11         4 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   max_depth eta\n",
      "14         7 0.1\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "   max_depth eta\n",
      "21         4 0.3\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "25         8 0.3\n",
      "   max_depth  eta\n",
      "10         8 0.05\n",
      "   max_depth eta\n",
      "25         8 0.3\n",
      "   max_depth eta\n",
      "16         4 0.2\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "   max_depth eta\n",
      "22         5 0.3\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "9         7 0.05\n",
      "  max_depth  eta\n",
      "8         6 0.05\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "19         7 0.2\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "6         4 0.05\n",
      "   max_depth eta\n",
      "15         8 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "13         6 0.1\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "   max_depth eta\n",
      "25         8 0.3\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "   max_depth eta\n",
      "24         7 0.3\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "   max_depth eta\n",
      "13         6 0.1\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "16         4 0.2\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "   max_depth  eta\n",
      "10         8 0.05\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "   max_depth eta\n",
      "25         8 0.3\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "4         7 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  max_depth  eta\n",
      "6         4 0.05\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "9         7 0.05\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "20         8 0.2\n",
      "   max_depth eta\n",
      "23         6 0.3\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "6         4 0.05\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "25         8 0.3\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "   max_depth eta\n",
      "22         5 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "   max_depth eta\n",
      "16         4 0.2\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "   max_depth eta\n",
      "21         4 0.3\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "   max_depth eta\n",
      "25         8 0.3\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "12         5 0.1\n",
      "   max_depth eta\n",
      "21         4 0.3\n",
      "   max_depth  eta\n",
      "10         8 0.05\n",
      "   max_depth eta\n",
      "20         8 0.2\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "   max_depth eta\n",
      "20         8 0.2\n",
      "   max_depth eta\n",
      "15         8 0.1\n",
      "   max_depth eta\n",
      "23         6 0.3\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "24         7 0.3\n",
      "   max_depth eta\n",
      "23         6 0.3\n",
      "   max_depth eta\n",
      "19         7 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   max_depth eta\n",
      "13         6 0.1\n",
      "   max_depth eta\n",
      "21         4 0.3\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "   max_depth eta\n",
      "23         6 0.3\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "20         8 0.2\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "13         6 0.1\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "24         7 0.3\n",
      "   max_depth eta\n",
      "14         7 0.1\n",
      "   max_depth eta\n",
      "15         8 0.1\n",
      "  max_depth  eta\n",
      "8         6 0.05\n",
      "   max_depth eta\n",
      "16         4 0.2\n",
      "  max_depth  eta\n",
      "6         4 0.05\n",
      "   max_depth eta\n",
      "22         5 0.3\n",
      "   max_depth eta\n",
      "25         8 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "  max_depth  eta\n",
      "9         7 0.05\n",
      "   max_depth eta\n",
      "11         4 0.1\n",
      "  max_depth  eta\n",
      "9         7 0.05\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "16         4 0.2\n",
      "  max_depth  eta\n",
      "6         4 0.05\n",
      "   max_depth eta\n",
      "25         8 0.3\n",
      "   max_depth eta\n",
      "12         5 0.1\n",
      "  max_depth  eta\n",
      "7         5 0.05\n",
      "   max_depth eta\n",
      "17         5 0.2\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "   max_depth eta\n",
      "14         7 0.1\n",
      "   max_depth  eta\n",
      "10         8 0.05\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "20         8 0.2\n",
      "   max_depth eta\n",
      "25         8 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  max_depth  eta\n",
      "9         7 0.05\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "   max_depth eta\n",
      "14         7 0.1\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "   max_depth eta\n",
      "19         7 0.2\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "   max_depth eta\n",
      "20         8 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  max_depth  eta\n",
      "5         8 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "19         7 0.2\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "   max_depth eta\n",
      "18         6 0.2\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "23         6 0.3\n",
      "   max_depth eta\n",
      "25         8 0.3\n",
      "   max_depth eta\n",
      "24         7 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91 % done.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   max_depth eta\n",
      "17         5 0.2\n",
      "  max_depth  eta\n",
      "8         6 0.05\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "  max_depth  eta\n",
      "4         7 0.01\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "23         6 0.3\n",
      "   max_depth eta\n",
      "23         6 0.3\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "15         8 0.1\n",
      "   max_depth eta\n",
      "14         7 0.1\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "22         5 0.3\n",
      "   max_depth eta\n",
      "21         4 0.3\n",
      "  max_depth  eta\n",
      "1         4 0.01\n",
      "   max_depth eta\n",
      "17         5 0.2\n",
      "   max_depth eta\n",
      "23         6 0.3\n",
      "  max_depth  eta\n",
      "3         6 0.01\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "   max_depth eta\n",
      "18         6 0.2\n",
      "  max_depth  eta\n",
      "2         5 0.01\n",
      "   max_depth eta\n",
      "12         5 0.1\n"
     ]
    }
   ],
   "source": [
    "result.m05.2 <- xgb.tsCV.mean(train.ml[,idx.label], train.ml[,idx.feautres], \n",
    "                              h=hori, window=wind, step=peri,\n",
    "                              max_depth = max_depth, eta = eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dc8e1c-2053-444f-84cb-5bd9132cecf3",
   "metadata": {},
   "source": [
    "## Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "82ffd869-5005-4fdb-8977-7712eac50d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my.figsize(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "12fa005b-99d2-4390-8adc-0eaf9f019ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94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\nIQAAQEgphAAAACGlEAIAAITU/wNXoy9tZhBYHQAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- new.get_result(result.m05.1, '1.GBM 1')\n",
    "errors.2 <- new.get_result(result.m05.2, '2.GBM param tuned')\n",
    "\n",
    "x <- errors.1\n",
    "x <- rbind(x, errors.2)\n",
    "\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6d5142-2f6f-4a02-a902-047b11d9a798",
   "metadata": {},
   "source": [
    "### save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "120fef0e-57e6-41e7-ae91-5608745ac02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- result.m05.1\n",
    "write.csv(x, file = \"gbm_result_m0501.csv\")\n",
    "x <- result.m05.2\n",
    "write.csv(x, file = \"gbm_result_m0502.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8a8c50-2cdd-4346-9796-f3fa26f85ebf",
   "metadata": {},
   "source": [
    "### load result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2934e69f-478c-4b34-9e90-2334ec83da27",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.m05.1 <- read.csv(file = 'gbm_result_m0501.csv')\n",
    "result.m05.2 <- read.csv(file = 'gbm_result_m0502.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ec947a05-e8a1-497a-8ce4-36da525d0607",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m05 <- result.m05.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb209ef-30c2-4407-b353-1a388b17d202",
   "metadata": {},
   "source": [
    "# Model Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b9a63c6f-09de-4820-a6e8-a454f4973d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.1 <- new.get_result(result.m01, '1. Prophet')\n",
    "errors.2 <- new.get_result(result.m02, '2. BSTS')\n",
    "errors.3 <- new.get_result(result.m03, '3. ARIMA')\n",
    "errors.4 <- new.get_result(result.m04, '4. ARIMA+GARCH')\n",
    "errors.5 <- new.get_result(result.m05, '5. Gradient Boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "27d10fd6-6a42-4cc0-8441-08220c600b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAAJYCAIAAAD9hIhNAAAACXBIWXMAABJ0AAASdAHeZh94\nAAAgAElEQVR4nOzdeVxU9f7H8e9s7Mi+iCBiuC+oWLkrJmpoLphrXjUts7TyVm6lYaa329Vf\naZnhvpbaYuRuppWamrlbakpuKCIiMDgwMOvvj+nOnVBhRMYBzuv5uI/74HzP9/s9n0MgvDnn\nfI/MbDYLAAAAAID0yJ1dAAAAAADAOQiEAAAAACBRBEIAAAAAkCgCIQAAAABIFIEQAAAAACSK\nQAgAAAAAEkUgBAAAAACJIhACAAAAgEQpHTq7RqNZtGjRr7/+ajAYGjdu/OKLLwYHB9/Z7dq1\nax9++GFqampKSkqpY+2c0+L27dsGg8ERp4aKr1q1amaz+fbt284uBKgiXFxc3N3dtVqtTqdz\ndi1AFeHt7S2E4EeVZCmVSsvXAOBEMrPZ7LjZZ86cmZWVNW7cODc3txUrVmRkZHz00Udy+d8u\nS+7du3fJkiXNmzf/8ccfbQPhvcbaM6eVWq3W6/WOO0FUZP7+/mazOScnx9mFAFWEm5ubl5eX\nRqMpLCx0di1AFeHn5yeTybKzs51dCJxDpVL5+Pg4uwpInQNvGc3Kyjp06NArr7wSHR0dHh4+\nfvz4a9eunThxolg3vV4/Z86cVq1a2TPWzjkBAAAAAKVy4C2j58+fd3FxiYqKsmx6eXlFRESc\nP3++efPmtt06d+4shPjzzz/tGVtYWFjynOnp6QcPHrTO07JlS39/f8ecHyo6mUwmhHBzc3N2\nIUAVoVKprP8PoFzIZDKZTMaPKsmy/K4COJcDA2FeXp63t7ftF7qPj49arX6QsT4+PiXP+ccf\nf/zrX/+ybi5YsKBmzZoPdBqozGQymZeXl7OrAKoUV1dXV1dXZ1cBVCn8qJIslrpAReDYRWWK\n/dnjvp5XvNfYkuesV6/em2++ad0MDQ3VaDT2HxRViaenp9lsLigocHYhQBWhUqlcXV2Liop4\nNhsoLx4eHjKZLD8/39mFwDlkMplS6djfxoFSOfBL0NfXNy8vz2w2WyOcWq328/N7kLGlzhkW\nFpaYmGjdVKvVLH4gWR4eHmazmS8AoBy5urrq9Xq+rYDy4u7uLoTge0qyuAkfFYEDF5WpW7eu\nXq9PTU21bKrV6rS0tPr16z/I2AeZEwAAAABgy4GB0M/Pr23bth9//HFqampaWtoHH3wQHR3d\nqFEjIcTOnTs3bdpk6ZaTk5OVlWV5A09WVlZWVlZhYeG9xpYwJwAAAADgvjj2PYQFBQWLFy8+\ncOCAyWRq3rz5mDFjLLd3zp49Oy8v79133xVCPPfcc5mZmbajnnvuuV69et1r7L3a74r3EEoZ\n7yEEyhfvIQTKHe8hlDjeQ4iKwLGB0OkIhFJGIATKF4EQKHcEQokjEKIicOAtowAAAACAioxA\nCAAAAAASRSAEAAAAAIkiEAIAAACARBEIAQAAAECiCIQAAAAAIFEEQgAAAACQKAIhAAAAAEgU\ngRAAAAAAJIpACAAAAAASRSAEAAAAAIkiEAIAAACARBEIAQAAAECilM4uAAAAQKL2799vMpka\nNWrk7EIASBeBEAAAwDnmzJmj1Wo///xzZxcCQLq4ZRQAAAAAJIpACAAAAAASRSAEAAAAAIki\nEAIAAACARBEIAQAAAECiCIQAAAAAIFEEQgAAAACQKAIhAAAAAEgUgRAAAAAAJIpACAAAAAAS\nRSAEAAAAAIkiEAIAAACARBEIAQAAAECiCIQAAAAAIFEEQlRZY8eOnThxorOrAAAAACoupbML\nABzl/Pnz3t7ezq4CAAAAqLgIhBXXkSNHvv76a7PZ7OxCKiuNRqPVaqdMmeLsQioruVz+zDPP\nNGzY0NmFAAAAwFEIhBXXTz/9dPToUWdXUbkZDIZjx445u4pKLDIykkAIAABQhREIK7rFjzYJ\nd3d3dhWQnDN5mteOn3Z2FQAAAHAsAmFF56FQVFPxnwkPm6dS4ewSAAAA4HCsMgoAAAAAEkUg\nBAAAAACJIhACAAAAgEQRCAEAAABAogiEAAAAACBRBEIAAAAAkCgCIQAAAABIFIEQAAAAACSK\nQAgAAAAAEkUgBAAAAACJIhACAAAAgEQpnV0AAKASSE9P37lzZ3Z2dmBgYHx8fGhoqLMrAgAA\n5YBACAAoxcGDB2fNmqXX6y2bX3zxxdtvv/3oo486tyoAAPDguGUUAFCSgoKCDz74wJoGhRB6\nvX727NlardaJVQEAgHJBIAQAlOT06dN5eXnFGvPy8s6cOeOUegAAQDkiEAIASlJUVHTXdp1O\n95ArAQAA5Y5ACAAoSXR09J2Ncrn8ru0AAKByIRACAEoSEhIyaNCgYo2DBw8ODAx0Sj0AAKAc\nscooAKAUw4YNCw4O3rx58/Xr18PCwnr27NmtWzdnFwUAAMoBgRAAUAq5XJ6QkJCYmOjl5aXR\naAoLC51dEQAAKB8EQlQsv9289fae/fuvXi8yGhsHBUxs1fKpOrXL0Hnmz7/M/PlQsf5xkRHb\nBvYpda8Q4sfLV98/ePhkZpbBZKzj7ze2RcygRvVk5XaWAAAAQIVAIEQFkpqT+8TnXwV5eLzT\noXU1F5c1v58Z8M2W9X179LpbJiy5s7pIJ5fJPukWZzskzMvL8kHJe7ekXuz/zZaY4MCpbR9T\nyGTrz5x7dst3F9V5b7bhNdwAAACoUgiEqEBm/XzIYDJ/Pzgx1MtTCDGgYd3WK9dN+mHfU3Vq\n33l1ruTO6qIibxfVs00b3fVAJe99e8+BSJ9qu5952l2pFEI8G9Modtnn8349OqXNo1wkBAAA\nQFXCKqOoKIxm8+bUi08+UssS8IQQCpnsH40bXMxVn8y8eb+d84p03i4u9zpWCXtNZvOzMY1m\nd25vSYNCCJVc/nhYqLpIV6DXP+A5AgAAABUKgRAVxaXcvNs6XZPgvy1k3ywkSAhxKjPrfjur\ni3TVXP+KfFqDodjwEvbKZbJxsTE9o6OsLWYhTmfdCvf28lSpynpyAAAAQEXELaOoKDLy84UQ\nIR4eto1BHu5CiOuagvvtnFdUVGQ0Prvlu62pF9VFOn93t8EN683o0NoS6krea1FkNGbmF6Rr\n8pOPnjx189bKp1hkHwAAAFUNgRAVRaHBKIRwUfztqrWrQiGEKDIWv8RXaufcoqILOep24TXm\nd+uslMu/PZf6yZETp7OyLeuIlrzX4uer6QnrU4QQNat5r+uTkPBIrfI/ZwAAAMCpCISoKNyU\nljhntG0sNBqFEG7K4l+opXb+blCiUi4P8fzrEmLfuo+4KBSrTp356crVjjXDS95raYwJDvw6\nsWeWVrvrUtrTGza/8XjsjA6ty/ukAQAAAGfiGUJUFNW9PIUQGfl/uzs0Q5MvhKjx3xdC2N+5\nhreXNe9ZPF2/jhDiZGZWqXstAtzde0RHDW/ScNVT3f75WPP/HDx8+PqNBztFAAAAoGIhEKKi\nqOVTzc/N9VhGpm3jr9dvCCGahwbdb+c8nS5Pp7Pdm683CCE8VMqS994s0C4+/tuvf89+bWqE\nCSF+u3nrQU4QAAAAqGgIhKgo5DJZn7rROy5cvqzOs7QUGowrTp5uEhRYP8D/vjrfyC+oPm/R\niE07bIesOnVaJkS78Bol73VRKF77/qcpP/5sMpute3+4nCaEqOnjXe5nDQAAADgRzxCiAnmr\n7WMbz1/ouu6bcbExnirV8pO/X8m7vWVAb8vezakXB36z5T+d24+NjSm5c4inxwvNmy44euKp\nL7/tU/cRndH0zbnUPVeuvdQipl6AnxCi5L0TW7Wctf9Ql7UbEutFuyoU+9KufXHm3ONhoZ3+\n+3ghAAAAUDUQCFGBhHt7/fBMvzd//Pndfb8YzKZmIcFbBvS2rvJiMpuNZrP1wl3Jnec80b6u\nv++KU6en/PCz3mRqEOj/Sbe4UTGN7dk7rd3j0X6+ycdO/uvnQzqTMbJatbfbt3o5tplcJnu4\nnw8AAADAsQiEqFjq+vt9ldjzrrt61aldOPFlOzvLZbIxLZqOadG0DHuFEIMb1RvcqJ7dVQMA\nAACVEs8QAgAAAIBEEQgBAAAAQKIIhAAAAAAgUQRCAAAAAJAoAiEAAAAASFQVX2XUzc3Nzc3N\n2VWUkUqlcnYJkDoXFxdvb29nV4GKQqFQCCHc3Nz41wkoX/xLK1nm/75MC3CiKh4IdTqd0Wh0\ndhVlVHkrR5VhMBi0Wq2zq0BF4eLiolQqdTqdTqdzdi1AlcK/tJKlUCgq76ULVBlVPBCaTCaD\nweDsKsrIZDI5uwRIXaX+DkK5UyqVgq8KwAH4npIsmUzm7BIAniEEAAAAAKkiEAIAAACARBEI\nAQAAAECiCIQAAAAAIFEEQgAAAACQKAIhAAAAAEgUgRAAAAAAJIpACAAAAAASVcVfTA8AtoxG\nY0FBgbOrqKz0er3JZMrPzy8sLHR2LZWVp6enXM6fYgEAFQiBEIBU6PX64cOHZ2dnO7sQSFdg\nYODy5ctVKpWzCwEA4C8EQgBSodFosrOzDZ6ygurOLuXhKlJrb528qr2pMZvMrj7u/g2re9bw\nfcDOek3R5e2/yxXy2n2bWRs1adm55zJ1eYVmk0nl6eodFehbJ1gml9kzVgo8rpuzsrIKCgp8\nfHycXQsAAH8hEAKQFk2k7M9/KJxdxUN0rVCMOyt8VWJMTeGhKNx5M/3nVJFUV7TxL3tnsxAT\nzwmjyegpPz/qvz9Hvr4u1l8WnQNFfIRQyoqOqYvWpmV554tpdUsfKw3Rq4w+Z0zOrgIAgL+R\n1g/jyuiXW7kX8rXOrgKSk1bAV11VsfqqMJrF/zUS/iohhIgLEC+dEgsvi9b+ovilO7s7b8sU\nZzSihY9Izf9f45ZMUd1VTIr+q2dMNXFJK/ZmC41BeClLGQsAAJyEQFjRfXT+krNLAFBpmczi\nQI543O+vgCeEkMtE1yCRfFlcyBePeJal8y2dWHxZDK4hbhT9LdS5yIRR/rfc6C4XcplQ2ayh\ncq+xAADASVjrDACqrowioTWK2h5/a4z2FEKIC3estmpn548viiBXMTCs+PCnw8Rlrfj8msjR\ni3yj2Jct9mWLXiHCVV76WAAA4CRcIQSAqitbL4QQfn9f09JXJYQQt/Rl6fzTLXEgR3zUWCjv\nuN+0S6BQycQHF8SKNCGEkAkxuIYYHvG/DiWMBQAATkIgrOhmNqlb3c3N2VVAcv7UFPzrTKqz\nq8AD05mEEEL595tBLPdw6u9Y3aTUzrcN4pNLom91Uc/rLsc6lSc+uCCaVhM9goWLXBzKFevS\nhYtcDKlR+lgAAOAkBMKKLsrTo5anR+n9gHJlMJudXQLKg8vdsp8l+Lnc8chAqZ2TLwtXuRgR\nUXygEMIsxJw/RQ03MaPeX48RtvARJrNYmSY6BogabiWNBQAAzsMzhABQdVmWh8n5+92h2Toh\nhAh0ub/OR9Ti+5vipVrCbBZao9AahdEshBBao9CZREaRuF4kWvr+bVGZ5j7CLMTp26WMBQAA\nzsMVQgCouqq7CS+lOPf39Tz/0AghRB3P++u8MUOYhUj6o/io3r+Kx33Fc5FCCGH4e7qzXGw0\nmMWB7JLGvlv/Ps8KAACUGwIhAFRdMiHa+4vvs8SNIhHiKoQQOpPYflPU9hA13e+vc78w0Snw\nb/3Xp4vf8sS79YW3UtRwE54KcVgtnhf/u0h4VC2EEPW8RDOfksYCAADn4ScxAGlxyTEHHpLQ\nbYqmxmG5P2XLXjnt1jpE5qIoPJxpyCjyGVFPdcgkhNCdzcn7PNXzyZrurUNK66wS4m8LkGoM\nyiKzLKDAUxQIccOs7RSev+Wy6oXf9WkamVLu1iJI+8tN1yb+3lmWZbFKGCuV/xwuOTyaCwCo\ncAiEkJaZP/8y8+dDxRrjIiO2DezjlHrw8HlcN0d+Y3R2FQ+TojCq3rVr127vuGY2mz08PMKi\n63if8BQnjEKI3FxTnsnsf9IUnGEstXMxly+bDTph88kMzKmtuHz5sjCazUaj+VhujephIaoQ\n2d0+23eMBQAAzkEghLSoi3RymeyTbnG2jWFerIOPqszNze2RRx656y5fX9/Y2Fg7OxcTGRkZ\nGRlp22I0Gs1mc7Vq1QoKCho1anRfY1FJ6fX6s2fPGgwGZxdSWRUVFRkMhmPHjjm7kMpKqVTW\nr19fpVKV3hXAPRAIIS3qoiJvF9WzTUv6VRWQmnPnzpnN5po1a169elWj0cjlcm9v74iICMvv\nWPf6XV8mkykUCuumXq+/evVqaGioTqcrKCh4SKXD2davX79mzRpnV1HpTZkyxdklVGL9+/cf\nNWqUs6sAKjECISqZrus26IymBd06v7Frzy/pGW5KZaeaNT7o0jHE08MsRLZWe9dRCrnc19VV\nCJFXpPN2uWO1fUjJ7SjZ1R6K0vtJSdH/yU3p2rPay6qR4a41PUx/anIWpubJheu4uma1Xjv+\nxF1HyUPd3N6L+d8kH10wh7rkvhOuW3XReFScGcfPl+Iithi9Lla1xwg1Go0QwrdugsozyNm1\nQHKMhbnZZ769ffu2swsBKjd+YKOScZErLuSoR2/7/q02jy0ODjx0/cbwTTsKjcavE3tm5hdE\nfrL0rqPq+vudfG6oEEJdpKvm+lcg1BoM7kq+BSTH6C4rqCErvZ+kuMlEts48JbooppoQQjR2\nFUeyjMfUBWEyEaIS/25w10EmN/n/PpM/3RLHc8RHjQtqyoWHTMgFn+Q7Gd1kQlS1QGgR2HiA\nR0hjZ1cBySnM/jP7zLfOrgKo9PhtGJWMTCau3tYs7RHfsWa4EKKvt9eaqJq7L6WZhfBzc916\nj7VhPP/7dEFeUVGR0fjslu+2pl5UF+n83d0GN6w3o0NrTx4/gMSp5KJptf9tBrqIIpPQmYSr\nXLTwKWXsbYP45JLoW13U43FcAAAqGQIhKh9XhaJDzXDrZpiXp9Zg0OoNHipl58iIksfmFhVd\nyFG3C68xv1tnpVz+7bnUT46cOJ2VzSqjkDofpbC9pCcXQghhsu9yVvJl4SoXI0r57gMAABUQ\ngRCVT4C7u+0vrgq5XAhhMtv1m+t3gxKVcnmIp4dls2/dR1wUilWnzvx05WpHm5AJ4C9mIfLu\nsYCkQggvpTiiFt/fFNPrCbNZaI1CCGE0CyGE1igUMuEif3ilAgCA+0cgRNVhz6IyNbyL39L2\ndP06q06dOZmZRSCUCO+L5gbzWSL/b65cMRVpRB2bT0vGKXOOEPUWGk1G3fkdd19UxsXL7ZHO\njTNO3coxC5H0R/HdvX/1CvGJeLyO48qudFxvVc0HCAEAlRqBEFWHPYvK5Ol0QohqNguN5usN\nQggPFd8LVZ+Xl1dUVFRWVpbIc3YpFcwNg9JgloXk/e/PJXk6VY4Qwbc9ZTKZR8xfS4kaDAa9\nXu/i4mJ524RCoaiW51UtOErnW8N2titXrqjV6iZNmiiVSs88z4d5IhWdSgSFBXl68jkBAFQg\n/BKMqqPURWVu5BfUXrCsW+3IDf2esu5adeq0TIh24TXuOhBViUql+vTTT51dRUU0YMCAs2fP\nfvnll9aWyZMnL126dPXq1bbp5fvvv58zZ87EiRM7d+5cwmzjx4/ftm3bd99958CKAQBAOSEQ\noupwUShKXlQmxNPjheZNFxw98dSX3/ap+4jOaPrmXOqeK9deahFTL8DvodUJAAAAVBA87g9p\nmfNE+7ldOt4s0E754ec3f/xZo9N/0i3ugy4dnF0X4ExffPHFyZMnbVv+/e9/37x5s2w3N86d\nO/ePP+54pBAAAFRIXCFEJbOpf+9iLXO7dJzbpaOdw+Uy2ZgWTce0aFredQEAAACVD1cIAQAA\nAECiCIQAAAAAIFEEQgAAAACQKAIhAAAAAEgUgRAAAAAAJIpVRiu6i/naQqPJ2VVAci7na51d\nAgAAAByOQFhxyWQyIcTUU7zOC04jl3MTAQAAQFVGIKy4evTooVAonF1FJbZr1y6VStWhAy+d\nLyOZTBYfH+/sKgAAAOBABMKKq27dunXr1nV2FZXY/v37vb29X3nlFWcXAgAAAFRQ3A8GAAAA\nABJFIAQAAAAAiSIQAgAAAIBEEQgBAAAAQKIIhAAAAAAgUawyiipr1KhRKpXK2VUAVUfXrl0T\nEhIMBoPJZHJ2LQAAoHwQCFFlDRw40Gw25+TkOLsQoIpwcXHx8vLSaDSFhYXOrgUAAJQPbhkF\nAAAAAIkiEAIAAACARBEIAQAAAECiCIQAAAAAIFEsKgMAAHB/cq6eOrLhzRup+4yGIv8aTZr2\neLNms95l63z97O4TW/6Vk3bCZNRXC6nbsMsrjzz+jJDJhBDHNk4/vvGdYrNVb/BE99e/1xXk\nfvaK310P98TYb2o271MeZwlAEgiEAAAA9yHvxvmt77d3qxYc23eWyr1a6v5Vuz7p+8RLG+4a\nw0runHZi0675ffxrNmvWK0kmV1z4Ze2eJf+4nXWxWc9pQgi9Vi2TydsMW2g7oYdvDSGE0sWj\n7fDFxY6VfnrnpcNfeQfVdtSZA6iKCIQAAAD34fimd0wmw5MTf/LwqS6EqP3Y4I3vxh764vWa\nzXpbruzZ3/nIhje9Amv1mLRP4eIuhKjb/rmUpCa/7/i/Zj2mCplMV6BWuXnXbf/cnTXIlS7F\n2nVa9bFvk+p3etEvvKmjzhxAVcQzhAAAAPYym4xXjm+MaNrDEvCEEDK5IrrNiNs3L2RfPXFf\nnc1mU932zz028ENLGhRCyBWq4Eda67Rqg65ACKHTqlXu1ews7Og3U01GfYu+M8vhJAFICYEQ\nAADAXrezLuoLb/uHx9g2BtRsLoTITiseCEvuLJPJG3Z5tWazXv/bZzbnXPvN0z9C6eopLIHQ\n7a9AaNRpS6gqN/30Hz8mt+jzrouHb5lPDYA0ccsoAACAvbTq60IIt2ohto1u1YKFEAXq62Xr\nbDQUFebdyM+5dvaHT7Kvnuz4/OeWdr1WbTIU7Vnyj7QTm3RatatXwCOPPxOb+C9LXLR1NGWa\nV1DUXW8uBYCSEQgBAADsZdQXCiEUShfbRoXS1bqrDJ1vnNu744N4IYRXQGTnl76OaNrT0q4r\nyM27+WdI3Q5thi2UyZWXj244veujnPTfu7/+ve2EuemnLx/7ps0/kmVyRTmdJQAJIRACAADY\nS6FyE0IYDUW2jZZ0p1S5l62zf81mXV7eWHj75rXTO3d93LvJk5NiE/8lhOg+4Qe5XOnuE2rp\nViu2n0Lpev7n5dfP/lC9fpx1+NkfFqhcvWo/PqT8zhKAhPAMIQAAgL08fMOEEFp1hm2j5dZQ\nD78aZevs5hUYEfNUnXYjO41e27jbGye3vpd16VchhKdfuDUNWkQ9OkD8/WFFk8lw8df14U2e\nVLl6lcPpAZAeAiEAAIC9vAKjXDz8si4fsW28efGQECIgMva+Ohfezjz7Y7Jl0yqkTjshRHba\nSSGEXpun1+bZ7tUX5QshlK4e/5vtz4OFmqwajZ984DMDIFEEQgAAAHvJZPJasf2undqmybpk\naTHqC8/tXeoX3tS3eoP76ixXuv6y9pXDX04wm03WIelndgkhvAIiteqMz171/2nxM7YTpv68\nXMhkoXU7WFsy/9wvhAio2azczxSARPAMIQAAwH1o9tTbV46lbJsT1/CJV1Wunuf2Lsm/dbnr\na99Z9l45vnH3gsTHBn7Q8IlXSu7s4u7TNGHK8U0ztv2nY63Yp+VK1xvn9lz4dV3wI62rN+gs\nk8nrx710ZtfH333YPTI20WTQXTrydcYfPzZ44mWf0PrWYtTXzwohvIMeccZnAkBVQCAEAAC4\nD57+EQmT9x3+auKxjUlmoyEgskXX17773yovZpPZZDSbTPZ0bt77nWohdc7+sOD4phkmg84r\nsFaL3jMaxo+XyeRCiMcHzfUJrXd+79Jfv5xgMup9qzdsM2xhvQ6jbYsp1GTJZHIeIARQZjKz\n2ezsGhxIrVbr9XpnVwHn8Pf3N5vNOTk5zi4EqCLc3Ny8vLw0Gk1hYfG19SFZycnJKSkp0Ykr\nPEIaO7sWSE5h9p/n1g/s3r37+PHjnV1LGalUKh8fH2dXAanjGUIAAAAAkCgCIQAAAABIFIEQ\nAAAAACSKQAgAAAAAEuXYVUY1Gs2iRYt+/fVXg8HQuHHjF198MTg42M4+aWlpy5cvP3v2rMlk\nioqKGj58eP369e2cEwAAAABQKsdeIZw7d+6VK1fefffdDz/8UKFQzJgxw2Qy2dNHr9dPnTrV\n29t79uzZH374YUhIyPTp07VarZ1zAgAAAABK5cBAmJWVdejQoVdeeSU6Ojo8PHz8+PHXrl07\nceKEPX0KCgr69OkzZsyYGjVqVK9evX///gUFBRkZGfbMCQAAAACwhwMD4fnz511cXKKioiyb\nXl5eERER58+ft6ePj49P37593d3dhRC3b9/euHFjeHh4eHi4PXMCAAAAAOzhwGcI8/LyvL29\nZTKZtcXHx0etVtvfx2QyPf300waDoVGjRjNnzlSpVKXOefjw4Xnz5lk3J0yY0LBhw3I/NVQK\ncrncbDb7+vo6uxCgipDL5UIIDw8PNzc3Z9eCisLV1dXZJUDqXFxcKu/Pep57QkXg2EVlbJOb\nEMJsNt9XH7lcPm/evNzc3I0bN7711ltz5swpdc7CwsJr165ZN/V6vUKheIAzQOUmk8n4AgDK\nF99WsGX5MwHgRHK5vPL+o3TX342Bh8yBgdDX1zcvL89sNlsjnFqt9vPzu68+ERERERERDRs2\nHDZs2I8//hgYGFhy/3bt2u3evdu6qVarb9265aATRAXn7+9vNptzcnKcXQhQRbi5uXl5eeXn\n5xcWFjq7FlQUlvXeACcqLCysvL/sqVQqHx8fZ1cBqXPgH/bq1q2r1+tTU1Mtm2q1Oi0tzfLq\niFL7nDhxYvTo0dbfOeRyuUwmM5vN9swJAAAAALCHAwOhn59f27ZtP/7449TU1LS0tA8++CA6\nOrpRo0ZCiJ07d27atKmEPtHR0UVFRfPmzUtLS8vIyFiyZElhYWGLFi1KmBMAAAAAcF8c+wzh\nuHHjFi9ePHXqVJPJ1Lx58/Hjx1tu9Tx+/HheXt5TTz11rz6enp4zZsxYuXLl5KZgmAIAACAA\nSURBVMmTjUZjZGTk22+/HRYWVsKcAAAAAID7IqvaD7Oq1Wq9Xu/sKuAcPEMIlC/LM4QajYZn\nCGGVnJyckpISnbjCI6Sxs2uB5BRm/3lu/cDu3buPHz/e2bWUEc8QoiJgcTAAAAAAkCgCIQAA\nAABIFIEQAAAAACSKQAgAAAAAEkUgBAAAAACJIhACAAAAgEQRCAEAAABAogiEAAAAACBRBEIA\nAAAAkCgCIQAAAABIFIEQAAAAACSKQAgAAAAAEkUgBAAAAACJUjq7AAAAULnlnNuan37E2VVA\ncvTaW84uAagKCIQAAOCB3PrtC2eXAAAoI24ZBQAAAACJIhACAAAAgERxyygAAHggkd1muwfW\ndXYVkJwi9ZWLm192dhVApUcgBAAAD0TlGeRSrYazq4DkmAyFzi4BqAq4ZRQAAAAAJIpACAAA\nAAASRSAEAAAAAIkiEAIAAACARBEIAQAAAECiCIQAAAAAIFEEQgAAAACQKAIhAAAAAEgUgRAA\nAAAAJIpACAAAAAASRSAEAAAAAIkiEAIAAACARCnt6aTRaLZt27Zjx45jx47dvHkzNzfX19c3\nKCioWbNm3bt3f/LJJ728vBxdKAAAAACgfJVyhbCwsHD27NlRUVEDBgxYvXq1Xq+vU6dOfHx8\nnTp19Hr9mjVrBgwYEBUVNWfOnMLCwodTMQAAAACgXJR0hfDixYuJiYknT57s37//8OHDO3bs\n6OHhYdshPz//p59+Wrly5aRJkz7//POvv/46KirKwQUDAAAAAMpHSYEwNja2WbNmv/32W4MG\nDe7awdPTMyEhISEh4cyZM2PHjo2Njc3OznZMnQAAAACAclbSLaNjx47duXPnvdKgrQYNGuzc\nufOll14qv8IAAAAAAI5V0hXCd99913ZTq9UeOXLk2rVrTzzxRGBgoMFgUCr/N1yhUMycOdNR\nZQIAAAAAypu9r52YPXt2aGho+/btBw0alJqaKoRISkoaOXKk0Wh0ZHkAAAAAAEexKxAuWbJk\n4sSJnTp1Sk5OtjbWq1dv9erVs2fPdlhtAAAAAAAHsisQzp8/f8yYMd9+++3w4cOtjcOGDZsw\nYcLq1asdVhsAAAAAwIHsCoRnz57t16/fne0dO3a8ePFieZcEAAAAAHgY7AqEKpVKq9Xe2X7j\nxg2VSlXeJQEAAAAAHga7AuFjjz02d+7coqIi28bc3NzZs2e3atXKMYUBAAAAABzLrkCYlJS0\nZ8+ehg0bvvbaa0KIRYsWjRgxolatWn/88cfbb7/t4AoBAAAA2Gv69OkymSw4OFiv19+59/nn\nn5fJZO3atSvb5IMGDfLy8rKnZ7t27erXr1+2o+BhsisQdujQYceOHb6+vp9++qkQYvny5StX\nrqxXr97OnTvbtm3r4AoBAAAA3Ae5XJ6dnb1t27Zi7YWFhV9++aWLi4tTqkLFVNKL6W117tz5\nyJEjWVlZaWlpMpksMjLSz8/PoZUBAAAAKAO5XP7444+vWLGiV69etu0bN27Mz89v2bKlswpD\nBWTvi+ktAgMDmzdv3qxZM9IgAAAAUDEZDIY+ffps2bLl1q1btu2rVq2Ki4srdoVw27ZtHTp0\n8Pb2dnd3b9y48QcffGA2my27zGbzjBkzIiIi3NzcmjRp8tVXX8lkMtuxP//8c3x8fLVq1dzd\n3Zs3b75s2bK71nP9+vXnn38+MjLSzc0tNDS0X79+Z8+eLdczRtmVdIXQzrt++c8JAAAAVCh9\n+/adNGnS2rVrx40bZ2nJzMzcsWPHwoULFy9erFAoLI0pKSmJiYnt2rVbsWKFt7f3V1999frr\nr6enp8+ZM0cIMXv27KSkpMGDBz/77LO3bt1KSkoyGo3WQ/z4449du3Zt06bNmjVr3N3dN2zY\nMGrUqOzs7DfeeKNYMYmJiZcuXZo5c2ZUVFR6evr7779veX2dh4fHQ/lkoCQlBcLAwMCHVgcA\nAACA8lKjRo3OnTuvWLHCGgjXrl2rUqn69++/aNEia7cpU6aEh4fv3LnT1dVVCNG1a9esrKyP\nPvpoypQp/v7+8+bNa9So0WeffWa5MNihQ4datWpZLzC+8cYb4eHhO3bssIyNj49PT0+fOXPm\n2LFj3d3drYfIy8s7ePDgpEmTRo0aZWlp27btunXrcnNzCYQVQUmBcN++fSUPzs/PT09PL9d6\nAAAAAJSDESNGDB069Pfff2/UqJEQYtWqVX369PH29rZ2SE9PP3v27OjRoy2JzqJHjx7ffPPN\nwYMHmzRpkp6e3q9fP+ttomFhYS1btjx58qQQIisr68iRIy+++KLZbC4sLLR0SEhI2Lhx45Ej\nR2xXMfXw8AgMDFy3bl18fHxcXJxcLo+KipoyZcpD+AzAHvf3DGExBw8e7NSpUzlVAgAAAKDc\n9O3b19vbe8WKFUKI06dPHz16dNiwYbYdrl27JoQIDw+3bQwLCxNCXL9+PSMjQwgRHBx8514h\nRFpamhDi008/dbcxZswY67RWSqVy69atMpmsS5cuQUFBAwcOXLt2re2tp3Aue1cZ3bJly9q1\na69cuWIymSwtRqPx999/t/1zAgAAAIAKwsPDo3///mvWrPn3v/+9atWq6tWrx8fH23awXPrT\n6XS2jZYVZWQymXVpGVvWIGcZ++yzz44ePbpYn+jo6GItjz76aGpq6p49e7Zv375t27Yvvvhi\n/vz5u3fvJkpUBHYFwnXr1g0ePFipVIaGhl69ejUsLEytVufn58fFxb3++uuOLhEAAABAGQwf\nPnzZsmX79u1bt27dkCFDrGvJWERERIj/Xuuzunr1qhAiPDw8KChICHHjxg3bvZcuXbJ8ULNm\nTSGEyWRq1aqVPZUoFIq4uLi4uLj3339/4cKFY8aMWb9+fbErlnAKu24ZnTNnTkJCQnZ2dlpa\nmqur665du3Jzcz/99FOlUtmxY0dHlwgAAACgDNq3b1+7du3Zs2dfvnz5zvQVEhLSpEmTzZs3\na7Vaa2NKSoqHh0fr1q1r1aoVGBi4a9cu6x2CZ8+etTxAKITw9/d/7LHHUlJScnNzrWNXrVo1\ndepUg8Fge5TDhw8PGjQoMzPT2mK5UGnbAieyKxCeO3fupZdesn0CValUjhkzJiYmZtKkSQ6r\nDQAAAEDZyWSyYcOGbdmyJSYmpmnTpnd2eO+993JycuLj47/++utNmzYNGTJk27Zt06ZNq1at\nmlwuf/HFF8+cOZOYmPjVV18tWLCge/fusbGx1rH/+c9/CgoK2rdvv3r16u+++27atGnPPfdc\nenq6Uvm3mxBr1Kixffv2+Pj4ZcuW7dy5c+3atUOHDnV1dX3qqaccfv6wg12BUC6XWxcXcnFx\nuX37tuXjXr16bdiwwVGlAQAAAHgww4YNs8TCu+7t0aPH1q1b5XL58OHD+/fvf/bs2WXLlk2e\nPNmyNykpafLkyb/88sszzzyTnJw8d+7cNm3aWJ857Nix4+7du6tXrz527NjevXt//fXXM2bM\nWLx4cbFDVK9efc+ePXXq1Hnrrbd69uz5+uuvBwcH79mzp169eo47a9jv7k+LFtOqVauIiIjP\nP/9cpVLVr19/1KhREyZMEEKkpKQMHTpUo9E4vs4yUqvVer3e2VXAOfz9/c1mc05OjrMLAaoI\nNzc3Ly8vjUZjXV4cSE5OTklJiU5c4RHS2Nm1QHIKs/88t35g9+7dx48f7+xaykilUvn4+Di7\nCkidXYvKvPrqq0OGDLl9+/b27du7des2bdq0q1evBgQELFy4MCYmxtElAgAAAAAcwa5AOHjw\nYLlcfuXKFSHE9OnTz5w589FHHwkhIiIi5s2b59gCAQAAAACOYe97CAcOHGj5wM/P77vvvktP\nT8/Ly3vkkUdUKpXDagMAAAAAOJBdi8oIIa5fv/7xxx9bN1Uq1RdffJGVleWYqgAAAAAADmdX\nIPzjjz9atGjxxhtvWFsKCgqSkpJiY2NTU1MdVhsAAAAAwIHsCoSTJ0/28vLat2+ftSUyMvL0\n6dOenp7WRWkBAAAAAJWLXYFw7969b7755qOPPmrb2KBBgwkTJuzZs8cxhQEAAAAAHMuuQJif\nn+/q6npnu1KpzM/PL++SAAAAAAAPg12BsHnz5itXrjSZTLaN+fn5ycnJzZo1c0xhAAAAAADH\nsuu1E9OmTevZs2fDhg3j4+NDQkIKCwuvXr26adOm3NzcLVu2OLpEAAAAAPa4ffu2I6b19vZ2\nxLSoCOwKhE8++eSmTZumTJkyf/58a2NMTMzq1au7d+/usNrKgVwuVyrtfdciqhiZTCaE4AsA\nKC9yuVzw7yr+zvJVAYfKy0xNmd5U6eIxZC6v+7qLSv2PEt9BqAjs/f5JSEhISEi4efPm1atX\nhRARERGBgYGOLKx8uLi4OLsEOJNMJnN3d3d2FUAVoVAohBAuLi6WDwDBH90eArP555XPG3Va\npYuHs0upoBQKReX9WW82m511aK1Wu2HDhp49e/r4+DirBlQQ9v47XlBQoFarq1evHhQUVFhY\nuH79+ps3b/bq1atu3boOre8BFRYW6vV6Z1cB5/D39zebzQ66cQKQIDc3Ny8vr8LCwsLCQmfX\ngopCp9M5u4Qq7o+9i29eOBjWsMutK8ecXUsFpdfrK+/PepVK5ebm5pRDHzhwYMmSJV5eXr17\n93ZKAag47LpOffbs2aioqJUrVwohDAZD586dR4wYMWHChJiYmCNHjji4QgAAgEpm2+y4Le+1\nzU3/fccH8avHeq0dH/RD8gCtOkMIIczmQk3WXf+nK8i1naQgN/3wlxOb9njTKyDSOaeBqsuy\nWmSxNSMhTXZdIXzrrbdCQ0MHDhwohFi/fv2BAwcWLVr0xBNPDB06dNasWRs2bHBwkQAAAJWJ\nQuly++afe5c926xXUrtnl9+88MtPi4cY9YVdXt6ozbux7vXqdx3lE1ovceZZ6+aBNS95+kc0\nfXLygTUvPqzCAUiOXYFw3759H374YVRUlBDi22+/bdq06fPPPy+EGDdu3MSJEx1bIAAAQOUj\ny89Oaz9yZfX6cUIIz9jw1P3d0s98L8xmV0//bq/tvOsYpaun9eOLv36RdmJTjzcPyBWqh1Qy\nqpaMjIy8vLx77b1+/boQIjMz89y5c/fq4+HhER4e7pDiUJHYFQhzc3OrV68uhDCZTLt27Xru\nuecs7UFBQVlZLHgFAABQnELpWr1eJ+ump18No05r0GuVLh5hDbuUPLYoP/vg5y837PJKUNRj\njq0SVdStW7eGDh1qNBpL7rZu3bp169bda69MJluxYkXNmjXLuzpULHYFwpCQkAsXLsTFxf3w\nww/Z2dlPPvmkpT0tLS0gIMCR5QEAAFRKrt6BQiazbspkCiGE2WzXI1uH1v9T6erRos9MRxWH\nqi4/P99oND7i5dE6wK9sMxzJUZ/J01TeBXtgP7sCYdeuXadOnXr+/Pl169bVqlWrffv2QojM\nzMx58+a1bdvWwRUCAABUIWZzYf6tu+6Ry5UuHr7Xfv8u9cDqJ8ammIVZX6QRQpiMBiGEvkgj\nlysVKucsSonKqJ6314vRZVyR6OPzl87kacq3HlRMdgXCd9999/fff3///feDgoK2bdtmeQPV\nK6+8cuXKlc8++8zBFQIAAFQdpS4qk3Z8ozCbd80v/jKANWO9I5r26PLKZsfXCNyf06dPT5w4\ncf/+/UajsVmzZu+9916bNm1KHpKZmRkREREcHHzp0iXb19u2bNnS9i0G/v7+zZs3nzlzZqtW\nrSwtQ4cOzcrK2r59u7Xz0aNHmzdvbh1iMBjCw8Nv3Lih1+ut70q91+Eg7AyE1atXP3DgQF5e\nnoeHh/XT+sYbb8ydOzc0NNSR5QEAAFQppS4q06jra1GPDbJtP7Xt/Rvn93Z5ZbOrp//DKBG4\nH0VFRV26dOnSpcuBAwcUCsW777775JNPXr161dvbu4RRS5Ysadeu3W+//bZ58+Zi70IcMWLE\nu+++a/n4xo0b//d//xcfH3/y5EnLCpfFBAcHL126dP78+daWrVu33vk6jRIOB3tfTC+EqFat\nmu1my5Yty7sYAACAKk6udCl5URnvoNreQbVtW1L3r5AplCF12jm4NKAs8vLyXnvttRdeeMGS\nAN96661Vq1ZduHAhJibmXkNMJtOiRYvefvvtEydOLFy4sFhC8/T0tK5uGh4evmrVKj8/vy1b\ntowbN+7OqRISEj777LM5c+a4uf11N/WyZcu6dOmydu1aOw8Hu15MDwAAAAB3CgoKeuONNyxp\nMDs7e+7cufXr169fv34JQ7Zu3ZqVlTVgwIBnn312x44dly5dKqGzQqFQKBQGg+Gue2NjYwMC\nAqzvRc/MzNy+fXu/fv3KfDgJuo8rhAAAALBH139uL9bS6pn5rZ6Zf9fOpWo7fEnb4UseuChI\nSEFBgRBi6/XMrdczH2Se3NxcO3sajUYPDw+dTtehQ4ddu3a5urqW0HnBggUDBgzw8vJq1qxZ\nTEzM4sWLZ82addeeGo3mnXfeKSgo6Nmz571mGzly5NKlS4cMGSKEWL16dVxcXI0aNcp2OGki\nEAIAAABVikqlEkIEuKiiPD3KNkOatvBGYZH1PsxSKRSK48ePZ2RkzJs3Ly4u7pdffvH19b1r\nz4sXL+7YsWPPnj2WzZEjR86cOXP69OmWmoUQixYtWrFiheXj/Pz8Ro0apaSkREdH3+vQI0aM\nmD59+oULF2rXrr18+fKkpKT7OhwIhAAAAECVYkk7jwf4vdXwnjmqZB+fv7TuSrr9gVAI0aBB\ngwYNGrRv3z40NHTNmjV3feRPCLFw4UKTydSjRw/LptFo1Gg0KSkp/fv3t7QMHDjQEury8vK6\ndOny0ksvJSQklHDcsLCwbt26LVu2rHfv3hkZGb179z569Kj9hwPPEAIAAAAoo127dkVHR+fn\n51s2FQqFTCYzm8137azT6ZYtW5aUlHT8v06dOvX0008vXLjQ2sfHxyc6Ojo6OrpFixYfffTR\nG2+8cfr06ZJrGDVq1JdffvnZZ58988wzLi4u93U42BUIVSqV1z14e3vXqFGjR48eP/zwg6Nr\nBQAAAFChxMbG5ufnjxgx4vTp0xcuXPjnP/+p0Wi6d+8uhFi6dOm8efNsO3/11VdqtXrcuHG1\nbLz88su7d+8+f/78nZMPHTr0ySefHDx4cFFRUQk19OzZU61Wr1mzZuTIkQ9yOGmyKxC++OKL\njRo1ys/Pj4yM7Nq1a7du3aKiovLz85s3b96rV6+GDRvu27evS5culhdEAgAAAJAIX1/fnTt3\narXa9u3bN2/e/PDhw1u2bKlTp44QYufOnZs2bbLt/OmnnyYmJgYGBto2dujQoV69eve6apec\nnJyRkTFp0qQSalAqlcOGDYuMjCz2rosyHE6C7HqG8Kmnntq4ceP+/ftbt25tbTxw4MDw4cPn\nzp0bGxurVqu7du06a9Ysyx8DAAAAAEhE48aNN2/efGf7unXrirXs3bv3rjOcOXPG8sHhw4eL\n7QoKCrpx44Z1c82aNdaPbTv/5z//sX7cqlUryz2rpR4Ows5AOGnSpJkzZ9qmQSFE69atJ0+e\n/Prrr//4448+Pj7jx49//vnnHVMkAAAAgPuzLyt71K8nyzb2RmFJt2iiKrErEP7+++8hISF3\ntoeFhf3666+Wjz08PGQyWXmWBgAAAOD+BQQEhIeHq9Xqa3df20UYDAatVuvm5nbPty+4ugX7\n+oWGhjquSFQQdgXCoKCgJUuWdOnSpVjkW7t2raenpxDCYDAsXLiwfv36DqkRAAAAgN08PT1X\nr15dQofvv/9+1qxZo0eP7tu370OrChWTXYFw1KhRM2bMOH36dHx8fPXq1WUy2c2bN3/88cdD\nhw69/PLLQogBAwZs27Zt7dq1Dq4WAAAAAFBu7AqESUlJSqVy/vz5H374obXRx8fnn//857//\n/W8hRMeOHfv37z9o0CBHlQkAAAAAKG92BUK5XD5t2rSpU6devnw5MzPTbDYHBARERUUpFApL\nh1dffdWRRQIAAAAoN5bHviz/D4mzKxBaZGdn//bbb9evX5fL5eHh4SEhId7e3o6rDAAAAIAj\ntGrV6pNPPqlXr56zC4Hz2RUITSbT66+//sknn+j1emujp6dnUlLShAkTHFYbAAAAgPInk8ka\nNmzo7CpQIdgVCD/44IO5c+cmJiYmJCSEhYWZzearV69u2LBh4sSJISEhw4YNc3SVAAAAAIBy\nZ1cgXL58+QsvvJCcnGzbOHr06EGDBs2bN49ACAAAAACVkdyeTn/++We/fv3ubB8yZMiZM2fK\nuyQAAAAADpSZmZmUlJSWlubsQuB8dgVCpVJ5+/btO9t1Op11oVEAAAAAlcKpU6f27Nlz5MgR\nZxcC57MrEDZv3nzevHk6nc62UavVzp07t0WLFo4pDAAAAIBDmM1m6/9D4ux6hnDKlCk9e/as\nU6dO9+7dw8PDdTpdWlra5s2bc3Nzt2/f7ugSAQAAAACOYFcgTEhI2LBhw5QpUxYtWmRtbNq0\n6erVq7t06eKw2gAAAACUxb59+3Jycu6117IOyG+//aZU3jMOeHl5derUSSaTOaQ+VBj2vpi+\nT58+ffr0SU9Pv3btmkwmi4iICAkJcWhlAAAAAMogIyNj2rRppXbbvXv37t27S+gQHh5ep06d\n8qsLFZG9gdAiLCwsLCzMQaUAAAAAeHCWtT/yI+VZLcp4fc/vlKlaqrnYGiKokkoKhPXr17dn\nirNnz5ZTMQAAAADKR2GgyHrMriUk7+R201wtlSVnJKGkL5FA+zy0WgEAAABUWCtWrJDJZCkp\nKaX2zMzMdHV1jYiIMBqNtu0tW7aU2QgICOjSpcvBgwetHYYOHdq9e3fbzseOHbOdwWAwhIaG\nymQyg8FQ6uFKduXKlRdffDEqKsrV1dXf379t27YrV64srxMRQly9enXMmDG1atVydXUNDQ3t\n1avX3r17bWcYN25cscO5ubklJyfbfwr2KCkQ7rNP+RYEAAAAoNK5cePG5MmT3d3d7em8ZMmS\ndu3a6XS6zZs3F9s1YsSItP/67rvvgoOD4+PjL168eNd5goODly5datuydetWk8lk/+GEEDk5\nOb/88kuxxtOnTzdv3nz//v3vvffeoUOHtm7dGhcXN3r06KlTp5bLiZw7d65FixZHjx798MMP\njx07tn79+oCAgLi4uK+//vquZ+o4JQXCkSNHarVaOyfSarWjRo0qj5IAAAAAVDJjx44dNmxY\ntWrVSu1pMpkWLVr0zDPPDBo0aOHChcX2enp6hv9XbGzsqlWrhBBbtmy561QJCQmfffZZYWGh\ntWXZsmXF3oNQ8uGEECdOnHjhhReKNY4ZMyYsLOzw4cODBg2KiYlp1arVzJkz165dq1KprIHz\nQU7kpZde8vPz27t3b9++fRs2bNixY8fly5dPnjz51KlTJX7yyl9JzxDu3r378ccf/+ijjzp1\n6lTyLHv37h03bpxarS7P0gAAAACUlbLA7HGtjM8BKjX3N3DDhg3Hjx9fvXq1JfaUbOvWrVlZ\nWQMGDGjRokVsbOylS5dq1ap1r84KhUKhUNje/2krNjZ27969GzZsGDJkiBAiMzNz+/btn332\n2dq1a8t2OIvr16/v3bt3zZo1KpXKtj0xMTExMfHBT+TmzZu7d+9eunSpq6urbZ+ZM2eWXJgj\nlBQIjxw5Mnjw4Li4uI4dOw4fPjw+Pj48PNy2w7Vr13bt2rVy5crdu3fHx8eXvGotAAAAgIcg\nLy9PCOFzxuxz5u45yk6ZmZmNGjUqtVtOTs64ceM+//xzO+8XXbBgwYABA7y8vJo1axYTE7N4\n8eJZs2bdtadGo3nnnXcKCgp69ux5r9lGjhy5dOlSSyBcvXp1XFxcjRo1ynY4qwsXLgghSj33\nMp/IhQsXzGZzkyZNSp2/2BOD9/UMpJ1KCoQBAQHbt2///PPP33nnnZEjRwohgoKCgoODfXx8\n1Gr1zZs3MzMzhRB16tRZs2bN4MGD5fIyrmIEAAAAoLx4eXkJIbShMnW9Mr52wvtPs+dVc0BA\ngD2dX3vttaeeeqrUmwotLl68uGPHjj179lg2R44cOXPmzOnTp1uvxS1atGjFihWWj/Pz8xs1\napSSkhIdHX2vCUeMGDF9+vQLFy7Url17+fLlSUlJdh5u165d/fr1E0IYDAatVuvr6yuEqFu3\n7qFDh1xcXCzt1nl8fX01Go3l4w0bNvTq1etBTsTS516XPa0GDRr05ptv2rbExsaWPKQMSnkP\noVwuHzp06ODBg/fv379jx44TJ07cvHkzOzvb19e3du3aMTEx3bp1a926tUKhKPfKAAAAAJSB\n5TpNQQ3Zte5l/C09fIvR86rZnl/yd+7c+cMPP5w8edLOmRcuXGgymXr06GHZNBqNGo0mJSWl\nf//+lpaBAwdaQl1eXl6XLl1eeumlhISEEiYMCwvr1q3bsmXLevfunZGR0bt376NHj9pzuDZt\n2hw/flwIcfDgwRkzZmzdulX8N6o98sgjCoXi2LFjLVu2tAw8cOCA5epcmzZtLM8QPsiJREVF\nKRSKI0eOtGrVyvZcjEajXC6Xyf6K8f7+/o0bN7btYN1Vjux6Mb1CoWjfvn379u3L/fAAAAAA\nKq9ly5bduHGjdu3als3s7Oxhw4bFx8ffdbVMnU63bNmypKSkESNGWBsnTJiwcOFCa47y8fGx\nXg/86KOPRo8e3alTp4YNG5ZQw6hRoyZNmqTRaJ555hnLxT17Dufu7m555O/SpUsuLi62j//5\n+/v36NFj1qxZQ4YM8fT0FEI0aNBACGFdTuYBT8TPz6979+7vvffeP/7xD9tleN5+++2DBw/u\n2rWrhJMtd3YFQgAAAAC40yeffDJ79mzrZosWLd57773evXsLIZYuXarRaF599VXr3q+++kqt\nVo8bN872ZeYvv/xyp06dzp8/X6dOnWKTDx069Jtvvhk8ePChQ4eKrb9iq2fPnmPGjFmzZk2x\nKHW/h7O1YMGC1q1bt2nTZurUqTExMUVFRUePHl2wYIGPj0/jxo0f/ETmA4cBVAAAIABJREFU\nz59vmX/atGlNmjTJyspatmzZF198Yc9bHMsXT/0BAAAAKCN/f/9wG3K5PCAgwBKTdu7cuWnT\nJtvOn376aWJiom2IEkJ06NChXr16d30hhBAiOTk5IyNj0qRJJdSgVCqHDRsWGRkZExNThsN1\n6tTJcu+orRo1ahw/frx79+6WQNi2bdtPPvmkT58+v/32W3R09IOfSK1atY4dO9a5c+cpU6a0\naNFiwIABWq32wIEDXbt2LeFMHUFmNpdxLdpKQa1W6/V6Z1cB5/D39zebzTk5Oc4uBKgi3Nzc\nvLy8NBqN7eueIHHJyckpKSnRiSs8QhqX3hsoV4XZf55bP7B79+7jx493di1lpFKpfHx8ynfO\n27dvCyGuXLkyfPjwW7HyS0+X/RnCkH2m+fPnW1ba9Pb2Ls8qUZFwyygAAABQpViWHgk4Ygo4\nYnJ2LajoCIQAAABAlRISEtK5c2e1Wn2vDrdu3bp06VJERERwcPC9+nh4eERFRTmmQFQgBEIA\nAACgSnFxcZk2bVoJHb7//vtZs2b17du3b9++D60qVEwsKgMAAAAAEkUgBAAAAACJIhACAAAA\n0hISEiKXy0NDQ51dCJyPZwgBAAAAaWnSpMnWrVtLeNU7pOM+rhBqtdp9+/atX78+KytLCGEw\nGBxWFQAAAAAHIg3Cwt5AOHv27NDQ0Pbt2w8aNCg1NVUIkZSUNHLkSKPR6MjyAAAAAACOYlcg\nXLJkycSJEzt16pScnGxtrFev3urVq2fPnu2w2gAAAAAADmRXIJw/f/6YMWO+/fbb4cOHWxuH\nDRs2YcKE1atXO6w2AAAAAOXvzz//HDRo0KlTp5xdCJzPrkB49uzZfv363dnesWPHixcvlndJ\nAAAAABzo4sWLN27csDwIBomzKxCqVCqtVntn+40bN1QqVXmXBAAAAAB4GOwKhI899tjcuXOL\niopsG3Nzc2fPnt2qVSvHFAYAAAAAcCy73kOYlJT0xBNPNGzYsFu3bkKIRYsWJScnp6SkFBQU\n2C4zAwAAJEiff1OXd83ZVUBy9Jobzi6h4jKZTCtWrMjNzb1Xh2vXrgkhdu/eXcLzX56ens8+\n+6yLi4tDSkSFYVcg/P/27jwgqur///iZGWXfBFRkUUHcQ8Rd01RcPpql4lJuuaJi5VK5YC64\nRGpogJmWmqItrp8yXHBJ8qP1pY+7pqaBJJAIiGwiiwwzvz/ut/nxZRlHFEe5z8dfM2fOvfd9\n7U7M655z733llVeOHDkyZ86cDRs2CCG2bt0qhOjQocMnn3zy8ssvV22BAADgeaVQKIQQCUfm\nGLsQyJd0EKKU5ORkQ279eOXKlStXrujp0K1btxYtWjy9uvA8MigQCiF8fX3PnTuXnp6elJSk\nUCgaNGhQq1atKq0MAAA853r37p2ZmclDiSvt7NmzxcXFHTt2NHYhL6qaNWtK89dQikajEULY\nevjW6zyzcmtIPfdV5vVIrVb7VOuqQrdu3XJ3d//999+bNWtWs2bNY8eO9e7d29hFVYZarX7G\n9RsaCPPy8rKzs+vVq+fo6FhQULBr1667d+8OHDiwSZMmVVofAAB4bjVq1CgwMNDYVbzAJk2a\nlJ+fv2DBAmMXgupJZWJpYuNSyWVNrQ3v7O3tffnyZd1bS0vL3Nxc/YskJiauWLHi8OHDycnJ\nlpaWzZs3nzJlSslH3FWaSqX6+eefvb29K7FsdHS0jY1Nu3btSrW3a9fu3Llz0mtbW9vGjRvP\nmjVr9OjRT1preZt+kvorx9DHTri7u2/btk0IoVarfX19x48fP2fOHG9vb90/DQAAAAAZysjI\nWLt2bdI//vzzT/39r1275uPj8z//8z8rVqw4ffr0oUOHevbsOWXKlIULF5bqWVRU9LjFKBSK\nHj16VG4y46effnr27NlyPxo/fry0d7/++quvr+9bb7115syZSmzikZt+kvorx6BAuGDBAicn\npzfffFMIsWvXrpiYmI0bN968edPHxyc4OLiKKwQAAADw/MrIyGjUqJHrP5ydnfX3DwgIcHZ2\nPnv27IgRI7y9vTt16vTRRx/t2LGjZs2aGo2mqKhIoVBs3brV3d194sSJQohr16717du3Vq1a\ndnZ2//rXv3SPT7x48WLHjh0tLS1btWr122+/SY1qtVqhUPz0009CiNTU1DfffNPOzs7BwaFv\n375Xr14VQmi1WoVCsXv37r59+3p6ejZo0GD79u1CCF9f30OHDs2aNatt27Zla7a0tJT2rmXL\nlsHBwQqF4tq1a9JHqampI0eOdHZ2dnBw6NWrl26wtKL2iIiI5s2bm5ubOzk5vf322wUFBSU3\nrau/ojqFEBcuXOjUqZOVlVXbtm2jo6MVCsWFCxcq/Z/PoED4yy+/zJs3z93dXQjx448/tmrV\navLkyR4eHu++++7p06crvW0AAAAAL7TCwsK8vLzvv/++VatW9evXHzx4cGxsrJ7+d+7cOXXq\nVGBgYKnnmQ8ZMiQoKEipVNasWVOhUGzYsOGHH374/PPPhRDDhw93cnJKTExMTEy0srKSZpZq\nNBo/P79mzZqlpqbu379fuvllKdKszvj4+L///rtDhw69e/fOy8tTKBQqlWrlypVbt26Ni4ub\nO3futGnTHjx4EB0dXb9+/bCwMP1TIB8+fLhhwwYbGxvdNX6DBg3Kycm5cOFCQkJC69atu3fv\nfu/evYra4+PjJ06cuG7dutzc3NOnT585cyY0NLTcTVdUZ2FhYf/+/Zs3b56SkrJjxw5p3v6T\nPBzeoGsIs7Ky6tWrJ4TQaDTHjx/39/eX2mvXrp2enq5nwdzc3I0bN545c0atVr/00kvTpk2r\nU6eO4X1u374dGhoaFxe3b9++x1onAAAAIHMFWQn3rn1fyWXvxQohDLmpTE5OTt26dXNycr78\n8kuVSrVkyZJXXnnljz/+sLOzK7d/fHy8EKJly5Z61qlUKgcOHNi6dWvp7cmTJ83MzCwtLYUQ\no0aNGjlypFar/e23327duvXTTz9ZWVlZWVm99957J0+eLLmSq1evHj9+PCUlxd7eXgixbNmy\nzz///MCBA2+88YYQYuzYsS4uLkKI11577d13371165b+kjZu3BgRESGEyMvLs7e33759u7T4\nhQsX/vvf/165cqVu3bpCiOXLl2/YsCEyMrJ169bltjdv3lyr1daqVUulUtWvX/+3335TqVR6\ntlu2zrt376ampgYFBVlZWTVp0mT69Oljx47Vs4ZHMigQ1q1bNz4+vmfPnj///HNGRkb//v2l\n9qSkJAcHBz0LhoWFpaenL1++3MzMLCIiYtmyZWvXrlUqlYb0OXXq1ObNm318fHSDwoavEwAA\nAJCtnJwcIUReyuW8lMuP7KxHamrqSy+9pL9P7dq1U1JSdG93797t7Oy8Z8+eyZMnl9tferCh\nWq3WtdjZ2eluQvP9998PHDhQCNG4cWNdhwsXLqxcuTI+Pl6j0eTn5xcVFRUXF0vPPmjYsKHU\np+ytLqWBSicnp5KNUhwVQjRo0EB6YWpqKoTIz8/Xv5tvvvlmUFCQECIvL+/MmTMTJkwIDg6e\nOnXqzZs3FQpF06ZNpW4WFhYuLi43b960trYut338+PHvvPNOx44dpRHLkSNHNmvWTM92y9aZ\nmJioUql07U9+m2KDAmHfvn0XLlwYGxu7c+fOhg0bduvWTQiRlpYWHh6u5zmE6enpp0+fDgsL\n8/DwEELMmjXrrbfeunTpko+PjyF9ioqKVq9effPmzRMnTjzWOgEAAAA5s7GxEUJYubR1aDm8\ncmvIuHHwfsKpUmnKEFZWVm5ubn///XdFHRo1aqRSqS5cuKC7mWdMTIz09JouXbpID8wQ/+Qf\nIURCQsJrr70WFBR06NAhExOTyMjIQYMGCSEKCwtLrrZkwpRIz6jMy8szNzcvW8bjPsHS1tbW\n09NTet2qVau0tLTFixdPnTpVaik5lCpd+1dRu0KhWLdu3bx58w4ePHjgwIEVK1Z888030qBl\nucrWWXL9ldiRsgwKhMuXL7969eqqVatq164dFRUlDWvOmDEjMTHx22+/rWip2NhYExMT6cpD\n8c/BERsbWzK86enj6+srhLh58+bjrhMAAACAibWzbaNKPsvuQerv9xMM6nnlypXw8PB169ZJ\nEe7+/fu3bt3SZaey7O3tBwwYEBwcPGrUKGkWaPPmzcU/z04s68yZM8XFxYGBgVLy0d0F1NXV\nVavVJiYmStFAumFMSdIY48WLFzt37iy1xMfHS6NKT06r1UoRtHHjxlqt9vr1615eXkKI3Nzc\n27dvN27cuKJ2tVqdmZnp5uYWEBAQEBAwa9as9evX6wmEZTk7O6vV6tu3b7u6ugohnvyWLgYF\nwnr16sXExOTk5FhYWNSo8b+LzJ49OywsTM9pg5ycHGmoVNdia2ubnZ39uH0eq39iYuLPP/+s\ne/vKK69whaFsScdJueeEAFSC9P9/6Vp/Y9cCVCv8qZKt6vG/U2dn5++///7hw4dBQUFFRUXz\n5893dHQcMmSIEOKrr77Kzc2dOXNmqUXWr1/fuXPnLl26LFy40Nvbu7Cw8Pz58+vXr7e1tS07\nQ9XV1VWtVp86dapr1667du2Kjo4WQiQnJ3fu3NnBwWHp0qWhoaEpKSnr1q0rtWCLFi18fX1n\nz569c+dOJyenzZs3z549++bNm3ryi4WFRVxc3L1798peFvfgwQNp2LOgoODcuXOhoaHSIxi8\nvb27dOkSGBgYERFhamo6f/58GxubwYMH29jYlNu+bdu2JUuW7Nu3z8fH5+7du1euXGnUqFHJ\nTdva2ur/B+/SpYutre3HH3+8evXqv//+u9y76TwWQx9ML4SwtLR88OCBLrtLuT8rK6uiC0ZF\nmaO83MtSDeljeP+bN29+9tlnurfNmzfXDSdChhQKhXTmCcDTYmpqqpvGA+Cp4E+VbJWd5fgi\nsre3P3r06Lx583x8fExNTbt27XrixAnpqD527Fh6enrZQOji4nLx4sVVq1YtXLgwMTGxZs2a\nzZo18/Pze/vtt8vGoU6dOs2ZM2fw4MFKpdLPz2///v29evVq167d6dOnDx48+Pbbbzs7Ozdu\n3HjVqlWvvvpqqecWfvvttzNnzvTy8lKr1a1atYqKitI/CXbq1KkffvjhDz/8UGqWohAiIiJC\nuqmMqalpgwYNpk+fPm/ePOmjnTt3Tp8+3cPDw9TUtGPHjqdOnZKm7JbbPnHixNu3bw8bNuzO\nnTt2dnb9+/dfs2ZNyU3fuHFD/z+4paXlvn37pk+fXrt2bR8fn6CgoL59+z7JHVUMCoSxsbH+\n/v4xMTHlPhqyoghnZ2eXk5NTcpJrdnZ2qWcsGtLnsfp7e3uvX79e99bNzU3PeCOqNxsbG61W\ne//+fWMXAlQTJiYm5ubm+fn5Dx8+NHYtQLXCbxXZUqlUVlZWxq7iKWjbtq303L9Sdu7cWdEi\n9vb2q1atWrVqVbmflorKn3zyySeffKJ7e/78eelFw4YNSz6nQZdKdC+cnJx27dqlf/1OTk66\n/jNnziwbX0WJearlcnNzK/lMBP3tCoVi8eLFixcvLtVectO6eiqqs2vXrufOnZNuzyM9gFGa\nPlo5BgXCqVOnXrhwYdiwYc7Ozropo4/UpEmToqKiuLg4af5udnZ2UlJSqbvoGNLnsfrb29t3\n6NBB9zY7O7vcEAs50Gq1Wq2WAwB4WqQLyIuLi/laAU8X3ylUEXV+Vv7dPyq3bHF+xtMtBk+L\nVqtt2bJlly5dQkND8/Pzly5d2qNHD2lMsnIMSnenT5/es2eP7mkTBqpVq9bLL7/82WefzZgx\nw9TUdPPmzZ6entLzPY4dO1ZQUPD666/r6ZOZmVlcXCwN70hPO7SystLTHwAAAIAQQppAmJNw\nKifh1JOsR/8j8mAUCoVi7969M2bMcHV1NTc379Gjx+bNm59ohYY8btLJyenkyZNlH+7xSHl5\neZs2bYqJidFoND4+PgEBAdL0zpCQkJycnOXLl+vp4+/vn5aWVnJt/v7+AwcOrKh/uRghlDN7\ne3utVpuZmWnsQoBqwszMzMrKKjc3t6CgwNi1ANXEpEmT8vPzv/vuO2MXAuOoWbPmI+8g8rik\n0RSNRrNnzx49s5Fv3boVExPTtm1bPb/wLSwsRowYIU0PtLa2frp14vlhUCCcN2+eUqlcsWLF\nMyjo6SIQyhmBEHi6CITAU0cglLmqC4SP9NNPPwUHB8+YMcPPz8+Q/gTCasygKaPBwcFDhw7t\n3Llz165dy96DNTAwsAoKAwAAAABULYMCYVhYWGRkpPjnJjalEAgBAAAA4EVkUCAMDQ3t379/\nYGDgY91lFAAAAMBzqHHjxo0aNWrevLmxC4HxGZTu7t27t2bNGo4YAAAAoBpo0KDBE96aEtWG\nQY+09/LyunfvXlWXAgAAAAB4lgwaIVy3bt28efPWrFnTtm3bqi4IAAAAQOVwO1A8LoMC4ezZ\nsxMTE9u1a2dlZVX2LqO3bt16+nUBAAAAAKqYQYFQqVR6eno2bty4qqsBAAAAADwzBgXC//zn\nP1VdBwAAAADgGXv0TWUePnzYvn37AwcOPINqAAAAAADPzKMDoYmJSXJyclxc3DOoBgAAAADw\nzBj02Ikvv/xy8+bNP/zwg1qtruqCAAAAAADPhkHXEIaEhKhUqiFDhtSoUaN27domJiYlP+Uu\nowAAAADwIjIoEKrV6lq1avXq1auqqwEAAAAAPDMGBcJff/21qusAAAAAADxjBl1DCAAAAACo\nfgiEAAAAACBTBEIAAAAAkCkCIQAAAADIFIEQAAAAAGSKQAgAAAAAMkUgBAAAAACZIhACAAAA\ngEwRCAEAAABApgiEAAAAACBTBEIAAAAAkCkCIQAAAADIFIEQAAAAAGSKQAgAAAAAMkUgBAAA\nAACZIhACAAAAgEwRCAEAAABApgiEAAAAACBTBEIAAAAAkCkCIQAAAADIFIEQAAAAAGSKQAgA\nAAAAMkUgBAAAAACZIhACAAAAgEwRCAEAAABApgiEAAAAACBTBEIAAAAAkCkCIQAAAADIFIEQ\nAAAAAGSKQAgAAAAAMkUgBAAAAACZIhACAAAAgEwRCAEAAABApgiEAAAAACBTBEIAAAAAkCkC\nIQAAAADIFIEQAAAAAGSKQAgAAAAAMkUgBAAAAACZIhACAAAAgEwRCAEAAABApgiEAAAAACBT\nBEIAAAAAkCkCIQAAAADIFIEQAAAAAGSKQAgAAAAAMkUgBAAAAACZIhACAAAAgEwRCAEAAABA\npgiEAAAAACBTBEIAAAAAkCkCIQAAAADIFIEQAAAAAGSKQAgAAAAAMkUgBAAAAACZIhACAAAA\ngEwRCAEAAABApgiEAAAAACBTBEIAAAAAkCkCIQAAAADIVA1jF1C1zM3NLS0tjV0FjEOpVGq1\nWjs7O2MXAlQTSqVSCGFhYWFmZmbsWoBqhT9VsqXRaIxdAlDdA2FhYaFarTZ2FTAOOzs7rVZ7\n//59YxcCVBOmpqYWFhYFBQWFhYXGrgWoVvhTJVsqlcrExMTYVUDuqnkg1Gg0xcXFxq4CxqHV\narVaLQcA8LRIZ7L5/yrw1PGdki1p5gVgXByFAAAAACBTBEIAAAAAkCkCIQAAAADIFIEQAAAA\nAGSKQAgAAAAAMkUgBAAAAACZIhACAAAAgEwRCAEAAABApgiEAAAAACBTBEIAAAAAkCkCIQAA\nAADIFIEQAAAAAGSKQAgAAAAAMkUgBAAAAACZIhACAAAAgEwRCAEAAABApgiEAAAAACBTBEIA\nAAAAkCkCIQAAAADIFIEQAAAAAGSKQAgAAAAAMkUgBAAAAACZIhACAAAAgEwRCAEAAABApgiE\nAAAAACBTBEIAAAAAkCkCIQAAAADIFIEQAAAAAGSKQAgAAAAAMkUgBAAAAACZIhACAAAAgEwR\nCAEAAABApgiEAAAAACBTBEIAAAAAkCkCIQAAAADIFIEQAAAAAGSKQAgAAAAAMkUgBAAAAACZ\nIhACAAAAgEwRCAEAAABApgiEAAAAACBTBEIAAAAAkCkCIQAAAADIFIEQAAAAAGSKQAgAAAAA\nMkUgBAAAAACZIhACAAAAgEwRCAEAAABApgiEAAAAACBTBEIAAAAAkCkCIQAAAADIFIEQAAAA\nAGSKQAgAAAAAMkUgBAAAAACZIhACAAAAgEwRCAEAAABApgiEAAAAACBTBEIAAAAAkCkCIQAA\nAADIFIEQAAAAAGSKQAgAAAAAMkUgBAAAAACZIhACAAAAgEwRCAEAAABApgiEAAAAACBTBEIA\nAAAAkCkCIQAAAADIFIEQAAAAAGSKQAgAAAAAMkUgBAAAAACZIhACAAAAgEwRCAEAAABApgiE\nAAAAACBTBEIAAAAAkKkaVbr23NzcjRs3njlzRq1Wv/TSS9OmTatTp46BfSpqT0pK2rp16/Xr\n1zUajbu7+7hx45o1a1alewEAAAAA1VLVjhCGhYUlJiYuX748NDRUpVItW7ZMo9EY2Kfc9qKi\nooULF1pbW4eEhISGhtatW3fJkiX5+flVuhcAAAAAUC1VYSBMT08/ffr0jBkzPD09XV1dZ82a\ndfv27UuXLhnSp6L2vLy8wYMHBwQEuLi41KtXb/jw4Xl5eSkpKVW3FwAAAABQXVVhIIyNjTUx\nMXF3d5feWllZubm5xcbGGtKnonZbW1s/Pz9zc3MhxP379yMjI11dXV1dXatuLwAAAACguqrC\nawhzcnKsra0VCoWuxdbWNjs725A+tra2epbVaDTDhg1Tq9UtW7b86KOPatasqev2yy+/LF68\nWPc2JCSkTZs2T33X8EKQjh8HBwdjFwJUK5aWlpaWlsauAqhW+FMlW2q12tglAFV8U5mSiU4I\nodVqDe+jZ1mlUhkeHp6VlRUZGblgwYLVq1frfp3UqFHD2tpa11OlUpW9ahEyoVKphBAcAMDT\nolAoFAqFVqst93/mACqNP1UAjKgKA6GdnV1OTo5Wq9VFu+zs7Fq1ahnS55HLurm5ubm5tWjR\nYuzYsSdOnBgwYIDU3qlTpx9//FHXLTs7OzMzs+r2Ec8ze3t7rVbLAQA8LWZmZlZWVnl5eQUF\nBcauBahW+FMlWzVr1rS1tTV2FZC7KryGsEmTJkVFRXFxcdLb7OzspKSkUo+IqKhPRe2XLl2a\nMmWK7reIUqmUTldX3V4AAAAAQHVVhYGwVq1aL7/88meffRYXF5eUlPTpp596enq2bNlSCHHs\n2LH9+/fr6VNRu6enZ2FhYXh4eFJSUkpKyubNmwsKCrhKEAAAAAAqoWqH1/Ly8jZt2hQTE6PR\naHx8fAICAqRpnyEhITk5OcuXL9fTp6L2hISEbdu23bhxo7i4uEGDBqNHj27VqlVFBWRnZxcV\nFVXdDuJ5xpRR4OmSpozm5uYyZRR4WiZNmpSfn//dd98ZuxAYB1NG8Tyo5vMtCYRyRiAEni4C\nIfDUEQhljkCI50EVThkFAAAAADzPCIQAAAAAIFMEQgAAAACQKQIhAAAAAMgUgRAAAAAAZIpA\nCAAAAAAyRSAEAAAAAJkiEAIAAACATBEIAQAAAECmCIQAAAAAIFMEQgAAAACQKQIhAAAAAMgU\ngRAAAAAAZIpACAAAAAAyRSAEAAAAAJkiEAIAAACATBEIAQAAAECmCIQAAAAAIFMEQgAAAACQ\nKQIhAAAAAMgUgRAAAAAAZIpACAAAAAAyRSAEAAAAAJkiEAIAAACATBEIAQAAAECmCIQAAAAA\nIFMEQgAAAACQKQIhAAAAAMgUgRAAAAAAZIpACAAAAAAyVcPYBQAAAMiUpaWlSqUydhUAZI1A\nCAAAYBxff/21QqHIyMgwdiEA5IspowAAAAAgUwRCAAAAAJApAiEAAAAAyBSBEAAAAABkikAI\nAAAAADJFIAQAAAAAmSIQAgAAAIBMEQgBAAAAQKYIhAAAAAAgUwRCAAAAAJApAiEAAAAAyBSB\nEAAAAABkikAIAAAAADJFIAQAAAAAmSIQAgAAAIBMEQgBAAAAQKYIhAAAAAAgUwRCAAAAAJAp\nAiEAAAAAyBSBEAAAAABkikAIAAAAADJFIAQAAAAAmSIQAgAAAIBMKbRarbFrAKpEaGiomZnZ\ntGnTjF0IUE1cvHjx0KFDAwYM8Pb2NnYtQDWxfv36hw8fzpo1y9iFAJAvRghRbR08ePDo0aPG\nrgKoPv7666/vv//+1q1bxi4EqD6OHDly6NAhY1cBQNYIhAAAAAAgUwRCAAAAAJApAiEAAAAA\nyBQ3lQEAAAAAmWKEEAAAAABkikAIAAAAADJFIAQAAHgiaWlpAwcOTEhIKC4uHjhw4KVLl4xd\nUSW96PUDqIQaxi4AEElJSVu3br1+/bpGo3F3dx83blyzZs30L5KdnT1hwgQ7O7vNmzcrlf//\nvMb7778fFxene2ttbe3h4TFmzJimTZtKLZ9++mlOTs6SJUt0ncPCwjw8PHSLFBcXT5gwISsr\n64cfflCpVPo3Bzy548ePh4eHf/jhh506ddLf84U47O/evbt3795z585lZGSYmZm5urr269fP\n19f3qeyIECI9PX337t3nz5/PyMiwsrJq0qSJn59fy5YtdWto2rTp1KlTS25u6NCh/v7+/fv3\nN3AX8MKZMWNGycdjmpmZ7d69W/8ihhyolaNUKoODg93d3Sux7OXLly0sLDw9PUu1l/xqWFhY\nODs7Dxw4sEePHk9YarmbfpL6AbygCIQwsqKiooULF7Zu3TokJESpVO7atWvJkiVbt241NzfX\ns9TRo0dbtGiRkJBw5syZjh07lvyoV69eo0ePll5nZWXt27dv0aJFn332Wd26dcuux9bW9tix\nYyV/Pp47d67snZb0bA54EllZWdu2bTMxMTGk83N12Ofm5iYnJzdp0qRkY1JSUmBgoIODw7hx\n41xdXR8+fHjmzJl169YlJyePGTPmyXfk9u3bgYGBderUmTRpkqura3Z29vHjxxcsWDB37twu\nXboY8E+I6ik3N3fKlCm6UyqPPH9h4IEqhCguLtadIjGQQqHw8vLbsD6UAAASfklEQVR6rEV0\n9u3b1759+7KBUJT4auTl5UVHR4eGhrq4uDRu3LhyG9Kz6SepH8ALikAII8vLyxs8eHC/fv2k\nBDh8+PDo6OiUlBQ9pye1Wu2RI0dGjBjx119/HT58uNQPSjMzM0dHR+m1o6Pje++9N3LkyLNn\nzw4YMKDsqtq1a3fixIkJEybofpEfO3bM29v75MmTBm4OeBJffPGFr69vdHT0I3s+b4f9X3/9\ntXnz5vDw8JKN69evt7e3Dw0N1f2Gbtq0aaNGjW7duqXVahUKxRPuyBdffGFlZbVy5cqaNWsK\nIdzc3F566SUHB4eEhAQCoZzdv3/fyclJd+Q8kv4DVaPR+Pn5zZgxY+fOnS1atHj//feTkpI2\nbdoUGxur1WqbNm0aEBBQr149IUR8fPz69esTEhKcnJzeeOMNaVXFxcV+fn7Lly/39vbOysra\nuHHj+fPnVSpVo0aN/P3969evr9VqBw0aNHfu3KNHj6akpBQXF48ePdrX13fBggVXrly5dOnS\n0aNHQ0NDS9Vc8qvx1ltv/fDDD0lJSVIgzMrK2rRp05UrV9Rqtbu7u7+/f8OGDfW0Hz9+/N//\n/ndaWpqFhUXnzp0nTZq0dOlS3aZXr14t1d+qVaty69TteGJioouLy4QJExYuXFhq0gGAFwuT\n32Bktra2fn5+Uhq8f/9+ZGSkq6urq6urnkXOnj2bk5PTtWvXXr16nT9/Pi0tTU9npVKpVCqL\ni4vL/dTT09Pa2jomJkZ6m52dff78+VK/LB9rc4DhYmJi4uPjR40aZUjn5/+wz8zMvHr16tCh\nQ0uNqHTu3HnkyJFSGnySHcnOzr58+fLQoUOlNKgzZsyYkSNHPrI8VFdFRUWFhYUxMTHTp0+f\nOHFicHBwcnKynv6PPFBVKpVCoYiKivrwww8DAgKEECtXrqxVq9aWLVu2bNliZmYmpTWtVvvx\nxx+7urp+/fXXixYtOnToUNltrVmzRgixadOmrVu3NmnSZNGiRYWFhQqFQqlU7t27d+bMmRs3\nbhwyZMiGDRsKCgqCg4Nr167t7+9fNg2WpFaro6KiLCwsvL29pZaPPvooPz8/PDz8q6++8vDw\nmD9//v379ytqT0lJWbt27dSpU3fv3r1mzZrY2NjIyMhyN11RnUVFRUuWLHFzc9u+ffvs2bO3\nbdsmhHjccVQAzxUCIZ4LGo1myJAho0ePTkxM/Oijj0r94Cvl0KFDXbt2NTMz8/DwcHd3P3Lk\nSEU9CwoKIiIiCgsL27dvX1GfPn36HDt2THr9888/e3l5OTg4VG5zgOFyc3O/+OKL6dOnGzhf\n9Pk/7FNSUoQQ9evXr6IdSU1N1Wq10hCH/vUP/r+KiooeWTxeXHl5eXZ2dnl5ee+8805gYKBa\nrZ4/f/6DBw8q6m/IgapQKDp06ODh4WFhYSGEWLly5bRp08zNzS0sLLp37y4NFd64cSMtLW3E\niBFmZmZ16tQZNGhQqZUkJiZeunRpypQp1tbWJiYmo0ePluamSp/6+vpKX7r27dsXFhY+8pzL\n4cOH33jjjTfeeGPo0KE7dux47733pMXj4+P//PPP8ePH29nZmZmZjR49uqio6L///W9F7dnZ\n2Vqt1srKSqlU1q5de/Xq1cOGDdOz3bJ1Xr9+PSsra+TIkWZmZi4uLq+99pr+ygE8/5gyiueC\nUqkMDw/PysqKjIxcsGDB6tWrLS0ty+2Zmpp6/vz5lStXSm/79Omza9euUaNG6U5PHj58+Pjx\n49LrgoKC+vXrL1iwQJreU65evXp99913KSkpTk5OP/30U6mhhkduDqicr776qkOHDgZeq/P8\nHPaXLl1asWKFEEKj0RQWFo4YMUII4eLismbNmho1akjtuvWMGDGioKBAev3hhx926NDhSXZE\n6lPRsKdOt27dhg8fXrLlvffe078IXmi2trbbt2/XvZ03b964ceN++eWXf/3rX+X2N+RAFUI4\nOzvrOsTHx+/duzclJUWr1RYWFhYXF2s0mrt37yoUijp16kh9XFxcSm1IGqgcO3ZsyUYpjgoh\nateuLb2QToA+fPhQ/25269ZN+p4WFhbGxsaGh4e/9dZb/fr1u3PnjkKh0G3d1NTUwcEhJSXF\n3Ny83PZevXoNGDBg9uzZjRs3bt269SuvvKJ/Sk7ZOu/evSuFSam91IXEAF5EBEI8L9zc3Nzc\n3Fq0aDF27NgTJ06Ue+2TEOLw4cNarXbp0qXSW41GU1BQ8Ntvv7388stSi+6vZl5e3qJFi159\n9dV27drp2a69vX2bNm1++umnjh07ZmZmduzY8ebNm4ZvDqiEixcv/v7772vXrjWw//Nz2Ddv\n3lwq+8aNGzt37gwKChL/RDUnJyelUnnz5k3dLTFCQkKkn91z586VXjzJjtStW1epVMbFxZW8\n6ai0EoVCoZuSam1t3aBBg5IddB9BDqRr7e7du1dRB0MOVPFP/hFCpKWlLVu2bOTIkUFBQTVq\n1Dh9+vRHH30khCg18lz2VIV04O3du7fcWQCPe1haWlrqTvE0bNgwOzv722+/7devX9meuut1\ny21XKBRTp04dOnTomTNnzpw5s2fPng8++KBr164VbbfcVZVs5PsFVAMEQhjZpUuXPv/887Vr\n15qZmQkhlEqlQqEoe8NDiVqtlkYzevXqpWvcunXr4cOHdT8oS/7VnDJlyrp167y8vNzc3PTU\n0KdPn23btuXn5/fo0UM6eWz45oBKOHbsWFZW1uTJk6W3ubm5oaGhrVu3nj9/ftnOz9Vhb2Ji\nIg2JpKam1qhRQzc8IoSwtrZu167dnj17unfvLn2dpQJ0X+cn3BErK6s2bdrs3bu3Z8+e0kQ+\nybfffnvjxg3pNzpkKCEhYf/+/VOnTpUiXH5+flpamp7h8UceqKXExsZqNJqhQ4dKySc2NlZq\nd3R01Gq1d+/elW6Bm5iYWGpBaYwxPj5e9yAlaUz+yXb3f0k3v5G2otVq//77b+k8SEFBQUZG\nRr169SpqLy4uzs3NdXR07N+/f//+/Tdt2iTN4jZ80/b29sXFxffu3ZNucvPnn38+lT0CYERc\nQwgj8/T0LCwsDA8PT0pKSklJ2bx5c0FBQZs2bYQQx44d279/f8nOv/7664MHDwYMGFCnhNde\ne+3y5cvl3kWgR48ebdu2DQkJ0X8RUfv27R88eHDixInevXs/yeYAAwUEBHzxxRfh/7CxsfH3\n93/nnXfEC37YT5s2TaPRzJ0799dff719+3ZCQkJ0dPScOXMsLS0bNGjw5DsSEBAgrf/UqVNJ\nSUlXr14NCwv78ccfhw4dqr8wVGP29vYxMTGff/55SkrK7du3w8LCbGxsOnfuLMr7Nkn0H6il\nOjs6OhYXF1+7dk2r1Z48efLy5ctCiIyMjGbNmllbW+/YsSM3NzcpKenAgQOlFnRzc2vVqtWW\nLVvS09OLi4ujoqKmT5+emZmpZ19MTU3v3Lkj3RKmlIKCgvT09PT09Dt37pw6derHH3+UUpy7\nu3uzZs22bduWnZ2dl5cXERFhbm7eqVOnitqjo6Pfe++9uLg4rVablZWVmJgoZVQ9my6lWbNm\nFhYWe/bsKSwsvH37dlRU1CMXAfCcIxDCyCwtLZctW1ZYWBgYGDhr1qy4uLjFixdLJ1YvXrx4\n+vTpkp2joqI6d+5sY2NTsrFly5YuLi6HDx8ud/1vv/12ZmZmRESEnhpUKpWvr2+dOnVKPeui\nEpsDDGFtbe1YgkKhsLa2lo60F+Ww9/LyKvXMCSGEg4NDeHh4mzZtvvnmm5kzZ86dO/fgwYOd\nOnVat25dvXr1nnxH6tSpExYW1qpVq+3bt8+aNWvVqlUPHz4MCQnx8fHRs6eo3qytrZcuXXrv\n3r1Zs2YFBgYKIT7++GNp6K/st0mi/0At1blp06ZDhgwJDg4eM2bM5cuXFy1a5OHh8f7772dl\nZQUFBSUkJIwfP/6TTz558803RZmJox988IGjo+O77747cuTIn3/+ecmSJbVq1dKzL/369YuK\nivrggw/KfnT8+PGJEydOnDjx3Xff/e6771577TV/f3/po7lz56pUqsmTJ0+ePDktLW3lypXS\nEHq57b179+7bt+/KlSuHDRs2Y8YMR0fHSZMm6d90KWZmZgsWLLh27dqYMWPWrl0rzfF+5LMf\nATzPKpybBwAAAJRSXFys1WqlqeY3btyYM2fOzp07S07kBvBi4YwOAAAADKLVat99993PP//8\nwYMHmZmZO3bs8PLyIg0CLzRGCAEAAGCohISEjRs3xsbGmpiYeHl5+fv7l3qQKYAXC4EQAAAA\nAGSKKaMAAAAAIFMEQgAAAACQKQIhAAAAAMgUgRAAAAAAZIpACADV05IlSxQKRZ06dYqKisp+\nOnnyZIVC0bVr18qtfMSIEVZWVob07Nq1a7NmzSq3FQAAUNUIhABQbSmVyoyMjKioqFLtBQUF\ne/bsMTExMUpVAADg+UEgBIBqS6lUdurUKSIiolR7ZGTkgwcP2rRpY4yiAADAc4RACADVllqt\nHjx48MGDB+/du1eyffv27T179iw1QhgVFfXKK69YW1ubm5u/9NJLn376qe5BtVqtdtmyZW5u\nbmZmZl5eXnv37lUoFCWX/fXXX/v06WNjY2Nubu7j47Nly5Zy67lz587kyZMbNGhgZmbm5OQ0\ndOjQ69evP9U9BgAAj4dACADVmZ+fn1qt3rFjh64lLS3tyJEjI0aMePjwoa5x3759AwYMEEJE\nRET8+OOPXbp0+eCDD+bMmSN9GhISEhQU1K1bt/379y9YsCAoKOjChQu6ZU+cONGzZ8+ioqJv\nvvkmMjKyU6dOkyZNWr16ddlihgwZcuDAgcWLFx86dGj16tV//vln9+7d8/LyqmrnAQDAoyh0\nJ4ABANXJkiVLli5dmp+f//rrr2dmZp49e1ZqDw8Pnz9/fmpqap8+fWrUqPHLL78IIZo3b/7g\nwYPY2FhTU1OpmxTe7ty5Y29v7+rqWqtWrd9//10aGExOTm7YsKGJiUlubq4Qol27dhkZGX/8\n8Ydu2UGDBv3nP/+5c+eOubl5165d09PTr1+/npOTY2trO2/evJUrV0rd/vrrr507d44bN87Z\n2fkZ/+MAAAAJI4QAUM2NHz/+3LlzV69eld5u37598ODB1tbWug7JycnXr1/v37+/LtEJIQYM\nGFBUVPTbb78lJSUlJyf7+vrqpok6Ozu3a9dOep2enn7u3Ll+/fpptdqCf7z66qvZ2dnnzp0r\nWYaFhYWjo+POnTuPHz+u0WiEEO7u7vPnzycNAgBgRARCAKjm/Pz8rK2tpVvLXLt27fz582PH\nji3Z4fbt20IIV1fXko1STrtz505KSooQok6dOmU/FUIkJSUJITZs2GBeQkBAgG61OjVq1Dh0\n6JBCoejdu3ft2rXffPPNHTt2FBcXP+W9BQAAj6OGsQsAAFQtCwuL4cOHf/PNNytXrty+fXu9\nevX69OlTsoM09FfykkIhhHRBgUJR/pUFuiAnLTthwoQpU6aU6uPp6VmqpX379nFxcSdPnjx8\n+HBUVNTu3bvXrVsXHR1dcmQSAAA8SwRCAKj+xo0bt2XLll9++WXnzp2jRo1SqVQlP3VzcxP/\njPXp/P3330IIV1fX2rVrCyFSU1NLfnrr1i3pRf369YUQGo2mU6dOhlSiUql69uzZs2fPVatW\nffnllwEBAbt27So1YgkAAJ4ZpowCQPXXrVs3Dw+PkJCQhISEsumrbt26Xl5eBw4cyM/P1zXu\n27fPwsKic+fODRs2dHR01F34J4S4fv365cuXpdf29vYdOnTYt29fVlaWbtnt27cvXLhQrVaX\n3MrZs2dHjBiRlpama5EGKku2AACAZ4xACADVn0KhGDt27MGDB729vVu1alW2w4oVKzIzM/v0\n6fPvf/97//79o0aNioqKWrRokY2NjVKpnDZt2h9//DFkyJC9e/euX7++X79+bdu21S37ySef\n5OXldevW7euvvz569OiiRYv8/f2Tk5Nr1Pg/k1BcXFwOHz7cp0+fLVu2HDt2bMeOHWPGjDE1\nNX399derfP8BAEAFmDIKALIwduzYpUuXVjQ5c8CAAYcOHQoODh43bpxarW7RosWWLVsmTJgg\nfRoUFFRUVBQREREVFdW0adOwsLATJ05cvHhR+rR79+7R0dHLli175513ioqK3N3dly1bpnuG\noU69evVOnjy5bNmyBQsWZGRkODg4dOjQ4eTJk02bNq26vQYAAPrxHEIAAAAAkCmmjAIAAACA\nTBEIAQAAAECmCIQAAAAAIFMEQgAAAACQKQIhAAAAAMgUgRAAAAAAZIpACAAAAAAyRSAEAAAA\nAJkiEAIAAACATBEIAQAAAECmCIQAAAAAIFP/D68VY6bCwgeQAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 300,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.list <- list(errors.1, errors.2, errors.3, errors.4, errors.5)\n",
    "x <- errors.list[[1]]\n",
    "for (e in errors.list[2:length(errors.list)]) {\n",
    "    x <- rbind(x, e)\n",
    "}\n",
    "\n",
    "my.figsize(10, 5)\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd06f2b6-2391-499a-ae18-3310b7dc6dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "write.csv(x, file = \"result_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6adf8ad-567c-461e-a306-052d9af2451b",
   "metadata": {},
   "source": [
    "## Forecast with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "cd4c644f-b363-4718-a2d5-84dc96697626",
   "metadata": {},
   "outputs": [],
   "source": [
    "h <- 21\n",
    "x.train <- train[1:wind]\n",
    "x.test <- train[(wind+1):(wind+h)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "468d812f-067c-41e8-b4cc-fa28cc823c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "my.figsize(10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "31da8a77-3e6b-405a-afa2-1c2113fd74c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -8729.901\n",
      " ARIMA(1,0,0) with non-zero mean : -13486.9\n",
      " ARIMA(0,0,1) with non-zero mean : -10820.55\n",
      " ARIMA(0,0,0) with zero mean     : -8407.697\n",
      " ARIMA(2,0,0) with non-zero mean : -13491.63\n",
      " ARIMA(3,0,0) with non-zero mean : -13491.75\n",
      " ARIMA(4,0,0) with non-zero mean : -13496.44\n",
      " ARIMA(5,0,0) with non-zero mean : -13502.01\n",
      " ARIMA(5,0,1) with non-zero mean : -13509.96\n",
      " ARIMA(4,0,1) with non-zero mean : -13504.29\n",
      " ARIMA(5,0,2) with non-zero mean : -13507.99\n",
      " ARIMA(4,0,2) with non-zero mean : -13508.66\n",
      " ARIMA(5,0,1) with zero mean     : -13497.02\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,1) with non-zero mean : -13497.21\n",
      "\n",
      " Best model: ARIMA(5,0,1) with non-zero mean \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAAJYCAIAAAD9hIhNAAAACXBIWXMAABJ0AAASdAHeZh94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\nAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 300,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fc <- arima.forecast(x.train, h)\n",
    "my.plot_forecast(fc, future=h, test=x.test, past=h*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dc2dfd61-7098-462a-8833-cce95aa054f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NULL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHQAAALQCAIAAAB+M7AjAAAACXBIWXMAABJ0AAASdAHeZh94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\nAAZyBQAAMJArAACAgVwBAAAMAqekVK3qFJWFAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 570
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bsts.lines <- function(fc, obs, ...) {\n",
    "    n1 <- ncol(fc$distribution)\n",
    "    time <- index(fc$original.series)\n",
    "    deltat <- tail(diff(tail(time, 2)), 1)\n",
    "    pred.time <- tail(time, 1) + (1:n1) * deltat\n",
    "    obs <- obs[1:length(pred.time)]\n",
    "    index(obs) <- pred.time\n",
    "    #l <- lines(obs)\n",
    "    l <- lines(pred.time, as.numeric(obs), ...)\n",
    "    return(l)\n",
    "}\n",
    "\n",
    "fc <- bsts.forecast(x.train, h, ping=0)\n",
    "\n",
    "my.figsize(9.5,6)\n",
    "plot(fc, plot.original=h*6)\n",
    "bsts.lines(fc, x.test, col='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "530e5ffb-d5b4-4115-9e2c-644a6fd1a604",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAIAAAByhViMAAAACXBIWXMAABJ0AAASdAHeZh94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\nAEEQ7AAAAATxP7CcZo9ig5r9AAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# testing\n",
    "h <- 21\n",
    "x.train <- train[1:wind]\n",
    "x.test <- train[(wind+1):(wind+h)]\n",
    "\n",
    "#fc <- prophet.forecast(x.train, h, result.error=TRUE)\n",
    "fc <- prophet.forecast(x.train, h)\n",
    "plot(fc$model, fc$pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "cf969669-5512-427c-b90f-8e780490f12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fc <- prophet.forecast(x.train, h, result.error=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "41fbfbe1-a009-4abb-9398-8b2378c91098",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 9\n",
      " $ data       :'data.frame':\t2289 obs. of  20 variables:\n",
      "  ..$ ds                        : POSIXct[1:2289], format: \"1991-01-31\" \"1991-02-01\" ...\n",
      "  ..$ y                         : num [1:2289] 0.0522 0.0636 0.0817 0.1076 0.1285 ...\n",
      "  ..$ trend                     : num [1:2289] 0.024 0.0239 0.0239 0.0239 0.0238 ...\n",
      "  ..$ additive_terms            : num [1:2289] 0.00722 0.00715 0.01232 0.01399 0.01474 ...\n",
      "  ..$ additive_terms_lower      : num [1:2289] 0.00722 0.00715 0.01232 0.01399 0.01474 ...\n",
      "  ..$ additive_terms_upper      : num [1:2289] 0.00722 0.00715 0.01232 0.01399 0.01474 ...\n",
      "  ..$ weekly                    : num [1:2289] -0.00562 -0.00683 -0.00537 -0.00495 -0.00543 ...\n",
      "  ..$ weekly_lower              : num [1:2289] -0.00562 -0.00683 -0.00537 -0.00495 -0.00543 ...\n",
      "  ..$ weekly_upper              : num [1:2289] -0.00562 -0.00683 -0.00537 -0.00495 -0.00543 ...\n",
      "  ..$ yearly                    : num [1:2289] 0.0128 0.014 0.0177 0.0189 0.0202 ...\n",
      "  ..$ yearly_lower              : num [1:2289] 0.0128 0.014 0.0177 0.0189 0.0202 ...\n",
      "  ..$ yearly_upper              : num [1:2289] 0.0128 0.014 0.0177 0.0189 0.0202 ...\n",
      "  ..$ multiplicative_terms      : num [1:2289] 0 0 0 0 0 0 0 0 0 0 ...\n",
      "  ..$ multiplicative_terms_lower: num [1:2289] 0 0 0 0 0 0 0 0 0 0 ...\n",
      "  ..$ multiplicative_terms_upper: num [1:2289] 0 0 0 0 0 0 0 0 0 0 ...\n",
      "  ..$ yhat_lower                : num [1:2289] -0.01149 -0.01235 -0.00413 -0.00416 -0.00214 ...\n",
      "  ..$ yhat_upper                : num [1:2289] 0.0738 0.074 0.0803 0.0809 0.0811 ...\n",
      "  ..$ trend_lower               : num [1:2289] 0.024 0.0239 0.0239 0.0239 0.0238 ...\n",
      "  ..$ trend_upper               : num [1:2289] 0.024 0.0239 0.0239 0.0239 0.0238 ...\n",
      "  ..$ yhat                      : num [1:2289] 0.0312 0.0311 0.0362 0.0379 0.0386 ...\n",
      " $ layers     :List of 3\n",
      "  ..$ :Classes 'LayerInstance', 'Layer', 'ggproto', 'gg' <ggproto object: Class LayerInstance, Layer, gg>\n",
      "    aes_params: list\n",
      "    compute_aesthetics: function\n",
      "    compute_geom_1: function\n",
      "    compute_geom_2: function\n",
      "    compute_position: function\n",
      "    compute_statistic: function\n",
      "    computed_geom_params: NULL\n",
      "    computed_mapping: NULL\n",
      "    computed_stat_params: NULL\n",
      "    data: waiver\n",
      "    draw_geom: function\n",
      "    finish_statistics: function\n",
      "    geom: <ggproto object: Class GeomRibbon, Geom, gg>\n",
      "        aesthetics: function\n",
      "        default_aes: uneval\n",
      "        draw_group: function\n",
      "        draw_key: function\n",
      "        draw_layer: function\n",
      "        draw_panel: function\n",
      "        extra_params: na.rm orientation\n",
      "        handle_na: function\n",
      "        non_missing_aes: \n",
      "        optional_aes: \n",
      "        parameters: function\n",
      "        required_aes: x|y ymin|xmin ymax|xmax\n",
      "        setup_data: function\n",
      "        setup_params: function\n",
      "        use_defaults: function\n",
      "        super:  <ggproto object: Class Geom, gg>\n",
      "    geom_params: list\n",
      "    inherit.aes: TRUE\n",
      "    layer_data: function\n",
      "    map_statistic: function\n",
      "    mapping: uneval\n",
      "    position: <ggproto object: Class PositionIdentity, Position, gg>\n",
      "        compute_layer: function\n",
      "        compute_panel: function\n",
      "        required_aes: \n",
      "        setup_data: function\n",
      "        setup_params: function\n",
      "        super:  <ggproto object: Class Position, gg>\n",
      "    print: function\n",
      "    setup_layer: function\n",
      "    show.legend: NA\n",
      "    stat: <ggproto object: Class StatIdentity, Stat, gg>\n",
      "        aesthetics: function\n",
      "        compute_group: function\n",
      "        compute_layer: function\n",
      "        compute_panel: function\n",
      "        default_aes: uneval\n",
      "        extra_params: na.rm\n",
      "        finish_layer: function\n",
      "        non_missing_aes: \n",
      "        optional_aes: \n",
      "        parameters: function\n",
      "        required_aes: \n",
      "        retransform: TRUE\n",
      "        setup_data: function\n",
      "        setup_params: function\n",
      "        super:  <ggproto object: Class Stat, gg>\n",
      "    stat_params: list\n",
      "    super:  <ggproto object: Class Layer, gg> \n",
      "  ..$ :Classes 'LayerInstance', 'Layer', 'ggproto', 'gg' <ggproto object: Class LayerInstance, Layer, gg>\n",
      "    aes_params: list\n",
      "    compute_aesthetics: function\n",
      "    compute_geom_1: function\n",
      "    compute_geom_2: function\n",
      "    compute_position: function\n",
      "    compute_statistic: function\n",
      "    computed_geom_params: NULL\n",
      "    computed_mapping: NULL\n",
      "    computed_stat_params: NULL\n",
      "    data: waiver\n",
      "    draw_geom: function\n",
      "    finish_statistics: function\n",
      "    geom: <ggproto object: Class GeomPoint, Geom, gg>\n",
      "        aesthetics: function\n",
      "        default_aes: uneval\n",
      "        draw_group: function\n",
      "        draw_key: function\n",
      "        draw_layer: function\n",
      "        draw_panel: function\n",
      "        extra_params: na.rm\n",
      "        handle_na: function\n",
      "        non_missing_aes: size shape colour\n",
      "        optional_aes: \n",
      "        parameters: function\n",
      "        required_aes: x y\n",
      "        setup_data: function\n",
      "        setup_params: function\n",
      "        use_defaults: function\n",
      "        super:  <ggproto object: Class Geom, gg>\n",
      "    geom_params: list\n",
      "    inherit.aes: TRUE\n",
      "    layer_data: function\n",
      "    map_statistic: function\n",
      "    mapping: NULL\n",
      "    position: <ggproto object: Class PositionIdentity, Position, gg>\n",
      "        compute_layer: function\n",
      "        compute_panel: function\n",
      "        required_aes: \n",
      "        setup_data: function\n",
      "        setup_params: function\n",
      "        super:  <ggproto object: Class Position, gg>\n",
      "    print: function\n",
      "    setup_layer: function\n",
      "    show.legend: NA\n",
      "    stat: <ggproto object: Class StatIdentity, Stat, gg>\n",
      "        aesthetics: function\n",
      "        compute_group: function\n",
      "        compute_layer: function\n",
      "        compute_panel: function\n",
      "        default_aes: uneval\n",
      "        extra_params: na.rm\n",
      "        finish_layer: function\n",
      "        non_missing_aes: \n",
      "        optional_aes: \n",
      "        parameters: function\n",
      "        required_aes: \n",
      "        retransform: TRUE\n",
      "        setup_data: function\n",
      "        setup_params: function\n",
      "        super:  <ggproto object: Class Stat, gg>\n",
      "    stat_params: list\n",
      "    super:  <ggproto object: Class Layer, gg> \n",
      "  ..$ :Classes 'LayerInstance', 'Layer', 'ggproto', 'gg' <ggproto object: Class LayerInstance, Layer, gg>\n",
      "    aes_params: list\n",
      "    compute_aesthetics: function\n",
      "    compute_geom_1: function\n",
      "    compute_geom_2: function\n",
      "    compute_position: function\n",
      "    compute_statistic: function\n",
      "    computed_geom_params: NULL\n",
      "    computed_mapping: NULL\n",
      "    computed_stat_params: NULL\n",
      "    data: waiver\n",
      "    draw_geom: function\n",
      "    finish_statistics: function\n",
      "    geom: <ggproto object: Class GeomLine, GeomPath, Geom, gg>\n",
      "        aesthetics: function\n",
      "        default_aes: uneval\n",
      "        draw_group: function\n",
      "        draw_key: function\n",
      "        draw_layer: function\n",
      "        draw_panel: function\n",
      "        extra_params: na.rm orientation\n",
      "        handle_na: function\n",
      "        non_missing_aes: \n",
      "        optional_aes: \n",
      "        parameters: function\n",
      "        required_aes: x y\n",
      "        setup_data: function\n",
      "        setup_params: function\n",
      "        use_defaults: function\n",
      "        super:  <ggproto object: Class GeomPath, Geom, gg>\n",
      "    geom_params: list\n",
      "    inherit.aes: TRUE\n",
      "    layer_data: function\n",
      "    map_statistic: function\n",
      "    mapping: uneval\n",
      "    position: <ggproto object: Class PositionIdentity, Position, gg>\n",
      "        compute_layer: function\n",
      "        compute_panel: function\n",
      "        required_aes: \n",
      "        setup_data: function\n",
      "        setup_params: function\n",
      "        super:  <ggproto object: Class Position, gg>\n",
      "    print: function\n",
      "    setup_layer: function\n",
      "    show.legend: NA\n",
      "    stat: <ggproto object: Class StatIdentity, Stat, gg>\n",
      "        aesthetics: function\n",
      "        compute_group: function\n",
      "        compute_layer: function\n",
      "        compute_panel: function\n",
      "        default_aes: uneval\n",
      "        extra_params: na.rm\n",
      "        finish_layer: function\n",
      "        non_missing_aes: \n",
      "        optional_aes: \n",
      "        parameters: function\n",
      "        required_aes: \n",
      "        retransform: TRUE\n",
      "        setup_data: function\n",
      "        setup_params: function\n",
      "        super:  <ggproto object: Class Stat, gg>\n",
      "    stat_params: list\n",
      "    super:  <ggproto object: Class Layer, gg> \n",
      " $ scales     :Classes 'ScalesList', 'ggproto', 'gg' <ggproto object: Class ScalesList, gg>\n",
      "    add: function\n",
      "    clone: function\n",
      "    find: function\n",
      "    get_scales: function\n",
      "    has_scale: function\n",
      "    input: function\n",
      "    n: function\n",
      "    non_position_scales: function\n",
      "    scales: list\n",
      "    super:  <ggproto object: Class ScalesList, gg> \n",
      " $ mapping    :List of 2\n",
      "  ..$ x: language ~ds\n",
      "  .. ..- attr(*, \".Environment\")=<environment: 0x559cd43a4120> \n",
      "  ..$ y: language ~y\n",
      "  .. ..- attr(*, \".Environment\")=<environment: 0x559cd43a4120> \n",
      "  ..- attr(*, \"class\")= chr \"uneval\"\n",
      " $ theme      :List of 1\n",
      "  ..$ aspect.ratio: num 0.6\n",
      "  ..- attr(*, \"complete\")= logi FALSE\n",
      "  ..- attr(*, \"validate\")= logi TRUE\n",
      " $ coordinates:Classes 'CoordCartesian', 'Coord', 'ggproto', 'gg' <ggproto object: Class CoordCartesian, Coord, gg>\n",
      "    aspect: function\n",
      "    backtransform_range: function\n",
      "    clip: on\n",
      "    default: TRUE\n",
      "    distance: function\n",
      "    expand: TRUE\n",
      "    is_free: function\n",
      "    is_linear: function\n",
      "    labels: function\n",
      "    limits: list\n",
      "    modify_scales: function\n",
      "    range: function\n",
      "    render_axis_h: function\n",
      "    render_axis_v: function\n",
      "    render_bg: function\n",
      "    render_fg: function\n",
      "    setup_data: function\n",
      "    setup_layout: function\n",
      "    setup_panel_guides: function\n",
      "    setup_panel_params: function\n",
      "    setup_params: function\n",
      "    train_panel_guides: function\n",
      "    transform: function\n",
      "    super:  <ggproto object: Class CoordCartesian, Coord, gg> \n",
      " $ facet      :Classes 'FacetNull', 'Facet', 'ggproto', 'gg' <ggproto object: Class FacetNull, Facet, gg>\n",
      "    compute_layout: function\n",
      "    draw_back: function\n",
      "    draw_front: function\n",
      "    draw_labels: function\n",
      "    draw_panels: function\n",
      "    finish_data: function\n",
      "    init_scales: function\n",
      "    map_data: function\n",
      "    params: list\n",
      "    setup_data: function\n",
      "    setup_params: function\n",
      "    shrink: TRUE\n",
      "    train_scales: function\n",
      "    vars: function\n",
      "    super:  <ggproto object: Class FacetNull, Facet, gg> \n",
      " $ plot_env   :<environment: 0x559cd43a4120> \n",
      " $ labels     :List of 4\n",
      "  ..$ x   : chr \"ds\"\n",
      "  ..$ y   : chr \"y\"\n",
      "  ..$ ymin: chr \"yhat_lower\"\n",
      "  ..$ ymax: chr \"yhat_upper\"\n",
      " - attr(*, \"class\")= chr [1:2] \"gg\" \"ggplot\"\n"
     ]
    }
   ],
   "source": [
    "str(plot(fc$model, fc$pred, type='l'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb2f8c5-aaba-46d9-9f39-50f832e2fdf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
