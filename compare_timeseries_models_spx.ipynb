{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403b7c49-b1e4-4567-b300-d0cf4343f1ef",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589d964f-db11-4ee9-b31e-43a56aa2ed1c",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c83acee-3f1c-4594-883d-7c9aa7615e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: xts\n",
      "\n",
      "Loading required package: zoo\n",
      "\n",
      "\n",
      "Attaching package: ‘zoo’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n",
      "\n",
      "Loading required package: TTR\n",
      "\n",
      "Registered S3 method overwritten by 'quantmod':\n",
      "  method            from\n",
      "  as.zoo.data.frame zoo \n",
      "\n",
      "Loading required package: parallel\n",
      "\n",
      "\n",
      "Attaching package: ‘rugarch’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    sigma\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(quantmod)\n",
    "library(forecast)\n",
    "library(rugarch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1cae5f-cb19-423f-9f75-23355f2b58d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "source(\"~/works/utils/r/myutils.r\")\n",
    "source(\"~/works/utils/r/myarimagarch.r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81965efe-0310-4a8f-bab8-f7d92d9d839f",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae10fdf1-3592-4ea5-8ae2-d5917a507e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start <- '1991-01-01'\n",
    "train_end <- '2019-12-31'\n",
    "\n",
    "test_start <- '2020-01-01'\n",
    "test_end <- '2020-12-31'\n",
    "\n",
    "lookahead <- 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee333ae3-056f-4986-aef5-64e8a03fcc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'^GSPC'"
      ],
      "text/latex": [
       "'\\textasciicircum{}GSPC'"
      ],
      "text/markdown": [
       "'^GSPC'"
      ],
      "text/plain": [
       "[1] \"^GSPC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from <- train_start\n",
    "to <- test_end\n",
    "getSymbols(\"^GSPC\", from=from, to=to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "214a3960-5dd7-47be-90ef-2e258d043250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spx <- GSPC\n",
    "colnames(spx) <- c('o','h','l','c','v','a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afb9af71-95b5-4285-93a0-0e5913510963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily log. return\n",
    "spx.ret <- diff(log(spx$a), lookahead)\n",
    "colnames(spx.ret) <- 'logret'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "651c6501-6ff3-4d97-a129-65e3ee317cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train <- window(spx.ret, end=as.Date(train_end))\n",
    "test <- window(spx.ret, start=as.Date(test_start), end=as.Date(test_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf7c574-fcaf-41e8-a22e-97b2caadd84a",
   "metadata": {},
   "source": [
    "## CV Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ad305fe-7f89-4186-a651-1873d64ef6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR <- 252\n",
    "hori <- 21\n",
    "peri <- floor(hori/2)\n",
    "#wind <- 5*YEAR\n",
    "wind <- 7*YEAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f16cf2d-16cb-45ad-adb3-4dfc8bcfda22",
   "metadata": {},
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6af023f6-9782-43de-ad8a-60f12ef422a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start <- '1991-01-01'\n",
    "#train_end <- '2000-12-31'\n",
    "train_end <- '1998-12-31'\n",
    "train <- window(spx.ret, start=as.Date(train_start), end=as.Date(train_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "493d63b9-0a03-4771-9aa1-53e0d58166f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"number of iterations: 24\"\n"
     ]
    }
   ],
   "source": [
    "n <- (nrow(train) - wind - hori)/floor(peri)\n",
    "print(paste('number of iterations: ', round(n), sep=''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a0b3d6-8fa4-4911-9127-b372ec88ba57",
   "metadata": {},
   "source": [
    "## Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f87d6209-3593-4659-b754-eef50734902f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x <- RSI(spx$a)\n",
    "trainx <- merge(train, x, join='left', fill=NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "063c43c3-688b-49ac-a6e2-89690219b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use close instead of adjusted to make consistent with \"un-adjusted\" high & low\n",
    "x <- BBands(spx[,c('h','l','c')])\n",
    "x <- x$pctB\n",
    "trainx <- merge(trainx, x, join='left', fill=NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff082501-d546-4510-bf61-43cfec923f72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x <- MACD(spx$a)\n",
    "x <- x$macd - x$signal\n",
    "trainx <- merge(trainx, x, join='left', fill=NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "befa6d49-0a1c-4bc7-8083-45ac91a02823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       y      rsi    bbands        macd\n",
       "1991-02-19  0.0008938101 72.59254 0.8419486 -0.03641515\n",
       "1991-02-20 -0.0115721543 66.25313 0.7706927 -0.18551057\n",
       "1991-02-21 -0.0004657216 66.00481 0.7330987 -0.30953562\n",
       "1991-02-22  0.0018614141 66.54491 0.7402938 -0.39546732\n",
       "1991-02-25  0.0043934960 67.84742 0.7305630 -0.43573971\n",
       "1991-02-26 -0.0121907956 60.80133 0.6379610 -0.55105032"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                       y      rsi    bbands      macd\n",
       "1998-12-23  0.0205344089 69.31506 1.1362226 0.1801475\n",
       "1998-12-24 -0.0018494463 68.33272 1.0891085 0.2591878\n",
       "1998-12-28 -0.0006363021 67.97622 0.9989878 0.2764233\n",
       "1998-12-29  0.0132292844 71.34467 1.0004403 0.3444776\n",
       "1998-12-30 -0.0079879511 66.76606 0.9423269 0.3006200\n",
       "1998-12-31 -0.0021941483 65.52839 0.8488094 0.2269923"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colnames(trainx) <- c('y','rsi','bbands','macd')\n",
    "trainx <- na.omit(trainx)\n",
    "head(trainx)\n",
    "tail(trainx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5049d74b-5700-4b0c-af48-c2d74dc6d9cd",
   "metadata": {},
   "source": [
    "# Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9653be84-20b9-4aad-b230-55cfa4fc581c",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a631ddab-2034-402d-90d7-b6583506f3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Rcpp\n",
      "\n",
      "Loading required package: rlang\n",
      "\n",
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:xts’:\n",
      "\n",
      "    first, last\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(prophet)\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b7eba21-cf1d-4989-a454-cb290745a2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast <- function(x, h, xreg=NULL, xreg.msize=NULL) {\n",
    "    \n",
    "    check.ds <- function(x) {\n",
    "        d <- try(as.POSIXct(x$ds, format = \"%Y-%m-%d\"), silent=T)\n",
    "        if ((sum(is.na(d))>0) | (is.element(\"try-error\", class(d))))  {\n",
    "            #print(\"That wasn't correct!\")\n",
    "            x$ds <- seq(as.Date('1901-01-01'), length.out=length(x$ds), by=1)\n",
    "        }\n",
    "        return(x)\n",
    "    }\n",
    "    \n",
    "    model <- prophet()\n",
    "\n",
    "    if (!is.null(xreg)) {\n",
    "        ### convert data for prophet\n",
    "        #x <- ifelse(is.null(dim(x)), data.frame(x), x) # not works\n",
    "        if (is.null(dim(x))) {x <- data.frame(x)}\n",
    "        colnames(x) <- 'y'\n",
    "        x.train <- cbind(x, xreg)\n",
    "        x.train <- as.data.frame(x.train)\n",
    "        x.train <- cbind(ds=rownames(x.train), x.train)\n",
    "        rownames(x.train) <- NULL\n",
    "        x.train <- check.ds(x.train)\n",
    "\n",
    "        ### add regressors before fitting\n",
    "        for (c in colnames(xreg)) {\n",
    "            model <- add_regressor(model, c)\n",
    "        }\n",
    "\n",
    "        ### fit: must run after add_regressor and before make_future_dataframe\n",
    "        model <- fit.prophet(model, x.train)\n",
    "\n",
    "        ### prepare future ds\n",
    "        future <- make_future_dataframe(model, periods=h)\n",
    "\n",
    "        # regessor assumption for future\n",
    "        if (is.null(xreg.msize)) {\n",
    "            xreg.m <- xreg # calc mean for future with all the xreg\n",
    "        } else {\n",
    "            # calc mean for future with xreg of length xreg.mszie\n",
    "            xreg.m <- tail(xreg, n=xreg.msize)\n",
    "        }\n",
    "        \n",
    "        if (is.null(dim(xreg))) {\n",
    "            xreg.h <- mean(xreg.m)\n",
    "        } else {\n",
    "            xreg.h <- colMeans(xreg.m)  \n",
    "        }\n",
    "\n",
    "        # rbind history & future of xreg\n",
    "        xreg.all <- data.frame(xreg)\n",
    "        xreg.coln <- colnames(xreg.all) # save name for the case of single xreg\n",
    "\n",
    "        xreg.h <- data.frame(xreg.h)\n",
    "        colnames(xreg.h) <- colnames(NA)\n",
    "        xreg.h <- t(xreg.h)\n",
    "        xreg.h <- as.ts(xreg.h[rep(seq_len(nrow(xreg.h)), h), ])\n",
    "        xreg.h <- data.frame(xreg.h) # convert to frame for the case of single xreg\n",
    "\n",
    "        # update future\n",
    "        colnames(xreg.h) <- xreg.coln # match name to rbind\n",
    "        xreg.all <- rbind(xreg.all, xreg.h)\n",
    "        xreg.all$ds <- future$ds\n",
    "        future <- xreg.all\n",
    "\n",
    "    } else {\n",
    "        x.train <- data.frame(ds=index(x), y=as.numeric(x))\n",
    "        x.train <- check.ds(x.train)\n",
    "        model <- fit.prophet(model, x.train)\n",
    "        future <- make_future_dataframe(model, periods=h)\n",
    "    }\n",
    "\n",
    "    fc <- predict(model, future)\n",
    "    fc <- list(method = \"Prophet Forecasting\", mean=tail(fc$yhat, h))\n",
    "    return(fc)\n",
    "} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e0fb38-d451-44d8-8834-ba4d69d19781",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dd96713-bac0-45e7-acee-91b3db181205",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"12 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"23 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"35 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"46 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"58 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"69 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"81 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"92 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m01.1 <- my.tsCV(train, cv.forecast, h=hori, window=wind, step=peri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ac8981d-15bf-408c-9638-7b4754cbf984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 1997-12-31\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m01.1\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c1ddd0-be96-456c-878f-5386005d6092",
   "metadata": {},
   "source": [
    "## Additional regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5003bce6-1677-46e3-a84f-18b57b7872bc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"9 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"18 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"27 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"36 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"45 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"55 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"64 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"73 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"82 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"91 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"100 % done.\"\n"
     ]
    }
   ],
   "source": [
    "result.m01.2 <- my.tsCV(trainx[,1], cv.forecast, h=hori, window=wind, step=peri,\n",
    "                       xreg=trainx[,2:4], silent=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2d5fe22-e405-4131-96d3-1cf18723f552",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"9 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"18 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"27 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"36 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"45 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"55 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"64 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"73 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"82 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"91 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"100 % done.\"\n"
     ]
    }
   ],
   "source": [
    "result.m01.3 <- my.tsCV(trainx[,1], cv.forecast, h=hori, window=wind, step=peri,\n",
    "                       xreg=trainx[,3], silent=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ba326e3-2a59-4a52-ab62-c7b71ccb9ea8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"9 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"18 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"27 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"36 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"45 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"55 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"64 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"73 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"82 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"91 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"100 % done.\"\n"
     ]
    }
   ],
   "source": [
    "result.m01.4 <- my.tsCV(trainx[,1], cv.forecast, h=hori, window=wind, step=peri,\n",
    "                       xreg=trainx[,2:4], xreg.msize=hori)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfe1cb3-5728-4fd8-a0ef-2593535940f5",
   "metadata": {},
   "source": [
    "## Compare Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "543bfe7d-1677-4f63-ad42-b738454d06f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAIAAAByhViMAAAACXBIWXMAABJ0AAASdAHeZh94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\nAhp2AAAAAABa4r+g8jZcXWuY2wAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- my.get_result(result.m01.1, '1.Prophet')\n",
    "errors.2 <- my.get_result(result.m01.2, '2.Prophet with Regressors')\n",
    "errors.3 <- my.get_result(result.m01.3, '3.Prophet with 1 Regressor')\n",
    "errors.4 <- my.get_result(result.m01.4, '4.Prophet with Regressor (2)')\n",
    "\n",
    "x <- rbind(errors.1, errors.2)\n",
    "x <- rbind(x, errors.3)\n",
    "x <- rbind(x, errors.4)\n",
    "my.plot_errors(x, metrics=c('rmse'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7cb8d98e-9491-400a-abd5-6a4694dfe9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m01 <- result.m01.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d38357-ca19-4a00-a9f3-88f56e5a4726",
   "metadata": {},
   "source": [
    "# BSTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b1a082-dca7-457f-a151-90f7518efe7a",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cdddaae-482a-4de2-932f-83458967d5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: BoomSpikeSlab\n",
      "\n",
      "Loading required package: Boom\n",
      "\n",
      "Loading required package: MASS\n",
      "\n",
      "\n",
      "Attaching package: ‘MASS’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    select\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘Boom’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    rWishart\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘BoomSpikeSlab’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    knots\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘bsts’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:BoomSpikeSlab’:\n",
      "\n",
      "    SuggestBurn\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(bsts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b121bf4e-1380-40ed-9d77-65fd35cd1bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast <- function(x, h, xreg=NULL, xreg.msize=NULL, expected.model.size=NULL) {\n",
    "    \n",
    "    if (!is.null(xreg)) {\n",
    "        ### convert data for bsts\n",
    "        if (is.null(dim(x))) {x <- data.frame(x)}\n",
    "        colnames(x) <- 'y'\n",
    "        x.train <- cbind(x, xreg)\n",
    "        x.train <- as.data.frame(x.train)\n",
    "        \n",
    "        ### fitting\n",
    "        n <- ncol(x.train)\n",
    "        if (is.null(expected.model.size)) {\n",
    "            expected.model.size <- n\n",
    "        } else if (expected.model.size > n) {\n",
    "            expected.model.size <- n\n",
    "        }\n",
    "        ss <- AddSemilocalLinearTrend(list(), x.train$y)\n",
    "        model <- bsts(y ~ .,\n",
    "                      state.specification = ss,\n",
    "                      niter = 1000,\n",
    "                      data = x.train,\n",
    "                      expected.model.size = expected.model.size)  # Passed to SpikeSlabPrior.\n",
    "        \n",
    "        ### prepare future of xreg for prediction\n",
    "        # regessor assumption for future\n",
    "        if (is.null(xreg.msize)) {\n",
    "            xreg.m <- xreg # calc mean for future with all the xreg\n",
    "        } else {\n",
    "            # calc mean for future with xreg of length xreg.mszie\n",
    "            xreg.m <- tail(xreg, n=xreg.msize)\n",
    "        }\n",
    "\n",
    "        if (is.null(dim(xreg))) {\n",
    "            xreg.h <- mean(xreg.m)\n",
    "        } else {\n",
    "            xreg.h <- colMeans(xreg.m)  \n",
    "        }\n",
    "\n",
    "        xreg.all <- data.frame(xreg)\n",
    "        xreg.coln <- colnames(xreg.all) # save name for the case of single xreg\n",
    "        xreg.h <- data.frame(xreg.h)\n",
    "        colnames(xreg.h) <- colnames(NA)\n",
    "        xreg.h <- t(xreg.h)\n",
    "        xreg.h <- as.ts(xreg.h[rep(seq_len(nrow(xreg.h)), h), ])\n",
    "        xreg.h <- data.frame(xreg.h) # convert to frame for the case of single xreg\n",
    "        colnames(xreg.h) <- xreg.coln # match name to rbind\n",
    "\n",
    "    } else {\n",
    "        ss <- AddSemilocalLinearTrend(list(), x)\n",
    "        model <- bsts(x, state.specification = ss, niter=1000)\n",
    "        xreg.h <- NULL\n",
    "    }\n",
    "    \n",
    "    fc <- predict(model, horizon=h, newdata=xreg.h)\n",
    "    return(fc)\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d8fc5f-8e48-4ea2-b707-e1f062d6b634",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d35a145-717d-4912-abd9-229767f0ce19",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:23:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:23:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:23:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:23:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:23:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:23:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:23:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:23:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:23:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:23:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:23:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:23:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:23:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:23:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:23:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:23:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:23:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:23:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:23:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:23:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:23:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:23:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:23:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:23:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:23:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:24:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:24:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:24:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:24:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:24:11 2022 =-=-=-=-=\n",
      "[1] \"12 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:24:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:24:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:24:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:24:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:24:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:24:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:24:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:24:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:24:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:24:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:24:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:24:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:24:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:24:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:24:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:24:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:24:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:24:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:24:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:25:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:25:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:25:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:25:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:25:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:25:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:25:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:25:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:25:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:25:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:25:25 2022 =-=-=-=-=\n",
      "[1] \"23 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:25:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:25:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:25:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:25:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:25:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:25:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:25:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:25:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:25:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:25:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:25:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:25:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:25:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:25:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:26:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:26:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:26:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:26:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:26:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:26:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:26:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:26:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:26:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:26:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:26:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:26:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:26:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:26:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:26:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:26:39 2022 =-=-=-=-=\n",
      "[1] \"35 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:26:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:26:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:26:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:26:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:26:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:26:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:26:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:26:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:27:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:27:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:27:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:27:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:27:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:27:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:27:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:27:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:27:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:27:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:27:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:27:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:27:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:27:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:27:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:27:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:27:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:27:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:27:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:27:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:27:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:27:53 2022 =-=-=-=-=\n",
      "[1] \"46 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:27:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:27:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:28:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:28:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:28:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:28:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:28:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:28:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:28:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:28:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:28:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:28:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:28:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:28:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:28:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:28:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:28:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:28:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:28:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:28:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:28:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:28:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:28:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:28:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:28:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:28:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:29:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:29:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:29:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:29:08 2022 =-=-=-=-=\n",
      "[1] \"58 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:29:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:29:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:29:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:29:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:29:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:29:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:29:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:29:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:29:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:29:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:29:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:29:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:29:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:29:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:29:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:29:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:29:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:29:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:29:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:29:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:30:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:30:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:30:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:30:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:30:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:30:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:30:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:30:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:30:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:30:22 2022 =-=-=-=-=\n",
      "[1] \"69 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:30:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:30:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:30:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:30:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:30:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:30:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:30:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:30:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:30:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:30:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:30:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:30:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:30:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:30:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:30:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:31:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:31:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:31:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:31:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:31:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:31:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:31:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:31:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:31:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:31:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:31:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:31:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:31:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:31:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:31:36 2022 =-=-=-=-=\n",
      "[1] \"81 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:31:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:31:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:31:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:31:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:31:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:31:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:31:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:31:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:31:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:32:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:32:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:32:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:32:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:32:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:32:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:32:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:32:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:32:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:32:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:32:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:32:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:32:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:32:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:32:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:32:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:32:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:32:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:32:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:32:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:32:51 2022 =-=-=-=-=\n",
      "[1] \"92 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:32:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:32:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:32:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:33:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:33:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:33:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:33:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:33:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:33:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:33:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:33:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:33:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:33:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:33:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:33:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:33:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:33:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:33:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:33:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:33:41 2022 =-=-=-=-=\n"
     ]
    }
   ],
   "source": [
    "result.m02.1 <- my.tsCV(train, cv.forecast, h=hori, window=wind, step=peri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "602a90d7-2081-46eb-8cf8-ca09307501bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 1997-12-31\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m02.1\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b296acaf-74d0-4185-b130-b6512bbf03be",
   "metadata": {},
   "source": [
    "## Regression with spike and slab priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ecce414-f5fc-4f70-9f89-4908c5fe4e9a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:33:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:33:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:33:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:33:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:33:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:33:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:34:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:34:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:34:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:34:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:34:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:34:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:34:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:34:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:34:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:34:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:34:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:34:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:34:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:34:39 2022 =-=-=-=-=\n",
      "[1] \"9 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:34:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:34:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:34:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:34:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:34:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:34:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:34:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:35:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:35:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:35:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:35:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:35:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:35:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:35:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:35:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:35:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:35:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:35:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:35:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:35:36 2022 =-=-=-=-=\n",
      "[1] \"18 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:35:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:35:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:35:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:35:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:35:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:35:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:35:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:35:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:36:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:36:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:36:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:36:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:36:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:36:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:36:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:36:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:36:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:36:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:36:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:36:33 2022 =-=-=-=-=\n",
      "[1] \"27 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:36:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:36:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:36:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:36:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:36:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:36:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:36:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:36:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:36:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:37:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:37:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:37:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:37:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:37:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:37:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:37:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:37:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:37:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:37:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:37:32 2022 =-=-=-=-=\n",
      "[1] \"36 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:37:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:37:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:37:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:37:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:37:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:37:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:37:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:37:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:37:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:38:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:38:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:38:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:38:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:38:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:38:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:38:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:38:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:38:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:38:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:38:30 2022 =-=-=-=-=\n",
      "[1] \"45 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:38:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:38:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:38:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:38:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:38:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:38:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:38:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:38:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:38:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:38:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:39:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:39:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:39:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:39:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:39:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:39:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:39:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:39:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:39:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:39:27 2022 =-=-=-=-=\n",
      "[1] \"55 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:39:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:39:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:39:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:39:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:39:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:39:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:39:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:39:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:39:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:39:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:39:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:40:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:40:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:40:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:40:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:40:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:40:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:40:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:40:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:40:25 2022 =-=-=-=-=\n",
      "[1] \"64 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:40:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:40:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:40:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:40:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:40:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:40:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:40:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:40:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:40:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:40:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:40:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:41:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:41:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:41:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:41:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:41:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:41:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:41:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:41:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:41:22 2022 =-=-=-=-=\n",
      "[1] \"73 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:41:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:41:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:41:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:41:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:41:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:41:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:41:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:41:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:41:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:41:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:41:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:41:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:42:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:42:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:42:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:42:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:42:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:42:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:42:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:42:20 2022 =-=-=-=-=\n",
      "[1] \"82 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:42:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:42:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:42:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:42:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:42:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:42:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:42:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:42:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:42:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:42:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:42:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:42:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:42:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:43:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:43:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:43:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:43:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:43:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:43:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:43:17 2022 =-=-=-=-=\n",
      "[1] \"91 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:43:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:43:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:43:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:43:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:43:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:43:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:43:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:43:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:43:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:43:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 15 18:43:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 15 18:43:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 15 18:43:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 15 18:43:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 15 18:44:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 15 18:44:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 15 18:44:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 15 18:44:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 15 18:44:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 15 18:44:16 2022 =-=-=-=-=\n",
      "[1] \"100 % done.\"\n"
     ]
    }
   ],
   "source": [
    "result.m02.2 <- my.tsCV(trainx[,1], cv.forecast, h=hori, window=wind, step=peri,\n",
    "                       xreg=trainx[,2:4], silent=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc65fefd-60b9-4ab4-a840-d24018cef2fc",
   "metadata": {},
   "source": [
    "## Compare Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58355e11-c950-44f5-b241-665c8d6aa2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my.figsize(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f874535-9c29-405a-add4-9bbce090b23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94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\nAIBA/S8klYsajhaP4wAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- my.get_result(result.m02.1, 'BSTS')\n",
    "errors.2 <- my.get_result(result.m02.2, 'BSTS w/ Regressors')\n",
    "\n",
    "x <- rbind(errors.1, errors.2)\n",
    "\n",
    "my.plot_errors(x, metrics=c('rmse'), loc='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78dcd688-1d13-455f-a104-9ce887522de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m02 <- result.m02.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69617942-9647-4c39-9fab-68b25004a5f6",
   "metadata": {},
   "source": [
    "# ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33397841-2bfc-4f97-8c37-6703954bf67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast <- function(x, h) {\n",
    "    forecast(auto.arima(x, trace=TRUE, ic='aicc', seasonal=FALSE, \n",
    "                        #allowdrift=TRUE, allowmean = TRUE, # default\n",
    "                        lambda=\"auto\"), h=h)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d4106be-b323-4bac-a185-893d7ec56a9f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12252.31\n",
      " ARIMA(0,0,0) with non-zero mean : -12248.37\n",
      " ARIMA(1,0,0) with non-zero mean : -12247.25\n",
      " ARIMA(0,0,1) with non-zero mean : -12246.81\n",
      " ARIMA(0,0,0) with zero mean     : 5005.842\n",
      " ARIMA(1,0,2) with non-zero mean : -12263.59\n",
      " ARIMA(0,0,2) with non-zero mean : -12245.56\n",
      " ARIMA(1,0,1) with non-zero mean : -12245.25\n",
      " ARIMA(1,0,3) with non-zero mean : -12261.66\n",
      " ARIMA(0,0,3) with non-zero mean : -12247.24\n",
      " ARIMA(2,0,1) with non-zero mean : -12251.02\n",
      " ARIMA(2,0,3) with non-zero mean : -12253.57\n",
      " ARIMA(1,0,2) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,2) with non-zero mean : -12248.74\n",
      "\n",
      " Best model: ARIMA(1,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12263.54\n",
      " ARIMA(0,0,0) with non-zero mean : -12253.43\n",
      " ARIMA(1,0,0) with non-zero mean : -12253.68\n",
      " ARIMA(0,0,1) with non-zero mean : -12251.61\n",
      " ARIMA(0,0,0) with zero mean     : 5005.985\n",
      " ARIMA(1,0,2) with non-zero mean : -12266.91\n",
      " ARIMA(0,0,2) with non-zero mean : -12250.36\n",
      " ARIMA(1,0,1) with non-zero mean : -12251.67\n",
      " ARIMA(1,0,3) with non-zero mean : -12265.11\n",
      " ARIMA(0,0,3) with non-zero mean : -12251.09\n",
      " ARIMA(2,0,1) with non-zero mean : -12262.92\n",
      " ARIMA(2,0,3) with non-zero mean : -12262.67\n",
      " ARIMA(1,0,2) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,2) with non-zero mean : -12255.86\n",
      "\n",
      " Best model: ARIMA(1,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12265.69\n",
      " ARIMA(0,0,0) with non-zero mean : -12256.43\n",
      " ARIMA(1,0,0) with non-zero mean : -12254.02\n",
      " ARIMA(0,0,1) with non-zero mean : -12254.6\n",
      " ARIMA(0,0,0) with zero mean     : 5006.091\n",
      " ARIMA(1,0,2) with non-zero mean : -12258.32\n",
      " ARIMA(2,0,1) with non-zero mean : -12265.37\n",
      " ARIMA(3,0,2) with non-zero mean : -12269.16\n",
      " ARIMA(3,0,1) with non-zero mean : -12266.73\n",
      " ARIMA(4,0,2) with non-zero mean : -12272.16\n",
      " ARIMA(4,0,1) with non-zero mean : -12268.06\n",
      " ARIMA(5,0,2) with non-zero mean : -12271.35\n",
      " ARIMA(4,0,3) with non-zero mean : -12270.76\n",
      " ARIMA(3,0,3) with non-zero mean : -12272.23\n",
      " ARIMA(2,0,3) with non-zero mean : -12264.62\n",
      " ARIMA(3,0,4) with non-zero mean : -12271.28\n",
      " ARIMA(2,0,4) with non-zero mean : -12264.75\n",
      " ARIMA(4,0,4) with non-zero mean : -12277.33\n",
      " ARIMA(5,0,4) with non-zero mean : -12276.58\n",
      " ARIMA(4,0,5) with non-zero mean : -12277.8\n",
      " ARIMA(3,0,5) with non-zero mean : -12272.71\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -12265.46\n",
      "\n",
      " Best model: ARIMA(4,0,4) with non-zero mean \n",
      "\n",
      "[1] \"12 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12271\n",
      " ARIMA(0,0,0) with non-zero mean : -12269.2\n",
      " ARIMA(1,0,0) with non-zero mean : -12266.5\n",
      " ARIMA(0,0,1) with non-zero mean : -12267.49\n",
      " ARIMA(0,0,0) with zero mean     : 5006.051\n",
      " ARIMA(1,0,2) with non-zero mean : -12274.51\n",
      " ARIMA(0,0,2) with non-zero mean : -12266.83\n",
      " ARIMA(1,0,1) with non-zero mean : -12264.5\n",
      " ARIMA(1,0,3) with non-zero mean : -12272.88\n",
      " ARIMA(0,0,3) with non-zero mean : -12268.68\n",
      " ARIMA(2,0,1) with non-zero mean : -12273.33\n",
      " ARIMA(2,0,3) with non-zero mean : -12273.09\n",
      " ARIMA(1,0,2) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,2) with non-zero mean : -12275.16\n",
      "\n",
      " Best model: ARIMA(1,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12206.3\n",
      " ARIMA(0,1,0) with drift         : -11066.19\n",
      " ARIMA(1,1,0) with drift         : -11515.91\n",
      " ARIMA(0,1,1) with drift         : Inf\n",
      " ARIMA(0,1,0)                    : -11068.19\n",
      " ARIMA(1,1,2) with drift         : -12228.91\n",
      " ARIMA(0,1,2) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -12220.39\n",
      " ARIMA(1,1,3) with drift         : -12227.83\n",
      " ARIMA(0,1,3) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : -12202.25\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,2)                    : -12229.99\n",
      " ARIMA(0,1,2)                    : Inf\n",
      " ARIMA(1,1,1)                    : -12221.62\n",
      " ARIMA(2,1,2)                    : -12207.62\n",
      " ARIMA(1,1,3)                    : -12222.91\n",
      " ARIMA(0,1,1)                    : Inf\n",
      " ARIMA(0,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -12203.63\n",
      " ARIMA(2,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : Inf\n",
      " ARIMA(1,1,3)                    : Inf\n",
      " ARIMA(1,1,1)                    : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1)                    : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(1,1,0) with drift         : -11525.7\n",
      "\n",
      " Best model: ARIMA(1,1,0) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -12274.49\n",
      " ARIMA(1,0,0) with non-zero mean : -12271.87\n",
      " ARIMA(0,0,1) with non-zero mean : -12272.83\n",
      " ARIMA(0,0,0) with zero mean     : 5005.975\n",
      " ARIMA(1,0,1) with non-zero mean : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,0,0) with non-zero mean : -12274.49\n",
      "\n",
      " Best model: ARIMA(0,0,0) with non-zero mean \n",
      "\n",
      "[1] \"23 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11079.07\n",
      " ARIMA(1,1,0) with drift         : -11530.87\n",
      " ARIMA(0,1,1) with drift         : -12214.24\n",
      " ARIMA(0,1,0)                    : -11081.07\n",
      " ARIMA(1,1,1) with drift         : -12179.3\n",
      " ARIMA(0,1,2) with drift         : -12213.4\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(0,1,1)                    : -12216.11\n",
      " ARIMA(1,1,1)                    : -12180.78\n",
      " ARIMA(0,1,2)                    : -12215.27\n",
      " ARIMA(1,1,0)                    : -11532.88\n",
      " ARIMA(1,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,1)                    : Inf\n",
      " ARIMA(0,1,2)                    : Inf\n",
      " ARIMA(0,1,1) with drift         : Inf\n",
      " ARIMA(0,1,2) with drift         : Inf\n",
      " ARIMA(1,1,1)                    : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,0)                    : -11538.15\n",
      "\n",
      " Best model: ARIMA(1,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11086.03\n",
      " ARIMA(1,1,0) with drift         : -11536.76\n",
      " ARIMA(0,1,1) with drift         : -12224.87\n",
      " ARIMA(0,1,0)                    : -11088.04\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(0,1,2) with drift         : -12223.82\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(0,1,1)                    : -12226.2\n",
      " ARIMA(1,1,1)                    : Inf\n",
      " ARIMA(0,1,2)                    : -12225.15\n",
      " ARIMA(1,1,0)                    : -11538.77\n",
      " ARIMA(1,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,1)                    : Inf\n",
      " ARIMA(0,1,2)                    : Inf\n",
      " ARIMA(0,1,1) with drift         : Inf\n",
      " ARIMA(0,1,2) with drift         : Inf\n",
      " ARIMA(1,1,0)                    : -11547.6\n",
      "\n",
      " Best model: ARIMA(1,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11085.5\n",
      " ARIMA(1,1,0) with drift         : -11537.57\n",
      " ARIMA(0,1,1) with drift         : Inf\n",
      " ARIMA(0,1,0)                    : -11087.5\n",
      " ARIMA(2,1,0) with drift         : -11727.5\n",
      " ARIMA(3,1,0) with drift         : -11830.21\n",
      " ARIMA(4,1,0) with drift         : -11898.39\n",
      " ARIMA(5,1,0) with drift         : -11950.54\n",
      " ARIMA(5,1,1) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -12156.75\n",
      " ARIMA(3,1,1) with drift         : -12191.68\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : -12217.82\n",
      " ARIMA(4,1,2) with drift         : -12230.34\n",
      " ARIMA(5,1,2) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2)                    : -12231.75\n",
      " ARIMA(3,1,2)                    : -12219.61\n",
      " ARIMA(4,1,1)                    : -12158.57\n",
      " ARIMA(5,1,2)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(3,1,1)                    : -12193.45\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(5,1,1)                    : Inf\n",
      " ARIMA(5,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(3,1,1)                    : Inf\n",
      " ARIMA(3,1,1) with drift         : Inf\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,1) with drift         : Inf\n",
      " ARIMA(5,1,0) with drift         : -11952.53\n",
      "\n",
      " Best model: ARIMA(5,1,0) with drift         \n",
      "\n",
      "[1] \"35 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12302.67\n",
      " ARIMA(0,0,0) with non-zero mean : -12295.42\n",
      " ARIMA(1,0,0) with non-zero mean : -12293.34\n",
      " ARIMA(0,0,1) with non-zero mean : -12294.39\n",
      " ARIMA(0,0,0) with zero mean     : 5005.935\n",
      " ARIMA(1,0,2) with non-zero mean : -12299.76\n",
      " ARIMA(2,0,1) with non-zero mean : -12301.31\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12301.6\n",
      " ARIMA(1,0,1) with non-zero mean : -12291.87\n",
      " ARIMA(1,0,3) with non-zero mean : -12299.13\n",
      " ARIMA(3,0,1) with non-zero mean : -12299.44\n",
      " ARIMA(3,0,3) with non-zero mean : -12301.54\n",
      " ARIMA(2,0,2) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,1) with non-zero mean : -12301.6\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11097.4\n",
      " ARIMA(1,1,0) with drift         : -11540.07\n",
      " ARIMA(0,1,1) with drift         : Inf\n",
      " ARIMA(0,1,0)                    : -11099.4\n",
      " ARIMA(2,1,0) with drift         : -11717.97\n",
      " ARIMA(3,1,0) with drift         : -11821.46\n",
      " ARIMA(4,1,0) with drift         : -11885.14\n",
      " ARIMA(5,1,0) with drift         : -11942.99\n",
      " ARIMA(5,1,1) with drift         : -12247.41\n",
      " ARIMA(4,1,1) with drift         : Inf\n",
      " ARIMA(5,1,2) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(5,1,1)                    : -12249.26\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(5,1,0)                    : -11945.01\n",
      " ARIMA(5,1,2)                    : Inf\n",
      " ARIMA(4,1,0)                    : -11887.15\n",
      " ARIMA(4,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,1,1)                    : Inf\n",
      " ARIMA(5,1,1) with drift         : Inf\n",
      " ARIMA(5,1,0)                    : -11955.1\n",
      "\n",
      " Best model: ARIMA(5,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11097.08\n",
      " ARIMA(1,1,0) with drift         : -11538.22\n",
      " ARIMA(0,1,1) with drift         : -12247.56\n",
      " ARIMA(0,1,0)                    : -11099.09\n",
      " ARIMA(1,1,1) with drift         : -12210.71\n",
      " ARIMA(0,1,2) with drift         : -12247.04\n",
      " ARIMA(1,1,2) with drift         : -12221.98\n",
      " ARIMA(0,1,1)                    : -12248.85\n",
      " ARIMA(1,1,1)                    : -12212.29\n",
      " ARIMA(0,1,2)                    : -12248.31\n",
      " ARIMA(1,1,0)                    : -11540.23\n",
      " ARIMA(1,1,2)                    : -12223.5\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,1)                    : Inf\n",
      " ARIMA(0,1,2)                    : Inf\n",
      " ARIMA(0,1,1) with drift         : Inf\n",
      " ARIMA(0,1,2) with drift         : Inf\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(1,1,1)                    : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,0)                    : -11549.86\n",
      "\n",
      " Best model: ARIMA(1,1,0)                    \n",
      "\n",
      "[1] \"46 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12289.2\n",
      " ARIMA(0,0,0) with non-zero mean : -12286.61\n",
      " ARIMA(1,0,0) with non-zero mean : -12284.82\n",
      " ARIMA(0,0,1) with non-zero mean : -12285.83\n",
      " ARIMA(0,0,0) with zero mean     : 5005.942\n",
      " ARIMA(1,0,2) with non-zero mean : -12293.42\n",
      " ARIMA(0,0,2) with non-zero mean : -12285.59\n",
      " ARIMA(1,0,1) with non-zero mean : -12283.09\n",
      " ARIMA(1,0,3) with non-zero mean : -12293.38\n",
      " ARIMA(0,0,3) with non-zero mean : -12288.38\n",
      " ARIMA(2,0,1) with non-zero mean : -12290.4\n",
      " ARIMA(2,0,3) with non-zero mean : -12289.69\n",
      " ARIMA(1,0,2) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,2) with non-zero mean : -12294.21\n",
      "\n",
      " Best model: ARIMA(1,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11089.51\n",
      " ARIMA(1,1,0) with drift         : -11534.43\n",
      " ARIMA(0,1,1) with drift         : Inf\n",
      " ARIMA(0,1,0)                    : -11091.52\n",
      " ARIMA(2,1,0) with drift         : -11707.9\n",
      " ARIMA(3,1,0) with drift         : -11806.56\n",
      " ARIMA(4,1,0) with drift         : -11877\n",
      " ARIMA(5,1,0) with drift         : -11934.68\n",
      " ARIMA(5,1,1) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -12212.44\n",
      " ARIMA(3,1,1) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : -12219.63\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(5,1,2) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : -12230.77\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(4,1,3)                    : -12232.04\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(4,1,2)                    : -12221.03\n",
      " ARIMA(5,1,3)                    : Inf\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(5,1,2)                    : Inf\n",
      " ARIMA(5,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : Inf\n",
      " ARIMA(5,1,0) with drift         : -11944.07\n",
      "\n",
      " Best model: ARIMA(5,1,0) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11083.22\n",
      " ARIMA(1,1,0) with drift         : -11531.66\n",
      " ARIMA(0,1,1) with drift         : Inf\n",
      " ARIMA(0,1,0)                    : -11085.23\n",
      " ARIMA(2,1,0) with drift         : -11702.3\n",
      " ARIMA(3,1,0) with drift         : -11803.96\n",
      " ARIMA(4,1,0) with drift         : -11873.01\n",
      " ARIMA(5,1,0) with drift         : -11932.64\n",
      " ARIMA(5,1,1) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -12176.87\n",
      " ARIMA(3,1,1) with drift         : -12225.27\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : -12224.14\n",
      " ARIMA(3,1,1)                    : -12226.64\n",
      " ARIMA(2,1,1)                    : Inf\n",
      " ARIMA(3,1,0)                    : -11805.97\n",
      " ARIMA(4,1,1)                    : -12178.72\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(2,1,0)                    : -11704.31\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(4,1,0)                    : -11875.02\n",
      " ARIMA(4,1,2)                    : -12226.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,1)                    : Inf\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,1) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,1) with drift         : Inf\n",
      " ARIMA(5,1,0) with drift         : -11941.58\n",
      "\n",
      " Best model: ARIMA(5,1,0) with drift         \n",
      "\n",
      "[1] \"58 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12251.68\n",
      " ARIMA(0,0,0) with non-zero mean : -12234.09\n",
      " ARIMA(1,0,0) with non-zero mean : -12231.88\n",
      " ARIMA(0,0,1) with non-zero mean : -12232.91\n",
      " ARIMA(0,0,0) with zero mean     : 5006.075\n",
      " ARIMA(1,0,2) with non-zero mean : -12235.91\n",
      " ARIMA(2,0,1) with non-zero mean : -12236.01\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(1,0,1) with non-zero mean : -12229.89\n",
      " ARIMA(1,0,3) with non-zero mean : -12236.52\n",
      " ARIMA(3,0,1) with non-zero mean : -12238.02\n",
      " ARIMA(3,0,3) with non-zero mean : -12245.63\n",
      " ARIMA(2,0,2) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12250.12\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12248.6\n",
      " ARIMA(0,0,0) with non-zero mean : -12239.8\n",
      " ARIMA(1,0,0) with non-zero mean : -12238.61\n",
      " ARIMA(0,0,1) with non-zero mean : -12238.37\n",
      " ARIMA(0,0,0) with zero mean     : 5006.062\n",
      " ARIMA(1,0,2) with non-zero mean : -12238.42\n",
      " ARIMA(2,0,1) with non-zero mean : -12241.93\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12246.79\n",
      " ARIMA(1,0,1) with non-zero mean : -12236.76\n",
      " ARIMA(1,0,3) with non-zero mean : -12239.79\n",
      " ARIMA(3,0,1) with non-zero mean : -12241.64\n",
      " ARIMA(3,0,3) with non-zero mean : -12248.27\n",
      " ARIMA(2,0,2) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,1) with non-zero mean : -12242.08\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12094.67\n",
      " ARIMA(0,0,0) with non-zero mean : -12100.64\n",
      " ARIMA(1,0,0) with non-zero mean : -12098.21\n",
      " ARIMA(0,0,1) with non-zero mean : -12098.75\n",
      " ARIMA(0,0,0) with zero mean     : 5006.235\n",
      " ARIMA(1,0,1) with non-zero mean : -12096.41\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,0,0) with non-zero mean : -12100.64\n",
      "\n",
      " Best model: ARIMA(0,0,0) with non-zero mean \n",
      "\n",
      "[1] \"69 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12016.64\n",
      " ARIMA(0,0,0) with non-zero mean : -12015.3\n",
      " ARIMA(1,0,0) with non-zero mean : -12012.33\n",
      " ARIMA(0,0,1) with non-zero mean : -12013.29\n",
      " ARIMA(0,0,0) with zero mean     : 5006.193\n",
      " ARIMA(1,0,2) with non-zero mean : -12015.4\n",
      " ARIMA(2,0,1) with non-zero mean : -12014.57\n",
      " ARIMA(3,0,2) with non-zero mean : -12014\n",
      " ARIMA(2,0,3) with non-zero mean : -12014.86\n",
      " ARIMA(1,0,1) with non-zero mean : Inf\n",
      " ARIMA(1,0,3) with non-zero mean : -12014.45\n",
      " ARIMA(3,0,1) with non-zero mean : -12011.96\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12016.09\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11963.77\n",
      " ARIMA(0,0,0) with non-zero mean : -11964.43\n",
      " ARIMA(1,0,0) with non-zero mean : -11962.78\n",
      " ARIMA(0,0,1) with non-zero mean : -11962.46\n",
      " ARIMA(0,0,0) with zero mean     : 5006.209\n",
      " ARIMA(1,0,1) with non-zero mean : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,0,0) with non-zero mean : -11964.43\n",
      "\n",
      " Best model: ARIMA(0,0,0) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11918.1\n",
      " ARIMA(0,0,0) with non-zero mean : -11921.05\n",
      " ARIMA(1,0,0) with non-zero mean : -11918.98\n",
      " ARIMA(0,0,1) with non-zero mean : -11919.04\n",
      " ARIMA(0,0,0) with zero mean     : 5006.15\n",
      " ARIMA(1,0,1) with non-zero mean : -11916.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,0,0) with non-zero mean : -11921.05\n",
      "\n",
      " Best model: ARIMA(0,0,0) with non-zero mean \n",
      "\n",
      "[1] \"81 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11916.84\n",
      " ARIMA(0,0,0) with non-zero mean : -11917.93\n",
      " ARIMA(1,0,0) with non-zero mean : -11916.13\n",
      " ARIMA(0,0,1) with non-zero mean : -11915.94\n",
      " ARIMA(0,0,0) with zero mean     : 5006.088\n",
      " ARIMA(1,0,1) with non-zero mean : -11914.12\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,0,0) with non-zero mean : -11917.93\n",
      "\n",
      " Best model: ARIMA(0,0,0) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -11936.24\n",
      " ARIMA(1,0,0) with non-zero mean : -11933.57\n",
      " ARIMA(0,0,1) with non-zero mean : -11934.4\n",
      " ARIMA(0,0,0) with zero mean     : 5005.97\n",
      " ARIMA(1,0,1) with non-zero mean : -11932.03\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,0,0) with non-zero mean : -11936.24\n",
      "\n",
      " Best model: ARIMA(0,0,0) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11928.11\n",
      " ARIMA(0,0,0) with non-zero mean : -11933.58\n",
      " ARIMA(1,0,0) with non-zero mean : -11931.07\n",
      " ARIMA(0,0,1) with non-zero mean : -11931.86\n",
      " ARIMA(0,0,0) with zero mean     : 5005.834\n",
      " ARIMA(1,0,1) with non-zero mean : -11929.34\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,0,0) with non-zero mean : -11933.58\n",
      "\n",
      " Best model: ARIMA(0,0,0) with non-zero mean \n",
      "\n",
      "[1] \"92 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11919.83\n",
      " ARIMA(0,0,0) with non-zero mean : -11907.75\n",
      " ARIMA(1,0,0) with non-zero mean : -11906.65\n",
      " ARIMA(0,0,1) with non-zero mean : -11905.84\n",
      " ARIMA(0,0,0) with zero mean     : 5005.907\n",
      " ARIMA(1,0,2) with non-zero mean : -11918.83\n",
      " ARIMA(2,0,1) with non-zero mean : -11921.15\n",
      " ARIMA(1,0,1) with non-zero mean : -11919.09\n",
      " ARIMA(2,0,0) with non-zero mean : -11913.66\n",
      " ARIMA(3,0,1) with non-zero mean : -11917.63\n",
      " ARIMA(3,0,0) with non-zero mean : -11912.06\n",
      " ARIMA(3,0,2) with non-zero mean : -11919.91\n",
      " ARIMA(2,0,1) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with non-zero mean : -11907.31\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11900.47\n",
      " ARIMA(0,0,0) with non-zero mean : -11904.31\n",
      " ARIMA(1,0,0) with non-zero mean : -11901.36\n",
      " ARIMA(0,0,1) with non-zero mean : -11902.31\n",
      " ARIMA(0,0,0) with zero mean     : 5005.986\n",
      " ARIMA(1,0,1) with non-zero mean : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,0,0) with non-zero mean : -11904.31\n",
      "\n",
      " Best model: ARIMA(0,0,0) with non-zero mean \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m03 <- my.tsCV(train, cv.forecast, h=hori, window=wind, step=peri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38e3abd7-a70b-465f-8b5c-e5b2ec4d4175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 1997-12-31\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m03\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3603b7c1-1626-4d08-a2f0-35ea2db6d2db",
   "metadata": {},
   "source": [
    "# Regression with ARIMA errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f906437-133e-45c7-853e-eecac2d20071",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e752fc6c-14a7-4d74-9e09-50c41a773544",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast <- function(x, h, xreg=NULL, xreg.msize=NULL) {\n",
    "    \n",
    "    if (!is.null(xreg)) {\n",
    "        \n",
    "        if (is.null(xreg.msize)) {\n",
    "            xreg.m <- xreg # calc mean for future with all the xreg\n",
    "        } else {\n",
    "            # calc mean for future with xreg of length xreg.mszie\n",
    "            xreg.m <- tail(xreg, n=xreg.msize)\n",
    "        }\n",
    "        \n",
    "        if (is.null(dim(xreg))) {\n",
    "            xreg.h <- mean(xreg.m)\n",
    "        } else {\n",
    "            xreg.h <- colMeans(xreg.m)  \n",
    "        }\n",
    "        \n",
    "        xreg.h <- data.frame(xreg.h)\n",
    "        colnames(xreg.h) <- colnames(NA)\n",
    "        #colnames(xreg.h) <- colnames(xreg) # error with multiple xreg\n",
    "        xreg.h <- t(xreg.h)\n",
    "        xreg.h <- as.ts(xreg.h[rep(seq_len(nrow(xreg.h)), h), ])\n",
    "        \n",
    "    } else {\n",
    "        xreg.h <- NULL\n",
    "    }\n",
    "    \n",
    "    fc <- forecast(auto.arima(x, trace=TRUE, ic='aicc', seasonal=FALSE, \n",
    "                              xreg=xreg, \n",
    "                              #lambda=\"auto\" # not for negative value\n",
    "                              ), h=h, xreg=xreg.h)\n",
    "    return(fc)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea1c4d3f-7813-4086-b886-e153684a2353",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13090.73\n",
      " Regression with ARIMA(0,0,0) errors : -12481.33\n",
      " Regression with ARIMA(1,0,0) errors : -12481.38\n",
      " Regression with ARIMA(0,0,1) errors : -12480.83\n",
      " Regression with ARIMA(0,0,0) errors : -12381.52\n",
      " Regression with ARIMA(1,0,2) errors : -12482.89\n",
      " Regression with ARIMA(2,0,1) errors : -12481.71\n",
      " Regression with ARIMA(3,0,2) errors : -13113.99\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(4,0,2) errors : -13085.22\n",
      " Regression with ARIMA(3,0,3) errors : -13121.87\n",
      " Regression with ARIMA(2,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -13113.33\n",
      " Regression with ARIMA(3,0,4) errors : -13121.99\n",
      " Regression with ARIMA(2,0,4) errors : -13095.36\n",
      " Regression with ARIMA(4,0,4) errors : -13124.65\n",
      " Regression with ARIMA(5,0,4) errors : -13115.73\n",
      " Regression with ARIMA(4,0,5) errors : -13124.6\n",
      " Regression with ARIMA(3,0,5) errors : -13123.9\n",
      " Regression with ARIMA(5,0,3) errors : -13110.75\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13047.39\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13119.29\n",
      " Regression with ARIMA(0,0,0) errors : -12489.66\n",
      " Regression with ARIMA(1,0,0) errors : -12489.5\n",
      " Regression with ARIMA(0,0,1) errors : -12489.19\n",
      " Regression with ARIMA(0,0,0) errors : -12389.96\n",
      " Regression with ARIMA(1,0,2) errors : -12486.02\n",
      " Regression with ARIMA(2,0,1) errors : -13079.92\n",
      " Regression with ARIMA(3,0,2) errors : -13137.1\n",
      " Regression with ARIMA(3,0,1) errors : -13084.01\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13132.05\n",
      " Regression with ARIMA(2,0,3) errors : -13120.51\n",
      " Regression with ARIMA(4,0,1) errors : -13104.28\n",
      " Regression with ARIMA(4,0,3) errors : -13132.38\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13128.53\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "[1] \"9 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13067.93\n",
      " Regression with ARIMA(0,0,0) errors : -12490.69\n",
      " Regression with ARIMA(1,0,0) errors : -12489.52\n",
      " Regression with ARIMA(0,0,1) errors : -12489.79\n",
      " Regression with ARIMA(0,0,0) errors : -12390.91\n",
      " Regression with ARIMA(1,0,2) errors : -13071.61\n",
      " Regression with ARIMA(0,0,2) errors : -12487.78\n",
      " Regression with ARIMA(1,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,3) errors : -13084.25\n",
      " Regression with ARIMA(0,0,3) errors : -12485.98\n",
      " Regression with ARIMA(2,0,3) errors : -13124.67\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,4) errors : -13088.13\n",
      " Regression with ARIMA(1,0,4) errors : -13086.83\n",
      " Regression with ARIMA(3,0,2) errors : -12490.65\n",
      " Regression with ARIMA(3,0,4) errors : -13123.75\n",
      " Regression with ARIMA(2,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,3) errors : -13072.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13075.33\n",
      " Regression with ARIMA(0,1,0) errors : -12859.84\n",
      " Regression with ARIMA(1,1,0) errors : -13018.33\n",
      " Regression with ARIMA(0,1,1) errors : -13051.45\n",
      " Regression with ARIMA(0,1,0) errors : -12861.82\n",
      " Regression with ARIMA(1,1,2) errors : -13076.68\n",
      " Regression with ARIMA(0,1,2) errors : -13055\n",
      " Regression with ARIMA(1,1,1) errors : -13052.98\n",
      " Regression with ARIMA(1,1,3) errors : -13076.35\n",
      " Regression with ARIMA(0,1,3) errors : -13064.81\n",
      " Regression with ARIMA(2,1,1) errors : -13057.41\n",
      " Regression with ARIMA(2,1,3) errors : -13073.19\n",
      " Regression with ARIMA(1,1,2) errors : -13078.7\n",
      " Regression with ARIMA(0,1,2) errors : -13056.97\n",
      " Regression with ARIMA(1,1,1) errors : -13054.95\n",
      " Regression with ARIMA(2,1,2) errors : -13077.34\n",
      " Regression with ARIMA(1,1,3) errors : -13078.36\n",
      " Regression with ARIMA(0,1,1) errors : -13053.41\n",
      " Regression with ARIMA(0,1,3) errors : -13066.79\n",
      " Regression with ARIMA(2,1,1) errors : -13059.4\n",
      " Regression with ARIMA(2,1,3) errors : -13075.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,2) errors : -13091.4\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,2) errors \n",
      "\n",
      "[1] \"18 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13062.5\n",
      " Regression with ARIMA(0,1,0) errors : -12857.49\n",
      " Regression with ARIMA(1,1,0) errors : -13017.93\n",
      " Regression with ARIMA(0,1,1) errors : -13050.83\n",
      " Regression with ARIMA(0,1,0) errors : -12859.5\n",
      " Regression with ARIMA(1,1,2) errors : -13076.79\n",
      " Regression with ARIMA(0,1,2) errors : -13054.82\n",
      " Regression with ARIMA(1,1,1) errors : -13052.11\n",
      " Regression with ARIMA(1,1,3) errors : -13076.3\n",
      " Regression with ARIMA(0,1,3) errors : -13064.36\n",
      " Regression with ARIMA(2,1,1) errors : -13057.4\n",
      " Regression with ARIMA(2,1,3) errors : -13071.36\n",
      " Regression with ARIMA(1,1,2) errors : -13078.79\n",
      " Regression with ARIMA(0,1,2) errors : -13056.82\n",
      " Regression with ARIMA(1,1,1) errors : -13054.1\n",
      " Regression with ARIMA(2,1,2) errors : -13064.53\n",
      " Regression with ARIMA(1,1,3) errors : -13078.3\n",
      " Regression with ARIMA(0,1,1) errors : -13052.83\n",
      " Regression with ARIMA(0,1,3) errors : -13066.37\n",
      " Regression with ARIMA(2,1,1) errors : -13059.41\n",
      " Regression with ARIMA(2,1,3) errors : -13073.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,2) errors : -13091.05\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13056.63\n",
      " Regression with ARIMA(0,1,0) errors : -12851.19\n",
      " Regression with ARIMA(1,1,0) errors : -13018.62\n",
      " Regression with ARIMA(0,1,1) errors : -13044.14\n",
      " Regression with ARIMA(0,1,0) errors : -12853.2\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -13058.58\n",
      " Regression with ARIMA(1,1,1) errors : -13050.26\n",
      " Regression with ARIMA(2,1,0) errors : -13060.09\n",
      " Regression with ARIMA(3,1,0) errors : -13059.86\n",
      " Regression with ARIMA(3,1,1) errors : -13058.39\n",
      " Regression with ARIMA(2,1,0) errors : -13062.1\n",
      " Regression with ARIMA(1,1,0) errors : -13020.63\n",
      " Regression with ARIMA(3,1,0) errors : -13061.87\n",
      " Regression with ARIMA(2,1,1) errors : -13060.59\n",
      " Regression with ARIMA(1,1,1) errors : -13052.28\n",
      " Regression with ARIMA(3,1,1) errors : -13060.41\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,0) errors : -13065.26\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,0) errors \n",
      "\n",
      "[1] \"27 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13083.43\n",
      " Regression with ARIMA(0,1,0) errors : -12862.09\n",
      " Regression with ARIMA(1,1,0) errors : -13024.52\n",
      " Regression with ARIMA(0,1,1) errors : -13055.26\n",
      " Regression with ARIMA(0,1,0) errors : -12864.1\n",
      " Regression with ARIMA(1,1,2) errors : -13081.05\n",
      " Regression with ARIMA(2,1,1) errors : -13062.71\n",
      " Regression with ARIMA(3,1,2) errors : -13079.48\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : -13058.83\n",
      " Regression with ARIMA(1,1,3) errors : -13081.32\n",
      " Regression with ARIMA(3,1,1) errors : -13063.44\n",
      " Regression with ARIMA(3,1,3) errors : -13082.21\n",
      " Regression with ARIMA(2,1,2) errors : -13085.44\n",
      " Regression with ARIMA(1,1,2) errors : -13083.04\n",
      " Regression with ARIMA(2,1,1) errors : -13064.71\n",
      " Regression with ARIMA(3,1,2) errors : -13081.5\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : -13060.83\n",
      " Regression with ARIMA(1,1,3) errors : -13083.32\n",
      " Regression with ARIMA(3,1,1) errors : -13065.45\n",
      " Regression with ARIMA(3,1,3) errors : -13084.22\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13096.27\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13085.12\n",
      " Regression with ARIMA(0,1,0) errors : -12863.89\n",
      " Regression with ARIMA(1,1,0) errors : -13025.23\n",
      " Regression with ARIMA(0,1,1) errors : -13057.19\n",
      " Regression with ARIMA(0,1,0) errors : -12865.9\n",
      " Regression with ARIMA(1,1,2) errors : -13081.19\n",
      " Regression with ARIMA(2,1,1) errors : -13061.76\n",
      " Regression with ARIMA(3,1,2) errors : -13063\n",
      " Regression with ARIMA(2,1,3) errors : -13088.64\n",
      " Regression with ARIMA(1,1,3) errors : -13080.92\n",
      " Regression with ARIMA(3,1,3) errors : -13080.88\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : -13079.26\n",
      " Regression with ARIMA(3,1,4) errors : -13086.91\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,3) errors : -13093.73\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,3) errors \n",
      "\n",
      "[1] \"36 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13077.89\n",
      " Regression with ARIMA(0,1,0) errors : -12867.73\n",
      " Regression with ARIMA(1,1,0) errors : -13033\n",
      " Regression with ARIMA(0,1,1) errors : -13059.31\n",
      " Regression with ARIMA(0,1,0) errors : -12869.74\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -13071.18\n",
      " Regression with ARIMA(3,1,2) errors : -13092.24\n",
      " Regression with ARIMA(3,1,1) errors : -13069.54\n",
      " Regression with ARIMA(4,1,2) errors : -13102.79\n",
      " Regression with ARIMA(4,1,1) errors : -13081.82\n",
      " Regression with ARIMA(5,1,2) errors : -13080.31\n",
      " Regression with ARIMA(4,1,3) errors : -13088.54\n",
      " Regression with ARIMA(3,1,3) errors : -13086.94\n",
      " Regression with ARIMA(5,1,1) errors : -13076.97\n",
      " Regression with ARIMA(5,1,3) errors : -13083.8\n",
      " Regression with ARIMA(4,1,2) errors : -13104.8\n",
      " Regression with ARIMA(3,1,2) errors : -13094.25\n",
      " Regression with ARIMA(4,1,1) errors : -13083.84\n",
      " Regression with ARIMA(5,1,2) errors : -13082.34\n",
      " Regression with ARIMA(4,1,3) errors : -13090.56\n",
      " Regression with ARIMA(3,1,1) errors : -13071.56\n",
      " Regression with ARIMA(3,1,3) errors : -13088.97\n",
      " Regression with ARIMA(5,1,1) errors : -13078.99\n",
      " Regression with ARIMA(5,1,3) errors : -13085.81\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,1,2) errors : -13115.72\n",
      "\n",
      " Best model: Regression with ARIMA(4,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -12495.14\n",
      " Regression with ARIMA(1,0,0) errors : -12497.29\n",
      " Regression with ARIMA(0,0,1) errors : -12495.71\n",
      " Regression with ARIMA(0,0,0) errors : -12398.89\n",
      " Regression with ARIMA(2,0,0) errors : -12494.62\n",
      " Regression with ARIMA(1,0,1) errors : -12495.31\n",
      " Regression with ARIMA(2,0,1) errors : -12492.61\n",
      " Regression with ARIMA(1,0,0) errors : -12398.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -12495.73\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "[1] \"45 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12494.59\n",
      " Regression with ARIMA(0,0,0) errors : -12494.74\n",
      " Regression with ARIMA(1,0,0) errors : -12494.28\n",
      " Regression with ARIMA(0,0,1) errors : -12494.96\n",
      " Regression with ARIMA(0,0,0) errors : -12397.83\n",
      " Regression with ARIMA(1,0,1) errors : Inf\n",
      " Regression with ARIMA(0,0,2) errors : -12493.11\n",
      " Regression with ARIMA(1,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,1) errors : -12397.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,1) errors : -12494.96\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -12481.47\n",
      " Regression with ARIMA(1,0,0) errors : -12481.45\n",
      " Regression with ARIMA(0,0,1) errors : -12481.66\n",
      " Regression with ARIMA(0,0,0) errors : -12384.65\n",
      " Regression with ARIMA(1,0,1) errors : -12479.63\n",
      " Regression with ARIMA(0,0,2) errors : -12480\n",
      " Regression with ARIMA(1,0,2) errors : -12480.01\n",
      " Regression with ARIMA(0,0,1) errors : -12384.15\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,1) errors : -12481.66\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,1) errors \n",
      "\n",
      "[1] \"55 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13023.72\n",
      " Regression with ARIMA(0,1,0) errors : -12800.73\n",
      " Regression with ARIMA(1,1,0) errors : -12976.44\n",
      " Regression with ARIMA(0,1,1) errors : -12998\n",
      " Regression with ARIMA(0,1,0) errors : -12802.74\n",
      " Regression with ARIMA(1,1,2) errors : -13014\n",
      " Regression with ARIMA(2,1,1) errors : -13011.83\n",
      " Regression with ARIMA(3,1,2) errors : -13013.24\n",
      " Regression with ARIMA(2,1,3) errors : -13028.89\n",
      " Regression with ARIMA(1,1,3) errors : -13016.12\n",
      " Regression with ARIMA(3,1,3) errors : -13027.42\n",
      " Regression with ARIMA(2,1,4) errors : -13015.58\n",
      " Regression with ARIMA(1,1,4) errors : -13017.13\n",
      " Regression with ARIMA(3,1,4) errors : -13032.6\n",
      " Regression with ARIMA(4,1,4) errors : -13041.3\n",
      " Regression with ARIMA(4,1,3) errors : -13041.76\n",
      " Regression with ARIMA(4,1,2) errors : -13025.99\n",
      " Regression with ARIMA(5,1,3) errors : -13048.62\n",
      " Regression with ARIMA(5,1,2) errors : -13038.65\n",
      " Regression with ARIMA(5,1,4) errors : -13047.51\n",
      " Regression with ARIMA(5,1,3) errors : -13050.64\n",
      " Regression with ARIMA(4,1,3) errors : -13043.77\n",
      " Regression with ARIMA(5,1,2) errors : -13040.68\n",
      " Regression with ARIMA(5,1,4) errors : -13049.5\n",
      " Regression with ARIMA(4,1,2) errors : -13028\n",
      " Regression with ARIMA(4,1,4) errors : -13043.34\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,3) errors : -13056.01\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -12446.62\n",
      " Regression with ARIMA(1,0,0) errors : -12446.34\n",
      " Regression with ARIMA(0,0,1) errors : -12445.86\n",
      " Regression with ARIMA(0,0,0) errors : -12352.07\n",
      " Regression with ARIMA(1,0,1) errors : -12444.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -12446.62\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "[1] \"64 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12706.42\n",
      " Regression with ARIMA(0,1,0) errors : -12457.66\n",
      " Regression with ARIMA(1,1,0) errors : -12668.51\n",
      " Regression with ARIMA(0,1,1) errors : -12695.81\n",
      " Regression with ARIMA(0,1,0) errors : -12459.65\n",
      " Regression with ARIMA(1,1,2) errors : -12708.71\n",
      " Regression with ARIMA(0,1,2) errors : -12704.41\n",
      " Regression with ARIMA(1,1,1) errors : -12702.2\n",
      " Regression with ARIMA(1,1,3) errors : -12707.24\n",
      " Regression with ARIMA(0,1,3) errors : -12704.03\n",
      " Regression with ARIMA(2,1,1) errors : -12699.84\n",
      " Regression with ARIMA(2,1,3) errors : -12713.23\n",
      " Regression with ARIMA(3,1,3) errors : -12711.48\n",
      " Regression with ARIMA(2,1,4) errors : -12712.54\n",
      " Regression with ARIMA(1,1,4) errors : -12713.62\n",
      " Regression with ARIMA(0,1,4) errors : -12706.53\n",
      " Regression with ARIMA(1,1,5) errors : -12711.62\n",
      " Regression with ARIMA(0,1,5) errors : -12705.05\n",
      " Regression with ARIMA(2,1,5) errors : -12711.59\n",
      " Regression with ARIMA(1,1,4) errors : -12715.63\n",
      " Regression with ARIMA(0,1,4) errors : -12708.53\n",
      " Regression with ARIMA(1,1,3) errors : -12709.25\n",
      " Regression with ARIMA(2,1,4) errors : -12714.52\n",
      " Regression with ARIMA(1,1,5) errors : -12713.63\n",
      " Regression with ARIMA(0,1,3) errors : -12706.03\n",
      " Regression with ARIMA(0,1,5) errors : -12707.05\n",
      " Regression with ARIMA(2,1,3) errors : -12715.25\n",
      " Regression with ARIMA(2,1,5) errors : -12713.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,4) errors : -12726.2\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12214.9\n",
      " Regression with ARIMA(0,0,0) errors : -12215.87\n",
      " Regression with ARIMA(1,0,0) errors : -12213.03\n",
      " Regression with ARIMA(0,0,1) errors : -12213.88\n",
      " Regression with ARIMA(0,0,0) errors : -12125.87\n",
      " Regression with ARIMA(1,0,1) errors : -12211.02\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -12215.87\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "[1] \"73 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12153.37\n",
      " Regression with ARIMA(0,0,0) errors : -12161.2\n",
      " Regression with ARIMA(1,0,0) errors : -12159.99\n",
      " Regression with ARIMA(0,0,1) errors : -12159.19\n",
      " Regression with ARIMA(0,0,0) errors : -12069.07\n",
      " Regression with ARIMA(1,0,1) errors : -12158.08\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -12161.2\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -12115.41\n",
      " Regression with ARIMA(1,0,0) errors : -12112.82\n",
      " Regression with ARIMA(0,0,1) errors : -12113.54\n",
      " Regression with ARIMA(0,0,0) errors : -12029.77\n",
      " Regression with ARIMA(1,0,1) errors : -12110.81\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -12115.41\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "[1] \"82 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12098.6\n",
      " Regression with ARIMA(0,0,0) errors : -12107.62\n",
      " Regression with ARIMA(1,0,0) errors : -12105.56\n",
      " Regression with ARIMA(0,0,1) errors : -12105.85\n",
      " Regression with ARIMA(0,0,0) errors : -12022.63\n",
      " Regression with ARIMA(1,0,1) errors : -12103.55\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -12107.62\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12124.59\n",
      " Regression with ARIMA(0,0,0) errors : -12125.03\n",
      " Regression with ARIMA(1,0,0) errors : -12124.15\n",
      " Regression with ARIMA(0,0,1) errors : -12123.46\n",
      " Regression with ARIMA(0,0,0) errors : -12041.75\n",
      " Regression with ARIMA(1,0,1) errors : -12122.15\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -12125.03\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "[1] \"91 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12107.83\n",
      " Regression with ARIMA(0,0,0) errors : -12114.31\n",
      " Regression with ARIMA(1,0,0) errors : -12111.77\n",
      " Regression with ARIMA(0,0,1) errors : -12112.67\n",
      " Regression with ARIMA(0,0,0) errors : -12029.04\n",
      " Regression with ARIMA(1,0,1) errors : -12109.75\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -12114.31\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -12095.7\n",
      " Regression with ARIMA(1,0,0) errors : -12094.23\n",
      " Regression with ARIMA(0,0,1) errors : -12093.78\n",
      " Regression with ARIMA(0,0,0) errors : -12007.69\n",
      " Regression with ARIMA(1,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -12095.7\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "[1] \"100 % done.\"\n"
     ]
    }
   ],
   "source": [
    "result.m04.1 <- my.tsCV(trainx[,1], cv.forecast, h=hori, window=wind, step=peri,\n",
    "                      silent=F,\n",
    "                      xreg=trainx[,2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7291e1f-bef0-4b61-8532-f90be11e5237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 1997-12-31\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m04.1\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99382fb5-38ae-4e21-b42c-9ecea62e9cb9",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d38ec38-3738-4949-81d6-4552da4fec51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              y      rsi     bbands       macd\n",
      "min -0.07112747 18.08944 -0.3975811 -0.9335563\n",
      "max  0.04988692 84.90071  1.3157451  1.0604552\n"
     ]
    }
   ],
   "source": [
    "mins <- t(apply(trainx, 2, min))\n",
    "maxs <- t(apply(trainx, 2, max))\n",
    "print(data.frame(rbind(mins, maxs), row.names=c('min','max')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "739b34a5-aba7-4e1a-952c-246fd27ec20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast.norm <- function(x, h, xreg=NULL, xreg.msize=NULL) {\n",
    "    \n",
    "    x <- my.minmaxscale(x)\n",
    "    sc <- attr(x, 'scaled:center')\n",
    "    ss <- attr(x, 'scaled:scale')\n",
    "    \n",
    "    if (!is.null(xreg)) {\n",
    "        xreg <- my.minmaxscale(xreg)\n",
    "        \n",
    "        if (is.null(xreg.msize)) {\n",
    "            xreg.m <- xreg # calc mean for future with all the xreg\n",
    "        } else {\n",
    "            # calc mean for future with xreg of length xreg.mszie\n",
    "            xreg.m <- tail(xreg, n=xreg.msize)\n",
    "        }\n",
    "        \n",
    "        if (is.null(dim(xreg))) {\n",
    "            xreg.h <- mean(xreg.m)\n",
    "        } else {\n",
    "            xreg.h <- colMeans(xreg.m)  \n",
    "        }\n",
    "        \n",
    "        xreg.h <- data.frame(xreg.h)\n",
    "        colnames(xreg.h) <- colnames(NA)\n",
    "        #colnames(xreg.h) <- colnames(xreg) # error with multiple xreg\n",
    "        xreg.h <- t(xreg.h)\n",
    "        xreg.h <- as.ts(xreg.h[rep(seq_len(nrow(xreg.h)), h), ])\n",
    "        \n",
    "    } else {\n",
    "        xreg.h <- NULL\n",
    "    }\n",
    "    \n",
    "    fc <- forecast(auto.arima(x, trace=TRUE, ic='aicc', seasonal=FALSE, \n",
    "                              xreg=xreg, \n",
    "                              #lambda=\"auto\" # not for negative value\n",
    "                              ), h=h, xreg=xreg.h)\n",
    "    fc.m <- my.minmaxscale(fc$mean, sc, ss)\n",
    "    fc <- list(method=fc$method, mean=fc.m)\n",
    "    return(fc)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58089be8-9eb2-42e3-83b3-2c349e1d7b5b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -3194.691\n",
      " Regression with ARIMA(0,0,0) errors : -2585.311\n",
      " Regression with ARIMA(1,0,0) errors : -2585.367\n",
      " Regression with ARIMA(0,0,1) errors : -2584.812\n",
      " Regression with ARIMA(0,0,0) errors : -2587.322\n",
      " Regression with ARIMA(1,0,2) errors : -2586.88\n",
      " Regression with ARIMA(2,0,1) errors : -2585.699\n",
      " Regression with ARIMA(3,0,2) errors : -3217.866\n",
      " Regression with ARIMA(3,0,1) errors : -2582.431\n",
      " Regression with ARIMA(4,0,2) errors : -3189.202\n",
      " Regression with ARIMA(3,0,3) errors : -3228.402\n",
      " Regression with ARIMA(2,0,3) errors : -3195.144\n",
      " Regression with ARIMA(4,0,3) errors : -3221.289\n",
      " Regression with ARIMA(3,0,4) errors : -3227.064\n",
      " Regression with ARIMA(2,0,4) errors : -3199.34\n",
      " Regression with ARIMA(4,0,4) errors : -3228.633\n",
      " Regression with ARIMA(5,0,4) errors : -3219.718\n",
      " Regression with ARIMA(4,0,5) errors : -3228.581\n",
      " Regression with ARIMA(3,0,5) errors : -3227.553\n",
      " Regression with ARIMA(5,0,3) errors : -3214.763\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -3221.943\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,4) errors : -3182.559\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -3223.254\n",
      " Regression with ARIMA(0,0,0) errors : -2593.649\n",
      " Regression with ARIMA(1,0,0) errors : -2593.483\n",
      " Regression with ARIMA(0,0,1) errors : -2593.178\n",
      " Regression with ARIMA(0,0,0) errors : -2595.661\n",
      " Regression with ARIMA(1,0,2) errors : -2590.004\n",
      " Regression with ARIMA(2,0,1) errors : -3183.871\n",
      " Regression with ARIMA(3,0,2) errors : -3241.239\n",
      " Regression with ARIMA(3,0,1) errors : -3187.993\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -3232.549\n",
      " Regression with ARIMA(2,0,3) errors : -3224.494\n",
      " Regression with ARIMA(4,0,1) errors : -3208.262\n",
      " Regression with ARIMA(4,0,3) errors : -3236.329\n",
      " Regression with ARIMA(3,0,2) errors : -3185.325\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -3230.717\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,3) errors \n",
      "\n",
      "[1] \"9 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -3171.909\n",
      " Regression with ARIMA(0,0,0) errors : -2594.675\n",
      " Regression with ARIMA(1,0,0) errors : -2593.506\n",
      " Regression with ARIMA(0,0,1) errors : -2593.775\n",
      " Regression with ARIMA(0,0,0) errors : -2596.686\n",
      " Regression with ARIMA(1,0,2) errors : -3175.593\n",
      " Regression with ARIMA(0,0,2) errors : -2591.769\n",
      " Regression with ARIMA(1,0,1) errors : -3170.39\n",
      " Regression with ARIMA(1,0,3) errors : -3188.234\n",
      " Regression with ARIMA(0,0,3) errors : -2589.961\n",
      " Regression with ARIMA(2,0,3) errors : -3226.958\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,4) errors : -3192.117\n",
      " Regression with ARIMA(1,0,4) errors : -3190.815\n",
      " Regression with ARIMA(3,0,2) errors : -2596.22\n",
      " Regression with ARIMA(3,0,4) errors : -3227.705\n",
      " Regression with ARIMA(4,0,4) errors : -3226.477\n",
      " Regression with ARIMA(3,0,5) errors : -3225.675\n",
      " Regression with ARIMA(2,0,5) errors : -3192.121\n",
      " Regression with ARIMA(4,0,3) errors : -3211.53\n",
      " Regression with ARIMA(4,0,5) errors : -3224.519\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -3176.019\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -3190.535\n",
      " Regression with ARIMA(0,1,0) errors : -2975.043\n",
      " Regression with ARIMA(1,1,0) errors : -3133.54\n",
      " Regression with ARIMA(0,1,1) errors : -3166.657\n",
      " Regression with ARIMA(0,1,0) errors : -2977.026\n",
      " Regression with ARIMA(1,1,2) errors : -3191.898\n",
      " Regression with ARIMA(0,1,2) errors : -3170.21\n",
      " Regression with ARIMA(1,1,1) errors : -3168.184\n",
      " Regression with ARIMA(1,1,3) errors : -3191.556\n",
      " Regression with ARIMA(0,1,3) errors : -3180.018\n",
      " Regression with ARIMA(2,1,1) errors : -3172.618\n",
      " Regression with ARIMA(2,1,3) errors : -3188.374\n",
      " Regression with ARIMA(1,1,2) errors : -3193.904\n",
      " Regression with ARIMA(0,1,2) errors : -3172.176\n",
      " Regression with ARIMA(1,1,1) errors : -3170.157\n",
      " Regression with ARIMA(2,1,2) errors : -3192.542\n",
      " Regression with ARIMA(1,1,3) errors : -3193.562\n",
      " Regression with ARIMA(0,1,1) errors : -3168.617\n",
      " Regression with ARIMA(0,1,3) errors : -3181.994\n",
      " Regression with ARIMA(2,1,1) errors : -3174.6\n",
      " Regression with ARIMA(2,1,3) errors : -3190.343\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,2) errors : -3200.99\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,2) errors \n",
      "\n",
      "[1] \"18 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -3177.718\n",
      " Regression with ARIMA(0,1,0) errors : -2972.696\n",
      " Regression with ARIMA(1,1,0) errors : -3133.132\n",
      " Regression with ARIMA(0,1,1) errors : -3166.035\n",
      " Regression with ARIMA(0,1,0) errors : -2974.701\n",
      " Regression with ARIMA(1,1,2) errors : -3191.996\n",
      " Regression with ARIMA(0,1,2) errors : -3170.029\n",
      " Regression with ARIMA(1,1,1) errors : -3167.312\n",
      " Regression with ARIMA(1,1,3) errors : -3191.502\n",
      " Regression with ARIMA(0,1,3) errors : -3179.568\n",
      " Regression with ARIMA(2,1,1) errors : -3172.604\n",
      " Regression with ARIMA(2,1,3) errors : -3186.57\n",
      " Regression with ARIMA(1,1,2) errors : -3193.995\n",
      " Regression with ARIMA(0,1,2) errors : -3172.031\n",
      " Regression with ARIMA(1,1,1) errors : -3169.31\n",
      " Regression with ARIMA(2,1,2) errors : -3179.738\n",
      " Regression with ARIMA(1,1,3) errors : -3193.505\n",
      " Regression with ARIMA(0,1,1) errors : -3168.033\n",
      " Regression with ARIMA(0,1,3) errors : -3181.574\n",
      " Regression with ARIMA(2,1,1) errors : -3174.611\n",
      " Regression with ARIMA(2,1,3) errors : -3188.585\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,2) errors : -3200.646\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -3171.835\n",
      " Regression with ARIMA(0,1,0) errors : -2966.393\n",
      " Regression with ARIMA(1,1,0) errors : -3133.824\n",
      " Regression with ARIMA(0,1,1) errors : -3159.343\n",
      " Regression with ARIMA(0,1,0) errors : -2968.401\n",
      " Regression with ARIMA(1,1,2) errors : -3164.073\n",
      " Regression with ARIMA(2,1,1) errors : -3173.782\n",
      " Regression with ARIMA(1,1,1) errors : -3165.467\n",
      " Regression with ARIMA(2,1,0) errors : -3175.292\n",
      " Regression with ARIMA(3,1,0) errors : -3175.06\n",
      " Regression with ARIMA(3,1,1) errors : -3173.594\n",
      " Regression with ARIMA(2,1,0) errors : -3177.306\n",
      " Regression with ARIMA(1,1,0) errors : -3135.837\n",
      " Regression with ARIMA(3,1,0) errors : -3177.078\n",
      " Regression with ARIMA(2,1,1) errors : -3175.798\n",
      " Regression with ARIMA(1,1,1) errors : -3167.483\n",
      " Regression with ARIMA(3,1,1) errors : -3175.614\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,0) errors : -3174.86\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,0) errors \n",
      "\n",
      "[1] \"27 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -3198.637\n",
      " Regression with ARIMA(0,1,0) errors : -2977.294\n",
      " Regression with ARIMA(1,1,0) errors : -3139.721\n",
      " Regression with ARIMA(0,1,1) errors : -3170.461\n",
      " Regression with ARIMA(0,1,0) errors : -2979.304\n",
      " Regression with ARIMA(1,1,2) errors : -3196.254\n",
      " Regression with ARIMA(2,1,1) errors : -3177.91\n",
      " Regression with ARIMA(3,1,2) errors : -3194.686\n",
      " Regression with ARIMA(2,1,3) errors : -3207.519\n",
      " Regression with ARIMA(1,1,3) errors : -3196.525\n",
      " Regression with ARIMA(3,1,3) errors : -3197.416\n",
      " Regression with ARIMA(2,1,4) errors : -3193.794\n",
      " Regression with ARIMA(1,1,4) errors : -3195.037\n",
      " Regression with ARIMA(3,1,4) errors : -3194.583\n",
      " Regression with ARIMA(2,1,3) errors : -3209.452\n",
      " Regression with ARIMA(1,1,3) errors : -3198.523\n",
      " Regression with ARIMA(2,1,2) errors : -3200.649\n",
      " Regression with ARIMA(3,1,3) errors : -3199.438\n",
      " Regression with ARIMA(2,1,4) errors : -3195.801\n",
      " Regression with ARIMA(1,1,2) errors : -3198.248\n",
      " Regression with ARIMA(1,1,4) errors : -3197.039\n",
      " Regression with ARIMA(3,1,2) errors : -3196.709\n",
      " Regression with ARIMA(3,1,4) errors : -3196.604\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,3) errors : -3203.304\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -3200.328\n",
      " Regression with ARIMA(0,1,0) errors : -2979.091\n",
      " Regression with ARIMA(1,1,0) errors : -3140.437\n",
      " Regression with ARIMA(0,1,1) errors : -3172.39\n",
      " Regression with ARIMA(0,1,0) errors : -2981.1\n",
      " Regression with ARIMA(1,1,2) errors : -3196.396\n",
      " Regression with ARIMA(2,1,1) errors : -3176.96\n",
      " Regression with ARIMA(3,1,2) errors : -3178.22\n",
      " Regression with ARIMA(2,1,3) errors : -3205.272\n",
      " Regression with ARIMA(1,1,3) errors : -3196.131\n",
      " Regression with ARIMA(3,1,3) errors : -3196.08\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : -3194.46\n",
      " Regression with ARIMA(3,1,4) errors : -3202.115\n",
      " Regression with ARIMA(2,1,3) errors : -3207.286\n",
      " Regression with ARIMA(1,1,3) errors : -3198.147\n",
      " Regression with ARIMA(2,1,2) errors : -3202.349\n",
      " Regression with ARIMA(3,1,3) errors : -3198.103\n",
      " Regression with ARIMA(2,1,4) errors : -3196.402\n",
      " Regression with ARIMA(1,1,2) errors : -3198.41\n",
      " Regression with ARIMA(1,1,4) errors : -3196.479\n",
      " Regression with ARIMA(3,1,2) errors : -3180.24\n",
      " Regression with ARIMA(3,1,4) errors : -3204.142\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,3) errors : -3205.172\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,3) errors \n",
      "\n",
      "[1] \"36 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -3193.09\n",
      " Regression with ARIMA(0,1,0) errors : -2982.936\n",
      " Regression with ARIMA(1,1,0) errors : -3148.205\n",
      " Regression with ARIMA(0,1,1) errors : -3174.52\n",
      " Regression with ARIMA(0,1,0) errors : -2984.945\n",
      " Regression with ARIMA(1,1,2) errors : -3175.924\n",
      " Regression with ARIMA(2,1,1) errors : -3186.38\n",
      " Regression with ARIMA(3,1,2) errors : -3207.441\n",
      " Regression with ARIMA(3,1,1) errors : -3184.755\n",
      " Regression with ARIMA(4,1,2) errors : -3217.99\n",
      " Regression with ARIMA(4,1,1) errors : -3197.022\n",
      " Regression with ARIMA(5,1,2) errors : -3195.515\n",
      " Regression with ARIMA(4,1,3) errors : -3203.736\n",
      " Regression with ARIMA(3,1,3) errors : -3202.155\n",
      " Regression with ARIMA(5,1,1) errors : -3192.179\n",
      " Regression with ARIMA(5,1,3) errors : -3199.002\n",
      " Regression with ARIMA(4,1,2) errors : -3220\n",
      " Regression with ARIMA(3,1,2) errors : -3209.458\n",
      " Regression with ARIMA(4,1,1) errors : -3199.043\n",
      " Regression with ARIMA(5,1,2) errors : -3197.542\n",
      " Regression with ARIMA(4,1,3) errors : -3205.769\n",
      " Regression with ARIMA(3,1,1) errors : -3186.771\n",
      " Regression with ARIMA(3,1,3) errors : -3204.179\n",
      " Regression with ARIMA(5,1,1) errors : -3194.2\n",
      " Regression with ARIMA(5,1,3) errors : -3201.024\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,1,2) errors : -3225.316\n",
      "\n",
      " Best model: Regression with ARIMA(4,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -2599.126\n",
      " Regression with ARIMA(1,0,0) errors : -2601.271\n",
      " Regression with ARIMA(0,0,1) errors : -2599.69\n",
      " Regression with ARIMA(0,0,0) errors : -2601.138\n",
      " Regression with ARIMA(2,0,0) errors : -2598.608\n",
      " Regression with ARIMA(1,0,1) errors : -2599.322\n",
      " Regression with ARIMA(2,0,1) errors : -2596.592\n",
      " Regression with ARIMA(1,0,0) errors : -2603.283\n",
      " Regression with ARIMA(2,0,0) errors : -2600.623\n",
      " Regression with ARIMA(1,0,1) errors : -2601.347\n",
      " Regression with ARIMA(0,0,1) errors : -2601.704\n",
      " Regression with ARIMA(2,0,1) errors : -2598.609\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -2601.731\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "[1] \"45 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -2598.57\n",
      " Regression with ARIMA(0,0,0) errors : -2598.728\n",
      " Regression with ARIMA(1,0,0) errors : -2598.264\n",
      " Regression with ARIMA(0,0,1) errors : -2598.945\n",
      " Regression with ARIMA(0,0,0) errors : -2600.739\n",
      " Regression with ARIMA(1,0,1) errors : -2596.609\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -2600.739\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -2582.097\n",
      " Regression with ARIMA(0,0,0) errors : -2585.454\n",
      " Regression with ARIMA(1,0,0) errors : -2585.439\n",
      " Regression with ARIMA(0,0,1) errors : -2585.645\n",
      " Regression with ARIMA(0,0,0) errors : -2587.465\n",
      " Regression with ARIMA(1,0,1) errors : -2583.618\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -2587.465\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "[1] \"55 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -3138.929\n",
      " Regression with ARIMA(0,1,0) errors : -2915.932\n",
      " Regression with ARIMA(1,1,0) errors : -3091.648\n",
      " Regression with ARIMA(0,1,1) errors : -3113.207\n",
      " Regression with ARIMA(0,1,0) errors : -2917.944\n",
      " Regression with ARIMA(1,1,2) errors : -3129.205\n",
      " Regression with ARIMA(2,1,1) errors : -3127.034\n",
      " Regression with ARIMA(3,1,2) errors : -3128.519\n",
      " Regression with ARIMA(2,1,3) errors : -3144.092\n",
      " Regression with ARIMA(1,1,3) errors : -3131.323\n",
      " Regression with ARIMA(3,1,3) errors : -3142.627\n",
      " Regression with ARIMA(2,1,4) errors : -3130.86\n",
      " Regression with ARIMA(1,1,4) errors : -3132.336\n",
      " Regression with ARIMA(3,1,4) errors : -3147.846\n",
      " Regression with ARIMA(4,1,4) errors : -3156.525\n",
      " Regression with ARIMA(4,1,3) errors : -3156.968\n",
      " Regression with ARIMA(4,1,2) errors : -3141.198\n",
      " Regression with ARIMA(5,1,3) errors : -3163.829\n",
      " Regression with ARIMA(5,1,2) errors : -3153.859\n",
      " Regression with ARIMA(5,1,4) errors : -3162.708\n",
      " Regression with ARIMA(5,1,3) errors : -3165.845\n",
      " Regression with ARIMA(4,1,3) errors : -3158.979\n",
      " Regression with ARIMA(5,1,2) errors : -3155.875\n",
      " Regression with ARIMA(5,1,4) errors : -3164.795\n",
      " Regression with ARIMA(4,1,2) errors : -3143.21\n",
      " Regression with ARIMA(4,1,4) errors : -3158.542\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,3) errors : -3165.666\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -2550.607\n",
      " Regression with ARIMA(1,0,0) errors : -2550.323\n",
      " Regression with ARIMA(0,0,1) errors : -2549.845\n",
      " Regression with ARIMA(0,0,0) errors : -2552.619\n",
      " Regression with ARIMA(1,0,1) errors : -2548.683\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -2552.619\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "[1] \"64 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -2821.625\n",
      " Regression with ARIMA(0,1,0) errors : -2572.866\n",
      " Regression with ARIMA(1,1,0) errors : -2783.713\n",
      " Regression with ARIMA(0,1,1) errors : -2811.017\n",
      " Regression with ARIMA(0,1,0) errors : -2574.856\n",
      " Regression with ARIMA(1,1,2) errors : -2823.915\n",
      " Regression with ARIMA(0,1,2) errors : -2819.613\n",
      " Regression with ARIMA(1,1,1) errors : -2817.401\n",
      " Regression with ARIMA(1,1,3) errors : -2822.441\n",
      " Regression with ARIMA(0,1,3) errors : -2819.232\n",
      " Regression with ARIMA(2,1,1) errors : -2815.05\n",
      " Regression with ARIMA(2,1,3) errors : -2828.44\n",
      " Regression with ARIMA(3,1,3) errors : -2826.687\n",
      " Regression with ARIMA(2,1,4) errors : -2827.741\n",
      " Regression with ARIMA(1,1,4) errors : -2828.821\n",
      " Regression with ARIMA(0,1,4) errors : -2821.735\n",
      " Regression with ARIMA(1,1,5) errors : -2826.827\n",
      " Regression with ARIMA(0,1,5) errors : -2820.251\n",
      " Regression with ARIMA(2,1,5) errors : -2826.793\n",
      " Regression with ARIMA(1,1,4) errors : -2830.831\n",
      " Regression with ARIMA(0,1,4) errors : -2823.739\n",
      " Regression with ARIMA(1,1,3) errors : -2824.451\n",
      " Regression with ARIMA(2,1,4) errors : -2829.757\n",
      " Regression with ARIMA(1,1,5) errors : -2828.84\n",
      " Regression with ARIMA(0,1,3) errors : -2821.235\n",
      " Regression with ARIMA(0,1,5) errors : -2822.258\n",
      " Regression with ARIMA(2,1,3) errors : -2830.454\n",
      " Regression with ARIMA(2,1,5) errors : -2828.812\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,4) errors : -2835.795\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -2318.889\n",
      " Regression with ARIMA(0,0,0) errors : -2319.853\n",
      " Regression with ARIMA(1,0,0) errors : -2317.017\n",
      " Regression with ARIMA(0,0,1) errors : -2317.864\n",
      " Regression with ARIMA(0,0,0) errors : -2321.864\n",
      " Regression with ARIMA(1,0,1) errors : -2315.002\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -2321.864\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "[1] \"73 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -2257.359\n",
      " Regression with ARIMA(0,0,0) errors : -2265.187\n",
      " Regression with ARIMA(1,0,0) errors : -2263.979\n",
      " Regression with ARIMA(0,0,1) errors : -2263.178\n",
      " Regression with ARIMA(0,0,0) errors : -2267.199\n",
      " Regression with ARIMA(1,0,1) errors : -2262.062\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -2267.199\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -2219.395\n",
      " Regression with ARIMA(1,0,0) errors : -2216.806\n",
      " Regression with ARIMA(0,0,1) errors : -2217.522\n",
      " Regression with ARIMA(0,0,0) errors : -2221.406\n",
      " Regression with ARIMA(1,0,1) errors : -2214.79\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -2221.406\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "[1] \"82 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -2215.312\n",
      " Regression with ARIMA(0,0,0) errors : -2211.605\n",
      " Regression with ARIMA(1,0,0) errors : -2209.544\n",
      " Regression with ARIMA(0,0,1) errors : -2209.833\n",
      " Regression with ARIMA(0,0,0) errors : -2213.617\n",
      " Regression with ARIMA(1,0,2) errors : -2205.577\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -2602.115\n",
      " Regression with ARIMA(3,0,1) errors : -2227.769\n",
      " Regression with ARIMA(4,0,2) errors : -2219.857\n",
      " Regression with ARIMA(3,0,3) errors : -2209.681\n",
      " Regression with ARIMA(2,0,3) errors : -2203.826\n",
      " Regression with ARIMA(4,0,1) errors : -2221.774\n",
      " Regression with ARIMA(4,0,3) errors : -2595.498\n",
      " Regression with ARIMA(3,0,2) errors : -2228.823\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -2601.526\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -2228.574\n",
      " Regression with ARIMA(0,0,0) errors : -2229.014\n",
      " Regression with ARIMA(1,0,0) errors : -2228.138\n",
      " Regression with ARIMA(0,0,1) errors : -2227.447\n",
      " Regression with ARIMA(0,0,0) errors : -2231.026\n",
      " Regression with ARIMA(1,0,1) errors : -2226.141\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -2231.026\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "[1] \"91 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -2212.732\n",
      " Regression with ARIMA(0,0,0) errors : -2218.294\n",
      " Regression with ARIMA(1,0,0) errors : -2215.751\n",
      " Regression with ARIMA(0,0,1) errors : -2216.653\n",
      " Regression with ARIMA(0,0,0) errors : -2220.305\n",
      " Regression with ARIMA(1,0,1) errors : -2213.732\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -2220.305\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -2199.686\n",
      " Regression with ARIMA(1,0,0) errors : -2198.219\n",
      " Regression with ARIMA(0,0,1) errors : -2197.762\n",
      " Regression with ARIMA(0,0,0) errors : -2201.698\n",
      " Regression with ARIMA(1,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -2201.698\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "[1] \"100 % done.\"\n"
     ]
    }
   ],
   "source": [
    "result.m04.2 <- my.tsCV(trainx[,1], cv.forecast.norm, h=hori, window=wind, step=peri,\n",
    "                      silent=F,\n",
    "                      xreg=trainx[,2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ac6e0de-a305-49a0-8d3c-77ce8506157a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 1997-12-31\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m04.2\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10b3ff6f-3d76-47a5-9fc9-79f871e6d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp saving\n",
    "#write.csv(result.m02, file=\"result.m02.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435ab53e-426a-4b91-9d3a-d037e4dd9995",
   "metadata": {},
   "source": [
    "## Regressor mean of smaller period for forecast \n",
    "- Regressor mean for forecast is calculated from the number of latest 'horizon' period\n",
    "- the 1st model used the number of latest 'window' period for the calc of regressor mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "035d6b87-06c6-4440-88ae-98eaf1e6ca7b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13090.73\n",
      " Regression with ARIMA(0,0,0) errors : -12481.33\n",
      " Regression with ARIMA(1,0,0) errors : -12481.38\n",
      " Regression with ARIMA(0,0,1) errors : -12480.83\n",
      " Regression with ARIMA(0,0,0) errors : -12381.52\n",
      " Regression with ARIMA(1,0,2) errors : -12482.89\n",
      " Regression with ARIMA(2,0,1) errors : -12481.71\n",
      " Regression with ARIMA(3,0,2) errors : -13113.99\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(4,0,2) errors : -13085.22\n",
      " Regression with ARIMA(3,0,3) errors : -13121.87\n",
      " Regression with ARIMA(2,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -13113.33\n",
      " Regression with ARIMA(3,0,4) errors : -13121.99\n",
      " Regression with ARIMA(2,0,4) errors : -13095.36\n",
      " Regression with ARIMA(4,0,4) errors : -13124.65\n",
      " Regression with ARIMA(5,0,4) errors : -13115.73\n",
      " Regression with ARIMA(4,0,5) errors : -13124.6\n",
      " Regression with ARIMA(3,0,5) errors : -13123.9\n",
      " Regression with ARIMA(5,0,3) errors : -13110.75\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13047.39\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13119.29\n",
      " Regression with ARIMA(0,0,0) errors : -12489.66\n",
      " Regression with ARIMA(1,0,0) errors : -12489.5\n",
      " Regression with ARIMA(0,0,1) errors : -12489.19\n",
      " Regression with ARIMA(0,0,0) errors : -12389.96\n",
      " Regression with ARIMA(1,0,2) errors : -12486.02\n",
      " Regression with ARIMA(2,0,1) errors : -13079.92\n",
      " Regression with ARIMA(3,0,2) errors : -13137.1\n",
      " Regression with ARIMA(3,0,1) errors : -13084.01\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13132.05\n",
      " Regression with ARIMA(2,0,3) errors : -13120.51\n",
      " Regression with ARIMA(4,0,1) errors : -13104.28\n",
      " Regression with ARIMA(4,0,3) errors : -13132.38\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13128.53\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "[1] \"9 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13067.93\n",
      " Regression with ARIMA(0,0,0) errors : -12490.69\n",
      " Regression with ARIMA(1,0,0) errors : -12489.52\n",
      " Regression with ARIMA(0,0,1) errors : -12489.79\n",
      " Regression with ARIMA(0,0,0) errors : -12390.91\n",
      " Regression with ARIMA(1,0,2) errors : -13071.61\n",
      " Regression with ARIMA(0,0,2) errors : -12487.78\n",
      " Regression with ARIMA(1,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,3) errors : -13084.25\n",
      " Regression with ARIMA(0,0,3) errors : -12485.98\n",
      " Regression with ARIMA(2,0,3) errors : -13124.67\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,4) errors : -13088.13\n",
      " Regression with ARIMA(1,0,4) errors : -13086.83\n",
      " Regression with ARIMA(3,0,2) errors : -12490.65\n",
      " Regression with ARIMA(3,0,4) errors : -13123.75\n",
      " Regression with ARIMA(2,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,3) errors : -13072.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13075.33\n",
      " Regression with ARIMA(0,1,0) errors : -12859.84\n",
      " Regression with ARIMA(1,1,0) errors : -13018.33\n",
      " Regression with ARIMA(0,1,1) errors : -13051.45\n",
      " Regression with ARIMA(0,1,0) errors : -12861.82\n",
      " Regression with ARIMA(1,1,2) errors : -13076.68\n",
      " Regression with ARIMA(0,1,2) errors : -13055\n",
      " Regression with ARIMA(1,1,1) errors : -13052.98\n",
      " Regression with ARIMA(1,1,3) errors : -13076.35\n",
      " Regression with ARIMA(0,1,3) errors : -13064.81\n",
      " Regression with ARIMA(2,1,1) errors : -13057.41\n",
      " Regression with ARIMA(2,1,3) errors : -13073.19\n",
      " Regression with ARIMA(1,1,2) errors : -13078.7\n",
      " Regression with ARIMA(0,1,2) errors : -13056.97\n",
      " Regression with ARIMA(1,1,1) errors : -13054.95\n",
      " Regression with ARIMA(2,1,2) errors : -13077.34\n",
      " Regression with ARIMA(1,1,3) errors : -13078.36\n",
      " Regression with ARIMA(0,1,1) errors : -13053.41\n",
      " Regression with ARIMA(0,1,3) errors : -13066.79\n",
      " Regression with ARIMA(2,1,1) errors : -13059.4\n",
      " Regression with ARIMA(2,1,3) errors : -13075.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,2) errors : -13091.4\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,2) errors \n",
      "\n",
      "[1] \"18 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13062.5\n",
      " Regression with ARIMA(0,1,0) errors : -12857.49\n",
      " Regression with ARIMA(1,1,0) errors : -13017.93\n",
      " Regression with ARIMA(0,1,1) errors : -13050.83\n",
      " Regression with ARIMA(0,1,0) errors : -12859.5\n",
      " Regression with ARIMA(1,1,2) errors : -13076.79\n",
      " Regression with ARIMA(0,1,2) errors : -13054.82\n",
      " Regression with ARIMA(1,1,1) errors : -13052.11\n",
      " Regression with ARIMA(1,1,3) errors : -13076.3\n",
      " Regression with ARIMA(0,1,3) errors : -13064.36\n",
      " Regression with ARIMA(2,1,1) errors : -13057.4\n",
      " Regression with ARIMA(2,1,3) errors : -13071.36\n",
      " Regression with ARIMA(1,1,2) errors : -13078.79\n",
      " Regression with ARIMA(0,1,2) errors : -13056.82\n",
      " Regression with ARIMA(1,1,1) errors : -13054.1\n",
      " Regression with ARIMA(2,1,2) errors : -13064.53\n",
      " Regression with ARIMA(1,1,3) errors : -13078.3\n",
      " Regression with ARIMA(0,1,1) errors : -13052.83\n",
      " Regression with ARIMA(0,1,3) errors : -13066.37\n",
      " Regression with ARIMA(2,1,1) errors : -13059.41\n",
      " Regression with ARIMA(2,1,3) errors : -13073.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,2) errors : -13091.05\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13056.63\n",
      " Regression with ARIMA(0,1,0) errors : -12851.19\n",
      " Regression with ARIMA(1,1,0) errors : -13018.62\n",
      " Regression with ARIMA(0,1,1) errors : -13044.14\n",
      " Regression with ARIMA(0,1,0) errors : -12853.2\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -13058.58\n",
      " Regression with ARIMA(1,1,1) errors : -13050.26\n",
      " Regression with ARIMA(2,1,0) errors : -13060.09\n",
      " Regression with ARIMA(3,1,0) errors : -13059.86\n",
      " Regression with ARIMA(3,1,1) errors : -13058.39\n",
      " Regression with ARIMA(2,1,0) errors : -13062.1\n",
      " Regression with ARIMA(1,1,0) errors : -13020.63\n",
      " Regression with ARIMA(3,1,0) errors : -13061.87\n",
      " Regression with ARIMA(2,1,1) errors : -13060.59\n",
      " Regression with ARIMA(1,1,1) errors : -13052.28\n",
      " Regression with ARIMA(3,1,1) errors : -13060.41\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,0) errors : -13065.26\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,0) errors \n",
      "\n",
      "[1] \"27 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13083.43\n",
      " Regression with ARIMA(0,1,0) errors : -12862.09\n",
      " Regression with ARIMA(1,1,0) errors : -13024.52\n",
      " Regression with ARIMA(0,1,1) errors : -13055.26\n",
      " Regression with ARIMA(0,1,0) errors : -12864.1\n",
      " Regression with ARIMA(1,1,2) errors : -13081.05\n",
      " Regression with ARIMA(2,1,1) errors : -13062.71\n",
      " Regression with ARIMA(3,1,2) errors : -13079.48\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : -13058.83\n",
      " Regression with ARIMA(1,1,3) errors : -13081.32\n",
      " Regression with ARIMA(3,1,1) errors : -13063.44\n",
      " Regression with ARIMA(3,1,3) errors : -13082.21\n",
      " Regression with ARIMA(2,1,2) errors : -13085.44\n",
      " Regression with ARIMA(1,1,2) errors : -13083.04\n",
      " Regression with ARIMA(2,1,1) errors : -13064.71\n",
      " Regression with ARIMA(3,1,2) errors : -13081.5\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : -13060.83\n",
      " Regression with ARIMA(1,1,3) errors : -13083.32\n",
      " Regression with ARIMA(3,1,1) errors : -13065.45\n",
      " Regression with ARIMA(3,1,3) errors : -13084.22\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13096.27\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13085.12\n",
      " Regression with ARIMA(0,1,0) errors : -12863.89\n",
      " Regression with ARIMA(1,1,0) errors : -13025.23\n",
      " Regression with ARIMA(0,1,1) errors : -13057.19\n",
      " Regression with ARIMA(0,1,0) errors : -12865.9\n",
      " Regression with ARIMA(1,1,2) errors : -13081.19\n",
      " Regression with ARIMA(2,1,1) errors : -13061.76\n",
      " Regression with ARIMA(3,1,2) errors : -13063\n",
      " Regression with ARIMA(2,1,3) errors : -13088.64\n",
      " Regression with ARIMA(1,1,3) errors : -13080.92\n",
      " Regression with ARIMA(3,1,3) errors : -13080.88\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : -13079.26\n",
      " Regression with ARIMA(3,1,4) errors : -13086.91\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,3) errors : -13093.73\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,3) errors \n",
      "\n",
      "[1] \"36 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13077.89\n",
      " Regression with ARIMA(0,1,0) errors : -12867.73\n",
      " Regression with ARIMA(1,1,0) errors : -13033\n",
      " Regression with ARIMA(0,1,1) errors : -13059.31\n",
      " Regression with ARIMA(0,1,0) errors : -12869.74\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -13071.18\n",
      " Regression with ARIMA(3,1,2) errors : -13092.24\n",
      " Regression with ARIMA(3,1,1) errors : -13069.54\n",
      " Regression with ARIMA(4,1,2) errors : -13102.79\n",
      " Regression with ARIMA(4,1,1) errors : -13081.82\n",
      " Regression with ARIMA(5,1,2) errors : -13080.31\n",
      " Regression with ARIMA(4,1,3) errors : -13088.54\n",
      " Regression with ARIMA(3,1,3) errors : -13086.94\n",
      " Regression with ARIMA(5,1,1) errors : -13076.97\n",
      " Regression with ARIMA(5,1,3) errors : -13083.8\n",
      " Regression with ARIMA(4,1,2) errors : -13104.8\n",
      " Regression with ARIMA(3,1,2) errors : -13094.25\n",
      " Regression with ARIMA(4,1,1) errors : -13083.84\n",
      " Regression with ARIMA(5,1,2) errors : -13082.34\n",
      " Regression with ARIMA(4,1,3) errors : -13090.56\n",
      " Regression with ARIMA(3,1,1) errors : -13071.56\n",
      " Regression with ARIMA(3,1,3) errors : -13088.97\n",
      " Regression with ARIMA(5,1,1) errors : -13078.99\n",
      " Regression with ARIMA(5,1,3) errors : -13085.81\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,1,2) errors : -13115.72\n",
      "\n",
      " Best model: Regression with ARIMA(4,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -12495.14\n",
      " Regression with ARIMA(1,0,0) errors : -12497.29\n",
      " Regression with ARIMA(0,0,1) errors : -12495.71\n",
      " Regression with ARIMA(0,0,0) errors : -12398.89\n",
      " Regression with ARIMA(2,0,0) errors : -12494.62\n",
      " Regression with ARIMA(1,0,1) errors : -12495.31\n",
      " Regression with ARIMA(2,0,1) errors : -12492.61\n",
      " Regression with ARIMA(1,0,0) errors : -12398.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -12495.73\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "[1] \"45 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12494.59\n",
      " Regression with ARIMA(0,0,0) errors : -12494.74\n",
      " Regression with ARIMA(1,0,0) errors : -12494.28\n",
      " Regression with ARIMA(0,0,1) errors : -12494.96\n",
      " Regression with ARIMA(0,0,0) errors : -12397.83\n",
      " Regression with ARIMA(1,0,1) errors : Inf\n",
      " Regression with ARIMA(0,0,2) errors : -12493.11\n",
      " Regression with ARIMA(1,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,1) errors : -12397.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,1) errors : -12494.96\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -12481.47\n",
      " Regression with ARIMA(1,0,0) errors : -12481.45\n",
      " Regression with ARIMA(0,0,1) errors : -12481.66\n",
      " Regression with ARIMA(0,0,0) errors : -12384.65\n",
      " Regression with ARIMA(1,0,1) errors : -12479.63\n",
      " Regression with ARIMA(0,0,2) errors : -12480\n",
      " Regression with ARIMA(1,0,2) errors : -12480.01\n",
      " Regression with ARIMA(0,0,1) errors : -12384.15\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,1) errors : -12481.66\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,1) errors \n",
      "\n",
      "[1] \"55 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13023.72\n",
      " Regression with ARIMA(0,1,0) errors : -12800.73\n",
      " Regression with ARIMA(1,1,0) errors : -12976.44\n",
      " Regression with ARIMA(0,1,1) errors : -12998\n",
      " Regression with ARIMA(0,1,0) errors : -12802.74\n",
      " Regression with ARIMA(1,1,2) errors : -13014\n",
      " Regression with ARIMA(2,1,1) errors : -13011.83\n",
      " Regression with ARIMA(3,1,2) errors : -13013.24\n",
      " Regression with ARIMA(2,1,3) errors : -13028.89\n",
      " Regression with ARIMA(1,1,3) errors : -13016.12\n",
      " Regression with ARIMA(3,1,3) errors : -13027.42\n",
      " Regression with ARIMA(2,1,4) errors : -13015.58\n",
      " Regression with ARIMA(1,1,4) errors : -13017.13\n",
      " Regression with ARIMA(3,1,4) errors : -13032.6\n",
      " Regression with ARIMA(4,1,4) errors : -13041.3\n",
      " Regression with ARIMA(4,1,3) errors : -13041.76\n",
      " Regression with ARIMA(4,1,2) errors : -13025.99\n",
      " Regression with ARIMA(5,1,3) errors : -13048.62\n",
      " Regression with ARIMA(5,1,2) errors : -13038.65\n",
      " Regression with ARIMA(5,1,4) errors : -13047.51\n",
      " Regression with ARIMA(5,1,3) errors : -13050.64\n",
      " Regression with ARIMA(4,1,3) errors : -13043.77\n",
      " Regression with ARIMA(5,1,2) errors : -13040.68\n",
      " Regression with ARIMA(5,1,4) errors : -13049.5\n",
      " Regression with ARIMA(4,1,2) errors : -13028\n",
      " Regression with ARIMA(4,1,4) errors : -13043.34\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,3) errors : -13056.01\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -12446.62\n",
      " Regression with ARIMA(1,0,0) errors : -12446.34\n",
      " Regression with ARIMA(0,0,1) errors : -12445.86\n",
      " Regression with ARIMA(0,0,0) errors : -12352.07\n",
      " Regression with ARIMA(1,0,1) errors : -12444.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -12446.62\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "[1] \"64 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12706.42\n",
      " Regression with ARIMA(0,1,0) errors : -12457.66\n",
      " Regression with ARIMA(1,1,0) errors : -12668.51\n",
      " Regression with ARIMA(0,1,1) errors : -12695.81\n",
      " Regression with ARIMA(0,1,0) errors : -12459.65\n",
      " Regression with ARIMA(1,1,2) errors : -12708.71\n",
      " Regression with ARIMA(0,1,2) errors : -12704.41\n",
      " Regression with ARIMA(1,1,1) errors : -12702.2\n",
      " Regression with ARIMA(1,1,3) errors : -12707.24\n",
      " Regression with ARIMA(0,1,3) errors : -12704.03\n",
      " Regression with ARIMA(2,1,1) errors : -12699.84\n",
      " Regression with ARIMA(2,1,3) errors : -12713.23\n",
      " Regression with ARIMA(3,1,3) errors : -12711.48\n",
      " Regression with ARIMA(2,1,4) errors : -12712.54\n",
      " Regression with ARIMA(1,1,4) errors : -12713.62\n",
      " Regression with ARIMA(0,1,4) errors : -12706.53\n",
      " Regression with ARIMA(1,1,5) errors : -12711.62\n",
      " Regression with ARIMA(0,1,5) errors : -12705.05\n",
      " Regression with ARIMA(2,1,5) errors : -12711.59\n",
      " Regression with ARIMA(1,1,4) errors : -12715.63\n",
      " Regression with ARIMA(0,1,4) errors : -12708.53\n",
      " Regression with ARIMA(1,1,3) errors : -12709.25\n",
      " Regression with ARIMA(2,1,4) errors : -12714.52\n",
      " Regression with ARIMA(1,1,5) errors : -12713.63\n",
      " Regression with ARIMA(0,1,3) errors : -12706.03\n",
      " Regression with ARIMA(0,1,5) errors : -12707.05\n",
      " Regression with ARIMA(2,1,3) errors : -12715.25\n",
      " Regression with ARIMA(2,1,5) errors : -12713.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,4) errors : -12726.2\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12214.9\n",
      " Regression with ARIMA(0,0,0) errors : -12215.87\n",
      " Regression with ARIMA(1,0,0) errors : -12213.03\n",
      " Regression with ARIMA(0,0,1) errors : -12213.88\n",
      " Regression with ARIMA(0,0,0) errors : -12125.87\n",
      " Regression with ARIMA(1,0,1) errors : -12211.02\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -12215.87\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "[1] \"73 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12153.37\n",
      " Regression with ARIMA(0,0,0) errors : -12161.2\n",
      " Regression with ARIMA(1,0,0) errors : -12159.99\n",
      " Regression with ARIMA(0,0,1) errors : -12159.19\n",
      " Regression with ARIMA(0,0,0) errors : -12069.07\n",
      " Regression with ARIMA(1,0,1) errors : -12158.08\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -12161.2\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -12115.41\n",
      " Regression with ARIMA(1,0,0) errors : -12112.82\n",
      " Regression with ARIMA(0,0,1) errors : -12113.54\n",
      " Regression with ARIMA(0,0,0) errors : -12029.77\n",
      " Regression with ARIMA(1,0,1) errors : -12110.81\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -12115.41\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "[1] \"82 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12098.6\n",
      " Regression with ARIMA(0,0,0) errors : -12107.62\n",
      " Regression with ARIMA(1,0,0) errors : -12105.56\n",
      " Regression with ARIMA(0,0,1) errors : -12105.85\n",
      " Regression with ARIMA(0,0,0) errors : -12022.63\n",
      " Regression with ARIMA(1,0,1) errors : -12103.55\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -12107.62\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12124.59\n",
      " Regression with ARIMA(0,0,0) errors : -12125.03\n",
      " Regression with ARIMA(1,0,0) errors : -12124.15\n",
      " Regression with ARIMA(0,0,1) errors : -12123.46\n",
      " Regression with ARIMA(0,0,0) errors : -12041.75\n",
      " Regression with ARIMA(1,0,1) errors : -12122.15\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -12125.03\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "[1] \"91 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12107.83\n",
      " Regression with ARIMA(0,0,0) errors : -12114.31\n",
      " Regression with ARIMA(1,0,0) errors : -12111.77\n",
      " Regression with ARIMA(0,0,1) errors : -12112.67\n",
      " Regression with ARIMA(0,0,0) errors : -12029.04\n",
      " Regression with ARIMA(1,0,1) errors : -12109.75\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -12114.31\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -12095.7\n",
      " Regression with ARIMA(1,0,0) errors : -12094.23\n",
      " Regression with ARIMA(0,0,1) errors : -12093.78\n",
      " Regression with ARIMA(0,0,0) errors : -12007.69\n",
      " Regression with ARIMA(1,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,0,0) errors : -12095.7\n",
      "\n",
      " Best model: Regression with ARIMA(0,0,0) errors \n",
      "\n",
      "[1] \"100 % done.\"\n"
     ]
    }
   ],
   "source": [
    "result.m04.3 <- my.tsCV(trainx[,1], cv.forecast, h=hori, window=wind, step=peri,\n",
    "                      xreg.msize=hori,\n",
    "                      xreg=trainx[,2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dfd95132-f6b6-449a-80b4-b9750616bde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 1997-12-31\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m04.3\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53f2b51-a9df-4dbd-bdd6-d77af2fe524f",
   "metadata": {},
   "source": [
    "## Compare Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed9c467c-feac-4461-816b-ac6a0abcae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "my.figsize(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e499e5ce-1237-49e0-a787-a1be8de29cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94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\ngRKEAAAAgRKEAAAAgRKEAAAAgfp/3xuvHF/wL3MAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- my.get_result(result.m04.1, 'ARIMA Errors 1')\n",
    "errors.2 <- my.get_result(result.m04.2, 'ARIMA Errors 2 (normalized)')\n",
    "n <- paste('ARIMA Errors 3 (future regressor mean of', hori ,'days)', sep=' ')\n",
    "errors.3 <- my.get_result(result.m04.3, n)\n",
    "\n",
    "x <- rbind(errors.1, errors.2)\n",
    "x <- rbind(x, errors.3)\n",
    "\n",
    "my.plot_errors(x, metrics=c('rmse'), loc='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f0a8df7-b56a-46aa-9af5-d6702ae1057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m04 <- result.m04.3\n",
    "#errors.m03 <- errors.m03.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88acae2-994b-4716-b170-6ce34970d63e",
   "metadata": {},
   "source": [
    "# ARIMA+GARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd2532b4-3bda-49cc-9b57-2dcb813bdcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast <- function(x, h) {\n",
    "    forc <- ag2.forecast(x, h, out.sample=0)\n",
    "    if (!is.na(forc)) {\n",
    "        fc <- list(method = \"ARIMA+GARCH Forecasting\", mean=forc@forecast$seriesFor[,1])\n",
    "        attr(fc$mean, \"names\") <- NULL\n",
    "        return(fc)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c06b0a1-de8c-450c-8caa-895de33f8fd9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"12 % done.\"\n",
      "[1] \"23 % done.\"\n",
      "[1] \"35 % done.\"\n",
      "[1] \"46 % done.\"\n",
      "[1] \"58 % done.\"\n",
      "[1] \"69 % done.\"\n",
      "[1] \"81 % done.\"\n",
      "[1] \"92 % done.\"\n"
     ]
    }
   ],
   "source": [
    "result.m05 <- my.tsCV(train, cv.forecast, h=hori, window=wind, step=peri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b4805d3a-1bc0-47e4-95f8-d358940ab858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 1997-12-31\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m05\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb209ef-30c2-4407-b353-1a388b17d202",
   "metadata": {},
   "source": [
    "# Model Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9a63c6f-09de-4820-a6e8-a454f4973d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.1 <- my.get_result(result.m01, '1. Prophet')\n",
    "errors.2 <- my.get_result(result.m02, '2. BSTS')\n",
    "errors.3 <- my.get_result(result.m03, '3. ARIMA')\n",
    "errors.4 <- my.get_result(result.m04, '4. ARIMA Errors')\n",
    "errors.5 <- my.get_result(result.m05, '5. ARIMA+GARCH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "27d10fd6-6a42-4cc0-8441-08220c600b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94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\nSUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.list <- list(errors.1, errors.2, errors.3, errors.4, errors.5)\n",
    "x <- errors.list[[1]]\n",
    "for (e in errors.list[2:length(errors.list)]) {\n",
    "    x <- rbind(x, e)\n",
    "}\n",
    "\n",
    "my.figsize(10, 6)\n",
    "my.plot_errors(x, metrics=c('rmse'), loc='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f22d9-79fa-4da9-a7fe-e1d6e0ea5a03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
