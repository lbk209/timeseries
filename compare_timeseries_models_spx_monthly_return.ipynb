{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403b7c49-b1e4-4567-b300-d0cf4343f1ef",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589d964f-db11-4ee9-b31e-43a56aa2ed1c",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c83acee-3f1c-4594-883d-7c9aa7615e83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: xts\n",
      "\n",
      "Loading required package: zoo\n",
      "\n",
      "\n",
      "Attaching package: ‘zoo’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n",
      "\n",
      "Loading required package: TTR\n",
      "\n",
      "Registered S3 method overwritten by 'quantmod':\n",
      "  method            from\n",
      "  as.zoo.data.frame zoo \n",
      "\n",
      "Loading required package: parallel\n",
      "\n",
      "\n",
      "Attaching package: ‘rugarch’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    sigma\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(quantmod)\n",
    "library(forecast)\n",
    "library(rugarch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a36dd52-ad96-4245-9985-ef4ee04f7323",
   "metadata": {},
   "source": [
    "### user's defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1cae5f-cb19-423f-9f75-23355f2b58d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path <- '~/works/utils/r'\n",
    "source(paste(path, \"myutils.r\", sep='/'))\n",
    "source(paste(path, \"myarimagarch.r\", sep='/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ca76d8-f191-41d9-b2f7-320cad9fd35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new.get_result <- function(x, group, group.col='Models',\n",
    "                          #errors=c('rmse','mape'), # unconditional forecast\n",
    "                          errors=c('rmse.mean','mape.mean') # daily forecast\n",
    "                          ) \n",
    "{\n",
    "    y <- my.get_result(x, group, errors=errors, group.col=group.col)\n",
    "    colnames(y) <- c('rmse','mape',group.col)\n",
    "    return(y)\n",
    "}\n",
    "\n",
    "new.plot_errors <- function(x, group.col='Models', ...) {\n",
    "    my.plot_errors(x, metrics=c('rmse'), group.col=group.col, ...)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81965efe-0310-4a8f-bab8-f7d92d9d839f",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b7c1c3-673b-420b-9e3c-c94ac7936b24",
   "metadata": {},
   "source": [
    "### S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae10fdf1-3592-4ea5-8ae2-d5917a507e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start <- '1991-01-01'\n",
    "train_end <- '2019-12-31'\n",
    "\n",
    "test_start <- '2020-01-01'\n",
    "test_end <- '2020-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee333ae3-056f-4986-aef5-64e8a03fcc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'^GSPC'"
      ],
      "text/latex": [
       "'\\textasciicircum{}GSPC'"
      ],
      "text/markdown": [
       "'^GSPC'"
      ],
      "text/plain": [
       "[1] \"^GSPC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from <- train_start\n",
    "to <- test_end\n",
    "getSymbols(\"^GSPC\", from=from, to=to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "214a3960-5dd7-47be-90ef-2e258d043250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spx <- GSPC\n",
    "colnames(spx) <- c('o','h','l','c','v','a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019dcc7f-aabe-4e1a-bced-ba8dcc21036b",
   "metadata": {},
   "source": [
    "### Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8becee7d-33dc-4db2-bab9-71e87158d6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookahead <- 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb9af71-95b5-4285-93a0-0e5913510963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               logret\n",
       "1991-01-31 0.05216129\n",
       "1991-02-01 0.06360416\n",
       "1991-02-04 0.08173788\n",
       "1991-02-05 0.10755822\n",
       "1991-02-06 0.12847341\n",
       "1991-02-07 0.13502311"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spx.ret <- diff(log(spx$a), lookahead)\n",
    "spx.ret <- na.omit(spx.ret)\n",
    "colnames(spx.ret) <- 'logret'\n",
    "head(spx.ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "651c6501-6ff3-4d97-a129-65e3ee317cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train <- window(spx.ret, end=as.Date(train_end))\n",
    "test <- window(spx.ret, start=as.Date(test_start), end=as.Date(test_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf7c574-fcaf-41e8-a22e-97b2caadd84a",
   "metadata": {},
   "source": [
    "## CV Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ad305fe-7f89-4186-a651-1873d64ef6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR <- 252\n",
    "\n",
    "#hori <- floor(YEAR/2)\n",
    "#hori <- floor(YEAR/6)\n",
    "hori <- floor(YEAR/12)\n",
    "\n",
    "#peri <- floor(hori/2)\n",
    "#peri <- hori*2\n",
    "peri <- hori\n",
    "\n",
    "#wind <- 5*YEAR\n",
    "#wind <- 7*YEAR\n",
    "wind <- 9*YEAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f16cf2d-16cb-45ad-adb3-4dfc8bcfda22",
   "metadata": {},
   "source": [
    "### testing\n",
    "- rerun Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6af023f6-9782-43de-ad8a-60f12ef422a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start <- '1991-01-01'\n",
    "train_end <- '2000-12-31'\n",
    "#train_end <- '1998-12-31'\n",
    "#train_end <- '1997-12-31'\n",
    "train <- window(spx.ret, start=as.Date(train_start), end=as.Date(train_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "493d63b9-0a03-4771-9aa1-53e0d58166f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"number of iterations: 21\"\n"
     ]
    }
   ],
   "source": [
    "sample.r <- 0.1\n",
    "#sample.r <- 0.05\n",
    "\n",
    "n <- (nrow(train) - wind - hori)/floor(peri) * round(hori * sample.r)\n",
    "print(paste('number of iterations: ', round(n), sep=''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a0b3d6-8fa4-4911-9127-b372ec88ba57",
   "metadata": {},
   "source": [
    "## Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f87d6209-3593-4659-b754-eef50734902f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x <- RSI(spx$a)\n",
    "trainx <- merge(train, x, join='left', fill=NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "063c43c3-688b-49ac-a6e2-89690219b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use close instead of adjusted to make consistent with \"un-adjusted\" high & low\n",
    "x <- BBands(spx[,c('h','l','c')])\n",
    "x <- x$pctB\n",
    "trainx <- merge(trainx, x, join='left', fill=NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff082501-d546-4510-bf61-43cfec923f72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x <- MACD(spx$a)\n",
    "x <- x$macd - x$signal\n",
    "trainx <- merge(trainx, x, join='left', fill=NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "befa6d49-0a1c-4bc7-8083-45ac91a02823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    y      rsi    bbands        macd\n",
       "1991-02-19 0.10602550 72.59254 0.8419486 -0.03641515\n",
       "1991-02-20 0.09798126 66.25313 0.7706927 -0.18551057\n",
       "1991-02-21 0.10585688 66.00481 0.7330987 -0.30953562\n",
       "1991-02-22 0.10194779 66.54491 0.7402938 -0.39546732\n",
       "1991-02-25 0.09259647 67.84742 0.7305630 -0.43573971\n",
       "1991-02-26 0.07655978 60.80133 0.6379610 -0.55105032"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                      y      rsi      bbands        macd\n",
       "2000-12-21 -0.055303326 35.58279 -0.08118867 -0.52657176\n",
       "2000-12-22 -0.012487300 43.27857  0.16850774 -0.39482896\n",
       "2000-12-26 -0.020008556 45.36756  0.31665756 -0.23687015\n",
       "2000-12-27 -0.014974701 48.40815  0.43464789 -0.04835247\n",
       "2000-12-28 -0.001400583 49.57479  0.50613909  0.10877207\n",
       "2000-12-29 -0.016265059 46.59058  0.45131826  0.14487942"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colnames(trainx) <- c('y','rsi','bbands','macd')\n",
    "trainx <- na.omit(trainx)\n",
    "head(trainx)\n",
    "tail(trainx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5049d74b-5700-4b0c-af48-c2d74dc6d9cd",
   "metadata": {},
   "source": [
    "# Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9653be84-20b9-4aad-b230-55cfa4fc581c",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a631ddab-2034-402d-90d7-b6583506f3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Rcpp\n",
      "\n",
      "Loading required package: rlang\n",
      "\n",
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:xts’:\n",
      "\n",
      "    first, last\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(prophet)\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2842860f-ca3a-4757-9d7e-a0f608b8b9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast <- function(x, h, xreg=NULL, xreg.msize=NULL) {\n",
    "    \n",
    "    check.ds <- function(x) {\n",
    "        d <- try(as.POSIXct(x$ds, format = \"%Y-%m-%d\"), silent=T)\n",
    "        if ((sum(is.na(d))>0) | (is.element(\"try-error\", class(d))))  {\n",
    "            #print(\"That wasn't correct!\")\n",
    "            x$ds <- seq(as.Date('1901-01-01'), length.out=length(x$ds), by=1)\n",
    "        }\n",
    "        return(x)\n",
    "    }\n",
    "    \n",
    "    model <- prophet()\n",
    "\n",
    "    if (!is.null(xreg)) {\n",
    "        ### convert data for prophet\n",
    "        #x <- ifelse(is.null(dim(x)), data.frame(x), x) # not works\n",
    "        if (is.null(dim(x))) {x <- data.frame(x)}\n",
    "        colnames(x) <- 'y'\n",
    "        x.train <- cbind(x, xreg)\n",
    "        x.train <- as.data.frame(x.train)\n",
    "        x.train <- cbind(ds=rownames(x.train), x.train)\n",
    "        rownames(x.train) <- NULL\n",
    "        x.train <- check.ds(x.train)\n",
    "\n",
    "        ### add regressors before fitting\n",
    "        for (c in colnames(xreg)) {\n",
    "            model <- add_regressor(model, c)\n",
    "        }\n",
    "\n",
    "        ### fit: must run after add_regressor and before make_future_dataframe\n",
    "        model <- fit.prophet(model, x.train)\n",
    "\n",
    "        ### prepare future ds\n",
    "        future <- make_future_dataframe(model, periods=h)\n",
    "\n",
    "        # regessor assumption for future\n",
    "        if (is.null(xreg.msize)) {\n",
    "            xreg.m <- xreg # calc mean for future with all the xreg\n",
    "        } else {\n",
    "            # calc mean for future with xreg of length xreg.mszie\n",
    "            xreg.m <- tail(xreg, n=xreg.msize)\n",
    "        }\n",
    "        \n",
    "        if (is.null(dim(xreg))) {\n",
    "            xreg.h <- mean(xreg.m)\n",
    "        } else {\n",
    "            xreg.h <- colMeans(xreg.m)  \n",
    "        }\n",
    "\n",
    "        # rbind history & future of xreg\n",
    "        xreg.all <- data.frame(xreg)\n",
    "        xreg.coln <- colnames(xreg.all) # save name for the case of single xreg\n",
    "\n",
    "        xreg.h <- data.frame(xreg.h)\n",
    "        colnames(xreg.h) <- colnames(NA)\n",
    "        xreg.h <- t(xreg.h)\n",
    "        xreg.h <- as.ts(xreg.h[rep(seq_len(nrow(xreg.h)), h), ])\n",
    "        xreg.h <- data.frame(xreg.h) # convert to frame for the case of single xreg\n",
    "        \n",
    "        # update future\n",
    "        if ((dim(xreg.h)[2]==1) & (dim(xreg.h)[1]==length(xreg.coln))) {\n",
    "            xreg.h <- t(xreg.h) # the case of h==1\n",
    "        }\n",
    "        colnames(xreg.h) <- xreg.coln # match name to rbind\n",
    "        #xreg.all <- rbind(xreg.all, xreg.h)\n",
    "        xreg.all <- rbind(as.matrix(xreg.all), xreg.h) \n",
    "        xreg.all <- data.frame(xreg.all, row.names = NULL) \n",
    "        xreg.all$ds <- future$ds\n",
    "        future <- xreg.all\n",
    "\n",
    "    } else {\n",
    "        x.train <- data.frame(ds=index(x), y=as.numeric(x))\n",
    "        x.train <- check.ds(x.train)\n",
    "        model <- fit.prophet(model, x.train)\n",
    "        future <- make_future_dataframe(model, periods=h)\n",
    "    }\n",
    "\n",
    "    fc <- predict(model, future)\n",
    "    fc <- list(method = \"Prophet Forecasting\", mean=tail(fc$yhat, h))\n",
    "    return(fc)\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39380c4f-4777-4631-8192-1023e1350df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main difference with cv.forecast is that cv.forecase.2 need data for forecasting\n",
    "cv.forecast.2 <- function(x, h, xreg=NULL, xreg.msize=NULL, sample.n=0) \n",
    "{\n",
    "    result.rmse <- c()\n",
    "    result.mape <- c()\n",
    "    train.len <- length(x) - h\n",
    "    my.subset <- function(x, s, e) {\n",
    "        if (!is.null(x)) {\n",
    "            #x <- subset(x, start=s, end=e)\n",
    "            #x <- subset(as.ts(x), start=s, end=e)\n",
    "            x <- subset(ts(x), start=s, end=e)\n",
    "        }\n",
    "        return(x)\n",
    "    }\n",
    "    idx <- 0:(h-1)\n",
    "    if ((sample.n>0) & (sample.n<h)) {\n",
    "        idx <- sort(sample(idx, sample.n))\n",
    "    }\n",
    "    for (i in seq_along(idx)) {\n",
    "        trlen <- train.len+idx[i]\n",
    "        x.train <- my.subset(x, 1, trlen)\n",
    "        xreg.train <- my.subset(xreg, 1, trlen)\n",
    "        fc <- cv.forecast(x.train, 1, xreg=xreg.train, xreg.msize=xreg.msize)\n",
    "        result.rmse[i] <- sqrt(mean((fc$mean - x[trlen+1])^2))\n",
    "        result.mape[i] <- mean(abs(1 - fc$mean / x[trlen+1]))\n",
    "    }\n",
    "    e <- list(rmse.mean=mean(result.rmse), rmse.sigma=sd(result.rmse), \n",
    "              mape.mean=mean(result.mape), mape.sigma=sd(result.mape))\n",
    "    return(e)\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e0fb38-d451-44d8-8834-ba4d69d19781",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dd96713-bac0-45e7-acee-91b3db181205",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"10 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"20 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"30 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"40 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"50 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"60 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"70 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"80 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"90 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m01.1 <- my.tsCV.2(train, cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          silent=F,\n",
    "                          sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ac8981d-15bf-408c-9638-7b4754cbf984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-01-24\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m01.1\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c1ddd0-be96-456c-878f-5386005d6092",
   "metadata": {},
   "source": [
    "## Additional regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5003bce6-1677-46e3-a84f-18b57b7872bc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"10 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"20 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"30 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"40 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"50 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"60 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"70 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"80 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"90 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m01.2 <- my.tsCV.2(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          xreg=trainx[,2:4], \n",
    "                          sample.n=round(hori*sample.r),\n",
    "                          silent=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2d5fe22-e405-4131-96d3-1cf18723f552",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"10 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"20 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"30 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"40 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"50 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"60 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"70 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"80 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"90 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m01.3 <- my.tsCV.2(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          xreg=trainx[,3], \n",
    "                          silent=F,\n",
    "                          sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ba326e3-2a59-4a52-ab62-c7b71ccb9ea8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"10 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"20 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"30 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"40 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"50 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"60 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"70 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"80 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"90 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m01.4 <- my.tsCV.2(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                         xreg=trainx[,2:4], \n",
    "                         sample.n=round(hori*sample.r),\n",
    "                         xreg.msize=hori)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfe1cb3-5728-4fd8-a0ef-2593535940f5",
   "metadata": {},
   "source": [
    "## Compare Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "729703b7-0e13-4ac8-9014-dbab6d2d5acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my.figsize(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88224355-62cb-4480-b79c-b2791413a8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94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\ngg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- new.get_result(result.m01.1, '1.Prophet')\n",
    "errors.2 <- new.get_result(result.m01.2, '2.Prophet with Regressors')\n",
    "errors.3 <- new.get_result(result.m01.3, '3.Prophet with 1 Regressor')\n",
    "errors.4 <- new.get_result(result.m01.4, '4.Prophet with Regressor (2)')\n",
    "\n",
    "x <- rbind(errors.1, errors.2)\n",
    "x <- rbind(x, errors.3)\n",
    "x <- rbind(x, errors.4)\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8351dcbc-33db-44ea-a47d-550e48cc6e6c",
   "metadata": {},
   "source": [
    "### save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b27ae32-b956-4e94-9aec-d07bfd72a72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- result.m01.1\n",
    "write.csv(x, file = \"prophet_result_m0101.csv\")\n",
    "x <- result.m01.2\n",
    "write.csv(x, file = \"prophet_result_m0102.csv\")\n",
    "x <- result.m01.3\n",
    "write.csv(x, file = \"prophet_result_m0103.csv\")\n",
    "x <- result.m01.4\n",
    "write.csv(x, file = \"prophet_result_m0104.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c5f45-45d6-4303-82e4-1a2f9d7fbd8c",
   "metadata": {},
   "source": [
    "### load result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2e2b68b-2e54-484a-9d72-6d74422bd9c6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.m01.1 <- read.csv(file = 'prophet_result_m0101.csv')\n",
    "result.m01.2 <- read.csv(file = 'prophet_result_m0102.csv')\n",
    "result.m01.3 <- read.csv(file = 'prophet_result_m0103.csv')\n",
    "result.m01.4 <- read.csv(file = 'prophet_result_m0104.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cb8d98e-9491-400a-abd5-6a4694dfe9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m01 <- result.m01.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d38357-ca19-4a00-a9f3-88f56e5a4726",
   "metadata": {},
   "source": [
    "# BSTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b1a082-dca7-457f-a151-90f7518efe7a",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cdddaae-482a-4de2-932f-83458967d5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: BoomSpikeSlab\n",
      "\n",
      "Loading required package: Boom\n",
      "\n",
      "Loading required package: MASS\n",
      "\n",
      "\n",
      "Attaching package: ‘Boom’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    rWishart\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘BoomSpikeSlab’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    knots\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘bsts’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:BoomSpikeSlab’:\n",
      "\n",
      "    SuggestBurn\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(bsts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92d8cf60-d4b2-4d74-b586-01285de500da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast <- function(x, h, xreg=NULL, xreg.msize=NULL, expected.model.size=0,\n",
    "                        model=NULL, niter=1000) \n",
    "{\n",
    "    if (!is.null(xreg)) {\n",
    "        ### set params for fitting\n",
    "        # organize data for fitting\n",
    "        if (is.null(dim(x))) {x <- data.frame(x)}\n",
    "        colnames(x) <- 'y'\n",
    "        x.train <- cbind(x, xreg)\n",
    "        x.train <- as.data.frame(x.train)\n",
    "        \n",
    "        if (is.null(model)) {\n",
    "            n <- ncol(x.train)\n",
    "            if ((expected.model.size < 1) | (expected.model.size > n)) {\n",
    "                expected.model.size <- n\n",
    "            }\n",
    "            ss <- AddSemilocalLinearTrend(list(), x.train$y)\n",
    "            model <- bsts(y ~ .,\n",
    "                          state.specification = ss,\n",
    "                          niter = niter,\n",
    "                          data = x.train,\n",
    "                          expected.model.size = expected.model.size)  # Passed to SpikeSlabPrior.\n",
    "            olddata <- NULL\n",
    "        } else {\n",
    "            olddata <- x.train\n",
    "        }\n",
    "        \n",
    "        ### set params for prediction\n",
    "        # regessor assumption for future\n",
    "        if (is.null(xreg.msize)) {\n",
    "            xreg.m <- xreg # calc mean for future with all the xreg\n",
    "        } else {\n",
    "            # calc mean for future with xreg of length xreg.mszie\n",
    "            xreg.m <- tail(xreg, n=xreg.msize)\n",
    "        }\n",
    "\n",
    "        if (is.null(dim(xreg))) {\n",
    "            xreg.h <- mean(xreg.m)\n",
    "        } else {\n",
    "            xreg.h <- colMeans(xreg.m)  \n",
    "        }\n",
    "\n",
    "        xreg.all <- data.frame(xreg)\n",
    "        xreg.coln <- colnames(xreg.all) # save name for the case of single xreg\n",
    "        xreg.h <- data.frame(xreg.h)\n",
    "        colnames(xreg.h) <- colnames(NA)\n",
    "        xreg.h <- t(xreg.h)\n",
    "        xreg.h <- as.ts(xreg.h[rep(seq_len(nrow(xreg.h)), h), ])\n",
    "        xreg.h <- data.frame(xreg.h) # convert to frame for the case of single xreg\n",
    "        \n",
    "        if ((dim(xreg.h)[2]==1) & (dim(xreg.h)[1]==length(xreg.coln))) {\n",
    "            xreg.h <- t(xreg.h) # the case of h==1\n",
    "        } else {\n",
    "            xreg.h <- as.ts(xreg.h) # convert to ts as xreg is ts\n",
    "        }\n",
    "        \n",
    "        colnames(xreg.h) <- xreg.coln # match name to rbind\n",
    "        \n",
    "    } else {\n",
    "        if (is.null(model)) {\n",
    "            ss <- AddSemilocalLinearTrend(list(), x)\n",
    "            model <- bsts(x, state.specification = ss, niter=niter)\n",
    "            olddata <- NULL\n",
    "        } else {\n",
    "            olddata <- x\n",
    "        }\n",
    "        xreg.h <- NULL\n",
    "    }\n",
    "    # predict\n",
    "    fc <- predict(model, horizon=h, newdata=xreg.h, olddata=olddata)\n",
    "    fc$model <- model\n",
    "    return(fc)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da073aa9-90be-43a4-a317-965c6c100ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main difference with cv.forecast is that cv.forecase.2 need data for forecasting\n",
    "cv.forecast.2 <- function(x, h, xreg=NULL, xreg.msize=NULL, sample.n=0) \n",
    "{\n",
    "    result.rmse <- c()\n",
    "    result.mape <- c()\n",
    "    train.len <- length(x) - h\n",
    "    my.subset <- function(x, s, e) {\n",
    "        if (!is.null(x)) {\n",
    "            x <- subset(ts(x), start=s, end=e)\n",
    "        }\n",
    "        return(x)\n",
    "    }\n",
    "    idx <- 0:(h-1)\n",
    "    if ((sample.n>0) & (sample.n<h)) {\n",
    "        idx <- sort(sample(idx, sample.n))\n",
    "    }\n",
    "    \n",
    "    model <- NULL\n",
    "    for (i in seq_along(idx)) {\n",
    "        trlen <- train.len+idx[i]\n",
    "        x.train <- my.subset(x, 1, trlen)\n",
    "        xreg.train <- my.subset(xreg, 1, trlen)\n",
    "        \n",
    "        fc <- cv.forecast(x.train, 1, xreg=xreg.train, xreg.msize=xreg.msize, \n",
    "                          #expected.model.size=0,\n",
    "                          model=model, niter=1000) \n",
    "        \n",
    "        if (i==1) { # reuse model for the rest of periods\n",
    "            model <- fc$model\n",
    "        }\n",
    "        \n",
    "        result.rmse[i] <- sqrt(mean((fc$mean - x[trlen+1])^2))\n",
    "        result.mape[i] <- mean(abs(1 - fc$mean / x[trlen+1]))\n",
    "    }\n",
    "    e <- list(rmse.mean=mean(result.rmse), rmse.sigma=sd(result.rmse), \n",
    "              mape.mean=mean(result.mape), mape.sigma=sd(result.mape))\n",
    "    return(e)\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d8fc5f-8e48-4ea2-b707-e1f062d6b634",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0bae75e-ad34-40a9-aceb-7542fa7c13fd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:49:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:49:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:49:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:49:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:49:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:49:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:49:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:49:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:49:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:49:48 2022 =-=-=-=-=\n",
      "[1] \"8 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:49:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:49:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:49:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:50:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:50:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:50:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:50:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:50:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:50:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:50:18 2022 =-=-=-=-=\n",
      "[1] \"17 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:50:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:50:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:50:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:50:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:50:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:50:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:50:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:50:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:50:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:50:48 2022 =-=-=-=-=\n",
      "[1] \"25 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:50:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:50:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:50:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:51:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:51:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:51:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:51:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:51:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:51:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:51:19 2022 =-=-=-=-=\n",
      "[1] \"33 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:51:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:51:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:51:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:51:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:51:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:51:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:51:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:51:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:51:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:51:48 2022 =-=-=-=-=\n",
      "[1] \"42 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:51:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:51:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:51:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:52:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:52:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:52:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:52:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:52:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:52:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:52:18 2022 =-=-=-=-=\n",
      "[1] \"50 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:52:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:52:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:52:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:52:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:52:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:52:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:52:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:52:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:52:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:52:48 2022 =-=-=-=-=\n",
      "[1] \"58 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:52:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:52:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:52:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:53:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:53:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:53:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:53:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:53:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:53:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:53:18 2022 =-=-=-=-=\n",
      "[1] \"67 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:53:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:53:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:53:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:53:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:53:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:53:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:53:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:53:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:53:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:53:48 2022 =-=-=-=-=\n",
      "[1] \"75 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:53:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:53:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:53:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:54:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:54:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:54:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:54:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:54:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:54:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:54:20 2022 =-=-=-=-=\n",
      "[1] \"83 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:54:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:54:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:54:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:54:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:54:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:54:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:54:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:54:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:54:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:54:50 2022 =-=-=-=-=\n",
      "[1] \"92 % done.\"\n"
     ]
    }
   ],
   "source": [
    "result.m02.1 <- my.tsCV.2(train, cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "602a90d7-2081-46eb-8cf8-ca09307501bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-01-24\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m02.1\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b296acaf-74d0-4185-b130-b6512bbf03be",
   "metadata": {},
   "source": [
    "## Regression with spike and slab priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ecce414-f5fc-4f70-9f89-4908c5fe4e9a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Thu Sep 22 12:54:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 12:54:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 12:54:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 12:55:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 12:55:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 12:55:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 12:55:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 12:55:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 12:55:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 12:55:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 12:55:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 12:55:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 12:55:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 12:55:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 12:55:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 12:55:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 12:55:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 12:55:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 12:56:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 12:56:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 12:56:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 12:56:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 12:56:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 12:56:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 12:56:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 12:56:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 12:56:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 12:56:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 12:56:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 12:56:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 12:56:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 12:56:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 12:57:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 12:57:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 12:57:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 12:57:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 12:57:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 12:57:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 12:57:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 12:57:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 12:57:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 12:57:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 12:57:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 12:57:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 12:57:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 12:57:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 12:57:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 12:58:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 12:58:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 12:58:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 12:58:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 12:58:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 12:58:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 12:58:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 12:58:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 12:58:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 12:58:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 12:58:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 12:58:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 12:58:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 12:58:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 12:59:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 12:59:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 12:59:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 12:59:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 12:59:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 12:59:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 12:59:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 12:59:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 12:59:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 12:59:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 12:59:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 12:59:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 12:59:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 12:59:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 12:59:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 12:59:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:00:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:00:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:00:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:00:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:00:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:00:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:00:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:00:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:00:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:00:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:00:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:00:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:00:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:00:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:01:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:01:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:01:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:01:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:01:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:01:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:01:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:01:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:01:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:01:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:01:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:01:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:01:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:01:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:01:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:01:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:02:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:02:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:02:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:02:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:02:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:02:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:02:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:02:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:02:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:02:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:02:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:02:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:02:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:03:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:03:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:03:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:03:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:03:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:03:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:03:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:03:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:03:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:03:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:03:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:03:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:03:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:03:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:03:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:03:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:04:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:04:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:04:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:04:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:04:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:04:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:04:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:04:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:04:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:04:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:04:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:04:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:04:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:04:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:05:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:05:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:05:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:05:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:05:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:05:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:05:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:05:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:05:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:05:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:05:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:05:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:05:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:05:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:05:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:06:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:06:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:06:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:06:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:06:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:06:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:06:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:06:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:06:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:06:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:06:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:06:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:06:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:06:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:06:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:07:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:07:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:07:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:07:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:07:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:07:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:07:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:07:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:07:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:07:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:07:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:07:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:07:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:07:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:07:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:08:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:08:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:08:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:08:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:08:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:08:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:08:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:08:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:08:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:08:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:08:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:08:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:08:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:08:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:08:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:09:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:09:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:09:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:09:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:09:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:09:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:09:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:09:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:09:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:09:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:09:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:09:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:09:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:09:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:10:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:10:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:10:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:10:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:10:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:10:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:10:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:10:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:10:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:10:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:10:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:10:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:10:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:10:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:10:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:10:59 2022 =-=-=-=-=\n",
      "[1] \"10 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:11:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:11:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:11:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:11:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:11:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:11:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:11:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:11:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:11:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:11:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:11:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:11:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:11:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:11:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:12:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:12:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:12:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:12:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:12:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:12:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:12:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:12:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:12:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:12:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:12:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:12:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:12:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:12:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:12:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:13:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:13:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:13:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:13:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:13:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:13:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:13:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:13:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:13:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:13:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:13:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:13:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:13:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:13:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:14:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:14:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:14:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:14:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:14:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:14:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:14:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:14:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:14:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:14:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:14:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:14:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:14:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:14:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:14:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:14:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:15:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:15:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:15:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:15:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:15:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:15:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:15:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:15:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:15:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:15:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:15:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:15:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:15:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:15:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:16:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:16:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:16:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:16:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:16:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:16:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:16:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:16:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:16:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:16:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:16:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:16:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:16:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:16:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:16:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:17:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:17:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:17:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:17:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:17:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:17:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:17:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:17:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:17:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:17:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:17:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:17:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:17:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:17:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:18:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:18:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:18:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:18:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:18:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:18:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:18:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:18:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:18:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:18:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:18:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:18:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:18:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:18:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:18:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:19:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:19:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:19:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:19:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:19:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:19:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:19:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:19:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:19:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:19:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:19:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:19:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:19:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:20:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:20:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:20:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:20:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:20:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:20:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:20:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:20:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:20:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:20:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:20:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:20:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:20:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:20:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:20:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:21:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:21:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:21:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:21:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:21:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:21:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:21:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:21:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:21:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:21:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:21:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:21:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:21:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:21:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:21:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:22:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:22:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:22:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:22:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:22:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:22:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:22:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:22:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:22:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:22:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:22:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:22:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:22:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:22:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:23:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:23:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:23:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:23:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:23:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:23:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:23:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:23:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:23:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:23:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:23:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:23:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:23:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:23:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:23:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:24:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:24:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:24:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:24:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:24:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:24:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:24:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:24:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:24:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:24:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:24:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:24:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:24:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:25:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:25:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:25:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:25:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:25:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:25:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:25:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:25:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:25:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:25:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:25:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:25:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:25:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:25:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:25:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:26:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:26:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:26:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:26:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:26:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:26:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:26:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:26:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:26:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:26:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:26:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:26:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:26:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:26:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:27:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:27:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:27:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:27:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:27:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:27:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:27:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:27:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:27:29 2022 =-=-=-=-=\n",
      "[1] \"20 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:27:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:27:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:27:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:27:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:27:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:27:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:28:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:28:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:28:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:28:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:28:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:28:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:28:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:28:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:28:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:28:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:28:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:28:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:28:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:28:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:29:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:29:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:29:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:29:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:29:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:29:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:29:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:29:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:29:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:29:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:29:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:29:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:29:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:29:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:29:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:30:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:30:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:30:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:30:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:30:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:30:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:30:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:30:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:30:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:30:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:30:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:30:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:30:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:30:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:30:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:31:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:31:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:31:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:31:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:31:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:31:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:31:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:31:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:31:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:31:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:31:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:31:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:31:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:31:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:32:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:32:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:32:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:32:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:32:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:32:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:32:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:32:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:32:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:32:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:32:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:32:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:32:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:32:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:32:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:33:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:33:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:33:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:33:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:33:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:33:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:33:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:33:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:33:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:33:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:33:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:33:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:33:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:33:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:33:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:34:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:34:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:34:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:34:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:34:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:34:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:34:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:34:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:34:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:34:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:34:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:34:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:34:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:34:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:34:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:35:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:35:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:35:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:35:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:35:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:35:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:35:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:35:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:35:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:35:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:35:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:35:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:35:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:35:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:36:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:36:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:36:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:36:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:36:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:36:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:36:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:36:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:36:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:36:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:36:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:36:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:36:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:36:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:36:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:36:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:37:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:37:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:37:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:37:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:37:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:37:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:37:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:37:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:37:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:37:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:37:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:37:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:37:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:37:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:38:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:38:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:38:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:38:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:38:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:38:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:38:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:38:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:38:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:38:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:38:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:38:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:38:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:38:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:38:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:39:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:39:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:39:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:39:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:39:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:39:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:39:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:39:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:39:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:39:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:39:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:39:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:39:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:39:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:40:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:40:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:40:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:40:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:40:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:40:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:40:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:40:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:40:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:40:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:40:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:40:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:40:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:40:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:40:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:41:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:41:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:41:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:41:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:41:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:41:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:41:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:41:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:41:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:41:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:41:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:41:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:41:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:41:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:42:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:42:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:42:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:42:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:42:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:42:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:42:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:42:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:42:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:42:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:42:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:42:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:42:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:42:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:42:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:42:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:43:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:43:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:43:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:43:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:43:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:43:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:43:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:43:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:43:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:43:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:43:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:43:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:43:50 2022 =-=-=-=-=\n",
      "[1] \"30 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:44:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:44:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:44:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:44:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:44:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:44:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:44:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:44:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:44:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:44:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:44:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:44:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:44:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:44:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:44:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:44:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:45:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:45:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:45:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:45:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:45:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:45:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:45:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:45:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:45:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:45:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:45:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:45:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:45:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:45:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:46:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:46:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:46:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:46:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:46:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:46:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:46:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:46:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:46:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:46:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:46:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:46:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:46:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:46:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:46:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:47:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:47:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:47:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:47:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:47:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:47:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:47:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:47:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:47:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:47:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:47:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:47:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:47:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:47:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:47:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:48:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:48:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:48:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:48:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:48:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:48:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:48:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:48:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:48:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:48:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:48:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:48:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:48:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:48:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:49:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:49:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:49:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:49:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:49:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:49:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:49:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:49:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:49:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:49:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:49:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:49:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:49:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:49:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:49:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:49:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:50:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:50:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:50:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:50:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:50:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:50:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:50:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:50:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:50:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:50:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:50:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:50:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:50:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:50:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:50:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:51:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:51:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:51:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:51:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:51:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:51:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:51:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:51:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:51:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:51:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:51:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:51:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:51:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:51:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:51:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:52:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:52:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:52:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:52:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:52:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:52:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:52:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:52:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:52:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:52:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:52:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:52:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:52:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:52:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:53:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:53:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:53:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:53:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:53:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:53:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:53:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:53:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:53:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:53:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:53:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:53:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:53:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:53:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:53:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:54:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:54:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:54:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:54:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:54:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:54:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:54:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:54:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:54:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:54:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:54:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:54:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:54:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:54:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:55:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:55:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:55:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:55:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:55:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:55:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:55:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:55:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:55:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:55:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:55:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:55:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:55:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:55:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:55:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:55:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:56:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:56:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:56:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:56:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:56:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:56:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:56:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:56:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:56:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:56:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:56:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:56:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:56:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:57:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:57:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:57:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:57:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:57:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:57:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:57:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:57:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:57:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:57:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:57:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:57:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:57:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:57:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:57:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:57:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:58:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:58:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:58:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:58:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:58:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:58:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:58:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:58:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:58:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:58:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:58:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:58:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:58:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:58:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:59:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:59:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:59:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:59:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:59:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:59:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:59:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:59:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:59:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:59:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:59:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:59:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:59:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:59:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:59:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:00:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:00:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:00:08 2022 =-=-=-=-=\n",
      "[1] \"40 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:00:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:00:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:00:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:00:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:00:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:00:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:00:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:00:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:00:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:00:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:00:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:01:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:01:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:01:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:01:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:01:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:01:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:01:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:01:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:01:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:01:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:01:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:01:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:01:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:01:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:01:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:02:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:02:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:02:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:02:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:02:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:02:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:02:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:02:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:02:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:02:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:02:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:02:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:02:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:02:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:03:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:03:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:03:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:03:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:03:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:03:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:03:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:03:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:03:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:03:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:03:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:03:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:03:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:03:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:03:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:03:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:04:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:04:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:04:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:04:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:04:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:04:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:04:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:04:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:04:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:04:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:04:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:04:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:04:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:04:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:05:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:05:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:05:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:05:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:05:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:05:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:05:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:05:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:05:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:05:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:05:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:05:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:05:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:05:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:05:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:06:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:06:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:06:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:06:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:06:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:06:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:06:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:06:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:06:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:06:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:06:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:06:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:06:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:06:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:06:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:07:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:07:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:07:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:07:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:07:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:07:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:07:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:07:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:07:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:07:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:07:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:07:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:07:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:07:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:07:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:08:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:08:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:08:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:08:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:08:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:08:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:08:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:08:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:08:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:08:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:08:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:08:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:08:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:08:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:08:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:09:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:09:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:09:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:09:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:09:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:09:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:09:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:09:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:09:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:09:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:09:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:09:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:09:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:09:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:09:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:10:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:10:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:10:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:10:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:10:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:10:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:10:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:10:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:10:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:10:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:10:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:10:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:10:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:10:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:10:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:11:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:11:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:11:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:11:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:11:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:11:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:11:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:11:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:11:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:11:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:11:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:11:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:11:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:11:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:11:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:12:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:12:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:12:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:12:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:12:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:12:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:12:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:12:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:12:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:12:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:12:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:12:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:12:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:12:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:12:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:13:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:13:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:13:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:13:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:13:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:13:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:13:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:13:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:13:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:13:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:13:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:13:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:13:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:13:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:14:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:14:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:14:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:14:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:14:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:14:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:14:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:14:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:14:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:14:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:14:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:14:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:14:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:14:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:14:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:14:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:15:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:15:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:15:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:15:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:15:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:15:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:15:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:15:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:15:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:15:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:15:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:15:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:15:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:15:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:16:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:16:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:16:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:16:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:16:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:16:19 2022 =-=-=-=-=\n",
      "[1] \"50 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:16:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:16:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:16:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:16:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:16:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:16:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:16:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:16:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:16:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:17:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:17:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:17:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:17:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:17:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:17:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:17:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:17:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:17:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:17:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:17:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:17:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:17:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:17:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:18:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:18:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:18:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:18:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:18:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:18:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:18:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:18:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:18:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:18:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:18:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:18:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:18:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:18:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:18:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:18:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:19:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:19:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:19:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:19:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:19:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:19:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:19:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:19:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:19:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:19:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:19:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:19:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:19:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:19:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:20:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:20:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:20:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:20:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:20:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:20:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:20:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:20:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:20:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:20:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:20:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:20:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:20:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:20:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:20:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:20:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:21:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:21:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:21:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:21:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:21:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:21:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:21:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:21:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:21:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:21:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:21:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:21:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:21:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:22:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:22:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:22:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:22:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:22:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:22:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:22:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:22:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:22:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:22:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:22:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:22:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:22:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:22:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:22:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:22:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:23:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:23:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:23:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:23:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:23:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:23:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:23:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:23:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:23:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:23:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:23:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:23:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:23:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:23:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:24:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:24:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:24:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:24:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:24:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:24:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:24:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:24:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:24:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:24:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:24:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:24:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:24:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:24:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:25:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:25:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:25:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:25:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:25:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:25:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:25:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:25:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:25:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:25:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:25:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:25:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:25:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:25:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:26:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:26:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:26:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:26:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:26:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:26:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:26:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:26:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:26:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:26:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:26:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:26:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:26:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:26:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:26:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:27:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:27:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:27:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:27:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:27:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:27:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:27:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:27:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:27:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:27:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:27:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:27:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:27:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:27:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:27:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:28:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:28:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:28:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:28:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:28:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:28:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:28:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:28:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:28:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:28:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:28:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:28:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:28:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:28:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:28:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:29:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:29:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:29:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:29:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:29:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:29:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:29:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:29:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:29:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:29:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:29:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:29:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:29:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:29:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:29:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:30:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:30:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:30:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:30:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:30:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:30:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:30:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:30:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:30:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:30:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:30:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:30:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:30:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:30:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:31:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:31:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:31:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:31:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:31:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:31:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:31:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:31:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:31:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:31:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:31:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:31:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:31:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:31:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:31:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:32:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:32:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:32:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:32:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:32:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:32:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:32:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:32:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:32:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:32:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:32:41 2022 =-=-=-=-=\n",
      "[1] \"60 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:32:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:32:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:32:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:33:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:33:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:33:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:33:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:33:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:33:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:33:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:33:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:33:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:33:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:33:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:33:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:33:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:33:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:33:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:33:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:34:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:34:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:34:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:34:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:34:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:34:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:34:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:34:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:34:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:34:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:34:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:34:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:34:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:35:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:35:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:35:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:35:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:35:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:35:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:35:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:35:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:35:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:35:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:35:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:35:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:35:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:35:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:35:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:35:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:36:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:36:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:36:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:36:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:36:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:36:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:36:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:36:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:36:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:36:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:36:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:36:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:36:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:36:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:37:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:37:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:37:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:37:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:37:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:37:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:37:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:37:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:37:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:37:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:37:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:37:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:37:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:37:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:37:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:37:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:38:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:38:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:38:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:38:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:38:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:38:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:38:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:38:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:38:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:38:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:38:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:38:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:38:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:39:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:39:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:39:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:39:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:39:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:39:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:39:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:39:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:39:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:39:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:39:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:39:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:39:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:39:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:39:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:39:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:40:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:40:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:40:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:40:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:40:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:40:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:40:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:40:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:40:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:40:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:40:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:40:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:40:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:41:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:41:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:41:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:41:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:41:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:41:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:41:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:41:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:41:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:41:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:41:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:41:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:41:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:41:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:41:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:41:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:42:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:42:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:42:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:42:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:42:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:42:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:42:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:42:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:42:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:42:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:42:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:42:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:42:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:42:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:43:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:43:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:43:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:43:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:43:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:43:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:43:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:43:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:43:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:43:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:43:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:43:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:43:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:43:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:43:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:44:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:44:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:44:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:44:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:44:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:44:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:44:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:44:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:44:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:44:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:44:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:44:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:44:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:44:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:44:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:45:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:45:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:45:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:45:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:45:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:45:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:45:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:45:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:45:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:45:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:45:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:45:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:45:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:45:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:45:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:46:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:46:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:46:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:46:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:46:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:46:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:46:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:46:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:46:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:46:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:46:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:46:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:46:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:46:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:46:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:47:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:47:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:47:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:47:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:47:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:47:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:47:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:47:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:47:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:47:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:47:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:47:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:47:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:47:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:48:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:48:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:48:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:48:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:48:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:48:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:48:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:48:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:48:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:48:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:48:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:48:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:48:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:48:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:48:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:49:00 2022 =-=-=-=-=\n",
      "[1] \"70 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:49:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:49:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:49:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:49:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:49:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:49:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:49:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:49:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:49:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:49:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:49:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:49:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:49:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:50:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:50:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:50:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:50:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:50:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:50:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:50:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:50:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:50:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:50:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:50:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:50:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:50:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:50:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:50:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:51:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:51:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:51:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:51:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:51:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:51:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:51:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:51:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:51:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:51:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:51:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:51:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:51:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:51:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:52:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:52:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:52:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:52:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:52:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:52:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:52:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:52:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:52:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:52:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:52:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:52:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:52:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:52:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:52:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:53:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:53:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:53:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:53:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:53:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:53:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:53:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:53:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:53:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:53:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:53:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:53:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:53:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:53:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:54:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:54:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:54:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:54:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:54:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:54:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:54:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:54:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:54:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:54:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:54:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:54:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:54:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:54:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:54:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:54:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:55:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:55:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:55:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:55:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:55:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:55:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:55:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:55:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:55:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:55:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:55:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:55:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:55:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:55:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:56:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:56:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:56:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:56:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:56:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:56:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:56:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:56:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:56:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:56:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:56:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:56:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:56:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:56:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:56:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:57:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:57:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:57:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:57:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:57:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:57:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:57:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:57:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:57:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:57:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:57:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:57:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:57:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:57:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:58:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:58:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:58:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:58:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:58:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:58:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:58:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:58:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:58:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:58:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:58:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:58:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:58:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:58:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:58:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:58:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:59:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:59:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:59:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:59:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:59:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:59:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:59:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:59:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:59:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:59:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:59:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:59:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:59:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:59:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:00:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:00:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:00:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:00:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:00:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:00:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:00:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:00:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:00:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:00:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:00:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:00:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:00:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:00:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:00:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:01:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:01:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:01:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:01:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:01:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:01:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:01:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:01:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:01:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:01:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:01:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:01:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:01:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:01:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:01:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:02:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:02:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:02:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:02:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:02:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:02:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:02:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:02:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:02:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:02:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:02:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:02:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:02:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:02:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:02:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:03:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:03:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:03:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:03:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:03:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:03:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:03:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:03:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:03:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:03:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:03:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:03:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:03:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:03:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:03:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:04:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:04:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:04:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:04:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:04:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:04:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:04:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:04:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:04:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:04:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:04:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:04:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:04:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:04:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:04:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:05:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:05:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:05:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:05:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:05:14 2022 =-=-=-=-=\n",
      "[1] \"80 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:05:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:05:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:05:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:05:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:05:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:05:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:05:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:05:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:05:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:05:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:06:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:06:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:06:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:06:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:06:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:06:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:06:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:06:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:06:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:06:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:06:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:06:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:06:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:06:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:06:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:07:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:07:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:07:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:07:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:07:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:07:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:07:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:07:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:07:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:07:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:07:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:07:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:07:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:07:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:07:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:08:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:08:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:08:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:08:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:08:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:08:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:08:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:08:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:08:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:08:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:08:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:08:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:08:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:08:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:08:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:09:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:09:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:09:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:09:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:09:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:09:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:09:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:09:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:09:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:09:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:09:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:09:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:09:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:09:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:09:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:10:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:10:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:10:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:10:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:10:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:10:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:10:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:10:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:10:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:10:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:10:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:10:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:10:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:10:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:11:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:11:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:11:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:11:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:11:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:11:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:11:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:11:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:11:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:11:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:11:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:11:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:11:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:11:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:11:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:11:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:12:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:12:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:12:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:12:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:12:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:12:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:12:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:12:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:12:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:12:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:12:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:12:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:12:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:12:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:13:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:13:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:13:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:13:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:13:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:13:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:13:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:13:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:13:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:13:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:13:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:13:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:13:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:13:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:13:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:14:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:14:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:14:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:14:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:14:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:14:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:14:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:14:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:14:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:14:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:14:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:14:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:14:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:14:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:15:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:15:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:15:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:15:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:15:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:15:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:15:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:15:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:15:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:15:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:15:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:15:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:15:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:15:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:15:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:16:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:16:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:16:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:16:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:16:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:16:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:16:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:16:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:16:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:16:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:16:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:16:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:16:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:16:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:17:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:17:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:17:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:17:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:17:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:17:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:17:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:17:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:17:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:17:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:17:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:17:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:17:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:17:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:17:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:17:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:18:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:18:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:18:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:18:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:18:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:18:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:18:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:18:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:18:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:18:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:18:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:18:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:18:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:19:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:19:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:19:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:19:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:19:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:19:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:19:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:19:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:19:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:19:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:19:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:19:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:19:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:19:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:19:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:19:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:20:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:20:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:20:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:20:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:20:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:20:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:20:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:20:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:20:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:20:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:20:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:20:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:20:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:21:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:21:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:21:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:21:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:21:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:21:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:21:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:21:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:21:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:21:32 2022 =-=-=-=-=\n",
      "[1] \"90 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:21:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:21:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:21:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:21:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:21:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:21:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:22:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:22:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:22:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:22:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:22:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:22:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:22:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:22:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:22:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:22:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:22:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:22:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:22:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:22:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:23:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:23:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:23:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:23:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:23:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:23:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:23:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:23:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:23:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:23:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:23:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:23:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:23:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:23:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:24:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:24:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:24:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:24:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:24:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:24:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:24:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:24:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:24:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:24:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:24:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:24:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:24:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:24:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:24:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:24:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:25:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:25:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:25:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:25:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:25:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:25:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:25:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:25:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:25:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:25:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:25:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:25:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:25:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:25:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:26:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:26:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:26:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:26:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:26:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:26:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:26:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:26:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:26:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:26:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:26:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:26:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:26:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:26:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:26:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:27:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:27:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:27:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:27:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:27:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:27:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:27:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:27:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:27:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:27:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:27:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:27:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:27:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:28:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:28:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:28:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:28:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:28:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:28:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:28:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:28:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:28:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:28:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:28:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:28:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:28:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:28:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:28:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:28:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:28:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:29:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:29:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:29:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:29:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:29:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:29:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:29:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:29:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:29:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:29:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:29:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:29:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:29:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:30:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:30:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:30:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:30:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:30:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:30:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:30:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:30:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:30:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:30:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:30:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:30:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:30:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:30:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:30:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:30:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:31:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:31:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:31:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:31:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:31:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:31:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:31:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:31:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:31:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:31:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:31:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:31:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:31:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:32:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:32:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:32:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:32:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:32:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:32:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:32:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:32:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:32:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:32:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:32:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:32:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:32:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:32:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:32:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:32:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:33:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:33:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:33:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:33:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:33:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:33:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:33:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:33:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:33:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:33:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:33:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:33:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:33:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:34:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:34:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:34:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:34:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:34:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:34:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:34:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:34:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:34:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:34:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:34:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:34:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:34:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:34:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:34:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:34:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:35:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:35:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:35:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:35:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:35:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:35:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:35:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:35:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:35:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:35:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:35:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:35:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:35:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:35:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:36:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:36:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:36:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:36:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:36:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:36:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:36:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:36:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:36:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:36:34 2022 =-=-=-=-=\n"
     ]
    }
   ],
   "source": [
    "result.m02.2 <- my.tsCV.2(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          xreg=trainx[,2:4], \n",
    "                          silent=F,\n",
    "                          sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb72044a-8da0-45cc-8d68-0119fe090cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-02-09\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m02.2\n",
    "from <- x[!is.na(x[,'forecast_start']),][,1][1]\n",
    "from <- index(trainx[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc2e74d7-8d59-4a62-be63-137bc65d7e26",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:36:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:36:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:36:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:36:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:36:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:37:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:37:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:37:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:37:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:37:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:37:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:37:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:37:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:37:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:37:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:37:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:37:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:37:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:37:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:37:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:38:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:38:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:38:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:38:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:38:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:38:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:38:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:38:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:38:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:38:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:38:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:38:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:38:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:38:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:39:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:39:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:39:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:39:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:39:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:39:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:39:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:39:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:39:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:39:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:39:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:39:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:39:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:39:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:39:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:39:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:40:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:40:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:40:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:40:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:40:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:40:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:40:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:40:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:40:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:40:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:40:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:40:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:40:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:40:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:41:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:41:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:41:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:41:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:41:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:41:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:41:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:41:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:41:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:41:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:41:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:41:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:41:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:41:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:41:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:41:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:42:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:42:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:42:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:42:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:42:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:42:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:42:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:42:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:42:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:42:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:42:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:42:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:42:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:43:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:43:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:43:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:43:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:43:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:43:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:43:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:43:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:43:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:43:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:43:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:43:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:43:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:43:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:43:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:43:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:44:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:44:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:44:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:44:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:44:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:44:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:44:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:44:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:44:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:44:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:44:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:44:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:44:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:44:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:45:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:45:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:45:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:45:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:45:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:45:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:45:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:45:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:45:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:45:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:45:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:45:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:45:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:45:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:45:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:45:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:46:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:46:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:46:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:46:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:46:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:46:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:46:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:46:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:46:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:46:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:46:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:46:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:46:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:47:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:47:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:47:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:47:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:47:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:47:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:47:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:47:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:47:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:47:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:47:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:47:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:47:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:47:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:47:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:47:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:48:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:48:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:48:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:48:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:48:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:48:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:48:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:48:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:48:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:48:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:48:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:48:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:48:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:48:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:49:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:49:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:49:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:49:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:49:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:49:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:49:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:49:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:49:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:49:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:49:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:49:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:49:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:49:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:49:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:49:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:50:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:50:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:50:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:50:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:50:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:50:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:50:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:50:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:50:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:50:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:50:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:50:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:50:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:50:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:51:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:51:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:51:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:51:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:51:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:51:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:51:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:51:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:51:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:51:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:51:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:51:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:51:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:51:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:51:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:52:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:52:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:52:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:52:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:52:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:52:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:52:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:52:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:52:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:52:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:52:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:52:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:52:48 2022 =-=-=-=-=\n",
      "[1] \"10 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:52:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:53:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:53:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:53:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:53:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:53:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:53:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:53:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:53:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:53:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:53:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:53:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:53:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:53:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:53:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:53:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:53:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:54:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:54:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:54:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:54:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:54:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:54:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:54:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:54:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:54:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:54:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:54:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:54:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:54:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:55:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:55:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:55:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:55:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:55:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:55:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:55:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:55:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:55:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:55:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:55:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:55:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:55:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:55:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:55:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:55:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:56:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:56:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:56:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:56:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:56:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:56:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:56:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:56:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:56:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:56:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:56:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:56:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:56:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:56:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:57:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:57:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:57:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:57:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:57:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:57:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:57:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:57:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:57:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:57:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:57:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:57:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:57:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:57:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:57:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:58:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:58:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:58:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:58:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:58:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:58:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:58:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:58:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:58:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:58:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:58:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:58:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:58:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:58:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:58:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:59:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:59:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:59:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:59:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:59:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:59:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:59:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:59:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:59:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:59:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:59:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:59:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:59:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:59:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:59:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:00:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:00:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:00:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:00:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:00:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:00:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:00:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:00:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:00:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:00:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:00:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:00:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:00:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:00:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:00:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:01:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:01:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:01:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:01:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:01:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:01:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:01:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:01:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:01:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:01:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:01:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:01:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:01:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:01:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:02:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:02:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:02:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:02:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:02:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:02:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:02:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:02:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:02:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:02:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:02:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:02:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:02:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:02:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:02:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:03:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:03:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:03:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:03:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:03:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:03:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:03:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:03:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:03:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:03:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:03:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:03:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:03:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:03:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:04:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:04:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:04:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:04:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:04:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:04:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:04:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:04:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:04:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:04:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:04:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:04:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:04:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:04:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:04:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:05:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:05:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:05:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:05:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:05:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:05:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:05:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:05:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:05:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:05:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:05:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:05:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:05:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:05:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:06:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:06:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:06:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:06:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:06:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:06:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:06:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:06:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:06:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:06:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:06:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:06:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:06:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:06:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:06:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:07:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:07:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:07:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:07:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:07:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:07:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:07:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:07:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:07:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:07:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:07:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:07:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:07:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:07:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:08:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:08:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:08:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:08:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:08:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:08:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:08:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:08:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:08:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:08:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:08:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:08:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:08:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:08:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:08:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:09:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:09:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:09:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:09:11 2022 =-=-=-=-=\n",
      "[1] \"20 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:09:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:09:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:09:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:09:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:09:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:09:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:09:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:09:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:09:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:09:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:10:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:10:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:10:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:10:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:10:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:10:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:10:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:10:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:10:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:10:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:10:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:10:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:10:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:10:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:10:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:10:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:10:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:11:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:11:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:11:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:11:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:11:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:11:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:11:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:11:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:11:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:11:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:11:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:11:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:11:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:11:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:12:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:12:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:12:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:12:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:12:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:12:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:12:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:12:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:12:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:12:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:12:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:12:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:12:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:12:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:12:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:12:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:12:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:13:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:13:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:13:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:13:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:13:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:13:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:13:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:13:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:13:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:13:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:13:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:13:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:13:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:13:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:14:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:14:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:14:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:14:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:14:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:14:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:14:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:14:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:14:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:14:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:14:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:14:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:14:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:14:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:14:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:14:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:15:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:15:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:15:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:15:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:15:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:15:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:15:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:15:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:15:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:15:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:15:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:15:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:15:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:16:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:16:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:16:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:16:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:16:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:16:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:16:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:16:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:16:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:16:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:16:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:16:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:16:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:16:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:16:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:17:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:17:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:17:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:17:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:17:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:17:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:17:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:17:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:17:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:17:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:17:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:17:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:17:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:17:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:18:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:18:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:18:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:18:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:18:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:18:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:18:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:18:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:18:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:18:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:18:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:18:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:18:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:18:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:18:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:18:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:19:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:19:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:19:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:19:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:19:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:19:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:19:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:19:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:19:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:19:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:19:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:19:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:19:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:19:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:20:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:20:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:20:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:20:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:20:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:20:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:20:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:20:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:20:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:20:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:20:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:20:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:20:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:20:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:20:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:20:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:21:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:21:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:21:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:21:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:21:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:21:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:21:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:21:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:21:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:21:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:21:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:21:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:21:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:21:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:22:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:22:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:22:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:22:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:22:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:22:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:22:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:22:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:22:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:22:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:22:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:22:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:22:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:22:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:22:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:23:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:23:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:23:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:23:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:23:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:23:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:23:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:23:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:23:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:23:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:23:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:23:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:23:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:23:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:23:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:24:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:24:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:24:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:24:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:24:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:24:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:24:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:24:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:24:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:24:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:24:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:24:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:24:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:24:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:24:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:25:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:25:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:25:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:25:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:25:16 2022 =-=-=-=-=\n",
      "[1] \"30 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:25:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:25:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:25:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:25:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:25:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:25:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:25:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:25:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:25:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:25:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:26:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:26:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:26:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:26:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:26:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:26:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:26:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:26:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:26:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:26:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:26:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:26:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:26:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:26:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:27:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:27:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:27:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:27:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:27:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:27:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:27:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:27:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:27:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:27:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:27:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:27:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:27:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:27:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:27:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:27:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:28:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:28:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:28:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:28:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:28:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:28:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:28:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:28:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:28:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:28:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:28:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:28:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:28:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:28:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:29:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:29:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:29:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:29:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:29:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:29:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:29:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:29:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:29:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:29:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:29:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:29:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:29:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:29:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:29:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:30:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:30:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:30:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:30:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:30:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:30:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:30:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:30:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:30:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:30:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:30:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:30:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:30:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:30:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:31:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:31:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:31:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:31:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:31:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:31:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:31:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:31:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:31:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:31:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:31:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:31:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:31:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:31:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:31:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:31:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:32:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:32:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:32:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:32:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:32:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:32:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:32:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:32:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:32:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:32:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:32:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:32:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:32:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:33:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:33:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:33:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:33:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:33:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:33:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:33:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:33:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:33:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:33:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:33:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:33:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:33:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:33:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:33:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:33:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:33:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:34:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:34:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:34:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:34:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:34:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:34:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:34:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:34:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:34:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:34:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:34:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:34:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:34:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:34:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:35:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:35:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:35:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:35:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:35:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:35:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:35:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:35:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:35:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:35:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:35:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:35:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:35:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:35:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:35:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:35:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:36:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:36:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:36:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:36:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:36:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:36:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:36:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:36:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:36:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:36:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:36:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:36:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:36:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:37:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:37:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:37:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:37:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:37:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:37:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:37:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:37:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:37:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:37:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:37:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:37:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:37:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:37:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:37:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:37:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:38:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:38:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:38:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:38:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:38:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:38:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:38:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:38:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:38:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:38:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:38:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:38:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:38:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:38:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:39:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:39:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:39:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:39:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:39:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:39:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:39:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:39:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:39:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:39:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:39:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:39:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:39:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:39:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:39:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:40:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:40:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:40:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:40:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:40:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:40:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:40:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:40:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:40:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:40:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:40:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:40:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:40:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:40:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:41:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:41:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:41:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:41:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:41:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:41:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:41:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:41:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:41:28 2022 =-=-=-=-=\n",
      "[1] \"40 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:41:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:41:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:41:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:41:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:41:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:41:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:41:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:42:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:42:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:42:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:42:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:42:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:42:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:42:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:42:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:42:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:42:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:42:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:42:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:42:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:43:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:43:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:43:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:43:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:43:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:43:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:43:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:43:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:43:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:43:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:43:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:43:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:43:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:43:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:43:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:43:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:44:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:44:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:44:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:44:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:44:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:44:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:44:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:44:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:44:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:44:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:44:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:44:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:44:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:44:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:45:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:45:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:45:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:45:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:45:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:45:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:45:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:45:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:45:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:45:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:45:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:45:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:45:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:45:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:45:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:46:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:46:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:46:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:46:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:46:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:46:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:46:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:46:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:46:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:46:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:46:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:46:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:46:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:46:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:46:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:47:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:47:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:47:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:47:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:47:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:47:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:47:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:47:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:47:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:47:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:47:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:47:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:47:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:47:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:47:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:48:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:48:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:48:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:48:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:48:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:48:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:48:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:48:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:48:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:48:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:48:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:48:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:48:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:48:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:48:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:49:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:49:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:49:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:49:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:49:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:49:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:49:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:49:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:49:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:49:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:49:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:49:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:49:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:49:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:49:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:49:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:50:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:50:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:50:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:50:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:50:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:50:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:50:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:50:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:50:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:50:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:50:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:50:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:50:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:50:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:51:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:51:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:51:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:51:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:51:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:51:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:51:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:51:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:51:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:51:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:51:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:51:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:51:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:51:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:51:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:52:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:52:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:52:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:52:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:52:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:52:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:52:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:52:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:52:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:52:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:52:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:52:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:52:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:52:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:52:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:53:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:53:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:53:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:53:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:53:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:53:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:53:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:53:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:53:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:53:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:53:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:53:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:53:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:53:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:53:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:54:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:54:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:54:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:54:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:54:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:54:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:54:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:54:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:54:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:54:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:54:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:54:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:54:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:54:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:54:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:55:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:55:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:55:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:55:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:55:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:55:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:55:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:55:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:55:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:55:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:55:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:55:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:55:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:55:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:55:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:56:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:56:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:56:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:56:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:56:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:56:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:56:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:56:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:56:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:56:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:56:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:56:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:56:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:56:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:56:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:57:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:57:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:57:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:57:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:57:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:57:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:57:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:57:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:57:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:57:35 2022 =-=-=-=-=\n",
      "[1] \"50 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:57:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:57:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:57:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:57:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:57:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:58:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:58:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:58:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:58:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:58:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:58:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:58:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:58:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:58:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:58:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:58:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:58:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:58:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:58:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:58:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:59:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:59:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:59:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:59:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:59:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:59:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:59:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:59:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:59:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:59:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:59:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:59:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:59:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:59:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:00:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:00:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:00:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:00:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:00:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:00:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:00:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:00:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:00:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:00:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:00:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:00:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:00:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:00:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:00:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:00:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:01:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:01:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:01:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:01:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:01:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:01:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:01:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:01:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:01:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:01:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:01:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:01:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:01:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:01:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:02:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:02:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:02:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:02:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:02:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:02:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:02:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:02:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:02:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:02:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:02:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:02:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:02:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:02:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:02:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:02:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:03:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:03:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:03:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:03:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:03:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:03:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:03:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:03:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:03:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:03:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:03:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:03:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:03:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:03:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:04:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:04:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:04:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:04:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:04:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:04:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:04:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:04:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:04:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:04:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:04:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:04:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:04:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:04:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:04:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:05:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:05:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:05:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:05:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:05:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:05:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:05:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:05:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:05:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:05:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:05:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:05:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:05:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:05:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:06:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:06:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:06:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:06:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:06:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:06:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:06:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:06:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:06:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:06:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:06:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:06:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:06:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:06:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:06:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:07:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:07:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:07:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:07:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:07:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:07:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:07:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:07:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:07:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:07:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:07:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:07:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:07:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:07:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:08:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:08:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:08:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:08:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:08:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:08:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:08:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:08:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:08:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:08:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:08:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:08:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:08:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:08:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:08:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:08:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:09:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:09:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:09:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:09:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:09:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:09:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:09:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:09:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:09:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:09:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:09:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:09:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:09:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:09:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:10:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:10:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:10:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:10:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:10:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:10:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:10:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:10:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:10:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:10:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:10:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:10:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:10:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:10:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:10:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:11:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:11:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:11:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:11:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:11:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:11:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:11:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:11:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:11:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:11:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:11:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:11:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:11:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:11:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:12:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:12:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:12:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:12:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:12:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:12:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:12:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:12:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:12:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:12:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:12:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:12:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:12:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:12:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:12:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:12:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:13:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:13:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:13:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:13:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:13:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:13:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:13:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:13:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:13:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:13:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:13:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:13:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:13:51 2022 =-=-=-=-=\n",
      "[1] \"60 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:14:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:14:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:14:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:14:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:14:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:14:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:14:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:14:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:14:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:14:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:14:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:14:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:14:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:14:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:14:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:14:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:15:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:15:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:15:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:15:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:15:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:15:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:15:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:15:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:15:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:15:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:15:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:15:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:15:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:15:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:16:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:16:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:16:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:16:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:16:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:16:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:16:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:16:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:16:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:16:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:16:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:16:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:16:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:16:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:16:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:17:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:17:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:17:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:17:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:17:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:17:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:17:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:17:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:17:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:17:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:17:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:17:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:17:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:17:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:17:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:18:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:18:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:18:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:18:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:18:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:18:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:18:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:18:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:18:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:18:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:18:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:18:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:18:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:18:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:18:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:19:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:19:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:19:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:19:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:19:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:19:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:19:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:19:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:19:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:19:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:19:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:19:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:19:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:19:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:19:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:20:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:20:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:20:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:20:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:20:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:20:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:20:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:20:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:20:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:20:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:20:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:20:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:20:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:20:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:21:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:21:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:21:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:21:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:21:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:21:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:21:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:21:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:21:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:21:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:21:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:21:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:21:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:21:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:21:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:21:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:22:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:22:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:22:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:22:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:22:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:22:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:22:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:22:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:22:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:22:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:22:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:22:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:22:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:23:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:23:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:23:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:23:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:23:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:23:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:23:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:23:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:23:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:23:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:23:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:23:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:23:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:23:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:23:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:23:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:24:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:24:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:24:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:24:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:24:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:24:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:24:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:24:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:24:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:24:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:24:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:24:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:24:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:25:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:25:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:25:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:25:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:25:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:25:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:25:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:25:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:25:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:25:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:25:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:25:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:25:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:25:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:25:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:25:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:26:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:26:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:26:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:26:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:26:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:26:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:26:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:26:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:26:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:26:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:26:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:26:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:26:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:26:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:27:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:27:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:27:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:27:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:27:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:27:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:27:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:27:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:27:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:27:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:27:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:27:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:27:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:27:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:27:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:27:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:28:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:28:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:28:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:28:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:28:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:28:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:28:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:28:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:28:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:28:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:28:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:28:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:28:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:29:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:29:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:29:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:29:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:29:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:29:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:29:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:29:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:29:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:29:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:29:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:29:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:29:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:29:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:29:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:29:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:30:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:30:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:30:08 2022 =-=-=-=-=\n",
      "[1] \"70 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:30:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:30:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:30:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:30:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:30:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:30:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:30:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:30:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:30:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:30:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:30:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:31:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:31:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:31:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:31:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:31:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:31:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:31:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:31:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:31:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:31:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:31:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:31:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:31:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:31:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:31:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:32:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:32:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:32:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:32:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:32:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:32:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:32:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:32:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:32:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:32:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:32:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:32:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:32:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:32:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:33:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:33:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:33:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:33:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:33:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:33:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:33:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:33:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:33:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:33:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:33:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:33:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:33:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:33:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:33:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:33:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:34:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:34:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:34:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:34:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:34:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:34:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:34:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:34:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:34:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:34:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:34:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:34:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:34:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:34:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:35:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:35:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:35:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:35:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:35:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:35:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:35:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:35:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:35:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:35:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:35:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:35:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:35:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:35:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:35:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:35:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:36:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:36:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:36:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:36:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:36:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:36:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:36:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:36:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:36:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:36:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:36:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:36:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:36:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:36:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:37:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:37:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:37:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:37:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:37:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:37:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:37:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:37:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:37:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:37:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:37:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:37:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:37:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:37:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:37:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:38:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:38:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:38:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:38:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:38:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:38:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:38:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:38:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:38:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:38:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:38:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:38:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:38:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:38:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:38:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:39:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:39:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:39:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:39:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:39:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:39:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:39:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:39:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:39:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:39:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:39:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:39:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:39:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:39:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:40:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:40:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:40:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:40:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:40:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:40:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:40:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:40:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:40:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:40:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:40:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:40:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:40:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:40:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:40:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:40:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:41:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:41:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:41:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:41:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:41:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:41:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:41:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:41:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:41:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:41:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:41:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:41:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:41:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:41:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:42:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:42:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:42:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:42:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:42:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:42:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:42:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:42:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:42:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:42:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:42:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:42:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:42:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:42:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:42:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:42:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:43:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:43:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:43:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:43:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:43:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:43:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:43:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:43:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:43:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:43:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:43:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:43:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:43:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:43:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:44:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:44:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:44:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:44:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:44:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:44:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:44:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:44:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:44:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:44:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:44:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:44:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:44:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:44:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:44:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:44:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:45:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:45:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:45:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:45:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:45:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:45:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:45:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:45:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:45:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:45:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:45:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:45:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:45:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:46:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:46:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:46:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:46:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:46:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:46:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:46:20 2022 =-=-=-=-=\n",
      "[1] \"80 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:46:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:46:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:46:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:46:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:46:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:46:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:46:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:46:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:46:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:47:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:47:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:47:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:47:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:47:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:47:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:47:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:47:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:47:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:47:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:47:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:47:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:47:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:47:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:48:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:48:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:48:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:48:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:48:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:48:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:48:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:48:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:48:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:48:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:48:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:48:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:48:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:48:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:48:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:48:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:49:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:49:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:49:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:49:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:49:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:49:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:49:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:49:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:49:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:49:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:49:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:49:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:49:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:49:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:50:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:50:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:50:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:50:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:50:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:50:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:50:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:50:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:50:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:50:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:50:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:50:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:50:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:50:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:50:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:51:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:51:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:51:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:51:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:51:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:51:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:51:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:51:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:51:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:51:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:51:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:51:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:51:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:51:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:52:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:52:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:52:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:52:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:52:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:52:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:52:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:52:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:52:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:52:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:52:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:52:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:52:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:52:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:52:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:52:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:53:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:53:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:53:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:53:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:53:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:53:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:53:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:53:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:53:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:53:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:53:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:53:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:53:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:53:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:54:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:54:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:54:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:54:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:54:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:54:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:54:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:54:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:54:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:54:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:54:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:54:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:54:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:54:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:54:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:54:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:55:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:55:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:55:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:55:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:55:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:55:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:55:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:55:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:55:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:55:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:55:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:55:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:55:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:56:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:56:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:56:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:56:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:56:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:56:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:56:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:56:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:56:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:56:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:56:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:56:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:56:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:56:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:56:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:56:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:57:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:57:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:57:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:57:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:57:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:57:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:57:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:57:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:57:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:57:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:57:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:57:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:57:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:57:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:58:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:58:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:58:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:58:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:58:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:58:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:58:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:58:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:58:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:58:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:58:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:58:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:58:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:58:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:58:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:59:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:59:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:59:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:59:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:59:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:59:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:59:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:59:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:59:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:59:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:59:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:59:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:59:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:59:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:00:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:00:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:00:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:00:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:00:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:00:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:00:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:00:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:00:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:00:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:00:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:00:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:00:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:00:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:00:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:00:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:01:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:01:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:01:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:01:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:01:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:01:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:01:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:01:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:01:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:01:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:01:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:01:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:01:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:01:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:02:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:02:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:02:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:02:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:02:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:02:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:02:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:02:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:02:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:02:34 2022 =-=-=-=-=\n",
      "[1] \"90 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:02:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:02:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:02:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:02:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:02:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:02:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:03:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:03:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:03:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:03:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:03:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:03:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:03:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:03:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:03:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:03:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:03:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:03:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:03:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:03:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:04:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:04:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:04:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:04:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:04:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:04:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:04:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:04:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:04:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:04:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:04:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:04:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:04:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:04:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:04:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:04:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:05:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:05:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:05:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:05:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:05:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:05:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:05:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:05:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:05:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:05:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:05:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:05:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:05:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:05:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:06:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:06:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:06:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:06:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:06:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:06:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:06:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:06:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:06:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:06:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:06:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:06:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:06:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:06:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:06:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:07:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:07:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:07:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:07:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:07:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:07:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:07:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:07:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:07:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:07:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:07:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:07:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:07:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:07:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:07:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:08:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:08:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:08:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:08:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:08:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:08:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:08:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:08:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:08:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:08:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:08:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:08:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:08:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:08:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:08:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:09:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:09:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:09:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:09:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:09:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:09:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:09:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:09:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:09:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:09:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:09:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:09:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:09:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:09:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:09:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:10:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:10:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:10:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:10:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:10:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:10:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:10:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:10:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:10:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:10:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:10:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:10:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:10:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:10:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:11:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:11:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:11:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:11:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:11:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:11:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:11:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:11:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:11:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:11:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:11:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:11:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:11:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:11:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:11:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:12:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:12:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:12:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:12:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:12:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:12:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:12:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:12:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:12:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:12:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:12:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:12:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:12:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:12:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:13:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:13:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:13:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:13:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:13:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:13:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:13:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:13:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:13:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:13:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:13:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:13:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:13:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:13:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:13:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:13:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:14:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:14:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:14:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:14:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:14:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:14:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:14:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:14:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:14:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:14:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:14:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:14:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:14:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:14:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:15:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:15:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:15:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:15:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:15:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:15:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:15:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:15:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:15:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:15:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:15:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:15:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:15:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:15:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:15:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:16:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:16:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:16:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:16:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:16:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:16:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:16:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:16:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:16:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:16:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:16:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:16:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:16:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:16:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:17:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:17:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:17:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:17:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:17:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:17:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:17:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:17:25 2022 =-=-=-=-=\n"
     ]
    }
   ],
   "source": [
    "result.m02.3 <- my.tsCV.2(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                        xreg=trainx[,2:4], silent=F,\n",
    "                        xreg.msize=hori,\n",
    "                        sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc65fefd-60b9-4ab4-a840-d24018cef2fc",
   "metadata": {},
   "source": [
    "## Compare Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58355e11-c950-44f5-b241-665c8d6aa2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my.figsize(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f874535-9c29-405a-add4-9bbce090b23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94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\nwJQQAgAATAkhAADAlBACAABMCSEAAMBUZ2GtjEJQADgAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- new.get_result(result.m02.1, '1.BSTS')\n",
    "errors.2 <- new.get_result(result.m02.2, '2.BSTS w/ Regressors')\n",
    "errors.3 <- new.get_result(result.m02.3, '3.BSTS w/ Regressors (2)')\n",
    "\n",
    "#x <- errors.1\n",
    "x <- rbind(errors.1, errors.2)\n",
    "x <- rbind(x, errors.3)\n",
    "\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78dcd688-1d13-455f-a104-9ce887522de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m02 <- result.m02.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18309db-511c-4dca-aae2-184266480211",
   "metadata": {},
   "source": [
    "### save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90ba8638-887a-4a67-868c-d3612e3556db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x <- result.m02.1\n",
    "#write.csv(x, file = \"bsts_result_m0201.csv\")\n",
    "x <- result.m02.2\n",
    "write.csv(x, file = \"bsts_result_m0202.csv\")\n",
    "x <- result.m02.3\n",
    "write.csv(x, file = \"bsts_result_m0203.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d128253-162e-4222-b582-fb0ee3ef80e7",
   "metadata": {},
   "source": [
    "### load result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bb1bd39-9ed6-4fb6-8abe-4d35c9b83632",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.m02.1 <- read.csv(file = 'bsts_result_m0201.csv')\n",
    "result.m02.2 <- read.csv(file = 'bsts_result_m0202.csv')\n",
    "result.m02.3 <- read.csv(file = 'bsts_result_m0203.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69617942-9647-4c39-9fab-68b25004a5f6",
   "metadata": {},
   "source": [
    "# ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714a4470-8e12-439a-b2ef-3b3e4d106e65",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1649827c-2f89-40f9-939c-5a35daceab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast <- function(x, h, xreg=NULL, xreg.msize=NULL, order=NULL) {\n",
    "    \n",
    "    if (!is.null(xreg)) {\n",
    "        \n",
    "        if (is.null(xreg.msize)) {\n",
    "            xreg.m <- xreg # calc mean for future with all the xreg\n",
    "        } else {\n",
    "            # calc mean for future with xreg of length xreg.mszie\n",
    "            xreg.m <- tail(xreg, n=xreg.msize)\n",
    "        }\n",
    "        \n",
    "        if (is.null(dim(xreg))) {\n",
    "            xreg.h <- mean(xreg.m)\n",
    "        } else {\n",
    "            xreg.h <- colMeans(xreg.m)  \n",
    "        }\n",
    "        \n",
    "        xreg.h <- data.frame(xreg.h)\n",
    "        colnames(xreg.h) <- colnames(NA)\n",
    "        #colnames(xreg.h) <- colnames(xreg) # error with multiple xreg\n",
    "        xreg.h <- t(xreg.h)\n",
    "        xreg.h <- as.ts(xreg.h[rep(seq_len(nrow(xreg.h)), h), ])\n",
    "        \n",
    "        ## added for single day forecast\n",
    "        xreg.coln <- colnames(xreg)\n",
    "        xreg.h <- data.frame(xreg.h) # convert to frame for the case of single xreg\n",
    "        if ((dim(xreg.h)[2]==1) & (dim(xreg.h)[1]==length(xreg.coln))) {\n",
    "            xreg.h <- t(xreg.h) # the case of h==1\n",
    "        } else {\n",
    "            xreg.h <- as.ts(xreg.h) # convert to ts as xreg is ts\n",
    "        }\n",
    "        \n",
    "    } else {\n",
    "        xreg.h <- NULL\n",
    "    }\n",
    "    if (is.null(order)) {\n",
    "        fc <- forecast(auto.arima(x, trace=TRUE, ic='aicc', seasonal=FALSE, \n",
    "                                  xreg=xreg, \n",
    "                                  #lambda=\"auto\" # not for negative value\n",
    "                                  ), h=h, xreg=xreg.h)\n",
    "    } else {\n",
    "        fc <- forecast(Arima(x, order=order, seasonal=FALSE, \n",
    "                                  xreg=xreg, \n",
    "                                  ), h=h, xreg=xreg.h)\n",
    "    }\n",
    "    return(fc)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "712a592c-6bca-47e8-a995-1fc75b0e0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main difference with cv.forecast is that cv.forecase.2 need data for forecasting\n",
    "cv.forecast.2 <- function(x, h, xreg=NULL, xreg.msize=NULL, sample.n=0) \n",
    "{\n",
    "    result.rmse <- c()\n",
    "    result.mape <- c()\n",
    "    train.len <- length(x) - h\n",
    "    my.subset <- function(x, s, e) {\n",
    "        if (!is.null(x)) {\n",
    "            #x <- subset(x, start=s, end=e)\n",
    "            #x <- subset(as.ts(x), start=s, end=e)\n",
    "            x <- subset(ts(x), start=s, end=e)\n",
    "        }\n",
    "        return(x)\n",
    "    }\n",
    "    idx <- 0:(h-1)\n",
    "    if ((sample.n>0) & (sample.n<h)) {\n",
    "        idx <- sort(sample(idx, sample.n))\n",
    "    }\n",
    "    \n",
    "    order <- NULL\n",
    "    for (i in seq_along(idx)) {\n",
    "        trlen <- train.len+idx[i]\n",
    "        x.train <- my.subset(x, 1, trlen)\n",
    "        xreg.train <- my.subset(xreg, 1, trlen)\n",
    "        \n",
    "        fc <- cv.forecast(x.train, 1, xreg=xreg.train, xreg.msize=xreg.msize,\n",
    "                          order=order)\n",
    "        if (i==1) { # reuse param for the rest of periods\n",
    "            p <- fc$model$arma[1]\n",
    "            d <- fc$model$arma[6]\n",
    "            q <- fc$model$arma[2]\n",
    "            order <- c(p, d, q)\n",
    "        }\n",
    "        \n",
    "        result.rmse[i] <- sqrt(mean((fc$mean - x[trlen+1])^2))\n",
    "        result.mape[i] <- mean(abs(1 - fc$mean / x[trlen+1]))\n",
    "    }\n",
    "    e <- list(rmse.mean=mean(result.rmse), rmse.sigma=sd(result.rmse), \n",
    "              mape.mean=mean(result.mape), mape.sigma=sd(result.mape))\n",
    "    return(e)\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0145d7-e293-4fdd-8dbb-f62c0d26e658",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b05b4a06-7253-42c9-b6f0-28b182f99b79",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -8729.901\n",
      " ARIMA(1,0,0) with non-zero mean : -13486.9\n",
      " ARIMA(0,0,1) with non-zero mean : -10820.55\n",
      " ARIMA(0,0,0) with zero mean     : -8407.697\n",
      " ARIMA(2,0,0) with non-zero mean : -13491.63\n",
      " ARIMA(3,0,0) with non-zero mean : -13491.75\n",
      " ARIMA(4,0,0) with non-zero mean : -13496.44\n",
      " ARIMA(5,0,0) with non-zero mean : -13502.01\n",
      " ARIMA(5,0,1) with non-zero mean : -13509.96\n",
      " ARIMA(4,0,1) with non-zero mean : -13504.29\n",
      " ARIMA(5,0,2) with non-zero mean : -13507.99\n",
      " ARIMA(4,0,2) with non-zero mean : -13508.66\n",
      " ARIMA(5,0,1) with zero mean     : -13497.02\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,1) with non-zero mean : -13497.21\n",
      "\n",
      " Best model: ARIMA(5,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -13377.54\n",
      " ARIMA(1,1,0) with drift         : -13378.28\n",
      " ARIMA(0,1,1) with drift         : -13376.14\n",
      " ARIMA(0,1,0)                    : -13379.49\n",
      " ARIMA(1,1,1) with drift         : -13377.51\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -13388.23\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -13351.94\n",
      " ARIMA(0,1,0) with drift         : -13329.65\n",
      " ARIMA(1,1,0) with drift         : -13329.34\n",
      " ARIMA(0,1,1) with drift         : -13328.48\n",
      " ARIMA(0,1,0)                    : -13331.64\n",
      " ARIMA(1,1,2) with drift         : -13333.18\n",
      " ARIMA(2,1,1) with drift         : -13367.24\n",
      " ARIMA(1,1,1) with drift         : -13327.34\n",
      " ARIMA(2,1,0) with drift         : -13329.21\n",
      " ARIMA(3,1,1) with drift         : -13330.64\n",
      " ARIMA(3,1,0) with drift         : -13332.29\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1)                    : -13368.81\n",
      " ARIMA(1,1,1)                    : -13329.32\n",
      " ARIMA(2,1,0)                    : -13331.19\n",
      " ARIMA(3,1,1)                    : -13332.67\n",
      " ARIMA(2,1,2)                    : -13353.95\n",
      " ARIMA(1,1,0)                    : -13331.32\n",
      " ARIMA(1,1,2)                    : -13348.06\n",
      " ARIMA(3,1,0)                    : -13334.28\n",
      " ARIMA(3,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,1)                    : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -13393.73\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -13234.71\n",
      " ARIMA(1,1,0) with drift         : -13232.87\n",
      " ARIMA(0,1,1) with drift         : -13233.97\n",
      " ARIMA(0,1,0)                    : -13236.7\n",
      " ARIMA(1,1,1) with drift         : -13231.87\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -13245.39\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13263.35\n",
      " ARIMA(0,0,0) with non-zero mean : -8706.059\n",
      " ARIMA(1,0,0) with non-zero mean : -13255.84\n",
      " ARIMA(0,0,1) with non-zero mean : -10773.99\n",
      " ARIMA(0,0,0) with zero mean     : -8448.555\n",
      " ARIMA(1,0,2) with non-zero mean : -13260.91\n",
      " ARIMA(2,0,1) with non-zero mean : -13259.89\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -13259.02\n",
      " ARIMA(1,0,1) with non-zero mean : -13262.92\n",
      " ARIMA(1,0,3) with non-zero mean : -13261.08\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -13255.47\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13263\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13234.55\n",
      " ARIMA(0,0,0) with non-zero mean : -8691.834\n",
      " ARIMA(1,0,0) with non-zero mean : -13229.55\n",
      " ARIMA(0,0,1) with non-zero mean : -10751.25\n",
      " ARIMA(0,0,0) with zero mean     : -8433.02\n",
      " ARIMA(1,0,2) with non-zero mean : -13235.37\n",
      " ARIMA(0,0,2) with non-zero mean : -11866.88\n",
      " ARIMA(1,0,1) with non-zero mean : -13237.32\n",
      " ARIMA(2,0,1) with non-zero mean : -13225.93\n",
      " ARIMA(2,0,0) with non-zero mean : -13237.39\n",
      " ARIMA(3,0,0) with non-zero mean : -13234.61\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(2,0,0) with zero mean     : -13228.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,0) with non-zero mean : -13235.12\n",
      "\n",
      " Best model: ARIMA(2,0,0) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13226.64\n",
      " ARIMA(0,0,0) with non-zero mean : -8693.681\n",
      " ARIMA(1,0,0) with non-zero mean : -13220.86\n",
      " ARIMA(0,0,1) with non-zero mean : -10750.64\n",
      " ARIMA(0,0,0) with zero mean     : -8430.203\n",
      " ARIMA(1,0,2) with non-zero mean : -13226.25\n",
      " ARIMA(2,0,1) with non-zero mean : -13226.06\n",
      " ARIMA(3,0,2) with non-zero mean : -13309.63\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -13307.61\n",
      " ARIMA(2,0,3) with non-zero mean : -13226.59\n",
      " ARIMA(4,0,1) with non-zero mean : -13224.04\n",
      " ARIMA(4,0,3) with non-zero mean : -13224.26\n",
      " ARIMA(3,0,2) with zero mean     : -13300.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,2) with non-zero mean : -13225.89\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13223.46\n",
      " ARIMA(0,0,0) with non-zero mean : -8692.073\n",
      " ARIMA(1,0,0) with non-zero mean : -13216.09\n",
      " ARIMA(0,0,1) with non-zero mean : -10746.36\n",
      " ARIMA(0,0,0) with zero mean     : -8438.64\n",
      " ARIMA(1,0,2) with non-zero mean : -13219.99\n",
      " ARIMA(2,0,1) with non-zero mean : -13219.26\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -13218.58\n",
      " ARIMA(1,0,1) with non-zero mean : -13221.81\n",
      " ARIMA(1,0,3) with non-zero mean : -13219.71\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -13215.75\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13222.6\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -8686.987\n",
      " ARIMA(1,0,0) with non-zero mean : -13209.96\n",
      " ARIMA(0,0,1) with non-zero mean : -10738.7\n",
      " ARIMA(0,0,0) with zero mean     : -8426.26\n",
      " ARIMA(2,0,0) with non-zero mean : -13214.47\n",
      " ARIMA(3,0,0) with non-zero mean : -13211.74\n",
      " ARIMA(2,0,1) with non-zero mean : -13212.45\n",
      " ARIMA(1,0,1) with non-zero mean : -13215.28\n",
      " ARIMA(1,0,2) with non-zero mean : -13213.51\n",
      " ARIMA(0,0,2) with non-zero mean : -11840.92\n",
      " ARIMA(1,0,1) with zero mean     : -13207.44\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -13213.63\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13183.35\n",
      " ARIMA(0,0,0) with non-zero mean : -8605.008\n",
      " ARIMA(1,0,0) with non-zero mean : -13178.74\n",
      " ARIMA(0,0,1) with non-zero mean : -10671.87\n",
      " ARIMA(0,0,0) with zero mean     : -8372.744\n",
      " ARIMA(1,0,2) with non-zero mean : -13181.28\n",
      " ARIMA(2,0,1) with non-zero mean : -13180.26\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -13179.48\n",
      " ARIMA(1,0,1) with non-zero mean : -13183.22\n",
      " ARIMA(1,0,3) with non-zero mean : -13180.78\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -13173.21\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13183.36\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13157.75\n",
      " ARIMA(0,0,0) with non-zero mean : -8599.633\n",
      " ARIMA(1,0,0) with non-zero mean : -13156.4\n",
      " ARIMA(0,0,1) with non-zero mean : -10657.5\n",
      " ARIMA(0,0,0) with zero mean     : -8371.167\n",
      " ARIMA(1,0,2) with non-zero mean : -13159.03\n",
      " ARIMA(0,0,2) with non-zero mean : -11765.46\n",
      " ARIMA(1,0,1) with non-zero mean : -13161.04\n",
      " ARIMA(2,0,1) with non-zero mean : -13159.02\n",
      " ARIMA(2,0,0) with non-zero mean : -13160.94\n",
      " ARIMA(1,0,1) with zero mean     : -13153.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -13157.39\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13118.41\n",
      " ARIMA(0,0,0) with non-zero mean : -8582.353\n",
      " ARIMA(1,0,0) with non-zero mean : -13116.65\n",
      " ARIMA(0,0,1) with non-zero mean : -10629.58\n",
      " ARIMA(0,0,0) with zero mean     : -8368.258\n",
      " ARIMA(1,0,2) with non-zero mean : -13119.21\n",
      " ARIMA(0,0,2) with non-zero mean : -11723.45\n",
      " ARIMA(1,0,1) with non-zero mean : -13121.15\n",
      " ARIMA(2,0,1) with non-zero mean : -13118.75\n",
      " ARIMA(2,0,0) with non-zero mean : -13120.42\n",
      " ARIMA(1,0,1) with zero mean     : -13115.91\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -13113.39\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13071.29\n",
      " ARIMA(0,0,0) with non-zero mean : -8638.881\n",
      " ARIMA(1,0,0) with non-zero mean : -13070.54\n",
      " ARIMA(0,0,1) with non-zero mean : -10684.56\n",
      " ARIMA(0,0,0) with zero mean     : -8450.488\n",
      " ARIMA(1,0,2) with non-zero mean : -13073.57\n",
      " ARIMA(0,0,2) with non-zero mean : -11760.84\n",
      " ARIMA(1,0,1) with non-zero mean : -13074.77\n",
      " ARIMA(2,0,1) with non-zero mean : -13072.43\n",
      " ARIMA(2,0,0) with non-zero mean : -13073.94\n",
      " ARIMA(1,0,1) with zero mean     : -13068.78\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -13073.39\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13020.07\n",
      " ARIMA(0,0,0) with non-zero mean : -8626.698\n",
      " ARIMA(1,0,0) with non-zero mean : -13019.34\n",
      " ARIMA(0,0,1) with non-zero mean : -10666.27\n",
      " ARIMA(0,0,0) with zero mean     : -8430.999\n",
      " ARIMA(1,0,2) with non-zero mean : -13022.74\n",
      " ARIMA(0,0,2) with non-zero mean : -11728.64\n",
      " ARIMA(1,0,1) with non-zero mean : -13023.48\n",
      " ARIMA(2,0,1) with non-zero mean : -13021.47\n",
      " ARIMA(2,0,0) with non-zero mean : -13022.39\n",
      " ARIMA(1,0,1) with zero mean     : -13018.08\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -13022.46\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12895.32\n",
      " ARIMA(1,1,0) with drift         : -12892.39\n",
      " ARIMA(0,1,1) with drift         : -12893.4\n",
      " ARIMA(0,1,0)                    : -12897.3\n",
      " ARIMA(1,1,1) with drift         : -12891.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12905.83\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12860.21\n",
      " ARIMA(0,1,0) with drift         : -12826.47\n",
      " ARIMA(1,1,0) with drift         : -12823.83\n",
      " ARIMA(0,1,1) with drift         : -12824.58\n",
      " ARIMA(0,1,0)                    : -12828.46\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : -12831.77\n",
      " ARIMA(3,1,2) with drift         : -12826.3\n",
      " ARIMA(2,1,3) with drift         : -12865.48\n",
      " ARIMA(1,1,3) with drift         : -12829.73\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : -12864.1\n",
      " ARIMA(1,1,4) with drift         : -12827.86\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -12866.89\n",
      " ARIMA(1,1,3)                    : -12831.68\n",
      " ARIMA(2,1,2)                    : -12861.71\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : -12865.52\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,4)                    : -12829.85\n",
      " ARIMA(3,1,2)                    : -12828.31\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3)                    : -12840.65\n",
      "\n",
      " Best model: ARIMA(1,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -8273.531\n",
      " ARIMA(1,0,0) with non-zero mean : -12881.86\n",
      " ARIMA(0,0,1) with non-zero mean : -10351.3\n",
      " ARIMA(0,0,0) with zero mean     : -8122.831\n",
      " ARIMA(2,0,0) with non-zero mean : -12882.19\n",
      " ARIMA(3,0,0) with non-zero mean : -12880.27\n",
      " ARIMA(2,0,1) with non-zero mean : -12880.5\n",
      " ARIMA(1,0,1) with non-zero mean : -12883.25\n",
      " ARIMA(1,0,2) with non-zero mean : -12881.73\n",
      " ARIMA(0,0,2) with non-zero mean : -11451.56\n",
      " ARIMA(1,0,1) with zero mean     : -12879.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -12882.2\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12871.42\n",
      " ARIMA(0,0,0) with non-zero mean : -8262.48\n",
      " ARIMA(1,0,0) with non-zero mean : -12871.81\n",
      " ARIMA(0,0,1) with non-zero mean : -10340.93\n",
      " ARIMA(0,0,0) with zero mean     : -8109.969\n",
      " ARIMA(2,0,0) with non-zero mean : -12874.6\n",
      " ARIMA(3,0,0) with non-zero mean : -12872.38\n",
      " ARIMA(2,0,1) with non-zero mean : -12873.19\n",
      " ARIMA(1,0,1) with non-zero mean : -12874.05\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(2,0,0) with zero mean     : -12871.34\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,0) with non-zero mean : -12872.16\n",
      "\n",
      " Best model: ARIMA(2,0,0) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12770.64\n",
      " ARIMA(1,1,0) with drift         : -12768.42\n",
      " ARIMA(0,1,1) with drift         : -12768.88\n",
      " ARIMA(0,1,0)                    : -12772.63\n",
      " ARIMA(1,1,1) with drift         : -12767.46\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12781.1\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12763.47\n",
      " ARIMA(1,1,0) with drift         : -12760.68\n",
      " ARIMA(0,1,1) with drift         : -12761.67\n",
      " ARIMA(0,1,0)                    : -12765.47\n",
      " ARIMA(1,1,1) with drift         : -12759.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12773.95\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12720.9\n",
      " ARIMA(1,1,0) with drift         : -12718.16\n",
      " ARIMA(0,1,1) with drift         : -12719.09\n",
      " ARIMA(0,1,0)                    : -12722.86\n",
      " ARIMA(1,1,1) with drift         : -12716.81\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12731.32\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12666.53\n",
      " ARIMA(1,1,0) with drift         : -12663.76\n",
      " ARIMA(0,1,1) with drift         : -12664.79\n",
      " ARIMA(0,1,0)                    : -12668.52\n",
      " ARIMA(1,1,1) with drift         : -12662.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12676.95\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12648.97\n",
      " ARIMA(1,1,0) with drift         : -12646.42\n",
      " ARIMA(0,1,1) with drift         : -12647.47\n",
      " ARIMA(0,1,0)                    : -12650.97\n",
      " ARIMA(1,1,1) with drift         : -12645.43\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12659.4\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12632.45\n",
      " ARIMA(0,1,0) with drift         : -12633.22\n",
      " ARIMA(1,1,0) with drift         : -12630.63\n",
      " ARIMA(0,1,1) with drift         : -12631.67\n",
      " ARIMA(0,1,0)                    : -12635.23\n",
      " ARIMA(1,1,1) with drift         : -12629.76\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12643.64\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "[1] \"10 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12619.17\n",
      " ARIMA(1,1,0) with drift         : -12616.45\n",
      " ARIMA(0,1,1) with drift         : -12617.47\n",
      " ARIMA(0,1,0)                    : -12621.17\n",
      " ARIMA(1,1,1) with drift         : -12615.73\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12629.58\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12599.68\n",
      " ARIMA(1,1,0) with drift         : -12597.63\n",
      " ARIMA(0,1,1) with drift         : -12597.91\n",
      " ARIMA(0,1,0)                    : -12601.68\n",
      " ARIMA(1,1,1) with drift         : -12597.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12610.08\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12585.52\n",
      " ARIMA(1,1,0) with drift         : -12583.61\n",
      " ARIMA(0,1,1) with drift         : -12583.79\n",
      " ARIMA(0,1,0)                    : -12587.53\n",
      " ARIMA(1,1,1) with drift         : -12582.95\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12595.92\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12575.75\n",
      " ARIMA(1,1,0) with drift         : -12573.03\n",
      " ARIMA(0,1,1) with drift         : -12574\n",
      " ARIMA(0,1,0)                    : -12577.75\n",
      " ARIMA(1,1,1) with drift         : -12572.21\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12586.14\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12556.22\n",
      " ARIMA(0,1,0) with drift         : -12555.96\n",
      " ARIMA(1,1,0) with drift         : -12553.13\n",
      " ARIMA(0,1,1) with drift         : -12554.03\n",
      " ARIMA(0,1,0)                    : -12557.96\n",
      " ARIMA(1,1,1) with drift         : -12552.09\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12566.34\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12536.16\n",
      " ARIMA(0,1,0) with drift         : -12534.17\n",
      " ARIMA(1,1,0) with drift         : -12531.56\n",
      " ARIMA(0,1,1) with drift         : -12532.27\n",
      " ARIMA(0,1,0)                    : -12536.16\n",
      " ARIMA(1,1,1) with drift         : -12530.62\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12544.53\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12493.21\n",
      " ARIMA(0,1,0) with drift         : -12492.02\n",
      " ARIMA(1,1,0) with drift         : -12489.42\n",
      " ARIMA(0,1,1) with drift         : -12490.39\n",
      " ARIMA(0,1,0)                    : -12494.01\n",
      " ARIMA(1,1,1) with drift         : -12488.94\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12502.36\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12363.39\n",
      " ARIMA(1,1,0) with drift         : -12361.92\n",
      " ARIMA(0,1,1) with drift         : -12362.83\n",
      " ARIMA(0,1,0)                    : -12365.4\n",
      " ARIMA(1,1,1) with drift         : -12361.31\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12373.69\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12316.14\n",
      " ARIMA(0,1,0) with drift         : -12318.09\n",
      " ARIMA(1,1,0) with drift         : -12316.48\n",
      " ARIMA(0,1,1) with drift         : -12317.45\n",
      " ARIMA(0,1,0)                    : -12320.08\n",
      " ARIMA(1,1,1) with drift         : -12315.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12328.35\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12249.54\n",
      " ARIMA(0,1,0) with drift         : -12252.65\n",
      " ARIMA(1,1,0) with drift         : -12251.38\n",
      " ARIMA(0,1,1) with drift         : -12252.12\n",
      " ARIMA(0,1,0)                    : -12254.65\n",
      " ARIMA(1,1,1) with drift         : -12249.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12262.9\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12188.61\n",
      " ARIMA(0,1,0) with drift         : -12192.2\n",
      " ARIMA(1,1,0) with drift         : -12190.99\n",
      " ARIMA(0,1,1) with drift         : -12191.78\n",
      " ARIMA(0,1,0)                    : -12194.2\n",
      " ARIMA(1,1,1) with drift         : -12189.56\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12202.42\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12173.86\n",
      " ARIMA(0,1,0) with drift         : -12177.26\n",
      " ARIMA(1,1,0) with drift         : -12175.8\n",
      " ARIMA(0,1,1) with drift         : -12176.9\n",
      " ARIMA(0,1,0)                    : -12179.26\n",
      " ARIMA(1,1,1) with drift         : -12174.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12187.48\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12149.5\n",
      " ARIMA(0,1,0) with drift         : -12153.1\n",
      " ARIMA(1,1,0) with drift         : -12151.82\n",
      " ARIMA(0,1,1) with drift         : -12152.63\n",
      " ARIMA(0,1,0)                    : -12155.1\n",
      " ARIMA(1,1,1) with drift         : -12150.29\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12163.3\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12128.62\n",
      " ARIMA(1,1,0) with drift         : -12127.02\n",
      " ARIMA(0,1,1) with drift         : -12127.98\n",
      " ARIMA(0,1,0)                    : -12130.62\n",
      " ARIMA(1,1,1) with drift         : -12125.41\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12138.81\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12094.83\n",
      " ARIMA(1,1,0) with drift         : -12093.74\n",
      " ARIMA(0,1,1) with drift         : -12093.52\n",
      " ARIMA(0,1,0)                    : -12096.83\n",
      " ARIMA(1,1,1) with drift         : -12091.74\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12105.01\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12082.79\n",
      " ARIMA(0,1,0) with drift         : -12069.6\n",
      " ARIMA(1,1,0) with drift         : -12068.53\n",
      " ARIMA(0,1,1) with drift         : -12068.08\n",
      " ARIMA(0,1,0)                    : -12071.6\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : -12069.65\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -12085.65\n",
      " ARIMA(1,1,3) with drift         : -12069.73\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : -12083.73\n",
      " ARIMA(1,1,4) with drift         : -12068.47\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -12087.68\n",
      " ARIMA(1,1,3)                    : -12071.71\n",
      " ARIMA(2,1,2)                    : -12068.25\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : -12085.75\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,4)                    : -12070.48\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(1,1,3)                    : -12081.21\n",
      "\n",
      " Best model: ARIMA(1,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12082.77\n",
      " ARIMA(0,1,0) with drift         : -12062.29\n",
      " ARIMA(1,1,0) with drift         : -12059.83\n",
      " ARIMA(0,1,1) with drift         : -12060.73\n",
      " ARIMA(0,1,0)                    : -12064.29\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -12058.07\n",
      " ARIMA(1,1,3) with drift         : -12062.87\n",
      " ARIMA(3,1,1) with drift         : -12071.37\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12093.41\n",
      "\n",
      " Best model: ARIMA(2,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12051.59\n",
      " ARIMA(0,1,0) with drift         : -12056.79\n",
      " ARIMA(1,1,0) with drift         : -12054.21\n",
      " ARIMA(0,1,1) with drift         : -12055.13\n",
      " ARIMA(0,1,0)                    : -12058.79\n",
      " ARIMA(1,1,1) with drift         : -12052.52\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12066.95\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12040.97\n",
      " ARIMA(0,1,0) with drift         : -12045.69\n",
      " ARIMA(1,1,0) with drift         : -12043.05\n",
      " ARIMA(0,1,1) with drift         : -12043.96\n",
      " ARIMA(0,1,0)                    : -12047.7\n",
      " ARIMA(1,1,1) with drift         : -12041.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12055.85\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12035.51\n",
      " ARIMA(1,1,0) with drift         : -12032.9\n",
      " ARIMA(0,1,1) with drift         : -12033.73\n",
      " ARIMA(0,1,0)                    : -12037.51\n",
      " ARIMA(1,1,1) with drift         : -12030.9\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12045.67\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12023.14\n",
      " ARIMA(0,1,0) with drift         : -12028.48\n",
      " ARIMA(1,1,0) with drift         : -12025.73\n",
      " ARIMA(0,1,1) with drift         : -12026.67\n",
      " ARIMA(0,1,0)                    : -12030.49\n",
      " ARIMA(1,1,1) with drift         : -12023.73\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12038.64\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12061.44\n",
      " ARIMA(0,1,0) with drift         : -12023.42\n",
      " ARIMA(1,1,0) with drift         : -12020.51\n",
      " ARIMA(0,1,1) with drift         : -12021.52\n",
      " ARIMA(0,1,0)                    : -12025.42\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : -12021.41\n",
      " ARIMA(3,1,2) with drift         : -12033.17\n",
      " ARIMA(2,1,3) with drift         : -12067.9\n",
      " ARIMA(1,1,3) with drift         : -12035.78\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : -12066.17\n",
      " ARIMA(1,1,4) with drift         : -12034.04\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -12069.61\n",
      " ARIMA(1,1,3)                    : -12037.79\n",
      " ARIMA(2,1,2)                    : -12021.24\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : -12067.88\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,4)                    : -12036.05\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(1,1,3)                    : -12046.92\n",
      "\n",
      " Best model: ARIMA(1,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12015.63\n",
      " ARIMA(0,1,0) with drift         : -12021.2\n",
      " ARIMA(1,1,0) with drift         : -12018.3\n",
      " ARIMA(0,1,1) with drift         : -12019.28\n",
      " ARIMA(0,1,0)                    : -12023.2\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12031.34\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12019.53\n",
      " ARIMA(1,1,0) with drift         : -12016.78\n",
      " ARIMA(0,1,1) with drift         : -12017.59\n",
      " ARIMA(0,1,0)                    : -12021.53\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12029.68\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "[1] \"20 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12017.38\n",
      " ARIMA(1,1,0) with drift         : -12014.64\n",
      " ARIMA(0,1,1) with drift         : -12015.43\n",
      " ARIMA(0,1,0)                    : -12019.38\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12027.53\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12013.54\n",
      " ARIMA(1,1,0) with drift         : -12010.62\n",
      " ARIMA(0,1,1) with drift         : -12011.59\n",
      " ARIMA(0,1,0)                    : -12015.55\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12023.69\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12010.11\n",
      " ARIMA(1,1,0) with drift         : -12007.44\n",
      " ARIMA(0,1,1) with drift         : -12008.17\n",
      " ARIMA(0,1,0)                    : -12012.11\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12020.25\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12001.03\n",
      " ARIMA(1,1,0) with drift         : -11998.11\n",
      " ARIMA(0,1,1) with drift         : -11999.06\n",
      " ARIMA(0,1,0)                    : -12003.03\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12011.17\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11991.51\n",
      " ARIMA(0,1,0) with drift         : -11995.98\n",
      " ARIMA(1,1,0) with drift         : -11993.05\n",
      " ARIMA(0,1,1) with drift         : -11994.03\n",
      " ARIMA(0,1,0)                    : -11997.99\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12006.12\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11996.07\n",
      " ARIMA(1,1,0) with drift         : -11993.21\n",
      " ARIMA(0,1,1) with drift         : -11994.15\n",
      " ARIMA(0,1,0)                    : -11998.07\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12006.21\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11996.85\n",
      " ARIMA(1,1,0) with drift         : -11994.15\n",
      " ARIMA(0,1,1) with drift         : -11994.92\n",
      " ARIMA(0,1,0)                    : -11998.85\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12006.98\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12016.73\n",
      " ARIMA(0,1,0) with drift         : -11995.59\n",
      " ARIMA(1,1,0) with drift         : -11992.68\n",
      " ARIMA(0,1,1) with drift         : -11993.67\n",
      " ARIMA(0,1,0)                    : -11997.59\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12006.39\n",
      " ARIMA(3,1,1) with drift         : -12004.19\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12027.23\n",
      "\n",
      " Best model: ARIMA(2,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12012.2\n",
      " ARIMA(0,1,0) with drift         : -11990.52\n",
      " ARIMA(1,1,0) with drift         : -11987.63\n",
      " ARIMA(0,1,1) with drift         : -11988.63\n",
      " ARIMA(0,1,0)                    : -11992.52\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12001.17\n",
      " ARIMA(3,1,1) with drift         : -11999.02\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12022.54\n",
      "\n",
      " Best model: ARIMA(2,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12043.99\n",
      " ARIMA(0,1,0) with drift         : -11987.17\n",
      " ARIMA(1,1,0) with drift         : -11984.55\n",
      " ARIMA(0,1,1) with drift         : -11985.26\n",
      " ARIMA(0,1,0)                    : -11989.17\n",
      " ARIMA(1,1,2) with drift         : -12023.86\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11982.54\n",
      " ARIMA(1,1,3) with drift         : -11995.32\n",
      " ARIMA(3,1,1) with drift         : -11994.67\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12006.86\n",
      "\n",
      " Best model: ARIMA(1,1,3) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11981.5\n",
      " ARIMA(1,1,0) with drift         : -11979.09\n",
      " ARIMA(0,1,1) with drift         : -11979.6\n",
      " ARIMA(0,1,0)                    : -11983.5\n",
      " ARIMA(1,1,1) with drift         : -11977.09\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11991.63\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11978.9\n",
      " ARIMA(1,1,0) with drift         : -11976.01\n",
      " ARIMA(0,1,1) with drift         : -11977.01\n",
      " ARIMA(0,1,0)                    : -11980.91\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11989.03\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11981.39\n",
      " ARIMA(1,1,0) with drift         : -11978.69\n",
      " ARIMA(0,1,1) with drift         : -11979.53\n",
      " ARIMA(0,1,0)                    : -11983.39\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11991.52\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11986.98\n",
      " ARIMA(1,1,0) with drift         : -11984.6\n",
      " ARIMA(0,1,1) with drift         : -11985.09\n",
      " ARIMA(0,1,0)                    : -11988.99\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11997.12\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11992.9\n",
      " ARIMA(1,1,0) with drift         : -11989.96\n",
      " ARIMA(0,1,1) with drift         : -11990.96\n",
      " ARIMA(0,1,0)                    : -11994.9\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12003.04\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12013.09\n",
      " ARIMA(0,1,0) with drift         : -11992.3\n",
      " ARIMA(1,1,0) with drift         : -11989.52\n",
      " ARIMA(0,1,1) with drift         : -11990.35\n",
      " ARIMA(0,1,0)                    : -11994.3\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12002.95\n",
      " ARIMA(3,1,1) with drift         : -12001.79\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12024.89\n",
      "\n",
      " Best model: ARIMA(2,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11988.37\n",
      " ARIMA(1,1,0) with drift         : -11985.73\n",
      " ARIMA(0,1,1) with drift         : -11986.38\n",
      " ARIMA(0,1,0)                    : -11990.37\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11998.5\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11987.63\n",
      " ARIMA(1,1,0) with drift         : -11984.66\n",
      " ARIMA(0,1,1) with drift         : -11985.63\n",
      " ARIMA(0,1,0)                    : -11989.63\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11997.77\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12008.82\n",
      " ARIMA(0,1,0) with drift         : -11994.44\n",
      " ARIMA(1,1,0) with drift         : -11992.07\n",
      " ARIMA(0,1,1) with drift         : -11992.44\n",
      " ARIMA(0,1,0)                    : -11996.43\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : -11991.26\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12004.44\n",
      " ARIMA(3,1,1) with drift         : -12005.12\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(3,1,1) with drift         : -12014.85\n",
      "\n",
      " Best model: ARIMA(3,1,1) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12059.59\n",
      " ARIMA(0,1,0) with drift         : -12000.97\n",
      " ARIMA(1,1,0) with drift         : -11998.47\n",
      " ARIMA(0,1,1) with drift         : -11998.97\n",
      " ARIMA(0,1,0)                    : -12002.96\n",
      " ARIMA(1,1,2) with drift         : -12039.27\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12008.38\n",
      " ARIMA(3,1,1) with drift         : -12007.62\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -12061.58\n",
      " ARIMA(1,1,2)                    : -12041.15\n",
      " ARIMA(2,1,1)                    : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(1,1,1)                    : Inf\n",
      " ARIMA(1,1,3)                    : -12010.39\n",
      " ARIMA(3,1,1)                    : -12009.59\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(1,1,3)                    : -12023.37\n",
      "\n",
      " Best model: ARIMA(1,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12004.31\n",
      " ARIMA(1,1,0) with drift         : -12001.41\n",
      " ARIMA(0,1,1) with drift         : -12002.33\n",
      " ARIMA(0,1,0)                    : -12006.31\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12014.45\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12001.45\n",
      " ARIMA(1,1,0) with drift         : -11998.66\n",
      " ARIMA(0,1,1) with drift         : -11999.47\n",
      " ARIMA(0,1,0)                    : -12003.45\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12011.58\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11997.55\n",
      " ARIMA(1,1,0) with drift         : -11995.35\n",
      " ARIMA(0,1,1) with drift         : -11995.58\n",
      " ARIMA(0,1,0)                    : -11999.55\n",
      " ARIMA(1,1,1) with drift         : -11996.94\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12007.69\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12000.21\n",
      " ARIMA(1,1,0) with drift         : -11997.28\n",
      " ARIMA(0,1,1) with drift         : -11998.26\n",
      " ARIMA(0,1,0)                    : -12002.22\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12010.35\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "[1] \"30 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12023.7\n",
      " ARIMA(0,1,0) with drift         : -12005.68\n",
      " ARIMA(1,1,0) with drift         : -12003.47\n",
      " ARIMA(0,1,1) with drift         : -12003.75\n",
      " ARIMA(0,1,0)                    : -12007.68\n",
      " ARIMA(1,1,2) with drift         : -12005.34\n",
      " ARIMA(2,1,1) with drift         : -12003.68\n",
      " ARIMA(3,1,2) with drift         : -12015.1\n",
      " ARIMA(2,1,3) with drift         : -12015.95\n",
      " ARIMA(1,1,1) with drift         : -12032.52\n",
      " ARIMA(0,1,2) with drift         : -12004.11\n",
      " ARIMA(2,1,0) with drift         : -12003.5\n",
      " ARIMA(1,1,1)                    : -12034.31\n",
      " ARIMA(0,1,1)                    : -12005.76\n",
      " ARIMA(1,1,0)                    : -12005.48\n",
      " ARIMA(2,1,1)                    : -12005.7\n",
      " ARIMA(1,1,2)                    : -12035.81\n",
      " ARIMA(0,1,2)                    : -12006.11\n",
      " ARIMA(2,1,2)                    : -12025.67\n",
      " ARIMA(1,1,3)                    : -12006.67\n",
      " ARIMA(0,1,3)                    : -12007.76\n",
      " ARIMA(2,1,3)                    : -12017.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,1)                    : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -12028.35\n",
      "\n",
      " Best model: ARIMA(2,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12046.07\n",
      " ARIMA(0,1,0) with drift         : -12011.57\n",
      " ARIMA(1,1,0) with drift         : -12009.1\n",
      " ARIMA(0,1,1) with drift         : -12009.67\n",
      " ARIMA(0,1,0)                    : -12013.57\n",
      " ARIMA(1,1,2) with drift         : -12038.51\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12020.19\n",
      " ARIMA(3,1,1) with drift         : -12017.76\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -12048.07\n",
      " ARIMA(1,1,2)                    : -12040.13\n",
      " ARIMA(2,1,1)                    : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(1,1,1)                    : Inf\n",
      " ARIMA(1,1,3)                    : -12022.21\n",
      " ARIMA(3,1,1)                    : -12019.74\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(1,1,3)                    : -12034.44\n",
      "\n",
      " Best model: ARIMA(1,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12018.83\n",
      " ARIMA(1,1,0) with drift         : -12015.98\n",
      " ARIMA(0,1,1) with drift         : -12016.99\n",
      " ARIMA(0,1,0)                    : -12020.83\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12028.97\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12024.85\n",
      " ARIMA(1,1,0) with drift         : -12022.27\n",
      " ARIMA(0,1,1) with drift         : -12022.98\n",
      " ARIMA(0,1,0)                    : -12026.85\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12035\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12098.61\n",
      " ARIMA(0,1,0) with drift         : -12045.53\n",
      " ARIMA(1,1,0) with drift         : -12043.15\n",
      " ARIMA(0,1,1) with drift         : -12043.76\n",
      " ARIMA(0,1,0)                    : -12047.51\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : -12073.39\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12054.62\n",
      " ARIMA(3,1,1) with drift         : -12044.52\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -12065.34\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(1,1,3) with drift         : -12066.73\n",
      "\n",
      " Best model: ARIMA(1,1,3) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12144.36\n",
      " ARIMA(0,0,0) with non-zero mean : -7379.697\n",
      " ARIMA(1,0,0) with non-zero mean : -12138.61\n",
      " ARIMA(0,0,1) with non-zero mean : -9450.926\n",
      " ARIMA(0,0,0) with zero mean     : -7370.04\n",
      " ARIMA(1,0,2) with non-zero mean : -12135.74\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12143.93\n",
      " ARIMA(1,0,1) with non-zero mean : -12137.74\n",
      " ARIMA(1,0,3) with non-zero mean : -12133.76\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -12146.18\n",
      " ARIMA(1,0,2) with zero mean     : -12137.45\n",
      " ARIMA(2,0,1) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -12145.78\n",
      " ARIMA(1,0,1) with zero mean     : -12139.45\n",
      " ARIMA(1,0,3) with zero mean     : -12135.48\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12147.75\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12147.26\n",
      " ARIMA(0,0,0) with non-zero mean : -7401.445\n",
      " ARIMA(1,0,0) with non-zero mean : -12140.99\n",
      " ARIMA(0,0,1) with non-zero mean : -9469.226\n",
      " ARIMA(0,0,0) with zero mean     : -7394.298\n",
      " ARIMA(1,0,2) with non-zero mean : -12138.1\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -12195.99\n",
      " ARIMA(3,0,1) with non-zero mean : -12147.37\n",
      " ARIMA(4,0,2) with non-zero mean : -12145.28\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,1) with non-zero mean : -12147.34\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -12195.39\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,1) with non-zero mean : -12148.48\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12157.48\n",
      " ARIMA(0,0,0) with non-zero mean : -7410.828\n",
      " ARIMA(1,0,0) with non-zero mean : -12147.29\n",
      " ARIMA(0,0,1) with non-zero mean : -9478.417\n",
      " ARIMA(0,0,0) with zero mean     : -7404.159\n",
      " ARIMA(1,0,2) with non-zero mean : -12144.29\n",
      " ARIMA(2,0,1) with non-zero mean : -12154.72\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(1,0,1) with non-zero mean : -12146.3\n",
      " ARIMA(1,0,3) with non-zero mean : -12142.28\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -12159.07\n",
      " ARIMA(1,0,2) with zero mean     : -12145.95\n",
      " ARIMA(2,0,1) with zero mean     : -12156.33\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -12158.89\n",
      " ARIMA(1,0,1) with zero mean     : -12147.96\n",
      " ARIMA(1,0,3) with zero mean     : -12143.94\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12157.53\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12176.38\n",
      " ARIMA(0,0,0) with non-zero mean : -7415.23\n",
      " ARIMA(1,0,0) with non-zero mean : -12168.98\n",
      " ARIMA(0,0,1) with non-zero mean : -9487.159\n",
      " ARIMA(0,0,0) with zero mean     : -7406.617\n",
      " ARIMA(1,0,2) with non-zero mean : -12166.19\n",
      " ARIMA(2,0,1) with non-zero mean : -12172.69\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(1,0,1) with non-zero mean : -12168.2\n",
      " ARIMA(1,0,3) with non-zero mean : -12164.18\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12174.04\n",
      " ARIMA(2,0,2) with zero mean     : -12178.13\n",
      " ARIMA(1,0,2) with zero mean     : -12167.84\n",
      " ARIMA(2,0,1) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -12178.04\n",
      " ARIMA(1,0,1) with zero mean     : -12169.85\n",
      " ARIMA(1,0,3) with zero mean     : -12165.83\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -12175.41\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12178.54\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12191.2\n",
      " ARIMA(0,0,0) with non-zero mean : -7418.218\n",
      " ARIMA(1,0,0) with non-zero mean : -12177.16\n",
      " ARIMA(0,0,1) with non-zero mean : -9490.666\n",
      " ARIMA(0,0,0) with zero mean     : -7409.668\n",
      " ARIMA(1,0,2) with non-zero mean : -12174.36\n",
      " ARIMA(2,0,1) with non-zero mean : -12187.67\n",
      " ARIMA(3,0,2) with non-zero mean : -12192.93\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -12199.74\n",
      " ARIMA(4,0,1) with non-zero mean : -12195.36\n",
      " ARIMA(5,0,2) with non-zero mean : -12202.29\n",
      " ARIMA(5,0,1) with non-zero mean : -12201.86\n",
      " ARIMA(5,0,3) with non-zero mean : -12200.54\n",
      " ARIMA(4,0,3) with non-zero mean : -12197.97\n",
      " ARIMA(5,0,2) with zero mean     : -12203.38\n",
      " ARIMA(4,0,2) with zero mean     : -12201.32\n",
      " ARIMA(5,0,1) with zero mean     : -12203.33\n",
      " ARIMA(5,0,3) with zero mean     : -12202\n",
      " ARIMA(4,0,1) with zero mean     : -12196.89\n",
      " ARIMA(4,0,3) with zero mean     : -12199.44\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,2) with zero mean     : -12194.79\n",
      "\n",
      " Best model: ARIMA(5,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12230.95\n",
      " ARIMA(0,0,0) with non-zero mean : -7432.886\n",
      " ARIMA(1,0,0) with non-zero mean : -12217.68\n",
      " ARIMA(0,0,1) with non-zero mean : -9511.6\n",
      " ARIMA(0,0,0) with zero mean     : -7420.807\n",
      " ARIMA(1,0,2) with non-zero mean : -12215.37\n",
      " ARIMA(2,0,1) with non-zero mean : -12225.89\n",
      " ARIMA(3,0,2) with non-zero mean : -12228.34\n",
      " ARIMA(2,0,3) with non-zero mean : -12230.77\n",
      " ARIMA(1,0,1) with non-zero mean : -12217.34\n",
      " ARIMA(1,0,3) with non-zero mean : -12213.4\n",
      " ARIMA(3,0,1) with non-zero mean : -12229.7\n",
      " ARIMA(3,0,3) with non-zero mean : -12227.59\n",
      " ARIMA(2,0,2) with zero mean     : -12232.43\n",
      " ARIMA(1,0,2) with zero mean     : -12216.89\n",
      " ARIMA(2,0,1) with zero mean     : -12227.44\n",
      " ARIMA(3,0,2) with zero mean     : -12229.35\n",
      " ARIMA(2,0,3) with zero mean     : -12232.29\n",
      " ARIMA(1,0,1) with zero mean     : -12218.86\n",
      " ARIMA(1,0,3) with zero mean     : -12214.92\n",
      " ARIMA(3,0,1) with zero mean     : -12231.19\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12227.28\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12256.5\n",
      " ARIMA(0,0,0) with non-zero mean : -7445.42\n",
      " ARIMA(1,0,0) with non-zero mean : -12257.49\n",
      " ARIMA(0,0,1) with non-zero mean : -9535.569\n",
      " ARIMA(0,0,0) with zero mean     : -7434.489\n",
      " ARIMA(2,0,0) with non-zero mean : -12258.72\n",
      " ARIMA(3,0,0) with non-zero mean : -12256.04\n",
      " ARIMA(2,0,1) with non-zero mean : -12256.73\n",
      " ARIMA(1,0,1) with non-zero mean : -12258.14\n",
      " ARIMA(3,0,1) with non-zero mean : -12262.6\n",
      " ARIMA(4,0,1) with non-zero mean : -12265.56\n",
      " ARIMA(4,0,0) with non-zero mean : -12253.08\n",
      " ARIMA(5,0,1) with non-zero mean : -12257.65\n",
      " ARIMA(4,0,2) with non-zero mean : -12266.8\n",
      " ARIMA(3,0,2) with non-zero mean : -12306.42\n",
      " ARIMA(3,0,3) with non-zero mean : -12267.78\n",
      " ARIMA(2,0,3) with non-zero mean : -12256.89\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -12308.34\n",
      " ARIMA(2,0,2) with zero mean     : -12257.99\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -12268.17\n",
      " ARIMA(3,0,3) with zero mean     : -12269.37\n",
      " ARIMA(2,0,1) with zero mean     : -12258.26\n",
      " ARIMA(2,0,3) with zero mean     : -12258.42\n",
      " ARIMA(4,0,1) with zero mean     : -12267.17\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,1) with zero mean     : -12267.77\n",
      "\n",
      " Best model: ARIMA(4,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12267.03\n",
      " ARIMA(0,0,0) with non-zero mean : -7448.715\n",
      " ARIMA(1,0,0) with non-zero mean : -12270.76\n",
      " ARIMA(0,0,1) with non-zero mean : -9539.854\n",
      " ARIMA(0,0,0) with zero mean     : -7436.768\n",
      " ARIMA(2,0,0) with non-zero mean : -12271.22\n",
      " ARIMA(3,0,0) with non-zero mean : -12269.75\n",
      " ARIMA(2,0,1) with non-zero mean : -12279.57\n",
      " ARIMA(1,0,1) with non-zero mean : -12271.36\n",
      " ARIMA(3,0,1) with non-zero mean : -12277.62\n",
      " ARIMA(1,0,2) with non-zero mean : -12269.4\n",
      " ARIMA(3,0,2) with non-zero mean : -12277.69\n",
      " ARIMA(2,0,1) with zero mean     : -12271.86\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with non-zero mean : -12276.5\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12284.93\n",
      " ARIMA(0,0,0) with non-zero mean : -7471.436\n",
      " ARIMA(1,0,0) with non-zero mean : -12282\n",
      " ARIMA(0,0,1) with non-zero mean : -9557.207\n",
      " ARIMA(0,0,0) with zero mean     : -7461.747\n",
      " ARIMA(1,0,2) with non-zero mean : -12280.56\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -12291.07\n",
      " ARIMA(3,0,1) with non-zero mean : -12291.38\n",
      " ARIMA(3,0,0) with non-zero mean : -12279.73\n",
      " ARIMA(4,0,1) with non-zero mean : -12289.84\n",
      " ARIMA(2,0,0) with non-zero mean : -12282.65\n",
      " ARIMA(4,0,0) with non-zero mean : -12276.77\n",
      " ARIMA(4,0,2) with non-zero mean : -12288.12\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -12289.07\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12288.43\n",
      " ARIMA(0,0,0) with non-zero mean : -7491.792\n",
      " ARIMA(1,0,0) with non-zero mean : -12281.96\n",
      " ARIMA(0,0,1) with non-zero mean : -9570.926\n",
      " ARIMA(0,0,0) with zero mean     : -7486.785\n",
      " ARIMA(1,0,2) with non-zero mean : -12280.72\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -12278.07\n",
      " ARIMA(2,0,3) with non-zero mean : -12287.42\n",
      " ARIMA(1,0,1) with non-zero mean : -12282.58\n",
      " ARIMA(1,0,3) with non-zero mean : -12278.8\n",
      " ARIMA(3,0,1) with non-zero mean : -12291.64\n",
      " ARIMA(3,0,0) with non-zero mean : -12279.17\n",
      " ARIMA(4,0,1) with non-zero mean : -12289.74\n",
      " ARIMA(2,0,0) with non-zero mean : -12281.9\n",
      " ARIMA(4,0,0) with non-zero mean : -12276.18\n",
      " ARIMA(4,0,2) with non-zero mean : -12287.82\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -12289.87\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12285.11\n",
      " ARIMA(0,0,0) with non-zero mean : -7496.174\n",
      " ARIMA(1,0,0) with non-zero mean : -12281.29\n",
      " ARIMA(0,0,1) with non-zero mean : -9575.749\n",
      " ARIMA(0,0,0) with zero mean     : -7491.335\n",
      " ARIMA(1,0,2) with non-zero mean : -12279.85\n",
      " ARIMA(2,0,1) with non-zero mean : -12280.01\n",
      " ARIMA(3,0,2) with non-zero mean : -12290.63\n",
      " ARIMA(3,0,1) with non-zero mean : -12291.52\n",
      " ARIMA(3,0,0) with non-zero mean : -12279.18\n",
      " ARIMA(4,0,1) with non-zero mean : -12286.39\n",
      " ARIMA(2,0,0) with non-zero mean : -12282.04\n",
      " ARIMA(4,0,0) with non-zero mean : -12276.54\n",
      " ARIMA(4,0,2) with non-zero mean : -12293.13\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12289.1\n",
      " ARIMA(5,0,1) with non-zero mean : -12281.77\n",
      " ARIMA(5,0,3) with non-zero mean : -12288.54\n",
      " ARIMA(4,0,2) with zero mean     : -12294.75\n",
      " ARIMA(3,0,2) with zero mean     : -12292.38\n",
      " ARIMA(4,0,1) with zero mean     : -12288.01\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,1) with zero mean     : -12293.2\n",
      " ARIMA(3,0,3) with zero mean     : -12290.83\n",
      " ARIMA(5,0,1) with zero mean     : -12283.48\n",
      " ARIMA(5,0,3) with zero mean     : -12290.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,2) with zero mean     : -12297.18\n",
      "\n",
      " Best model: ARIMA(4,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12288.25\n",
      " ARIMA(0,0,0) with non-zero mean : -7487.697\n",
      " ARIMA(1,0,0) with non-zero mean : -12283.46\n",
      " ARIMA(0,0,1) with non-zero mean : -9569.537\n",
      " ARIMA(0,0,0) with zero mean     : -7481.002\n",
      " ARIMA(1,0,2) with non-zero mean : -12282.02\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12287.41\n",
      " ARIMA(1,0,1) with non-zero mean : -12283.88\n",
      " ARIMA(1,0,3) with non-zero mean : -12280.08\n",
      " ARIMA(3,0,1) with non-zero mean : -12291.9\n",
      " ARIMA(3,0,0) with non-zero mean : -12281.24\n",
      " ARIMA(4,0,1) with non-zero mean : -12283.79\n",
      " ARIMA(2,0,0) with non-zero mean : -12284.01\n",
      " ARIMA(4,0,0) with non-zero mean : -12279.07\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -12293\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12304.9\n",
      " ARIMA(0,0,0) with non-zero mean : -7489.45\n",
      " ARIMA(1,0,0) with non-zero mean : -12294.5\n",
      " ARIMA(0,0,1) with non-zero mean : -9570.78\n",
      " ARIMA(0,0,0) with zero mean     : -7482.208\n",
      " ARIMA(1,0,2) with non-zero mean : -12292.56\n",
      " ARIMA(2,0,1) with non-zero mean : -12299.81\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12303.87\n",
      " ARIMA(1,0,1) with non-zero mean : -12294.41\n",
      " ARIMA(1,0,3) with non-zero mean : -12290.57\n",
      " ARIMA(3,0,1) with non-zero mean : -12303.05\n",
      " ARIMA(3,0,3) with non-zero mean : -12300.62\n",
      " ARIMA(2,0,2) with zero mean     : -12306.73\n",
      " ARIMA(1,0,2) with zero mean     : -12294.33\n",
      " ARIMA(2,0,1) with zero mean     : -12301.66\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -12305.7\n",
      " ARIMA(1,0,1) with zero mean     : -12296.18\n",
      " ARIMA(1,0,3) with zero mean     : -12292.33\n",
      " ARIMA(3,0,1) with zero mean     : -12304.74\n",
      " ARIMA(3,0,3) with zero mean     : -12302.28\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12305.7\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12296.47\n",
      " ARIMA(0,0,0) with non-zero mean : -7512.433\n",
      " ARIMA(1,0,0) with non-zero mean : -12293.41\n",
      " ARIMA(0,0,1) with non-zero mean : -9590.106\n",
      " ARIMA(0,0,0) with zero mean     : -7507.644\n",
      " ARIMA(1,0,2) with non-zero mean : -12291.22\n",
      " ARIMA(2,0,1) with non-zero mean : -12290.49\n",
      " ARIMA(3,0,2) with non-zero mean : -12349.06\n",
      " ARIMA(3,0,1) with non-zero mean : -12288.8\n",
      " ARIMA(4,0,2) with non-zero mean : -12302.23\n",
      " ARIMA(3,0,3) with non-zero mean : -12348.81\n",
      " ARIMA(2,0,3) with non-zero mean : -12290.13\n",
      " ARIMA(4,0,1) with non-zero mean : -12303.48\n",
      " ARIMA(4,0,3) with non-zero mean : -12301.4\n",
      " ARIMA(3,0,2) with zero mean     : -12350.91\n",
      " ARIMA(2,0,2) with zero mean     : -12291.96\n",
      " ARIMA(3,0,1) with zero mean     : -12304.11\n",
      " ARIMA(4,0,2) with zero mean     : -12304.06\n",
      " ARIMA(3,0,3) with zero mean     : -12350.67\n",
      " ARIMA(2,0,1) with zero mean     : -12292.34\n",
      " ARIMA(2,0,3) with zero mean     : -12291.95\n",
      " ARIMA(4,0,1) with zero mean     : -12305.28\n",
      " ARIMA(4,0,3) with zero mean     : -12303.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,1) with zero mean     : -12302.9\n",
      "\n",
      " Best model: ARIMA(4,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12294.73\n",
      " ARIMA(0,0,0) with non-zero mean : -7523.726\n",
      " ARIMA(1,0,0) with non-zero mean : -12282.66\n",
      " ARIMA(0,0,1) with non-zero mean : -9599.263\n",
      " ARIMA(0,0,0) with zero mean     : -7518.565\n",
      " ARIMA(1,0,2) with non-zero mean : -12280.27\n",
      " ARIMA(2,0,1) with non-zero mean : -12290.51\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12293.89\n",
      " ARIMA(1,0,1) with non-zero mean : -12282.22\n",
      " ARIMA(1,0,3) with non-zero mean : -12278.26\n",
      " ARIMA(3,0,1) with non-zero mean : -12292.79\n",
      " ARIMA(3,0,3) with non-zero mean : -12290.64\n",
      " ARIMA(2,0,2) with zero mean     : -12296.31\n",
      " ARIMA(1,0,2) with zero mean     : -12281.96\n",
      " ARIMA(2,0,1) with zero mean     : -12292.13\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -12295.48\n",
      " ARIMA(1,0,1) with zero mean     : -12283.92\n",
      " ARIMA(1,0,3) with zero mean     : -12279.96\n",
      " ARIMA(3,0,1) with zero mean     : -12294.58\n",
      " ARIMA(3,0,3) with zero mean     : -12292.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12292.19\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12310.49\n",
      " ARIMA(0,0,0) with non-zero mean : -7579.667\n",
      " ARIMA(1,0,0) with non-zero mean : -12312.78\n",
      " ARIMA(0,0,1) with non-zero mean : -9644.894\n",
      " ARIMA(0,0,0) with zero mean     : -7568.096\n",
      " ARIMA(2,0,0) with non-zero mean : -12313.95\n",
      " ARIMA(3,0,0) with non-zero mean : -12311.6\n",
      " ARIMA(2,0,1) with non-zero mean : -12311.94\n",
      " ARIMA(1,0,1) with non-zero mean : -12311.83\n",
      " ARIMA(3,0,1) with non-zero mean : -12308.85\n",
      " ARIMA(2,0,0) with zero mean     : -12315.33\n",
      " ARIMA(1,0,0) with zero mean     : -12314.23\n",
      " ARIMA(3,0,0) with zero mean     : -12312.98\n",
      " ARIMA(2,0,1) with zero mean     : -12313.26\n",
      " ARIMA(1,0,1) with zero mean     : -12313.27\n",
      " ARIMA(3,0,1) with zero mean     : -12310.2\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,0) with zero mean     : -12312.02\n",
      "\n",
      " Best model: ARIMA(2,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -7575.447\n",
      " ARIMA(1,0,0) with non-zero mean : -12376.55\n",
      " ARIMA(0,0,1) with non-zero mean : -9658.299\n",
      " ARIMA(0,0,0) with zero mean     : -7561.632\n",
      " ARIMA(2,0,0) with non-zero mean : -12375.94\n",
      " ARIMA(1,0,1) with non-zero mean : -12375.92\n",
      " ARIMA(2,0,1) with non-zero mean : -12393.48\n",
      " ARIMA(3,0,1) with non-zero mean : -12385.09\n",
      " ARIMA(1,0,2) with non-zero mean : -12374.8\n",
      " ARIMA(3,0,0) with non-zero mean : -12373.92\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -12395.1\n",
      " ARIMA(1,0,1) with zero mean     : -12377.4\n",
      " ARIMA(2,0,0) with zero mean     : -12377.45\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(2,0,2) with zero mean     : Inf\n",
      " ARIMA(1,0,0) with zero mean     : -12378.05\n",
      " ARIMA(1,0,2) with zero mean     : -12376.26\n",
      " ARIMA(3,0,0) with zero mean     : -12375.41\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with zero mean     : -12385.55\n",
      "\n",
      " Best model: ARIMA(2,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12383.96\n",
      " ARIMA(0,0,0) with non-zero mean : -7636.592\n",
      " ARIMA(1,0,0) with non-zero mean : -12385.34\n",
      " ARIMA(0,0,1) with non-zero mean : -9698.714\n",
      " ARIMA(0,0,0) with zero mean     : -7631.109\n",
      " ARIMA(2,0,0) with non-zero mean : -12387.27\n",
      " ARIMA(3,0,0) with non-zero mean : -12385.41\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(1,0,1) with non-zero mean : -12383.83\n",
      " ARIMA(3,0,1) with non-zero mean : -12396.18\n",
      " ARIMA(4,0,1) with non-zero mean : -12382.81\n",
      " ARIMA(3,0,2) with non-zero mean : -12395.78\n",
      " ARIMA(4,0,0) with non-zero mean : -12384.08\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -12389.8\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12386.98\n",
      " ARIMA(0,0,0) with non-zero mean : -7665.854\n",
      " ARIMA(1,0,0) with non-zero mean : -12379.12\n",
      " ARIMA(0,0,1) with non-zero mean : -9722.335\n",
      " ARIMA(0,0,0) with zero mean     : -7662.672\n",
      " ARIMA(1,0,2) with non-zero mean : -12376.91\n",
      " ARIMA(2,0,1) with non-zero mean : -12385.12\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12385.91\n",
      " ARIMA(1,0,1) with non-zero mean : -12377.7\n",
      " ARIMA(1,0,3) with non-zero mean : -12375.44\n",
      " ARIMA(3,0,1) with non-zero mean : -12385.99\n",
      " ARIMA(3,0,3) with non-zero mean : -12396.33\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -12394.71\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -12398.09\n",
      " ARIMA(2,0,3) with zero mean     : -12387.69\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -12388.8\n",
      " ARIMA(2,0,4) with zero mean     : -12377.08\n",
      " ARIMA(4,0,2) with zero mean     : -12396.46\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with zero mean     : -12397.04\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "[1] \"40 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12372.1\n",
      " ARIMA(0,0,0) with non-zero mean : -7638.056\n",
      " ARIMA(1,0,0) with non-zero mean : -12367.87\n",
      " ARIMA(0,0,1) with non-zero mean : -9696.992\n",
      " ARIMA(0,0,0) with zero mean     : -7638.917\n",
      " ARIMA(1,0,2) with non-zero mean : -12365.83\n",
      " ARIMA(2,0,1) with non-zero mean : -12370.39\n",
      " ARIMA(3,0,2) with non-zero mean : -12376.09\n",
      " ARIMA(3,0,1) with non-zero mean : -12376.91\n",
      " ARIMA(3,0,0) with non-zero mean : -12364.17\n",
      " ARIMA(4,0,1) with non-zero mean : -12371.52\n",
      " ARIMA(2,0,0) with non-zero mean : -12365.48\n",
      " ARIMA(4,0,0) with non-zero mean : -12363.21\n",
      " ARIMA(4,0,2) with non-zero mean : -12384.24\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,1) with non-zero mean : -12363.16\n",
      " ARIMA(5,0,3) with non-zero mean : -12358.93\n",
      " ARIMA(4,0,2) with zero mean     : -12386.23\n",
      " ARIMA(3,0,2) with zero mean     : -12377.81\n",
      " ARIMA(4,0,1) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -12399.98\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -12386.19\n",
      "\n",
      " Best model: ARIMA(4,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12382.29\n",
      " ARIMA(0,0,0) with non-zero mean : -7629.492\n",
      " ARIMA(1,0,0) with non-zero mean : -12385.42\n",
      " ARIMA(0,0,1) with non-zero mean : -9699.086\n",
      " ARIMA(0,0,0) with zero mean     : -7630.842\n",
      " ARIMA(2,0,0) with non-zero mean : -12384.88\n",
      " ARIMA(1,0,1) with non-zero mean : -12384.14\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(1,0,0) with zero mean     : -12387.41\n",
      " ARIMA(2,0,0) with zero mean     : -12386.87\n",
      " ARIMA(1,0,1) with zero mean     : -12386.14\n",
      " ARIMA(0,0,1) with zero mean     : -9700.538\n",
      " ARIMA(2,0,1) with zero mean     : -12384.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,0) with zero mean     : -12386.2\n",
      "\n",
      " Best model: ARIMA(1,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12379.96\n",
      " ARIMA(0,0,0) with non-zero mean : -7632.211\n",
      " ARIMA(1,0,0) with non-zero mean : -12374.22\n",
      " ARIMA(0,0,1) with non-zero mean : -9700.155\n",
      " ARIMA(0,0,0) with zero mean     : -7634.093\n",
      " ARIMA(1,0,2) with non-zero mean : -12371.66\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -12387.1\n",
      " ARIMA(3,0,1) with non-zero mean : -12370.64\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12375.05\n",
      " ARIMA(2,0,3) with non-zero mean : -12382.17\n",
      " ARIMA(4,0,1) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -12424.22\n",
      " ARIMA(5,0,3) with non-zero mean : -12430.73\n",
      " ARIMA(5,0,2) with non-zero mean : -12370.49\n",
      " ARIMA(5,0,4) with non-zero mean : -12414.34\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : -12412.76\n",
      "\n",
      " Best model: ARIMA(5,0,4) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12372.17\n",
      " ARIMA(0,0,0) with non-zero mean : -7632.978\n",
      " ARIMA(1,0,0) with non-zero mean : -12362.63\n",
      " ARIMA(0,0,1) with non-zero mean : -9696.85\n",
      " ARIMA(0,0,0) with zero mean     : -7634.852\n",
      " ARIMA(1,0,2) with non-zero mean : -12359.87\n",
      " ARIMA(2,0,1) with non-zero mean : -12370.59\n",
      " ARIMA(3,0,2) with non-zero mean : -12380.13\n",
      " ARIMA(3,0,1) with non-zero mean : -12365.23\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12378.26\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,1) with non-zero mean : -12369.57\n",
      " ARIMA(4,0,3) with non-zero mean : -12413.15\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -12404.7\n",
      " ARIMA(3,0,4) with non-zero mean : -12380.06\n",
      " ARIMA(5,0,2) with non-zero mean : -12357.86\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -12415.18\n",
      " ARIMA(3,0,3) with zero mean     : -12380.26\n",
      " ARIMA(4,0,2) with zero mean     : -12379.48\n",
      " ARIMA(5,0,3) with zero mean     : -12402.01\n",
      " ARIMA(4,0,4) with zero mean     : -12404.73\n",
      " ARIMA(3,0,2) with zero mean     : -12382.14\n",
      " ARIMA(3,0,4) with zero mean     : -12382.08\n",
      " ARIMA(5,0,2) with zero mean     : -12359.88\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -12381.67\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12370.68\n",
      " ARIMA(0,0,0) with non-zero mean : -7632.239\n",
      " ARIMA(1,0,0) with non-zero mean : -12374.84\n",
      " ARIMA(0,0,1) with non-zero mean : -9694.237\n",
      " ARIMA(0,0,0) with zero mean     : -7634.062\n",
      " ARIMA(2,0,0) with non-zero mean : -12372.61\n",
      " ARIMA(1,0,1) with non-zero mean : -12373.2\n",
      " ARIMA(2,0,1) with non-zero mean : -12370.81\n",
      " ARIMA(1,0,0) with zero mean     : -12376.82\n",
      " ARIMA(2,0,0) with zero mean     : -12374.6\n",
      " ARIMA(1,0,1) with zero mean     : -12375.19\n",
      " ARIMA(0,0,1) with zero mean     : -9696.14\n",
      " ARIMA(2,0,1) with zero mean     : -12372.8\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,0) with zero mean     : -12374.11\n",
      "\n",
      " Best model: ARIMA(1,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12380.54\n",
      " ARIMA(0,0,0) with non-zero mean : -7616.551\n",
      " ARIMA(1,0,0) with non-zero mean : -12374.77\n",
      " ARIMA(0,0,1) with non-zero mean : -9683.817\n",
      " ARIMA(0,0,0) with zero mean     : -7618.513\n",
      " ARIMA(1,0,2) with non-zero mean : -12371.59\n",
      " ARIMA(2,0,1) with non-zero mean : -12379.25\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(1,0,1) with non-zero mean : -12373.11\n",
      " ARIMA(1,0,3) with non-zero mean : -12370.14\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12386.46\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -12385\n",
      " ARIMA(2,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -12393.23\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : -12407.97\n",
      " ARIMA(3,0,5) with non-zero mean : -12418.55\n",
      " ARIMA(2,0,5) with non-zero mean : -12380.2\n",
      " ARIMA(3,0,5) with zero mean     : -12420.47\n",
      " ARIMA(2,0,5) with zero mean     : -12382.22\n",
      " ARIMA(3,0,4) with zero mean     : -12391.04\n",
      " ARIMA(4,0,5) with zero mean     : -12409.98\n",
      " ARIMA(2,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : -12395\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with zero mean     : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -12394.39\n",
      "\n",
      " Best model: ARIMA(3,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -7593.37\n",
      " ARIMA(1,0,0) with non-zero mean : -12357.29\n",
      " ARIMA(0,0,1) with non-zero mean : -9659.48\n",
      " ARIMA(0,0,0) with zero mean     : -7594.572\n",
      " ARIMA(2,0,0) with non-zero mean : -12355.13\n",
      " ARIMA(1,0,1) with non-zero mean : -12355.44\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(1,0,0) with zero mean     : -12359.26\n",
      " ARIMA(2,0,0) with zero mean     : -12357.09\n",
      " ARIMA(1,0,1) with zero mean     : -12357.41\n",
      " ARIMA(0,0,1) with zero mean     : -9660.873\n",
      " ARIMA(2,0,1) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,0) with zero mean     : -12357.88\n",
      "\n",
      " Best model: ARIMA(1,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12358.85\n",
      " ARIMA(0,0,0) with non-zero mean : -7612.88\n",
      " ARIMA(1,0,0) with non-zero mean : -12352.73\n",
      " ARIMA(0,0,1) with non-zero mean : -9667.962\n",
      " ARIMA(0,0,0) with zero mean     : -7614.768\n",
      " ARIMA(1,0,2) with non-zero mean : -12349.17\n",
      " ARIMA(2,0,1) with non-zero mean : -12359.18\n",
      " ARIMA(1,0,1) with non-zero mean : -12350.72\n",
      " ARIMA(2,0,0) with non-zero mean : -12349.76\n",
      " ARIMA(3,0,1) with non-zero mean : -12352.18\n",
      " ARIMA(3,0,0) with non-zero mean : -12348.2\n",
      " ARIMA(3,0,2) with non-zero mean : -12402.73\n",
      " ARIMA(4,0,2) with non-zero mean : -12357.4\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,1) with non-zero mean : -12353.57\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -12403.67\n",
      " ARIMA(2,0,2) with zero mean     : -12360.86\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -12359.45\n",
      " ARIMA(3,0,3) with zero mean     : -12405.32\n",
      " ARIMA(2,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -12404.75\n",
      " ARIMA(2,0,4) with zero mean     : -12351.32\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -12360.99\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12245.28\n",
      " ARIMA(0,0,0) with non-zero mean : -7579.394\n",
      " ARIMA(1,0,0) with non-zero mean : -12250.31\n",
      " ARIMA(0,0,1) with non-zero mean : -9614.418\n",
      " ARIMA(0,0,0) with zero mean     : -7580.618\n",
      " ARIMA(2,0,0) with non-zero mean : -12248.88\n",
      " ARIMA(1,0,1) with non-zero mean : -12248.42\n",
      " ARIMA(2,0,1) with non-zero mean : -12247.28\n",
      " ARIMA(1,0,0) with zero mean     : -12252.25\n",
      " ARIMA(2,0,0) with zero mean     : -12250.84\n",
      " ARIMA(1,0,1) with zero mean     : -12250.37\n",
      " ARIMA(0,0,1) with zero mean     : -9615.668\n",
      " ARIMA(2,0,1) with zero mean     : -12249.09\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,0) with zero mean     : -12249.31\n",
      "\n",
      " Best model: ARIMA(1,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11918.13\n",
      " ARIMA(0,0,0) with non-zero mean : -7093.706\n",
      " ARIMA(1,0,0) with non-zero mean : -11917.05\n",
      " ARIMA(0,0,1) with non-zero mean : -9189.946\n",
      " ARIMA(0,0,0) with zero mean     : -7089.844\n",
      " ARIMA(1,0,2) with non-zero mean : -11919.1\n",
      " ARIMA(0,0,2) with non-zero mean : -10255.34\n",
      " ARIMA(1,0,1) with non-zero mean : -11919.47\n",
      " ARIMA(2,0,1) with non-zero mean : -11926.69\n",
      " ARIMA(2,0,0) with non-zero mean : -11918.19\n",
      " ARIMA(3,0,1) with non-zero mean : -11918.52\n",
      " ARIMA(3,0,0) with non-zero mean : -11918.52\n",
      " ARIMA(3,0,2) with non-zero mean : -11964.9\n",
      " ARIMA(4,0,2) with non-zero mean : -11921.13\n",
      " ARIMA(3,0,3) with non-zero mean : -11919.65\n",
      " ARIMA(2,0,3) with non-zero mean : -11921.89\n",
      " ARIMA(4,0,1) with non-zero mean : -11922.48\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11965.73\n",
      " ARIMA(2,0,2) with zero mean     : -11919.78\n",
      " ARIMA(3,0,1) with zero mean     : -11920.19\n",
      " ARIMA(4,0,2) with zero mean     : -11922.77\n",
      " ARIMA(3,0,3) with zero mean     : -11921.72\n",
      " ARIMA(2,0,1) with zero mean     : -11928.33\n",
      " ARIMA(2,0,3) with zero mean     : -11923.53\n",
      " ARIMA(4,0,1) with zero mean     : -11924.09\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11982.88\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11592.45\n",
      " ARIMA(0,1,0) with drift         : -11555.24\n",
      " ARIMA(1,1,0) with drift         : -11572.02\n",
      " ARIMA(0,1,1) with drift         : -11577.1\n",
      " ARIMA(0,1,0)                    : -11557.22\n",
      " ARIMA(1,1,2) with drift         : -11589.93\n",
      " ARIMA(2,1,1) with drift         : -11592.45\n",
      " ARIMA(1,1,1) with drift         : -11581.25\n",
      " ARIMA(2,1,0) with drift         : -11591.47\n",
      " ARIMA(3,1,1) with drift         : -11590.91\n",
      " ARIMA(3,1,0) with drift         : -11592.77\n",
      " ARIMA(4,1,0) with drift         : -11594.37\n",
      " ARIMA(5,1,0) with drift         : -11597.15\n",
      " ARIMA(5,1,1) with drift         : -11624.61\n",
      " ARIMA(4,1,1) with drift         : -11595.39\n",
      " ARIMA(5,1,2) with drift         : -11634.3\n",
      " ARIMA(4,1,2) with drift         : -11650.69\n",
      " ARIMA(3,1,2) with drift         : -11589.14\n",
      " ARIMA(4,1,3) with drift         : -11594.46\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(5,1,3) with drift         : -11642.34\n",
      " ARIMA(4,1,2)                    : -11652.57\n",
      " ARIMA(3,1,2)                    : -11591.12\n",
      " ARIMA(4,1,1)                    : -11597.4\n",
      " ARIMA(5,1,2)                    : -11636.3\n",
      " ARIMA(4,1,3)                    : -11596.53\n",
      " ARIMA(3,1,1)                    : -11592.9\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(5,1,1)                    : Inf\n",
      " ARIMA(5,1,3)                    : -11644.74\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(5,1,3)                    : Inf\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(5,1,2)                    : Inf\n",
      " ARIMA(5,1,2) with drift         : Inf\n",
      " ARIMA(5,1,1) with drift         : -11640.1\n",
      "\n",
      " Best model: ARIMA(5,1,1) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11415.47\n",
      " ARIMA(0,1,0) with drift         : -11362.54\n",
      " ARIMA(1,1,0) with drift         : -11389.78\n",
      " ARIMA(0,1,1) with drift         : -11394.48\n",
      " ARIMA(0,1,0)                    : -11364.55\n",
      " ARIMA(1,1,2) with drift         : -11409.16\n",
      " ARIMA(2,1,1) with drift         : -11412.81\n",
      " ARIMA(3,1,2) with drift         : -11412.71\n",
      " ARIMA(2,1,3) with drift         : -11413.64\n",
      " ARIMA(1,1,1) with drift         : -11398.6\n",
      " ARIMA(1,1,3) with drift         : -11410.51\n",
      " ARIMA(3,1,1) with drift         : -11412.09\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11417.47\n",
      " ARIMA(1,1,2)                    : -11411.16\n",
      " ARIMA(2,1,1)                    : -11414.81\n",
      " ARIMA(3,1,2)                    : -11414.69\n",
      " ARIMA(2,1,3)                    : -11415.64\n",
      " ARIMA(1,1,1)                    : -11400.6\n",
      " ARIMA(1,1,3)                    : -11412.52\n",
      " ARIMA(3,1,1)                    : -11414.08\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11425.36\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11353.65\n",
      " ARIMA(0,1,0) with drift         : -11294.89\n",
      " ARIMA(1,1,0) with drift         : -11324.01\n",
      " ARIMA(0,1,1) with drift         : -11330.99\n",
      " ARIMA(0,1,0)                    : -11296.89\n",
      " ARIMA(1,1,2) with drift         : -11345.36\n",
      " ARIMA(2,1,1) with drift         : -11350.29\n",
      " ARIMA(3,1,2) with drift         : -11350.17\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11334.27\n",
      " ARIMA(1,1,3) with drift         : -11347.22\n",
      " ARIMA(3,1,1) with drift         : -11349.78\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11355.66\n",
      " ARIMA(1,1,2)                    : -11347.37\n",
      " ARIMA(2,1,1)                    : -11352.3\n",
      " ARIMA(3,1,2)                    : -11352.16\n",
      " ARIMA(2,1,3)                    : -11353.71\n",
      " ARIMA(1,1,1)                    : -11336.27\n",
      " ARIMA(1,1,3)                    : -11349.22\n",
      " ARIMA(3,1,1)                    : -11351.79\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11365.31\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11320.7\n",
      " ARIMA(0,1,0) with drift         : -11261.92\n",
      " ARIMA(1,1,0) with drift         : -11289.31\n",
      " ARIMA(0,1,1) with drift         : -11296.15\n",
      " ARIMA(0,1,0)                    : -11263.9\n",
      " ARIMA(1,1,2) with drift         : -11312.32\n",
      " ARIMA(2,1,1) with drift         : -11317.17\n",
      " ARIMA(3,1,2) with drift         : -11317.32\n",
      " ARIMA(2,1,3) with drift         : -11318.7\n",
      " ARIMA(1,1,1) with drift         : -11299.93\n",
      " ARIMA(1,1,3) with drift         : -11314.09\n",
      " ARIMA(3,1,1) with drift         : -11316.82\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11322.69\n",
      " ARIMA(1,1,2)                    : -11314.3\n",
      " ARIMA(2,1,1)                    : -11319.15\n",
      " ARIMA(3,1,2)                    : -11319.28\n",
      " ARIMA(2,1,3)                    : -11320.61\n",
      " ARIMA(1,1,1)                    : -11301.9\n",
      " ARIMA(1,1,3)                    : -11316.07\n",
      " ARIMA(3,1,1)                    : -11318.8\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11331.48\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11266.31\n",
      " ARIMA(0,1,0) with drift         : -11205.21\n",
      " ARIMA(1,1,0) with drift         : -11233.03\n",
      " ARIMA(0,1,1) with drift         : -11240.17\n",
      " ARIMA(0,1,0)                    : -11207.21\n",
      " ARIMA(1,1,2) with drift         : -11254.87\n",
      " ARIMA(2,1,1) with drift         : -11261.21\n",
      " ARIMA(3,1,2) with drift         : -11262.81\n",
      " ARIMA(2,1,3) with drift         : -11264.32\n",
      " ARIMA(1,1,1) with drift         : -11242.56\n",
      " ARIMA(1,1,3) with drift         : -11258.05\n",
      " ARIMA(3,1,1) with drift         : -11262.14\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11268.32\n",
      " ARIMA(1,1,2)                    : -11256.88\n",
      " ARIMA(2,1,1)                    : -11263.21\n",
      " ARIMA(3,1,2)                    : -11264.84\n",
      " ARIMA(2,1,3)                    : -11266.33\n",
      " ARIMA(1,1,1)                    : -11244.57\n",
      " ARIMA(1,1,3)                    : -11260.06\n",
      " ARIMA(3,1,1)                    : -11264.14\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11277.31\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11262.05\n",
      " ARIMA(0,1,0) with drift         : -11192.23\n",
      " ARIMA(1,1,0) with drift         : -11226.71\n",
      " ARIMA(0,1,1) with drift         : -11231.46\n",
      " ARIMA(0,1,0)                    : -11194.21\n",
      " ARIMA(1,1,2) with drift         : -11247.34\n",
      " ARIMA(2,1,1) with drift         : -11252.98\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11305.6\n",
      " ARIMA(1,1,3) with drift         : -11251.68\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : -11261.91\n",
      " ARIMA(1,1,4) with drift         : -11257.86\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11307.46\n",
      " ARIMA(1,1,3)                    : -11253.67\n",
      " ARIMA(2,1,2)                    : -11264.03\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : -11263.89\n",
      " ARIMA(1,1,2)                    : -11249.32\n",
      " ARIMA(1,1,4)                    : -11259.86\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,4)                    : -11294.48\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4)                    : -11267.25\n",
      "\n",
      " Best model: ARIMA(1,1,4)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11328.07\n",
      " ARIMA(0,0,0) with non-zero mean : -6737.816\n",
      " ARIMA(1,0,0) with non-zero mean : -11296.4\n",
      " ARIMA(0,0,1) with non-zero mean : -8758.488\n",
      " ARIMA(0,0,0) with zero mean     : -6726.062\n",
      " ARIMA(1,0,2) with non-zero mean : -11320.74\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11400.22\n",
      " ARIMA(3,0,1) with non-zero mean : -11334.05\n",
      " ARIMA(4,0,2) with non-zero mean : -11349.24\n",
      " ARIMA(3,0,3) with non-zero mean : -11349.61\n",
      " ARIMA(2,0,3) with non-zero mean : -11343.52\n",
      " ARIMA(4,0,1) with non-zero mean : -11346.17\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11401.72\n",
      " ARIMA(2,0,2) with zero mean     : -11329.9\n",
      " ARIMA(3,0,1) with zero mean     : -11335.87\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11351.36\n",
      " ARIMA(2,0,1) with zero mean     : -11314.01\n",
      " ARIMA(2,0,3) with zero mean     : -11345.27\n",
      " ARIMA(4,0,1) with zero mean     : -11347.94\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11350.88\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11324.39\n",
      " ARIMA(0,0,0) with non-zero mean : -6739.838\n",
      " ARIMA(1,0,0) with non-zero mean : -11291.47\n",
      " ARIMA(0,0,1) with non-zero mean : -8753.561\n",
      " ARIMA(0,0,0) with zero mean     : -6728.901\n",
      " ARIMA(1,0,2) with non-zero mean : -11317.24\n",
      " ARIMA(2,0,1) with non-zero mean : -11314.87\n",
      " ARIMA(3,0,2) with non-zero mean : -11397.8\n",
      " ARIMA(3,0,1) with non-zero mean : -11330.92\n",
      " ARIMA(4,0,2) with non-zero mean : -11345.12\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11338.13\n",
      " ARIMA(4,0,1) with non-zero mean : -11342.03\n",
      " ARIMA(4,0,3) with non-zero mean : -11399.92\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11398.25\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11401.72\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11346.63\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11399.42\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11405.72\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11314.12\n",
      " ARIMA(0,0,0) with non-zero mean : -6723.367\n",
      " ARIMA(1,0,0) with non-zero mean : -11283.77\n",
      " ARIMA(0,0,1) with non-zero mean : -8741.907\n",
      " ARIMA(0,0,0) with zero mean     : -6711.968\n",
      " ARIMA(1,0,2) with non-zero mean : -11307.4\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11381.18\n",
      " ARIMA(3,0,1) with non-zero mean : -11320.77\n",
      " ARIMA(4,0,2) with non-zero mean : -11332\n",
      " ARIMA(3,0,3) with non-zero mean : -11332.98\n",
      " ARIMA(2,0,3) with non-zero mean : -11328.13\n",
      " ARIMA(4,0,1) with non-zero mean : -11331.31\n",
      " ARIMA(4,0,3) with non-zero mean : -11383.32\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11382.31\n",
      " ARIMA(3,0,4) with non-zero mean : -11359.17\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11384.72\n",
      " ARIMA(3,0,3) with zero mean     : -11334.68\n",
      " ARIMA(4,0,2) with zero mean     : -11333.85\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11382.66\n",
      " ARIMA(3,0,4) with zero mean     : -11360.21\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with zero mean     : -11440.78\n",
      " ARIMA(5,0,5) with zero mean     : -11456.27\n",
      " ARIMA(4,0,5) with zero mean     : Inf\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,5) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11396.91\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11305.83\n",
      " ARIMA(0,0,0) with non-zero mean : -6670.167\n",
      " ARIMA(1,0,0) with non-zero mean : -11278.25\n",
      " ARIMA(0,0,1) with non-zero mean : -8697.836\n",
      " ARIMA(0,0,0) with zero mean     : -6663.345\n",
      " ARIMA(1,0,2) with non-zero mean : -11300.93\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11382.19\n",
      " ARIMA(3,0,1) with non-zero mean : -11312.28\n",
      " ARIMA(4,0,2) with non-zero mean : -11324.03\n",
      " ARIMA(3,0,3) with non-zero mean : -11324.58\n",
      " ARIMA(2,0,3) with non-zero mean : -11320.3\n",
      " ARIMA(4,0,1) with non-zero mean : -11323.14\n",
      " ARIMA(4,0,3) with non-zero mean : -11382.62\n",
      " ARIMA(5,0,3) with non-zero mean : -11391.42\n",
      " ARIMA(5,0,2) with non-zero mean : -11375.24\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11388.66\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11299.77\n",
      " ARIMA(0,0,0) with non-zero mean : -6664.974\n",
      " ARIMA(1,0,0) with non-zero mean : -11273.07\n",
      " ARIMA(0,0,1) with non-zero mean : -8693.479\n",
      " ARIMA(0,0,0) with zero mean     : -6658.911\n",
      " ARIMA(1,0,2) with non-zero mean : -11295.08\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11384.49\n",
      " ARIMA(3,0,1) with non-zero mean : -11305.45\n",
      " ARIMA(4,0,2) with non-zero mean : -11318.63\n",
      " ARIMA(3,0,3) with non-zero mean : -11318.26\n",
      " ARIMA(2,0,3) with non-zero mean : -11313.84\n",
      " ARIMA(4,0,1) with non-zero mean : -11316.33\n",
      " ARIMA(4,0,3) with non-zero mean : -11379.31\n",
      " ARIMA(3,0,2) with zero mean     : -11386.24\n",
      " ARIMA(2,0,2) with zero mean     : -11301.64\n",
      " ARIMA(3,0,1) with zero mean     : -11307.33\n",
      " ARIMA(4,0,2) with zero mean     : -11320.49\n",
      " ARIMA(3,0,3) with zero mean     : -11320.1\n",
      " ARIMA(2,0,1) with zero mean     : -11294.37\n",
      " ARIMA(2,0,3) with zero mean     : -11315.67\n",
      " ARIMA(4,0,1) with zero mean     : -11318.18\n",
      " ARIMA(4,0,3) with zero mean     : -11381.1\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11385.3\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11310.13\n",
      " ARIMA(0,0,0) with non-zero mean : -6682.719\n",
      " ARIMA(1,0,0) with non-zero mean : -11283.7\n",
      " ARIMA(0,0,1) with non-zero mean : -8709.728\n",
      " ARIMA(0,0,0) with zero mean     : -6679.951\n",
      " ARIMA(1,0,2) with non-zero mean : -11305.28\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11394.4\n",
      " ARIMA(3,0,1) with non-zero mean : -11315.74\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11324.19\n",
      " ARIMA(4,0,1) with non-zero mean : -11326.94\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : -11394.4\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11318.53\n",
      " ARIMA(0,0,0) with non-zero mean : -6684.289\n",
      " ARIMA(1,0,0) with non-zero mean : -11291.02\n",
      " ARIMA(0,0,1) with non-zero mean : -8709.777\n",
      " ARIMA(0,0,0) with zero mean     : -6682.252\n",
      " ARIMA(1,0,2) with non-zero mean : -11313.56\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11407.09\n",
      " ARIMA(3,0,1) with non-zero mean : -11326.07\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -11411.55\n",
      " ARIMA(2,0,3) with non-zero mean : -11332.96\n",
      " ARIMA(4,0,3) with non-zero mean : -11406.01\n",
      " ARIMA(3,0,4) with non-zero mean : -11393.61\n",
      " ARIMA(2,0,4) with non-zero mean : -11372\n",
      " ARIMA(4,0,4) with non-zero mean : -11408.79\n",
      " ARIMA(3,0,3) with zero mean     : -11413.52\n",
      " ARIMA(2,0,3) with zero mean     : -11334.9\n",
      " ARIMA(3,0,2) with zero mean     : -11409.07\n",
      " ARIMA(4,0,3) with zero mean     : -11407.69\n",
      " ARIMA(3,0,4) with zero mean     : -11393.81\n",
      " ARIMA(2,0,2) with zero mean     : -11320.49\n",
      " ARIMA(2,0,4) with zero mean     : -11373.96\n",
      " ARIMA(4,0,2) with zero mean     : -11342.57\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11404.21\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11332.95\n",
      " ARIMA(0,0,0) with non-zero mean : -6690.754\n",
      " ARIMA(1,0,0) with non-zero mean : -11305.57\n",
      " ARIMA(0,0,1) with non-zero mean : -8717.595\n",
      " ARIMA(0,0,0) with zero mean     : -6690.452\n",
      " ARIMA(1,0,2) with non-zero mean : -11328.33\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11416.47\n",
      " ARIMA(3,0,1) with non-zero mean : -11342.34\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -11418.63\n",
      " ARIMA(2,0,3) with non-zero mean : -11348.62\n",
      " ARIMA(4,0,3) with non-zero mean : -11414.74\n",
      " ARIMA(3,0,4) with non-zero mean : -11416.61\n",
      " ARIMA(2,0,4) with non-zero mean : -11388.3\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11420.66\n",
      " ARIMA(2,0,3) with zero mean     : -11350.61\n",
      " ARIMA(3,0,2) with zero mean     : -11418.51\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -11418.65\n",
      " ARIMA(2,0,2) with zero mean     : -11334.95\n",
      " ARIMA(2,0,4) with zero mean     : -11390.32\n",
      " ARIMA(4,0,2) with zero mean     : -11357.1\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11415.5\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "[1] \"50 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11356.17\n",
      " ARIMA(0,0,0) with non-zero mean : -6690.499\n",
      " ARIMA(1,0,0) with non-zero mean : -11329.91\n",
      " ARIMA(0,0,1) with non-zero mean : -8719.031\n",
      " ARIMA(0,0,0) with zero mean     : -6690.897\n",
      " ARIMA(1,0,2) with non-zero mean : -11352.13\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11428.68\n",
      " ARIMA(3,0,1) with non-zero mean : -11362.48\n",
      " ARIMA(4,0,2) with non-zero mean : -11375.33\n",
      " ARIMA(3,0,3) with non-zero mean : -11375.66\n",
      " ARIMA(2,0,3) with non-zero mean : -11371.34\n",
      " ARIMA(4,0,1) with non-zero mean : -11374.63\n",
      " ARIMA(4,0,3) with non-zero mean : -11431.51\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11412.53\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11433.45\n",
      " ARIMA(3,0,3) with zero mean     : -11377.55\n",
      " ARIMA(4,0,2) with zero mean     : -11376.63\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11430.46\n",
      " ARIMA(3,0,4) with zero mean     : -11376.2\n",
      " ARIMA(5,0,2) with zero mean     : -11414.43\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -11432.83\n",
      "\n",
      " Best model: ARIMA(4,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11368.76\n",
      " ARIMA(0,0,0) with non-zero mean : -6688.274\n",
      " ARIMA(1,0,0) with non-zero mean : -11342.11\n",
      " ARIMA(0,0,1) with non-zero mean : -8719.819\n",
      " ARIMA(0,0,0) with zero mean     : -6687.667\n",
      " ARIMA(1,0,2) with non-zero mean : -11363.98\n",
      " ARIMA(2,0,1) with non-zero mean : -11362.28\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11383.19\n",
      " ARIMA(1,0,3) with non-zero mean : -11385.67\n",
      " ARIMA(0,0,3) with non-zero mean : -10195.6\n",
      " ARIMA(1,0,4) with non-zero mean : -11384.18\n",
      " ARIMA(0,0,2) with non-zero mean : -9651.636\n",
      " ARIMA(0,0,4) with non-zero mean : -10619.64\n",
      " ARIMA(2,0,4) with non-zero mean : -11413.52\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11423.72\n",
      " ARIMA(1,0,5) with non-zero mean : -11388.13\n",
      " ARIMA(3,0,5) with non-zero mean : -11416.08\n",
      " ARIMA(2,0,5) with zero mean     : -11425.66\n",
      " ARIMA(1,0,5) with zero mean     : -11390.15\n",
      " ARIMA(2,0,4) with zero mean     : -11415.42\n",
      " ARIMA(3,0,5) with zero mean     : -11418.12\n",
      " ARIMA(1,0,4) with zero mean     : -11386.19\n",
      " ARIMA(3,0,4) with zero mean     : -11485.51\n",
      " ARIMA(3,0,3) with zero mean     : -11390.06\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -11385.19\n",
      " ARIMA(4,0,3) with zero mean     : -11445.33\n",
      " ARIMA(4,0,5) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,5) with zero mean     : -11430.84\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11379.91\n",
      " ARIMA(0,0,0) with non-zero mean : -6735.304\n",
      " ARIMA(1,0,0) with non-zero mean : -11354.43\n",
      " ARIMA(0,0,1) with non-zero mean : -8758.988\n",
      " ARIMA(0,0,0) with zero mean     : -6737.172\n",
      " ARIMA(1,0,2) with non-zero mean : -11375.63\n",
      " ARIMA(2,0,1) with non-zero mean : -11373.84\n",
      " ARIMA(3,0,2) with non-zero mean : -11461.55\n",
      " ARIMA(3,0,1) with non-zero mean : -11386.02\n",
      " ARIMA(4,0,2) with non-zero mean : -11400.26\n",
      " ARIMA(3,0,3) with non-zero mean : -11400.01\n",
      " ARIMA(2,0,3) with non-zero mean : -11395.61\n",
      " ARIMA(4,0,1) with non-zero mean : -11398.44\n",
      " ARIMA(4,0,3) with non-zero mean : -11457.4\n",
      " ARIMA(3,0,2) with zero mean     : -11463.57\n",
      " ARIMA(2,0,2) with zero mean     : -11381.74\n",
      " ARIMA(3,0,1) with zero mean     : -11388.02\n",
      " ARIMA(4,0,2) with zero mean     : -11402.26\n",
      " ARIMA(3,0,3) with zero mean     : -11402.03\n",
      " ARIMA(2,0,1) with zero mean     : -11375.86\n",
      " ARIMA(2,0,3) with zero mean     : -11397.63\n",
      " ARIMA(4,0,1) with zero mean     : -11400.45\n",
      " ARIMA(4,0,3) with zero mean     : -11459.4\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11399.38\n",
      "\n",
      " Best model: ARIMA(4,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11418.83\n",
      " ARIMA(0,0,0) with non-zero mean : -6770.192\n",
      " ARIMA(1,0,0) with non-zero mean : -11389.52\n",
      " ARIMA(0,0,1) with non-zero mean : -8798.915\n",
      " ARIMA(0,0,0) with zero mean     : -6772.157\n",
      " ARIMA(1,0,2) with non-zero mean : -11413.24\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11497.24\n",
      " ARIMA(3,0,1) with non-zero mean : -11425.94\n",
      " ARIMA(4,0,2) with non-zero mean : -11440.64\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11432.73\n",
      " ARIMA(4,0,1) with non-zero mean : -11439.86\n",
      " ARIMA(4,0,3) with non-zero mean : -11482.5\n",
      " ARIMA(3,0,2) with zero mean     : -11499.25\n",
      " ARIMA(2,0,2) with zero mean     : -11420.85\n",
      " ARIMA(3,0,1) with zero mean     : -11427.95\n",
      " ARIMA(4,0,2) with zero mean     : -11442.65\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -11434.74\n",
      " ARIMA(4,0,1) with zero mean     : -11441.87\n",
      " ARIMA(4,0,3) with zero mean     : -11484.67\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11438.64\n",
      "\n",
      " Best model: ARIMA(4,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11414.32\n",
      " ARIMA(0,0,0) with non-zero mean : -6776.125\n",
      " ARIMA(1,0,0) with non-zero mean : -11387.21\n",
      " ARIMA(0,0,1) with non-zero mean : -8799.227\n",
      " ARIMA(0,0,0) with zero mean     : -6777.222\n",
      " ARIMA(1,0,2) with non-zero mean : -11409.82\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11486.69\n",
      " ARIMA(3,0,1) with non-zero mean : -11419.62\n",
      " ARIMA(4,0,2) with non-zero mean : -11432.54\n",
      " ARIMA(3,0,3) with non-zero mean : -11432.11\n",
      " ARIMA(2,0,3) with non-zero mean : -11428.57\n",
      " ARIMA(4,0,1) with non-zero mean : -11432.22\n",
      " ARIMA(4,0,3) with non-zero mean : -11426.07\n",
      " ARIMA(3,0,2) with zero mean     : -11488.4\n",
      " ARIMA(2,0,2) with zero mean     : -11416.24\n",
      " ARIMA(3,0,1) with zero mean     : -11421.53\n",
      " ARIMA(4,0,2) with zero mean     : -11434.45\n",
      " ARIMA(3,0,3) with zero mean     : -11434.02\n",
      " ARIMA(2,0,1) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -11430.48\n",
      " ARIMA(4,0,1) with zero mean     : -11434.15\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11433.84\n",
      "\n",
      " Best model: ARIMA(4,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11396.28\n",
      " ARIMA(0,0,0) with non-zero mean : -6767.655\n",
      " ARIMA(1,0,0) with non-zero mean : -11366.24\n",
      " ARIMA(0,0,1) with non-zero mean : -8786.68\n",
      " ARIMA(0,0,0) with zero mean     : -6768.269\n",
      " ARIMA(1,0,2) with non-zero mean : -11391.4\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11410.85\n",
      " ARIMA(1,0,3) with non-zero mean : -11413.2\n",
      " ARIMA(0,0,3) with non-zero mean : -10241.8\n",
      " ARIMA(1,0,4) with non-zero mean : -11411.5\n",
      " ARIMA(0,0,2) with non-zero mean : -9706.747\n",
      " ARIMA(0,0,4) with non-zero mean : -10664.67\n",
      " ARIMA(2,0,4) with non-zero mean : -11450.27\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11458.58\n",
      " ARIMA(1,0,5) with non-zero mean : -11415.38\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with zero mean     : -11460.53\n",
      " ARIMA(1,0,5) with zero mean     : -11417.36\n",
      " ARIMA(2,0,4) with zero mean     : -11452.21\n",
      " ARIMA(3,0,5) with zero mean     : -11458.99\n",
      " ARIMA(1,0,4) with zero mean     : -11413.48\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,5) with zero mean     : -11459.53\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11379.85\n",
      " ARIMA(0,0,0) with non-zero mean : -6769.06\n",
      " ARIMA(1,0,0) with non-zero mean : -11350.52\n",
      " ARIMA(0,0,1) with non-zero mean : -8784.121\n",
      " ARIMA(0,0,0) with zero mean     : -6770.196\n",
      " ARIMA(1,0,2) with non-zero mean : -11374.77\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11440.14\n",
      " ARIMA(3,0,1) with non-zero mean : -11385.46\n",
      " ARIMA(4,0,2) with non-zero mean : -11398.72\n",
      " ARIMA(3,0,3) with non-zero mean : -11399.1\n",
      " ARIMA(2,0,3) with non-zero mean : -11395.62\n",
      " ARIMA(4,0,1) with non-zero mean : -11397.24\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11442.2\n",
      " ARIMA(2,0,2) with zero mean     : -11381.87\n",
      " ARIMA(3,0,1) with zero mean     : -11387.48\n",
      " ARIMA(4,0,2) with zero mean     : -11400.7\n",
      " ARIMA(3,0,3) with zero mean     : -11401.11\n",
      " ARIMA(2,0,1) with zero mean     : -11375.84\n",
      " ARIMA(2,0,3) with zero mean     : -11397.63\n",
      " ARIMA(4,0,1) with zero mean     : -11399.24\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11400.25\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11368.58\n",
      " ARIMA(0,0,0) with non-zero mean : -6755.177\n",
      " ARIMA(1,0,0) with non-zero mean : -11340.91\n",
      " ARIMA(0,0,1) with non-zero mean : -8775.252\n",
      " ARIMA(0,0,0) with zero mean     : -6756.647\n",
      " ARIMA(1,0,2) with non-zero mean : -11363.4\n",
      " ARIMA(2,0,1) with non-zero mean : -11362.12\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11383.49\n",
      " ARIMA(1,0,3) with non-zero mean : -11385.66\n",
      " ARIMA(0,0,3) with non-zero mean : -10228.52\n",
      " ARIMA(1,0,4) with non-zero mean : -11383.84\n",
      " ARIMA(0,0,2) with non-zero mean : -9695.095\n",
      " ARIMA(0,0,4) with non-zero mean : -10649.52\n",
      " ARIMA(2,0,4) with non-zero mean : -11413.73\n",
      " ARIMA(3,0,4) with non-zero mean : -11467.64\n",
      " ARIMA(3,0,3) with non-zero mean : -11386.95\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : -11449.17\n",
      " ARIMA(2,0,5) with non-zero mean : -11419.96\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -11459.53\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11424.77\n",
      "\n",
      " Best model: ARIMA(2,0,5) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11384.56\n",
      " ARIMA(0,0,0) with non-zero mean : -6817.572\n",
      " ARIMA(1,0,0) with non-zero mean : -11356.29\n",
      " ARIMA(0,0,1) with non-zero mean : -8815.3\n",
      " ARIMA(0,0,0) with zero mean     : -6819.524\n",
      " ARIMA(1,0,2) with non-zero mean : -11378.77\n",
      " ARIMA(2,0,1) with non-zero mean : -11376.91\n",
      " ARIMA(3,0,2) with non-zero mean : -11457.48\n",
      " ARIMA(3,0,1) with non-zero mean : -11390.32\n",
      " ARIMA(4,0,2) with non-zero mean : -11401.89\n",
      " ARIMA(3,0,3) with non-zero mean : -11402.85\n",
      " ARIMA(2,0,3) with non-zero mean : -11397.85\n",
      " ARIMA(4,0,1) with non-zero mean : -11401.42\n",
      " ARIMA(4,0,3) with non-zero mean : -11408.13\n",
      " ARIMA(3,0,2) with zero mean     : -11459.44\n",
      " ARIMA(2,0,2) with zero mean     : -11386.54\n",
      " ARIMA(3,0,1) with zero mean     : -11392.27\n",
      " ARIMA(4,0,2) with zero mean     : -11403.82\n",
      " ARIMA(3,0,3) with zero mean     : -11404.78\n",
      " ARIMA(2,0,1) with zero mean     : -11378.84\n",
      " ARIMA(2,0,3) with zero mean     : -11399.82\n",
      " ARIMA(4,0,1) with zero mean     : -11403.36\n",
      " ARIMA(4,0,3) with zero mean     : -11401.82\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -11429.81\n",
      "\n",
      " Best model: ARIMA(4,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11412.64\n",
      " ARIMA(0,0,0) with non-zero mean : -6848.389\n",
      " ARIMA(1,0,0) with non-zero mean : -11381.79\n",
      " ARIMA(0,0,1) with non-zero mean : -8850.215\n",
      " ARIMA(0,0,0) with zero mean     : -6849.878\n",
      " ARIMA(1,0,2) with non-zero mean : -11405.42\n",
      " ARIMA(2,0,1) with non-zero mean : -11408.53\n",
      " ARIMA(3,0,2) with non-zero mean : -11426.53\n",
      " ARIMA(3,0,1) with non-zero mean : -11419.05\n",
      " ARIMA(4,0,2) with non-zero mean : -11428.85\n",
      " ARIMA(4,0,1) with non-zero mean : -11428.66\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -11427.82\n",
      " ARIMA(5,0,1) with non-zero mean : -11459.29\n",
      " ARIMA(5,0,0) with non-zero mean : -11427.85\n",
      " ARIMA(4,0,0) with non-zero mean : -11430.59\n",
      " ARIMA(5,0,1) with zero mean     : -11461.27\n",
      " ARIMA(4,0,1) with zero mean     : -11430.65\n",
      " ARIMA(5,0,0) with zero mean     : -11429.84\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,0) with zero mean     : -11432.58\n",
      " ARIMA(4,0,2) with zero mean     : -11431.03\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,1) with zero mean     : -11456.59\n",
      "\n",
      " Best model: ARIMA(5,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11417.39\n",
      " ARIMA(0,0,0) with non-zero mean : -6856.506\n",
      " ARIMA(1,0,0) with non-zero mean : -11388.09\n",
      " ARIMA(0,0,1) with non-zero mean : -8862.562\n",
      " ARIMA(0,0,0) with zero mean     : -6858.168\n",
      " ARIMA(1,0,2) with non-zero mean : -11413.18\n",
      " ARIMA(2,0,1) with non-zero mean : -11411.51\n",
      " ARIMA(3,0,2) with non-zero mean : -11436.07\n",
      " ARIMA(3,0,1) with non-zero mean : -11423.64\n",
      " ARIMA(4,0,2) with non-zero mean : -11435.75\n",
      " ARIMA(3,0,3) with non-zero mean : -11435.89\n",
      " ARIMA(2,0,3) with non-zero mean : -11430.71\n",
      " ARIMA(4,0,1) with non-zero mean : -11434.25\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11438.08\n",
      " ARIMA(2,0,2) with zero mean     : -11419.4\n",
      " ARIMA(3,0,1) with zero mean     : -11425.65\n",
      " ARIMA(4,0,2) with zero mean     : -11437.77\n",
      " ARIMA(3,0,3) with zero mean     : -11437.9\n",
      " ARIMA(2,0,1) with zero mean     : -11413.52\n",
      " ARIMA(2,0,3) with zero mean     : -11432.72\n",
      " ARIMA(4,0,1) with zero mean     : -11436.26\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11434.82\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11423.12\n",
      " ARIMA(0,0,0) with non-zero mean : -6855.742\n",
      " ARIMA(1,0,0) with non-zero mean : -11392.02\n",
      " ARIMA(0,0,1) with non-zero mean : -8862.21\n",
      " ARIMA(0,0,0) with zero mean     : -6857.312\n",
      " ARIMA(1,0,2) with non-zero mean : -11417.26\n",
      " ARIMA(2,0,1) with non-zero mean : -11416.16\n",
      " ARIMA(3,0,2) with non-zero mean : -11493.1\n",
      " ARIMA(3,0,1) with non-zero mean : -11428.28\n",
      " ARIMA(4,0,2) with non-zero mean : -11437.52\n",
      " ARIMA(3,0,3) with non-zero mean : -11438.52\n",
      " ARIMA(2,0,3) with non-zero mean : -11434.97\n",
      " ARIMA(4,0,1) with non-zero mean : -11437.01\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11495.07\n",
      " ARIMA(2,0,2) with zero mean     : -11425.08\n",
      " ARIMA(3,0,1) with zero mean     : -11430.27\n",
      " ARIMA(4,0,2) with zero mean     : -11439.6\n",
      " ARIMA(3,0,3) with zero mean     : -11440.51\n",
      " ARIMA(2,0,1) with zero mean     : -11418.15\n",
      " ARIMA(2,0,3) with zero mean     : -11436.96\n",
      " ARIMA(4,0,1) with zero mean     : -11438.99\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11438.77\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11430.97\n",
      " ARIMA(0,0,0) with non-zero mean : -6848.48\n",
      " ARIMA(1,0,0) with non-zero mean : -11402.64\n",
      " ARIMA(0,0,1) with non-zero mean : -8856.769\n",
      " ARIMA(0,0,0) with zero mean     : -6849.649\n",
      " ARIMA(1,0,2) with non-zero mean : -11427.39\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11502.31\n",
      " ARIMA(3,0,1) with non-zero mean : -11437.26\n",
      " ARIMA(4,0,2) with non-zero mean : -11447.51\n",
      " ARIMA(3,0,3) with non-zero mean : -11448.73\n",
      " ARIMA(2,0,3) with non-zero mean : -11443.78\n",
      " ARIMA(4,0,1) with non-zero mean : -11446.63\n",
      " ARIMA(4,0,3) with non-zero mean : -11509.92\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -11446.8\n",
      " ARIMA(5,0,2) with non-zero mean : -11447.79\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11511.9\n",
      " ARIMA(3,0,3) with zero mean     : -11450.67\n",
      " ARIMA(4,0,2) with zero mean     : -11449.59\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11504.14\n",
      " ARIMA(3,0,4) with zero mean     : -11448.79\n",
      " ARIMA(5,0,2) with zero mean     : -11449.75\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11448.04\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11440.69\n",
      " ARIMA(0,0,0) with non-zero mean : -6856.218\n",
      " ARIMA(1,0,0) with non-zero mean : -11411.42\n",
      " ARIMA(0,0,1) with non-zero mean : -8866.494\n",
      " ARIMA(0,0,0) with zero mean     : -6856.027\n",
      " ARIMA(1,0,2) with non-zero mean : -11436.86\n",
      " ARIMA(2,0,1) with non-zero mean : -11435.31\n",
      " ARIMA(3,0,2) with non-zero mean : -11514.58\n",
      " ARIMA(3,0,1) with non-zero mean : -11446.49\n",
      " ARIMA(4,0,2) with non-zero mean : -11454.49\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11453.31\n",
      " ARIMA(4,0,1) with non-zero mean : -11454.65\n",
      " ARIMA(4,0,3) with non-zero mean : -11488.67\n",
      " ARIMA(3,0,2) with zero mean     : -11516.38\n",
      " ARIMA(2,0,2) with zero mean     : -11442.63\n",
      " ARIMA(3,0,1) with zero mean     : -11448.44\n",
      " ARIMA(4,0,2) with zero mean     : -11456.57\n",
      " ARIMA(3,0,3) with zero mean     : -11457.42\n",
      " ARIMA(2,0,1) with zero mean     : -11437.26\n",
      " ARIMA(2,0,3) with zero mean     : -11455.25\n",
      " ARIMA(4,0,1) with zero mean     : -11456.59\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -11493.26\n",
      "\n",
      " Best model: ARIMA(4,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11441.76\n",
      " ARIMA(0,0,0) with non-zero mean : -6867.168\n",
      " ARIMA(1,0,0) with non-zero mean : -11412.83\n",
      " ARIMA(0,0,1) with non-zero mean : -8874.459\n",
      " ARIMA(0,0,0) with zero mean     : -6868.118\n",
      " ARIMA(1,0,2) with non-zero mean : -11438.26\n",
      " ARIMA(2,0,1) with non-zero mean : -11439.57\n",
      " ARIMA(3,0,2) with non-zero mean : -11460.46\n",
      " ARIMA(3,0,1) with non-zero mean : -11452.45\n",
      " ARIMA(4,0,2) with non-zero mean : -11460.15\n",
      " ARIMA(3,0,3) with non-zero mean : -11460.42\n",
      " ARIMA(2,0,3) with non-zero mean : -11457.03\n",
      " ARIMA(4,0,1) with non-zero mean : -11460.67\n",
      " ARIMA(4,0,0) with non-zero mean : -11462.52\n",
      " ARIMA(3,0,0) with non-zero mean : -11445.99\n",
      " ARIMA(5,0,0) with non-zero mean : -11460.51\n",
      " ARIMA(5,0,1) with non-zero mean : -11490.28\n",
      " ARIMA(5,0,2) with non-zero mean : -11489.45\n",
      " ARIMA(5,0,1) with zero mean     : -11492.28\n",
      " ARIMA(4,0,1) with zero mean     : -11462.63\n",
      " ARIMA(5,0,0) with zero mean     : -11462.47\n",
      " ARIMA(5,0,2) with zero mean     : -11491.47\n",
      " ARIMA(4,0,0) with zero mean     : -11464.49\n",
      " ARIMA(4,0,2) with zero mean     : -11462.11\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,1) with zero mean     : -11489.3\n",
      "\n",
      " Best model: ARIMA(5,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11450.16\n",
      " ARIMA(0,0,0) with non-zero mean : -6876.022\n",
      " ARIMA(1,0,0) with non-zero mean : -11420.01\n",
      " ARIMA(0,0,1) with non-zero mean : -8882.957\n",
      " ARIMA(0,0,0) with zero mean     : -6875.829\n",
      " ARIMA(1,0,2) with non-zero mean : -11445.95\n",
      " ARIMA(2,0,1) with non-zero mean : -11444.35\n",
      " ARIMA(3,0,2) with non-zero mean : -11466.46\n",
      " ARIMA(3,0,1) with non-zero mean : -11456.16\n",
      " ARIMA(4,0,2) with non-zero mean : -11465.03\n",
      " ARIMA(3,0,3) with non-zero mean : -11466.1\n",
      " ARIMA(2,0,3) with non-zero mean : -11463.41\n",
      " ARIMA(4,0,1) with non-zero mean : -11464.87\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11468.34\n",
      " ARIMA(2,0,2) with zero mean     : -11452.05\n",
      " ARIMA(3,0,1) with zero mean     : -11458.07\n",
      " ARIMA(4,0,2) with zero mean     : -11466.92\n",
      " ARIMA(3,0,3) with zero mean     : -11468.01\n",
      " ARIMA(2,0,1) with zero mean     : -11446.24\n",
      " ARIMA(2,0,3) with zero mean     : -11465.3\n",
      " ARIMA(4,0,1) with zero mean     : -11466.76\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11467.86\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11459.35\n",
      " ARIMA(0,0,0) with non-zero mean : -6885.081\n",
      " ARIMA(1,0,0) with non-zero mean : -11430.32\n",
      " ARIMA(0,0,1) with non-zero mean : -8894.963\n",
      " ARIMA(0,0,0) with zero mean     : -6883.912\n",
      " ARIMA(1,0,2) with non-zero mean : -11455.26\n",
      " ARIMA(2,0,1) with non-zero mean : -11453.41\n",
      " ARIMA(3,0,2) with non-zero mean : -11478.09\n",
      " ARIMA(3,0,1) with non-zero mean : -11465.83\n",
      " ARIMA(4,0,2) with non-zero mean : -11476.69\n",
      " ARIMA(3,0,3) with non-zero mean : -11477.8\n",
      " ARIMA(2,0,3) with non-zero mean : -11472.47\n",
      " ARIMA(4,0,1) with non-zero mean : -11475.17\n",
      " ARIMA(4,0,3) with non-zero mean : -11529.99\n",
      " ARIMA(5,0,3) with non-zero mean : -11474.61\n",
      " ARIMA(4,0,4) with non-zero mean : -11559.37\n",
      " ARIMA(3,0,4) with non-zero mean : -11492.22\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : -11504.37\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,4) with non-zero mean : -11508.64\n",
      "\n",
      " Best model: ARIMA(4,0,4) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11473.67\n",
      " ARIMA(0,0,0) with non-zero mean : -6904.305\n",
      " ARIMA(1,0,0) with non-zero mean : -11442.86\n",
      " ARIMA(0,0,1) with non-zero mean : -8909.573\n",
      " ARIMA(0,0,0) with zero mean     : -6902.564\n",
      " ARIMA(1,0,2) with non-zero mean : -11467.87\n",
      " ARIMA(2,0,1) with non-zero mean : -11468.18\n",
      " ARIMA(3,0,2) with non-zero mean : -11488.61\n",
      " ARIMA(3,0,1) with non-zero mean : -11478.94\n",
      " ARIMA(4,0,2) with non-zero mean : -11488.89\n",
      " ARIMA(4,0,1) with non-zero mean : -11488.23\n",
      " ARIMA(5,0,2) with non-zero mean : -11530.04\n",
      " ARIMA(5,0,1) with non-zero mean : -11514.48\n",
      " ARIMA(5,0,3) with non-zero mean : -11533.06\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,1) with non-zero mean : -11515.81\n",
      "\n",
      " Best model: ARIMA(5,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11497.17\n",
      " ARIMA(0,0,0) with non-zero mean : -7026.856\n",
      " ARIMA(1,0,0) with non-zero mean : -11463.53\n",
      " ARIMA(0,0,1) with non-zero mean : -8998.064\n",
      " ARIMA(0,0,0) with zero mean     : -7018.215\n",
      " ARIMA(1,0,2) with non-zero mean : -11490.08\n",
      " ARIMA(2,0,1) with non-zero mean : -11479.81\n",
      " ARIMA(3,0,2) with non-zero mean : -11511.03\n",
      " ARIMA(3,0,1) with non-zero mean : -11502\n",
      " ARIMA(4,0,2) with non-zero mean : -11515.83\n",
      " ARIMA(4,0,1) with non-zero mean : -11517.05\n",
      " ARIMA(4,0,0) with non-zero mean : -11516.32\n",
      " ARIMA(5,0,1) with non-zero mean : -11532.81\n",
      " ARIMA(5,0,0) with non-zero mean : -11533.61\n",
      " ARIMA(5,0,0) with zero mean     : -11534.97\n",
      " ARIMA(4,0,0) with zero mean     : -11517.84\n",
      " ARIMA(5,0,1) with zero mean     : -11534.17\n",
      " ARIMA(4,0,1) with zero mean     : -11518.5\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,0) with zero mean     : -11510.2\n",
      "\n",
      " Best model: ARIMA(5,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11522.36\n",
      " ARIMA(0,0,0) with non-zero mean : -6976.397\n",
      " ARIMA(1,0,0) with non-zero mean : -11483.5\n",
      " ARIMA(0,0,1) with non-zero mean : -8955.384\n",
      " ARIMA(0,0,0) with zero mean     : -6973.519\n",
      " ARIMA(1,0,2) with non-zero mean : -11518.05\n",
      " ARIMA(2,0,1) with non-zero mean : -11502.5\n",
      " ARIMA(3,0,2) with non-zero mean : -11539.76\n",
      " ARIMA(3,0,1) with non-zero mean : -11532\n",
      " ARIMA(4,0,2) with non-zero mean : -11540.01\n",
      " ARIMA(4,0,1) with non-zero mean : -11541.17\n",
      " ARIMA(4,0,0) with non-zero mean : -11542.91\n",
      " ARIMA(3,0,0) with non-zero mean : -11523.24\n",
      " ARIMA(5,0,0) with non-zero mean : -11548.94\n",
      " ARIMA(5,0,1) with non-zero mean : -11560.19\n",
      " ARIMA(5,0,2) with non-zero mean : -11558.2\n",
      " ARIMA(5,0,1) with zero mean     : -11562.08\n",
      " ARIMA(4,0,1) with zero mean     : -11543.1\n",
      " ARIMA(5,0,0) with zero mean     : -11550.92\n",
      " ARIMA(5,0,2) with zero mean     : -11560.09\n",
      " ARIMA(4,0,0) with zero mean     : -11544.85\n",
      " ARIMA(4,0,2) with zero mean     : -11541.94\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,1) with zero mean     : -11573.33\n",
      "\n",
      " Best model: ARIMA(5,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11485.88\n",
      " ARIMA(0,0,0) with non-zero mean : -7008.245\n",
      " ARIMA(1,0,0) with non-zero mean : -11447.22\n",
      " ARIMA(0,0,1) with non-zero mean : -8956.127\n",
      " ARIMA(0,0,0) with zero mean     : -7003.898\n",
      " ARIMA(1,0,2) with non-zero mean : -11483.16\n",
      " ARIMA(2,0,1) with non-zero mean : -11482.32\n",
      " ARIMA(3,0,2) with non-zero mean : -11506.05\n",
      " ARIMA(3,0,1) with non-zero mean : -11491.58\n",
      " ARIMA(4,0,2) with non-zero mean : -11505.48\n",
      " ARIMA(3,0,3) with non-zero mean : -11505.8\n",
      " ARIMA(2,0,3) with non-zero mean : -11498.3\n",
      " ARIMA(4,0,1) with non-zero mean : -11502.45\n",
      " ARIMA(4,0,3) with non-zero mean : -11520.2\n",
      " ARIMA(5,0,3) with non-zero mean : -11529.58\n",
      " ARIMA(5,0,2) with non-zero mean : -11525.97\n",
      " ARIMA(5,0,4) with non-zero mean : -11582.08\n",
      " ARIMA(4,0,4) with non-zero mean : -11531.68\n",
      " ARIMA(5,0,5) with non-zero mean : -11565.09\n",
      " ARIMA(4,0,5) with non-zero mean : -11538.66\n",
      " ARIMA(5,0,4) with zero mean     : -11583.66\n",
      " ARIMA(4,0,4) with zero mean     : -11533.24\n",
      " ARIMA(5,0,3) with zero mean     : -11531.52\n",
      " ARIMA(5,0,5) with zero mean     : -11566.72\n",
      " ARIMA(4,0,3) with zero mean     : -11521.86\n",
      " ARIMA(4,0,5) with zero mean     : -11540.44\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,5) with zero mean     : Inf\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with zero mean     : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11532.83\n",
      "\n",
      " Best model: ARIMA(5,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11484.53\n",
      " ARIMA(0,0,0) with non-zero mean : -7045.561\n",
      " ARIMA(1,0,0) with non-zero mean : -11444.21\n",
      " ARIMA(0,0,1) with non-zero mean : -8986.409\n",
      " ARIMA(0,0,0) with zero mean     : -7038.631\n",
      " ARIMA(1,0,2) with non-zero mean : -11482.13\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11504.12\n",
      " ARIMA(3,0,1) with non-zero mean : -11491.11\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11494.91\n",
      " ARIMA(4,0,1) with non-zero mean : -11499.35\n",
      " ARIMA(4,0,3) with non-zero mean : -11526.26\n",
      " ARIMA(5,0,3) with non-zero mean : -11517.71\n",
      " ARIMA(4,0,4) with non-zero mean : -11527.82\n",
      " ARIMA(3,0,4) with non-zero mean : -11575.39\n",
      " ARIMA(2,0,4) with non-zero mean : -11528.58\n",
      " ARIMA(3,0,5) with non-zero mean : -11562.18\n",
      " ARIMA(2,0,5) with non-zero mean : -11534.69\n",
      " ARIMA(4,0,5) with non-zero mean : -11524.81\n",
      " ARIMA(3,0,4) with zero mean     : -11577.89\n",
      " ARIMA(2,0,4) with zero mean     : -11530.23\n",
      " ARIMA(3,0,3) with zero mean     : -11566.83\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with zero mean     : -11564.21\n",
      " ARIMA(2,0,3) with zero mean     : -11496.61\n",
      " ARIMA(2,0,5) with zero mean     : -11536.4\n",
      " ARIMA(4,0,3) with zero mean     : -11527.89\n",
      " ARIMA(4,0,5) with zero mean     : -11526.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with zero mean     : -11533.26\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11512.55\n",
      " ARIMA(0,0,0) with non-zero mean : -7061.255\n",
      " ARIMA(1,0,0) with non-zero mean : -11465.68\n",
      " ARIMA(0,0,1) with non-zero mean : -9005.312\n",
      " ARIMA(0,0,0) with zero mean     : -7056.084\n",
      " ARIMA(1,0,2) with non-zero mean : -11505.82\n",
      " ARIMA(2,0,1) with non-zero mean : -11507.85\n",
      " ARIMA(3,0,2) with non-zero mean : -11529.8\n",
      " ARIMA(3,0,1) with non-zero mean : -11518.26\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -11528.69\n",
      " ARIMA(2,0,3) with non-zero mean : -11525.98\n",
      " ARIMA(4,0,1) with non-zero mean : -11526.77\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11531.71\n",
      " ARIMA(2,0,2) with zero mean     : -11514.51\n",
      " ARIMA(3,0,1) with zero mean     : -11520.21\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11530.61\n",
      " ARIMA(2,0,1) with zero mean     : -11509.79\n",
      " ARIMA(2,0,3) with zero mean     : -11527.91\n",
      " ARIMA(4,0,1) with zero mean     : -11528.68\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11531.16\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11482.71\n",
      " ARIMA(0,0,0) with non-zero mean : -7055.949\n",
      " ARIMA(1,0,0) with non-zero mean : -11440.36\n",
      " ARIMA(0,0,1) with non-zero mean : -8999.116\n",
      " ARIMA(0,0,0) with zero mean     : -7050.65\n",
      " ARIMA(1,0,2) with non-zero mean : -11479.36\n",
      " ARIMA(2,0,1) with non-zero mean : -11479.16\n",
      " ARIMA(3,0,2) with non-zero mean : -11504.84\n",
      " ARIMA(3,0,1) with non-zero mean : -11490.33\n",
      " ARIMA(4,0,2) with non-zero mean : -11502.25\n",
      " ARIMA(3,0,3) with non-zero mean : -11503.38\n",
      " ARIMA(2,0,3) with non-zero mean : -11497.76\n",
      " ARIMA(4,0,1) with non-zero mean : -11502.16\n",
      " ARIMA(4,0,3) with non-zero mean : -11506.83\n",
      " ARIMA(5,0,3) with non-zero mean : -11536.13\n",
      " ARIMA(5,0,2) with non-zero mean : -11529.28\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11522.49\n",
      " ARIMA(5,0,3) with zero mean     : -11537.82\n",
      " ARIMA(4,0,3) with zero mean     : -11507.84\n",
      " ARIMA(5,0,2) with zero mean     : -11530.86\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11503.86\n",
      " ARIMA(4,0,4) with zero mean     : -11523.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with zero mean     : -11537.58\n",
      "\n",
      " Best model: ARIMA(5,0,3) with zero mean     \n",
      "\n",
      "[1] \"60 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11490.37\n",
      " ARIMA(0,0,0) with non-zero mean : -7047.452\n",
      " ARIMA(1,0,0) with non-zero mean : -11444.65\n",
      " ARIMA(0,0,1) with non-zero mean : -8991.749\n",
      " ARIMA(0,0,0) with zero mean     : -7039.512\n",
      " ARIMA(1,0,2) with non-zero mean : -11484.88\n",
      " ARIMA(2,0,1) with non-zero mean : -11485.48\n",
      " ARIMA(3,0,2) with non-zero mean : -11509.2\n",
      " ARIMA(3,0,1) with non-zero mean : -11496.02\n",
      " ARIMA(4,0,2) with non-zero mean : -11507.8\n",
      " ARIMA(3,0,3) with non-zero mean : -11507.44\n",
      " ARIMA(2,0,3) with non-zero mean : -11503.08\n",
      " ARIMA(4,0,1) with non-zero mean : -11507.8\n",
      " ARIMA(4,0,3) with non-zero mean : -11548.82\n",
      " ARIMA(5,0,3) with non-zero mean : -11539.74\n",
      " ARIMA(4,0,4) with non-zero mean : -11525.75\n",
      " ARIMA(3,0,4) with non-zero mean : -11542.99\n",
      " ARIMA(5,0,2) with non-zero mean : -11530.54\n",
      " ARIMA(5,0,4) with non-zero mean : -11540.45\n",
      " ARIMA(4,0,3) with zero mean     : -11550.67\n",
      " ARIMA(3,0,3) with zero mean     : -11509.09\n",
      " ARIMA(4,0,2) with zero mean     : -11509.38\n",
      " ARIMA(5,0,3) with zero mean     : -11540.95\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11510.85\n",
      " ARIMA(3,0,4) with zero mean     : -11544.76\n",
      " ARIMA(5,0,2) with zero mean     : -11532.19\n",
      " ARIMA(5,0,4) with zero mean     : -11579.37\n",
      " ARIMA(5,0,5) with zero mean     : -11543.06\n",
      " ARIMA(4,0,5) with zero mean     : -11592.29\n",
      " ARIMA(3,0,5) with zero mean     : -11545.3\n",
      " ARIMA(4,0,5) with non-zero mean : -11590.86\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,5) with zero mean     : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with zero mean     : -11578.88\n",
      "\n",
      " Best model: ARIMA(5,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11508.12\n",
      " ARIMA(0,0,0) with non-zero mean : -7087.399\n",
      " ARIMA(1,0,0) with non-zero mean : -11462.71\n",
      " ARIMA(0,0,1) with non-zero mean : -9025.635\n",
      " ARIMA(0,0,0) with zero mean     : -7072.381\n",
      " ARIMA(1,0,2) with non-zero mean : -11504.23\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11528.6\n",
      " ARIMA(3,0,1) with non-zero mean : -11515.45\n",
      " ARIMA(4,0,2) with non-zero mean : -11526.53\n",
      " ARIMA(3,0,3) with non-zero mean : -11527.53\n",
      " ARIMA(2,0,3) with non-zero mean : -11520.4\n",
      " ARIMA(4,0,1) with non-zero mean : -11523.82\n",
      " ARIMA(4,0,3) with non-zero mean : -11542.11\n",
      " ARIMA(5,0,3) with non-zero mean : -11554.06\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : -11602.43\n",
      " ARIMA(4,0,4) with non-zero mean : -11549.88\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : -11557.33\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,4) with non-zero mean : -11602.48\n",
      "\n",
      " Best model: ARIMA(5,0,4) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11526.79\n",
      " ARIMA(0,0,0) with non-zero mean : -7092.398\n",
      " ARIMA(1,0,0) with non-zero mean : -11484.3\n",
      " ARIMA(0,0,1) with non-zero mean : -9043.673\n",
      " ARIMA(0,0,0) with zero mean     : -7075.856\n",
      " ARIMA(1,0,2) with non-zero mean : -11524.41\n",
      " ARIMA(2,0,1) with non-zero mean : -11524.82\n",
      " ARIMA(3,0,2) with non-zero mean : -11552.34\n",
      " ARIMA(3,0,1) with non-zero mean : -11541.36\n",
      " ARIMA(4,0,2) with non-zero mean : -11552.16\n",
      " ARIMA(3,0,3) with non-zero mean : -11552.84\n",
      " ARIMA(2,0,3) with non-zero mean : -11543.3\n",
      " ARIMA(4,0,3) with non-zero mean : -11554.74\n",
      " ARIMA(5,0,3) with non-zero mean : -11575.93\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -11577.43\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11553.65\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with zero mean     : -11571.37\n",
      "\n",
      " Best model: ARIMA(5,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11547.91\n",
      " ARIMA(0,0,0) with non-zero mean : -7107.758\n",
      " ARIMA(1,0,0) with non-zero mean : -11504.77\n",
      " ARIMA(0,0,1) with non-zero mean : -9060.209\n",
      " ARIMA(0,0,0) with zero mean     : -7094.49\n",
      " ARIMA(1,0,2) with non-zero mean : -11544.18\n",
      " ARIMA(2,0,1) with non-zero mean : -11542.64\n",
      " ARIMA(3,0,2) with non-zero mean : -11570.25\n",
      " ARIMA(3,0,1) with non-zero mean : -11554.96\n",
      " ARIMA(4,0,2) with non-zero mean : -11567.73\n",
      " ARIMA(3,0,3) with non-zero mean : -11568.73\n",
      " ARIMA(2,0,3) with non-zero mean : -11562.27\n",
      " ARIMA(4,0,1) with non-zero mean : -11563.92\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11571.9\n",
      " ARIMA(2,0,2) with zero mean     : -11549.64\n",
      " ARIMA(3,0,1) with zero mean     : -11556.68\n",
      " ARIMA(4,0,2) with zero mean     : -11569.38\n",
      " ARIMA(3,0,3) with zero mean     : -11570.38\n",
      " ARIMA(2,0,1) with zero mean     : -11544.33\n",
      " ARIMA(2,0,3) with zero mean     : -11563.9\n",
      " ARIMA(4,0,1) with zero mean     : -11565.55\n",
      " ARIMA(4,0,3) with zero mean     : -11629.13\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : -11626\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11570.11\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11556.06\n",
      " ARIMA(0,0,0) with non-zero mean : -7115.878\n",
      " ARIMA(1,0,0) with non-zero mean : -11512.93\n",
      " ARIMA(0,0,1) with non-zero mean : -9071.081\n",
      " ARIMA(0,0,0) with zero mean     : -7107.797\n",
      " ARIMA(1,0,2) with non-zero mean : -11552.01\n",
      " ARIMA(2,0,1) with non-zero mean : -11550.3\n",
      " ARIMA(3,0,2) with non-zero mean : -11577.24\n",
      " ARIMA(3,0,1) with non-zero mean : -11562.77\n",
      " ARIMA(4,0,2) with non-zero mean : -11575.26\n",
      " ARIMA(3,0,3) with non-zero mean : -11575.39\n",
      " ARIMA(2,0,3) with non-zero mean : -11569.65\n",
      " ARIMA(4,0,1) with non-zero mean : -11572.43\n",
      " ARIMA(4,0,3) with non-zero mean : -11632.57\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11572.78\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11634.31\n",
      " ARIMA(3,0,3) with zero mean     : -11577.2\n",
      " ARIMA(4,0,2) with zero mean     : -11577.1\n",
      " ARIMA(5,0,3) with zero mean     : -11596.63\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11579.07\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : -11574.61\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -11598.87\n",
      "\n",
      " Best model: ARIMA(5,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11550.76\n",
      " ARIMA(0,0,0) with non-zero mean : -7126.439\n",
      " ARIMA(1,0,0) with non-zero mean : -11509.95\n",
      " ARIMA(0,0,1) with non-zero mean : -9081.564\n",
      " ARIMA(0,0,0) with zero mean     : -7121.931\n",
      " ARIMA(1,0,2) with non-zero mean : -11547.26\n",
      " ARIMA(2,0,1) with non-zero mean : -11545.45\n",
      " ARIMA(3,0,2) with non-zero mean : -11615.83\n",
      " ARIMA(3,0,1) with non-zero mean : -11557.98\n",
      " ARIMA(4,0,2) with non-zero mean : -11570.85\n",
      " ARIMA(3,0,3) with non-zero mean : -11570.56\n",
      " ARIMA(2,0,3) with non-zero mean : -11564.49\n",
      " ARIMA(4,0,1) with non-zero mean : -11567.12\n",
      " ARIMA(4,0,3) with non-zero mean : -11624.41\n",
      " ARIMA(5,0,3) with non-zero mean : -11590.89\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -11596.23\n",
      " ARIMA(5,0,2) with non-zero mean : -11567.64\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11635.38\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11572.65\n",
      " ARIMA(5,0,3) with zero mean     : -11592.65\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11617.52\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : -11569.6\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : -11638.66\n",
      "\n",
      " Best model: ARIMA(4,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11545.12\n",
      " ARIMA(0,0,0) with non-zero mean : -7119.86\n",
      " ARIMA(1,0,0) with non-zero mean : -11506.09\n",
      " ARIMA(0,0,1) with non-zero mean : -9075.953\n",
      " ARIMA(0,0,0) with zero mean     : -7114.27\n",
      " ARIMA(1,0,2) with non-zero mean : -11541.95\n",
      " ARIMA(2,0,1) with non-zero mean : -11540.33\n",
      " ARIMA(3,0,2) with non-zero mean : -11606\n",
      " ARIMA(3,0,1) with non-zero mean : -11553.66\n",
      " ARIMA(4,0,2) with non-zero mean : -11563.55\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11558.54\n",
      " ARIMA(4,0,1) with non-zero mean : -11561.29\n",
      " ARIMA(4,0,3) with non-zero mean : -11618.61\n",
      " ARIMA(5,0,3) with non-zero mean : -11617\n",
      " ARIMA(4,0,4) with non-zero mean : -11627.13\n",
      " ARIMA(3,0,4) with non-zero mean : -11578.07\n",
      " ARIMA(5,0,4) with non-zero mean : -11649.58\n",
      " ARIMA(5,0,5) with non-zero mean : -11575.81\n",
      " ARIMA(4,0,5) with non-zero mean : -11587.7\n",
      " ARIMA(5,0,4) with zero mean     : -11623.15\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with zero mean     : -11631.44\n",
      "\n",
      " Best model: ARIMA(5,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11546.6\n",
      " ARIMA(0,0,0) with non-zero mean : -7114.313\n",
      " ARIMA(1,0,0) with non-zero mean : -11507.8\n",
      " ARIMA(0,0,1) with non-zero mean : -9072.376\n",
      " ARIMA(0,0,0) with zero mean     : -7106.949\n",
      " ARIMA(1,0,2) with non-zero mean : -11543.3\n",
      " ARIMA(2,0,1) with non-zero mean : -11541.55\n",
      " ARIMA(3,0,2) with non-zero mean : -11566.73\n",
      " ARIMA(3,0,1) with non-zero mean : -11554.22\n",
      " ARIMA(4,0,2) with non-zero mean : -11564.63\n",
      " ARIMA(3,0,3) with non-zero mean : -11565.27\n",
      " ARIMA(2,0,3) with non-zero mean : -11558.99\n",
      " ARIMA(4,0,1) with non-zero mean : -11562.35\n",
      " ARIMA(4,0,3) with non-zero mean : -11613.32\n",
      " ARIMA(5,0,3) with non-zero mean : -11628.52\n",
      " ARIMA(5,0,2) with non-zero mean : -11620.28\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11619.37\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : -11634.67\n",
      "\n",
      " Best model: ARIMA(5,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11551.54\n",
      " ARIMA(0,0,0) with non-zero mean : -7118.416\n",
      " ARIMA(1,0,0) with non-zero mean : -11511.29\n",
      " ARIMA(0,0,1) with non-zero mean : -9078.301\n",
      " ARIMA(0,0,0) with zero mean     : -7111.373\n",
      " ARIMA(1,0,2) with non-zero mean : -11547.03\n",
      " ARIMA(2,0,1) with non-zero mean : -11545.53\n",
      " ARIMA(3,0,2) with non-zero mean : -11615.2\n",
      " ARIMA(3,0,1) with non-zero mean : -11557.44\n",
      " ARIMA(4,0,2) with non-zero mean : -11568.29\n",
      " ARIMA(3,0,3) with non-zero mean : -11568.78\n",
      " ARIMA(2,0,3) with non-zero mean : -11563.36\n",
      " ARIMA(4,0,1) with non-zero mean : -11564.77\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11617.02\n",
      " ARIMA(2,0,2) with zero mean     : -11553.27\n",
      " ARIMA(3,0,1) with zero mean     : -11559.16\n",
      " ARIMA(4,0,2) with zero mean     : -11569.97\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -11547.24\n",
      " ARIMA(2,0,3) with zero mean     : -11565.04\n",
      " ARIMA(4,0,1) with zero mean     : -11566.45\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11620.7\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11554.01\n",
      " ARIMA(0,0,0) with non-zero mean : -7116.973\n",
      " ARIMA(1,0,0) with non-zero mean : -11514.16\n",
      " ARIMA(0,0,1) with non-zero mean : -9078.843\n",
      " ARIMA(0,0,0) with zero mean     : -7110.575\n",
      " ARIMA(1,0,2) with non-zero mean : -11549.31\n",
      " ARIMA(2,0,1) with non-zero mean : -11547.38\n",
      " ARIMA(3,0,2) with non-zero mean : -11617.37\n",
      " ARIMA(3,0,1) with non-zero mean : -11560.2\n",
      " ARIMA(4,0,2) with non-zero mean : -11570.91\n",
      " ARIMA(3,0,3) with non-zero mean : -11632.39\n",
      " ARIMA(2,0,3) with non-zero mean : -11565.17\n",
      " ARIMA(4,0,3) with non-zero mean : -11630.52\n",
      " ARIMA(3,0,4) with non-zero mean : -11585.25\n",
      " ARIMA(2,0,4) with non-zero mean : -11587.21\n",
      " ARIMA(4,0,4) with non-zero mean : -11628.73\n",
      " ARIMA(3,0,3) with zero mean     : -11634.27\n",
      " ARIMA(2,0,3) with zero mean     : -11566.99\n",
      " ARIMA(3,0,2) with zero mean     : -11619.19\n",
      " ARIMA(4,0,3) with zero mean     : -11632.5\n",
      " ARIMA(3,0,4) with zero mean     : -11625.88\n",
      " ARIMA(2,0,2) with zero mean     : -11555.88\n",
      " ARIMA(2,0,4) with zero mean     : -11588.91\n",
      " ARIMA(4,0,2) with zero mean     : -11572.75\n",
      " ARIMA(4,0,4) with zero mean     : -11630.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -11628.23\n",
      "\n",
      " Best model: ARIMA(3,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11551.34\n",
      " ARIMA(0,0,0) with non-zero mean : -7106.605\n",
      " ARIMA(1,0,0) with non-zero mean : -11513.4\n",
      " ARIMA(0,0,1) with non-zero mean : -9071.249\n",
      " ARIMA(0,0,0) with zero mean     : -7102.428\n",
      " ARIMA(1,0,2) with non-zero mean : -11547.63\n",
      " ARIMA(2,0,1) with non-zero mean : -11545.49\n",
      " ARIMA(3,0,2) with non-zero mean : -11617.89\n",
      " ARIMA(3,0,1) with non-zero mean : -11557.32\n",
      " ARIMA(4,0,2) with non-zero mean : -11568.4\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11562.84\n",
      " ARIMA(4,0,1) with non-zero mean : -11564.69\n",
      " ARIMA(4,0,3) with non-zero mean : -11630.55\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11636.38\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : -11589.82\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : -11638.05\n",
      " ARIMA(3,0,4) with zero mean     : -11633.51\n",
      " ARIMA(4,0,3) with zero mean     : -11632.3\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,5) with zero mean     : -11591.73\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,5) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,4) with zero mean     : -11590.88\n",
      "\n",
      " Best model: ARIMA(4,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11548.17\n",
      " ARIMA(0,0,0) with non-zero mean : -7106.547\n",
      " ARIMA(1,0,0) with non-zero mean : -11510.72\n",
      " ARIMA(0,0,1) with non-zero mean : -9069.574\n",
      " ARIMA(0,0,0) with zero mean     : -7102.552\n",
      " ARIMA(1,0,2) with non-zero mean : -11544.52\n",
      " ARIMA(2,0,1) with non-zero mean : -11542.44\n",
      " ARIMA(3,0,2) with non-zero mean : -11617.49\n",
      " ARIMA(3,0,1) with non-zero mean : -11553.85\n",
      " ARIMA(4,0,2) with non-zero mean : -11565.16\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11559.85\n",
      " ARIMA(4,0,1) with non-zero mean : -11561.4\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11619.37\n",
      " ARIMA(2,0,2) with zero mean     : -11550.07\n",
      " ARIMA(3,0,1) with zero mean     : -11555.75\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -11544.33\n",
      " ARIMA(2,0,3) with zero mean     : -11561.72\n",
      " ARIMA(4,0,1) with zero mean     : -11563.27\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11619.52\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11546.07\n",
      " ARIMA(0,0,0) with non-zero mean : -7112.958\n",
      " ARIMA(1,0,0) with non-zero mean : -11508.98\n",
      " ARIMA(0,0,1) with non-zero mean : -9075.459\n",
      " ARIMA(0,0,0) with zero mean     : -7109.358\n",
      " ARIMA(1,0,2) with non-zero mean : -11542.43\n",
      " ARIMA(2,0,1) with non-zero mean : -11540.32\n",
      " ARIMA(3,0,2) with non-zero mean : -11617.21\n",
      " ARIMA(3,0,1) with non-zero mean : -11551.7\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11557.75\n",
      " ARIMA(4,0,1) with non-zero mean : -11559.25\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11618.96\n",
      " ARIMA(2,0,2) with zero mean     : -11547.9\n",
      " ARIMA(3,0,1) with zero mean     : -11553.51\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -11542.14\n",
      " ARIMA(2,0,3) with zero mean     : -11559.55\n",
      " ARIMA(4,0,1) with zero mean     : -11561.06\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11619.15\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11546.69\n",
      " ARIMA(0,0,0) with non-zero mean : -7110.009\n",
      " ARIMA(1,0,0) with non-zero mean : -11509.7\n",
      " ARIMA(0,0,1) with non-zero mean : -9073.832\n",
      " ARIMA(0,0,0) with zero mean     : -7105.975\n",
      " ARIMA(1,0,2) with non-zero mean : -11542.96\n",
      " ARIMA(2,0,1) with non-zero mean : -11540.83\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11558.31\n",
      " ARIMA(1,0,3) with non-zero mean : -11560.89\n",
      " ARIMA(0,0,3) with non-zero mean : -10457.85\n",
      " ARIMA(1,0,4) with non-zero mean : -11559.83\n",
      " ARIMA(0,0,2) with non-zero mean : -9950.234\n",
      " ARIMA(0,0,4) with non-zero mean : -10869.46\n",
      " ARIMA(2,0,4) with non-zero mean : -11584.44\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11592.16\n",
      " ARIMA(1,0,5) with non-zero mean : -11564.19\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with zero mean     : -11594.02\n",
      " ARIMA(1,0,5) with zero mean     : -11566.03\n",
      " ARIMA(2,0,4) with zero mean     : -11586.28\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(1,0,4) with zero mean     : -11561.65\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,5) with zero mean     : -11593.87\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11547.96\n",
      " ARIMA(0,0,0) with non-zero mean : -7112.272\n",
      " ARIMA(1,0,0) with non-zero mean : -11510.05\n",
      " ARIMA(0,0,1) with non-zero mean : -9074.982\n",
      " ARIMA(0,0,0) with zero mean     : -7106.199\n",
      " ARIMA(1,0,2) with non-zero mean : -11544.13\n",
      " ARIMA(2,0,1) with non-zero mean : -11542.04\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11559.77\n",
      " ARIMA(1,0,3) with non-zero mean : -11562.34\n",
      " ARIMA(0,0,3) with non-zero mean : -10457.36\n",
      " ARIMA(1,0,4) with non-zero mean : -11561.29\n",
      " ARIMA(0,0,2) with non-zero mean : -9949.54\n",
      " ARIMA(0,0,4) with non-zero mean : -10868.67\n",
      " ARIMA(2,0,4) with non-zero mean : -11586.17\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11593.93\n",
      " ARIMA(1,0,5) with non-zero mean : -11565.7\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with zero mean     : -11595.61\n",
      " ARIMA(1,0,5) with zero mean     : -11567.42\n",
      " ARIMA(2,0,4) with zero mean     : -11587.81\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(1,0,4) with zero mean     : -11562.99\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,5) with zero mean     : -11595.61\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11551.98\n",
      " ARIMA(0,0,0) with non-zero mean : -7114.245\n",
      " ARIMA(1,0,0) with non-zero mean : -11513.27\n",
      " ARIMA(0,0,1) with non-zero mean : -9076.409\n",
      " ARIMA(0,0,0) with zero mean     : -7108.062\n",
      " ARIMA(1,0,2) with non-zero mean : -11548.07\n",
      " ARIMA(2,0,1) with non-zero mean : -11545.97\n",
      " ARIMA(3,0,2) with non-zero mean : -11621.92\n",
      " ARIMA(3,0,1) with non-zero mean : -11557.83\n",
      " ARIMA(4,0,2) with non-zero mean : -11569.14\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11563.49\n",
      " ARIMA(4,0,1) with non-zero mean : -11565.27\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : -11623.02\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11549.82\n",
      " ARIMA(0,0,0) with non-zero mean : -7108.307\n",
      " ARIMA(1,0,0) with non-zero mean : -11511.15\n",
      " ARIMA(0,0,1) with non-zero mean : -9070.413\n",
      " ARIMA(0,0,0) with zero mean     : -7098.131\n",
      " ARIMA(1,0,2) with non-zero mean : -11546.06\n",
      " ARIMA(2,0,1) with non-zero mean : -11543.98\n",
      " ARIMA(3,0,2) with non-zero mean : -11620.06\n",
      " ARIMA(3,0,1) with non-zero mean : -11555.65\n",
      " ARIMA(4,0,2) with non-zero mean : -11567.5\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11561.41\n",
      " ARIMA(4,0,1) with non-zero mean : -11563.26\n",
      " ARIMA(4,0,3) with non-zero mean : -11630.88\n",
      " ARIMA(5,0,3) with non-zero mean : -11623.84\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11631.65\n",
      " ARIMA(5,0,1) with non-zero mean : -11590.51\n",
      " ARIMA(5,0,2) with zero mean     : -11633.39\n",
      " ARIMA(4,0,2) with zero mean     : -11569.12\n",
      " ARIMA(5,0,1) with zero mean     : -11592.07\n",
      " ARIMA(5,0,3) with zero mean     : -11636.77\n",
      " ARIMA(4,0,3) with zero mean     : -11632.71\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with zero mean     : -11591.97\n",
      "\n",
      " Best model: ARIMA(5,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11546.59\n",
      " ARIMA(0,0,0) with non-zero mean : -7108.494\n",
      " ARIMA(1,0,0) with non-zero mean : -11507.88\n",
      " ARIMA(0,0,1) with non-zero mean : -9068.035\n",
      " ARIMA(0,0,0) with zero mean     : -7100.783\n",
      " ARIMA(1,0,2) with non-zero mean : -11542.94\n",
      " ARIMA(2,0,1) with non-zero mean : -11541.28\n",
      " ARIMA(3,0,2) with non-zero mean : -11614.15\n",
      " ARIMA(3,0,1) with non-zero mean : -11552.61\n",
      " ARIMA(4,0,2) with non-zero mean : -11630.6\n",
      " ARIMA(4,0,1) with non-zero mean : -11560.2\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,1) with non-zero mean : -11587.56\n",
      " ARIMA(5,0,3) with non-zero mean : -11634.25\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : -11635.68\n",
      "\n",
      " Best model: ARIMA(5,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11543.12\n",
      " ARIMA(0,0,0) with non-zero mean : -7104.029\n",
      " ARIMA(1,0,0) with non-zero mean : -11504.2\n",
      " ARIMA(0,0,1) with non-zero mean : -9062.16\n",
      " ARIMA(0,0,0) with zero mean     : -7093.004\n",
      " ARIMA(1,0,2) with non-zero mean : -11538.94\n",
      " ARIMA(2,0,1) with non-zero mean : -11537.27\n",
      " ARIMA(3,0,2) with non-zero mean : -11611.29\n",
      " ARIMA(3,0,1) with non-zero mean : -11548.77\n",
      " ARIMA(4,0,2) with non-zero mean : -11560.94\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11554.65\n",
      " ARIMA(4,0,1) with non-zero mean : -11556.15\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11612.56\n",
      " ARIMA(2,0,2) with zero mean     : -11544.66\n",
      " ARIMA(3,0,1) with zero mean     : -11550.31\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -11538.8\n",
      " ARIMA(2,0,3) with zero mean     : -11556.13\n",
      " ARIMA(4,0,1) with zero mean     : -11557.64\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11614.8\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11541.63\n",
      " ARIMA(0,0,0) with non-zero mean : -7104.001\n",
      " ARIMA(1,0,0) with non-zero mean : -11503.56\n",
      " ARIMA(0,0,1) with non-zero mean : -9064.192\n",
      " ARIMA(0,0,0) with zero mean     : -7092.129\n",
      " ARIMA(1,0,2) with non-zero mean : -11538.1\n",
      " ARIMA(2,0,1) with non-zero mean : -11536.04\n",
      " ARIMA(3,0,2) with non-zero mean : -11611.74\n",
      " ARIMA(3,0,1) with non-zero mean : -11547.4\n",
      " ARIMA(4,0,2) with non-zero mean : -11558.95\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11553.51\n",
      " ARIMA(4,0,1) with non-zero mean : -11555.88\n",
      " ARIMA(4,0,3) with non-zero mean : -11629.28\n",
      " ARIMA(5,0,3) with non-zero mean : -11628.64\n",
      " ARIMA(4,0,4) with non-zero mean : -11616.24\n",
      " ARIMA(3,0,4) with non-zero mean : -11583.02\n",
      " ARIMA(5,0,2) with non-zero mean : -11610.32\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11619.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with non-zero mean : -11580.32\n",
      "\n",
      " Best model: ARIMA(4,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11542.31\n",
      " ARIMA(0,0,0) with non-zero mean : -7104.746\n",
      " ARIMA(1,0,0) with non-zero mean : -11503.98\n",
      " ARIMA(0,0,1) with non-zero mean : -9064.626\n",
      " ARIMA(0,0,0) with zero mean     : -7093.767\n",
      " ARIMA(1,0,2) with non-zero mean : -11538.59\n",
      " ARIMA(2,0,1) with non-zero mean : -11536.52\n",
      " ARIMA(3,0,2) with non-zero mean : -11610.53\n",
      " ARIMA(3,0,1) with non-zero mean : -11548.59\n",
      " ARIMA(4,0,2) with non-zero mean : -11560.71\n",
      " ARIMA(3,0,3) with non-zero mean : -11625.57\n",
      " ARIMA(2,0,3) with non-zero mean : -11554\n",
      " ARIMA(4,0,3) with non-zero mean : -11622.92\n",
      " ARIMA(3,0,4) with non-zero mean : -11580.38\n",
      " ARIMA(2,0,4) with non-zero mean : -11581.82\n",
      " ARIMA(4,0,4) with non-zero mean : -11621.31\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -11627.63\n",
      "\n",
      " Best model: ARIMA(4,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11539.47\n",
      " ARIMA(0,0,0) with non-zero mean : -7102.276\n",
      " ARIMA(1,0,0) with non-zero mean : -11501.5\n",
      " ARIMA(0,0,1) with non-zero mean : -9062.581\n",
      " ARIMA(0,0,0) with zero mean     : -7090.135\n",
      " ARIMA(1,0,2) with non-zero mean : -11535.92\n",
      " ARIMA(2,0,1) with non-zero mean : -11533.8\n",
      " ARIMA(3,0,2) with non-zero mean : -11606.73\n",
      " ARIMA(3,0,1) with non-zero mean : -11545.4\n",
      " ARIMA(4,0,2) with non-zero mean : -11558.05\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11551.07\n",
      " ARIMA(4,0,1) with non-zero mean : -11553.3\n",
      " ARIMA(4,0,3) with non-zero mean : -11619.69\n",
      " ARIMA(5,0,3) with non-zero mean : -11619.9\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11625.96\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : -11583\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : -11627.36\n",
      " ARIMA(3,0,4) with zero mean     : -11622.97\n",
      " ARIMA(4,0,3) with zero mean     : -11621.42\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,5) with zero mean     : -11584.58\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -11621.32\n",
      " ARIMA(5,0,5) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -11626.69\n",
      "\n",
      " Best model: ARIMA(3,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11543\n",
      " ARIMA(0,0,0) with non-zero mean : -7109.443\n",
      " ARIMA(1,0,0) with non-zero mean : -11504.54\n",
      " ARIMA(0,0,1) with non-zero mean : -9066.509\n",
      " ARIMA(0,0,0) with zero mean     : -7097.631\n",
      " ARIMA(1,0,2) with non-zero mean : -11539.42\n",
      " ARIMA(2,0,1) with non-zero mean : -11537.33\n",
      " ARIMA(3,0,2) with non-zero mean : -11607.85\n",
      " ARIMA(3,0,1) with non-zero mean : -11549.09\n",
      " ARIMA(4,0,2) with non-zero mean : -11561.32\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11554.41\n",
      " ARIMA(4,0,1) with non-zero mean : -11556.82\n",
      " ARIMA(4,0,3) with non-zero mean : -11619.75\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11627.91\n",
      " ARIMA(3,0,4) with non-zero mean : -11576.49\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : -11586.89\n",
      " ARIMA(3,0,5) with non-zero mean : -11634.43\n",
      " ARIMA(2,0,5) with non-zero mean : -11590.8\n",
      " ARIMA(2,0,4) with non-zero mean : -11582.07\n",
      " ARIMA(3,0,5) with zero mean     : -11635\n",
      " ARIMA(2,0,5) with zero mean     : -11592.46\n",
      " ARIMA(3,0,4) with zero mean     : -11624.41\n",
      " ARIMA(4,0,5) with zero mean     : -11588.56\n",
      " ARIMA(2,0,4) with zero mean     : -11583.67\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -11629.23\n",
      "\n",
      " Best model: ARIMA(3,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11489.56\n",
      " ARIMA(0,1,0) with drift         : -11407.73\n",
      " ARIMA(1,1,0) with drift         : -11459.08\n",
      " ARIMA(0,1,1) with drift         : -11469.07\n",
      " ARIMA(0,1,0)                    : -11409.73\n",
      " ARIMA(1,1,2) with drift         : -11476.07\n",
      " ARIMA(2,1,1) with drift         : -11481.59\n",
      " ARIMA(3,1,2) with drift         : -11545.27\n",
      " ARIMA(3,1,1) with drift         : -11482.08\n",
      " ARIMA(4,1,2) with drift         : -11551.58\n",
      " ARIMA(4,1,1) with drift         : -11484.96\n",
      " ARIMA(5,1,2) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11548.26\n",
      " ARIMA(5,1,1) with drift         : -11492.25\n",
      " ARIMA(5,1,3) with drift         : -11514.51\n",
      " ARIMA(4,1,2)                    : -11553.38\n",
      " ARIMA(3,1,2)                    : -11547.18\n",
      " ARIMA(4,1,1)                    : -11486.97\n",
      " ARIMA(5,1,2)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(3,1,1)                    : -11484.09\n",
      " ARIMA(3,1,3)                    : -11550.27\n",
      " ARIMA(5,1,1)                    : -11494.27\n",
      " ARIMA(5,1,3)                    : -11516.53\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11568.56\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "[1] \"70 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11488.51\n",
      " ARIMA(0,1,0) with drift         : -11406.48\n",
      " ARIMA(1,1,0) with drift         : -11458.08\n",
      " ARIMA(0,1,1) with drift         : -11467.77\n",
      " ARIMA(0,1,0)                    : -11408.49\n",
      " ARIMA(1,1,2) with drift         : -11474.57\n",
      " ARIMA(2,1,1) with drift         : -11479.9\n",
      " ARIMA(3,1,2) with drift         : -11548.76\n",
      " ARIMA(3,1,1) with drift         : -11480.84\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11550.62\n",
      " ARIMA(2,1,3) with drift         : -11554.97\n",
      " ARIMA(1,1,3) with drift         : -11477.58\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11486.33\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11556.97\n",
      " ARIMA(1,1,3)                    : -11479.59\n",
      " ARIMA(2,1,2)                    : -11490.52\n",
      " ARIMA(3,1,3)                    : -11552.63\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11476.58\n",
      " ARIMA(1,1,4)                    : -11488.34\n",
      " ARIMA(3,1,2)                    : -11550.73\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11567.3\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11539.15\n",
      " ARIMA(0,0,0) with non-zero mean : -7107.673\n",
      " ARIMA(1,0,0) with non-zero mean : -11500.94\n",
      " ARIMA(0,0,1) with non-zero mean : -9065.001\n",
      " ARIMA(0,0,0) with zero mean     : -7096.296\n",
      " ARIMA(1,0,2) with non-zero mean : -11535.64\n",
      " ARIMA(2,0,1) with non-zero mean : -11533.93\n",
      " ARIMA(3,0,2) with non-zero mean : -11608.97\n",
      " ARIMA(3,0,1) with non-zero mean : -11545.34\n",
      " ARIMA(4,0,2) with non-zero mean : -11558.35\n",
      " ARIMA(3,0,3) with non-zero mean : -11559.27\n",
      " ARIMA(2,0,3) with non-zero mean : -11551.85\n",
      " ARIMA(4,0,1) with non-zero mean : -11553.66\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11610.6\n",
      " ARIMA(2,0,2) with zero mean     : -11540.78\n",
      " ARIMA(3,0,1) with zero mean     : -11546.94\n",
      " ARIMA(4,0,2) with zero mean     : -11559.91\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -11535.53\n",
      " ARIMA(2,0,3) with zero mean     : -11553.4\n",
      " ARIMA(4,0,1) with zero mean     : -11555.22\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11611.22\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11484.71\n",
      " ARIMA(0,1,0) with drift         : -11402.92\n",
      " ARIMA(1,1,0) with drift         : -11453.72\n",
      " ARIMA(0,1,1) with drift         : -11463.3\n",
      " ARIMA(0,1,0)                    : -11404.93\n",
      " ARIMA(1,1,2) with drift         : -11470.24\n",
      " ARIMA(2,1,1) with drift         : -11475.7\n",
      " ARIMA(3,1,2) with drift         : -11537.52\n",
      " ARIMA(3,1,1) with drift         : -11476.24\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11479.22\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2) with drift         : -11549.01\n",
      "\n",
      " Best model: ARIMA(3,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11541.88\n",
      " ARIMA(0,0,0) with non-zero mean : -7110.457\n",
      " ARIMA(1,0,0) with non-zero mean : -11504.25\n",
      " ARIMA(0,0,1) with non-zero mean : -9071.053\n",
      " ARIMA(0,0,0) with zero mean     : -7095.669\n",
      " ARIMA(1,0,2) with non-zero mean : -11537.67\n",
      " ARIMA(2,0,1) with non-zero mean : -11535.9\n",
      " ARIMA(3,0,2) with non-zero mean : -11610.43\n",
      " ARIMA(3,0,1) with non-zero mean : -11547.99\n",
      " ARIMA(4,0,2) with non-zero mean : -11561.34\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11554.77\n",
      " ARIMA(4,0,1) with non-zero mean : -11556.7\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11611.69\n",
      " ARIMA(2,0,2) with zero mean     : -11543.41\n",
      " ARIMA(3,0,1) with zero mean     : -11549.52\n",
      " ARIMA(4,0,2) with zero mean     : -11562.84\n",
      " ARIMA(3,0,3) with zero mean     : -11563.17\n",
      " ARIMA(2,0,1) with zero mean     : -11537.42\n",
      " ARIMA(2,0,3) with zero mean     : -11556.22\n",
      " ARIMA(4,0,1) with zero mean     : -11558.16\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11614.18\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11489.65\n",
      " ARIMA(0,1,0) with drift         : -11408.33\n",
      " ARIMA(1,1,0) with drift         : -11457.28\n",
      " ARIMA(0,1,1) with drift         : -11467.04\n",
      " ARIMA(0,1,0)                    : -11410.33\n",
      " ARIMA(1,1,2) with drift         : -11474.81\n",
      " ARIMA(2,1,1) with drift         : -11480.57\n",
      " ARIMA(3,1,2) with drift         : -11549.16\n",
      " ARIMA(3,1,1) with drift         : -11481.79\n",
      " ARIMA(4,1,2) with drift         : -11541.63\n",
      " ARIMA(3,1,3) with drift         : -11548.71\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11551.15\n",
      " ARIMA(2,1,2)                    : -11491.66\n",
      " ARIMA(3,1,1)                    : -11483.8\n",
      " ARIMA(4,1,2)                    : -11543.55\n",
      " ARIMA(3,1,3)                    : -11550.71\n",
      " ARIMA(2,1,1)                    : -11482.57\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11566.72\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11491.43\n",
      " ARIMA(0,1,0) with drift         : -11409.56\n",
      " ARIMA(1,1,0) with drift         : -11458.85\n",
      " ARIMA(0,1,1) with drift         : -11467.94\n",
      " ARIMA(0,1,0)                    : -11411.56\n",
      " ARIMA(1,1,2) with drift         : -11476.06\n",
      " ARIMA(2,1,1) with drift         : -11481.97\n",
      " ARIMA(3,1,2) with drift         : -11552.28\n",
      " ARIMA(3,1,1) with drift         : -11482.84\n",
      " ARIMA(4,1,2) with drift         : -11551.35\n",
      " ARIMA(3,1,3) with drift         : -11551.43\n",
      " ARIMA(2,1,3) with drift         : -11554.61\n",
      " ARIMA(1,1,3) with drift         : -11479.29\n",
      " ARIMA(2,1,4) with drift         : -11548.45\n",
      " ARIMA(1,1,4) with drift         : -11487.19\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11556.62\n",
      " ARIMA(1,1,3)                    : -11481.3\n",
      " ARIMA(2,1,2)                    : -11493.44\n",
      " ARIMA(3,1,3)                    : -11553.42\n",
      " ARIMA(2,1,4)                    : -11550.41\n",
      " ARIMA(1,1,2)                    : -11478.06\n",
      " ARIMA(1,1,4)                    : -11489.19\n",
      " ARIMA(3,1,2)                    : -11554.25\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : -11567.05\n",
      "\n",
      " Best model: ARIMA(2,1,3) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11488.75\n",
      " ARIMA(0,1,0) with drift         : -11408.4\n",
      " ARIMA(1,1,0) with drift         : -11457.15\n",
      " ARIMA(0,1,1) with drift         : -11466.65\n",
      " ARIMA(0,1,0)                    : -11410.4\n",
      " ARIMA(1,1,2) with drift         : -11474.23\n",
      " ARIMA(2,1,1) with drift         : -11479.83\n",
      " ARIMA(3,1,2) with drift         : -11552.95\n",
      " ARIMA(3,1,1) with drift         : -11480.15\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11553.93\n",
      " ARIMA(1,1,3) with drift         : -11477.19\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11485.58\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11555.94\n",
      " ARIMA(1,1,3)                    : -11479.19\n",
      " ARIMA(2,1,2)                    : -11490.76\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11476.23\n",
      " ARIMA(1,1,4)                    : -11487.59\n",
      " ARIMA(3,1,2)                    : -11554.95\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11566.29\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11487.92\n",
      " ARIMA(0,1,0) with drift         : -11407.66\n",
      " ARIMA(1,1,0) with drift         : -11456.44\n",
      " ARIMA(0,1,1) with drift         : -11466.09\n",
      " ARIMA(0,1,0)                    : -11409.66\n",
      " ARIMA(1,1,2) with drift         : -11473.69\n",
      " ARIMA(2,1,1) with drift         : -11479.01\n",
      " ARIMA(3,1,2) with drift         : -11553.48\n",
      " ARIMA(3,1,1) with drift         : -11479.31\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11482.74\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11555.47\n",
      " ARIMA(2,1,2)                    : -11489.93\n",
      " ARIMA(3,1,1)                    : -11481.31\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11481.01\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11565.76\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11488.54\n",
      " ARIMA(0,1,0) with drift         : -11407.27\n",
      " ARIMA(1,1,0) with drift         : -11456.51\n",
      " ARIMA(0,1,1) with drift         : -11465.84\n",
      " ARIMA(0,1,0)                    : -11409.28\n",
      " ARIMA(1,1,2) with drift         : -11473.84\n",
      " ARIMA(2,1,1) with drift         : -11479.38\n",
      " ARIMA(3,1,2) with drift         : -11550.57\n",
      " ARIMA(3,1,1) with drift         : -11479.9\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11549.41\n",
      " ARIMA(2,1,3) with drift         : -11551.1\n",
      " ARIMA(1,1,3) with drift         : -11476.99\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11484.53\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11553.11\n",
      " ARIMA(1,1,3)                    : -11478.99\n",
      " ARIMA(2,1,2)                    : -11490.55\n",
      " ARIMA(3,1,3)                    : -11551.39\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11475.85\n",
      " ARIMA(1,1,4)                    : -11486.54\n",
      " ARIMA(3,1,2)                    : -11552.52\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11565.82\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11483.48\n",
      " ARIMA(0,1,0) with drift         : -11402.7\n",
      " ARIMA(1,1,0) with drift         : -11451.73\n",
      " ARIMA(0,1,1) with drift         : -11461.1\n",
      " ARIMA(0,1,0)                    : -11404.7\n",
      " ARIMA(1,1,2) with drift         : -11468.25\n",
      " ARIMA(2,1,1) with drift         : -11474.04\n",
      " ARIMA(3,1,2) with drift         : -11536.83\n",
      " ARIMA(3,1,1) with drift         : -11474.56\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11549\n",
      " ARIMA(1,1,3) with drift         : -11471.67\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11480.23\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11550.98\n",
      " ARIMA(1,1,3)                    : -11473.67\n",
      " ARIMA(2,1,2)                    : -11485.48\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11470.26\n",
      " ARIMA(1,1,4)                    : -11482.24\n",
      " ARIMA(3,1,2)                    : -11548.92\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11561.42\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11482.57\n",
      " ARIMA(0,1,0) with drift         : -11400.37\n",
      " ARIMA(1,1,0) with drift         : -11450.16\n",
      " ARIMA(0,1,1) with drift         : -11458.84\n",
      " ARIMA(0,1,0)                    : -11402.37\n",
      " ARIMA(1,1,2) with drift         : -11465.69\n",
      " ARIMA(2,1,1) with drift         : -11472.97\n",
      " ARIMA(3,1,2) with drift         : -11540.16\n",
      " ARIMA(3,1,1) with drift         : -11473.79\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11539.88\n",
      " ARIMA(2,1,3) with drift         : -11537.05\n",
      " ARIMA(4,1,1) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11542.16\n",
      " ARIMA(2,1,2)                    : -11484.58\n",
      " ARIMA(3,1,1)                    : -11475.8\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11541.9\n",
      " ARIMA(2,1,1)                    : -11474.98\n",
      " ARIMA(2,1,3)                    : -11538.99\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11558.63\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11479.35\n",
      " ARIMA(0,1,0) with drift         : -11399.67\n",
      " ARIMA(1,1,0) with drift         : -11448.3\n",
      " ARIMA(0,1,1) with drift         : -11457.52\n",
      " ARIMA(0,1,0)                    : -11401.67\n",
      " ARIMA(1,1,2) with drift         : -11464.19\n",
      " ARIMA(2,1,1) with drift         : -11469.55\n",
      " ARIMA(3,1,2) with drift         : -11543.91\n",
      " ARIMA(3,1,1) with drift         : -11470.27\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11545.94\n",
      " ARIMA(2,1,2)                    : -11481.36\n",
      " ARIMA(3,1,1)                    : -11472.28\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11471.56\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11557.18\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11470.5\n",
      " ARIMA(0,1,0) with drift         : -11391.25\n",
      " ARIMA(1,1,0) with drift         : -11440.04\n",
      " ARIMA(0,1,1) with drift         : -11449.27\n",
      " ARIMA(0,1,0)                    : -11393.26\n",
      " ARIMA(1,1,2) with drift         : -11455.74\n",
      " ARIMA(2,1,1) with drift         : -11461.2\n",
      " ARIMA(3,1,2) with drift         : -11525.03\n",
      " ARIMA(3,1,1) with drift         : -11462.98\n",
      " ARIMA(4,1,2) with drift         : -11520.54\n",
      " ARIMA(3,1,3) with drift         : -11524.95\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11466.16\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11526.97\n",
      " ARIMA(2,1,2)                    : -11472.51\n",
      " ARIMA(3,1,1)                    : -11464.99\n",
      " ARIMA(4,1,2)                    : -11522.35\n",
      " ARIMA(3,1,3)                    : -11526.95\n",
      " ARIMA(2,1,1)                    : -11463.21\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : -11468.17\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11548.01\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11465.7\n",
      " ARIMA(0,1,0) with drift         : -11387.82\n",
      " ARIMA(1,1,0) with drift         : -11435.95\n",
      " ARIMA(0,1,1) with drift         : -11445.09\n",
      " ARIMA(0,1,0)                    : -11389.82\n",
      " ARIMA(1,1,2) with drift         : -11451.65\n",
      " ARIMA(2,1,1) with drift         : -11456.63\n",
      " ARIMA(3,1,2) with drift         : -11531.51\n",
      " ARIMA(3,1,1) with drift         : -11456.91\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11459.7\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11533.52\n",
      " ARIMA(2,1,2)                    : -11467.71\n",
      " ARIMA(3,1,1)                    : -11458.92\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11458.63\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11543.83\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11463.12\n",
      " ARIMA(0,1,0) with drift         : -11386.02\n",
      " ARIMA(1,1,0) with drift         : -11433.6\n",
      " ARIMA(0,1,1) with drift         : -11442.58\n",
      " ARIMA(0,1,0)                    : -11388.03\n",
      " ARIMA(1,1,2) with drift         : -11448.94\n",
      " ARIMA(2,1,1) with drift         : -11453.81\n",
      " ARIMA(3,1,2) with drift         : -11525.39\n",
      " ARIMA(3,1,1) with drift         : -11454.66\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11524.52\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11457.02\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11527.4\n",
      " ARIMA(2,1,2)                    : -11465.13\n",
      " ARIMA(3,1,1)                    : -11456.67\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11526.53\n",
      " ARIMA(2,1,1)                    : -11455.82\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : -11459.03\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11541.25\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11458.77\n",
      " ARIMA(0,1,0) with drift         : -11381.36\n",
      " ARIMA(1,1,0) with drift         : -11429.64\n",
      " ARIMA(0,1,1) with drift         : -11438.35\n",
      " ARIMA(0,1,0)                    : -11383.36\n",
      " ARIMA(1,1,2) with drift         : -11444.64\n",
      " ARIMA(2,1,1) with drift         : -11449.51\n",
      " ARIMA(3,1,2) with drift         : -11523.98\n",
      " ARIMA(3,1,1) with drift         : -11449.86\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11522.53\n",
      " ARIMA(2,1,3) with drift         : -11515.81\n",
      " ARIMA(4,1,1) with drift         : -11452.53\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11525.99\n",
      " ARIMA(2,1,2)                    : -11460.78\n",
      " ARIMA(3,1,1)                    : -11451.87\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11524.55\n",
      " ARIMA(2,1,1)                    : -11451.52\n",
      " ARIMA(2,1,3)                    : -11526.75\n",
      " ARIMA(1,1,3)                    : -11449.44\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11446.65\n",
      " ARIMA(1,1,4)                    : -11457.35\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : -11537.12\n",
      "\n",
      " Best model: ARIMA(2,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11461.71\n",
      " ARIMA(0,1,0) with drift         : -11383.29\n",
      " ARIMA(1,1,0) with drift         : -11431.95\n",
      " ARIMA(0,1,1) with drift         : -11440.93\n",
      " ARIMA(0,1,0)                    : -11385.29\n",
      " ARIMA(1,1,2) with drift         : -11446.83\n",
      " ARIMA(2,1,1) with drift         : -11452.16\n",
      " ARIMA(3,1,2) with drift         : -11524.45\n",
      " ARIMA(3,1,1) with drift         : -11453.21\n",
      " ARIMA(4,1,2) with drift         : -11516.21\n",
      " ARIMA(3,1,3) with drift         : -11523.63\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11456.45\n",
      " ARIMA(4,1,3) with drift         : -11557.15\n",
      " ARIMA(5,1,3) with drift         : -11485.61\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(5,1,2) with drift         : Inf\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(4,1,3)                    : -11558.96\n",
      " ARIMA(3,1,3)                    : -11525.63\n",
      " ARIMA(4,1,2)                    : -11518.15\n",
      " ARIMA(5,1,3)                    : -11487.74\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11526.44\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(5,1,2)                    : Inf\n",
      " ARIMA(5,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11539.94\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11464.63\n",
      " ARIMA(0,1,0) with drift         : -11385.89\n",
      " ARIMA(1,1,0) with drift         : -11435.55\n",
      " ARIMA(0,1,1) with drift         : -11444.16\n",
      " ARIMA(0,1,0)                    : -11387.89\n",
      " ARIMA(1,1,2) with drift         : -11450.41\n",
      " ARIMA(2,1,1) with drift         : -11455.3\n",
      " ARIMA(3,1,2) with drift         : -11527.35\n",
      " ARIMA(3,1,1) with drift         : -11455.78\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11529.4\n",
      " ARIMA(1,1,3) with drift         : -11453.12\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11460.64\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11531.41\n",
      " ARIMA(1,1,3)                    : -11455.13\n",
      " ARIMA(2,1,2)                    : -11466.63\n",
      " ARIMA(3,1,3)                    : -11528.15\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11452.43\n",
      " ARIMA(1,1,4)                    : -11462.65\n",
      " ARIMA(3,1,2)                    : -11529.33\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : -11541.1\n",
      "\n",
      " Best model: ARIMA(2,1,3) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11467.17\n",
      " ARIMA(0,1,0) with drift         : -11390.13\n",
      " ARIMA(1,1,0) with drift         : -11438.99\n",
      " ARIMA(0,1,1) with drift         : -11447.86\n",
      " ARIMA(0,1,0)                    : -11392.14\n",
      " ARIMA(1,1,2) with drift         : -11453.3\n",
      " ARIMA(2,1,1) with drift         : -11458.1\n",
      " ARIMA(3,1,2) with drift         : -11528.67\n",
      " ARIMA(3,1,1) with drift         : -11458.43\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11527.28\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11461.22\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11530.68\n",
      " ARIMA(2,1,2)                    : -11469.17\n",
      " ARIMA(3,1,1)                    : -11460.44\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11529.3\n",
      " ARIMA(2,1,1)                    : -11460.11\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : -11463.24\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11544.53\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11457.26\n",
      " ARIMA(0,1,0) with drift         : -11383.29\n",
      " ARIMA(1,1,0) with drift         : -11430.38\n",
      " ARIMA(0,1,1) with drift         : -11438.84\n",
      " ARIMA(0,1,0)                    : -11385.28\n",
      " ARIMA(1,1,2) with drift         : -11444.28\n",
      " ARIMA(2,1,1) with drift         : -11448.59\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11522.67\n",
      " ARIMA(1,1,3) with drift         : -11446.31\n",
      " ARIMA(3,1,3) with drift         : -11520.59\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11454.56\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11524.67\n",
      " ARIMA(1,1,3)                    : -11448.3\n",
      " ARIMA(2,1,2)                    : -11459.25\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11446.27\n",
      " ARIMA(1,1,4)                    : -11456.53\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : -11535.62\n",
      "\n",
      " Best model: ARIMA(2,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11426.76\n",
      " ARIMA(0,1,0) with drift         : -11358.01\n",
      " ARIMA(1,1,0) with drift         : -11402.29\n",
      " ARIMA(0,1,1) with drift         : -11410.68\n",
      " ARIMA(0,1,0)                    : -11360.01\n",
      " ARIMA(1,1,2) with drift         : -11416.65\n",
      " ARIMA(2,1,1) with drift         : -11420.05\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11411.29\n",
      " ARIMA(1,1,3) with drift         : -11417.46\n",
      " ARIMA(3,1,1) with drift         : -11419.14\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11428.77\n",
      " ARIMA(1,1,2)                    : -11418.66\n",
      " ARIMA(2,1,1)                    : -11422.06\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(1,1,1)                    : -11413.29\n",
      " ARIMA(1,1,3)                    : -11419.46\n",
      " ARIMA(3,1,1)                    : -11421.15\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11438.63\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11419.96\n",
      " ARIMA(0,1,0) with drift         : -11350.92\n",
      " ARIMA(1,1,0) with drift         : -11394.9\n",
      " ARIMA(0,1,1) with drift         : -11403.11\n",
      " ARIMA(0,1,0)                    : -11352.92\n",
      " ARIMA(1,1,2) with drift         : -11408.89\n",
      " ARIMA(2,1,1) with drift         : -11412.58\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11403.44\n",
      " ARIMA(1,1,3) with drift         : -11410.03\n",
      " ARIMA(3,1,1) with drift         : -11411.93\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11421.97\n",
      " ARIMA(1,1,2)                    : -11410.89\n",
      " ARIMA(2,1,1)                    : -11414.58\n",
      " ARIMA(3,1,2)                    : -11484.89\n",
      " ARIMA(3,1,1)                    : -11413.93\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : -11417.69\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11497.38\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11416.52\n",
      " ARIMA(0,1,0) with drift         : -11347.64\n",
      " ARIMA(1,1,0) with drift         : -11391.62\n",
      " ARIMA(0,1,1) with drift         : -11399.55\n",
      " ARIMA(0,1,0)                    : -11349.64\n",
      " ARIMA(1,1,2) with drift         : -11405.39\n",
      " ARIMA(2,1,1) with drift         : -11409.03\n",
      " ARIMA(3,1,2) with drift         : -11479.96\n",
      " ARIMA(3,1,1) with drift         : -11408.41\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11481.73\n",
      " ARIMA(1,1,3) with drift         : -11406.63\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11414.79\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11483.74\n",
      " ARIMA(1,1,3)                    : -11408.63\n",
      " ARIMA(2,1,2)                    : -11418.53\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11407.41\n",
      " ARIMA(1,1,4)                    : -11416.8\n",
      " ARIMA(3,1,2)                    : -11481.98\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : -11494.17\n",
      "\n",
      " Best model: ARIMA(2,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11407.96\n",
      " ARIMA(0,1,0) with drift         : -11338.46\n",
      " ARIMA(1,1,0) with drift         : -11382.61\n",
      " ARIMA(0,1,1) with drift         : -11390.38\n",
      " ARIMA(0,1,0)                    : -11340.46\n",
      " ARIMA(1,1,2) with drift         : -11396.61\n",
      " ARIMA(2,1,1) with drift         : -11400.55\n",
      " ARIMA(3,1,2) with drift         : -11471.9\n",
      " ARIMA(3,1,1) with drift         : -11399.74\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11470.53\n",
      " ARIMA(4,1,1) with drift         : -11403.38\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11473.9\n",
      " ARIMA(2,1,2)                    : -11409.97\n",
      " ARIMA(3,1,1)                    : -11401.75\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11402.56\n",
      " ARIMA(2,1,3)                    : -11472.5\n",
      " ARIMA(4,1,1)                    : -11405.4\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11484.35\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "[1] \"80 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11396.17\n",
      " ARIMA(0,1,0) with drift         : -11328.02\n",
      " ARIMA(1,1,0) with drift         : -11371.4\n",
      " ARIMA(0,1,1) with drift         : -11379.49\n",
      " ARIMA(0,1,0)                    : -11330.02\n",
      " ARIMA(1,1,2) with drift         : -11385.91\n",
      " ARIMA(2,1,1) with drift         : -11389.47\n",
      " ARIMA(3,1,2) with drift         : -11458.66\n",
      " ARIMA(3,1,1) with drift         : -11388.42\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11458.39\n",
      " ARIMA(4,1,1) with drift         : -11391.51\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11460.67\n",
      " ARIMA(2,1,2)                    : -11398.17\n",
      " ARIMA(3,1,1)                    : -11390.41\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11391.47\n",
      " ARIMA(2,1,3)                    : -11460.41\n",
      " ARIMA(4,1,1)                    : -11393.51\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11472.04\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11384.39\n",
      " ARIMA(0,1,0) with drift         : -11316.01\n",
      " ARIMA(1,1,0) with drift         : -11360.76\n",
      " ARIMA(0,1,1) with drift         : -11368.5\n",
      " ARIMA(0,1,0)                    : -11318.01\n",
      " ARIMA(1,1,2) with drift         : -11375.04\n",
      " ARIMA(2,1,1) with drift         : -11378.36\n",
      " ARIMA(3,1,2) with drift         : -11443.48\n",
      " ARIMA(3,1,1) with drift         : -11377.21\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11445.13\n",
      " ARIMA(2,1,3) with drift         : -11446.41\n",
      " ARIMA(1,1,3) with drift         : -11375.64\n",
      " ARIMA(2,1,4) with drift         : -11438.15\n",
      " ARIMA(1,1,4) with drift         : -11381.98\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11440.96\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3) with drift         : -11458.24\n",
      "\n",
      " Best model: ARIMA(2,1,3) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11382.84\n",
      " ARIMA(0,1,0) with drift         : -11314.2\n",
      " ARIMA(1,1,0) with drift         : -11359.08\n",
      " ARIMA(0,1,1) with drift         : -11366.52\n",
      " ARIMA(0,1,0)                    : -11316.21\n",
      " ARIMA(1,1,2) with drift         : -11373.79\n",
      " ARIMA(2,1,1) with drift         : -11377.02\n",
      " ARIMA(3,1,2) with drift         : -11443.18\n",
      " ARIMA(3,1,1) with drift         : -11375.83\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11441.2\n",
      " ARIMA(2,1,3) with drift         : -11440.68\n",
      " ARIMA(4,1,1) with drift         : -11378.62\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11445.18\n",
      " ARIMA(2,1,2)                    : -11384.85\n",
      " ARIMA(3,1,1)                    : -11377.84\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11443.21\n",
      " ARIMA(2,1,1)                    : -11379.03\n",
      " ARIMA(2,1,3)                    : -11442.69\n",
      " ARIMA(4,1,1)                    : -11380.64\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11457.01\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11385.06\n",
      " ARIMA(0,1,0) with drift         : -11317.34\n",
      " ARIMA(1,1,0) with drift         : -11361\n",
      " ARIMA(0,1,1) with drift         : -11369.29\n",
      " ARIMA(0,1,0)                    : -11319.34\n",
      " ARIMA(1,1,2) with drift         : -11375.57\n",
      " ARIMA(2,1,1) with drift         : -11378.89\n",
      " ARIMA(3,1,2) with drift         : -11447.76\n",
      " ARIMA(3,1,1) with drift         : -11377.8\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11380.61\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11449.77\n",
      " ARIMA(2,1,2)                    : -11387.06\n",
      " ARIMA(3,1,1)                    : -11379.81\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11380.9\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : -11382.62\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11460.04\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11381.42\n",
      " ARIMA(0,1,0) with drift         : -11314.33\n",
      " ARIMA(1,1,0) with drift         : -11358.1\n",
      " ARIMA(0,1,1) with drift         : -11366.38\n",
      " ARIMA(0,1,0)                    : -11316.34\n",
      " ARIMA(1,1,2) with drift         : -11372.29\n",
      " ARIMA(2,1,1) with drift         : -11375.63\n",
      " ARIMA(3,1,2) with drift         : -11437\n",
      " ARIMA(3,1,1) with drift         : -11375\n",
      " ARIMA(4,1,2) with drift         : -11443.02\n",
      " ARIMA(4,1,1) with drift         : -11377.67\n",
      " ARIMA(5,1,2) with drift         : -11383.28\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(5,1,1) with drift         : -11384.28\n",
      " ARIMA(5,1,3) with drift         : -11460.66\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(5,1,3)                    : -11406.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : -11455.43\n",
      "\n",
      " Best model: ARIMA(3,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11376\n",
      " ARIMA(0,1,0) with drift         : -11310.81\n",
      " ARIMA(1,1,0) with drift         : -11353.5\n",
      " ARIMA(0,1,1) with drift         : -11361.68\n",
      " ARIMA(0,1,0)                    : -11312.81\n",
      " ARIMA(1,1,2) with drift         : -11367.66\n",
      " ARIMA(2,1,1) with drift         : -11370.74\n",
      " ARIMA(3,1,2) with drift         : -11435.23\n",
      " ARIMA(3,1,1) with drift         : -11369.84\n",
      " ARIMA(4,1,2) with drift         : -11435.36\n",
      " ARIMA(4,1,1) with drift         : -11372.57\n",
      " ARIMA(5,1,2) with drift         : -11379.67\n",
      " ARIMA(4,1,3) with drift         : -11462.93\n",
      " ARIMA(3,1,3) with drift         : -11437.7\n",
      " ARIMA(5,1,3) with drift         : -11450.93\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(5,1,4) with drift         : -11457.04\n",
      " ARIMA(4,1,3)                    : -11464.8\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(4,1,2)                    : -11437.24\n",
      " ARIMA(5,1,3)                    : -11452.91\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11437.19\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(5,1,2)                    : -11381.68\n",
      " ARIMA(5,1,4)                    : -11458.98\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(5,1,4)                    : Inf\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(5,1,3)                    : Inf\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11451.79\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11377.46\n",
      " ARIMA(0,1,0) with drift         : -11311.79\n",
      " ARIMA(1,1,0) with drift         : -11353.83\n",
      " ARIMA(0,1,1) with drift         : -11361.84\n",
      " ARIMA(0,1,0)                    : -11313.79\n",
      " ARIMA(1,1,2) with drift         : -11367.56\n",
      " ARIMA(2,1,1) with drift         : -11372.91\n",
      " ARIMA(3,1,2) with drift         : -11421.85\n",
      " ARIMA(3,1,1) with drift         : -11371.51\n",
      " ARIMA(4,1,2) with drift         : -11441.18\n",
      " ARIMA(4,1,1) with drift         : -11374.72\n",
      " ARIMA(5,1,2) with drift         : -11382.23\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11422.45\n",
      " ARIMA(5,1,1) with drift         : -11383.49\n",
      " ARIMA(5,1,3) with drift         : -11452.79\n",
      " ARIMA(5,1,4) with drift         : -11453.95\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(5,1,5) with drift         : Inf\n",
      " ARIMA(4,1,5) with drift         : Inf\n",
      " ARIMA(5,1,4)                    : -11456\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(5,1,3)                    : -11454.45\n",
      " ARIMA(5,1,5)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(4,1,5)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,1,4)                    : Inf\n",
      " ARIMA(5,1,3)                    : Inf\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : -11449.4\n",
      "\n",
      " Best model: ARIMA(3,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11401.14\n",
      " ARIMA(0,1,0) with drift         : -11333.59\n",
      " ARIMA(1,1,0) with drift         : -11375.37\n",
      " ARIMA(0,1,1) with drift         : -11383.32\n",
      " ARIMA(0,1,0)                    : -11335.6\n",
      " ARIMA(1,1,2) with drift         : -11388.38\n",
      " ARIMA(2,1,1) with drift         : -11397.14\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11436.48\n",
      " ARIMA(1,1,3) with drift         : -11388.8\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11395.96\n",
      " ARIMA(3,1,4) with drift         : -11404.42\n",
      " ARIMA(2,1,3)                    : -11438.39\n",
      " ARIMA(1,1,3)                    : -11390.8\n",
      " ARIMA(2,1,2)                    : -11403.15\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11390.39\n",
      " ARIMA(1,1,4)                    : -11397.97\n",
      " ARIMA(3,1,2)                    : -11399.44\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11409.43\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11414.62\n",
      " ARIMA(0,1,0) with drift         : -11349.66\n",
      " ARIMA(1,1,0) with drift         : -11391.07\n",
      " ARIMA(0,1,1) with drift         : -11398.77\n",
      " ARIMA(0,1,0)                    : -11351.66\n",
      " ARIMA(1,1,2) with drift         : -11404.51\n",
      " ARIMA(2,1,1) with drift         : -11408.59\n",
      " ARIMA(3,1,2) with drift         : -11474.76\n",
      " ARIMA(3,1,1) with drift         : -11407.28\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11474.66\n",
      " ARIMA(2,1,3) with drift         : -11475\n",
      " ARIMA(1,1,3) with drift         : -11405.01\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11411.68\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11476.95\n",
      " ARIMA(1,1,3)                    : -11407\n",
      " ARIMA(2,1,2)                    : -11416.63\n",
      " ARIMA(3,1,3)                    : -11476.66\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11406.51\n",
      " ARIMA(1,1,4)                    : -11413.69\n",
      " ARIMA(3,1,2)                    : -11476.73\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : -11489.85\n",
      "\n",
      " Best model: ARIMA(3,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11417\n",
      " ARIMA(0,1,0) with drift         : -11350.81\n",
      " ARIMA(1,1,0) with drift         : -11393.43\n",
      " ARIMA(0,1,1) with drift         : -11401.37\n",
      " ARIMA(0,1,0)                    : -11352.81\n",
      " ARIMA(1,1,2) with drift         : -11408.15\n",
      " ARIMA(2,1,1) with drift         : -11411.62\n",
      " ARIMA(3,1,2) with drift         : -11478.61\n",
      " ARIMA(3,1,1) with drift         : -11410.14\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11477.88\n",
      " ARIMA(2,1,3) with drift         : -11480.64\n",
      " ARIMA(1,1,3) with drift         : -11408.04\n",
      " ARIMA(2,1,4) with drift         : -11470.54\n",
      " ARIMA(1,1,4) with drift         : -11413.2\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11482.64\n",
      " ARIMA(1,1,3)                    : -11410.05\n",
      " ARIMA(2,1,2)                    : -11419\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : -11472.55\n",
      " ARIMA(1,1,2)                    : -11410.17\n",
      " ARIMA(1,1,4)                    : -11415.2\n",
      " ARIMA(3,1,2)                    : -11480.59\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11494.28\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11428.15\n",
      " ARIMA(0,1,0) with drift         : -11363.82\n",
      " ARIMA(1,1,0) with drift         : -11405.04\n",
      " ARIMA(0,1,1) with drift         : -11413.13\n",
      " ARIMA(0,1,0)                    : -11365.82\n",
      " ARIMA(1,1,2) with drift         : -11419.24\n",
      " ARIMA(2,1,1) with drift         : -11423.1\n",
      " ARIMA(3,1,2) with drift         : -11485.43\n",
      " ARIMA(3,1,1) with drift         : -11421.44\n",
      " ARIMA(4,1,2) with drift         : -11470.37\n",
      " ARIMA(3,1,3) with drift         : -11484.77\n",
      " ARIMA(2,1,3) with drift         : -11487.17\n",
      " ARIMA(1,1,3) with drift         : -11419.2\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11425.26\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11489.13\n",
      " ARIMA(1,1,3)                    : -11421.2\n",
      " ARIMA(2,1,2)                    : -11430.16\n",
      " ARIMA(3,1,3)                    : -11486.74\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11421.24\n",
      " ARIMA(1,1,4)                    : -11427.26\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11439.42\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11445.44\n",
      " ARIMA(0,1,0) with drift         : -11379.2\n",
      " ARIMA(1,1,0) with drift         : -11421.84\n",
      " ARIMA(0,1,1) with drift         : -11429.11\n",
      " ARIMA(0,1,0)                    : -11381.2\n",
      " ARIMA(1,1,2) with drift         : -11437.71\n",
      " ARIMA(2,1,1) with drift         : -11440.18\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11507.1\n",
      " ARIMA(1,1,3) with drift         : -11437.5\n",
      " ARIMA(3,1,3) with drift         : -11506.37\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11443.66\n",
      " ARIMA(3,1,4) with drift         : -11533.54\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(3,1,5) with drift         : -11472.61\n",
      " ARIMA(2,1,5) with drift         : -11477.81\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(4,1,5) with drift         : -11542.91\n",
      " ARIMA(5,1,5) with drift         : Inf\n",
      " ARIMA(5,1,4) with drift         : -11515.88\n",
      " ARIMA(4,1,5)                    : -11544.81\n",
      " ARIMA(3,1,5)                    : -11474.62\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(5,1,5)                    : Inf\n",
      " ARIMA(3,1,4)                    : -11533.75\n",
      " ARIMA(5,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,5)                    : Inf\n",
      " ARIMA(4,1,5) with drift         : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,5) with drift         : -11486.28\n",
      "\n",
      " Best model: ARIMA(2,1,5) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11460.12\n",
      " ARIMA(0,1,0) with drift         : -11392.48\n",
      " ARIMA(1,1,0) with drift         : -11436.18\n",
      " ARIMA(0,1,1) with drift         : -11443.02\n",
      " ARIMA(0,1,0)                    : -11394.47\n",
      " ARIMA(1,1,2) with drift         : -11452\n",
      " ARIMA(2,1,1) with drift         : -11454.69\n",
      " ARIMA(3,1,2) with drift         : -11512.45\n",
      " ARIMA(3,1,1) with drift         : -11453.12\n",
      " ARIMA(4,1,2) with drift         : -11538.32\n",
      " ARIMA(4,1,1) with drift         : -11454.98\n",
      " ARIMA(5,1,2) with drift         : -11480.96\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11519.43\n",
      " ARIMA(5,1,1) with drift         : -11465.65\n",
      " ARIMA(5,1,3) with drift         : -11541.25\n",
      " ARIMA(5,1,4) with drift         : -11546.31\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(5,1,5) with drift         : Inf\n",
      " ARIMA(4,1,5) with drift         : Inf\n",
      " ARIMA(5,1,4)                    : -11548.31\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(5,1,3)                    : -11543.22\n",
      " ARIMA(5,1,5)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(4,1,5)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,1,4)                    : Inf\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(5,1,3)                    : Inf\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : -11520.63\n",
      "\n",
      " Best model: ARIMA(3,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11473.66\n",
      " ARIMA(0,1,0) with drift         : -11405.4\n",
      " ARIMA(1,1,0) with drift         : -11449.03\n",
      " ARIMA(0,1,1) with drift         : -11457.36\n",
      " ARIMA(0,1,0)                    : -11407.4\n",
      " ARIMA(1,1,2) with drift         : -11465.21\n",
      " ARIMA(2,1,1) with drift         : -11468.1\n",
      " ARIMA(3,1,2) with drift         : -11522.67\n",
      " ARIMA(3,1,1) with drift         : -11466.94\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11523.94\n",
      " ARIMA(2,1,3) with drift         : -11530.31\n",
      " ARIMA(1,1,3) with drift         : -11464.92\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11469.99\n",
      " ARIMA(3,1,4) with drift         : -11553.79\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(3,1,5) with drift         : -11506.29\n",
      " ARIMA(2,1,5) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(4,1,5) with drift         : Inf\n",
      " ARIMA(3,1,4)                    : -11555.37\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11525.89\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(3,1,5)                    : -11508.29\n",
      " ARIMA(2,1,3)                    : -11532.31\n",
      " ARIMA(2,1,5)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(4,1,5)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(3,1,5)                    : -11517.89\n",
      "\n",
      " Best model: ARIMA(3,1,5)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11563.65\n",
      " ARIMA(0,0,0) with non-zero mean : -7092.942\n",
      " ARIMA(1,0,0) with non-zero mean : -11532.35\n",
      " ARIMA(0,0,1) with non-zero mean : -9062.662\n",
      " ARIMA(0,0,0) with zero mean     : -7069.286\n",
      " ARIMA(1,0,2) with non-zero mean : -11561.12\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11629.33\n",
      " ARIMA(3,0,1) with non-zero mean : -11567.62\n",
      " ARIMA(4,0,2) with non-zero mean : -11577.15\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11570.59\n",
      " ARIMA(4,0,1) with non-zero mean : -11573.86\n",
      " ARIMA(4,0,3) with non-zero mean : -11639.6\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11626.91\n",
      " ARIMA(5,0,4) with non-zero mean : -11629.53\n",
      " ARIMA(4,0,3) with zero mean     : -11641.48\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11643.49\n",
      " ARIMA(3,0,2) with zero mean     : -11630.38\n",
      " ARIMA(4,0,1) with zero mean     : -11575.2\n",
      " ARIMA(5,0,2) with zero mean     : -11627.71\n",
      " ARIMA(3,0,1) with zero mean     : -11569\n",
      " ARIMA(5,0,1) with zero mean     : -11604.21\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11634.59\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11531.84\n",
      " ARIMA(0,1,0) with drift         : -11462.99\n",
      " ARIMA(1,1,0) with drift         : -11505.42\n",
      " ARIMA(0,1,1) with drift         : -11513.88\n",
      " ARIMA(0,1,0)                    : -11464.99\n",
      " ARIMA(1,1,2) with drift         : -11520.31\n",
      " ARIMA(2,1,1) with drift         : -11524.07\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11514.74\n",
      " ARIMA(1,1,3) with drift         : -11521.21\n",
      " ARIMA(3,1,1) with drift         : -11523.29\n",
      " ARIMA(3,1,3) with drift         : -11595.73\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : -11603.16\n",
      " ARIMA(4,1,1) with drift         : -11525.22\n",
      " ARIMA(5,1,2) with drift         : -11560.26\n",
      " ARIMA(5,1,1) with drift         : -11535.35\n",
      " ARIMA(5,1,3) with drift         : -11560.94\n",
      " ARIMA(4,1,2)                    : -11605.05\n",
      " ARIMA(3,1,2)                    : -11599.29\n",
      " ARIMA(4,1,1)                    : -11527.23\n",
      " ARIMA(5,1,2)                    : -11562.29\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(3,1,1)                    : -11525.3\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(5,1,1)                    : -11537.37\n",
      " ARIMA(5,1,3)                    : -11562.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(5,1,3)                    : Inf\n",
      " ARIMA(5,1,2)                    : -11574.41\n",
      "\n",
      " Best model: ARIMA(5,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11540.3\n",
      " ARIMA(0,1,0) with drift         : -11469.86\n",
      " ARIMA(1,1,0) with drift         : -11512.62\n",
      " ARIMA(0,1,1) with drift         : -11521.01\n",
      " ARIMA(0,1,0)                    : -11471.86\n",
      " ARIMA(1,1,2) with drift         : -11527.97\n",
      " ARIMA(2,1,1) with drift         : -11531.89\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11522.06\n",
      " ARIMA(1,1,3) with drift         : -11529.09\n",
      " ARIMA(3,1,1) with drift         : -11531.68\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11542.31\n",
      " ARIMA(1,1,2)                    : -11529.98\n",
      " ARIMA(2,1,1)                    : -11533.89\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(1,1,1)                    : -11524.06\n",
      " ARIMA(1,1,3)                    : -11531.09\n",
      " ARIMA(3,1,1)                    : -11533.69\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11551.54\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11545.43\n",
      " ARIMA(0,1,0) with drift         : -11476.22\n",
      " ARIMA(1,1,0) with drift         : -11519.24\n",
      " ARIMA(0,1,1) with drift         : -11527.35\n",
      " ARIMA(0,1,0)                    : -11478.22\n",
      " ARIMA(1,1,2) with drift         : -11535.3\n",
      " ARIMA(2,1,1) with drift         : -11538.4\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11606.01\n",
      " ARIMA(1,1,3) with drift         : -11536.07\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11543.1\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11608.02\n",
      " ARIMA(1,1,3)                    : -11538.06\n",
      " ARIMA(2,1,2)                    : -11547.44\n",
      " ARIMA(3,1,3)                    : -11608.56\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(4,1,2)                    : -11548.72\n",
      " ARIMA(4,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(2,1,2)                    : -11557.99\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11626.41\n",
      " ARIMA(0,0,0) with non-zero mean : -7180.606\n",
      " ARIMA(1,0,0) with non-zero mean : -11595.23\n",
      " ARIMA(0,0,1) with non-zero mean : -9148.012\n",
      " ARIMA(0,0,0) with zero mean     : -7147.407\n",
      " ARIMA(1,0,2) with non-zero mean : -11622.24\n",
      " ARIMA(2,0,1) with non-zero mean : -11605.97\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11635.32\n",
      " ARIMA(1,0,3) with non-zero mean : -11637.31\n",
      " ARIMA(0,0,3) with non-zero mean : -10542.52\n",
      " ARIMA(1,0,4) with non-zero mean : -11636.59\n",
      " ARIMA(0,0,2) with non-zero mean : -10038.07\n",
      " ARIMA(0,0,4) with non-zero mean : -10971.87\n",
      " ARIMA(2,0,4) with non-zero mean : -11663.67\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11674.55\n",
      " ARIMA(1,0,5) with non-zero mean : -11642.38\n",
      " ARIMA(3,0,5) with non-zero mean : -11671.84\n",
      " ARIMA(2,0,5) with zero mean     : -11675.29\n",
      " ARIMA(1,0,5) with zero mean     : -11643.28\n",
      " ARIMA(2,0,4) with zero mean     : -11664.18\n",
      " ARIMA(3,0,5) with zero mean     : -11672.8\n",
      " ARIMA(1,0,4) with zero mean     : -11637.4\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,5) with zero mean     : -11676.74\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11637.1\n",
      " ARIMA(0,0,0) with non-zero mean : -7183.094\n",
      " ARIMA(1,0,0) with non-zero mean : -11607.12\n",
      " ARIMA(0,0,1) with non-zero mean : -9156.432\n",
      " ARIMA(0,0,0) with zero mean     : -7151.929\n",
      " ARIMA(1,0,2) with non-zero mean : -11633.92\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11646.52\n",
      " ARIMA(1,0,3) with non-zero mean : -11649.07\n",
      " ARIMA(0,0,3) with non-zero mean : -10551.96\n",
      " ARIMA(1,0,4) with non-zero mean : -11648.28\n",
      " ARIMA(0,0,2) with non-zero mean : -10047.3\n",
      " ARIMA(0,0,4) with non-zero mean : -10983.71\n",
      " ARIMA(2,0,4) with non-zero mean : -11680.57\n",
      " ARIMA(3,0,4) with non-zero mean : -11756.89\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11689.65\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11690\n",
      "\n",
      " Best model: ARIMA(2,0,5) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11726.86\n",
      " ARIMA(0,0,0) with non-zero mean : -7219.871\n",
      " ARIMA(1,0,0) with non-zero mean : -11704.34\n",
      " ARIMA(0,0,1) with non-zero mean : -9202.304\n",
      " ARIMA(0,0,0) with zero mean     : -7181.348\n",
      " ARIMA(1,0,2) with non-zero mean : -11725.28\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11821.89\n",
      " ARIMA(3,0,1) with non-zero mean : -11737.16\n",
      " ARIMA(4,0,2) with non-zero mean : -11746.45\n",
      " ARIMA(3,0,3) with non-zero mean : -11841.21\n",
      " ARIMA(2,0,3) with non-zero mean : -11736.78\n",
      " ARIMA(4,0,3) with non-zero mean : -11883.48\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11882.26\n",
      " ARIMA(3,0,4) with non-zero mean : -11841.53\n",
      " ARIMA(5,0,2) with non-zero mean : -11819.23\n",
      " ARIMA(5,0,4) with non-zero mean : -11834.07\n",
      " ARIMA(4,0,3) with zero mean     : -11883.42\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,1) with non-zero mean : -11727.48\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12048.88\n",
      " ARIMA(0,0,0) with non-zero mean : -7798.523\n",
      " ARIMA(1,0,0) with non-zero mean : -12046.89\n",
      " ARIMA(0,0,1) with non-zero mean : -9695.57\n",
      " ARIMA(0,0,0) with zero mean     : -7706.469\n",
      " ARIMA(1,0,2) with non-zero mean : -12050.93\n",
      " ARIMA(0,0,2) with non-zero mean : -10590.18\n",
      " ARIMA(1,0,1) with non-zero mean : -12052.27\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(2,0,0) with non-zero mean : -12051.33\n",
      " ARIMA(1,0,1) with zero mean     : -12048.87\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -12021.88\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12434.36\n",
      " ARIMA(0,0,0) with non-zero mean : -7980.504\n",
      " ARIMA(1,0,0) with non-zero mean : -12372.67\n",
      " ARIMA(0,0,1) with non-zero mean : -9941.412\n",
      " ARIMA(0,0,0) with zero mean     : -7857.589\n",
      " ARIMA(1,0,2) with non-zero mean : -12376.41\n",
      " ARIMA(2,0,1) with non-zero mean : -12436.06\n",
      " ARIMA(1,0,1) with non-zero mean : -12377.95\n",
      " ARIMA(2,0,0) with non-zero mean : -12437.96\n",
      " ARIMA(3,0,0) with non-zero mean : -12435.15\n",
      " ARIMA(3,0,1) with non-zero mean : -12454.73\n",
      " ARIMA(4,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -12464.93\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12537.98\n",
      " ARIMA(2,0,3) with non-zero mean : -12436.37\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -12558.88\n",
      " ARIMA(2,0,4) with non-zero mean : -12437.89\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : -12482.54\n",
      " ARIMA(2,0,5) with non-zero mean : -12443.38\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -12558.06\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : -12501.26\n",
      "\n",
      " Best model: ARIMA(3,0,5) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12731.55\n",
      " ARIMA(0,0,0) with non-zero mean : -8064.913\n",
      " ARIMA(1,0,0) with non-zero mean : -12677.97\n",
      " ARIMA(0,0,1) with non-zero mean : -10058.9\n",
      " ARIMA(0,0,0) with zero mean     : -7927.111\n",
      " ARIMA(1,0,2) with non-zero mean : -12680.87\n",
      " ARIMA(2,0,1) with non-zero mean : -12729.28\n",
      " ARIMA(3,0,2) with non-zero mean : -12759.62\n",
      " ARIMA(3,0,1) with non-zero mean : -12730.55\n",
      " ARIMA(4,0,2) with non-zero mean : -12811.44\n",
      " ARIMA(4,0,1) with non-zero mean : -12738.03\n",
      " ARIMA(5,0,2) with non-zero mean : -12780.21\n",
      " ARIMA(4,0,3) with non-zero mean : -12809.91\n",
      " ARIMA(3,0,3) with non-zero mean : -12761.06\n",
      " ARIMA(5,0,1) with non-zero mean : -12747.6\n",
      " ARIMA(5,0,3) with non-zero mean : -12832.04\n",
      " ARIMA(5,0,4) with non-zero mean : -12815.29\n",
      " ARIMA(4,0,4) with non-zero mean : -12808.46\n",
      " ARIMA(5,0,3) with zero mean     : -12788.39\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -12735.86\n",
      "\n",
      " Best model: ARIMA(5,0,3) with zero mean     \n",
      "\n",
      "[1] \"90 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12838.17\n",
      " ARIMA(0,0,0) with non-zero mean : -8091.392\n",
      " ARIMA(1,0,0) with non-zero mean : -12837.14\n",
      " ARIMA(0,0,1) with non-zero mean : -10097.45\n",
      " ARIMA(0,0,0) with zero mean     : -7938.12\n",
      " ARIMA(1,0,2) with non-zero mean : -12838.32\n",
      " ARIMA(0,0,2) with non-zero mean : -11279.5\n",
      " ARIMA(1,0,1) with non-zero mean : -12837.52\n",
      " ARIMA(1,0,3) with non-zero mean : -12836.31\n",
      " ARIMA(0,0,3) with non-zero mean : -11685.67\n",
      " ARIMA(2,0,1) with non-zero mean : -12838.94\n",
      " ARIMA(2,0,0) with non-zero mean : -12838.65\n",
      " ARIMA(3,0,1) with non-zero mean : -12842.45\n",
      " ARIMA(3,0,0) with non-zero mean : -12841.35\n",
      " ARIMA(4,0,1) with non-zero mean : -12840.34\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,0) with non-zero mean : -12838.9\n",
      " ARIMA(4,0,2) with non-zero mean : -12861.04\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -12898.44\n",
      " ARIMA(3,0,3) with non-zero mean : -12879.27\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -12896.67\n",
      " ARIMA(3,0,4) with non-zero mean : -12878.13\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -12852.41\n",
      "\n",
      " Best model: ARIMA(4,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12927.14\n",
      " ARIMA(0,0,0) with non-zero mean : -8198.192\n",
      " ARIMA(1,0,0) with non-zero mean : -12908.82\n",
      " ARIMA(0,0,1) with non-zero mean : -10141.79\n",
      " ARIMA(0,0,0) with zero mean     : -8024.557\n",
      " ARIMA(1,0,2) with non-zero mean : -12911.9\n",
      " ARIMA(2,0,1) with non-zero mean : -12929.13\n",
      " ARIMA(1,0,1) with non-zero mean : -12908.74\n",
      " ARIMA(2,0,0) with non-zero mean : -12908.7\n",
      " ARIMA(3,0,1) with non-zero mean : -12938.63\n",
      " ARIMA(3,0,0) with non-zero mean : -12936.86\n",
      " ARIMA(4,0,1) with non-zero mean : -12933.76\n",
      " ARIMA(3,0,2) with non-zero mean : -12952.1\n",
      " ARIMA(4,0,2) with non-zero mean : -12950.34\n",
      " ARIMA(3,0,3) with non-zero mean : -12953.03\n",
      " ARIMA(2,0,3) with non-zero mean : -12926.06\n",
      " ARIMA(4,0,3) with non-zero mean : -13011.78\n",
      " ARIMA(5,0,3) with non-zero mean : -12957.38\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -12955.51\n",
      " ARIMA(5,0,2) with non-zero mean : -12958.24\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -12944\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -12921.65\n",
      "\n",
      " Best model: ARIMA(3,0,4) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13034.35\n",
      " ARIMA(0,0,0) with non-zero mean : -8419.008\n",
      " ARIMA(1,0,0) with non-zero mean : -13034.07\n",
      " ARIMA(0,0,1) with non-zero mean : -10368.77\n",
      " ARIMA(0,0,0) with zero mean     : -8212.474\n",
      " ARIMA(1,0,2) with non-zero mean : -13036.71\n",
      " ARIMA(0,0,2) with non-zero mean : -11525.41\n",
      " ARIMA(1,0,1) with non-zero mean : -13033.75\n",
      " ARIMA(1,0,3) with non-zero mean : -13035.61\n",
      " ARIMA(0,0,3) with non-zero mean : -11936.39\n",
      " ARIMA(2,0,1) with non-zero mean : -13032.6\n",
      " ARIMA(2,0,3) with non-zero mean : -13034.24\n",
      " ARIMA(1,0,2) with zero mean     : -13032.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,2) with non-zero mean : -13022.48\n",
      "\n",
      " Best model: ARIMA(1,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13141.92\n",
      " ARIMA(0,0,0) with non-zero mean : -8600.267\n",
      " ARIMA(1,0,0) with non-zero mean : -13132.96\n",
      " ARIMA(0,0,1) with non-zero mean : -10567.03\n",
      " ARIMA(0,0,0) with zero mean     : -8417.529\n",
      " ARIMA(1,0,2) with non-zero mean : -13135.69\n",
      " ARIMA(2,0,1) with non-zero mean : -13143.46\n",
      " ARIMA(1,0,1) with non-zero mean : -13131.3\n",
      " ARIMA(2,0,0) with non-zero mean : -13130.87\n",
      " ARIMA(3,0,1) with non-zero mean : -13141.06\n",
      " ARIMA(3,0,0) with non-zero mean : -13135.48\n",
      " ARIMA(3,0,2) with non-zero mean : -13139.83\n",
      " ARIMA(2,0,1) with zero mean     : -13139.77\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with non-zero mean : -13135.84\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13193.12\n",
      " ARIMA(0,0,0) with non-zero mean : -8651.976\n",
      " ARIMA(1,0,0) with non-zero mean : -13170.43\n",
      " ARIMA(0,0,1) with non-zero mean : -10600.05\n",
      " ARIMA(0,0,0) with zero mean     : -8478.609\n",
      " ARIMA(1,0,2) with non-zero mean : -13174.57\n",
      " ARIMA(2,0,1) with non-zero mean : -13191\n",
      " ARIMA(3,0,2) with non-zero mean : -13202.7\n",
      " ARIMA(3,0,1) with non-zero mean : -13192.86\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -13200.6\n",
      " ARIMA(2,0,3) with non-zero mean : -13191.28\n",
      " ARIMA(4,0,1) with non-zero mean : -13191.15\n",
      " ARIMA(4,0,3) with non-zero mean : -13218.39\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -13200.58\n",
      " ARIMA(5,0,2) with non-zero mean : -13252.64\n",
      " ARIMA(5,0,1) with non-zero mean : -13189.33\n",
      " ARIMA(5,0,2) with zero mean     : -13248.74\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -13185.97\n",
      "\n",
      " Best model: ARIMA(3,0,4) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13224.59\n",
      " ARIMA(0,0,0) with non-zero mean : -8659.661\n",
      " ARIMA(1,0,0) with non-zero mean : -13222\n",
      " ARIMA(0,0,1) with non-zero mean : -10646.41\n",
      " ARIMA(0,0,0) with zero mean     : -8488.456\n",
      " ARIMA(1,0,2) with non-zero mean : -13223.63\n",
      " ARIMA(2,0,1) with non-zero mean : -13221.42\n",
      " ARIMA(3,0,2) with non-zero mean : -13234.74\n",
      " ARIMA(3,0,1) with non-zero mean : -13224.58\n",
      " ARIMA(4,0,2) with non-zero mean : -13224.71\n",
      " ARIMA(3,0,3) with non-zero mean : -13233.34\n",
      " ARIMA(2,0,3) with non-zero mean : -13222.66\n",
      " ARIMA(4,0,1) with non-zero mean : -13223.65\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -13227.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : -13241.51\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13264.36\n",
      " ARIMA(0,0,0) with non-zero mean : -8704.311\n",
      " ARIMA(1,0,0) with non-zero mean : -13253.56\n",
      " ARIMA(0,0,1) with non-zero mean : -10687.09\n",
      " ARIMA(0,0,0) with zero mean     : -8526.564\n",
      " ARIMA(1,0,2) with non-zero mean : -13254.11\n",
      " ARIMA(2,0,1) with non-zero mean : -13262.34\n",
      " ARIMA(3,0,2) with non-zero mean : -13271.99\n",
      " ARIMA(3,0,1) with non-zero mean : -13272.92\n",
      " ARIMA(3,0,0) with non-zero mean : -13267.33\n",
      " ARIMA(4,0,1) with non-zero mean : -13266.58\n",
      " ARIMA(2,0,0) with non-zero mean : -13264.86\n",
      " ARIMA(4,0,0) with non-zero mean : -13267.59\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,1) with zero mean     : -13268.9\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -13257.04\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13286.09\n",
      " ARIMA(0,0,0) with non-zero mean : -8799.759\n",
      " ARIMA(1,0,0) with non-zero mean : -13281.32\n",
      " ARIMA(0,0,1) with non-zero mean : -10765\n",
      " ARIMA(0,0,0) with zero mean     : -8632.875\n",
      " ARIMA(1,0,2) with non-zero mean : -13281.08\n",
      " ARIMA(2,0,1) with non-zero mean : -13284.31\n",
      " ARIMA(3,0,2) with non-zero mean : -13294.12\n",
      " ARIMA(3,0,1) with non-zero mean : -13296\n",
      " ARIMA(3,0,0) with non-zero mean : -13287.48\n",
      " ARIMA(4,0,1) with non-zero mean : -13292.11\n",
      " ARIMA(2,0,0) with non-zero mean : -13286.29\n",
      " ARIMA(4,0,0) with non-zero mean : -13285.57\n",
      " ARIMA(4,0,2) with non-zero mean : -13307.77\n",
      " ARIMA(5,0,2) with non-zero mean : -13333.7\n",
      " ARIMA(5,0,1) with non-zero mean : -13288.79\n",
      " ARIMA(5,0,3) with non-zero mean : -13381.08\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -13370.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -13298.7\n",
      "\n",
      " Best model: ARIMA(4,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13315.22\n",
      " ARIMA(0,0,0) with non-zero mean : -8818.601\n",
      " ARIMA(1,0,0) with non-zero mean : -13308.47\n",
      " ARIMA(0,0,1) with non-zero mean : -10784.96\n",
      " ARIMA(0,0,0) with zero mean     : -8656.278\n",
      " ARIMA(1,0,2) with non-zero mean : -13308.69\n",
      " ARIMA(2,0,1) with non-zero mean : -13316.57\n",
      " ARIMA(1,0,1) with non-zero mean : -13306.78\n",
      " ARIMA(2,0,0) with non-zero mean : -13305.83\n",
      " ARIMA(3,0,1) with non-zero mean : -13313.95\n",
      " ARIMA(3,0,0) with non-zero mean : -13307.08\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -13312.98\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with non-zero mean : -13315.59\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13294.52\n",
      " ARIMA(0,0,0) with non-zero mean : -8751.451\n",
      " ARIMA(1,0,0) with non-zero mean : -13289.34\n",
      " ARIMA(0,0,1) with non-zero mean : -10730.44\n",
      " ARIMA(0,0,0) with zero mean     : -8614.585\n",
      " ARIMA(1,0,2) with non-zero mean : -13289.61\n",
      " ARIMA(2,0,1) with non-zero mean : -13295.78\n",
      " ARIMA(1,0,1) with non-zero mean : -13287.61\n",
      " ARIMA(2,0,0) with non-zero mean : -13286.67\n",
      " ARIMA(3,0,1) with non-zero mean : -13288.61\n",
      " ARIMA(3,0,0) with non-zero mean : -13288.71\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -13293.98\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with non-zero mean : -13296.56\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13281.55\n",
      " ARIMA(0,0,0) with non-zero mean : -8730.333\n",
      " ARIMA(1,0,0) with non-zero mean : -13273.79\n",
      " ARIMA(0,0,1) with non-zero mean : -10715.07\n",
      " ARIMA(0,0,0) with zero mean     : -8603.515\n",
      " ARIMA(1,0,2) with non-zero mean : -13273.78\n",
      " ARIMA(2,0,1) with non-zero mean : -13279.31\n",
      " ARIMA(3,0,2) with non-zero mean : -13289.56\n",
      " ARIMA(3,0,1) with non-zero mean : -13288.08\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -13288.21\n",
      " ARIMA(2,0,3) with non-zero mean : -13279.63\n",
      " ARIMA(4,0,1) with non-zero mean : -13289.48\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -13287.32\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : -13277.09\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13244.45\n",
      " ARIMA(0,0,0) with non-zero mean : -8638.893\n",
      " ARIMA(1,0,0) with non-zero mean : -13241.32\n",
      " ARIMA(0,0,1) with non-zero mean : -10627.38\n",
      " ARIMA(0,0,0) with zero mean     : -8538.471\n",
      " ARIMA(1,0,2) with non-zero mean : -13241.96\n",
      " ARIMA(2,0,1) with non-zero mean : -13242.56\n",
      " ARIMA(3,0,2) with non-zero mean : -13242.28\n",
      " ARIMA(2,0,3) with non-zero mean : -13242.54\n",
      " ARIMA(1,0,1) with non-zero mean : -13239.47\n",
      " ARIMA(1,0,3) with non-zero mean : -13239.97\n",
      " ARIMA(3,0,1) with non-zero mean : -13242.75\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -13243.81\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13247.7\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13202.85\n",
      " ARIMA(0,0,0) with non-zero mean : -8591.905\n",
      " ARIMA(1,0,0) with non-zero mean : -13201\n",
      " ARIMA(0,0,1) with non-zero mean : -10586.47\n",
      " ARIMA(0,0,0) with zero mean     : -8489.949\n",
      " ARIMA(1,0,2) with non-zero mean : -13201.67\n",
      " ARIMA(2,0,1) with non-zero mean : -13200.09\n",
      " ARIMA(3,0,2) with non-zero mean : -13249.76\n",
      " ARIMA(3,0,1) with non-zero mean : -13215.09\n",
      " ARIMA(4,0,2) with non-zero mean : -13220.25\n",
      " ARIMA(3,0,3) with non-zero mean : -13213.48\n",
      " ARIMA(2,0,3) with non-zero mean : -13200.89\n",
      " ARIMA(4,0,1) with non-zero mean : -13210.99\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -13248.67\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -13219.49\n",
      "\n",
      " Best model: ARIMA(4,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13217.65\n",
      " ARIMA(0,0,0) with non-zero mean : -8600.973\n",
      " ARIMA(1,0,0) with non-zero mean : -13216.62\n",
      " ARIMA(0,0,1) with non-zero mean : -10599.03\n",
      " ARIMA(0,0,0) with zero mean     : -8478.971\n",
      " ARIMA(1,0,2) with non-zero mean : -13217.71\n",
      " ARIMA(0,0,2) with non-zero mean : -11739.39\n",
      " ARIMA(1,0,1) with non-zero mean : -13214.72\n",
      " ARIMA(1,0,3) with non-zero mean : -13215.7\n",
      " ARIMA(0,0,3) with non-zero mean : -12182.37\n",
      " ARIMA(2,0,1) with non-zero mean : -13218.8\n",
      " ARIMA(2,0,0) with non-zero mean : -13214.1\n",
      " ARIMA(3,0,1) with non-zero mean : -13230.16\n",
      " ARIMA(3,0,0) with non-zero mean : -13218.76\n",
      " ARIMA(4,0,1) with non-zero mean : -13222.52\n",
      " ARIMA(3,0,2) with non-zero mean : -13230.85\n",
      " ARIMA(4,0,2) with non-zero mean : -13234.85\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -13233.84\n",
      " ARIMA(3,0,3) with non-zero mean : -13229.16\n",
      " ARIMA(5,0,1) with non-zero mean : -13223.37\n",
      " ARIMA(5,0,3) with non-zero mean : -13293.72\n",
      " ARIMA(5,0,4) with non-zero mean : -13262.21\n",
      " ARIMA(4,0,4) with non-zero mean : -13229.1\n",
      " ARIMA(5,0,3) with zero mean     : -13290.35\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -13234.4\n",
      "\n",
      " Best model: ARIMA(4,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13229.23\n",
      " ARIMA(0,0,0) with non-zero mean : -8638.204\n",
      " ARIMA(1,0,0) with non-zero mean : -13222.89\n",
      " ARIMA(0,0,1) with non-zero mean : -10628.86\n",
      " ARIMA(0,0,0) with zero mean     : -8523.826\n",
      " ARIMA(1,0,2) with non-zero mean : -13223.89\n",
      " ARIMA(2,0,1) with non-zero mean : -13230.19\n",
      " ARIMA(1,0,1) with non-zero mean : -13220.98\n",
      " ARIMA(2,0,0) with non-zero mean : -13220.28\n",
      " ARIMA(3,0,1) with non-zero mean : -13227.34\n",
      " ARIMA(3,0,0) with non-zero mean : -13222.97\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -13228.25\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with non-zero mean : -13228.97\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13225.78\n",
      " ARIMA(0,0,0) with non-zero mean : -8640.479\n",
      " ARIMA(1,0,0) with non-zero mean : -13222.35\n",
      " ARIMA(0,0,1) with non-zero mean : -10630.57\n",
      " ARIMA(0,0,0) with zero mean     : -8526.609\n",
      " ARIMA(1,0,2) with non-zero mean : -13223.83\n",
      " ARIMA(2,0,1) with non-zero mean : -13223.03\n",
      " ARIMA(3,0,2) with non-zero mean : -13251.14\n",
      " ARIMA(3,0,1) with non-zero mean : -13231.06\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -13249.33\n",
      " ARIMA(2,0,3) with non-zero mean : -13237.37\n",
      " ARIMA(4,0,1) with non-zero mean : -13228.66\n",
      " ARIMA(4,0,3) with non-zero mean : -13312.69\n",
      " ARIMA(5,0,3) with non-zero mean : -13240.06\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -13225.83\n",
      " ARIMA(5,0,2) with non-zero mean : -13241.89\n",
      " ARIMA(5,0,4) with non-zero mean : -13272.13\n",
      " ARIMA(4,0,3) with zero mean     : -13226.4\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -13240.64\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13273.5\n",
      " ARIMA(0,0,0) with non-zero mean : -8726.392\n",
      " ARIMA(1,0,0) with non-zero mean : -13268.27\n",
      " ARIMA(0,0,1) with non-zero mean : -10693.44\n",
      " ARIMA(0,0,0) with zero mean     : -8598.523\n",
      " ARIMA(1,0,2) with non-zero mean : -13269.54\n",
      " ARIMA(2,0,1) with non-zero mean : -13270.56\n",
      " ARIMA(3,0,2) with non-zero mean : -13290.67\n",
      " ARIMA(3,0,1) with non-zero mean : -13275.6\n",
      " ARIMA(4,0,2) with non-zero mean : -13337.17\n",
      " ARIMA(4,0,1) with non-zero mean : -13273.2\n",
      " ARIMA(5,0,2) with non-zero mean : -13320.19\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -13322.75\n",
      " ARIMA(5,0,1) with non-zero mean : -13288.19\n",
      " ARIMA(5,0,3) with non-zero mean : -13339.1\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -13330.91\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,1) with non-zero mean : -13260.9\n",
      "\n",
      " Best model: ARIMA(5,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13330.8\n",
      " ARIMA(0,0,0) with non-zero mean : -8763.678\n",
      " ARIMA(1,0,0) with non-zero mean : -13327.64\n",
      " ARIMA(0,0,1) with non-zero mean : -10748.55\n",
      " ARIMA(0,0,0) with zero mean     : -8614.882\n",
      " ARIMA(1,0,2) with non-zero mean : -13328.81\n",
      " ARIMA(2,0,1) with non-zero mean : -13325.66\n",
      " ARIMA(3,0,2) with non-zero mean : -13359.55\n",
      " ARIMA(3,0,1) with non-zero mean : -13338.61\n",
      " ARIMA(4,0,2) with non-zero mean : -13350.39\n",
      " ARIMA(3,0,3) with non-zero mean : -13339.44\n",
      " ARIMA(2,0,3) with non-zero mean : -13328.85\n",
      " ARIMA(4,0,1) with non-zero mean : -13346.18\n",
      " ARIMA(4,0,3) with non-zero mean : -13351.1\n",
      " ARIMA(3,0,2) with zero mean     : -13351.9\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -13344.81\n",
      "\n",
      " Best model: ARIMA(4,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13380.83\n",
      " ARIMA(0,0,0) with non-zero mean : -8778.684\n",
      " ARIMA(1,0,0) with non-zero mean : -13373.4\n",
      " ARIMA(0,0,1) with non-zero mean : -10763.15\n",
      " ARIMA(0,0,0) with zero mean     : -8621.15\n",
      " ARIMA(1,0,2) with non-zero mean : -13374.03\n",
      " ARIMA(2,0,1) with non-zero mean : -13379.57\n",
      " ARIMA(3,0,2) with non-zero mean : -13384\n",
      " ARIMA(3,0,1) with non-zero mean : -13385.76\n",
      " ARIMA(3,0,0) with non-zero mean : -13372.9\n",
      " ARIMA(4,0,1) with non-zero mean : -13374.4\n",
      " ARIMA(2,0,0) with non-zero mean : -13370.69\n",
      " ARIMA(4,0,0) with non-zero mean : -13374.31\n",
      " ARIMA(4,0,2) with non-zero mean : -13396.01\n",
      " ARIMA(5,0,2) with non-zero mean : -13400.34\n",
      " ARIMA(5,0,1) with non-zero mean : -13377.97\n",
      " ARIMA(5,0,3) with non-zero mean : -13399.47\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with zero mean     : -13397.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,2) with non-zero mean : -13433.95\n",
      "\n",
      " Best model: ARIMA(5,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13389.44\n",
      " ARIMA(0,0,0) with non-zero mean : -8785.203\n",
      " ARIMA(1,0,0) with non-zero mean : -13383.45\n",
      " ARIMA(0,0,1) with non-zero mean : -10766.55\n",
      " ARIMA(0,0,0) with zero mean     : -8638.774\n",
      " ARIMA(1,0,2) with non-zero mean : -13384.41\n",
      " ARIMA(2,0,1) with non-zero mean : -13386.49\n",
      " ARIMA(3,0,2) with non-zero mean : -13397.52\n",
      " ARIMA(3,0,1) with non-zero mean : -13398.73\n",
      " ARIMA(3,0,0) with non-zero mean : -13387.59\n",
      " ARIMA(4,0,1) with non-zero mean : -13394.72\n",
      " ARIMA(2,0,0) with non-zero mean : -13385.51\n",
      " ARIMA(4,0,0) with non-zero mean : -13385.26\n",
      " ARIMA(4,0,2) with non-zero mean : -13394.06\n",
      " ARIMA(3,0,1) with zero mean     : -13394.67\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -13389.26\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -8817.258\n",
      " ARIMA(1,0,0) with non-zero mean : -13394.02\n",
      " ARIMA(0,0,1) with non-zero mean : -10796.54\n",
      " ARIMA(0,0,0) with zero mean     : -8668.423\n",
      " ARIMA(2,0,0) with non-zero mean : -13393.41\n",
      " ARIMA(1,0,1) with non-zero mean : -13392.02\n",
      " ARIMA(2,0,1) with non-zero mean : -13394.62\n",
      " ARIMA(3,0,1) with non-zero mean : -13399.28\n",
      " ARIMA(3,0,0) with non-zero mean : -13396.73\n",
      " ARIMA(4,0,1) with non-zero mean : -13397.52\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,0) with non-zero mean : -13394.6\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,1) with zero mean     : -13396.56\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -13399.41\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13412.76\n",
      " ARIMA(0,0,0) with non-zero mean : -8835.11\n",
      " ARIMA(1,0,0) with non-zero mean : -13400.98\n",
      " ARIMA(0,0,1) with non-zero mean : -10816.87\n",
      " ARIMA(0,0,0) with zero mean     : -8697.246\n",
      " ARIMA(1,0,2) with non-zero mean : -13402.43\n",
      " ARIMA(2,0,1) with non-zero mean : -13412.29\n",
      " ARIMA(3,0,2) with non-zero mean : -13425.78\n",
      " ARIMA(3,0,1) with non-zero mean : -13408.73\n",
      " ARIMA(4,0,2) with non-zero mean : -13405.3\n",
      " ARIMA(3,0,3) with non-zero mean : -13423.77\n",
      " ARIMA(2,0,3) with non-zero mean : -13411.32\n",
      " ARIMA(4,0,1) with non-zero mean : -13407.09\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -13401.33\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : -13426.43\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m03.1 <- my.tsCV.2(train, cv.forecast.2, h=hori, window=wind, step=peri, \n",
    "                          silent=T,\n",
    "                          sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4247b4e2-a191-4310-9df8-ee11224a71a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-01-24\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m03.1\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3603b7c1-1626-4d08-a2f0-35ea2db6d2db",
   "metadata": {},
   "source": [
    "## Regression with ARIMA errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad1a4e08-fca6-4a5b-b997-cf9d1e3cbe00",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14728.24\n",
      " Regression with ARIMA(0,1,0) errors : -14705.76\n",
      " Regression with ARIMA(1,1,0) errors : -14703.21\n",
      " Regression with ARIMA(0,1,1) errors : -14703.85\n",
      " Regression with ARIMA(0,1,0) errors : -14707.74\n",
      " Regression with ARIMA(1,1,2) errors : -14755.07\n",
      " Regression with ARIMA(0,1,2) errors : -14703.58\n",
      " Regression with ARIMA(1,1,1) errors : -14701.2\n",
      " Regression with ARIMA(1,1,3) errors : -14756.2\n",
      " Regression with ARIMA(0,1,3) errors : -14715.69\n",
      " Regression with ARIMA(2,1,3) errors : -14743.68\n",
      " Regression with ARIMA(1,1,4) errors : -14754.84\n",
      " Regression with ARIMA(0,1,4) errors : -14713.96\n",
      " Regression with ARIMA(2,1,4) errors : -14742.53\n",
      " Regression with ARIMA(1,1,3) errors : -14757.92\n",
      " Regression with ARIMA(0,1,3) errors : -14717.66\n",
      " Regression with ARIMA(1,1,2) errors : -14756.77\n",
      " Regression with ARIMA(2,1,3) errors : -14745.4\n",
      " Regression with ARIMA(1,1,4) errors : -14756.51\n",
      " Regression with ARIMA(0,1,2) errors : -14705.55\n",
      " Regression with ARIMA(0,1,4) errors : -14715.93\n",
      " Regression with ARIMA(2,1,2) errors : -14729.97\n",
      " Regression with ARIMA(2,1,4) errors : -14744.25\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14726.99\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14688.58\n",
      " Regression with ARIMA(1,1,0) errors : -14687.3\n",
      " Regression with ARIMA(0,1,1) errors : -14686.7\n",
      " Regression with ARIMA(0,1,0) errors : -14690.58\n",
      " Regression with ARIMA(1,1,1) errors : -14685.35\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14699.9\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14648.88\n",
      " Regression with ARIMA(1,1,0) errors : -14646.36\n",
      " Regression with ARIMA(0,1,1) errors : -14647.06\n",
      " Regression with ARIMA(0,1,0) errors : -14650.88\n",
      " Regression with ARIMA(1,1,1) errors : -14644.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14660.19\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14557.56\n",
      " Regression with ARIMA(1,1,0) errors : -14555.41\n",
      " Regression with ARIMA(0,1,1) errors : -14555.93\n",
      " Regression with ARIMA(0,1,0) errors : -14559.56\n",
      " Regression with ARIMA(1,1,1) errors : -14553.98\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14568.83\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14466.15\n",
      " Regression with ARIMA(1,1,0) errors : -14464.59\n",
      " Regression with ARIMA(0,1,1) errors : -14465.14\n",
      " Regression with ARIMA(0,1,0) errors : -14468.15\n",
      " Regression with ARIMA(1,1,1) errors : -14463.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14477.38\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14431.62\n",
      " Regression with ARIMA(1,1,0) errors : -14429.42\n",
      " Regression with ARIMA(0,1,1) errors : -14430.5\n",
      " Regression with ARIMA(0,1,0) errors : -14433.63\n",
      " Regression with ARIMA(1,1,1) errors : -14428.06\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14442.84\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14487.01\n",
      " Regression with ARIMA(0,1,0) errors : -14420.66\n",
      " Regression with ARIMA(1,1,0) errors : -14418.52\n",
      " Regression with ARIMA(0,1,1) errors : -14419.3\n",
      " Regression with ARIMA(0,1,0) errors : -14422.67\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14487.4\n",
      " Regression with ARIMA(1,1,1) errors : -14416.73\n",
      " Regression with ARIMA(2,1,0) errors : -14420.92\n",
      " Regression with ARIMA(3,1,1) errors : -14426\n",
      " Regression with ARIMA(3,1,0) errors : -14427.6\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14489.16\n",
      " Regression with ARIMA(1,1,1) errors : -14418.75\n",
      " Regression with ARIMA(2,1,0) errors : -14422.93\n",
      " Regression with ARIMA(3,1,1) errors : -14427.99\n",
      " Regression with ARIMA(2,1,2) errors : -14488.71\n",
      " Regression with ARIMA(1,1,0) errors : -14420.53\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -14429.61\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -14440.44\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14445.76\n",
      " Regression with ARIMA(0,1,0) errors : -14415.25\n",
      " Regression with ARIMA(1,1,0) errors : -14413.72\n",
      " Regression with ARIMA(0,1,1) errors : -14413.85\n",
      " Regression with ARIMA(0,1,0) errors : -14417.26\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14433.81\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14468.58\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14468.82\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14469.94\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14471.73\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14470.6\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14426.46\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14421.25\n",
      " Regression with ARIMA(1,1,0) errors : -14418.78\n",
      " Regression with ARIMA(0,1,1) errors : -14419.77\n",
      " Regression with ARIMA(0,1,0) errors : -14423.26\n",
      " Regression with ARIMA(1,1,1) errors : -14417.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14432.47\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14414.4\n",
      " Regression with ARIMA(1,1,0) errors : -14411.72\n",
      " Regression with ARIMA(0,1,1) errors : -14412.71\n",
      " Regression with ARIMA(0,1,0) errors : -14416.41\n",
      " Regression with ARIMA(1,1,1) errors : -14410.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14425.61\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14371.6\n",
      " Regression with ARIMA(1,1,0) errors : -14369.53\n",
      " Regression with ARIMA(0,1,1) errors : -14370.05\n",
      " Regression with ARIMA(0,1,0) errors : -14373.59\n",
      " Regression with ARIMA(1,1,1) errors : -14368.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14382.78\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14319.68\n",
      " Regression with ARIMA(0,1,0) errors : -14316.26\n",
      " Regression with ARIMA(1,1,0) errors : -14313.77\n",
      " Regression with ARIMA(0,1,1) errors : -14314.65\n",
      " Regression with ARIMA(0,1,0) errors : -14318.23\n",
      " Regression with ARIMA(1,1,2) errors : -14385.93\n",
      " Regression with ARIMA(0,1,2) errors : -14319.04\n",
      " Regression with ARIMA(1,1,1) errors : -14312.24\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14327.45\n",
      " Regression with ARIMA(2,1,1) errors : -14356.37\n",
      " Regression with ARIMA(2,1,3) errors : -14367.96\n",
      " Regression with ARIMA(1,1,2) errors : -14387.45\n",
      " Regression with ARIMA(0,1,2) errors : -14321.01\n",
      " Regression with ARIMA(1,1,1) errors : -14314.22\n",
      " Regression with ARIMA(2,1,2) errors : -14321.64\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(0,1,1) errors : -14316.62\n",
      " Regression with ARIMA(0,1,3) errors : -14329.42\n",
      " Regression with ARIMA(2,1,1) errors : -14358.04\n",
      " Regression with ARIMA(2,1,3) errors : -14369.57\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14338.56\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14254.7\n",
      " Regression with ARIMA(1,1,0) errors : -14252.25\n",
      " Regression with ARIMA(0,1,1) errors : -14252.87\n",
      " Regression with ARIMA(0,1,0) errors : -14256.7\n",
      " Regression with ARIMA(1,1,1) errors : -14250.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14265.84\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14249.15\n",
      " Regression with ARIMA(1,1,0) errors : -14246.58\n",
      " Regression with ARIMA(0,1,1) errors : -14247.46\n",
      " Regression with ARIMA(0,1,0) errors : -14251.14\n",
      " Regression with ARIMA(1,1,1) errors : -14245.11\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14260.28\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14341.48\n",
      " Regression with ARIMA(0,0,0) errors : -10840.14\n",
      " Regression with ARIMA(1,0,0) errors : -14339.73\n",
      " Regression with ARIMA(0,0,1) errors : -12569.99\n",
      " Regression with ARIMA(0,0,0) errors : -9528.814\n",
      " Regression with ARIMA(1,0,2) errors : -14343.89\n",
      " Regression with ARIMA(0,0,2) errors : -13424.35\n",
      " Regression with ARIMA(1,0,1) errors : -14345.89\n",
      " Regression with ARIMA(2,0,1) errors : -14342.88\n",
      " Regression with ARIMA(2,0,0) errors : -14344.83\n",
      " Regression with ARIMA(1,0,1) errors : -14199.07\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14344.44\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14131.23\n",
      " Regression with ARIMA(1,1,0) errors : -14129.6\n",
      " Regression with ARIMA(0,1,1) errors : -14129.22\n",
      " Regression with ARIMA(0,1,0) errors : -14133.21\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14142.29\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14104.7\n",
      " Regression with ARIMA(1,1,0) errors : -14102.15\n",
      " Regression with ARIMA(0,1,1) errors : -14102.72\n",
      " Regression with ARIMA(0,1,0) errors : -14106.71\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14115.78\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14094.76\n",
      " Regression with ARIMA(1,1,0) errors : -14092.35\n",
      " Regression with ARIMA(0,1,1) errors : -14092.76\n",
      " Regression with ARIMA(0,1,0) errors : -14096.76\n",
      " Regression with ARIMA(1,1,1) errors : -14091.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14105.82\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14158.82\n",
      " Regression with ARIMA(0,1,0) errors : -14086.53\n",
      " Regression with ARIMA(1,1,0) errors : -14083.63\n",
      " Regression with ARIMA(0,1,1) errors : -14084.57\n",
      " Regression with ARIMA(0,1,0) errors : -14088.54\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14155.6\n",
      " Regression with ARIMA(3,1,2) errors : -14153.06\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : -14177.73\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14178.44\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14179.86\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14181.4\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14179.99\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14166.32\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14097.6\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14074.57\n",
      " Regression with ARIMA(1,1,0) errors : -14071.57\n",
      " Regression with ARIMA(0,1,1) errors : -14072.57\n",
      " Regression with ARIMA(0,1,0) errors : -14076.57\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14085.63\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14156.68\n",
      " Regression with ARIMA(0,0,0) errors : -10543.02\n",
      " Regression with ARIMA(1,0,0) errors : -14157.58\n",
      " Regression with ARIMA(0,0,1) errors : -12288.52\n",
      " Regression with ARIMA(0,0,0) errors : -9161.948\n",
      " Regression with ARIMA(2,0,0) errors : -14160.85\n",
      " Regression with ARIMA(3,0,0) errors : -14159.41\n",
      " Regression with ARIMA(2,0,1) errors : -14158.76\n",
      " Regression with ARIMA(1,0,1) errors : -14161.58\n",
      " Regression with ARIMA(1,0,2) errors : -14159.57\n",
      " Regression with ARIMA(0,0,2) errors : -13166.06\n",
      " Regression with ARIMA(1,0,1) errors : -14036.84\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14160.49\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14097.59\n",
      " Regression with ARIMA(0,0,0) errors : -10474.05\n",
      " Regression with ARIMA(1,0,0) errors : -14096.1\n",
      " Regression with ARIMA(0,0,1) errors : -12234.47\n",
      " Regression with ARIMA(0,0,0) errors : -9152.683\n",
      " Regression with ARIMA(1,0,2) errors : -14099.35\n",
      " Regression with ARIMA(0,0,2) errors : -13115.29\n",
      " Regression with ARIMA(1,0,1) errors : -14101.37\n",
      " Regression with ARIMA(2,0,1) errors : -14098.29\n",
      " Regression with ARIMA(2,0,0) errors : -14100.36\n",
      " Regression with ARIMA(1,0,1) errors : -13962.68\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14100.49\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13956.34\n",
      " Regression with ARIMA(1,1,0) errors : -13954.24\n",
      " Regression with ARIMA(0,1,1) errors : -13954.58\n",
      " Regression with ARIMA(0,1,0) errors : -13958.35\n",
      " Regression with ARIMA(1,1,1) errors : -13952.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13967.35\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13942.25\n",
      " Regression with ARIMA(1,1,0) errors : -13939.51\n",
      " Regression with ARIMA(0,1,1) errors : -13940.54\n",
      " Regression with ARIMA(0,1,0) errors : -13944.26\n",
      " Regression with ARIMA(1,1,1) errors : -13938.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13953.25\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "[1] \"10 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14057.56\n",
      " Regression with ARIMA(0,0,0) errors : -10451.94\n",
      " Regression with ARIMA(1,0,0) errors : -14055.02\n",
      " Regression with ARIMA(0,0,1) errors : -12212.26\n",
      " Regression with ARIMA(0,0,0) errors : -9125.585\n",
      " Regression with ARIMA(1,0,2) errors : -14059.61\n",
      " Regression with ARIMA(0,0,2) errors : -13092.48\n",
      " Regression with ARIMA(1,0,1) errors : -14061.59\n",
      " Regression with ARIMA(2,0,1) errors : -14058.81\n",
      " Regression with ARIMA(2,0,0) errors : -14060.82\n",
      " Regression with ARIMA(1,0,1) errors : -13926.65\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14060.43\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14049.73\n",
      " Regression with ARIMA(0,0,0) errors : -10463.36\n",
      " Regression with ARIMA(1,0,0) errors : -14047.15\n",
      " Regression with ARIMA(0,0,1) errors : -12215.94\n",
      " Regression with ARIMA(0,0,0) errors : -9113.651\n",
      " Regression with ARIMA(1,0,2) errors : -14050.93\n",
      " Regression with ARIMA(0,0,2) errors : -13088.83\n",
      " Regression with ARIMA(1,0,1) errors : -14052.85\n",
      " Regression with ARIMA(2,0,1) errors : -14049.93\n",
      " Regression with ARIMA(2,0,0) errors : -14051.82\n",
      " Regression with ARIMA(1,0,1) errors : -13912.48\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14051.09\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13911.02\n",
      " Regression with ARIMA(1,1,0) errors : -13908.48\n",
      " Regression with ARIMA(0,1,1) errors : -13909.2\n",
      " Regression with ARIMA(0,1,0) errors : -13913.03\n",
      " Regression with ARIMA(1,1,1) errors : -13907.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13922.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13900.07\n",
      " Regression with ARIMA(1,1,0) errors : -13897.25\n",
      " Regression with ARIMA(0,1,1) errors : -13898.14\n",
      " Regression with ARIMA(0,1,0) errors : -13902.07\n",
      " Regression with ARIMA(1,1,1) errors : -13896.05\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13911.05\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13876.42\n",
      " Regression with ARIMA(0,1,0) errors : -13873.69\n",
      " Regression with ARIMA(1,1,0) errors : -13870.8\n",
      " Regression with ARIMA(0,1,1) errors : -13871.79\n",
      " Regression with ARIMA(0,1,0) errors : -13875.69\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -13951.7\n",
      " Regression with ARIMA(1,1,1) errors : -13869.75\n",
      " Regression with ARIMA(2,1,0) errors : -13877.74\n",
      " Regression with ARIMA(3,1,1) errors : -13879.69\n",
      " Regression with ARIMA(3,1,0) errors : -13878.26\n",
      " Regression with ARIMA(3,1,2) errors : -13880.96\n",
      " Regression with ARIMA(2,1,1) errors : -13953.47\n",
      " Regression with ARIMA(1,1,1) errors : -13871.73\n",
      " Regression with ARIMA(2,1,0) errors : -13879.75\n",
      " Regression with ARIMA(3,1,1) errors : -13881.7\n",
      " Regression with ARIMA(2,1,2) errors : -13878.44\n",
      " Regression with ARIMA(1,1,0) errors : -13872.8\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -13880.27\n",
      " Regression with ARIMA(3,1,2) errors : -13883\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -13906.38\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13861.23\n",
      " Regression with ARIMA(1,1,0) errors : -13858.29\n",
      " Regression with ARIMA(0,1,1) errors : -13859.25\n",
      " Regression with ARIMA(0,1,0) errors : -13863.23\n",
      " Regression with ARIMA(1,1,1) errors : -13857.3\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13872.19\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13896.9\n",
      " Regression with ARIMA(0,0,0) errors : -10196.26\n",
      " Regression with ARIMA(1,0,0) errors : -13893.1\n",
      " Regression with ARIMA(0,0,1) errors : -11966.99\n",
      " Regression with ARIMA(0,0,0) errors : -8742.913\n",
      " Regression with ARIMA(1,0,2) errors : -13897.42\n",
      " Regression with ARIMA(0,0,2) errors : -12878.36\n",
      " Regression with ARIMA(1,0,1) errors : -13899.18\n",
      " Regression with ARIMA(2,0,1) errors : -13896.32\n",
      " Regression with ARIMA(2,0,0) errors : -13897.97\n",
      " Regression with ARIMA(1,0,1) errors : -13775.62\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13898.36\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13779.66\n",
      " Regression with ARIMA(0,0,0) errors : -10097.98\n",
      " Regression with ARIMA(1,0,0) errors : -13771.91\n",
      " Regression with ARIMA(0,0,1) errors : -11865.72\n",
      " Regression with ARIMA(0,0,0) errors : -8710.896\n",
      " Regression with ARIMA(1,0,2) errors : -13777.93\n",
      " Regression with ARIMA(2,0,1) errors : -13777.15\n",
      " Regression with ARIMA(3,0,2) errors : -13783.79\n",
      " Regression with ARIMA(3,0,1) errors : -13778.18\n",
      " Regression with ARIMA(4,0,2) errors : -13782.79\n",
      " Regression with ARIMA(3,0,3) errors : -13790.74\n",
      " Regression with ARIMA(2,0,3) errors : -13778.27\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13781.06\n",
      " Regression with ARIMA(2,0,4) errors : -13781.18\n",
      " Regression with ARIMA(4,0,4) errors : -13783.64\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,3) errors : -13791.61\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13736.94\n",
      " Regression with ARIMA(0,0,0) errors : -10002.66\n",
      " Regression with ARIMA(1,0,0) errors : -13730.41\n",
      " Regression with ARIMA(0,0,1) errors : -11778.89\n",
      " Regression with ARIMA(0,0,0) errors : -8620.765\n",
      " Regression with ARIMA(1,0,2) errors : -13736.26\n",
      " Regression with ARIMA(2,0,1) errors : -13735.25\n",
      " Regression with ARIMA(3,0,2) errors : -13738.48\n",
      " Regression with ARIMA(3,0,1) errors : -13735.53\n",
      " Regression with ARIMA(4,0,2) errors : -13732.51\n",
      " Regression with ARIMA(3,0,3) errors : -13747.21\n",
      " Regression with ARIMA(2,0,3) errors : -13735.02\n",
      " Regression with ARIMA(4,0,3) errors : -13743.42\n",
      " Regression with ARIMA(3,0,4) errors : -13736.01\n",
      " Regression with ARIMA(2,0,4) errors : -13737.88\n",
      " Regression with ARIMA(4,0,4) errors : -13742.31\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,3) errors : -13748.29\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13671.5\n",
      " Regression with ARIMA(0,0,0) errors : -9894.943\n",
      " Regression with ARIMA(1,0,0) errors : -13665.86\n",
      " Regression with ARIMA(0,0,1) errors : -11694.71\n",
      " Regression with ARIMA(0,0,0) errors : -8560.227\n",
      " Regression with ARIMA(1,0,2) errors : -13672.38\n",
      " Regression with ARIMA(0,0,2) errors : -12612.9\n",
      " Regression with ARIMA(1,0,1) errors : -13674.2\n",
      " Regression with ARIMA(2,0,1) errors : -13671.58\n",
      " Regression with ARIMA(2,0,0) errors : -13673.48\n",
      " Regression with ARIMA(1,0,1) errors : -13559.42\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13673.28\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13629.1\n",
      " Regression with ARIMA(0,0,0) errors : -9878.792\n",
      " Regression with ARIMA(1,0,0) errors : -13624.85\n",
      " Regression with ARIMA(0,0,1) errors : -11666.73\n",
      " Regression with ARIMA(0,0,0) errors : -8556.701\n",
      " Regression with ARIMA(1,0,2) errors : -13629.96\n",
      " Regression with ARIMA(0,0,2) errors : -12579.75\n",
      " Regression with ARIMA(1,0,1) errors : -13631.19\n",
      " Regression with ARIMA(2,0,1) errors : -13629.28\n",
      " Regression with ARIMA(2,0,0) errors : -13630.88\n",
      " Regression with ARIMA(1,0,1) errors : -13512.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13630.37\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13611.31\n",
      " Regression with ARIMA(0,0,0) errors : -9870.771\n",
      " Regression with ARIMA(1,0,0) errors : -13607.01\n",
      " Regression with ARIMA(0,0,1) errors : -11652.28\n",
      " Regression with ARIMA(0,0,0) errors : -8549.922\n",
      " Regression with ARIMA(1,0,2) errors : -13611.78\n",
      " Regression with ARIMA(0,0,2) errors : -12567.48\n",
      " Regression with ARIMA(1,0,1) errors : -13612.86\n",
      " Regression with ARIMA(2,0,1) errors : -13620.17\n",
      " Regression with ARIMA(2,0,0) errors : -13612.21\n",
      " Regression with ARIMA(3,0,1) errors : -13610.14\n",
      " Regression with ARIMA(3,0,0) errors : -13609.99\n",
      " Regression with ARIMA(3,0,2) errors : -13609.53\n",
      " Regression with ARIMA(2,0,1) errors : -13511.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13612.06\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13585.71\n",
      " Regression with ARIMA(0,0,0) errors : -9844.615\n",
      " Regression with ARIMA(1,0,0) errors : -13581.02\n",
      " Regression with ARIMA(0,0,1) errors : -11622.06\n",
      " Regression with ARIMA(0,0,0) errors : -8510.432\n",
      " Regression with ARIMA(1,0,2) errors : -13586.32\n",
      " Regression with ARIMA(0,0,2) errors : -12543.41\n",
      " Regression with ARIMA(1,0,1) errors : -13587.02\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -13586.54\n",
      " Regression with ARIMA(1,0,1) errors : -13475.64\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13585.99\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13574.71\n",
      " Regression with ARIMA(0,0,0) errors : -9826.549\n",
      " Regression with ARIMA(1,0,0) errors : -13570.27\n",
      " Regression with ARIMA(0,0,1) errors : -11609.5\n",
      " Regression with ARIMA(0,0,0) errors : -8481.914\n",
      " Regression with ARIMA(1,0,2) errors : -13575.26\n",
      " Regression with ARIMA(0,0,2) errors : -12534.01\n",
      " Regression with ARIMA(1,0,1) errors : -13576.15\n",
      " Regression with ARIMA(2,0,1) errors : -13583.87\n",
      " Regression with ARIMA(2,0,0) errors : -13575.76\n",
      " Regression with ARIMA(3,0,1) errors : -13573.56\n",
      " Regression with ARIMA(3,0,0) errors : -13574.15\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13575.33\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13420.85\n",
      " Regression with ARIMA(1,1,0) errors : -13418.28\n",
      " Regression with ARIMA(0,1,1) errors : -13419.05\n",
      " Regression with ARIMA(0,1,0) errors : -13422.86\n",
      " Regression with ARIMA(1,1,1) errors : -13416.27\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13431.63\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13406.54\n",
      " Regression with ARIMA(1,1,0) errors : -13403.97\n",
      " Regression with ARIMA(0,1,1) errors : -13404.69\n",
      " Regression with ARIMA(0,1,0) errors : -13408.55\n",
      " Regression with ARIMA(1,1,1) errors : -13401.96\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13417.31\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13398.85\n",
      " Regression with ARIMA(1,1,0) errors : -13397.03\n",
      " Regression with ARIMA(0,1,1) errors : -13396.96\n",
      " Regression with ARIMA(0,1,0) errors : -13400.86\n",
      " Regression with ARIMA(1,1,1) errors : -13395.03\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13409.61\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13388.05\n",
      " Regression with ARIMA(1,1,0) errors : -13385.34\n",
      " Regression with ARIMA(0,1,1) errors : -13386.18\n",
      " Regression with ARIMA(0,1,0) errors : -13390.05\n",
      " Regression with ARIMA(1,1,1) errors : -13383.59\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13398.81\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13385.45\n",
      " Regression with ARIMA(1,1,0) errors : -13382.92\n",
      " Regression with ARIMA(0,1,1) errors : -13383.57\n",
      " Regression with ARIMA(0,1,0) errors : -13387.46\n",
      " Regression with ARIMA(1,1,1) errors : -13380.91\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13396.21\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13381.56\n",
      " Regression with ARIMA(1,1,0) errors : -13380.11\n",
      " Regression with ARIMA(0,1,1) errors : -13379.6\n",
      " Regression with ARIMA(0,1,0) errors : -13383.57\n",
      " Regression with ARIMA(1,1,1) errors : -13378.27\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13392.32\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13382.25\n",
      " Regression with ARIMA(1,1,0) errors : -13380.87\n",
      " Regression with ARIMA(0,1,1) errors : -13380.28\n",
      " Regression with ARIMA(0,1,0) errors : -13384.26\n",
      " Regression with ARIMA(1,1,1) errors : -13379.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13393.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13380.14\n",
      " Regression with ARIMA(1,1,0) errors : -13377.47\n",
      " Regression with ARIMA(0,1,1) errors : -13378.15\n",
      " Regression with ARIMA(0,1,0) errors : -13382.15\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.9\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13378.91\n",
      " Regression with ARIMA(1,1,0) errors : -13377.73\n",
      " Regression with ARIMA(0,1,1) errors : -13376.9\n",
      " Regression with ARIMA(0,1,0) errors : -13380.91\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13389.66\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13379.35\n",
      " Regression with ARIMA(1,1,0) errors : -13377.78\n",
      " Regression with ARIMA(0,1,1) errors : -13377.34\n",
      " Regression with ARIMA(0,1,0) errors : -13381.35\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.1\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "[1] \"20 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13379.9\n",
      " Regression with ARIMA(1,1,0) errors : -13377.2\n",
      " Regression with ARIMA(0,1,1) errors : -13377.89\n",
      " Regression with ARIMA(0,1,0) errors : -13381.91\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.66\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13381.25\n",
      " Regression with ARIMA(1,1,0) errors : -13378.41\n",
      " Regression with ARIMA(0,1,1) errors : -13379.25\n",
      " Regression with ARIMA(0,1,0) errors : -13383.26\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13392.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13376.01\n",
      " Regression with ARIMA(1,1,0) errors : -13373.65\n",
      " Regression with ARIMA(0,1,1) errors : -13374\n",
      " Regression with ARIMA(0,1,0) errors : -13378.02\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13386.77\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13369.58\n",
      " Regression with ARIMA(1,1,0) errors : -13366.83\n",
      " Regression with ARIMA(0,1,1) errors : -13367.57\n",
      " Regression with ARIMA(0,1,0) errors : -13371.59\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13380.33\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13497.89\n",
      " Regression with ARIMA(0,0,0) errors : -9950.123\n",
      " Regression with ARIMA(1,0,0) errors : -13493.27\n",
      " Regression with ARIMA(0,0,1) errors : -11642.05\n",
      " Regression with ARIMA(0,0,0) errors : -8458.864\n",
      " Regression with ARIMA(1,0,2) errors : -13494.53\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -13496.04\n",
      " Regression with ARIMA(1,0,1) errors : -13495.7\n",
      " Regression with ARIMA(1,0,3) errors : -13492.7\n",
      " Regression with ARIMA(3,0,1) errors : -13497.36\n",
      " Regression with ARIMA(3,0,3) errors : -13498.01\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13507.72\n",
      " Regression with ARIMA(2,0,4) errors : -13500.47\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13500.7\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13506.03\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13499.98\n",
      " Regression with ARIMA(0,0,0) errors : -9960.775\n",
      " Regression with ARIMA(1,0,0) errors : -13495.47\n",
      " Regression with ARIMA(0,0,1) errors : -11645.81\n",
      " Regression with ARIMA(0,0,0) errors : -8453.629\n",
      " Regression with ARIMA(1,0,2) errors : -13496.49\n",
      " Regression with ARIMA(2,0,1) errors : -13507.19\n",
      " Regression with ARIMA(1,0,1) errors : -13497.52\n",
      " Regression with ARIMA(2,0,0) errors : -13496.74\n",
      " Regression with ARIMA(3,0,1) errors : -13497.31\n",
      " Regression with ARIMA(3,0,0) errors : -13495.2\n",
      " Regression with ARIMA(3,0,2) errors : -13495.71\n",
      " Regression with ARIMA(2,0,1) errors : -13378.82\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13506.74\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13497.77\n",
      " Regression with ARIMA(0,0,0) errors : -9958.269\n",
      " Regression with ARIMA(1,0,0) errors : -13494.31\n",
      " Regression with ARIMA(0,0,1) errors : -11644.45\n",
      " Regression with ARIMA(0,0,0) errors : -8449.905\n",
      " Regression with ARIMA(1,0,2) errors : -13495.3\n",
      " Regression with ARIMA(2,0,1) errors : -13507.9\n",
      " Regression with ARIMA(1,0,1) errors : -13496.33\n",
      " Regression with ARIMA(2,0,0) errors : -13495.6\n",
      " Regression with ARIMA(3,0,1) errors : -13496.54\n",
      " Regression with ARIMA(3,0,0) errors : -13493.75\n",
      " Regression with ARIMA(3,0,2) errors : -13495.71\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13508.08\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13493.96\n",
      " Regression with ARIMA(0,0,0) errors : -9977.205\n",
      " Regression with ARIMA(1,0,0) errors : -13489.97\n",
      " Regression with ARIMA(0,0,1) errors : -11647.24\n",
      " Regression with ARIMA(0,0,0) errors : -8450.876\n",
      " Regression with ARIMA(1,0,2) errors : -13490.98\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13488.95\n",
      " Regression with ARIMA(2,0,3) errors : -13487.5\n",
      " Regression with ARIMA(1,0,1) errors : -13492.01\n",
      " Regression with ARIMA(1,0,3) errors : -13489.23\n",
      " Regression with ARIMA(3,0,1) errors : -13492.37\n",
      " Regression with ARIMA(3,0,3) errors : -13486.94\n",
      " Regression with ARIMA(2,0,2) errors : -13356.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.62\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.03\n",
      " Regression with ARIMA(0,0,0) errors : -10035.28\n",
      " Regression with ARIMA(1,0,0) errors : -13487.39\n",
      " Regression with ARIMA(0,0,1) errors : -11673.35\n",
      " Regression with ARIMA(0,0,0) errors : -8457.324\n",
      " Regression with ARIMA(1,0,2) errors : -13488\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13489.24\n",
      " Regression with ARIMA(2,0,3) errors : -13489.21\n",
      " Regression with ARIMA(1,0,1) errors : -13488.93\n",
      " Regression with ARIMA(1,0,3) errors : -13486.24\n",
      " Regression with ARIMA(3,0,1) errors : -13491.09\n",
      " Regression with ARIMA(3,0,0) errors : -13487.21\n",
      " Regression with ARIMA(4,0,1) errors : -13487.57\n",
      " Regression with ARIMA(2,0,0) errors : -13488.97\n",
      " Regression with ARIMA(4,0,0) errors : -13485.19\n",
      " Regression with ARIMA(4,0,2) errors : -13498.14\n",
      " Regression with ARIMA(5,0,2) errors : -13499.05\n",
      " Regression with ARIMA(5,0,1) errors : -13492.88\n",
      " Regression with ARIMA(5,0,3) errors : -13497.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13501.63\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.2\n",
      " Regression with ARIMA(0,0,0) errors : -10019.33\n",
      " Regression with ARIMA(1,0,0) errors : -13487.57\n",
      " Regression with ARIMA(0,0,1) errors : -11667.27\n",
      " Regression with ARIMA(0,0,0) errors : -8455.887\n",
      " Regression with ARIMA(1,0,2) errors : -13488.56\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13489.44\n",
      " Regression with ARIMA(2,0,3) errors : -13490.16\n",
      " Regression with ARIMA(1,0,1) errors : -13489.31\n",
      " Regression with ARIMA(1,0,3) errors : -13486.85\n",
      " Regression with ARIMA(3,0,1) errors : -13491.32\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13350.82\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.68\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13489.2\n",
      " Regression with ARIMA(0,0,0) errors : -10028.88\n",
      " Regression with ARIMA(1,0,0) errors : -13485\n",
      " Regression with ARIMA(0,0,1) errors : -11673.96\n",
      " Regression with ARIMA(0,0,0) errors : -8443.256\n",
      " Regression with ARIMA(1,0,2) errors : -13486.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -13487.2\n",
      " Regression with ARIMA(1,0,1) errors : -13487.01\n",
      " Regression with ARIMA(1,0,3) errors : -13484.63\n",
      " Regression with ARIMA(3,0,1) errors : -13491.48\n",
      " Regression with ARIMA(3,0,0) errors : -13487\n",
      " Regression with ARIMA(4,0,1) errors : -13489.1\n",
      " Regression with ARIMA(2,0,0) errors : -13486.23\n",
      " Regression with ARIMA(4,0,0) errors : -13484.88\n",
      " Regression with ARIMA(4,0,2) errors : -13500.18\n",
      " Regression with ARIMA(5,0,2) errors : -13502.09\n",
      " Regression with ARIMA(5,0,1) errors : -13494.32\n",
      " Regression with ARIMA(5,0,3) errors : -13500.12\n",
      " Regression with ARIMA(4,0,3) errors : -13500.55\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13500.88\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492\n",
      " Regression with ARIMA(0,0,0) errors : -10028.08\n",
      " Regression with ARIMA(1,0,0) errors : -13487.35\n",
      " Regression with ARIMA(0,0,1) errors : -11679.14\n",
      " Regression with ARIMA(0,0,0) errors : -8442.705\n",
      " Regression with ARIMA(1,0,2) errors : -13488.66\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13487.58\n",
      " Regression with ARIMA(2,0,3) errors : -13489.99\n",
      " Regression with ARIMA(1,0,1) errors : -13489.51\n",
      " Regression with ARIMA(1,0,3) errors : -13487.09\n",
      " Regression with ARIMA(3,0,1) errors : -13489.86\n",
      " Regression with ARIMA(3,0,3) errors : -13482.34\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.71\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13496.48\n",
      " Regression with ARIMA(0,0,0) errors : -10046.87\n",
      " Regression with ARIMA(1,0,0) errors : -13491.11\n",
      " Regression with ARIMA(0,0,1) errors : -11686.59\n",
      " Regression with ARIMA(0,0,0) errors : -8439.819\n",
      " Regression with ARIMA(1,0,2) errors : -13492.36\n",
      " Regression with ARIMA(2,0,1) errors : -13506.72\n",
      " Regression with ARIMA(1,0,1) errors : -13493.26\n",
      " Regression with ARIMA(2,0,0) errors : -13492.87\n",
      " Regression with ARIMA(3,0,1) errors : -13494.79\n",
      " Regression with ARIMA(3,0,0) errors : -13491.08\n",
      " Regression with ARIMA(3,0,2) errors : -13506.27\n",
      " Regression with ARIMA(2,0,1) errors : -13358.47\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13505.42\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.02\n",
      " Regression with ARIMA(0,0,0) errors : -10051.63\n",
      " Regression with ARIMA(1,0,0) errors : -13487.72\n",
      " Regression with ARIMA(0,0,1) errors : -11688.79\n",
      " Regression with ARIMA(0,0,0) errors : -8460.12\n",
      " Regression with ARIMA(1,0,2) errors : -13489\n",
      " Regression with ARIMA(2,0,1) errors : -13501\n",
      " Regression with ARIMA(1,0,1) errors : -13489.93\n",
      " Regression with ARIMA(2,0,0) errors : -13489.16\n",
      " Regression with ARIMA(3,0,1) errors : -13490.72\n",
      " Regression with ARIMA(3,0,0) errors : -13487.43\n",
      " Regression with ARIMA(3,0,2) errors : -13488.68\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13501.14\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13500.43\n",
      " Regression with ARIMA(0,0,0) errors : -10047.97\n",
      " Regression with ARIMA(1,0,0) errors : -13495.4\n",
      " Regression with ARIMA(0,0,1) errors : -11686.73\n",
      " Regression with ARIMA(0,0,0) errors : -8459.472\n",
      " Regression with ARIMA(1,0,2) errors : -13496.66\n",
      " Regression with ARIMA(2,0,1) errors : -13510.38\n",
      " Regression with ARIMA(1,0,1) errors : -13497.58\n",
      " Regression with ARIMA(2,0,0) errors : -13497.07\n",
      " Regression with ARIMA(3,0,1) errors : -13498.19\n",
      " Regression with ARIMA(3,0,0) errors : -13495.29\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13509.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10051.61\n",
      " Regression with ARIMA(1,0,0) errors : -13499.36\n",
      " Regression with ARIMA(0,0,1) errors : -11694.33\n",
      " Regression with ARIMA(0,0,0) errors : -8454.72\n",
      " Regression with ARIMA(2,0,0) errors : -13501.93\n",
      " Regression with ARIMA(3,0,0) errors : -13500.22\n",
      " Regression with ARIMA(2,0,1) errors : -13512.21\n",
      " Regression with ARIMA(1,0,1) errors : -13501.76\n",
      " Regression with ARIMA(3,0,1) errors : -13503.01\n",
      " Regression with ARIMA(1,0,2) errors : -13500.7\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13514.04\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13505.3\n",
      " Regression with ARIMA(0,0,0) errors : -10067.87\n",
      " Regression with ARIMA(1,0,0) errors : -13500.56\n",
      " Regression with ARIMA(0,0,1) errors : -11703.92\n",
      " Regression with ARIMA(0,0,0) errors : -8459.352\n",
      " Regression with ARIMA(1,0,2) errors : -13501.48\n",
      " Regression with ARIMA(2,0,1) errors : -13513.92\n",
      " Regression with ARIMA(1,0,1) errors : -13502.47\n",
      " Regression with ARIMA(2,0,0) errors : -13501.76\n",
      " Regression with ARIMA(3,0,1) errors : -13504.22\n",
      " Regression with ARIMA(3,0,0) errors : -13499.98\n",
      " Regression with ARIMA(3,0,2) errors : -13502.51\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13509.66\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13504.43\n",
      " Regression with ARIMA(0,0,0) errors : -10066.73\n",
      " Regression with ARIMA(1,0,0) errors : -13500.34\n",
      " Regression with ARIMA(0,0,1) errors : -11703.9\n",
      " Regression with ARIMA(0,0,0) errors : -8459.982\n",
      " Regression with ARIMA(1,0,2) errors : -13501.46\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13502.1\n",
      " Regression with ARIMA(2,0,3) errors : -13502.47\n",
      " Regression with ARIMA(1,0,1) errors : -13502.43\n",
      " Regression with ARIMA(1,0,3) errors : -13499.75\n",
      " Regression with ARIMA(3,0,1) errors : -13504.38\n",
      " Regression with ARIMA(3,0,3) errors : -13511.67\n",
      " Regression with ARIMA(4,0,3) errors : -13502.32\n",
      " Regression with ARIMA(3,0,4) errors : -13513.38\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -13510.29\n",
      " Regression with ARIMA(3,0,5) errors : -13505.27\n",
      " Regression with ARIMA(2,0,5) errors : -13506.32\n",
      " Regression with ARIMA(4,0,5) errors : -13507.77\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13512.15\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13504.84\n",
      " Regression with ARIMA(0,0,0) errors : -10082.23\n",
      " Regression with ARIMA(1,0,0) errors : -13499.69\n",
      " Regression with ARIMA(0,0,1) errors : -11711.37\n",
      " Regression with ARIMA(0,0,0) errors : -8482.428\n",
      " Regression with ARIMA(1,0,2) errors : -13500.44\n",
      " Regression with ARIMA(2,0,1) errors : -13506.21\n",
      " Regression with ARIMA(1,0,1) errors : -13501.67\n",
      " Regression with ARIMA(2,0,0) errors : -13507.48\n",
      " Regression with ARIMA(3,0,0) errors : -13505.43\n",
      " Regression with ARIMA(3,0,1) errors : -13508.06\n",
      " Regression with ARIMA(4,0,1) errors : -13504.51\n",
      " Regression with ARIMA(3,0,2) errors : -13507\n",
      " Regression with ARIMA(4,0,0) errors : -13503.26\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -13503.39\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13511.77\n",
      " Regression with ARIMA(0,0,0) errors : -10089.38\n",
      " Regression with ARIMA(1,0,0) errors : -13508.45\n",
      " Regression with ARIMA(0,0,1) errors : -11717.82\n",
      " Regression with ARIMA(0,0,0) errors : -8486.146\n",
      " Regression with ARIMA(1,0,2) errors : -13508.73\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13508.14\n",
      " Regression with ARIMA(2,0,3) errors : -13509.84\n",
      " Regression with ARIMA(1,0,1) errors : -13509.99\n",
      " Regression with ARIMA(1,0,3) errors : -13507.09\n",
      " Regression with ARIMA(3,0,1) errors : -13509.92\n",
      " Regression with ARIMA(3,0,3) errors : -13517.49\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13519.73\n",
      " Regression with ARIMA(2,0,4) errors : -13513.32\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13514.28\n",
      " Regression with ARIMA(4,0,5) errors : -13514.96\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13520.01\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13510.51\n",
      " Regression with ARIMA(0,0,0) errors : -10105.18\n",
      " Regression with ARIMA(1,0,0) errors : -13507.88\n",
      " Regression with ARIMA(0,0,1) errors : -11721.86\n",
      " Regression with ARIMA(0,0,0) errors : -8493.114\n",
      " Regression with ARIMA(1,0,2) errors : -13508.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13516.56\n",
      " Regression with ARIMA(3,0,1) errors : -13506.85\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13515.63\n",
      " Regression with ARIMA(2,0,3) errors : -13508.55\n",
      " Regression with ARIMA(4,0,1) errors : -13509.07\n",
      " Regression with ARIMA(4,0,3) errors : -13513.32\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13519.6\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13508.31\n",
      " Regression with ARIMA(0,0,0) errors : -10126.55\n",
      " Regression with ARIMA(1,0,0) errors : -13507.44\n",
      " Regression with ARIMA(0,0,1) errors : -11732.75\n",
      " Regression with ARIMA(0,0,0) errors : -8479.726\n",
      " Regression with ARIMA(1,0,2) errors : -13507.67\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13508.26\n",
      " Regression with ARIMA(2,0,3) errors : -13506.52\n",
      " Regression with ARIMA(1,0,1) errors : -13508.92\n",
      " Regression with ARIMA(0,0,2) errors : -12538.44\n",
      " Regression with ARIMA(2,0,0) errors : -13508.97\n",
      " Regression with ARIMA(3,0,0) errors : -13506.81\n",
      " Regression with ARIMA(3,0,1) errors : -13510.29\n",
      " Regression with ARIMA(4,0,1) errors : -13507.38\n",
      " Regression with ARIMA(4,0,0) errors : -13504.51\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -13510.44\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10215.23\n",
      " Regression with ARIMA(1,0,0) errors : -13503.24\n",
      " Regression with ARIMA(0,0,1) errors : -11765.85\n",
      " Regression with ARIMA(0,0,0) errors : -8496.584\n",
      " Regression with ARIMA(2,0,0) errors : -13503.84\n",
      " Regression with ARIMA(3,0,0) errors : -13502.9\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13504.35\n",
      " Regression with ARIMA(1,0,2) errors : -13503.03\n",
      " Regression with ARIMA(0,0,2) errors : -12548.3\n",
      " Regression with ARIMA(1,0,1) errors : -13380.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13503.51\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10218.34\n",
      " Regression with ARIMA(1,0,0) errors : -13503.41\n",
      " Regression with ARIMA(0,0,1) errors : -11768.16\n",
      " Regression with ARIMA(0,0,0) errors : -8499.03\n",
      " Regression with ARIMA(2,0,0) errors : -13503.77\n",
      " Regression with ARIMA(3,0,0) errors : -13502.7\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13504.25\n",
      " Regression with ARIMA(1,0,2) errors : -13502.87\n",
      " Regression with ARIMA(0,0,2) errors : -12542.4\n",
      " Regression with ARIMA(1,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13503.42\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "[1] \"30 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13509.32\n",
      " Regression with ARIMA(0,0,0) errors : -10219.25\n",
      " Regression with ARIMA(1,0,0) errors : -13507.76\n",
      " Regression with ARIMA(0,0,1) errors : -11765.04\n",
      " Regression with ARIMA(0,0,0) errors : -8502.109\n",
      " Regression with ARIMA(1,0,2) errors : -13506.99\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13502.83\n",
      " Regression with ARIMA(2,0,3) errors : -13507.36\n",
      " Regression with ARIMA(1,0,1) errors : -13508.29\n",
      " Regression with ARIMA(1,0,3) errors : -13505.45\n",
      " Regression with ARIMA(3,0,1) errors : -13506.88\n",
      " Regression with ARIMA(3,0,3) errors : -13513.93\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13514.85\n",
      " Regression with ARIMA(2,0,4) errors : -13509.02\n",
      " Regression with ARIMA(4,0,4) errors : -13512.96\n",
      " Regression with ARIMA(3,0,5) errors : -13508.01\n",
      " Regression with ARIMA(2,0,5) errors : -13510.83\n",
      " Regression with ARIMA(4,0,5) errors : -13505.08\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13517.28\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10222.58\n",
      " Regression with ARIMA(1,0,0) errors : -13506.49\n",
      " Regression with ARIMA(0,0,1) errors : -11761.77\n",
      " Regression with ARIMA(0,0,0) errors : -8501.931\n",
      " Regression with ARIMA(2,0,0) errors : -13505.83\n",
      " Regression with ARIMA(1,0,1) errors : -13506.71\n",
      " Regression with ARIMA(2,0,1) errors : -13516.88\n",
      " Regression with ARIMA(3,0,1) errors : -13512.26\n",
      " Regression with ARIMA(1,0,2) errors : -13505.56\n",
      " Regression with ARIMA(3,0,0) errors : -13505.02\n",
      " Regression with ARIMA(3,0,2) errors : -13499.27\n",
      " Regression with ARIMA(2,0,1) errors : -13367.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13503.41\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13512.51\n",
      " Regression with ARIMA(0,0,0) errors : -10227.27\n",
      " Regression with ARIMA(1,0,0) errors : -13513.98\n",
      " Regression with ARIMA(0,0,1) errors : -11762.97\n",
      " Regression with ARIMA(0,0,0) errors : -8502.27\n",
      " Regression with ARIMA(2,0,0) errors : -13514.25\n",
      " Regression with ARIMA(3,0,0) errors : -13513.04\n",
      " Regression with ARIMA(2,0,1) errors : -13512.24\n",
      " Regression with ARIMA(1,0,1) errors : -13514.02\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -13380.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,0) errors : -13511.98\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13526.34\n",
      " Regression with ARIMA(0,0,0) errors : -10223.66\n",
      " Regression with ARIMA(1,0,0) errors : -13526.45\n",
      " Regression with ARIMA(0,0,1) errors : -11757.01\n",
      " Regression with ARIMA(0,0,0) errors : -8519.276\n",
      " Regression with ARIMA(2,0,0) errors : -13525.32\n",
      " Regression with ARIMA(1,0,1) errors : -13526.23\n",
      " Regression with ARIMA(2,0,1) errors : -13535.26\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13525.01\n",
      " Regression with ARIMA(3,0,0) errors : -13523.41\n",
      " Regression with ARIMA(3,0,2) errors : -13520.69\n",
      " Regression with ARIMA(2,0,1) errors : -13408.03\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13521.31\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10227.11\n",
      " Regression with ARIMA(1,0,0) errors : -13535.83\n",
      " Regression with ARIMA(0,0,1) errors : -11776.31\n",
      " Regression with ARIMA(0,0,0) errors : -8558.409\n",
      " Regression with ARIMA(2,0,0) errors : -13535.04\n",
      " Regression with ARIMA(1,0,1) errors : -13535.63\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13535.07\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10239.17\n",
      " Regression with ARIMA(1,0,0) errors : -13532.83\n",
      " Regression with ARIMA(0,0,1) errors : -11782.72\n",
      " Regression with ARIMA(0,0,0) errors : -8566.374\n",
      " Regression with ARIMA(2,0,0) errors : -13533.02\n",
      " Regression with ARIMA(3,0,0) errors : -13531.58\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13532.77\n",
      " Regression with ARIMA(3,0,1) errors : -13532.73\n",
      " Regression with ARIMA(2,0,0) errors : -13415.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,0) errors : -13531.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13539.55\n",
      " Regression with ARIMA(0,0,0) errors : -10238.93\n",
      " Regression with ARIMA(1,0,0) errors : -13540.07\n",
      " Regression with ARIMA(0,0,1) errors : -11784.97\n",
      " Regression with ARIMA(0,0,0) errors : -8571.174\n",
      " Regression with ARIMA(2,0,0) errors : -13539.5\n",
      " Regression with ARIMA(1,0,1) errors : -13540.16\n",
      " Regression with ARIMA(2,0,1) errors : -13549.2\n",
      " Regression with ARIMA(3,0,1) errors : -13539.61\n",
      " Regression with ARIMA(1,0,2) errors : -13539.06\n",
      " Regression with ARIMA(3,0,0) errors : -13537.64\n",
      " Regression with ARIMA(3,0,2) errors : -13537.96\n",
      " Regression with ARIMA(2,0,1) errors : -13400.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13550.1\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13537.09\n",
      " Regression with ARIMA(0,0,0) errors : -10239.99\n",
      " Regression with ARIMA(1,0,0) errors : -13540.98\n",
      " Regression with ARIMA(0,0,1) errors : -11788.21\n",
      " Regression with ARIMA(0,0,0) errors : -8584.355\n",
      " Regression with ARIMA(2,0,0) errors : -13540.68\n",
      " Regression with ARIMA(1,0,1) errors : -13540.96\n",
      " Regression with ARIMA(2,0,1) errors : -13550.79\n",
      " Regression with ARIMA(3,0,1) errors : -13544.63\n",
      " Regression with ARIMA(1,0,2) errors : -13539.89\n",
      " Regression with ARIMA(3,0,0) errors : -13538.95\n",
      " Regression with ARIMA(3,0,2) errors : -13543.48\n",
      " Regression with ARIMA(2,0,1) errors : -13423.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : -13541.93\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13563.2\n",
      " Regression with ARIMA(0,0,0) errors : -10221.42\n",
      " Regression with ARIMA(1,0,0) errors : -13558.89\n",
      " Regression with ARIMA(0,0,1) errors : -11783.59\n",
      " Regression with ARIMA(0,0,0) errors : -8587.344\n",
      " Regression with ARIMA(1,0,2) errors : -13557.75\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13560.36\n",
      " Regression with ARIMA(2,0,3) errors : -13561.2\n",
      " Regression with ARIMA(1,0,1) errors : -13558.83\n",
      " Regression with ARIMA(1,0,3) errors : -13556.36\n",
      " Regression with ARIMA(3,0,1) errors : -13562.66\n",
      " Regression with ARIMA(3,0,3) errors : -13569.83\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13571.17\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -13563.95\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13566.38\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13567.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13570.4\n",
      " Regression with ARIMA(0,0,0) errors : -10190.39\n",
      " Regression with ARIMA(1,0,0) errors : -13568.75\n",
      " Regression with ARIMA(0,0,1) errors : -11771.15\n",
      " Regression with ARIMA(0,0,0) errors : -8593.643\n",
      " Regression with ARIMA(1,0,2) errors : -13567.8\n",
      " Regression with ARIMA(2,0,1) errors : -13578.25\n",
      " Regression with ARIMA(1,0,1) errors : -13568.87\n",
      " Regression with ARIMA(2,0,0) errors : -13567.98\n",
      " Regression with ARIMA(3,0,1) errors : -13566.18\n",
      " Regression with ARIMA(3,0,0) errors : -13566.18\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : -13449.02\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13568.25\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13634.9\n",
      " Regression with ARIMA(0,0,0) errors : -10190.23\n",
      " Regression with ARIMA(1,0,0) errors : -13630.94\n",
      " Regression with ARIMA(0,0,1) errors : -11790.6\n",
      " Regression with ARIMA(0,0,0) errors : -8611.59\n",
      " Regression with ARIMA(1,0,2) errors : -13631.17\n",
      " Regression with ARIMA(2,0,1) errors : -13641.72\n",
      " Regression with ARIMA(1,0,1) errors : -13631.97\n",
      " Regression with ARIMA(2,0,0) errors : -13632.33\n",
      " Regression with ARIMA(3,0,1) errors : -13630.61\n",
      " Regression with ARIMA(3,0,0) errors : -13630.85\n",
      " Regression with ARIMA(3,0,2) errors : -13642.1\n",
      " Regression with ARIMA(4,0,2) errors : -13636.63\n",
      " Regression with ARIMA(3,0,3) errors : -13640.47\n",
      " Regression with ARIMA(2,0,3) errors : -13632.93\n",
      " Regression with ARIMA(4,0,1) errors : -13631.33\n",
      " Regression with ARIMA(4,0,3) errors : -13636.07\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13640.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13645.23\n",
      " Regression with ARIMA(0,0,0) errors : -10202.47\n",
      " Regression with ARIMA(1,0,0) errors : -13645.74\n",
      " Regression with ARIMA(0,0,1) errors : -11804.3\n",
      " Regression with ARIMA(0,0,0) errors : -8622.517\n",
      " Regression with ARIMA(2,0,0) errors : -13646.54\n",
      " Regression with ARIMA(3,0,0) errors : -13646.95\n",
      " Regression with ARIMA(4,0,0) errors : -13644.57\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -13646.54\n",
      " Regression with ARIMA(3,0,0) errors : -13536.11\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,0) errors : -13645.14\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13662.78\n",
      " Regression with ARIMA(0,0,0) errors : -10203.12\n",
      " Regression with ARIMA(1,0,0) errors : -13661.7\n",
      " Regression with ARIMA(0,0,1) errors : -11801.53\n",
      " Regression with ARIMA(0,0,0) errors : -8623.09\n",
      " Regression with ARIMA(1,0,2) errors : -13661.65\n",
      " Regression with ARIMA(2,0,1) errors : -13670.27\n",
      " Regression with ARIMA(1,0,1) errors : -13662.54\n",
      " Regression with ARIMA(2,0,0) errors : -13662.03\n",
      " Regression with ARIMA(3,0,1) errors : -13660.85\n",
      " Regression with ARIMA(3,0,0) errors : -13660.75\n",
      " Regression with ARIMA(3,0,2) errors : -13668.59\n",
      " Regression with ARIMA(2,0,1) errors : -13554.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13669.89\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13665.71\n",
      " Regression with ARIMA(0,0,0) errors : -10188.87\n",
      " Regression with ARIMA(1,0,0) errors : -13663.7\n",
      " Regression with ARIMA(0,0,1) errors : -11795.42\n",
      " Regression with ARIMA(0,0,0) errors : -8643.892\n",
      " Regression with ARIMA(1,0,2) errors : -13663.8\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13660.35\n",
      " Regression with ARIMA(2,0,3) errors : -13663.69\n",
      " Regression with ARIMA(1,0,1) errors : -13664.64\n",
      " Regression with ARIMA(1,0,3) errors : -13662.17\n",
      " Regression with ARIMA(3,0,1) errors : -13664.67\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13565.22\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13665.83\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13656.64\n",
      " Regression with ARIMA(0,0,0) errors : -10191.97\n",
      " Regression with ARIMA(1,0,0) errors : -13653.06\n",
      " Regression with ARIMA(0,0,1) errors : -11788.05\n",
      " Regression with ARIMA(0,0,0) errors : -8651.602\n",
      " Regression with ARIMA(1,0,2) errors : -13653.54\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13653.21\n",
      " Regression with ARIMA(2,0,3) errors : -13654.62\n",
      " Regression with ARIMA(1,0,1) errors : -13654.33\n",
      " Regression with ARIMA(1,0,3) errors : -13651.95\n",
      " Regression with ARIMA(3,0,1) errors : -13655.42\n",
      " Regression with ARIMA(3,0,3) errors : -13661.07\n",
      " Regression with ARIMA(4,0,3) errors : -13648.86\n",
      " Regression with ARIMA(3,0,4) errors : -13662.96\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13661.06\n",
      " Regression with ARIMA(4,0,5) errors : -13659.57\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13659.73\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13649.41\n",
      " Regression with ARIMA(0,0,0) errors : -10167.99\n",
      " Regression with ARIMA(1,0,0) errors : -13648.99\n",
      " Regression with ARIMA(0,0,1) errors : -11774.26\n",
      " Regression with ARIMA(0,0,0) errors : -8653.868\n",
      " Regression with ARIMA(1,0,2) errors : -13649.56\n",
      " Regression with ARIMA(0,0,2) errors : -12612.9\n",
      " Regression with ARIMA(1,0,1) errors : -13650.24\n",
      " Regression with ARIMA(2,0,1) errors : -13660.4\n",
      " Regression with ARIMA(2,0,0) errors : -13649.71\n",
      " Regression with ARIMA(3,0,1) errors : -13651.41\n",
      " Regression with ARIMA(3,0,0) errors : -13648.4\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13661.18\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13655.63\n",
      " Regression with ARIMA(0,0,0) errors : -10165.57\n",
      " Regression with ARIMA(1,0,0) errors : -13654.18\n",
      " Regression with ARIMA(0,0,1) errors : -11773.14\n",
      " Regression with ARIMA(0,0,0) errors : -8656.522\n",
      " Regression with ARIMA(1,0,2) errors : -13654.42\n",
      " Regression with ARIMA(2,0,1) errors : -13665.49\n",
      " Regression with ARIMA(1,0,1) errors : -13655.18\n",
      " Regression with ARIMA(2,0,0) errors : -13654.5\n",
      " Regression with ARIMA(3,0,1) errors : -13655.23\n",
      " Regression with ARIMA(3,0,0) errors : -13653.04\n",
      " Regression with ARIMA(3,0,2) errors : -13653.31\n",
      " Regression with ARIMA(2,0,1) errors : -13554.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13666.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13657.3\n",
      " Regression with ARIMA(0,0,0) errors : -10165.83\n",
      " Regression with ARIMA(1,0,0) errors : -13655.15\n",
      " Regression with ARIMA(0,0,1) errors : -11771.76\n",
      " Regression with ARIMA(0,0,0) errors : -8655.923\n",
      " Regression with ARIMA(1,0,2) errors : -13655.23\n",
      " Regression with ARIMA(2,0,1) errors : -13667.08\n",
      " Regression with ARIMA(1,0,1) errors : -13656.02\n",
      " Regression with ARIMA(2,0,0) errors : -13655.19\n",
      " Regression with ARIMA(3,0,1) errors : -13655.86\n",
      " Regression with ARIMA(3,0,0) errors : -13658.04\n",
      " Regression with ARIMA(3,0,2) errors : -13655.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13666.52\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13655.6\n",
      " Regression with ARIMA(0,0,0) errors : -10159.47\n",
      " Regression with ARIMA(1,0,0) errors : -13654.74\n",
      " Regression with ARIMA(0,0,1) errors : -11765.48\n",
      " Regression with ARIMA(0,0,0) errors : -8662.39\n",
      " Regression with ARIMA(1,0,2) errors : -13655.14\n",
      " Regression with ARIMA(2,0,1) errors : -13671.56\n",
      " Regression with ARIMA(1,0,1) errors : -13655.72\n",
      " Regression with ARIMA(2,0,0) errors : -13656.86\n",
      " Regression with ARIMA(3,0,1) errors : -13656.12\n",
      " Regression with ARIMA(3,0,0) errors : -13655.95\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13665.81\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13656.79\n",
      " Regression with ARIMA(0,0,0) errors : -10173.96\n",
      " Regression with ARIMA(1,0,0) errors : -13652.05\n",
      " Regression with ARIMA(0,0,1) errors : -11777.5\n",
      " Regression with ARIMA(0,0,0) errors : -8700.468\n",
      " Regression with ARIMA(1,0,2) errors : -13652.23\n",
      " Regression with ARIMA(2,0,1) errors : -13668.02\n",
      " Regression with ARIMA(1,0,1) errors : -13652.1\n",
      " Regression with ARIMA(2,0,0) errors : -13652.19\n",
      " Regression with ARIMA(3,0,1) errors : -13656.11\n",
      " Regression with ARIMA(3,0,0) errors : -13652.01\n",
      " Regression with ARIMA(3,0,2) errors : -13662.39\n",
      " Regression with ARIMA(2,0,1) errors : -13548.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13662.69\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13625.68\n",
      " Regression with ARIMA(0,1,0) errors : -13621.46\n",
      " Regression with ARIMA(1,1,0) errors : -13624.34\n",
      " Regression with ARIMA(0,1,1) errors : -13619.6\n",
      " Regression with ARIMA(0,1,0) errors : -13623.47\n",
      " Regression with ARIMA(1,1,2) errors : -13629.17\n",
      " Regression with ARIMA(0,1,2) errors : -13617.77\n",
      " Regression with ARIMA(1,1,1) errors : -13628.01\n",
      " Regression with ARIMA(1,1,3) errors : -13633.78\n",
      " Regression with ARIMA(0,1,3) errors : -13616.46\n",
      " Regression with ARIMA(2,1,3) errors : -13627.37\n",
      " Regression with ARIMA(1,1,4) errors : -13638.05\n",
      " Regression with ARIMA(0,1,4) errors : -13614.88\n",
      " Regression with ARIMA(2,1,4) errors : -13627.68\n",
      " Regression with ARIMA(1,1,5) errors : -13657.04\n",
      " Regression with ARIMA(0,1,5) errors : -13617.4\n",
      " Regression with ARIMA(2,1,5) errors : -13647.25\n",
      " Regression with ARIMA(1,1,5) errors : -13658.92\n",
      " Regression with ARIMA(0,1,5) errors : -13619.42\n",
      " Regression with ARIMA(1,1,4) errors : -13639.93\n",
      " Regression with ARIMA(2,1,5) errors : -13649.14\n",
      " Regression with ARIMA(0,1,4) errors : -13616.89\n",
      " Regression with ARIMA(2,1,4) errors : -13629.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,0) errors : -13628.45\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13669.46\n",
      " Regression with ARIMA(0,1,0) errors : -13667.96\n",
      " Regression with ARIMA(1,1,0) errors : -13665.88\n",
      " Regression with ARIMA(0,1,1) errors : -13666.47\n",
      " Regression with ARIMA(0,1,0) errors : -13669.95\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13678.82\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10272.74\n",
      " Regression with ARIMA(1,0,0) errors : -13772.01\n",
      " Regression with ARIMA(0,0,1) errors : -11891.74\n",
      " Regression with ARIMA(0,0,0) errors : -8843.671\n",
      " Regression with ARIMA(2,0,0) errors : -13770.9\n",
      " Regression with ARIMA(1,0,1) errors : -13771.44\n",
      " Regression with ARIMA(2,0,1) errors : -13785.75\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13772.19\n",
      " Regression with ARIMA(3,0,0) errors : -13772.31\n",
      " Regression with ARIMA(3,0,2) errors : -13785.11\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13783.28\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13764.52\n",
      " Regression with ARIMA(0,0,0) errors : -10268.04\n",
      " Regression with ARIMA(1,0,0) errors : -13761.23\n",
      " Regression with ARIMA(0,0,1) errors : -11885.1\n",
      " Regression with ARIMA(0,0,0) errors : -8858.715\n",
      " Regression with ARIMA(1,0,2) errors : -13761.55\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13782.76\n",
      " Regression with ARIMA(3,0,1) errors : -13780.45\n",
      " Regression with ARIMA(4,0,2) errors : -13778.02\n",
      " Regression with ARIMA(3,0,3) errors : -13780.93\n",
      " Regression with ARIMA(2,0,3) errors : -13762.9\n",
      " Regression with ARIMA(4,0,1) errors : -13774.34\n",
      " Regression with ARIMA(4,0,3) errors : -13775.95\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13775.78\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "[1] \"40 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13769.81\n",
      " Regression with ARIMA(0,0,0) errors : -10265.3\n",
      " Regression with ARIMA(1,0,0) errors : -13762.85\n",
      " Regression with ARIMA(0,0,1) errors : -11881.84\n",
      " Regression with ARIMA(0,0,0) errors : -8821.143\n",
      " Regression with ARIMA(1,0,2) errors : -13762.57\n",
      " Regression with ARIMA(2,0,1) errors : -13768.3\n",
      " Regression with ARIMA(3,0,2) errors : -13783.22\n",
      " Regression with ARIMA(3,0,1) errors : -13768.49\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13781.28\n",
      " Regression with ARIMA(2,0,3) errors : -13768.18\n",
      " Regression with ARIMA(4,0,1) errors : -13769.2\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13777.69\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13769.38\n",
      " Regression with ARIMA(0,0,0) errors : -10260.46\n",
      " Regression with ARIMA(1,0,0) errors : -13763.75\n",
      " Regression with ARIMA(0,0,1) errors : -11877.06\n",
      " Regression with ARIMA(0,0,0) errors : -8820.979\n",
      " Regression with ARIMA(1,0,2) errors : -13763.9\n",
      " Regression with ARIMA(2,0,1) errors : -13767.21\n",
      " Regression with ARIMA(3,0,2) errors : -13781.12\n",
      " Regression with ARIMA(3,0,1) errors : -13768.51\n",
      " Regression with ARIMA(4,0,2) errors : -13781.64\n",
      " Regression with ARIMA(4,0,1) errors : -13767.06\n",
      " Regression with ARIMA(5,0,2) errors : -13779.5\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13781.37\n",
      " Regression with ARIMA(5,0,1) errors : -13775.92\n",
      " Regression with ARIMA(5,0,3) errors : -13777.89\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,2) errors : -13774.84\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13730.6\n",
      " Regression with ARIMA(0,0,0) errors : -10252.14\n",
      " Regression with ARIMA(1,0,0) errors : -13734.15\n",
      " Regression with ARIMA(0,0,1) errors : -11865.14\n",
      " Regression with ARIMA(0,0,0) errors : -8811.741\n",
      " Regression with ARIMA(2,0,0) errors : -13732.86\n",
      " Regression with ARIMA(1,0,1) errors : -13733.55\n",
      " Regression with ARIMA(2,0,1) errors : -13745.03\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13733.84\n",
      " Regression with ARIMA(3,0,0) errors : -13732.77\n",
      " Regression with ARIMA(3,0,2) errors : -13730.31\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13733.34\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10248.64\n",
      " Regression with ARIMA(1,0,0) errors : -13726.11\n",
      " Regression with ARIMA(0,0,1) errors : -11859.38\n",
      " Regression with ARIMA(0,0,0) errors : -8814.75\n",
      " Regression with ARIMA(2,0,0) errors : -13726.2\n",
      " Regression with ARIMA(3,0,0) errors : -13726.52\n",
      " Regression with ARIMA(4,0,0) errors : -13725.54\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : -13736.42\n",
      " Regression with ARIMA(1,0,1) errors : -13725.25\n",
      " Regression with ARIMA(1,0,2) errors : -13725.96\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,0) errors : -13725.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10253.6\n",
      " Regression with ARIMA(1,0,0) errors : -13735.62\n",
      " Regression with ARIMA(0,0,1) errors : -11865.12\n",
      " Regression with ARIMA(0,0,0) errors : -8816.856\n",
      " Regression with ARIMA(2,0,0) errors : -13733.87\n",
      " Regression with ARIMA(1,0,1) errors : -13734.66\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13733.14\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13750.01\n",
      " Regression with ARIMA(0,0,0) errors : -10257.06\n",
      " Regression with ARIMA(1,0,0) errors : -13738.28\n",
      " Regression with ARIMA(0,0,1) errors : -11865.9\n",
      " Regression with ARIMA(0,0,0) errors : -8780.029\n",
      " Regression with ARIMA(1,0,2) errors : -13737.34\n",
      " Regression with ARIMA(2,0,1) errors : -13751.1\n",
      " Regression with ARIMA(1,0,1) errors : -13737.18\n",
      " Regression with ARIMA(2,0,0) errors : -13736.6\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,0) errors : -13736.27\n",
      " Regression with ARIMA(3,0,2) errors : -13732.63\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13735.84\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10256.83\n",
      " Regression with ARIMA(1,0,0) errors : -13730.95\n",
      " Regression with ARIMA(0,0,1) errors : -11861.77\n",
      " Regression with ARIMA(0,0,0) errors : -8779.258\n",
      " Regression with ARIMA(2,0,0) errors : -13729.15\n",
      " Regression with ARIMA(1,0,1) errors : -13729.46\n",
      " Regression with ARIMA(2,0,1) errors : -13743.66\n",
      " Regression with ARIMA(3,0,1) errors : -13740.11\n",
      " Regression with ARIMA(1,0,2) errors : -13729.66\n",
      " Regression with ARIMA(3,0,0) errors : -13731.65\n",
      " Regression with ARIMA(3,0,2) errors : -13742.18\n",
      " Regression with ARIMA(2,0,1) errors : -13618.71\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13744.27\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13704.92\n",
      " Regression with ARIMA(0,0,0) errors : -10273.67\n",
      " Regression with ARIMA(1,0,0) errors : -13706.69\n",
      " Regression with ARIMA(0,0,1) errors : -11878.39\n",
      " Regression with ARIMA(0,0,0) errors : -8797.955\n",
      " Regression with ARIMA(2,0,0) errors : -13704.19\n",
      " Regression with ARIMA(1,0,1) errors : -13704.98\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13577.35\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13704.77\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13513.55\n",
      " Regression with ARIMA(0,0,0) errors : -10068.34\n",
      " Regression with ARIMA(1,0,0) errors : -13520.38\n",
      " Regression with ARIMA(0,0,1) errors : -11654.6\n",
      " Regression with ARIMA(0,0,0) errors : -8614.487\n",
      " Regression with ARIMA(2,0,0) errors : -13517.43\n",
      " Regression with ARIMA(1,0,1) errors : -13518.38\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13517.53\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12970.83\n",
      " Regression with ARIMA(0,1,0) errors : -12930.49\n",
      " Regression with ARIMA(1,1,0) errors : -12945.11\n",
      " Regression with ARIMA(0,1,1) errors : -12947.22\n",
      " Regression with ARIMA(0,1,0) errors : -12932.5\n",
      " Regression with ARIMA(1,1,2) errors : -12962.91\n",
      " Regression with ARIMA(2,1,1) errors : -12971.71\n",
      " Regression with ARIMA(1,1,1) errors : -12955.51\n",
      " Regression with ARIMA(2,1,0) errors : -12969.84\n",
      " Regression with ARIMA(3,1,1) errors : -12974.24\n",
      " Regression with ARIMA(3,1,0) errors : -12974.64\n",
      " Regression with ARIMA(4,1,0) errors : -12978.76\n",
      " Regression with ARIMA(5,1,0) errors : -12976.29\n",
      " Regression with ARIMA(4,1,1) errors : -12976.71\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,0) errors : -12980.76\n",
      " Regression with ARIMA(3,1,0) errors : -12976.65\n",
      " Regression with ARIMA(5,1,0) errors : -12978.28\n",
      " Regression with ARIMA(4,1,1) errors : -12978.77\n",
      " Regression with ARIMA(3,1,1) errors : -12976.24\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,1,0) errors : -12980.2\n",
      "\n",
      " Best model: Regression with ARIMA(4,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12722.08\n",
      " Regression with ARIMA(0,1,0) errors : -12682.87\n",
      " Regression with ARIMA(1,1,0) errors : -12702.85\n",
      " Regression with ARIMA(0,1,1) errors : -12708.6\n",
      " Regression with ARIMA(0,1,0) errors : -12684.84\n",
      " Regression with ARIMA(1,1,2) errors : -12720.75\n",
      " Regression with ARIMA(2,1,1) errors : -12722.99\n",
      " Regression with ARIMA(1,1,1) errors : -12711.35\n",
      " Regression with ARIMA(2,1,0) errors : -12720.41\n",
      " Regression with ARIMA(3,1,1) errors : -12722.13\n",
      " Regression with ARIMA(3,1,0) errors : -12724.07\n",
      " Regression with ARIMA(4,1,0) errors : -12721.18\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -12726.05\n",
      " Regression with ARIMA(2,1,0) errors : -12722.38\n",
      " Regression with ARIMA(4,1,0) errors : -12723.17\n",
      " Regression with ARIMA(3,1,1) errors : -12724.11\n",
      " Regression with ARIMA(2,1,1) errors : -12724.96\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,0) errors : -12736.42\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12560.78\n",
      " Regression with ARIMA(0,1,0) errors : -12505.96\n",
      " Regression with ARIMA(1,1,0) errors : -12527.34\n",
      " Regression with ARIMA(0,1,1) errors : -12533.58\n",
      " Regression with ARIMA(0,1,0) errors : -12507.97\n",
      " Regression with ARIMA(1,1,2) errors : -12551.89\n",
      " Regression with ARIMA(2,1,1) errors : -12557.49\n",
      " Regression with ARIMA(3,1,2) errors : -12557.93\n",
      " Regression with ARIMA(2,1,3) errors : -12558.92\n",
      " Regression with ARIMA(1,1,1) errors : -12537.48\n",
      " Regression with ARIMA(1,1,3) errors : -12554.56\n",
      " Regression with ARIMA(3,1,1) errors : -12557.55\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12562.8\n",
      " Regression with ARIMA(1,1,2) errors : -12553.91\n",
      " Regression with ARIMA(2,1,1) errors : -12559.5\n",
      " Regression with ARIMA(3,1,2) errors : -12559.9\n",
      " Regression with ARIMA(2,1,3) errors : -12560.93\n",
      " Regression with ARIMA(1,1,1) errors : -12539.48\n",
      " Regression with ARIMA(1,1,3) errors : -12556.58\n",
      " Regression with ARIMA(3,1,1) errors : -12559.56\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12572.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12525.75\n",
      " Regression with ARIMA(0,1,0) errors : -12472.26\n",
      " Regression with ARIMA(1,1,0) errors : -12494.36\n",
      " Regression with ARIMA(0,1,1) errors : -12499.92\n",
      " Regression with ARIMA(0,1,0) errors : -12474.27\n",
      " Regression with ARIMA(1,1,2) errors : -12516.93\n",
      " Regression with ARIMA(2,1,1) errors : -12522.47\n",
      " Regression with ARIMA(3,1,2) errors : -12522.7\n",
      " Regression with ARIMA(2,1,3) errors : -12523.75\n",
      " Regression with ARIMA(1,1,1) errors : -12502.95\n",
      " Regression with ARIMA(1,1,3) errors : -12520.19\n",
      " Regression with ARIMA(3,1,1) errors : -12522.74\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12527.77\n",
      " Regression with ARIMA(1,1,2) errors : -12518.94\n",
      " Regression with ARIMA(2,1,1) errors : -12524.48\n",
      " Regression with ARIMA(3,1,2) errors : -12524.7\n",
      " Regression with ARIMA(2,1,3) errors : -12525.77\n",
      " Regression with ARIMA(1,1,1) errors : -12504.95\n",
      " Regression with ARIMA(1,1,3) errors : -12522.21\n",
      " Regression with ARIMA(3,1,1) errors : -12524.75\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12537.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12470.37\n",
      " Regression with ARIMA(0,1,0) errors : -12414.35\n",
      " Regression with ARIMA(1,1,0) errors : -12436.58\n",
      " Regression with ARIMA(0,1,1) errors : -12443.12\n",
      " Regression with ARIMA(0,1,0) errors : -12416.35\n",
      " Regression with ARIMA(1,1,2) errors : -12461.95\n",
      " Regression with ARIMA(2,1,1) errors : -12468.01\n",
      " Regression with ARIMA(3,1,2) errors : -12467.45\n",
      " Regression with ARIMA(2,1,3) errors : -12468.34\n",
      " Regression with ARIMA(1,1,1) errors : -12445.63\n",
      " Regression with ARIMA(1,1,3) errors : -12464.82\n",
      " Regression with ARIMA(3,1,1) errors : -12468.7\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12472.37\n",
      " Regression with ARIMA(1,1,2) errors : -12463.95\n",
      " Regression with ARIMA(2,1,1) errors : -12470\n",
      " Regression with ARIMA(3,1,2) errors : -12469.45\n",
      " Regression with ARIMA(2,1,3) errors : -12470.36\n",
      " Regression with ARIMA(1,1,1) errors : -12447.62\n",
      " Regression with ARIMA(1,1,3) errors : -12466.82\n",
      " Regression with ARIMA(3,1,1) errors : -12470.69\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12481.51\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12415.46\n",
      " Regression with ARIMA(0,1,0) errors : -12357.7\n",
      " Regression with ARIMA(1,1,0) errors : -12377.73\n",
      " Regression with ARIMA(0,1,1) errors : -12382.8\n",
      " Regression with ARIMA(0,1,0) errors : -12359.71\n",
      " Regression with ARIMA(1,1,2) errors : -12397.26\n",
      " Regression with ARIMA(2,1,1) errors : -12405.48\n",
      " Regression with ARIMA(3,1,2) errors : -12413.51\n",
      " Regression with ARIMA(2,1,3) errors : -12414.64\n",
      " Regression with ARIMA(1,1,1) errors : -12383.72\n",
      " Regression with ARIMA(1,1,3) errors : -12404.76\n",
      " Regression with ARIMA(3,1,1) errors : -12410.9\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12417.47\n",
      " Regression with ARIMA(1,1,2) errors : -12399.27\n",
      " Regression with ARIMA(2,1,1) errors : -12407.49\n",
      " Regression with ARIMA(3,1,2) errors : -12415.52\n",
      " Regression with ARIMA(2,1,3) errors : -12416.65\n",
      " Regression with ARIMA(1,1,1) errors : -12385.73\n",
      " Regression with ARIMA(1,1,3) errors : -12406.78\n",
      " Regression with ARIMA(3,1,1) errors : -12412.92\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12422.35\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12392.88\n",
      " Regression with ARIMA(0,1,0) errors : -12334.96\n",
      " Regression with ARIMA(1,1,0) errors : -12358.48\n",
      " Regression with ARIMA(0,1,1) errors : -12364.77\n",
      " Regression with ARIMA(0,1,0) errors : -12336.95\n",
      " Regression with ARIMA(1,1,2) errors : -12380.24\n",
      " Regression with ARIMA(2,1,1) errors : -12390.33\n",
      " Regression with ARIMA(3,1,2) errors : -12392.56\n",
      " Regression with ARIMA(2,1,3) errors : -12390.88\n",
      " Regression with ARIMA(1,1,1) errors : -12366.94\n",
      " Regression with ARIMA(1,1,3) errors : -12386.73\n",
      " Regression with ARIMA(3,1,1) errors : -12394.33\n",
      " Regression with ARIMA(3,1,0) errors : -12396.28\n",
      " Regression with ARIMA(2,1,0) errors : -12381.04\n",
      " Regression with ARIMA(4,1,0) errors : -12409.24\n",
      " Regression with ARIMA(5,1,0) errors : -12418.87\n",
      " Regression with ARIMA(5,1,1) errors : -12429.22\n",
      " Regression with ARIMA(4,1,1) errors : -12408.98\n",
      " Regression with ARIMA(5,1,2) errors : -12419\n",
      " Regression with ARIMA(4,1,2) errors : -12415.77\n",
      " Regression with ARIMA(5,1,1) errors : -12431.1\n",
      " Regression with ARIMA(4,1,1) errors : -12410.99\n",
      " Regression with ARIMA(5,1,0) errors : -12420.89\n",
      " Regression with ARIMA(5,1,2) errors : -12421.01\n",
      " Regression with ARIMA(4,1,0) errors : -12411.25\n",
      " Regression with ARIMA(4,1,2) errors : -12417.78\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,0) errors : -12408.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12405.22\n",
      " Regression with ARIMA(0,1,0) errors : -12342.22\n",
      " Regression with ARIMA(1,1,0) errors : -12369.17\n",
      " Regression with ARIMA(0,1,1) errors : -12375.11\n",
      " Regression with ARIMA(0,1,0) errors : -12344.23\n",
      " Regression with ARIMA(1,1,2) errors : -12390.01\n",
      " Regression with ARIMA(2,1,1) errors : -12397.17\n",
      " Regression with ARIMA(3,1,2) errors : -12404.33\n",
      " Regression with ARIMA(2,1,3) errors : -12403.26\n",
      " Regression with ARIMA(1,1,1) errors : -12376.7\n",
      " Regression with ARIMA(1,1,3) errors : -12397.27\n",
      " Regression with ARIMA(3,1,1) errors : -12402.52\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12407.23\n",
      " Regression with ARIMA(1,1,2) errors : -12392.02\n",
      " Regression with ARIMA(2,1,1) errors : -12399.19\n",
      " Regression with ARIMA(3,1,2) errors : -12406.34\n",
      " Regression with ARIMA(2,1,3) errors : -12405.28\n",
      " Regression with ARIMA(1,1,1) errors : -12378.71\n",
      " Regression with ARIMA(1,1,3) errors : -12399.28\n",
      " Regression with ARIMA(3,1,1) errors : -12404.53\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12418.09\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12479.1\n",
      " Regression with ARIMA(0,0,0) errors : -8904.547\n",
      " Regression with ARIMA(1,0,0) errors : -12457.86\n",
      " Regression with ARIMA(0,0,1) errors : -10586.67\n",
      " Regression with ARIMA(0,0,0) errors : -7757.971\n",
      " Regression with ARIMA(1,0,2) errors : -12470.62\n",
      " Regression with ARIMA(2,0,1) errors : -12467.78\n",
      " Regression with ARIMA(3,0,2) errors : -12535.04\n",
      " Regression with ARIMA(3,0,1) errors : -12486.22\n",
      " Regression with ARIMA(4,0,2) errors : -12504.23\n",
      " Regression with ARIMA(3,0,3) errors : -12504.59\n",
      " Regression with ARIMA(2,0,3) errors : -12501.85\n",
      " Regression with ARIMA(4,0,1) errors : -12505.69\n",
      " Regression with ARIMA(4,0,3) errors : -12533.86\n",
      " Regression with ARIMA(3,0,2) errors : -12438.48\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12506.31\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12465.71\n",
      " Regression with ARIMA(0,0,0) errors : -8892.805\n",
      " Regression with ARIMA(1,0,0) errors : -12446.23\n",
      " Regression with ARIMA(0,0,1) errors : -10571.36\n",
      " Regression with ARIMA(0,0,0) errors : -7709.597\n",
      " Regression with ARIMA(1,0,2) errors : -12458.34\n",
      " Regression with ARIMA(2,0,1) errors : -12455.94\n",
      " Regression with ARIMA(3,0,2) errors : -12524.46\n",
      " Regression with ARIMA(3,0,1) errors : -12471.77\n",
      " Regression with ARIMA(4,0,2) errors : -12490.22\n",
      " Regression with ARIMA(3,0,3) errors : -12489.3\n",
      " Regression with ARIMA(2,0,3) errors : -12488.4\n",
      " Regression with ARIMA(4,0,1) errors : -12491.45\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12529.33\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12465.29\n",
      " Regression with ARIMA(0,0,0) errors : -8894.651\n",
      " Regression with ARIMA(1,0,0) errors : -12445.35\n",
      " Regression with ARIMA(0,0,1) errors : -10573.51\n",
      " Regression with ARIMA(0,0,0) errors : -7703.577\n",
      " Regression with ARIMA(1,0,2) errors : -12457.79\n",
      " Regression with ARIMA(2,0,1) errors : -12455.34\n",
      " Regression with ARIMA(3,0,2) errors : -12521.44\n",
      " Regression with ARIMA(3,0,1) errors : -12471.75\n",
      " Regression with ARIMA(4,0,2) errors : -12489.95\n",
      " Regression with ARIMA(3,0,3) errors : -12489.87\n",
      " Regression with ARIMA(2,0,3) errors : -12487.74\n",
      " Regression with ARIMA(4,0,1) errors : -12490.93\n",
      " Regression with ARIMA(4,0,3) errors : -12517.07\n",
      " Regression with ARIMA(3,0,2) errors : -12443.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12527.75\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12457.74\n",
      " Regression with ARIMA(0,0,0) errors : -8888.053\n",
      " Regression with ARIMA(1,0,0) errors : -12438.77\n",
      " Regression with ARIMA(0,0,1) errors : -10568.72\n",
      " Regression with ARIMA(0,0,0) errors : -7699.325\n",
      " Regression with ARIMA(1,0,2) errors : -12450.59\n",
      " Regression with ARIMA(2,0,1) errors : -12447.71\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12479.45\n",
      " Regression with ARIMA(1,0,3) errors : -12482.41\n",
      " Regression with ARIMA(0,0,3) errors : -11655.39\n",
      " Regression with ARIMA(1,0,4) errors : -12480.42\n",
      " Regression with ARIMA(0,0,2) errors : -11226.37\n",
      " Regression with ARIMA(0,0,4) errors : -11987.9\n",
      " Regression with ARIMA(2,0,4) errors : -12508.61\n",
      " Regression with ARIMA(3,0,4) errors : -12510.98\n",
      " Regression with ARIMA(3,0,3) errors : -12480.89\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12508.89\n",
      " Regression with ARIMA(2,0,5) errors : -12511.16\n",
      " Regression with ARIMA(1,0,5) errors : -12481.3\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12511.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12454.54\n",
      " Regression with ARIMA(0,0,0) errors : -8881.322\n",
      " Regression with ARIMA(1,0,0) errors : -12434.91\n",
      " Regression with ARIMA(0,0,1) errors : -10562.75\n",
      " Regression with ARIMA(0,0,0) errors : -7707.396\n",
      " Regression with ARIMA(1,0,2) errors : -12446.19\n",
      " Regression with ARIMA(2,0,1) errors : -12444.84\n",
      " Regression with ARIMA(3,0,2) errors : -12469.19\n",
      " Regression with ARIMA(3,0,1) errors : -12458.01\n",
      " Regression with ARIMA(4,0,2) errors : -12484.21\n",
      " Regression with ARIMA(4,0,1) errors : -12483.69\n",
      " Regression with ARIMA(5,0,2) errors : -12502.19\n",
      " Regression with ARIMA(5,0,1) errors : -12498.17\n",
      " Regression with ARIMA(5,0,3) errors : -12504.05\n",
      " Regression with ARIMA(4,0,3) errors : -12482.32\n",
      " Regression with ARIMA(5,0,4) errors : -12490.42\n",
      " Regression with ARIMA(4,0,4) errors : -12481.71\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : -12506.66\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12464.6\n",
      " Regression with ARIMA(0,0,0) errors : -8887.118\n",
      " Regression with ARIMA(1,0,0) errors : -12445.24\n",
      " Regression with ARIMA(0,0,1) errors : -10561.18\n",
      " Regression with ARIMA(0,0,0) errors : -7708.215\n",
      " Regression with ARIMA(1,0,2) errors : -12456.91\n",
      " Regression with ARIMA(2,0,1) errors : -12455.73\n",
      " Regression with ARIMA(3,0,2) errors : -12528.24\n",
      " Regression with ARIMA(3,0,1) errors : -12470.67\n",
      " Regression with ARIMA(4,0,2) errors : -12491.02\n",
      " Regression with ARIMA(3,0,3) errors : -12487.94\n",
      " Regression with ARIMA(2,0,3) errors : -12488.17\n",
      " Regression with ARIMA(4,0,1) errors : -12491.62\n",
      " Regression with ARIMA(4,0,3) errors : -12490.61\n",
      " Regression with ARIMA(3,0,2) errors : -12436.46\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12488.78\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12482.33\n",
      " Regression with ARIMA(0,0,0) errors : -8891.815\n",
      " Regression with ARIMA(1,0,0) errors : -12463.17\n",
      " Regression with ARIMA(0,0,1) errors : -10569.71\n",
      " Regression with ARIMA(0,0,0) errors : -7717.256\n",
      " Regression with ARIMA(1,0,2) errors : -12475.08\n",
      " Regression with ARIMA(2,0,1) errors : -12474.77\n",
      " Regression with ARIMA(3,0,2) errors : -12536.91\n",
      " Regression with ARIMA(3,0,1) errors : -12489.05\n",
      " Regression with ARIMA(4,0,2) errors : -12507.21\n",
      " Regression with ARIMA(3,0,3) errors : -12507.02\n",
      " Regression with ARIMA(2,0,3) errors : -12506.61\n",
      " Regression with ARIMA(4,0,1) errors : -12508.71\n",
      " Regression with ARIMA(4,0,3) errors : -12506.62\n",
      " Regression with ARIMA(3,0,2) errors : -12453.39\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12508.55\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "[1] \"50 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12503.57\n",
      " Regression with ARIMA(0,0,0) errors : -8896.241\n",
      " Regression with ARIMA(1,0,0) errors : -12485.86\n",
      " Regression with ARIMA(0,0,1) errors : -10569.77\n",
      " Regression with ARIMA(0,0,0) errors : -7714.817\n",
      " Regression with ARIMA(1,0,2) errors : -12497.82\n",
      " Regression with ARIMA(2,0,1) errors : -12496.35\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12527.94\n",
      " Regression with ARIMA(1,0,3) errors : -12530.81\n",
      " Regression with ARIMA(0,0,3) errors : -11677.03\n",
      " Regression with ARIMA(1,0,4) errors : -12528.79\n",
      " Regression with ARIMA(0,0,2) errors : -11229.55\n",
      " Regression with ARIMA(0,0,4) errors : -12012.79\n",
      " Regression with ARIMA(2,0,4) errors : -12555.48\n",
      " Regression with ARIMA(3,0,4) errors : -12559.17\n",
      " Regression with ARIMA(3,0,3) errors : -12529.19\n",
      " Regression with ARIMA(4,0,4) errors : -12555.94\n",
      " Regression with ARIMA(3,0,5) errors : -12539.67\n",
      " Regression with ARIMA(2,0,5) errors : -12558.37\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -12560.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12499.29\n",
      " Regression with ARIMA(0,0,0) errors : -8896.211\n",
      " Regression with ARIMA(1,0,0) errors : -12479.6\n",
      " Regression with ARIMA(0,0,1) errors : -10569.06\n",
      " Regression with ARIMA(0,0,0) errors : -7726.249\n",
      " Regression with ARIMA(1,0,2) errors : -12491.43\n",
      " Regression with ARIMA(2,0,1) errors : -12490.08\n",
      " Regression with ARIMA(3,0,2) errors : -12549.65\n",
      " Regression with ARIMA(3,0,1) errors : -12505.95\n",
      " Regression with ARIMA(4,0,2) errors : -12523.02\n",
      " Regression with ARIMA(3,0,3) errors : -12522.73\n",
      " Regression with ARIMA(2,0,3) errors : -12520.84\n",
      " Regression with ARIMA(4,0,1) errors : -12524.79\n",
      " Regression with ARIMA(4,0,3) errors : -12548.68\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12521.78\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12522.71\n",
      " Regression with ARIMA(0,0,0) errors : -8912.717\n",
      " Regression with ARIMA(1,0,0) errors : -12499.7\n",
      " Regression with ARIMA(0,0,1) errors : -10598.43\n",
      " Regression with ARIMA(0,0,0) errors : -7791.064\n",
      " Regression with ARIMA(1,0,2) errors : -12511.99\n",
      " Regression with ARIMA(2,0,1) errors : -12511.69\n",
      " Regression with ARIMA(3,0,2) errors : -12565.33\n",
      " Regression with ARIMA(3,0,1) errors : -12529.16\n",
      " Regression with ARIMA(4,0,2) errors : -12545.66\n",
      " Regression with ARIMA(3,0,3) errors : -12545.28\n",
      " Regression with ARIMA(2,0,3) errors : -12543.96\n",
      " Regression with ARIMA(4,0,1) errors : -12547.58\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12526.08\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.95\n",
      " Regression with ARIMA(0,0,0) errors : -8942.089\n",
      " Regression with ARIMA(1,0,0) errors : -12527.3\n",
      " Regression with ARIMA(0,0,1) errors : -10625.79\n",
      " Regression with ARIMA(0,0,0) errors : -7815.365\n",
      " Regression with ARIMA(1,0,2) errors : -12539.1\n",
      " Regression with ARIMA(2,0,1) errors : -12537.44\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12568.26\n",
      " Regression with ARIMA(1,0,3) errors : -12570.63\n",
      " Regression with ARIMA(0,0,3) errors : -11727.96\n",
      " Regression with ARIMA(1,0,4) errors : -12568.62\n",
      " Regression with ARIMA(0,0,2) errors : -11285.05\n",
      " Regression with ARIMA(0,0,4) errors : -12063.02\n",
      " Regression with ARIMA(2,0,4) errors : -12594.01\n",
      " Regression with ARIMA(3,0,4) errors : -12602.32\n",
      " Regression with ARIMA(3,0,3) errors : -12568.74\n",
      " Regression with ARIMA(4,0,4) errors : -12567.01\n",
      " Regression with ARIMA(3,0,5) errors : -12578.76\n",
      " Regression with ARIMA(2,0,5) errors : -12598.99\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12467.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -12600.43\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12532.16\n",
      " Regression with ARIMA(0,0,0) errors : -8934.83\n",
      " Regression with ARIMA(1,0,0) errors : -12512.55\n",
      " Regression with ARIMA(0,0,1) errors : -10617.82\n",
      " Regression with ARIMA(0,0,0) errors : -7779.834\n",
      " Regression with ARIMA(1,0,2) errors : -12525.18\n",
      " Regression with ARIMA(2,0,1) errors : -12523.58\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12554.76\n",
      " Regression with ARIMA(1,0,3) errors : -12557.17\n",
      " Regression with ARIMA(0,0,3) errors : -11723.56\n",
      " Regression with ARIMA(1,0,4) errors : -12555.2\n",
      " Regression with ARIMA(0,0,2) errors : -11272.84\n",
      " Regression with ARIMA(0,0,4) errors : -12053.22\n",
      " Regression with ARIMA(2,0,4) errors : -12583\n",
      " Regression with ARIMA(3,0,4) errors : -12586.36\n",
      " Regression with ARIMA(3,0,3) errors : -12555.78\n",
      " Regression with ARIMA(4,0,4) errors : -12586.4\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12572.16\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12559.34\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,5) errors : -12569.81\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : -12587.09\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12509.71\n",
      " Regression with ARIMA(0,0,0) errors : -8923.006\n",
      " Regression with ARIMA(1,0,0) errors : -12490.06\n",
      " Regression with ARIMA(0,0,1) errors : -10606.06\n",
      " Regression with ARIMA(0,0,0) errors : -7778.001\n",
      " Regression with ARIMA(1,0,2) errors : -12503.3\n",
      " Regression with ARIMA(2,0,1) errors : -12501.4\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12532.82\n",
      " Regression with ARIMA(1,0,3) errors : -12535.75\n",
      " Regression with ARIMA(0,0,3) errors : -11707.59\n",
      " Regression with ARIMA(1,0,4) errors : -12533.75\n",
      " Regression with ARIMA(0,0,2) errors : -11261.54\n",
      " Regression with ARIMA(0,0,4) errors : -12037.84\n",
      " Regression with ARIMA(2,0,4) errors : -12562.35\n",
      " Regression with ARIMA(3,0,4) errors : -12563.64\n",
      " Regression with ARIMA(3,0,3) errors : -12534.12\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12540.3\n",
      " Regression with ARIMA(2,0,5) errors : -12565.8\n",
      " Regression with ARIMA(1,0,5) errors : -12534.53\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12565.48\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12497.83\n",
      " Regression with ARIMA(0,0,0) errors : -8905.257\n",
      " Regression with ARIMA(1,0,0) errors : -12479.66\n",
      " Regression with ARIMA(0,0,1) errors : -10592.39\n",
      " Regression with ARIMA(0,0,0) errors : -7770.197\n",
      " Regression with ARIMA(1,0,2) errors : -12491.59\n",
      " Regression with ARIMA(2,0,1) errors : -12491.59\n",
      " Regression with ARIMA(3,0,2) errors : -12541.44\n",
      " Regression with ARIMA(3,0,1) errors : -12505.67\n",
      " Regression with ARIMA(4,0,2) errors : -12524.33\n",
      " Regression with ARIMA(3,0,3) errors : -12524.65\n",
      " Regression with ARIMA(2,0,3) errors : -12523.33\n",
      " Regression with ARIMA(4,0,1) errors : -12525.8\n",
      " Regression with ARIMA(4,0,3) errors : -12554.64\n",
      " Regression with ARIMA(5,0,3) errors : -12551.24\n",
      " Regression with ARIMA(4,0,4) errors : -12549.94\n",
      " Regression with ARIMA(3,0,4) errors : -12553.02\n",
      " Regression with ARIMA(5,0,2) errors : -12548.7\n",
      " Regression with ARIMA(5,0,4) errors : -12528.29\n",
      " Regression with ARIMA(4,0,3) errors : -12482.77\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12554.1\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12497.83\n",
      " Regression with ARIMA(0,0,0) errors : -8898.064\n",
      " Regression with ARIMA(1,0,0) errors : -12477.67\n",
      " Regression with ARIMA(0,0,1) errors : -10586.17\n",
      " Regression with ARIMA(0,0,0) errors : -7763.444\n",
      " Regression with ARIMA(1,0,2) errors : -12489.24\n",
      " Regression with ARIMA(2,0,1) errors : -12490.62\n",
      " Regression with ARIMA(3,0,2) errors : -12555.3\n",
      " Regression with ARIMA(3,0,1) errors : -12503.83\n",
      " Regression with ARIMA(4,0,2) errors : -12522.97\n",
      " Regression with ARIMA(3,0,3) errors : -12522.77\n",
      " Regression with ARIMA(2,0,3) errors : -12522.46\n",
      " Regression with ARIMA(4,0,1) errors : -12524.5\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12474.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12523.61\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12513.83\n",
      " Regression with ARIMA(0,0,0) errors : -8943.164\n",
      " Regression with ARIMA(1,0,0) errors : -12488.42\n",
      " Regression with ARIMA(0,0,1) errors : -10621.1\n",
      " Regression with ARIMA(0,0,0) errors : -7868.129\n",
      " Regression with ARIMA(1,0,2) errors : -12499.53\n",
      " Regression with ARIMA(2,0,1) errors : -12510\n",
      " Regression with ARIMA(3,0,2) errors : -12538.21\n",
      " Regression with ARIMA(3,0,1) errors : -12522.06\n",
      " Regression with ARIMA(4,0,2) errors : -12545.22\n",
      " Regression with ARIMA(4,0,1) errors : -12546.86\n",
      " Regression with ARIMA(4,0,0) errors : -12546.27\n",
      " Regression with ARIMA(5,0,1) errors : -12549.63\n",
      " Regression with ARIMA(5,0,0) errors : -12550.19\n",
      " Regression with ARIMA(5,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,0) errors : -12530.49\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12537.41\n",
      " Regression with ARIMA(0,0,0) errors : -8980.404\n",
      " Regression with ARIMA(1,0,0) errors : -12515.87\n",
      " Regression with ARIMA(0,0,1) errors : -10652.29\n",
      " Regression with ARIMA(0,0,0) errors : -7878.327\n",
      " Regression with ARIMA(1,0,2) errors : -12530.48\n",
      " Regression with ARIMA(2,0,1) errors : -12528.68\n",
      " Regression with ARIMA(3,0,2) errors : -12554.48\n",
      " Regression with ARIMA(3,0,1) errors : -12543.44\n",
      " Regression with ARIMA(4,0,2) errors : -12559.77\n",
      " Regression with ARIMA(4,0,1) errors : -12561.17\n",
      " Regression with ARIMA(4,0,0) errors : -12562.64\n",
      " Regression with ARIMA(3,0,0) errors : -12534.45\n",
      " Regression with ARIMA(5,0,0) errors : -12560.32\n",
      " Regression with ARIMA(5,0,1) errors : -12583.89\n",
      " Regression with ARIMA(5,0,2) errors : -12582.7\n",
      " Regression with ARIMA(5,0,1) errors : -12494.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12584.44\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.24\n",
      " Regression with ARIMA(0,0,0) errors : -8985.481\n",
      " Regression with ARIMA(1,0,0) errors : -12523.97\n",
      " Regression with ARIMA(0,0,1) errors : -10655.97\n",
      " Regression with ARIMA(0,0,0) errors : -7884.878\n",
      " Regression with ARIMA(1,0,2) errors : -12538.88\n",
      " Regression with ARIMA(2,0,1) errors : -12537.23\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12566.95\n",
      " Regression with ARIMA(1,0,3) errors : -12569.82\n",
      " Regression with ARIMA(0,0,3) errors : -11754.84\n",
      " Regression with ARIMA(1,0,4) errors : -12567.97\n",
      " Regression with ARIMA(0,0,2) errors : -11299.19\n",
      " Regression with ARIMA(0,0,4) errors : -12073.38\n",
      " Regression with ARIMA(2,0,4) errors : -12592.97\n",
      " Regression with ARIMA(3,0,4) errors : -12597.31\n",
      " Regression with ARIMA(3,0,3) errors : -12567.29\n",
      " Regression with ARIMA(4,0,4) errors : -12596.6\n",
      " Regression with ARIMA(3,0,5) errors : -12570.58\n",
      " Regression with ARIMA(2,0,5) errors : -12597.68\n",
      " Regression with ARIMA(1,0,5) errors : -12568.02\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12597.69\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12546.78\n",
      " Regression with ARIMA(0,0,0) errors : -8970.223\n",
      " Regression with ARIMA(1,0,0) errors : -12525.95\n",
      " Regression with ARIMA(0,0,1) errors : -10649.53\n",
      " Regression with ARIMA(0,0,0) errors : -7878.626\n",
      " Regression with ARIMA(1,0,2) errors : -12540.83\n",
      " Regression with ARIMA(2,0,1) errors : -12539.25\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12568.27\n",
      " Regression with ARIMA(1,0,3) errors : -12571.19\n",
      " Regression with ARIMA(0,0,3) errors : -11751.13\n",
      " Regression with ARIMA(1,0,4) errors : -12569.31\n",
      " Regression with ARIMA(0,0,2) errors : -11296.38\n",
      " Regression with ARIMA(0,0,4) errors : -12067\n",
      " Regression with ARIMA(2,0,4) errors : -12594.34\n",
      " Regression with ARIMA(3,0,4) errors : -12595.54\n",
      " Regression with ARIMA(3,0,3) errors : -12568.5\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12574.84\n",
      " Regression with ARIMA(2,0,5) errors : -12598.8\n",
      " Regression with ARIMA(1,0,5) errors : -12569.08\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12597.59\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.79\n",
      " Regression with ARIMA(0,0,0) errors : -8964.909\n",
      " Regression with ARIMA(1,0,0) errors : -12525.68\n",
      " Regression with ARIMA(0,0,1) errors : -10646.25\n",
      " Regression with ARIMA(0,0,0) errors : -7885.222\n",
      " Regression with ARIMA(1,0,2) errors : -12540.83\n",
      " Regression with ARIMA(2,0,1) errors : -12539.59\n",
      " Regression with ARIMA(3,0,2) errors : -12603.07\n",
      " Regression with ARIMA(3,0,1) errors : -12554.12\n",
      " Regression with ARIMA(4,0,2) errors : -12569.57\n",
      " Regression with ARIMA(3,0,3) errors : -12569.71\n",
      " Regression with ARIMA(2,0,3) errors : -12568.45\n",
      " Regression with ARIMA(4,0,1) errors : -12570.93\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12494.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12570.9\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12548.69\n",
      " Regression with ARIMA(0,0,0) errors : -8959.862\n",
      " Regression with ARIMA(1,0,0) errors : -12529.05\n",
      " Regression with ARIMA(0,0,1) errors : -10643.71\n",
      " Regression with ARIMA(0,0,0) errors : -7886.635\n",
      " Regression with ARIMA(1,0,2) errors : -12544.11\n",
      " Regression with ARIMA(2,0,1) errors : -12544.13\n",
      " Regression with ARIMA(3,0,2) errors : -12571.06\n",
      " Regression with ARIMA(3,0,1) errors : -12561.51\n",
      " Regression with ARIMA(4,0,2) errors : -12576.07\n",
      " Regression with ARIMA(4,0,1) errors : -12578.07\n",
      " Regression with ARIMA(4,0,0) errors : -12579.62\n",
      " Regression with ARIMA(3,0,0) errors : -12551.25\n",
      " Regression with ARIMA(5,0,0) errors : -12579.64\n",
      " Regression with ARIMA(5,0,1) errors : Inf\n",
      " Regression with ARIMA(5,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,0) errors : -12575.23\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12551.97\n",
      " Regression with ARIMA(0,0,0) errors : -8967.683\n",
      " Regression with ARIMA(1,0,0) errors : -12529.69\n",
      " Regression with ARIMA(0,0,1) errors : -10653.67\n",
      " Regression with ARIMA(0,0,0) errors : -7896.484\n",
      " Regression with ARIMA(1,0,2) errors : -12544.97\n",
      " Regression with ARIMA(2,0,1) errors : -12543.7\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12573.37\n",
      " Regression with ARIMA(1,0,3) errors : -12575.68\n",
      " Regression with ARIMA(0,0,3) errors : -11753.95\n",
      " Regression with ARIMA(1,0,4) errors : -12573.8\n",
      " Regression with ARIMA(0,0,2) errors : -11300.67\n",
      " Regression with ARIMA(0,0,4) errors : -12074.69\n",
      " Regression with ARIMA(2,0,4) errors : -12591.45\n",
      " Regression with ARIMA(3,0,4) errors : -12595.99\n",
      " Regression with ARIMA(3,0,3) errors : -12573.8\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12580.86\n",
      " Regression with ARIMA(2,0,5) errors : -12597\n",
      " Regression with ARIMA(1,0,5) errors : -12573.86\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12603.04\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12556.25\n",
      " Regression with ARIMA(0,0,0) errors : -8962.755\n",
      " Regression with ARIMA(1,0,0) errors : -12535.8\n",
      " Regression with ARIMA(0,0,1) errors : -10648.64\n",
      " Regression with ARIMA(0,0,0) errors : -7898.839\n",
      " Regression with ARIMA(1,0,2) errors : -12550.14\n",
      " Regression with ARIMA(2,0,1) errors : -12548.54\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12578.72\n",
      " Regression with ARIMA(1,0,3) errors : -12581.63\n",
      " Regression with ARIMA(0,0,3) errors : -11752.88\n",
      " Regression with ARIMA(1,0,4) errors : -12579.7\n",
      " Regression with ARIMA(0,0,2) errors : -11299.22\n",
      " Regression with ARIMA(0,0,4) errors : -12072.91\n",
      " Regression with ARIMA(2,0,4) errors : -12605.06\n",
      " Regression with ARIMA(3,0,4) errors : -12603.2\n",
      " Regression with ARIMA(2,0,5) errors : -12609.26\n",
      " Regression with ARIMA(1,0,5) errors : -12579.72\n",
      " Regression with ARIMA(3,0,5) errors : -12582.04\n",
      " Regression with ARIMA(2,0,5) errors : -12540.55\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12607.82\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12570.6\n",
      " Regression with ARIMA(0,0,0) errors : -8967.56\n",
      " Regression with ARIMA(1,0,0) errors : -12549.25\n",
      " Regression with ARIMA(0,0,1) errors : -10654.34\n",
      " Regression with ARIMA(0,0,0) errors : -7906.854\n",
      " Regression with ARIMA(1,0,2) errors : -12564.03\n",
      " Regression with ARIMA(2,0,1) errors : -12563.91\n",
      " Regression with ARIMA(3,0,2) errors : -12627.87\n",
      " Regression with ARIMA(3,0,1) errors : -12577.27\n",
      " Regression with ARIMA(4,0,2) errors : -12593.34\n",
      " Regression with ARIMA(3,0,3) errors : -12593.82\n",
      " Regression with ARIMA(2,0,3) errors : -12593.22\n",
      " Regression with ARIMA(4,0,1) errors : -12594.72\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12522.09\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12594.39\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12576.56\n",
      " Regression with ARIMA(0,0,0) errors : -8968.532\n",
      " Regression with ARIMA(1,0,0) errors : -12555.14\n",
      " Regression with ARIMA(0,0,1) errors : -10657.19\n",
      " Regression with ARIMA(0,0,0) errors : -7936.331\n",
      " Regression with ARIMA(1,0,2) errors : -12569.91\n",
      " Regression with ARIMA(2,0,1) errors : -12570.88\n",
      " Regression with ARIMA(3,0,2) errors : -12594.83\n",
      " Regression with ARIMA(3,0,1) errors : -12583.62\n",
      " Regression with ARIMA(4,0,2) errors : -12601.21\n",
      " Regression with ARIMA(4,0,1) errors : -12602.62\n",
      " Regression with ARIMA(4,0,0) errors : -12603.98\n",
      " Regression with ARIMA(3,0,0) errors : -12574.44\n",
      " Regression with ARIMA(5,0,0) errors : -12601.82\n",
      " Regression with ARIMA(5,0,1) errors : -12626.33\n",
      " Regression with ARIMA(5,0,2) errors : -12625.22\n",
      " Regression with ARIMA(5,0,1) errors : -12547.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12620.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12601.85\n",
      " Regression with ARIMA(0,0,0) errors : -9048.224\n",
      " Regression with ARIMA(1,0,0) errors : -12582.93\n",
      " Regression with ARIMA(0,0,1) errors : -10732.82\n",
      " Regression with ARIMA(0,0,0) errors : -8067.123\n",
      " Regression with ARIMA(1,0,2) errors : -12598.44\n",
      " Regression with ARIMA(2,0,1) errors : -12601.12\n",
      " Regression with ARIMA(3,0,2) errors : -12619.05\n",
      " Regression with ARIMA(3,0,1) errors : -12618.74\n",
      " Regression with ARIMA(4,0,2) errors : -12650.56\n",
      " Regression with ARIMA(4,0,1) errors : -12652.27\n",
      " Regression with ARIMA(4,0,0) errors : -12652.06\n",
      " Regression with ARIMA(5,0,1) errors : -12662.55\n",
      " Regression with ARIMA(5,0,0) errors : -12658.45\n",
      " Regression with ARIMA(5,0,2) errors : -12663.08\n",
      " Regression with ARIMA(5,0,3) errors : -12661.14\n",
      " Regression with ARIMA(4,0,3) errors : -12649.44\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -12652.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12607.62\n",
      " Regression with ARIMA(0,0,0) errors : -9029.222\n",
      " Regression with ARIMA(1,0,0) errors : -12581.78\n",
      " Regression with ARIMA(0,0,1) errors : -10679.8\n",
      " Regression with ARIMA(0,0,0) errors : -7988.616\n",
      " Regression with ARIMA(1,0,2) errors : -12606.76\n",
      " Regression with ARIMA(2,0,1) errors : -12606.03\n",
      " Regression with ARIMA(3,0,2) errors : -12633.3\n",
      " Regression with ARIMA(3,0,1) errors : -12616.63\n",
      " Regression with ARIMA(4,0,2) errors : -12637.18\n",
      " Regression with ARIMA(4,0,1) errors : -12639.14\n",
      " Regression with ARIMA(4,0,0) errors : -12638.63\n",
      " Regression with ARIMA(5,0,1) errors : -12657.77\n",
      " Regression with ARIMA(5,0,0) errors : -12639.34\n",
      " Regression with ARIMA(5,0,2) errors : -12656.11\n",
      " Regression with ARIMA(5,0,1) errors : -12576.93\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12665.38\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12515.14\n",
      " Regression with ARIMA(0,1,0) errors : -12443.47\n",
      " Regression with ARIMA(1,1,0) errors : -12487.68\n",
      " Regression with ARIMA(0,1,1) errors : -12495.53\n",
      " Regression with ARIMA(0,1,0) errors : -12445.47\n",
      " Regression with ARIMA(1,1,2) errors : -12499.79\n",
      " Regression with ARIMA(2,1,1) errors : -12505.72\n",
      " Regression with ARIMA(3,1,2) errors : -12545.83\n",
      " Regression with ARIMA(3,1,1) errors : -12512.71\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -12547.75\n",
      " Regression with ARIMA(2,1,2) errors : -12517.15\n",
      " Regression with ARIMA(3,1,1) errors : -12514.72\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -12507.73\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12527.28\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12606.67\n",
      " Regression with ARIMA(0,0,0) errors : -9078.123\n",
      " Regression with ARIMA(1,0,0) errors : -12575.25\n",
      " Regression with ARIMA(0,0,1) errors : -10725.64\n",
      " Regression with ARIMA(0,0,0) errors : -8063.193\n",
      " Regression with ARIMA(1,0,2) errors : -12597.15\n",
      " Regression with ARIMA(2,0,1) errors : -12601.19\n",
      " Regression with ARIMA(3,0,2) errors : -12625.54\n",
      " Regression with ARIMA(3,0,1) errors : -12611.94\n",
      " Regression with ARIMA(4,0,2) errors : -12627.49\n",
      " Regression with ARIMA(4,0,1) errors : -12627.75\n",
      " Regression with ARIMA(4,0,0) errors : -12627.47\n",
      " Regression with ARIMA(5,0,1) errors : -12646.75\n",
      " Regression with ARIMA(5,0,0) errors : -12630.02\n",
      " Regression with ARIMA(5,0,2) errors : -12645.2\n",
      " Regression with ARIMA(5,0,1) errors : -12548.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12650.4\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12592.63\n",
      " Regression with ARIMA(0,0,0) errors : -9082.048\n",
      " Regression with ARIMA(1,0,0) errors : -12566.66\n",
      " Regression with ARIMA(0,0,1) errors : -10726.09\n",
      " Regression with ARIMA(0,0,0) errors : -8059.077\n",
      " Regression with ARIMA(1,0,2) errors : -12588.96\n",
      " Regression with ARIMA(2,0,1) errors : -12589.11\n",
      " Regression with ARIMA(3,0,2) errors : -12638.23\n",
      " Regression with ARIMA(3,0,1) errors : -12600.16\n",
      " Regression with ARIMA(4,0,2) errors : -12617.62\n",
      " Regression with ARIMA(3,0,3) errors : -12618.48\n",
      " Regression with ARIMA(2,0,3) errors : -12614.14\n",
      " Regression with ARIMA(4,0,1) errors : -12616.7\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12548.15\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12652.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12584\n",
      " Regression with ARIMA(0,0,0) errors : -9072.623\n",
      " Regression with ARIMA(1,0,0) errors : -12558.92\n",
      " Regression with ARIMA(0,0,1) errors : -10724.45\n",
      " Regression with ARIMA(0,0,0) errors : -8059.797\n",
      " Regression with ARIMA(1,0,2) errors : -12579.62\n",
      " Regression with ARIMA(2,0,1) errors : -12579.45\n",
      " Regression with ARIMA(3,0,2) errors : -12637.15\n",
      " Regression with ARIMA(3,0,1) errors : -12590.09\n",
      " Regression with ARIMA(4,0,2) errors : -12609.14\n",
      " Regression with ARIMA(3,0,3) errors : -12608.81\n",
      " Regression with ARIMA(2,0,3) errors : -12605.33\n",
      " Regression with ARIMA(4,0,1) errors : -12609.45\n",
      " Regression with ARIMA(4,0,3) errors : -12638.04\n",
      " Regression with ARIMA(5,0,3) errors : -12624.89\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12633.6\n",
      " Regression with ARIMA(5,0,2) errors : -12623.44\n",
      " Regression with ARIMA(5,0,4) errors : -12618.15\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12645.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "[1] \"60 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12597.56\n",
      " Regression with ARIMA(0,0,0) errors : -9087.133\n",
      " Regression with ARIMA(1,0,0) errors : -12572.15\n",
      " Regression with ARIMA(0,0,1) errors : -10736.93\n",
      " Regression with ARIMA(0,0,0) errors : -8079.117\n",
      " Regression with ARIMA(1,0,2) errors : -12594.14\n",
      " Regression with ARIMA(2,0,1) errors : -12593.03\n",
      " Regression with ARIMA(3,0,2) errors : -12658.36\n",
      " Regression with ARIMA(3,0,1) errors : -12603.77\n",
      " Regression with ARIMA(4,0,2) errors : -12622.07\n",
      " Regression with ARIMA(3,0,3) errors : -12622.59\n",
      " Regression with ARIMA(2,0,3) errors : -12619.12\n",
      " Regression with ARIMA(4,0,1) errors : -12620.82\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12548.61\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12655.81\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12610.85\n",
      " Regression with ARIMA(0,0,0) errors : -9095.509\n",
      " Regression with ARIMA(1,0,0) errors : -12584.86\n",
      " Regression with ARIMA(0,0,1) errors : -10749.33\n",
      " Regression with ARIMA(0,0,0) errors : -8097.852\n",
      " Regression with ARIMA(1,0,2) errors : -12606.97\n",
      " Regression with ARIMA(2,0,1) errors : -12608.39\n",
      " Regression with ARIMA(3,0,2) errors : -12658.34\n",
      " Regression with ARIMA(3,0,1) errors : -12619.38\n",
      " Regression with ARIMA(4,0,2) errors : -12636.67\n",
      " Regression with ARIMA(3,0,3) errors : -12637.2\n",
      " Regression with ARIMA(2,0,3) errors : -12634.49\n",
      " Regression with ARIMA(4,0,1) errors : -12636.79\n",
      " Regression with ARIMA(4,0,3) errors : -12679.01\n",
      " Regression with ARIMA(5,0,3) errors : -12665.31\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12669.72\n",
      " Regression with ARIMA(5,0,2) errors : -12665.96\n",
      " Regression with ARIMA(5,0,4) errors : -12644.1\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12661.83\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.42\n",
      " Regression with ARIMA(0,0,0) errors : -9117.955\n",
      " Regression with ARIMA(1,0,0) errors : -12604.61\n",
      " Regression with ARIMA(0,0,1) errors : -10769.78\n",
      " Regression with ARIMA(0,0,0) errors : -8106.906\n",
      " Regression with ARIMA(1,0,2) errors : -12626.91\n",
      " Regression with ARIMA(2,0,1) errors : -12625.67\n",
      " Regression with ARIMA(3,0,2) errors : -12690.09\n",
      " Regression with ARIMA(3,0,1) errors : -12637.43\n",
      " Regression with ARIMA(4,0,2) errors : -12655.81\n",
      " Regression with ARIMA(3,0,3) errors : -12655.49\n",
      " Regression with ARIMA(2,0,3) errors : -12652.79\n",
      " Regression with ARIMA(4,0,1) errors : -12654.8\n",
      " Regression with ARIMA(4,0,3) errors : -12693.24\n",
      " Regression with ARIMA(5,0,3) errors : -12662.02\n",
      " Regression with ARIMA(4,0,4) errors : -12671.03\n",
      " Regression with ARIMA(3,0,4) errors : -12677.48\n",
      " Regression with ARIMA(5,0,2) errors : -12662.99\n",
      " Regression with ARIMA(5,0,4) errors : -12675.56\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12692.59\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12641.13\n",
      " Regression with ARIMA(0,0,0) errors : -9120.512\n",
      " Regression with ARIMA(1,0,0) errors : -12614.69\n",
      " Regression with ARIMA(0,0,1) errors : -10777.29\n",
      " Regression with ARIMA(0,0,0) errors : -8113.97\n",
      " Regression with ARIMA(1,0,2) errors : -12636.3\n",
      " Regression with ARIMA(2,0,1) errors : -12634.97\n",
      " Regression with ARIMA(3,0,2) errors : -12703.57\n",
      " Regression with ARIMA(3,0,1) errors : -12648.05\n",
      " Regression with ARIMA(4,0,2) errors : -12667.51\n",
      " Regression with ARIMA(3,0,3) errors : -12666.81\n",
      " Regression with ARIMA(2,0,3) errors : -12663.2\n",
      " Regression with ARIMA(4,0,1) errors : -12665.98\n",
      " Regression with ARIMA(4,0,3) errors : -12703.17\n",
      " Regression with ARIMA(3,0,2) errors : -12608.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.93\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12643.6\n",
      " Regression with ARIMA(0,0,0) errors : -9119.216\n",
      " Regression with ARIMA(1,0,0) errors : -12616.26\n",
      " Regression with ARIMA(0,0,1) errors : -10777.52\n",
      " Regression with ARIMA(0,0,0) errors : -8101.041\n",
      " Regression with ARIMA(1,0,2) errors : -12637.47\n",
      " Regression with ARIMA(2,0,1) errors : -12640.52\n",
      " Regression with ARIMA(3,0,2) errors : -12680.71\n",
      " Regression with ARIMA(3,0,1) errors : -12652.57\n",
      " Regression with ARIMA(4,0,2) errors : -12672.29\n",
      " Regression with ARIMA(3,0,3) errors : -12671.04\n",
      " Regression with ARIMA(2,0,3) errors : -12668.46\n",
      " Regression with ARIMA(4,0,1) errors : -12671.99\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12605.13\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12704.4\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12641.82\n",
      " Regression with ARIMA(0,0,0) errors : -9125.129\n",
      " Regression with ARIMA(1,0,0) errors : -12617.13\n",
      " Regression with ARIMA(0,0,1) errors : -10783.88\n",
      " Regression with ARIMA(0,0,0) errors : -8122.685\n",
      " Regression with ARIMA(1,0,2) errors : -12638.09\n",
      " Regression with ARIMA(2,0,1) errors : -12636.93\n",
      " Regression with ARIMA(3,0,2) errors : -12695.39\n",
      " Regression with ARIMA(3,0,1) errors : -12649.51\n",
      " Regression with ARIMA(4,0,2) errors : -12667.03\n",
      " Regression with ARIMA(3,0,3) errors : -12667.49\n",
      " Regression with ARIMA(2,0,3) errors : -12664.06\n",
      " Regression with ARIMA(4,0,1) errors : -12666.82\n",
      " Regression with ARIMA(4,0,3) errors : -12707.83\n",
      " Regression with ARIMA(5,0,3) errors : -12686.77\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12686.56\n",
      " Regression with ARIMA(5,0,2) errors : -12685.94\n",
      " Regression with ARIMA(5,0,4) errors : -12670.08\n",
      " Regression with ARIMA(4,0,3) errors : -12637.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12704.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12640.83\n",
      " Regression with ARIMA(0,0,0) errors : -9124.201\n",
      " Regression with ARIMA(1,0,0) errors : -12614.79\n",
      " Regression with ARIMA(0,0,1) errors : -10783.44\n",
      " Regression with ARIMA(0,0,0) errors : -8122.209\n",
      " Regression with ARIMA(1,0,2) errors : -12635.64\n",
      " Regression with ARIMA(2,0,1) errors : -12634.86\n",
      " Regression with ARIMA(3,0,2) errors : -12695.41\n",
      " Regression with ARIMA(3,0,1) errors : -12647.57\n",
      " Regression with ARIMA(4,0,2) errors : -12665.91\n",
      " Regression with ARIMA(3,0,3) errors : -12665.62\n",
      " Regression with ARIMA(2,0,3) errors : -12662.3\n",
      " Regression with ARIMA(4,0,1) errors : -12664.73\n",
      " Regression with ARIMA(4,0,3) errors : -12708.36\n",
      " Regression with ARIMA(5,0,3) errors : -12683.74\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12676.17\n",
      " Regression with ARIMA(4,0,3) errors : -12636.53\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12702.9\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.35\n",
      " Regression with ARIMA(0,0,0) errors : -9121.854\n",
      " Regression with ARIMA(1,0,0) errors : -12613.51\n",
      " Regression with ARIMA(0,0,1) errors : -10782.18\n",
      " Regression with ARIMA(0,0,0) errors : -8117.61\n",
      " Regression with ARIMA(1,0,2) errors : -12633.27\n",
      " Regression with ARIMA(2,0,1) errors : -12632.06\n",
      " Regression with ARIMA(3,0,2) errors : -12698.45\n",
      " Regression with ARIMA(3,0,1) errors : -12643.7\n",
      " Regression with ARIMA(4,0,2) errors : -12660.83\n",
      " Regression with ARIMA(3,0,3) errors : -12661.66\n",
      " Regression with ARIMA(2,0,3) errors : -12658.11\n",
      " Regression with ARIMA(4,0,1) errors : -12659.62\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12597.25\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12700.82\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.09\n",
      " Regression with ARIMA(0,0,0) errors : -9116.676\n",
      " Regression with ARIMA(1,0,0) errors : -12611.67\n",
      " Regression with ARIMA(0,0,1) errors : -10780.74\n",
      " Regression with ARIMA(0,0,0) errors : -8116.581\n",
      " Regression with ARIMA(1,0,2) errors : -12630.99\n",
      " Regression with ARIMA(2,0,1) errors : -12629.63\n",
      " Regression with ARIMA(3,0,2) errors : -12699.18\n",
      " Regression with ARIMA(3,0,1) errors : -12641.18\n",
      " Regression with ARIMA(4,0,2) errors : -12658.75\n",
      " Regression with ARIMA(3,0,3) errors : -12659.44\n",
      " Regression with ARIMA(2,0,3) errors : -12655.65\n",
      " Regression with ARIMA(4,0,1) errors : -12657.53\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12615.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12699.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12639.03\n",
      " Regression with ARIMA(0,0,0) errors : -9117.537\n",
      " Regression with ARIMA(1,0,0) errors : -12615.18\n",
      " Regression with ARIMA(0,0,1) errors : -10783.7\n",
      " Regression with ARIMA(0,0,0) errors : -8118.136\n",
      " Regression with ARIMA(1,0,2) errors : -12634.65\n",
      " Regression with ARIMA(2,0,1) errors : -12633.24\n",
      " Regression with ARIMA(3,0,2) errors : -12699.98\n",
      " Regression with ARIMA(3,0,1) errors : -12645.33\n",
      " Regression with ARIMA(4,0,2) errors : -12662.46\n",
      " Regression with ARIMA(3,0,3) errors : -12663.29\n",
      " Regression with ARIMA(2,0,3) errors : -12659.28\n",
      " Regression with ARIMA(4,0,1) errors : -12661.46\n",
      " Regression with ARIMA(4,0,3) errors : -12704.33\n",
      " Regression with ARIMA(5,0,3) errors : -12680.72\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12676.03\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12672.54\n",
      " Regression with ARIMA(4,0,3) errors : -12599.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12703.36\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.78\n",
      " Regression with ARIMA(0,0,0) errors : -9113.603\n",
      " Regression with ARIMA(1,0,0) errors : -12610.36\n",
      " Regression with ARIMA(0,0,1) errors : -10781.97\n",
      " Regression with ARIMA(0,0,0) errors : -8111.354\n",
      " Regression with ARIMA(1,0,2) errors : -12629.21\n",
      " Regression with ARIMA(2,0,1) errors : -12627.93\n",
      " Regression with ARIMA(3,0,2) errors : -12693.18\n",
      " Regression with ARIMA(3,0,1) errors : -12639.63\n",
      " Regression with ARIMA(4,0,2) errors : -12657.34\n",
      " Regression with ARIMA(3,0,3) errors : -12657.78\n",
      " Regression with ARIMA(2,0,3) errors : -12654.23\n",
      " Regression with ARIMA(4,0,1) errors : -12656.4\n",
      " Regression with ARIMA(4,0,3) errors : -12699.31\n",
      " Regression with ARIMA(5,0,3) errors : -12674.55\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12675.54\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12667.95\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.07\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.46\n",
      " Regression with ARIMA(0,0,0) errors : -9119.245\n",
      " Regression with ARIMA(1,0,0) errors : -12613.96\n",
      " Regression with ARIMA(0,0,1) errors : -10785.81\n",
      " Regression with ARIMA(0,0,0) errors : -8116.382\n",
      " Regression with ARIMA(1,0,2) errors : -12632.76\n",
      " Regression with ARIMA(2,0,1) errors : -12631.28\n",
      " Regression with ARIMA(3,0,2) errors : -12700.56\n",
      " Regression with ARIMA(3,0,1) errors : -12643.51\n",
      " Regression with ARIMA(4,0,2) errors : -12660.35\n",
      " Regression with ARIMA(3,0,3) errors : -12660.75\n",
      " Regression with ARIMA(2,0,3) errors : -12657.34\n",
      " Regression with ARIMA(4,0,1) errors : -12659.28\n",
      " Regression with ARIMA(4,0,3) errors : -12705.25\n",
      " Regression with ARIMA(5,0,3) errors : -12677.25\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12659.26\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12674.2\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12701.28\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.91\n",
      " Regression with ARIMA(0,0,0) errors : -9115.346\n",
      " Regression with ARIMA(1,0,0) errors : -12609.25\n",
      " Regression with ARIMA(0,0,1) errors : -10783.59\n",
      " Regression with ARIMA(0,0,0) errors : -8119.022\n",
      " Regression with ARIMA(1,0,2) errors : -12628.07\n",
      " Regression with ARIMA(2,0,1) errors : -12626.55\n",
      " Regression with ARIMA(3,0,2) errors : -12695.08\n",
      " Regression with ARIMA(3,0,1) errors : -12639.09\n",
      " Regression with ARIMA(4,0,2) errors : -12655.57\n",
      " Regression with ARIMA(3,0,3) errors : -12655.97\n",
      " Regression with ARIMA(2,0,3) errors : -12652.64\n",
      " Regression with ARIMA(4,0,1) errors : -12654.48\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12608.86\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12697.61\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12634.77\n",
      " Regression with ARIMA(0,0,0) errors : -9112.722\n",
      " Regression with ARIMA(1,0,0) errors : -12611.67\n",
      " Regression with ARIMA(0,0,1) errors : -10782.69\n",
      " Regression with ARIMA(0,0,0) errors : -8118.407\n",
      " Regression with ARIMA(1,0,2) errors : -12630.3\n",
      " Regression with ARIMA(2,0,1) errors : -12628.79\n",
      " Regression with ARIMA(3,0,2) errors : -12698.97\n",
      " Regression with ARIMA(3,0,1) errors : -12640.78\n",
      " Regression with ARIMA(4,0,2) errors : -12656.92\n",
      " Regression with ARIMA(3,0,3) errors : -12657.7\n",
      " Regression with ARIMA(2,0,3) errors : -12654.48\n",
      " Regression with ARIMA(4,0,1) errors : -12655.94\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12604.1\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12699.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.36\n",
      " Regression with ARIMA(0,0,0) errors : -9119.25\n",
      " Regression with ARIMA(1,0,0) errors : -12613.66\n",
      " Regression with ARIMA(0,0,1) errors : -10784.04\n",
      " Regression with ARIMA(0,0,0) errors : -8121.82\n",
      " Regression with ARIMA(1,0,2) errors : -12632.84\n",
      " Regression with ARIMA(2,0,1) errors : -12631.38\n",
      " Regression with ARIMA(3,0,2) errors : -12686.69\n",
      " Regression with ARIMA(3,0,1) errors : -12643.65\n",
      " Regression with ARIMA(4,0,2) errors : -12661.74\n",
      " Regression with ARIMA(3,0,3) errors : -12661.05\n",
      " Regression with ARIMA(2,0,3) errors : -12657.15\n",
      " Regression with ARIMA(4,0,1) errors : -12661.45\n",
      " Regression with ARIMA(4,0,3) errors : -12661.55\n",
      " Regression with ARIMA(3,0,2) errors : -12592.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.86\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.03\n",
      " Regression with ARIMA(0,0,0) errors : -9124.803\n",
      " Regression with ARIMA(1,0,0) errors : -12611.58\n",
      " Regression with ARIMA(0,0,1) errors : -10785.79\n",
      " Regression with ARIMA(0,0,0) errors : -8120.735\n",
      " Regression with ARIMA(1,0,2) errors : -12631.26\n",
      " Regression with ARIMA(2,0,1) errors : -12629.83\n",
      " Regression with ARIMA(3,0,2) errors : -12695.7\n",
      " Regression with ARIMA(3,0,1) errors : -12642.68\n",
      " Regression with ARIMA(4,0,2) errors : -12659.94\n",
      " Regression with ARIMA(3,0,3) errors : -12660.68\n",
      " Regression with ARIMA(2,0,3) errors : -12655.54\n",
      " Regression with ARIMA(4,0,1) errors : -12658.46\n",
      " Regression with ARIMA(4,0,3) errors : -12702.36\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12659.16\n",
      " Regression with ARIMA(5,0,2) errors : -12657.49\n",
      " Regression with ARIMA(5,0,4) errors : -12659.7\n",
      " Regression with ARIMA(4,0,3) errors : -12584.34\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.35\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12639.64\n",
      " Regression with ARIMA(0,0,0) errors : -9126.097\n",
      " Regression with ARIMA(1,0,0) errors : -12614.91\n",
      " Regression with ARIMA(0,0,1) errors : -10785.02\n",
      " Regression with ARIMA(0,0,0) errors : -8116.995\n",
      " Regression with ARIMA(1,0,2) errors : -12635.07\n",
      " Regression with ARIMA(2,0,1) errors : -12633.58\n",
      " Regression with ARIMA(3,0,2) errors : -12700.58\n",
      " Regression with ARIMA(3,0,1) errors : -12646.01\n",
      " Regression with ARIMA(4,0,2) errors : -12662.46\n",
      " Regression with ARIMA(3,0,3) errors : -12663.22\n",
      " Regression with ARIMA(2,0,3) errors : -12659.45\n",
      " Regression with ARIMA(4,0,1) errors : -12661.32\n",
      " Regression with ARIMA(4,0,3) errors : -12707.82\n",
      " Regression with ARIMA(5,0,3) errors : -12680.87\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.94\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12674.86\n",
      " Regression with ARIMA(4,0,3) errors : -12602.62\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12703.26\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.76\n",
      " Regression with ARIMA(0,0,0) errors : -9126.664\n",
      " Regression with ARIMA(1,0,0) errors : -12610.17\n",
      " Regression with ARIMA(0,0,1) errors : -10784.22\n",
      " Regression with ARIMA(0,0,0) errors : -8120.924\n",
      " Regression with ARIMA(1,0,2) errors : -12630.62\n",
      " Regression with ARIMA(2,0,1) errors : -12629.52\n",
      " Regression with ARIMA(3,0,2) errors : -12694.59\n",
      " Regression with ARIMA(3,0,1) errors : -12642.09\n",
      " Regression with ARIMA(4,0,2) errors : -12658.44\n",
      " Regression with ARIMA(3,0,3) errors : -12658.75\n",
      " Regression with ARIMA(2,0,3) errors : -12655.04\n",
      " Regression with ARIMA(4,0,1) errors : -12657.14\n",
      " Regression with ARIMA(4,0,3) errors : -12704.19\n",
      " Regression with ARIMA(5,0,3) errors : -12674.9\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.25\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12664.74\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.55\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.01\n",
      " Regression with ARIMA(0,0,0) errors : -9129.67\n",
      " Regression with ARIMA(1,0,0) errors : -12606.43\n",
      " Regression with ARIMA(0,0,1) errors : -10786.26\n",
      " Regression with ARIMA(0,0,0) errors : -8109.689\n",
      " Regression with ARIMA(1,0,2) errors : -12626.33\n",
      " Regression with ARIMA(2,0,1) errors : -12625.7\n",
      " Regression with ARIMA(3,0,2) errors : -12685.15\n",
      " Regression with ARIMA(3,0,1) errors : -12638.15\n",
      " Regression with ARIMA(4,0,2) errors : -12654.36\n",
      " Regression with ARIMA(3,0,3) errors : -12654.53\n",
      " Regression with ARIMA(2,0,3) errors : -12651.32\n",
      " Regression with ARIMA(4,0,1) errors : -12653.1\n",
      " Regression with ARIMA(4,0,3) errors : -12701.37\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12653.24\n",
      " Regression with ARIMA(3,0,4) errors : -12676.54\n",
      " Regression with ARIMA(5,0,2) errors : -12652.64\n",
      " Regression with ARIMA(5,0,4) errors : -12668.09\n",
      " Regression with ARIMA(4,0,3) errors : -12590.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.56\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.77\n",
      " Regression with ARIMA(0,0,0) errors : -9125.562\n",
      " Regression with ARIMA(1,0,0) errors : -12610.64\n",
      " Regression with ARIMA(0,0,1) errors : -10785.7\n",
      " Regression with ARIMA(0,0,0) errors : -8108.179\n",
      " Regression with ARIMA(1,0,2) errors : -12630.51\n",
      " Regression with ARIMA(2,0,1) errors : -12629.36\n",
      " Regression with ARIMA(3,0,2) errors : -12694.15\n",
      " Regression with ARIMA(3,0,1) errors : -12642.13\n",
      " Regression with ARIMA(4,0,2) errors : -12658.37\n",
      " Regression with ARIMA(3,0,3) errors : -12658.83\n",
      " Regression with ARIMA(2,0,3) errors : -12655.24\n",
      " Regression with ARIMA(4,0,1) errors : -12657.12\n",
      " Regression with ARIMA(4,0,3) errors : -12704.42\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12679.15\n",
      " Regression with ARIMA(3,0,4) errors : -12677.56\n",
      " Regression with ARIMA(5,0,2) errors : -12656.96\n",
      " Regression with ARIMA(5,0,4) errors : -12670.89\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12699.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.76\n",
      " Regression with ARIMA(0,0,0) errors : -9119.29\n",
      " Regression with ARIMA(1,0,0) errors : -12609.83\n",
      " Regression with ARIMA(0,0,1) errors : -10782.32\n",
      " Regression with ARIMA(0,0,0) errors : -8104.093\n",
      " Regression with ARIMA(1,0,2) errors : -12629.02\n",
      " Regression with ARIMA(2,0,1) errors : -12627.65\n",
      " Regression with ARIMA(3,0,2) errors : -12693.41\n",
      " Regression with ARIMA(3,0,1) errors : -12640.24\n",
      " Regression with ARIMA(4,0,2) errors : -12657.4\n",
      " Regression with ARIMA(3,0,3) errors : -12657.65\n",
      " Regression with ARIMA(2,0,3) errors : -12654\n",
      " Regression with ARIMA(4,0,1) errors : -12655.98\n",
      " Regression with ARIMA(4,0,3) errors : -12700.63\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12678.52\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12666.19\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.72\n",
      " Regression with ARIMA(0,0,0) errors : -9127.533\n",
      " Regression with ARIMA(1,0,0) errors : -12608.51\n",
      " Regression with ARIMA(0,0,1) errors : -10784.58\n",
      " Regression with ARIMA(0,0,0) errors : -8099.693\n",
      " Regression with ARIMA(1,0,2) errors : -12627.71\n",
      " Regression with ARIMA(2,0,1) errors : -12626.53\n",
      " Regression with ARIMA(3,0,2) errors : -12687.4\n",
      " Regression with ARIMA(3,0,1) errors : -12638.82\n",
      " Regression with ARIMA(4,0,2) errors : -12655.24\n",
      " Regression with ARIMA(3,0,3) errors : -12655.99\n",
      " Regression with ARIMA(2,0,3) errors : -12651.92\n",
      " Regression with ARIMA(4,0,1) errors : -12654.76\n",
      " Regression with ARIMA(4,0,3) errors : -12698.43\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12654.62\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -12611.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12696.67\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.19\n",
      " Regression with ARIMA(0,0,0) errors : -9131.072\n",
      " Regression with ARIMA(1,0,0) errors : -12612.33\n",
      " Regression with ARIMA(0,0,1) errors : -10786.34\n",
      " Regression with ARIMA(0,0,0) errors : -8111.89\n",
      " Regression with ARIMA(1,0,2) errors : -12632.14\n",
      " Regression with ARIMA(2,0,1) errors : -12630.94\n",
      " Regression with ARIMA(3,0,2) errors : -12697.09\n",
      " Regression with ARIMA(3,0,1) errors : -12642.55\n",
      " Regression with ARIMA(4,0,2) errors : -12659.42\n",
      " Regression with ARIMA(3,0,3) errors : -12660.03\n",
      " Regression with ARIMA(2,0,3) errors : -12656.53\n",
      " Regression with ARIMA(4,0,1) errors : -12658.14\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12614.5\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12700.42\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.26\n",
      " Regression with ARIMA(0,0,0) errors : -9126.592\n",
      " Regression with ARIMA(1,0,0) errors : -12609.67\n",
      " Regression with ARIMA(0,0,1) errors : -10781.77\n",
      " Regression with ARIMA(0,0,0) errors : -8113.176\n",
      " Regression with ARIMA(1,0,2) errors : -12629.18\n",
      " Regression with ARIMA(2,0,1) errors : -12627.73\n",
      " Regression with ARIMA(3,0,2) errors : -12692.71\n",
      " Regression with ARIMA(3,0,1) errors : -12639.26\n",
      " Regression with ARIMA(4,0,2) errors : -12656.27\n",
      " Regression with ARIMA(3,0,3) errors : -12657.03\n",
      " Regression with ARIMA(2,0,3) errors : -12652.75\n",
      " Regression with ARIMA(4,0,1) errors : -12654.72\n",
      " Regression with ARIMA(4,0,3) errors : -12699.6\n",
      " Regression with ARIMA(5,0,3) errors : -12672.77\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12668.99\n",
      " Regression with ARIMA(4,0,3) errors : -12626.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12697.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "[1] \"70 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.51\n",
      " Regression with ARIMA(0,0,0) errors : -9120.766\n",
      " Regression with ARIMA(1,0,0) errors : -12607\n",
      " Regression with ARIMA(0,0,1) errors : -10776.09\n",
      " Regression with ARIMA(0,0,0) errors : -8111.103\n",
      " Regression with ARIMA(1,0,2) errors : -12626.77\n",
      " Regression with ARIMA(2,0,1) errors : -12625.53\n",
      " Regression with ARIMA(3,0,2) errors : -12685.73\n",
      " Regression with ARIMA(3,0,1) errors : -12637.75\n",
      " Regression with ARIMA(4,0,2) errors : -12654.14\n",
      " Regression with ARIMA(3,0,3) errors : -12654.51\n",
      " Regression with ARIMA(2,0,3) errors : -12650.91\n",
      " Regression with ARIMA(4,0,1) errors : -12654.37\n",
      " Regression with ARIMA(4,0,3) errors : -12686.13\n",
      " Regression with ARIMA(5,0,3) errors : -12700.25\n",
      " Regression with ARIMA(5,0,2) errors : -12654.47\n",
      " Regression with ARIMA(5,0,4) errors : -12662.71\n",
      " Regression with ARIMA(4,0,4) errors : -12698.47\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : -12673.47\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12629.83\n",
      " Regression with ARIMA(0,0,0) errors : -9123.342\n",
      " Regression with ARIMA(1,0,0) errors : -12606.52\n",
      " Regression with ARIMA(0,0,1) errors : -10778\n",
      " Regression with ARIMA(0,0,0) errors : -8105.722\n",
      " Regression with ARIMA(1,0,2) errors : -12626.01\n",
      " Regression with ARIMA(2,0,1) errors : -12624.6\n",
      " Regression with ARIMA(3,0,2) errors : -12689.93\n",
      " Regression with ARIMA(3,0,1) errors : -12636.27\n",
      " Regression with ARIMA(4,0,2) errors : -12652.8\n",
      " Regression with ARIMA(3,0,3) errors : -12653.27\n",
      " Regression with ARIMA(2,0,3) errors : -12649.98\n",
      " Regression with ARIMA(4,0,1) errors : -12652.27\n",
      " Regression with ARIMA(4,0,3) errors : -12694.07\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12670.15\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12654.04\n",
      " Regression with ARIMA(4,0,3) errors : -12618.5\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.06\n",
      " Regression with ARIMA(0,0,0) errors : -9131.681\n",
      " Regression with ARIMA(1,0,0) errors : -12608.01\n",
      " Regression with ARIMA(0,0,1) errors : -10782.66\n",
      " Regression with ARIMA(0,0,0) errors : -8107.119\n",
      " Regression with ARIMA(1,0,2) errors : -12628.11\n",
      " Regression with ARIMA(2,0,1) errors : -12626.67\n",
      " Regression with ARIMA(3,0,2) errors : -12693.49\n",
      " Regression with ARIMA(3,0,1) errors : -12638.11\n",
      " Regression with ARIMA(4,0,2) errors : -12655.3\n",
      " Regression with ARIMA(3,0,3) errors : -12655.92\n",
      " Regression with ARIMA(2,0,3) errors : -12652.11\n",
      " Regression with ARIMA(4,0,1) errors : -12653.8\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12610.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12696.06\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.24\n",
      " Regression with ARIMA(0,0,0) errors : -9131.239\n",
      " Regression with ARIMA(1,0,0) errors : -12606.95\n",
      " Regression with ARIMA(0,0,1) errors : -10780.44\n",
      " Regression with ARIMA(0,0,0) errors : -8112.5\n",
      " Regression with ARIMA(1,0,2) errors : -12627\n",
      " Regression with ARIMA(2,0,1) errors : -12625.5\n",
      " Regression with ARIMA(3,0,2) errors : -12689.64\n",
      " Regression with ARIMA(3,0,1) errors : -12638.39\n",
      " Regression with ARIMA(4,0,2) errors : -12654.7\n",
      " Regression with ARIMA(3,0,3) errors : -12654.57\n",
      " Regression with ARIMA(2,0,3) errors : -12650.34\n",
      " Regression with ARIMA(4,0,1) errors : -12654\n",
      " Regression with ARIMA(4,0,3) errors : -12691.8\n",
      " Regression with ARIMA(5,0,3) errors : -12674.84\n",
      " Regression with ARIMA(4,0,4) errors : -12670.68\n",
      " Regression with ARIMA(3,0,4) errors : -12676.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12662.77\n",
      " Regression with ARIMA(4,0,3) errors : -12620.21\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.43\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.92\n",
      " Regression with ARIMA(0,0,0) errors : -9128.861\n",
      " Regression with ARIMA(1,0,0) errors : -12610.07\n",
      " Regression with ARIMA(0,0,1) errors : -10783.53\n",
      " Regression with ARIMA(0,0,0) errors : -8110.608\n",
      " Regression with ARIMA(1,0,2) errors : -12629.79\n",
      " Regression with ARIMA(2,0,1) errors : -12628.8\n",
      " Regression with ARIMA(3,0,2) errors : -12690.81\n",
      " Regression with ARIMA(3,0,1) errors : -12640.88\n",
      " Regression with ARIMA(4,0,2) errors : -12657.06\n",
      " Regression with ARIMA(3,0,3) errors : -12657.59\n",
      " Regression with ARIMA(2,0,3) errors : -12654.11\n",
      " Regression with ARIMA(4,0,1) errors : -12656.04\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12597.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12697.96\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12634.62\n",
      " Regression with ARIMA(0,0,0) errors : -9126.781\n",
      " Regression with ARIMA(1,0,0) errors : -12610.65\n",
      " Regression with ARIMA(0,0,1) errors : -10781.97\n",
      " Regression with ARIMA(0,0,0) errors : -8113.142\n",
      " Regression with ARIMA(1,0,2) errors : -12630.54\n",
      " Regression with ARIMA(2,0,1) errors : -12629.23\n",
      " Regression with ARIMA(3,0,2) errors : -12696.42\n",
      " Regression with ARIMA(3,0,1) errors : -12641.18\n",
      " Regression with ARIMA(4,0,2) errors : -12657.47\n",
      " Regression with ARIMA(3,0,3) errors : -12658.27\n",
      " Regression with ARIMA(2,0,3) errors : -12654.69\n",
      " Regression with ARIMA(4,0,1) errors : -12656.72\n",
      " Regression with ARIMA(4,0,3) errors : -12703.68\n",
      " Regression with ARIMA(5,0,3) errors : -12677.09\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12669.72\n",
      " Regression with ARIMA(4,0,3) errors : -12577.74\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.4\n",
      " Regression with ARIMA(0,0,0) errors : -9125.689\n",
      " Regression with ARIMA(1,0,0) errors : -12612.41\n",
      " Regression with ARIMA(0,0,1) errors : -10783.44\n",
      " Regression with ARIMA(0,0,0) errors : -8112.957\n",
      " Regression with ARIMA(1,0,2) errors : -12632.37\n",
      " Regression with ARIMA(2,0,1) errors : -12631.02\n",
      " Regression with ARIMA(3,0,2) errors : -12698.98\n",
      " Regression with ARIMA(3,0,1) errors : -12642.99\n",
      " Regression with ARIMA(4,0,2) errors : -12659.39\n",
      " Regression with ARIMA(3,0,3) errors : -12660.05\n",
      " Regression with ARIMA(2,0,3) errors : -12656.41\n",
      " Regression with ARIMA(4,0,1) errors : -12658.4\n",
      " Regression with ARIMA(4,0,3) errors : -12705.73\n",
      " Regression with ARIMA(5,0,3) errors : -12677.06\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12682.47\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12672.68\n",
      " Regression with ARIMA(4,0,3) errors : -12592.32\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.68\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.3\n",
      " Regression with ARIMA(0,0,0) errors : -9115.868\n",
      " Regression with ARIMA(1,0,0) errors : -12611.51\n",
      " Regression with ARIMA(0,0,1) errors : -10777.8\n",
      " Regression with ARIMA(0,0,0) errors : -8111.841\n",
      " Regression with ARIMA(1,0,2) errors : -12631.09\n",
      " Regression with ARIMA(2,0,1) errors : -12629.64\n",
      " Regression with ARIMA(3,0,2) errors : -12698.43\n",
      " Regression with ARIMA(3,0,1) errors : -12641.39\n",
      " Regression with ARIMA(4,0,2) errors : -12658.34\n",
      " Regression with ARIMA(3,0,3) errors : -12658.92\n",
      " Regression with ARIMA(2,0,3) errors : -12655.53\n",
      " Regression with ARIMA(4,0,1) errors : -12657.54\n",
      " Regression with ARIMA(4,0,3) errors : -12704.55\n",
      " Regression with ARIMA(5,0,3) errors : -12677.45\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12671.36\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.66\n",
      " Regression with ARIMA(0,0,0) errors : -9124.945\n",
      " Regression with ARIMA(1,0,0) errors : -12612.72\n",
      " Regression with ARIMA(0,0,1) errors : -10780.08\n",
      " Regression with ARIMA(0,0,0) errors : -8108.834\n",
      " Regression with ARIMA(1,0,2) errors : -12632.51\n",
      " Regression with ARIMA(2,0,1) errors : -12631.82\n",
      " Regression with ARIMA(3,0,2) errors : -12694.27\n",
      " Regression with ARIMA(3,0,1) errors : -12643.59\n",
      " Regression with ARIMA(4,0,2) errors : -12660.23\n",
      " Regression with ARIMA(3,0,3) errors : -12660.57\n",
      " Regression with ARIMA(2,0,3) errors : -12657.73\n",
      " Regression with ARIMA(4,0,1) errors : -12659.39\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12588.55\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.13\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12627.74\n",
      " Regression with ARIMA(0,0,0) errors : -9117.039\n",
      " Regression with ARIMA(1,0,0) errors : -12604.36\n",
      " Regression with ARIMA(0,0,1) errors : -10772.74\n",
      " Regression with ARIMA(0,0,0) errors : -8100.168\n",
      " Regression with ARIMA(1,0,2) errors : -12624.03\n",
      " Regression with ARIMA(2,0,1) errors : -12622.73\n",
      " Regression with ARIMA(3,0,2) errors : -12688.87\n",
      " Regression with ARIMA(3,0,1) errors : -12635.29\n",
      " Regression with ARIMA(4,0,2) errors : -12652.41\n",
      " Regression with ARIMA(3,0,3) errors : -12652.42\n",
      " Regression with ARIMA(2,0,3) errors : -12648.98\n",
      " Regression with ARIMA(4,0,1) errors : -12651.73\n",
      " Regression with ARIMA(4,0,3) errors : -12695.02\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12668.42\n",
      " Regression with ARIMA(3,0,4) errors : -12666.86\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12662.55\n",
      " Regression with ARIMA(4,0,3) errors : -12583.67\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12692.62\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12629.95\n",
      " Regression with ARIMA(0,0,0) errors : -9111.839\n",
      " Regression with ARIMA(1,0,0) errors : -12606.59\n",
      " Regression with ARIMA(0,0,1) errors : -10768.97\n",
      " Regression with ARIMA(0,0,0) errors : -8094.359\n",
      " Regression with ARIMA(1,0,2) errors : -12626.11\n",
      " Regression with ARIMA(2,0,1) errors : -12624.99\n",
      " Regression with ARIMA(3,0,2) errors : -12691.49\n",
      " Regression with ARIMA(3,0,1) errors : -12636.29\n",
      " Regression with ARIMA(4,0,2) errors : -12654.61\n",
      " Regression with ARIMA(3,0,3) errors : -12655.25\n",
      " Regression with ARIMA(2,0,3) errors : -12651.79\n",
      " Regression with ARIMA(4,0,1) errors : -12653.54\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12606.28\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12694.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12625.86\n",
      " Regression with ARIMA(0,0,0) errors : -9104.057\n",
      " Regression with ARIMA(1,0,0) errors : -12602.52\n",
      " Regression with ARIMA(0,0,1) errors : -10763.32\n",
      " Regression with ARIMA(0,0,0) errors : -8093.859\n",
      " Regression with ARIMA(1,0,2) errors : -12621.83\n",
      " Regression with ARIMA(2,0,1) errors : -12620.75\n",
      " Regression with ARIMA(3,0,2) errors : -12688.22\n",
      " Regression with ARIMA(3,0,1) errors : -12631.52\n",
      " Regression with ARIMA(4,0,2) errors : -12652.06\n",
      " Regression with ARIMA(3,0,3) errors : -12650.46\n",
      " Regression with ARIMA(2,0,3) errors : -12647.56\n",
      " Regression with ARIMA(4,0,1) errors : -12651.23\n",
      " Regression with ARIMA(4,0,3) errors : -12681.28\n",
      " Regression with ARIMA(3,0,2) errors : -12603.68\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12690.63\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12618.91\n",
      " Regression with ARIMA(0,0,0) errors : -9103.363\n",
      " Regression with ARIMA(1,0,0) errors : -12597.31\n",
      " Regression with ARIMA(0,0,1) errors : -10765.68\n",
      " Regression with ARIMA(0,0,0) errors : -8091.292\n",
      " Regression with ARIMA(1,0,2) errors : -12615.19\n",
      " Regression with ARIMA(2,0,1) errors : -12613.85\n",
      " Regression with ARIMA(3,0,2) errors : -12682.31\n",
      " Regression with ARIMA(3,0,1) errors : -12625.35\n",
      " Regression with ARIMA(4,0,2) errors : -12644.79\n",
      " Regression with ARIMA(3,0,3) errors : -12644.37\n",
      " Regression with ARIMA(2,0,3) errors : -12640.45\n",
      " Regression with ARIMA(4,0,1) errors : -12643.65\n",
      " Regression with ARIMA(4,0,3) errors : -12682.08\n",
      " Regression with ARIMA(3,0,2) errors : -12580.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12684.69\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12615.06\n",
      " Regression with ARIMA(0,0,0) errors : -9099.58\n",
      " Regression with ARIMA(1,0,0) errors : -12592.84\n",
      " Regression with ARIMA(0,0,1) errors : -10762.48\n",
      " Regression with ARIMA(0,0,0) errors : -8087.004\n",
      " Regression with ARIMA(1,0,2) errors : -12610.83\n",
      " Regression with ARIMA(2,0,1) errors : -12609.67\n",
      " Regression with ARIMA(3,0,2) errors : -12677.21\n",
      " Regression with ARIMA(3,0,1) errors : -12621.08\n",
      " Regression with ARIMA(4,0,2) errors : -12640.17\n",
      " Regression with ARIMA(3,0,3) errors : -12640.85\n",
      " Regression with ARIMA(2,0,3) errors : -12636.93\n",
      " Regression with ARIMA(4,0,1) errors : -12638.83\n",
      " Regression with ARIMA(4,0,3) errors : -12684.27\n",
      " Regression with ARIMA(5,0,3) errors : -12658.04\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12639.53\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12654.82\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12680.01\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12613.46\n",
      " Regression with ARIMA(0,0,0) errors : -9099.695\n",
      " Regression with ARIMA(1,0,0) errors : -12591.66\n",
      " Regression with ARIMA(0,0,1) errors : -10763.22\n",
      " Regression with ARIMA(0,0,0) errors : -8089.962\n",
      " Regression with ARIMA(1,0,2) errors : -12609.68\n",
      " Regression with ARIMA(2,0,1) errors : -12608.39\n",
      " Regression with ARIMA(3,0,2) errors : -12677.01\n",
      " Regression with ARIMA(3,0,1) errors : -12619.63\n",
      " Regression with ARIMA(4,0,2) errors : -12638.73\n",
      " Regression with ARIMA(3,0,3) errors : -12639.14\n",
      " Regression with ARIMA(2,0,3) errors : -12635.44\n",
      " Regression with ARIMA(4,0,1) errors : -12637.36\n",
      " Regression with ARIMA(4,0,3) errors : -12681.2\n",
      " Regression with ARIMA(5,0,3) errors : -12656.69\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12660.48\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12652.18\n",
      " Regression with ARIMA(4,0,3) errors : -12597.54\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12678.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12615.16\n",
      " Regression with ARIMA(0,0,0) errors : -9100.818\n",
      " Regression with ARIMA(1,0,0) errors : -12593.22\n",
      " Regression with ARIMA(0,0,1) errors : -10765.31\n",
      " Regression with ARIMA(0,0,0) errors : -8091.06\n",
      " Regression with ARIMA(1,0,2) errors : -12611.24\n",
      " Regression with ARIMA(2,0,1) errors : -12609.93\n",
      " Regression with ARIMA(3,0,2) errors : -12679.3\n",
      " Regression with ARIMA(3,0,1) errors : -12621.06\n",
      " Regression with ARIMA(4,0,2) errors : -12639.78\n",
      " Regression with ARIMA(3,0,3) errors : -12640.43\n",
      " Regression with ARIMA(2,0,3) errors : -12636.97\n",
      " Regression with ARIMA(4,0,1) errors : -12638.66\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12594.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12679.67\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12617.12\n",
      " Regression with ARIMA(0,0,0) errors : -9109.583\n",
      " Regression with ARIMA(1,0,0) errors : -12595.07\n",
      " Regression with ARIMA(0,0,1) errors : -10771.08\n",
      " Regression with ARIMA(0,0,0) errors : -8093.37\n",
      " Regression with ARIMA(1,0,2) errors : -12613.21\n",
      " Regression with ARIMA(2,0,1) errors : -12611.88\n",
      " Regression with ARIMA(3,0,2) errors : -12678.72\n",
      " Regression with ARIMA(3,0,1) errors : -12623\n",
      " Regression with ARIMA(4,0,2) errors : -12641.23\n",
      " Regression with ARIMA(3,0,3) errors : -12641.89\n",
      " Regression with ARIMA(2,0,3) errors : -12638.42\n",
      " Regression with ARIMA(4,0,1) errors : -12640.06\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12592.8\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12681.68\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12619.74\n",
      " Regression with ARIMA(0,0,0) errors : -9112.072\n",
      " Regression with ARIMA(1,0,0) errors : -12597.43\n",
      " Regression with ARIMA(0,0,1) errors : -10771.67\n",
      " Regression with ARIMA(0,0,0) errors : -8099.27\n",
      " Regression with ARIMA(1,0,2) errors : -12615.95\n",
      " Regression with ARIMA(2,0,1) errors : -12614.81\n",
      " Regression with ARIMA(3,0,2) errors : -12684.97\n",
      " Regression with ARIMA(3,0,1) errors : -12626.06\n",
      " Regression with ARIMA(4,0,2) errors : -12644.83\n",
      " Regression with ARIMA(3,0,3) errors : -12645.37\n",
      " Regression with ARIMA(2,0,3) errors : -12641.62\n",
      " Regression with ARIMA(4,0,1) errors : -12643.67\n",
      " Regression with ARIMA(4,0,3) errors : -12690.35\n",
      " Regression with ARIMA(5,0,3) errors : -12663.66\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12668.79\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12658.85\n",
      " Regression with ARIMA(4,0,3) errors : -12609.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12685.05\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12619.78\n",
      " Regression with ARIMA(0,0,0) errors : -9111.436\n",
      " Regression with ARIMA(1,0,0) errors : -12596.51\n",
      " Regression with ARIMA(0,0,1) errors : -10769.82\n",
      " Regression with ARIMA(0,0,0) errors : -8099.19\n",
      " Regression with ARIMA(1,0,2) errors : -12615.12\n",
      " Regression with ARIMA(2,0,1) errors : -12615.29\n",
      " Regression with ARIMA(3,0,2) errors : -12677.01\n",
      " Regression with ARIMA(3,0,1) errors : -12626.47\n",
      " Regression with ARIMA(4,0,2) errors : -12646.5\n",
      " Regression with ARIMA(3,0,3) errors : -12647.04\n",
      " Regression with ARIMA(2,0,3) errors : -12642.14\n",
      " Regression with ARIMA(4,0,1) errors : -12644.59\n",
      " Regression with ARIMA(4,0,3) errors : -12686.33\n",
      " Regression with ARIMA(5,0,3) errors : -12661.66\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12668.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12657.53\n",
      " Regression with ARIMA(4,0,3) errors : -12608.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12683.18\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12616.6\n",
      " Regression with ARIMA(0,0,0) errors : -9093.993\n",
      " Regression with ARIMA(1,0,0) errors : -12593.32\n",
      " Regression with ARIMA(0,0,1) errors : -10754.58\n",
      " Regression with ARIMA(0,0,0) errors : -8057.969\n",
      " Regression with ARIMA(1,0,2) errors : -12612.81\n",
      " Regression with ARIMA(2,0,1) errors : -12611.61\n",
      " Regression with ARIMA(3,0,2) errors : -12678.85\n",
      " Regression with ARIMA(3,0,1) errors : -12622.82\n",
      " Regression with ARIMA(4,0,2) errors : -12641.44\n",
      " Regression with ARIMA(3,0,3) errors : -12642.14\n",
      " Regression with ARIMA(2,0,3) errors : -12638.25\n",
      " Regression with ARIMA(4,0,1) errors : -12639.95\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12583.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12680.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12583.96\n",
      " Regression with ARIMA(0,0,0) errors : -9092.613\n",
      " Regression with ARIMA(1,0,0) errors : -12563.7\n",
      " Regression with ARIMA(0,0,1) errors : -10747.78\n",
      " Regression with ARIMA(0,0,0) errors : -8051.218\n",
      " Regression with ARIMA(1,0,2) errors : -12580.28\n",
      " Regression with ARIMA(2,0,1) errors : -12579.03\n",
      " Regression with ARIMA(3,0,2) errors : -12646.7\n",
      " Regression with ARIMA(3,0,1) errors : -12589.65\n",
      " Regression with ARIMA(4,0,2) errors : -12606.27\n",
      " Regression with ARIMA(3,0,3) errors : -12606.89\n",
      " Regression with ARIMA(2,0,3) errors : -12603.05\n",
      " Regression with ARIMA(4,0,1) errors : -12604.75\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12556.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12648.35\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12577.66\n",
      " Regression with ARIMA(0,0,0) errors : -9095.204\n",
      " Regression with ARIMA(1,0,0) errors : -12557.4\n",
      " Regression with ARIMA(0,0,1) errors : -10745.91\n",
      " Regression with ARIMA(0,0,0) errors : -8037.239\n",
      " Regression with ARIMA(1,0,2) errors : -12573.72\n",
      " Regression with ARIMA(2,0,1) errors : -12572.35\n",
      " Regression with ARIMA(3,0,2) errors : -12641.2\n",
      " Regression with ARIMA(3,0,1) errors : -12583.1\n",
      " Regression with ARIMA(4,0,2) errors : -12600.41\n",
      " Regression with ARIMA(3,0,3) errors : -12601.11\n",
      " Regression with ARIMA(2,0,3) errors : -12597.21\n",
      " Regression with ARIMA(4,0,1) errors : -12599.03\n",
      " Regression with ARIMA(4,0,3) errors : -12644.07\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12622.13\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12612.01\n",
      " Regression with ARIMA(4,0,3) errors : -12563.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12642.54\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12575.52\n",
      " Regression with ARIMA(0,0,0) errors : -9101.37\n",
      " Regression with ARIMA(1,0,0) errors : -12554.94\n",
      " Regression with ARIMA(0,0,1) errors : -10747.52\n",
      " Regression with ARIMA(0,0,0) errors : -8033.351\n",
      " Regression with ARIMA(1,0,2) errors : -12571.38\n",
      " Regression with ARIMA(2,0,1) errors : -12570.05\n",
      " Regression with ARIMA(3,0,2) errors : -12638.35\n",
      " Regression with ARIMA(3,0,1) errors : -12581.07\n",
      " Regression with ARIMA(4,0,2) errors : -12598.59\n",
      " Regression with ARIMA(3,0,3) errors : -12599.01\n",
      " Regression with ARIMA(2,0,3) errors : -12595.34\n",
      " Regression with ARIMA(4,0,1) errors : -12597.11\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12519.88\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12639.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12565.83\n",
      " Regression with ARIMA(0,0,0) errors : -9101.364\n",
      " Regression with ARIMA(1,0,0) errors : -12545.42\n",
      " Regression with ARIMA(0,0,1) errors : -10744.99\n",
      " Regression with ARIMA(0,0,0) errors : -8028.435\n",
      " Regression with ARIMA(1,0,2) errors : -12561.69\n",
      " Regression with ARIMA(2,0,1) errors : -12560.33\n",
      " Regression with ARIMA(3,0,2) errors : -12625.38\n",
      " Regression with ARIMA(3,0,1) errors : -12571.55\n",
      " Regression with ARIMA(4,0,2) errors : -12589.48\n",
      " Regression with ARIMA(3,0,3) errors : -12589.91\n",
      " Regression with ARIMA(2,0,3) errors : -12585.25\n",
      " Regression with ARIMA(4,0,1) errors : -12587.54\n",
      " Regression with ARIMA(4,0,3) errors : -12629.39\n",
      " Regression with ARIMA(5,0,3) errors : -12606.27\n",
      " Regression with ARIMA(4,0,4) errors : -12632.75\n",
      " Regression with ARIMA(3,0,4) errors : -12604.33\n",
      " Regression with ARIMA(5,0,4) errors : -12602.45\n",
      " Regression with ARIMA(4,0,5) errors : -12606.94\n",
      " Regression with ARIMA(3,0,5) errors : -12601.51\n",
      " Regression with ARIMA(5,0,5) errors : -12608.1\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12629.36\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "[1] \"80 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12550.88\n",
      " Regression with ARIMA(0,0,0) errors : -9082.974\n",
      " Regression with ARIMA(1,0,0) errors : -12530.87\n",
      " Regression with ARIMA(0,0,1) errors : -10726.19\n",
      " Regression with ARIMA(0,0,0) errors : -7990.949\n",
      " Regression with ARIMA(1,0,2) errors : -12547.22\n",
      " Regression with ARIMA(2,0,1) errors : -12546.03\n",
      " Regression with ARIMA(3,0,2) errors : -12611.03\n",
      " Regression with ARIMA(3,0,1) errors : -12556.14\n",
      " Regression with ARIMA(4,0,2) errors : -12573.38\n",
      " Regression with ARIMA(3,0,3) errors : -12573.93\n",
      " Regression with ARIMA(2,0,3) errors : -12570.37\n",
      " Regression with ARIMA(4,0,1) errors : -12572.13\n",
      " Regression with ARIMA(4,0,3) errors : -12616.54\n",
      " Regression with ARIMA(5,0,3) errors : -12590.07\n",
      " Regression with ARIMA(4,0,4) errors : -12620.02\n",
      " Regression with ARIMA(3,0,4) errors : -12593.33\n",
      " Regression with ARIMA(5,0,4) errors : -12585.19\n",
      " Regression with ARIMA(4,0,5) errors : -12590.96\n",
      " Regression with ARIMA(3,0,5) errors : -12586.08\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12613.46\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12541.98\n",
      " Regression with ARIMA(0,0,0) errors : -9085.693\n",
      " Regression with ARIMA(1,0,0) errors : -12521.52\n",
      " Regression with ARIMA(0,0,1) errors : -10727.61\n",
      " Regression with ARIMA(0,0,0) errors : -7984.545\n",
      " Regression with ARIMA(1,0,2) errors : -12537.92\n",
      " Regression with ARIMA(2,0,1) errors : -12537.24\n",
      " Regression with ARIMA(3,0,2) errors : -12601.89\n",
      " Regression with ARIMA(3,0,1) errors : -12547.19\n",
      " Regression with ARIMA(4,0,2) errors : -12564.24\n",
      " Regression with ARIMA(3,0,3) errors : -12564.26\n",
      " Regression with ARIMA(2,0,3) errors : -12561.62\n",
      " Regression with ARIMA(4,0,1) errors : -12563.37\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12499.3\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12602.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.96\n",
      " Regression with ARIMA(0,0,0) errors : -9090.727\n",
      " Regression with ARIMA(1,0,0) errors : -12524.23\n",
      " Regression with ARIMA(0,0,1) errors : -10729.14\n",
      " Regression with ARIMA(0,0,0) errors : -7988.192\n",
      " Regression with ARIMA(1,0,2) errors : -12541.23\n",
      " Regression with ARIMA(2,0,1) errors : -12541.2\n",
      " Regression with ARIMA(3,0,2) errors : -12596.53\n",
      " Regression with ARIMA(3,0,1) errors : -12551.61\n",
      " Regression with ARIMA(4,0,2) errors : -12568.27\n",
      " Regression with ARIMA(3,0,3) errors : -12568.72\n",
      " Regression with ARIMA(2,0,3) errors : -12565.53\n",
      " Regression with ARIMA(4,0,1) errors : -12567.05\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12496.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12605.49\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12548.88\n",
      " Regression with ARIMA(0,0,0) errors : -9100.305\n",
      " Regression with ARIMA(1,0,0) errors : -12527.5\n",
      " Regression with ARIMA(0,0,1) errors : -10736.35\n",
      " Regression with ARIMA(0,0,0) errors : -7988.759\n",
      " Regression with ARIMA(1,0,2) errors : -12544.66\n",
      " Regression with ARIMA(2,0,1) errors : -12543.65\n",
      " Regression with ARIMA(3,0,2) errors : -12605.4\n",
      " Regression with ARIMA(3,0,1) errors : -12554.44\n",
      " Regression with ARIMA(4,0,2) errors : -12571.11\n",
      " Regression with ARIMA(3,0,3) errors : -12571.91\n",
      " Regression with ARIMA(2,0,3) errors : -12568.5\n",
      " Regression with ARIMA(4,0,1) errors : -12570.06\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12504.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12608.79\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.27\n",
      " Regression with ARIMA(0,0,0) errors : -9095.28\n",
      " Regression with ARIMA(1,0,0) errors : -12526.27\n",
      " Regression with ARIMA(0,0,1) errors : -10733.95\n",
      " Regression with ARIMA(0,0,0) errors : -7985.631\n",
      " Regression with ARIMA(1,0,2) errors : -12543.29\n",
      " Regression with ARIMA(2,0,1) errors : -12541.96\n",
      " Regression with ARIMA(3,0,2) errors : -12605.92\n",
      " Regression with ARIMA(3,0,1) errors : -12552.76\n",
      " Regression with ARIMA(4,0,2) errors : -12569.38\n",
      " Regression with ARIMA(3,0,3) errors : -12569.97\n",
      " Regression with ARIMA(2,0,3) errors : -12566.62\n",
      " Regression with ARIMA(4,0,1) errors : -12568.51\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12514.77\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12607.57\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12551.72\n",
      " Regression with ARIMA(0,0,0) errors : -9094.616\n",
      " Regression with ARIMA(1,0,0) errors : -12527.72\n",
      " Regression with ARIMA(0,0,1) errors : -10731.91\n",
      " Regression with ARIMA(0,0,0) errors : -7984.814\n",
      " Regression with ARIMA(1,0,2) errors : -12544.83\n",
      " Regression with ARIMA(2,0,1) errors : -12545.69\n",
      " Regression with ARIMA(3,0,2) errors : -12599.12\n",
      " Regression with ARIMA(3,0,1) errors : -12556.69\n",
      " Regression with ARIMA(4,0,2) errors : -12574.58\n",
      " Regression with ARIMA(3,0,3) errors : -12572.21\n",
      " Regression with ARIMA(2,0,3) errors : -12570.48\n",
      " Regression with ARIMA(4,0,1) errors : -12574.57\n",
      " Regression with ARIMA(4,0,3) errors : -12602.14\n",
      " Regression with ARIMA(5,0,3) errors : -12593.97\n",
      " Regression with ARIMA(4,0,4) errors : -12614.31\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12592.12\n",
      " Regression with ARIMA(4,0,5) errors : -12613.12\n",
      " Regression with ARIMA(3,0,5) errors : -12593.98\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -12615.97\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.25\n",
      " Regression with ARIMA(0,0,0) errors : -9103.285\n",
      " Regression with ARIMA(1,0,0) errors : -12525.6\n",
      " Regression with ARIMA(0,0,1) errors : -10740.02\n",
      " Regression with ARIMA(0,0,0) errors : -7987.126\n",
      " Regression with ARIMA(1,0,2) errors : -12542.63\n",
      " Regression with ARIMA(2,0,1) errors : -12541.09\n",
      " Regression with ARIMA(3,0,2) errors : -12595.27\n",
      " Regression with ARIMA(3,0,1) errors : -12553.61\n",
      " Regression with ARIMA(4,0,2) errors : -12567.35\n",
      " Regression with ARIMA(3,0,3) errors : -12568.1\n",
      " Regression with ARIMA(2,0,3) errors : -12564.84\n",
      " Regression with ARIMA(4,0,1) errors : -12567.61\n",
      " Regression with ARIMA(4,0,3) errors : -12599.93\n",
      " Regression with ARIMA(5,0,3) errors : -12585.25\n",
      " Regression with ARIMA(4,0,4) errors : -12587.13\n",
      " Regression with ARIMA(3,0,4) errors : -12586.59\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12587.56\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12603.94\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12563.76\n",
      " Regression with ARIMA(0,0,0) errors : -9114.748\n",
      " Regression with ARIMA(1,0,0) errors : -12542.44\n",
      " Regression with ARIMA(0,0,1) errors : -10750.26\n",
      " Regression with ARIMA(0,0,0) errors : -7996.79\n",
      " Regression with ARIMA(1,0,2) errors : -12559.52\n",
      " Regression with ARIMA(2,0,1) errors : -12557.88\n",
      " Regression with ARIMA(3,0,2) errors : -12623.24\n",
      " Regression with ARIMA(3,0,1) errors : -12569.07\n",
      " Regression with ARIMA(4,0,2) errors : -12584.06\n",
      " Regression with ARIMA(3,0,3) errors : -12584.83\n",
      " Regression with ARIMA(2,0,3) errors : -12581.2\n",
      " Regression with ARIMA(4,0,1) errors : -12583.59\n",
      " Regression with ARIMA(4,0,3) errors : -12622.16\n",
      " Regression with ARIMA(3,0,2) errors : -12529.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12623.55\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12571.66\n",
      " Regression with ARIMA(0,0,0) errors : -9119.255\n",
      " Regression with ARIMA(1,0,0) errors : -12550.63\n",
      " Regression with ARIMA(0,0,1) errors : -10754.38\n",
      " Regression with ARIMA(0,0,0) errors : -7999.828\n",
      " Regression with ARIMA(1,0,2) errors : -12567.56\n",
      " Regression with ARIMA(2,0,1) errors : -12565.97\n",
      " Regression with ARIMA(3,0,2) errors : -12623.38\n",
      " Regression with ARIMA(3,0,1) errors : -12577.61\n",
      " Regression with ARIMA(4,0,2) errors : -12592.71\n",
      " Regression with ARIMA(3,0,3) errors : -12593.33\n",
      " Regression with ARIMA(2,0,3) errors : -12589.24\n",
      " Regression with ARIMA(4,0,1) errors : -12591.99\n",
      " Regression with ARIMA(4,0,3) errors : -12628.14\n",
      " Regression with ARIMA(5,0,3) errors : -12611.42\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12608.22\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12601.46\n",
      " Regression with ARIMA(4,0,3) errors : -12518.46\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12632.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12570.69\n",
      " Regression with ARIMA(0,0,0) errors : -9115.278\n",
      " Regression with ARIMA(1,0,0) errors : -12549.82\n",
      " Regression with ARIMA(0,0,1) errors : -10753.47\n",
      " Regression with ARIMA(0,0,0) errors : -8003.712\n",
      " Regression with ARIMA(1,0,2) errors : -12566.64\n",
      " Regression with ARIMA(2,0,1) errors : -12564.99\n",
      " Regression with ARIMA(3,0,2) errors : -12627.12\n",
      " Regression with ARIMA(3,0,1) errors : -12576.67\n",
      " Regression with ARIMA(4,0,2) errors : -12592.86\n",
      " Regression with ARIMA(3,0,3) errors : -12593.53\n",
      " Regression with ARIMA(2,0,3) errors : -12588.09\n",
      " Regression with ARIMA(4,0,1) errors : -12591.37\n",
      " Regression with ARIMA(4,0,3) errors : -12631.06\n",
      " Regression with ARIMA(5,0,3) errors : -12608.52\n",
      " Regression with ARIMA(4,0,4) errors : -12636.78\n",
      " Regression with ARIMA(3,0,4) errors : -12595.05\n",
      " Regression with ARIMA(5,0,4) errors : -12606.13\n",
      " Regression with ARIMA(4,0,5) errors : -12611.46\n",
      " Regression with ARIMA(3,0,5) errors : -12589.1\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12631.52\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12578.38\n",
      " Regression with ARIMA(0,0,0) errors : -9111.17\n",
      " Regression with ARIMA(1,0,0) errors : -12558.92\n",
      " Regression with ARIMA(0,0,1) errors : -10753.78\n",
      " Regression with ARIMA(0,0,0) errors : -8020.573\n",
      " Regression with ARIMA(1,0,2) errors : -12574.68\n",
      " Regression with ARIMA(2,0,1) errors : -12573.05\n",
      " Regression with ARIMA(3,0,2) errors : -12623.18\n",
      " Regression with ARIMA(3,0,1) errors : -12586.14\n",
      " Regression with ARIMA(4,0,2) errors : -12599.85\n",
      " Regression with ARIMA(3,0,3) errors : -12600.52\n",
      " Regression with ARIMA(2,0,3) errors : -12595.7\n",
      " Regression with ARIMA(4,0,1) errors : -12599.55\n",
      " Regression with ARIMA(4,0,3) errors : -12630.95\n",
      " Regression with ARIMA(5,0,3) errors : -12614.41\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12610.87\n",
      " Regression with ARIMA(5,0,2) errors : -12611.96\n",
      " Regression with ARIMA(5,0,4) errors : -12609.33\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12639.79\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12589.89\n",
      " Regression with ARIMA(0,0,0) errors : -9118.887\n",
      " Regression with ARIMA(1,0,0) errors : -12570.44\n",
      " Regression with ARIMA(0,0,1) errors : -10762.54\n",
      " Regression with ARIMA(0,0,0) errors : -8023.134\n",
      " Regression with ARIMA(1,0,2) errors : -12586.06\n",
      " Regression with ARIMA(2,0,1) errors : -12584.58\n",
      " Regression with ARIMA(3,0,2) errors : -12650.24\n",
      " Regression with ARIMA(3,0,1) errors : -12595.09\n",
      " Regression with ARIMA(4,0,2) errors : -12610.13\n",
      " Regression with ARIMA(3,0,3) errors : -12611.25\n",
      " Regression with ARIMA(2,0,3) errors : -12607.47\n",
      " Regression with ARIMA(4,0,1) errors : -12610.04\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12562.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12652.57\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12605.76\n",
      " Regression with ARIMA(0,0,0) errors : -9124.298\n",
      " Regression with ARIMA(1,0,0) errors : -12585.84\n",
      " Regression with ARIMA(0,0,1) errors : -10776.69\n",
      " Regression with ARIMA(0,0,0) errors : -8072.897\n",
      " Regression with ARIMA(1,0,2) errors : -12601.79\n",
      " Regression with ARIMA(2,0,1) errors : -12600.13\n",
      " Regression with ARIMA(3,0,2) errors : -12662.69\n",
      " Regression with ARIMA(3,0,1) errors : -12612.34\n",
      " Regression with ARIMA(4,0,2) errors : -12629.9\n",
      " Regression with ARIMA(3,0,3) errors : -12629.01\n",
      " Regression with ARIMA(2,0,3) errors : -12623.63\n",
      " Regression with ARIMA(4,0,1) errors : -12627.83\n",
      " Regression with ARIMA(4,0,3) errors : -12662.1\n",
      " Regression with ARIMA(3,0,2) errors : -12538.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12668.81\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12617.98\n",
      " Regression with ARIMA(0,0,0) errors : -9103.826\n",
      " Regression with ARIMA(1,0,0) errors : -12597.39\n",
      " Regression with ARIMA(0,0,1) errors : -10769.07\n",
      " Regression with ARIMA(0,0,0) errors : -8071.78\n",
      " Regression with ARIMA(1,0,2) errors : -12613.58\n",
      " Regression with ARIMA(2,0,1) errors : -12612.03\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12634.81\n",
      " Regression with ARIMA(1,0,3) errors : -12637.74\n",
      " Regression with ARIMA(0,0,3) errors : -11857.74\n",
      " Regression with ARIMA(1,0,4) errors : -12635.79\n",
      " Regression with ARIMA(0,0,2) errors : -11425.89\n",
      " Regression with ARIMA(0,0,4) errors : -12183.34\n",
      " Regression with ARIMA(2,0,4) errors : -12660.74\n",
      " Regression with ARIMA(3,0,4) errors : -12661.91\n",
      " Regression with ARIMA(3,0,3) errors : -12639.57\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12664.79\n",
      " Regression with ARIMA(1,0,5) errors : -12637.48\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12662.8\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12648.96\n",
      " Regression with ARIMA(0,0,0) errors : -9121.032\n",
      " Regression with ARIMA(1,0,0) errors : -12628.13\n",
      " Regression with ARIMA(0,0,1) errors : -10785.99\n",
      " Regression with ARIMA(0,0,0) errors : -8086.924\n",
      " Regression with ARIMA(1,0,2) errors : -12643.58\n",
      " Regression with ARIMA(2,0,1) errors : -12645.29\n",
      " Regression with ARIMA(3,0,2) errors : -12693.39\n",
      " Regression with ARIMA(3,0,1) errors : -12657.07\n",
      " Regression with ARIMA(4,0,2) errors : -12674.99\n",
      " Regression with ARIMA(3,0,3) errors : -12674.05\n",
      " Regression with ARIMA(2,0,3) errors : -12670.13\n",
      " Regression with ARIMA(4,0,1) errors : -12673.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12586.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12712.63\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12660.79\n",
      " Regression with ARIMA(0,0,0) errors : -9128.864\n",
      " Regression with ARIMA(1,0,0) errors : -12639.5\n",
      " Regression with ARIMA(0,0,1) errors : -10794.45\n",
      " Regression with ARIMA(0,0,0) errors : -8086.79\n",
      " Regression with ARIMA(1,0,2) errors : -12656.36\n",
      " Regression with ARIMA(2,0,1) errors : -12654.67\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12681.02\n",
      " Regression with ARIMA(1,0,3) errors : -12683.93\n",
      " Regression with ARIMA(0,0,3) errors : -11882.7\n",
      " Regression with ARIMA(1,0,4) errors : -12681.93\n",
      " Regression with ARIMA(0,0,2) errors : -11451.05\n",
      " Regression with ARIMA(0,0,4) errors : -12222.24\n",
      " Regression with ARIMA(2,0,4) errors : -12708.43\n",
      " Regression with ARIMA(3,0,4) errors : -12700.64\n",
      " Regression with ARIMA(2,0,5) errors : -12711.77\n",
      " Regression with ARIMA(1,0,5) errors : -12684.46\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12635.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12712.16\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12663.87\n",
      " Regression with ARIMA(0,0,0) errors : -9125.032\n",
      " Regression with ARIMA(1,0,0) errors : -12642.83\n",
      " Regression with ARIMA(0,0,1) errors : -10795.06\n",
      " Regression with ARIMA(0,0,0) errors : -8088.558\n",
      " Regression with ARIMA(1,0,2) errors : -12659.49\n",
      " Regression with ARIMA(2,0,1) errors : -12657.96\n",
      " Regression with ARIMA(3,0,2) errors : -12717.9\n",
      " Regression with ARIMA(3,0,1) errors : -12671.05\n",
      " Regression with ARIMA(4,0,2) errors : -12688.31\n",
      " Regression with ARIMA(3,0,3) errors : -12688.66\n",
      " Regression with ARIMA(2,0,3) errors : -12684.8\n",
      " Regression with ARIMA(4,0,1) errors : -12687.93\n",
      " Regression with ARIMA(4,0,3) errors : -12724.73\n",
      " Regression with ARIMA(5,0,3) errors : -12705.98\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12706.33\n",
      " Regression with ARIMA(5,0,2) errors : -12704.8\n",
      " Regression with ARIMA(5,0,4) errors : -12707.76\n",
      " Regression with ARIMA(4,0,3) errors : -12626.28\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12711.43\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12675.17\n",
      " Regression with ARIMA(0,0,0) errors : -9127.822\n",
      " Regression with ARIMA(1,0,0) errors : -12652.69\n",
      " Regression with ARIMA(0,0,1) errors : -10797.32\n",
      " Regression with ARIMA(0,0,0) errors : -8122.42\n",
      " Regression with ARIMA(1,0,2) errors : -12669.49\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12695.32\n",
      " Regression with ARIMA(1,0,3) errors : -12697.68\n",
      " Regression with ARIMA(0,0,3) errors : -11885.17\n",
      " Regression with ARIMA(1,0,4) errors : -12695.67\n",
      " Regression with ARIMA(0,0,2) errors : -11454.21\n",
      " Regression with ARIMA(0,0,4) errors : -12223.07\n",
      " Regression with ARIMA(2,0,4) errors : -12724.02\n",
      " Regression with ARIMA(3,0,4) errors : -12727\n",
      " Regression with ARIMA(3,0,3) errors : -12699.87\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12728.15\n",
      " Regression with ARIMA(1,0,5) errors : -12698.24\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12723.48\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12683.94\n",
      " Regression with ARIMA(0,0,0) errors : -9138.188\n",
      " Regression with ARIMA(1,0,0) errors : -12661.92\n",
      " Regression with ARIMA(0,0,1) errors : -10809.04\n",
      " Regression with ARIMA(0,0,0) errors : -8146.342\n",
      " Regression with ARIMA(1,0,2) errors : -12678.66\n",
      " Regression with ARIMA(2,0,1) errors : -12676.73\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12704.85\n",
      " Regression with ARIMA(1,0,3) errors : -12707.91\n",
      " Regression with ARIMA(0,0,3) errors : -11899.86\n",
      " Regression with ARIMA(1,0,4) errors : -12705.92\n",
      " Regression with ARIMA(0,0,2) errors : -11462.84\n",
      " Regression with ARIMA(0,0,4) errors : -12239.61\n",
      " Regression with ARIMA(2,0,4) errors : -12733.61\n",
      " Regression with ARIMA(3,0,4) errors : -12727.8\n",
      " Regression with ARIMA(2,0,5) errors : -12736.88\n",
      " Regression with ARIMA(1,0,5) errors : -12708.11\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12658.61\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12738.19\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12707.9\n",
      " Regression with ARIMA(0,0,0) errors : -9146.696\n",
      " Regression with ARIMA(1,0,0) errors : -12685.85\n",
      " Regression with ARIMA(0,0,1) errors : -10816.31\n",
      " Regression with ARIMA(0,0,0) errors : -8145.991\n",
      " Regression with ARIMA(1,0,2) errors : -12701.98\n",
      " Regression with ARIMA(2,0,1) errors : -12702.83\n",
      " Regression with ARIMA(3,0,2) errors : -12752.59\n",
      " Regression with ARIMA(3,0,1) errors : -12716.78\n",
      " Regression with ARIMA(4,0,2) errors : -12776.93\n",
      " Regression with ARIMA(4,0,1) errors : -12738.81\n",
      " Regression with ARIMA(5,0,2) errors : -12750.69\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -12740.15\n",
      " Regression with ARIMA(5,0,1) errors : -12807.17\n",
      " Regression with ARIMA(5,0,0) errors : -12741.34\n",
      " Regression with ARIMA(4,0,0) errors : -12738.7\n",
      " Regression with ARIMA(5,0,1) errors : -12728.9\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12760.88\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12912.84\n",
      " Regression with ARIMA(0,0,0) errors : -9287.558\n",
      " Regression with ARIMA(1,0,0) errors : -12838.23\n",
      " Regression with ARIMA(0,0,1) errors : -10970.44\n",
      " Regression with ARIMA(0,0,0) errors : -8334.607\n",
      " Regression with ARIMA(1,0,2) errors : -12850.07\n",
      " Regression with ARIMA(2,0,1) errors : -12896.83\n",
      " Regression with ARIMA(3,0,2) errors : -12886.59\n",
      " Regression with ARIMA(2,0,3) errors : -12920.49\n",
      " Regression with ARIMA(1,0,3) errors : -12869.31\n",
      " Regression with ARIMA(3,0,3) errors : -12922.93\n",
      " Regression with ARIMA(4,0,3) errors : -12951.22\n",
      " Regression with ARIMA(4,0,2) errors : -12979.64\n",
      " Regression with ARIMA(4,0,1) errors : -12919.17\n",
      " Regression with ARIMA(5,0,2) errors : -13016.01\n",
      " Regression with ARIMA(5,0,1) errors : -12918.05\n",
      " Regression with ARIMA(5,0,3) errors : -13009.45\n",
      " Regression with ARIMA(5,0,2) errors : -12924.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -12851.52\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13340.53\n",
      " Regression with ARIMA(0,0,0) errors : -9896.247\n",
      " Regression with ARIMA(1,0,0) errors : -13321.04\n",
      " Regression with ARIMA(0,0,1) errors : -11543.52\n",
      " Regression with ARIMA(0,0,0) errors : -8940.049\n",
      " Regression with ARIMA(1,0,2) errors : -13322.44\n",
      " Regression with ARIMA(2,0,1) errors : -13321.63\n",
      " Regression with ARIMA(3,0,2) errors : -13355.77\n",
      " Regression with ARIMA(3,0,1) errors : -13337\n",
      " Regression with ARIMA(4,0,2) errors : -13354.79\n",
      " Regression with ARIMA(3,0,3) errors : -13380.32\n",
      " Regression with ARIMA(2,0,3) errors : -13333.79\n",
      " Regression with ARIMA(4,0,3) errors : -13412.84\n",
      " Regression with ARIMA(5,0,3) errors : -13428.89\n",
      " Regression with ARIMA(5,0,2) errors : -13429.21\n",
      " Regression with ARIMA(5,0,1) errors : -13348.63\n",
      " Regression with ARIMA(4,0,1) errors : -13348.07\n",
      " Regression with ARIMA(5,0,2) errors : -13296.63\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13383.36\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13638.8\n",
      " Regression with ARIMA(0,1,0) errors : -13557.1\n",
      " Regression with ARIMA(1,1,0) errors : -13569.73\n",
      " Regression with ARIMA(0,1,1) errors : -13568.98\n",
      " Regression with ARIMA(0,1,0) errors : -13559.1\n",
      " Regression with ARIMA(1,1,2) errors : -13569.88\n",
      " Regression with ARIMA(2,1,1) errors : -13572.21\n",
      " Regression with ARIMA(3,1,2) errors : -13655.74\n",
      " Regression with ARIMA(3,1,1) errors : -13608.61\n",
      " Regression with ARIMA(4,1,2) errors : -13690.96\n",
      " Regression with ARIMA(4,1,1) errors : -13635.24\n",
      " Regression with ARIMA(5,1,2) errors : -13685.37\n",
      " Regression with ARIMA(4,1,3) errors : -13668.95\n",
      " Regression with ARIMA(3,1,3) errors : -13656.78\n",
      " Regression with ARIMA(5,1,1) errors : -13674.36\n",
      " Regression with ARIMA(5,1,3) errors : -13699.07\n",
      " Regression with ARIMA(5,1,4) errors : -13798\n",
      " Regression with ARIMA(4,1,4) errors : -13766.7\n",
      " Regression with ARIMA(5,1,5) errors : -13796.13\n",
      " Regression with ARIMA(4,1,5) errors : -13791.29\n",
      " Regression with ARIMA(5,1,4) errors : -13800.01\n",
      " Regression with ARIMA(4,1,4) errors : -13768.68\n",
      " Regression with ARIMA(5,1,3) errors : -13701.1\n",
      " Regression with ARIMA(5,1,5) errors : -13798.15\n",
      " Regression with ARIMA(4,1,3) errors : -13669.36\n",
      " Regression with ARIMA(4,1,5) errors : -13793.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,4) errors : -13627.14\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13856.97\n",
      " Regression with ARIMA(0,1,0) errors : -13830.28\n",
      " Regression with ARIMA(1,1,0) errors : -13844.83\n",
      " Regression with ARIMA(0,1,1) errors : -13841.77\n",
      " Regression with ARIMA(0,1,0) errors : -13832.29\n",
      " Regression with ARIMA(1,1,2) errors : -13852.88\n",
      " Regression with ARIMA(2,1,1) errors : -13857.98\n",
      " Regression with ARIMA(1,1,1) errors : -13853.24\n",
      " Regression with ARIMA(2,1,0) errors : -13857.59\n",
      " Regression with ARIMA(3,1,1) errors : -13856.45\n",
      " Regression with ARIMA(3,1,0) errors : -13855.79\n",
      " Regression with ARIMA(3,1,2) errors : -13853.87\n",
      " Regression with ARIMA(2,1,1) errors : -13859.99\n",
      " Regression with ARIMA(1,1,1) errors : -13855.24\n",
      " Regression with ARIMA(2,1,0) errors : -13859.61\n",
      " Regression with ARIMA(3,1,1) errors : -13858.47\n",
      " Regression with ARIMA(2,1,2) errors : -13858.99\n",
      " Regression with ARIMA(1,1,0) errors : -13846.84\n",
      " Regression with ARIMA(1,1,2) errors : -13854.88\n",
      " Regression with ARIMA(3,1,0) errors : -13857.8\n",
      " Regression with ARIMA(3,1,2) errors : -13855.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : -13852.22\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,1) errors \n",
      "\n",
      "[1] \"90 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13947.36\n",
      " Regression with ARIMA(0,1,0) errors : -13900.86\n",
      " Regression with ARIMA(1,1,0) errors : -13932.84\n",
      " Regression with ARIMA(0,1,1) errors : -13911.73\n",
      " Regression with ARIMA(0,1,0) errors : -13902.87\n",
      " Regression with ARIMA(1,1,2) errors : -13939.01\n",
      " Regression with ARIMA(2,1,1) errors : -13943.65\n",
      " Regression with ARIMA(3,1,2) errors : -13959.09\n",
      " Regression with ARIMA(3,1,1) errors : -13956.45\n",
      " Regression with ARIMA(4,1,2) errors : -14000.17\n",
      " Regression with ARIMA(4,1,1) errors : -13952.05\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : -14004.61\n",
      " Regression with ARIMA(3,1,3) errors : -13984.19\n",
      " Regression with ARIMA(5,1,3) errors : -14058.98\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : -14034.52\n",
      " Regression with ARIMA(5,1,3) errors : -14060.9\n",
      " Regression with ARIMA(4,1,3) errors : -14006.63\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : -14002.15\n",
      " Regression with ARIMA(4,1,4) errors : -14036.43\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : -13974.19\n",
      "\n",
      " Best model: Regression with ARIMA(4,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14051.09\n",
      " Regression with ARIMA(0,1,0) errors : -14017.53\n",
      " Regression with ARIMA(1,1,0) errors : -14026.02\n",
      " Regression with ARIMA(0,1,1) errors : -14026.4\n",
      " Regression with ARIMA(0,1,0) errors : -14019.51\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14049.92\n",
      " Regression with ARIMA(3,1,2) errors : -14072.45\n",
      " Regression with ARIMA(3,1,1) errors : -14060.26\n",
      " Regression with ARIMA(4,1,2) errors : -14078.94\n",
      " Regression with ARIMA(4,1,1) errors : -14061.76\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : -14126.2\n",
      " Regression with ARIMA(2,1,3) errors : -14050.56\n",
      " Regression with ARIMA(3,1,4) errors : -14077.3\n",
      " Regression with ARIMA(2,1,4) errors : -14048.58\n",
      " Regression with ARIMA(4,1,4) errors : -14193.59\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14215.31\n",
      " Regression with ARIMA(2,1,5) errors : -14059.26\n",
      " Regression with ARIMA(3,1,5) errors : -14216.42\n",
      " Regression with ARIMA(2,1,5) errors : -14061.28\n",
      " Regression with ARIMA(3,1,4) errors : -14177.43\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14050.61\n",
      " Regression with ARIMA(4,1,4) errors : -14194.71\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -14036.04\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14232.72\n",
      " Regression with ARIMA(0,1,0) errors : -14162.77\n",
      " Regression with ARIMA(1,1,0) errors : -14185.38\n",
      " Regression with ARIMA(0,1,1) errors : -14173.07\n",
      " Regression with ARIMA(0,1,0) errors : -14164.75\n",
      " Regression with ARIMA(1,1,2) errors : -14207.81\n",
      " Regression with ARIMA(2,1,1) errors : -14224.23\n",
      " Regression with ARIMA(3,1,2) errors : -14248.4\n",
      " Regression with ARIMA(3,1,1) errors : -14225.86\n",
      " Regression with ARIMA(4,1,2) errors : -14270.04\n",
      " Regression with ARIMA(4,1,1) errors : -14226.79\n",
      " Regression with ARIMA(5,1,2) errors : -14276.69\n",
      " Regression with ARIMA(5,1,1) errors : -14239.31\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : -14278.66\n",
      " Regression with ARIMA(4,1,2) errors : -14272.05\n",
      " Regression with ARIMA(5,1,1) errors : -14241.32\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : -14228.77\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,1) errors : -14188.43\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14269.51\n",
      " Regression with ARIMA(1,1,0) errors : -14280.67\n",
      " Regression with ARIMA(0,1,1) errors : -14275.99\n",
      " Regression with ARIMA(0,1,0) errors : -14271.49\n",
      " Regression with ARIMA(2,1,0) errors : -14280.26\n",
      " Regression with ARIMA(1,1,1) errors : -14283.64\n",
      " Regression with ARIMA(2,1,1) errors : -14282.63\n",
      " Regression with ARIMA(1,1,2) errors : -14281.81\n",
      " Regression with ARIMA(0,1,2) errors : -14276.35\n",
      " Regression with ARIMA(1,1,1) errors : -14285.62\n",
      " Regression with ARIMA(0,1,1) errors : -14277.97\n",
      " Regression with ARIMA(1,1,0) errors : -14282.66\n",
      " Regression with ARIMA(2,1,1) errors : -14284.63\n",
      " Regression with ARIMA(1,1,2) errors : -14283.8\n",
      " Regression with ARIMA(0,1,2) errors : -14278.33\n",
      " Regression with ARIMA(2,1,0) errors : -14282.25\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14292.77\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14392.52\n",
      " Regression with ARIMA(0,1,0) errors : -14319.87\n",
      " Regression with ARIMA(1,1,0) errors : -14323.95\n",
      " Regression with ARIMA(0,1,1) errors : -14324.28\n",
      " Regression with ARIMA(0,1,0) errors : -14321.88\n",
      " Regression with ARIMA(1,1,2) errors : -14328.67\n",
      " Regression with ARIMA(2,1,1) errors : -14322.2\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14396.05\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14397.58\n",
      " Regression with ARIMA(1,1,4) errors : -14325.55\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14409.11\n",
      " Regression with ARIMA(0,1,5) errors : -14329.22\n",
      " Regression with ARIMA(0,1,4) errors : -14322.36\n",
      " Regression with ARIMA(1,1,5) errors : -14410.56\n",
      " Regression with ARIMA(0,1,5) errors : -14331.23\n",
      " Regression with ARIMA(1,1,4) errors : -14327.56\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(0,1,4) errors : -14324.37\n",
      " Regression with ARIMA(2,1,4) errors : -14399.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,5) errors : -14340.4\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14414.39\n",
      " Regression with ARIMA(0,1,0) errors : -14347.05\n",
      " Regression with ARIMA(1,1,0) errors : -14351.5\n",
      " Regression with ARIMA(0,1,1) errors : -14351.98\n",
      " Regression with ARIMA(0,1,0) errors : -14349.06\n",
      " Regression with ARIMA(1,1,2) errors : -14355.74\n",
      " Regression with ARIMA(2,1,1) errors : -14357.14\n",
      " Regression with ARIMA(3,1,2) errors : -14356.58\n",
      " Regression with ARIMA(2,1,3) errors : -14416.78\n",
      " Regression with ARIMA(1,1,3) errors : -14352.44\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14426.08\n",
      " Regression with ARIMA(1,1,4) errors : -14352.46\n",
      " Regression with ARIMA(3,1,4) errors : -14359.23\n",
      " Regression with ARIMA(2,1,5) errors : -14433.08\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14448.43\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14449.79\n",
      " Regression with ARIMA(2,1,5) errors : -14434.5\n",
      " Regression with ARIMA(3,1,4) errors : -14361.25\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14427.62\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14373.05\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14467.17\n",
      " Regression with ARIMA(0,1,0) errors : -14387.79\n",
      " Regression with ARIMA(1,1,0) errors : -14392.42\n",
      " Regression with ARIMA(0,1,1) errors : -14393.12\n",
      " Regression with ARIMA(0,1,0) errors : -14389.79\n",
      " Regression with ARIMA(1,1,2) errors : -14393.52\n",
      " Regression with ARIMA(2,1,1) errors : -14392.46\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14467.02\n",
      " Regression with ARIMA(1,1,1) errors : -14394.63\n",
      " Regression with ARIMA(1,1,3) errors : -14391.52\n",
      " Regression with ARIMA(3,1,1) errors : -14450.2\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -14468.77\n",
      " Regression with ARIMA(1,1,2) errors : -14395.53\n",
      " Regression with ARIMA(2,1,1) errors : -14394.46\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14468.52\n",
      " Regression with ARIMA(1,1,1) errors : -14396.63\n",
      " Regression with ARIMA(1,1,3) errors : -14393.52\n",
      " Regression with ARIMA(3,1,1) errors : -14452.03\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : -14406.82\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11132.19\n",
      " Regression with ARIMA(1,0,0) errors : -14540.36\n",
      " Regression with ARIMA(0,0,1) errors : -12745.99\n",
      " Regression with ARIMA(0,0,0) errors : -9972.371\n",
      " Regression with ARIMA(2,0,0) errors : -14537.54\n",
      " Regression with ARIMA(1,0,1) errors : -14538.45\n",
      " Regression with ARIMA(2,0,1) errors : -14542.87\n",
      " Regression with ARIMA(3,0,1) errors : -14558.56\n",
      " Regression with ARIMA(3,0,0) errors : -14548.35\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -14559.21\n",
      " Regression with ARIMA(4,0,2) errors : -14555.78\n",
      " Regression with ARIMA(3,0,3) errors : -14558.89\n",
      " Regression with ARIMA(2,0,3) errors : -14545.56\n",
      " Regression with ARIMA(4,0,3) errors : -14553.54\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14560.17\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11151.48\n",
      " Regression with ARIMA(1,0,0) errors : -14551.11\n",
      " Regression with ARIMA(0,0,1) errors : -12768.97\n",
      " Regression with ARIMA(0,0,0) errors : -9991.611\n",
      " Regression with ARIMA(2,0,0) errors : -14548.25\n",
      " Regression with ARIMA(1,0,1) errors : -14549.23\n",
      " Regression with ARIMA(2,0,1) errors : -14552.94\n",
      " Regression with ARIMA(3,0,1) errors : -14567.66\n",
      " Regression with ARIMA(3,0,0) errors : -14558.46\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,0) errors : -14557.43\n",
      " Regression with ARIMA(4,0,2) errors : -14572.3\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -14567.45\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,1) errors : -14571.65\n",
      " Regression with ARIMA(5,0,3) errors : -14591.07\n",
      " Regression with ARIMA(5,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -14588.65\n",
      " Regression with ARIMA(5,0,3) errors : -14466.83\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -14592.39\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14560.15\n",
      " Regression with ARIMA(0,0,0) errors : -11132.88\n",
      " Regression with ARIMA(1,0,0) errors : -14543.96\n",
      " Regression with ARIMA(0,0,1) errors : -12748.49\n",
      " Regression with ARIMA(0,0,0) errors : -9916.669\n",
      " Regression with ARIMA(1,0,2) errors : -14552.05\n",
      " Regression with ARIMA(2,0,1) errors : -14544.14\n",
      " Regression with ARIMA(3,0,2) errors : -14551.85\n",
      " Regression with ARIMA(2,0,3) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -14542.09\n",
      " Regression with ARIMA(1,0,3) errors : -14551.93\n",
      " Regression with ARIMA(3,0,1) errors : -14569.13\n",
      " Regression with ARIMA(3,0,0) errors : -14553.2\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -14542.46\n",
      " Regression with ARIMA(4,0,0) errors : -14553.19\n",
      " Regression with ARIMA(4,0,2) errors : -14568.72\n",
      " Regression with ARIMA(3,0,1) errors : -14400.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -14566.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11155.69\n",
      " Regression with ARIMA(1,0,0) errors : -14548.92\n",
      " Regression with ARIMA(0,0,1) errors : -12768.48\n",
      " Regression with ARIMA(0,0,0) errors : -9907.063\n",
      " Regression with ARIMA(2,0,0) errors : -14546.07\n",
      " Regression with ARIMA(1,0,1) errors : -14546.93\n",
      " Regression with ARIMA(2,0,1) errors : -14550.78\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -14554.96\n",
      " Regression with ARIMA(0,0,2) errors : -13588.57\n",
      " Regression with ARIMA(1,0,3) errors : -14555.05\n",
      " Regression with ARIMA(0,0,3) errors : -13929.67\n",
      " Regression with ARIMA(2,0,3) errors : -14552.73\n",
      " Regression with ARIMA(1,0,4) errors : -14561.38\n",
      " Regression with ARIMA(0,0,4) errors : -14217.43\n",
      " Regression with ARIMA(2,0,4) errors : -14559.98\n",
      " Regression with ARIMA(1,0,5) errors : -14560.36\n",
      " Regression with ARIMA(0,0,5) errors : -14327\n",
      " Regression with ARIMA(2,0,5) errors : -14558.11\n",
      " Regression with ARIMA(1,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,4) errors : -14560.62\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14379.34\n",
      " Regression with ARIMA(1,1,0) errors : -14383.72\n",
      " Regression with ARIMA(0,1,1) errors : -14382.54\n",
      " Regression with ARIMA(0,1,0) errors : -14381.35\n",
      " Regression with ARIMA(2,1,0) errors : -14382.72\n",
      " Regression with ARIMA(1,1,1) errors : -14384.5\n",
      " Regression with ARIMA(2,1,1) errors : -14382.23\n",
      " Regression with ARIMA(1,1,2) errors : -14382.66\n",
      " Regression with ARIMA(0,1,2) errors : -14382.21\n",
      " Regression with ARIMA(1,1,1) errors : -14386.51\n",
      " Regression with ARIMA(0,1,1) errors : -14384.55\n",
      " Regression with ARIMA(1,1,0) errors : -14385.73\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : -14384.54\n",
      " Regression with ARIMA(0,1,2) errors : -14384.22\n",
      " Regression with ARIMA(2,1,0) errors : -14384.73\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14397.22\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14483.22\n",
      " Regression with ARIMA(0,0,0) errors : -11017.35\n",
      " Regression with ARIMA(1,0,0) errors : -14460.22\n",
      " Regression with ARIMA(0,0,1) errors : -12640.36\n",
      " Regression with ARIMA(0,0,0) errors : -9780.733\n",
      " Regression with ARIMA(1,0,2) errors : -14467.99\n",
      " Regression with ARIMA(2,0,1) errors : -14461.13\n",
      " Regression with ARIMA(3,0,2) errors : -14483.56\n",
      " Regression with ARIMA(3,0,1) errors : -14483.17\n",
      " Regression with ARIMA(4,0,2) errors : -14480.81\n",
      " Regression with ARIMA(3,0,3) errors : -14482.96\n",
      " Regression with ARIMA(2,0,3) errors : -14464.37\n",
      " Regression with ARIMA(4,0,1) errors : -14477.63\n",
      " Regression with ARIMA(4,0,3) errors : -14478.99\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14477.22\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14498.8\n",
      " Regression with ARIMA(0,0,0) errors : -11029\n",
      " Regression with ARIMA(1,0,0) errors : -14478.15\n",
      " Regression with ARIMA(0,0,1) errors : -12661.86\n",
      " Regression with ARIMA(0,0,0) errors : -9798.577\n",
      " Regression with ARIMA(1,0,2) errors : -14485.32\n",
      " Regression with ARIMA(2,0,1) errors : -14479.56\n",
      " Regression with ARIMA(3,0,2) errors : -14498.67\n",
      " Regression with ARIMA(2,0,3) errors : -14482.25\n",
      " Regression with ARIMA(1,0,1) errors : -14476.18\n",
      " Regression with ARIMA(1,0,3) errors : -14486.49\n",
      " Regression with ARIMA(3,0,1) errors : -14499.33\n",
      " Regression with ARIMA(3,0,0) errors : -14485.04\n",
      " Regression with ARIMA(4,0,1) errors : -14493.81\n",
      " Regression with ARIMA(2,0,0) errors : -14475.19\n",
      " Regression with ARIMA(4,0,0) errors : -14489\n",
      " Regression with ARIMA(4,0,2) errors : -14497.35\n",
      " Regression with ARIMA(3,0,1) errors : -14328.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -14499.04\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14499.82\n",
      " Regression with ARIMA(0,0,0) errors : -11030.92\n",
      " Regression with ARIMA(1,0,0) errors : -14479.83\n",
      " Regression with ARIMA(0,0,1) errors : -12666.18\n",
      " Regression with ARIMA(0,0,0) errors : -9815.953\n",
      " Regression with ARIMA(1,0,2) errors : -14487.24\n",
      " Regression with ARIMA(2,0,1) errors : -14480.13\n",
      " Regression with ARIMA(3,0,2) errors : -14499.16\n",
      " Regression with ARIMA(2,0,3) errors : -14482.98\n",
      " Regression with ARIMA(1,0,1) errors : -14477.85\n",
      " Regression with ARIMA(1,0,3) errors : -14488.5\n",
      " Regression with ARIMA(3,0,1) errors : -14497.61\n",
      " Regression with ARIMA(3,0,3) errors : -14499.03\n",
      " Regression with ARIMA(2,0,2) errors : -14337.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14481.43\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14520.82\n",
      " Regression with ARIMA(0,0,0) errors : -11039.14\n",
      " Regression with ARIMA(1,0,0) errors : -14493.69\n",
      " Regression with ARIMA(0,0,1) errors : -12672\n",
      " Regression with ARIMA(0,0,0) errors : -9822.197\n",
      " Regression with ARIMA(1,0,2) errors : -14500.76\n",
      " Regression with ARIMA(2,0,1) errors : -14497.56\n",
      " Regression with ARIMA(3,0,2) errors : -14524.84\n",
      " Regression with ARIMA(3,0,1) errors : -14518.61\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -14524.22\n",
      " Regression with ARIMA(2,0,3) errors : -14520.02\n",
      " Regression with ARIMA(4,0,1) errors : -14521.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14510.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14421.28\n",
      " Regression with ARIMA(1,1,0) errors : -14438.68\n",
      " Regression with ARIMA(0,1,1) errors : -14424.25\n",
      " Regression with ARIMA(0,1,0) errors : -14423.29\n",
      " Regression with ARIMA(2,1,0) errors : -14439.8\n",
      " Regression with ARIMA(3,1,0) errors : -14439.79\n",
      " Regression with ARIMA(2,1,1) errors : -14444.89\n",
      " Regression with ARIMA(1,1,1) errors : -14446.77\n",
      " Regression with ARIMA(1,1,2) errors : -14444.79\n",
      " Regression with ARIMA(0,1,2) errors : -14423.33\n",
      " Regression with ARIMA(1,1,1) errors : -14448.78\n",
      " Regression with ARIMA(0,1,1) errors : -14426.26\n",
      " Regression with ARIMA(1,1,0) errors : -14440.69\n",
      " Regression with ARIMA(2,1,1) errors : -14446.9\n",
      " Regression with ARIMA(1,1,2) errors : -14446.8\n",
      " Regression with ARIMA(0,1,2) errors : -14425.34\n",
      " Regression with ARIMA(2,1,0) errors : -14441.81\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14440.01\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14553.28\n",
      " Regression with ARIMA(0,1,0) errors : -14483.96\n",
      " Regression with ARIMA(1,1,0) errors : -14484.77\n",
      " Regression with ARIMA(0,1,1) errors : -14485.54\n",
      " Regression with ARIMA(0,1,0) errors : -14485.96\n",
      " Regression with ARIMA(1,1,2) errors : -14488.25\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14562.68\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14567.68\n",
      " Regression with ARIMA(1,1,4) errors : -14484.21\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14585.28\n",
      " Regression with ARIMA(1,1,5) errors : -14492.24\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14586.81\n",
      " Regression with ARIMA(1,1,5) errors : -14494.25\n",
      " Regression with ARIMA(2,1,4) errors : -14569.27\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : -14485.81\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14504.5\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14595.43\n",
      " Regression with ARIMA(0,1,0) errors : -14527.09\n",
      " Regression with ARIMA(1,1,0) errors : -14529.37\n",
      " Regression with ARIMA(0,1,1) errors : -14529.7\n",
      " Regression with ARIMA(0,1,0) errors : -14529.09\n",
      " Regression with ARIMA(1,1,2) errors : -14533.99\n",
      " Regression with ARIMA(2,1,1) errors : -14543.6\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14601.94\n",
      " Regression with ARIMA(1,1,3) errors : -14532.49\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14605.78\n",
      " Regression with ARIMA(1,1,4) errors : -14530.67\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14537.39\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14607.58\n",
      " Regression with ARIMA(1,1,4) errors : -14532.67\n",
      " Regression with ARIMA(2,1,3) errors : -14603.75\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : -14534.49\n",
      " Regression with ARIMA(1,1,5) errors : -14539.39\n",
      " Regression with ARIMA(3,1,3) errors : -14598.8\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14549.06\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14516.87\n",
      " Regression with ARIMA(1,1,0) errors : -14525.36\n",
      " Regression with ARIMA(0,1,1) errors : -14520.46\n",
      " Regression with ARIMA(0,1,0) errors : -14518.88\n",
      " Regression with ARIMA(2,1,0) errors : -14523.87\n",
      " Regression with ARIMA(1,1,1) errors : -14523.58\n",
      " Regression with ARIMA(2,1,1) errors : -14528.44\n",
      " Regression with ARIMA(3,1,1) errors : -14605.73\n",
      " Regression with ARIMA(3,1,0) errors : -14522.73\n",
      " Regression with ARIMA(4,1,1) errors : -14552.02\n",
      " Regression with ARIMA(3,1,2) errors : -14601.37\n",
      " Regression with ARIMA(4,1,0) errors : -14523.8\n",
      " Regression with ARIMA(4,1,2) errors : -14570.42\n",
      " Regression with ARIMA(3,1,1) errors : -14607.28\n",
      " Regression with ARIMA(2,1,1) errors : -14530.46\n",
      " Regression with ARIMA(3,1,0) errors : -14524.74\n",
      " Regression with ARIMA(4,1,1) errors : -14553.78\n",
      " Regression with ARIMA(3,1,2) errors : -14602.92\n",
      " Regression with ARIMA(2,1,0) errors : -14525.88\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,0) errors : -14525.81\n",
      " Regression with ARIMA(4,1,2) errors : -14572.1\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14535.51\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11250.18\n",
      " Regression with ARIMA(1,0,0) errors : -14656.36\n",
      " Regression with ARIMA(0,0,1) errors : -12862.56\n",
      " Regression with ARIMA(0,0,0) errors : -10027.92\n",
      " Regression with ARIMA(2,0,0) errors : -14654.03\n",
      " Regression with ARIMA(1,0,1) errors : -14654.36\n",
      " Regression with ARIMA(2,0,1) errors : -14660.84\n",
      " Regression with ARIMA(3,0,1) errors : -14661.21\n",
      " Regression with ARIMA(3,0,0) errors : -14664.08\n",
      " Regression with ARIMA(4,0,0) errors : -14664.12\n",
      " Regression with ARIMA(5,0,0) errors : -14670.91\n",
      " Regression with ARIMA(5,0,1) errors : -14674.19\n",
      " Regression with ARIMA(4,0,1) errors : -14674.78\n",
      " Regression with ARIMA(4,0,2) errors : -14678.29\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : -14693.27\n",
      " Regression with ARIMA(5,0,3) errors : -14691.32\n",
      " Regression with ARIMA(4,0,3) errors : -14661.91\n",
      " Regression with ARIMA(5,0,2) errors : -14579.72\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -14701.58\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11249.56\n",
      " Regression with ARIMA(1,0,0) errors : -14656.24\n",
      " Regression with ARIMA(0,0,1) errors : -12864.81\n",
      " Regression with ARIMA(0,0,0) errors : -10027.74\n",
      " Regression with ARIMA(2,0,0) errors : -14657.78\n",
      " Regression with ARIMA(3,0,0) errors : -14666.92\n",
      " Regression with ARIMA(4,0,0) errors : -14666.09\n",
      " Regression with ARIMA(3,0,1) errors : -14664.16\n",
      " Regression with ARIMA(2,0,1) errors : -14658.57\n",
      " Regression with ARIMA(4,0,1) errors : -14666.46\n",
      " Regression with ARIMA(3,0,0) errors : -14546.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,0) errors : -14662.78\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m03.2 <- my.tsCV.2(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                      silent=F,\n",
    "                      xreg=trainx[,2:4],\n",
    "                      sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4fa7c88-54f4-4a91-954c-62b4b79f5327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-01-24\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m03.2\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435ab53e-426a-4b91-9d3a-d037e4dd9995",
   "metadata": {},
   "source": [
    "## Regressor mean of smaller period for forecast \n",
    "- Regressor mean for forecast is calculated from the number of latest 'horizon' period\n",
    "- the 1st model used the number of latest 'window' period for the calc of regressor mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "035d6b87-06c6-4440-88ae-98eaf1e6ca7b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14728.24\n",
      " Regression with ARIMA(0,1,0) errors : -14705.76\n",
      " Regression with ARIMA(1,1,0) errors : -14703.21\n",
      " Regression with ARIMA(0,1,1) errors : -14703.85\n",
      " Regression with ARIMA(0,1,0) errors : -14707.74\n",
      " Regression with ARIMA(1,1,2) errors : -14755.07\n",
      " Regression with ARIMA(0,1,2) errors : -14703.58\n",
      " Regression with ARIMA(1,1,1) errors : -14701.2\n",
      " Regression with ARIMA(1,1,3) errors : -14756.2\n",
      " Regression with ARIMA(0,1,3) errors : -14715.69\n",
      " Regression with ARIMA(2,1,3) errors : -14743.68\n",
      " Regression with ARIMA(1,1,4) errors : -14754.84\n",
      " Regression with ARIMA(0,1,4) errors : -14713.96\n",
      " Regression with ARIMA(2,1,4) errors : -14742.53\n",
      " Regression with ARIMA(1,1,3) errors : -14757.92\n",
      " Regression with ARIMA(0,1,3) errors : -14717.66\n",
      " Regression with ARIMA(1,1,2) errors : -14756.77\n",
      " Regression with ARIMA(2,1,3) errors : -14745.4\n",
      " Regression with ARIMA(1,1,4) errors : -14756.51\n",
      " Regression with ARIMA(0,1,2) errors : -14705.55\n",
      " Regression with ARIMA(0,1,4) errors : -14715.93\n",
      " Regression with ARIMA(2,1,2) errors : -14729.97\n",
      " Regression with ARIMA(2,1,4) errors : -14744.25\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14726.99\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14688.58\n",
      " Regression with ARIMA(1,1,0) errors : -14687.3\n",
      " Regression with ARIMA(0,1,1) errors : -14686.7\n",
      " Regression with ARIMA(0,1,0) errors : -14690.58\n",
      " Regression with ARIMA(1,1,1) errors : -14685.35\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14699.9\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14648.88\n",
      " Regression with ARIMA(1,1,0) errors : -14646.36\n",
      " Regression with ARIMA(0,1,1) errors : -14647.06\n",
      " Regression with ARIMA(0,1,0) errors : -14650.88\n",
      " Regression with ARIMA(1,1,1) errors : -14644.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14660.19\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14557.56\n",
      " Regression with ARIMA(1,1,0) errors : -14555.41\n",
      " Regression with ARIMA(0,1,1) errors : -14555.93\n",
      " Regression with ARIMA(0,1,0) errors : -14559.56\n",
      " Regression with ARIMA(1,1,1) errors : -14553.98\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14568.83\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14466.15\n",
      " Regression with ARIMA(1,1,0) errors : -14464.59\n",
      " Regression with ARIMA(0,1,1) errors : -14465.14\n",
      " Regression with ARIMA(0,1,0) errors : -14468.15\n",
      " Regression with ARIMA(1,1,1) errors : -14463.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14477.38\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14431.62\n",
      " Regression with ARIMA(1,1,0) errors : -14429.42\n",
      " Regression with ARIMA(0,1,1) errors : -14430.5\n",
      " Regression with ARIMA(0,1,0) errors : -14433.63\n",
      " Regression with ARIMA(1,1,1) errors : -14428.06\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14442.84\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14487.01\n",
      " Regression with ARIMA(0,1,0) errors : -14420.66\n",
      " Regression with ARIMA(1,1,0) errors : -14418.52\n",
      " Regression with ARIMA(0,1,1) errors : -14419.3\n",
      " Regression with ARIMA(0,1,0) errors : -14422.67\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14487.4\n",
      " Regression with ARIMA(1,1,1) errors : -14416.73\n",
      " Regression with ARIMA(2,1,0) errors : -14420.92\n",
      " Regression with ARIMA(3,1,1) errors : -14426\n",
      " Regression with ARIMA(3,1,0) errors : -14427.6\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14489.16\n",
      " Regression with ARIMA(1,1,1) errors : -14418.75\n",
      " Regression with ARIMA(2,1,0) errors : -14422.93\n",
      " Regression with ARIMA(3,1,1) errors : -14427.99\n",
      " Regression with ARIMA(2,1,2) errors : -14488.71\n",
      " Regression with ARIMA(1,1,0) errors : -14420.53\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -14429.61\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -14440.44\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14445.76\n",
      " Regression with ARIMA(0,1,0) errors : -14415.25\n",
      " Regression with ARIMA(1,1,0) errors : -14413.72\n",
      " Regression with ARIMA(0,1,1) errors : -14413.85\n",
      " Regression with ARIMA(0,1,0) errors : -14417.26\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14433.81\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14468.58\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14468.82\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14469.94\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14471.73\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14470.6\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14426.46\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14421.25\n",
      " Regression with ARIMA(1,1,0) errors : -14418.78\n",
      " Regression with ARIMA(0,1,1) errors : -14419.77\n",
      " Regression with ARIMA(0,1,0) errors : -14423.26\n",
      " Regression with ARIMA(1,1,1) errors : -14417.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14432.47\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14414.4\n",
      " Regression with ARIMA(1,1,0) errors : -14411.72\n",
      " Regression with ARIMA(0,1,1) errors : -14412.71\n",
      " Regression with ARIMA(0,1,0) errors : -14416.41\n",
      " Regression with ARIMA(1,1,1) errors : -14410.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14425.61\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14371.6\n",
      " Regression with ARIMA(1,1,0) errors : -14369.53\n",
      " Regression with ARIMA(0,1,1) errors : -14370.05\n",
      " Regression with ARIMA(0,1,0) errors : -14373.59\n",
      " Regression with ARIMA(1,1,1) errors : -14368.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14382.78\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14319.68\n",
      " Regression with ARIMA(0,1,0) errors : -14316.26\n",
      " Regression with ARIMA(1,1,0) errors : -14313.77\n",
      " Regression with ARIMA(0,1,1) errors : -14314.65\n",
      " Regression with ARIMA(0,1,0) errors : -14318.23\n",
      " Regression with ARIMA(1,1,2) errors : -14385.93\n",
      " Regression with ARIMA(0,1,2) errors : -14319.04\n",
      " Regression with ARIMA(1,1,1) errors : -14312.24\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14327.45\n",
      " Regression with ARIMA(2,1,1) errors : -14356.37\n",
      " Regression with ARIMA(2,1,3) errors : -14367.96\n",
      " Regression with ARIMA(1,1,2) errors : -14387.45\n",
      " Regression with ARIMA(0,1,2) errors : -14321.01\n",
      " Regression with ARIMA(1,1,1) errors : -14314.22\n",
      " Regression with ARIMA(2,1,2) errors : -14321.64\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(0,1,1) errors : -14316.62\n",
      " Regression with ARIMA(0,1,3) errors : -14329.42\n",
      " Regression with ARIMA(2,1,1) errors : -14358.04\n",
      " Regression with ARIMA(2,1,3) errors : -14369.57\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14338.56\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14254.7\n",
      " Regression with ARIMA(1,1,0) errors : -14252.25\n",
      " Regression with ARIMA(0,1,1) errors : -14252.87\n",
      " Regression with ARIMA(0,1,0) errors : -14256.7\n",
      " Regression with ARIMA(1,1,1) errors : -14250.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14265.84\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14249.15\n",
      " Regression with ARIMA(1,1,0) errors : -14246.58\n",
      " Regression with ARIMA(0,1,1) errors : -14247.46\n",
      " Regression with ARIMA(0,1,0) errors : -14251.14\n",
      " Regression with ARIMA(1,1,1) errors : -14245.11\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14260.28\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14341.48\n",
      " Regression with ARIMA(0,0,0) errors : -10840.14\n",
      " Regression with ARIMA(1,0,0) errors : -14339.73\n",
      " Regression with ARIMA(0,0,1) errors : -12569.99\n",
      " Regression with ARIMA(0,0,0) errors : -9528.814\n",
      " Regression with ARIMA(1,0,2) errors : -14343.89\n",
      " Regression with ARIMA(0,0,2) errors : -13424.35\n",
      " Regression with ARIMA(1,0,1) errors : -14345.89\n",
      " Regression with ARIMA(2,0,1) errors : -14342.88\n",
      " Regression with ARIMA(2,0,0) errors : -14344.83\n",
      " Regression with ARIMA(1,0,1) errors : -14199.07\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14344.44\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14131.23\n",
      " Regression with ARIMA(1,1,0) errors : -14129.6\n",
      " Regression with ARIMA(0,1,1) errors : -14129.22\n",
      " Regression with ARIMA(0,1,0) errors : -14133.21\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14142.29\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14104.7\n",
      " Regression with ARIMA(1,1,0) errors : -14102.15\n",
      " Regression with ARIMA(0,1,1) errors : -14102.72\n",
      " Regression with ARIMA(0,1,0) errors : -14106.71\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14115.78\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14094.76\n",
      " Regression with ARIMA(1,1,0) errors : -14092.35\n",
      " Regression with ARIMA(0,1,1) errors : -14092.76\n",
      " Regression with ARIMA(0,1,0) errors : -14096.76\n",
      " Regression with ARIMA(1,1,1) errors : -14091.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14105.82\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14158.82\n",
      " Regression with ARIMA(0,1,0) errors : -14086.53\n",
      " Regression with ARIMA(1,1,0) errors : -14083.63\n",
      " Regression with ARIMA(0,1,1) errors : -14084.57\n",
      " Regression with ARIMA(0,1,0) errors : -14088.54\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14155.6\n",
      " Regression with ARIMA(3,1,2) errors : -14153.06\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : -14177.73\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14178.44\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14179.86\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14181.4\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14179.99\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14166.32\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14097.6\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14074.57\n",
      " Regression with ARIMA(1,1,0) errors : -14071.57\n",
      " Regression with ARIMA(0,1,1) errors : -14072.57\n",
      " Regression with ARIMA(0,1,0) errors : -14076.57\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14085.63\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14156.68\n",
      " Regression with ARIMA(0,0,0) errors : -10543.02\n",
      " Regression with ARIMA(1,0,0) errors : -14157.58\n",
      " Regression with ARIMA(0,0,1) errors : -12288.52\n",
      " Regression with ARIMA(0,0,0) errors : -9161.948\n",
      " Regression with ARIMA(2,0,0) errors : -14160.85\n",
      " Regression with ARIMA(3,0,0) errors : -14159.41\n",
      " Regression with ARIMA(2,0,1) errors : -14158.76\n",
      " Regression with ARIMA(1,0,1) errors : -14161.58\n",
      " Regression with ARIMA(1,0,2) errors : -14159.57\n",
      " Regression with ARIMA(0,0,2) errors : -13166.06\n",
      " Regression with ARIMA(1,0,1) errors : -14036.84\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14160.49\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14097.59\n",
      " Regression with ARIMA(0,0,0) errors : -10474.05\n",
      " Regression with ARIMA(1,0,0) errors : -14096.1\n",
      " Regression with ARIMA(0,0,1) errors : -12234.47\n",
      " Regression with ARIMA(0,0,0) errors : -9152.683\n",
      " Regression with ARIMA(1,0,2) errors : -14099.35\n",
      " Regression with ARIMA(0,0,2) errors : -13115.29\n",
      " Regression with ARIMA(1,0,1) errors : -14101.37\n",
      " Regression with ARIMA(2,0,1) errors : -14098.29\n",
      " Regression with ARIMA(2,0,0) errors : -14100.36\n",
      " Regression with ARIMA(1,0,1) errors : -13962.68\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14100.49\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13956.34\n",
      " Regression with ARIMA(1,1,0) errors : -13954.24\n",
      " Regression with ARIMA(0,1,1) errors : -13954.58\n",
      " Regression with ARIMA(0,1,0) errors : -13958.35\n",
      " Regression with ARIMA(1,1,1) errors : -13952.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13967.35\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13942.25\n",
      " Regression with ARIMA(1,1,0) errors : -13939.51\n",
      " Regression with ARIMA(0,1,1) errors : -13940.54\n",
      " Regression with ARIMA(0,1,0) errors : -13944.26\n",
      " Regression with ARIMA(1,1,1) errors : -13938.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13953.25\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "[1] \"10 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14057.56\n",
      " Regression with ARIMA(0,0,0) errors : -10451.94\n",
      " Regression with ARIMA(1,0,0) errors : -14055.02\n",
      " Regression with ARIMA(0,0,1) errors : -12212.26\n",
      " Regression with ARIMA(0,0,0) errors : -9125.585\n",
      " Regression with ARIMA(1,0,2) errors : -14059.61\n",
      " Regression with ARIMA(0,0,2) errors : -13092.48\n",
      " Regression with ARIMA(1,0,1) errors : -14061.59\n",
      " Regression with ARIMA(2,0,1) errors : -14058.81\n",
      " Regression with ARIMA(2,0,0) errors : -14060.82\n",
      " Regression with ARIMA(1,0,1) errors : -13926.65\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14060.43\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14049.73\n",
      " Regression with ARIMA(0,0,0) errors : -10463.36\n",
      " Regression with ARIMA(1,0,0) errors : -14047.15\n",
      " Regression with ARIMA(0,0,1) errors : -12215.94\n",
      " Regression with ARIMA(0,0,0) errors : -9113.651\n",
      " Regression with ARIMA(1,0,2) errors : -14050.93\n",
      " Regression with ARIMA(0,0,2) errors : -13088.83\n",
      " Regression with ARIMA(1,0,1) errors : -14052.85\n",
      " Regression with ARIMA(2,0,1) errors : -14049.93\n",
      " Regression with ARIMA(2,0,0) errors : -14051.82\n",
      " Regression with ARIMA(1,0,1) errors : -13912.48\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14051.09\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13911.02\n",
      " Regression with ARIMA(1,1,0) errors : -13908.48\n",
      " Regression with ARIMA(0,1,1) errors : -13909.2\n",
      " Regression with ARIMA(0,1,0) errors : -13913.03\n",
      " Regression with ARIMA(1,1,1) errors : -13907.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13922.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13900.07\n",
      " Regression with ARIMA(1,1,0) errors : -13897.25\n",
      " Regression with ARIMA(0,1,1) errors : -13898.14\n",
      " Regression with ARIMA(0,1,0) errors : -13902.07\n",
      " Regression with ARIMA(1,1,1) errors : -13896.05\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13911.05\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13876.42\n",
      " Regression with ARIMA(0,1,0) errors : -13873.69\n",
      " Regression with ARIMA(1,1,0) errors : -13870.8\n",
      " Regression with ARIMA(0,1,1) errors : -13871.79\n",
      " Regression with ARIMA(0,1,0) errors : -13875.69\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -13951.7\n",
      " Regression with ARIMA(1,1,1) errors : -13869.75\n",
      " Regression with ARIMA(2,1,0) errors : -13877.74\n",
      " Regression with ARIMA(3,1,1) errors : -13879.69\n",
      " Regression with ARIMA(3,1,0) errors : -13878.26\n",
      " Regression with ARIMA(3,1,2) errors : -13880.96\n",
      " Regression with ARIMA(2,1,1) errors : -13953.47\n",
      " Regression with ARIMA(1,1,1) errors : -13871.73\n",
      " Regression with ARIMA(2,1,0) errors : -13879.75\n",
      " Regression with ARIMA(3,1,1) errors : -13881.7\n",
      " Regression with ARIMA(2,1,2) errors : -13878.44\n",
      " Regression with ARIMA(1,1,0) errors : -13872.8\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -13880.27\n",
      " Regression with ARIMA(3,1,2) errors : -13883\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -13906.38\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13861.23\n",
      " Regression with ARIMA(1,1,0) errors : -13858.29\n",
      " Regression with ARIMA(0,1,1) errors : -13859.25\n",
      " Regression with ARIMA(0,1,0) errors : -13863.23\n",
      " Regression with ARIMA(1,1,1) errors : -13857.3\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13872.19\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13896.9\n",
      " Regression with ARIMA(0,0,0) errors : -10196.26\n",
      " Regression with ARIMA(1,0,0) errors : -13893.1\n",
      " Regression with ARIMA(0,0,1) errors : -11966.99\n",
      " Regression with ARIMA(0,0,0) errors : -8742.913\n",
      " Regression with ARIMA(1,0,2) errors : -13897.42\n",
      " Regression with ARIMA(0,0,2) errors : -12878.36\n",
      " Regression with ARIMA(1,0,1) errors : -13899.18\n",
      " Regression with ARIMA(2,0,1) errors : -13896.32\n",
      " Regression with ARIMA(2,0,0) errors : -13897.97\n",
      " Regression with ARIMA(1,0,1) errors : -13775.62\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13898.36\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13779.66\n",
      " Regression with ARIMA(0,0,0) errors : -10097.98\n",
      " Regression with ARIMA(1,0,0) errors : -13771.91\n",
      " Regression with ARIMA(0,0,1) errors : -11865.72\n",
      " Regression with ARIMA(0,0,0) errors : -8710.896\n",
      " Regression with ARIMA(1,0,2) errors : -13777.93\n",
      " Regression with ARIMA(2,0,1) errors : -13777.15\n",
      " Regression with ARIMA(3,0,2) errors : -13783.79\n",
      " Regression with ARIMA(3,0,1) errors : -13778.18\n",
      " Regression with ARIMA(4,0,2) errors : -13782.79\n",
      " Regression with ARIMA(3,0,3) errors : -13790.74\n",
      " Regression with ARIMA(2,0,3) errors : -13778.27\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13781.06\n",
      " Regression with ARIMA(2,0,4) errors : -13781.18\n",
      " Regression with ARIMA(4,0,4) errors : -13783.64\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,3) errors : -13791.61\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13736.94\n",
      " Regression with ARIMA(0,0,0) errors : -10002.66\n",
      " Regression with ARIMA(1,0,0) errors : -13730.41\n",
      " Regression with ARIMA(0,0,1) errors : -11778.89\n",
      " Regression with ARIMA(0,0,0) errors : -8620.765\n",
      " Regression with ARIMA(1,0,2) errors : -13736.26\n",
      " Regression with ARIMA(2,0,1) errors : -13735.25\n",
      " Regression with ARIMA(3,0,2) errors : -13738.48\n",
      " Regression with ARIMA(3,0,1) errors : -13735.53\n",
      " Regression with ARIMA(4,0,2) errors : -13732.51\n",
      " Regression with ARIMA(3,0,3) errors : -13747.21\n",
      " Regression with ARIMA(2,0,3) errors : -13735.02\n",
      " Regression with ARIMA(4,0,3) errors : -13743.42\n",
      " Regression with ARIMA(3,0,4) errors : -13736.01\n",
      " Regression with ARIMA(2,0,4) errors : -13737.88\n",
      " Regression with ARIMA(4,0,4) errors : -13742.31\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,3) errors : -13748.29\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13671.5\n",
      " Regression with ARIMA(0,0,0) errors : -9894.943\n",
      " Regression with ARIMA(1,0,0) errors : -13665.86\n",
      " Regression with ARIMA(0,0,1) errors : -11694.71\n",
      " Regression with ARIMA(0,0,0) errors : -8560.227\n",
      " Regression with ARIMA(1,0,2) errors : -13672.38\n",
      " Regression with ARIMA(0,0,2) errors : -12612.9\n",
      " Regression with ARIMA(1,0,1) errors : -13674.2\n",
      " Regression with ARIMA(2,0,1) errors : -13671.58\n",
      " Regression with ARIMA(2,0,0) errors : -13673.48\n",
      " Regression with ARIMA(1,0,1) errors : -13559.42\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13673.28\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13629.1\n",
      " Regression with ARIMA(0,0,0) errors : -9878.792\n",
      " Regression with ARIMA(1,0,0) errors : -13624.85\n",
      " Regression with ARIMA(0,0,1) errors : -11666.73\n",
      " Regression with ARIMA(0,0,0) errors : -8556.701\n",
      " Regression with ARIMA(1,0,2) errors : -13629.96\n",
      " Regression with ARIMA(0,0,2) errors : -12579.75\n",
      " Regression with ARIMA(1,0,1) errors : -13631.19\n",
      " Regression with ARIMA(2,0,1) errors : -13629.28\n",
      " Regression with ARIMA(2,0,0) errors : -13630.88\n",
      " Regression with ARIMA(1,0,1) errors : -13512.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13630.37\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13611.31\n",
      " Regression with ARIMA(0,0,0) errors : -9870.771\n",
      " Regression with ARIMA(1,0,0) errors : -13607.01\n",
      " Regression with ARIMA(0,0,1) errors : -11652.28\n",
      " Regression with ARIMA(0,0,0) errors : -8549.922\n",
      " Regression with ARIMA(1,0,2) errors : -13611.78\n",
      " Regression with ARIMA(0,0,2) errors : -12567.48\n",
      " Regression with ARIMA(1,0,1) errors : -13612.86\n",
      " Regression with ARIMA(2,0,1) errors : -13620.17\n",
      " Regression with ARIMA(2,0,0) errors : -13612.21\n",
      " Regression with ARIMA(3,0,1) errors : -13610.14\n",
      " Regression with ARIMA(3,0,0) errors : -13609.99\n",
      " Regression with ARIMA(3,0,2) errors : -13609.53\n",
      " Regression with ARIMA(2,0,1) errors : -13511.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13612.06\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13585.71\n",
      " Regression with ARIMA(0,0,0) errors : -9844.615\n",
      " Regression with ARIMA(1,0,0) errors : -13581.02\n",
      " Regression with ARIMA(0,0,1) errors : -11622.06\n",
      " Regression with ARIMA(0,0,0) errors : -8510.432\n",
      " Regression with ARIMA(1,0,2) errors : -13586.32\n",
      " Regression with ARIMA(0,0,2) errors : -12543.41\n",
      " Regression with ARIMA(1,0,1) errors : -13587.02\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -13586.54\n",
      " Regression with ARIMA(1,0,1) errors : -13475.64\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13585.99\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13574.71\n",
      " Regression with ARIMA(0,0,0) errors : -9826.549\n",
      " Regression with ARIMA(1,0,0) errors : -13570.27\n",
      " Regression with ARIMA(0,0,1) errors : -11609.5\n",
      " Regression with ARIMA(0,0,0) errors : -8481.914\n",
      " Regression with ARIMA(1,0,2) errors : -13575.26\n",
      " Regression with ARIMA(0,0,2) errors : -12534.01\n",
      " Regression with ARIMA(1,0,1) errors : -13576.15\n",
      " Regression with ARIMA(2,0,1) errors : -13583.87\n",
      " Regression with ARIMA(2,0,0) errors : -13575.76\n",
      " Regression with ARIMA(3,0,1) errors : -13573.56\n",
      " Regression with ARIMA(3,0,0) errors : -13574.15\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13575.33\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13420.85\n",
      " Regression with ARIMA(1,1,0) errors : -13418.28\n",
      " Regression with ARIMA(0,1,1) errors : -13419.05\n",
      " Regression with ARIMA(0,1,0) errors : -13422.86\n",
      " Regression with ARIMA(1,1,1) errors : -13416.27\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13431.63\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13406.54\n",
      " Regression with ARIMA(1,1,0) errors : -13403.97\n",
      " Regression with ARIMA(0,1,1) errors : -13404.69\n",
      " Regression with ARIMA(0,1,0) errors : -13408.55\n",
      " Regression with ARIMA(1,1,1) errors : -13401.96\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13417.31\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13398.85\n",
      " Regression with ARIMA(1,1,0) errors : -13397.03\n",
      " Regression with ARIMA(0,1,1) errors : -13396.96\n",
      " Regression with ARIMA(0,1,0) errors : -13400.86\n",
      " Regression with ARIMA(1,1,1) errors : -13395.03\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13409.61\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13388.05\n",
      " Regression with ARIMA(1,1,0) errors : -13385.34\n",
      " Regression with ARIMA(0,1,1) errors : -13386.18\n",
      " Regression with ARIMA(0,1,0) errors : -13390.05\n",
      " Regression with ARIMA(1,1,1) errors : -13383.59\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13398.81\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13385.45\n",
      " Regression with ARIMA(1,1,0) errors : -13382.92\n",
      " Regression with ARIMA(0,1,1) errors : -13383.57\n",
      " Regression with ARIMA(0,1,0) errors : -13387.46\n",
      " Regression with ARIMA(1,1,1) errors : -13380.91\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13396.21\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13381.56\n",
      " Regression with ARIMA(1,1,0) errors : -13380.11\n",
      " Regression with ARIMA(0,1,1) errors : -13379.6\n",
      " Regression with ARIMA(0,1,0) errors : -13383.57\n",
      " Regression with ARIMA(1,1,1) errors : -13378.27\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13392.32\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13382.25\n",
      " Regression with ARIMA(1,1,0) errors : -13380.87\n",
      " Regression with ARIMA(0,1,1) errors : -13380.28\n",
      " Regression with ARIMA(0,1,0) errors : -13384.26\n",
      " Regression with ARIMA(1,1,1) errors : -13379.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13393.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13380.14\n",
      " Regression with ARIMA(1,1,0) errors : -13377.47\n",
      " Regression with ARIMA(0,1,1) errors : -13378.15\n",
      " Regression with ARIMA(0,1,0) errors : -13382.15\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.9\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13378.91\n",
      " Regression with ARIMA(1,1,0) errors : -13377.73\n",
      " Regression with ARIMA(0,1,1) errors : -13376.9\n",
      " Regression with ARIMA(0,1,0) errors : -13380.91\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13389.66\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13379.35\n",
      " Regression with ARIMA(1,1,0) errors : -13377.78\n",
      " Regression with ARIMA(0,1,1) errors : -13377.34\n",
      " Regression with ARIMA(0,1,0) errors : -13381.35\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.1\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "[1] \"20 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13379.9\n",
      " Regression with ARIMA(1,1,0) errors : -13377.2\n",
      " Regression with ARIMA(0,1,1) errors : -13377.89\n",
      " Regression with ARIMA(0,1,0) errors : -13381.91\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.66\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13381.25\n",
      " Regression with ARIMA(1,1,0) errors : -13378.41\n",
      " Regression with ARIMA(0,1,1) errors : -13379.25\n",
      " Regression with ARIMA(0,1,0) errors : -13383.26\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13392.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13376.01\n",
      " Regression with ARIMA(1,1,0) errors : -13373.65\n",
      " Regression with ARIMA(0,1,1) errors : -13374\n",
      " Regression with ARIMA(0,1,0) errors : -13378.02\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13386.77\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13369.58\n",
      " Regression with ARIMA(1,1,0) errors : -13366.83\n",
      " Regression with ARIMA(0,1,1) errors : -13367.57\n",
      " Regression with ARIMA(0,1,0) errors : -13371.59\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13380.33\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13497.89\n",
      " Regression with ARIMA(0,0,0) errors : -9950.123\n",
      " Regression with ARIMA(1,0,0) errors : -13493.27\n",
      " Regression with ARIMA(0,0,1) errors : -11642.05\n",
      " Regression with ARIMA(0,0,0) errors : -8458.864\n",
      " Regression with ARIMA(1,0,2) errors : -13494.53\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -13496.04\n",
      " Regression with ARIMA(1,0,1) errors : -13495.7\n",
      " Regression with ARIMA(1,0,3) errors : -13492.7\n",
      " Regression with ARIMA(3,0,1) errors : -13497.36\n",
      " Regression with ARIMA(3,0,3) errors : -13498.01\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13507.72\n",
      " Regression with ARIMA(2,0,4) errors : -13500.47\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13500.7\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13506.03\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13499.98\n",
      " Regression with ARIMA(0,0,0) errors : -9960.775\n",
      " Regression with ARIMA(1,0,0) errors : -13495.47\n",
      " Regression with ARIMA(0,0,1) errors : -11645.81\n",
      " Regression with ARIMA(0,0,0) errors : -8453.629\n",
      " Regression with ARIMA(1,0,2) errors : -13496.49\n",
      " Regression with ARIMA(2,0,1) errors : -13507.19\n",
      " Regression with ARIMA(1,0,1) errors : -13497.52\n",
      " Regression with ARIMA(2,0,0) errors : -13496.74\n",
      " Regression with ARIMA(3,0,1) errors : -13497.31\n",
      " Regression with ARIMA(3,0,0) errors : -13495.2\n",
      " Regression with ARIMA(3,0,2) errors : -13495.71\n",
      " Regression with ARIMA(2,0,1) errors : -13378.82\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13506.74\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13497.77\n",
      " Regression with ARIMA(0,0,0) errors : -9958.269\n",
      " Regression with ARIMA(1,0,0) errors : -13494.31\n",
      " Regression with ARIMA(0,0,1) errors : -11644.45\n",
      " Regression with ARIMA(0,0,0) errors : -8449.905\n",
      " Regression with ARIMA(1,0,2) errors : -13495.3\n",
      " Regression with ARIMA(2,0,1) errors : -13507.9\n",
      " Regression with ARIMA(1,0,1) errors : -13496.33\n",
      " Regression with ARIMA(2,0,0) errors : -13495.6\n",
      " Regression with ARIMA(3,0,1) errors : -13496.54\n",
      " Regression with ARIMA(3,0,0) errors : -13493.75\n",
      " Regression with ARIMA(3,0,2) errors : -13495.71\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13508.08\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13493.96\n",
      " Regression with ARIMA(0,0,0) errors : -9977.205\n",
      " Regression with ARIMA(1,0,0) errors : -13489.97\n",
      " Regression with ARIMA(0,0,1) errors : -11647.24\n",
      " Regression with ARIMA(0,0,0) errors : -8450.876\n",
      " Regression with ARIMA(1,0,2) errors : -13490.98\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13488.95\n",
      " Regression with ARIMA(2,0,3) errors : -13487.5\n",
      " Regression with ARIMA(1,0,1) errors : -13492.01\n",
      " Regression with ARIMA(1,0,3) errors : -13489.23\n",
      " Regression with ARIMA(3,0,1) errors : -13492.37\n",
      " Regression with ARIMA(3,0,3) errors : -13486.94\n",
      " Regression with ARIMA(2,0,2) errors : -13356.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.62\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.03\n",
      " Regression with ARIMA(0,0,0) errors : -10035.28\n",
      " Regression with ARIMA(1,0,0) errors : -13487.39\n",
      " Regression with ARIMA(0,0,1) errors : -11673.35\n",
      " Regression with ARIMA(0,0,0) errors : -8457.324\n",
      " Regression with ARIMA(1,0,2) errors : -13488\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13489.24\n",
      " Regression with ARIMA(2,0,3) errors : -13489.21\n",
      " Regression with ARIMA(1,0,1) errors : -13488.93\n",
      " Regression with ARIMA(1,0,3) errors : -13486.24\n",
      " Regression with ARIMA(3,0,1) errors : -13491.09\n",
      " Regression with ARIMA(3,0,0) errors : -13487.21\n",
      " Regression with ARIMA(4,0,1) errors : -13487.57\n",
      " Regression with ARIMA(2,0,0) errors : -13488.97\n",
      " Regression with ARIMA(4,0,0) errors : -13485.19\n",
      " Regression with ARIMA(4,0,2) errors : -13498.14\n",
      " Regression with ARIMA(5,0,2) errors : -13499.05\n",
      " Regression with ARIMA(5,0,1) errors : -13492.88\n",
      " Regression with ARIMA(5,0,3) errors : -13497.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13501.63\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.2\n",
      " Regression with ARIMA(0,0,0) errors : -10019.33\n",
      " Regression with ARIMA(1,0,0) errors : -13487.57\n",
      " Regression with ARIMA(0,0,1) errors : -11667.27\n",
      " Regression with ARIMA(0,0,0) errors : -8455.887\n",
      " Regression with ARIMA(1,0,2) errors : -13488.56\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13489.44\n",
      " Regression with ARIMA(2,0,3) errors : -13490.16\n",
      " Regression with ARIMA(1,0,1) errors : -13489.31\n",
      " Regression with ARIMA(1,0,3) errors : -13486.85\n",
      " Regression with ARIMA(3,0,1) errors : -13491.32\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13350.82\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.68\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13489.2\n",
      " Regression with ARIMA(0,0,0) errors : -10028.88\n",
      " Regression with ARIMA(1,0,0) errors : -13485\n",
      " Regression with ARIMA(0,0,1) errors : -11673.96\n",
      " Regression with ARIMA(0,0,0) errors : -8443.256\n",
      " Regression with ARIMA(1,0,2) errors : -13486.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -13487.2\n",
      " Regression with ARIMA(1,0,1) errors : -13487.01\n",
      " Regression with ARIMA(1,0,3) errors : -13484.63\n",
      " Regression with ARIMA(3,0,1) errors : -13491.48\n",
      " Regression with ARIMA(3,0,0) errors : -13487\n",
      " Regression with ARIMA(4,0,1) errors : -13489.1\n",
      " Regression with ARIMA(2,0,0) errors : -13486.23\n",
      " Regression with ARIMA(4,0,0) errors : -13484.88\n",
      " Regression with ARIMA(4,0,2) errors : -13500.18\n",
      " Regression with ARIMA(5,0,2) errors : -13502.09\n",
      " Regression with ARIMA(5,0,1) errors : -13494.32\n",
      " Regression with ARIMA(5,0,3) errors : -13500.12\n",
      " Regression with ARIMA(4,0,3) errors : -13500.55\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13500.88\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492\n",
      " Regression with ARIMA(0,0,0) errors : -10028.08\n",
      " Regression with ARIMA(1,0,0) errors : -13487.35\n",
      " Regression with ARIMA(0,0,1) errors : -11679.14\n",
      " Regression with ARIMA(0,0,0) errors : -8442.705\n",
      " Regression with ARIMA(1,0,2) errors : -13488.66\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13487.58\n",
      " Regression with ARIMA(2,0,3) errors : -13489.99\n",
      " Regression with ARIMA(1,0,1) errors : -13489.51\n",
      " Regression with ARIMA(1,0,3) errors : -13487.09\n",
      " Regression with ARIMA(3,0,1) errors : -13489.86\n",
      " Regression with ARIMA(3,0,3) errors : -13482.34\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.71\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13496.48\n",
      " Regression with ARIMA(0,0,0) errors : -10046.87\n",
      " Regression with ARIMA(1,0,0) errors : -13491.11\n",
      " Regression with ARIMA(0,0,1) errors : -11686.59\n",
      " Regression with ARIMA(0,0,0) errors : -8439.819\n",
      " Regression with ARIMA(1,0,2) errors : -13492.36\n",
      " Regression with ARIMA(2,0,1) errors : -13506.72\n",
      " Regression with ARIMA(1,0,1) errors : -13493.26\n",
      " Regression with ARIMA(2,0,0) errors : -13492.87\n",
      " Regression with ARIMA(3,0,1) errors : -13494.79\n",
      " Regression with ARIMA(3,0,0) errors : -13491.08\n",
      " Regression with ARIMA(3,0,2) errors : -13506.27\n",
      " Regression with ARIMA(2,0,1) errors : -13358.47\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13505.42\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.02\n",
      " Regression with ARIMA(0,0,0) errors : -10051.63\n",
      " Regression with ARIMA(1,0,0) errors : -13487.72\n",
      " Regression with ARIMA(0,0,1) errors : -11688.79\n",
      " Regression with ARIMA(0,0,0) errors : -8460.12\n",
      " Regression with ARIMA(1,0,2) errors : -13489\n",
      " Regression with ARIMA(2,0,1) errors : -13501\n",
      " Regression with ARIMA(1,0,1) errors : -13489.93\n",
      " Regression with ARIMA(2,0,0) errors : -13489.16\n",
      " Regression with ARIMA(3,0,1) errors : -13490.72\n",
      " Regression with ARIMA(3,0,0) errors : -13487.43\n",
      " Regression with ARIMA(3,0,2) errors : -13488.68\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13501.14\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13500.43\n",
      " Regression with ARIMA(0,0,0) errors : -10047.97\n",
      " Regression with ARIMA(1,0,0) errors : -13495.4\n",
      " Regression with ARIMA(0,0,1) errors : -11686.73\n",
      " Regression with ARIMA(0,0,0) errors : -8459.472\n",
      " Regression with ARIMA(1,0,2) errors : -13496.66\n",
      " Regression with ARIMA(2,0,1) errors : -13510.38\n",
      " Regression with ARIMA(1,0,1) errors : -13497.58\n",
      " Regression with ARIMA(2,0,0) errors : -13497.07\n",
      " Regression with ARIMA(3,0,1) errors : -13498.19\n",
      " Regression with ARIMA(3,0,0) errors : -13495.29\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13509.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10051.61\n",
      " Regression with ARIMA(1,0,0) errors : -13499.36\n",
      " Regression with ARIMA(0,0,1) errors : -11694.33\n",
      " Regression with ARIMA(0,0,0) errors : -8454.72\n",
      " Regression with ARIMA(2,0,0) errors : -13501.93\n",
      " Regression with ARIMA(3,0,0) errors : -13500.22\n",
      " Regression with ARIMA(2,0,1) errors : -13512.21\n",
      " Regression with ARIMA(1,0,1) errors : -13501.76\n",
      " Regression with ARIMA(3,0,1) errors : -13503.01\n",
      " Regression with ARIMA(1,0,2) errors : -13500.7\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13514.04\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13505.3\n",
      " Regression with ARIMA(0,0,0) errors : -10067.87\n",
      " Regression with ARIMA(1,0,0) errors : -13500.56\n",
      " Regression with ARIMA(0,0,1) errors : -11703.92\n",
      " Regression with ARIMA(0,0,0) errors : -8459.352\n",
      " Regression with ARIMA(1,0,2) errors : -13501.48\n",
      " Regression with ARIMA(2,0,1) errors : -13513.92\n",
      " Regression with ARIMA(1,0,1) errors : -13502.47\n",
      " Regression with ARIMA(2,0,0) errors : -13501.76\n",
      " Regression with ARIMA(3,0,1) errors : -13504.22\n",
      " Regression with ARIMA(3,0,0) errors : -13499.98\n",
      " Regression with ARIMA(3,0,2) errors : -13502.51\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13509.66\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13504.43\n",
      " Regression with ARIMA(0,0,0) errors : -10066.73\n",
      " Regression with ARIMA(1,0,0) errors : -13500.34\n",
      " Regression with ARIMA(0,0,1) errors : -11703.9\n",
      " Regression with ARIMA(0,0,0) errors : -8459.982\n",
      " Regression with ARIMA(1,0,2) errors : -13501.46\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13502.1\n",
      " Regression with ARIMA(2,0,3) errors : -13502.47\n",
      " Regression with ARIMA(1,0,1) errors : -13502.43\n",
      " Regression with ARIMA(1,0,3) errors : -13499.75\n",
      " Regression with ARIMA(3,0,1) errors : -13504.38\n",
      " Regression with ARIMA(3,0,3) errors : -13511.67\n",
      " Regression with ARIMA(4,0,3) errors : -13502.32\n",
      " Regression with ARIMA(3,0,4) errors : -13513.38\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -13510.29\n",
      " Regression with ARIMA(3,0,5) errors : -13505.27\n",
      " Regression with ARIMA(2,0,5) errors : -13506.32\n",
      " Regression with ARIMA(4,0,5) errors : -13507.77\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13512.15\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13504.84\n",
      " Regression with ARIMA(0,0,0) errors : -10082.23\n",
      " Regression with ARIMA(1,0,0) errors : -13499.69\n",
      " Regression with ARIMA(0,0,1) errors : -11711.37\n",
      " Regression with ARIMA(0,0,0) errors : -8482.428\n",
      " Regression with ARIMA(1,0,2) errors : -13500.44\n",
      " Regression with ARIMA(2,0,1) errors : -13506.21\n",
      " Regression with ARIMA(1,0,1) errors : -13501.67\n",
      " Regression with ARIMA(2,0,0) errors : -13507.48\n",
      " Regression with ARIMA(3,0,0) errors : -13505.43\n",
      " Regression with ARIMA(3,0,1) errors : -13508.06\n",
      " Regression with ARIMA(4,0,1) errors : -13504.51\n",
      " Regression with ARIMA(3,0,2) errors : -13507\n",
      " Regression with ARIMA(4,0,0) errors : -13503.26\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -13503.39\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13511.77\n",
      " Regression with ARIMA(0,0,0) errors : -10089.38\n",
      " Regression with ARIMA(1,0,0) errors : -13508.45\n",
      " Regression with ARIMA(0,0,1) errors : -11717.82\n",
      " Regression with ARIMA(0,0,0) errors : -8486.146\n",
      " Regression with ARIMA(1,0,2) errors : -13508.73\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13508.14\n",
      " Regression with ARIMA(2,0,3) errors : -13509.84\n",
      " Regression with ARIMA(1,0,1) errors : -13509.99\n",
      " Regression with ARIMA(1,0,3) errors : -13507.09\n",
      " Regression with ARIMA(3,0,1) errors : -13509.92\n",
      " Regression with ARIMA(3,0,3) errors : -13517.49\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13519.73\n",
      " Regression with ARIMA(2,0,4) errors : -13513.32\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13514.28\n",
      " Regression with ARIMA(4,0,5) errors : -13514.96\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13520.01\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13510.51\n",
      " Regression with ARIMA(0,0,0) errors : -10105.18\n",
      " Regression with ARIMA(1,0,0) errors : -13507.88\n",
      " Regression with ARIMA(0,0,1) errors : -11721.86\n",
      " Regression with ARIMA(0,0,0) errors : -8493.114\n",
      " Regression with ARIMA(1,0,2) errors : -13508.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13516.56\n",
      " Regression with ARIMA(3,0,1) errors : -13506.85\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13515.63\n",
      " Regression with ARIMA(2,0,3) errors : -13508.55\n",
      " Regression with ARIMA(4,0,1) errors : -13509.07\n",
      " Regression with ARIMA(4,0,3) errors : -13513.32\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13519.6\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13508.31\n",
      " Regression with ARIMA(0,0,0) errors : -10126.55\n",
      " Regression with ARIMA(1,0,0) errors : -13507.44\n",
      " Regression with ARIMA(0,0,1) errors : -11732.75\n",
      " Regression with ARIMA(0,0,0) errors : -8479.726\n",
      " Regression with ARIMA(1,0,2) errors : -13507.67\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13508.26\n",
      " Regression with ARIMA(2,0,3) errors : -13506.52\n",
      " Regression with ARIMA(1,0,1) errors : -13508.92\n",
      " Regression with ARIMA(0,0,2) errors : -12538.44\n",
      " Regression with ARIMA(2,0,0) errors : -13508.97\n",
      " Regression with ARIMA(3,0,0) errors : -13506.81\n",
      " Regression with ARIMA(3,0,1) errors : -13510.29\n",
      " Regression with ARIMA(4,0,1) errors : -13507.38\n",
      " Regression with ARIMA(4,0,0) errors : -13504.51\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -13510.44\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10215.23\n",
      " Regression with ARIMA(1,0,0) errors : -13503.24\n",
      " Regression with ARIMA(0,0,1) errors : -11765.85\n",
      " Regression with ARIMA(0,0,0) errors : -8496.584\n",
      " Regression with ARIMA(2,0,0) errors : -13503.84\n",
      " Regression with ARIMA(3,0,0) errors : -13502.9\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13504.35\n",
      " Regression with ARIMA(1,0,2) errors : -13503.03\n",
      " Regression with ARIMA(0,0,2) errors : -12548.3\n",
      " Regression with ARIMA(1,0,1) errors : -13380.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13503.51\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10218.34\n",
      " Regression with ARIMA(1,0,0) errors : -13503.41\n",
      " Regression with ARIMA(0,0,1) errors : -11768.16\n",
      " Regression with ARIMA(0,0,0) errors : -8499.03\n",
      " Regression with ARIMA(2,0,0) errors : -13503.77\n",
      " Regression with ARIMA(3,0,0) errors : -13502.7\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13504.25\n",
      " Regression with ARIMA(1,0,2) errors : -13502.87\n",
      " Regression with ARIMA(0,0,2) errors : -12542.4\n",
      " Regression with ARIMA(1,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13503.42\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "[1] \"30 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13509.32\n",
      " Regression with ARIMA(0,0,0) errors : -10219.25\n",
      " Regression with ARIMA(1,0,0) errors : -13507.76\n",
      " Regression with ARIMA(0,0,1) errors : -11765.04\n",
      " Regression with ARIMA(0,0,0) errors : -8502.109\n",
      " Regression with ARIMA(1,0,2) errors : -13506.99\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13502.83\n",
      " Regression with ARIMA(2,0,3) errors : -13507.36\n",
      " Regression with ARIMA(1,0,1) errors : -13508.29\n",
      " Regression with ARIMA(1,0,3) errors : -13505.45\n",
      " Regression with ARIMA(3,0,1) errors : -13506.88\n",
      " Regression with ARIMA(3,0,3) errors : -13513.93\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13514.85\n",
      " Regression with ARIMA(2,0,4) errors : -13509.02\n",
      " Regression with ARIMA(4,0,4) errors : -13512.96\n",
      " Regression with ARIMA(3,0,5) errors : -13508.01\n",
      " Regression with ARIMA(2,0,5) errors : -13510.83\n",
      " Regression with ARIMA(4,0,5) errors : -13505.08\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13517.28\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10222.58\n",
      " Regression with ARIMA(1,0,0) errors : -13506.49\n",
      " Regression with ARIMA(0,0,1) errors : -11761.77\n",
      " Regression with ARIMA(0,0,0) errors : -8501.931\n",
      " Regression with ARIMA(2,0,0) errors : -13505.83\n",
      " Regression with ARIMA(1,0,1) errors : -13506.71\n",
      " Regression with ARIMA(2,0,1) errors : -13516.88\n",
      " Regression with ARIMA(3,0,1) errors : -13512.26\n",
      " Regression with ARIMA(1,0,2) errors : -13505.56\n",
      " Regression with ARIMA(3,0,0) errors : -13505.02\n",
      " Regression with ARIMA(3,0,2) errors : -13499.27\n",
      " Regression with ARIMA(2,0,1) errors : -13367.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13503.41\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13512.51\n",
      " Regression with ARIMA(0,0,0) errors : -10227.27\n",
      " Regression with ARIMA(1,0,0) errors : -13513.98\n",
      " Regression with ARIMA(0,0,1) errors : -11762.97\n",
      " Regression with ARIMA(0,0,0) errors : -8502.27\n",
      " Regression with ARIMA(2,0,0) errors : -13514.25\n",
      " Regression with ARIMA(3,0,0) errors : -13513.04\n",
      " Regression with ARIMA(2,0,1) errors : -13512.24\n",
      " Regression with ARIMA(1,0,1) errors : -13514.02\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -13380.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,0) errors : -13511.98\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13526.34\n",
      " Regression with ARIMA(0,0,0) errors : -10223.66\n",
      " Regression with ARIMA(1,0,0) errors : -13526.45\n",
      " Regression with ARIMA(0,0,1) errors : -11757.01\n",
      " Regression with ARIMA(0,0,0) errors : -8519.276\n",
      " Regression with ARIMA(2,0,0) errors : -13525.32\n",
      " Regression with ARIMA(1,0,1) errors : -13526.23\n",
      " Regression with ARIMA(2,0,1) errors : -13535.26\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13525.01\n",
      " Regression with ARIMA(3,0,0) errors : -13523.41\n",
      " Regression with ARIMA(3,0,2) errors : -13520.69\n",
      " Regression with ARIMA(2,0,1) errors : -13408.03\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13521.31\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10227.11\n",
      " Regression with ARIMA(1,0,0) errors : -13535.83\n",
      " Regression with ARIMA(0,0,1) errors : -11776.31\n",
      " Regression with ARIMA(0,0,0) errors : -8558.409\n",
      " Regression with ARIMA(2,0,0) errors : -13535.04\n",
      " Regression with ARIMA(1,0,1) errors : -13535.63\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13535.07\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10239.17\n",
      " Regression with ARIMA(1,0,0) errors : -13532.83\n",
      " Regression with ARIMA(0,0,1) errors : -11782.72\n",
      " Regression with ARIMA(0,0,0) errors : -8566.374\n",
      " Regression with ARIMA(2,0,0) errors : -13533.02\n",
      " Regression with ARIMA(3,0,0) errors : -13531.58\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13532.77\n",
      " Regression with ARIMA(3,0,1) errors : -13532.73\n",
      " Regression with ARIMA(2,0,0) errors : -13415.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,0) errors : -13531.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13539.55\n",
      " Regression with ARIMA(0,0,0) errors : -10238.93\n",
      " Regression with ARIMA(1,0,0) errors : -13540.07\n",
      " Regression with ARIMA(0,0,1) errors : -11784.97\n",
      " Regression with ARIMA(0,0,0) errors : -8571.174\n",
      " Regression with ARIMA(2,0,0) errors : -13539.5\n",
      " Regression with ARIMA(1,0,1) errors : -13540.16\n",
      " Regression with ARIMA(2,0,1) errors : -13549.2\n",
      " Regression with ARIMA(3,0,1) errors : -13539.61\n",
      " Regression with ARIMA(1,0,2) errors : -13539.06\n",
      " Regression with ARIMA(3,0,0) errors : -13537.64\n",
      " Regression with ARIMA(3,0,2) errors : -13537.96\n",
      " Regression with ARIMA(2,0,1) errors : -13400.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13550.1\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13537.09\n",
      " Regression with ARIMA(0,0,0) errors : -10239.99\n",
      " Regression with ARIMA(1,0,0) errors : -13540.98\n",
      " Regression with ARIMA(0,0,1) errors : -11788.21\n",
      " Regression with ARIMA(0,0,0) errors : -8584.355\n",
      " Regression with ARIMA(2,0,0) errors : -13540.68\n",
      " Regression with ARIMA(1,0,1) errors : -13540.96\n",
      " Regression with ARIMA(2,0,1) errors : -13550.79\n",
      " Regression with ARIMA(3,0,1) errors : -13544.63\n",
      " Regression with ARIMA(1,0,2) errors : -13539.89\n",
      " Regression with ARIMA(3,0,0) errors : -13538.95\n",
      " Regression with ARIMA(3,0,2) errors : -13543.48\n",
      " Regression with ARIMA(2,0,1) errors : -13423.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : -13541.93\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13563.2\n",
      " Regression with ARIMA(0,0,0) errors : -10221.42\n",
      " Regression with ARIMA(1,0,0) errors : -13558.89\n",
      " Regression with ARIMA(0,0,1) errors : -11783.59\n",
      " Regression with ARIMA(0,0,0) errors : -8587.344\n",
      " Regression with ARIMA(1,0,2) errors : -13557.75\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13560.36\n",
      " Regression with ARIMA(2,0,3) errors : -13561.2\n",
      " Regression with ARIMA(1,0,1) errors : -13558.83\n",
      " Regression with ARIMA(1,0,3) errors : -13556.36\n",
      " Regression with ARIMA(3,0,1) errors : -13562.66\n",
      " Regression with ARIMA(3,0,3) errors : -13569.83\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13571.17\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -13563.95\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13566.38\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13567.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13570.4\n",
      " Regression with ARIMA(0,0,0) errors : -10190.39\n",
      " Regression with ARIMA(1,0,0) errors : -13568.75\n",
      " Regression with ARIMA(0,0,1) errors : -11771.15\n",
      " Regression with ARIMA(0,0,0) errors : -8593.643\n",
      " Regression with ARIMA(1,0,2) errors : -13567.8\n",
      " Regression with ARIMA(2,0,1) errors : -13578.25\n",
      " Regression with ARIMA(1,0,1) errors : -13568.87\n",
      " Regression with ARIMA(2,0,0) errors : -13567.98\n",
      " Regression with ARIMA(3,0,1) errors : -13566.18\n",
      " Regression with ARIMA(3,0,0) errors : -13566.18\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : -13449.02\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13568.25\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13634.9\n",
      " Regression with ARIMA(0,0,0) errors : -10190.23\n",
      " Regression with ARIMA(1,0,0) errors : -13630.94\n",
      " Regression with ARIMA(0,0,1) errors : -11790.6\n",
      " Regression with ARIMA(0,0,0) errors : -8611.59\n",
      " Regression with ARIMA(1,0,2) errors : -13631.17\n",
      " Regression with ARIMA(2,0,1) errors : -13641.72\n",
      " Regression with ARIMA(1,0,1) errors : -13631.97\n",
      " Regression with ARIMA(2,0,0) errors : -13632.33\n",
      " Regression with ARIMA(3,0,1) errors : -13630.61\n",
      " Regression with ARIMA(3,0,0) errors : -13630.85\n",
      " Regression with ARIMA(3,0,2) errors : -13642.1\n",
      " Regression with ARIMA(4,0,2) errors : -13636.63\n",
      " Regression with ARIMA(3,0,3) errors : -13640.47\n",
      " Regression with ARIMA(2,0,3) errors : -13632.93\n",
      " Regression with ARIMA(4,0,1) errors : -13631.33\n",
      " Regression with ARIMA(4,0,3) errors : -13636.07\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13640.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13645.23\n",
      " Regression with ARIMA(0,0,0) errors : -10202.47\n",
      " Regression with ARIMA(1,0,0) errors : -13645.74\n",
      " Regression with ARIMA(0,0,1) errors : -11804.3\n",
      " Regression with ARIMA(0,0,0) errors : -8622.517\n",
      " Regression with ARIMA(2,0,0) errors : -13646.54\n",
      " Regression with ARIMA(3,0,0) errors : -13646.95\n",
      " Regression with ARIMA(4,0,0) errors : -13644.57\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -13646.54\n",
      " Regression with ARIMA(3,0,0) errors : -13536.11\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,0) errors : -13645.14\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13662.78\n",
      " Regression with ARIMA(0,0,0) errors : -10203.12\n",
      " Regression with ARIMA(1,0,0) errors : -13661.7\n",
      " Regression with ARIMA(0,0,1) errors : -11801.53\n",
      " Regression with ARIMA(0,0,0) errors : -8623.09\n",
      " Regression with ARIMA(1,0,2) errors : -13661.65\n",
      " Regression with ARIMA(2,0,1) errors : -13670.27\n",
      " Regression with ARIMA(1,0,1) errors : -13662.54\n",
      " Regression with ARIMA(2,0,0) errors : -13662.03\n",
      " Regression with ARIMA(3,0,1) errors : -13660.85\n",
      " Regression with ARIMA(3,0,0) errors : -13660.75\n",
      " Regression with ARIMA(3,0,2) errors : -13668.59\n",
      " Regression with ARIMA(2,0,1) errors : -13554.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13669.89\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13665.71\n",
      " Regression with ARIMA(0,0,0) errors : -10188.87\n",
      " Regression with ARIMA(1,0,0) errors : -13663.7\n",
      " Regression with ARIMA(0,0,1) errors : -11795.42\n",
      " Regression with ARIMA(0,0,0) errors : -8643.892\n",
      " Regression with ARIMA(1,0,2) errors : -13663.8\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13660.35\n",
      " Regression with ARIMA(2,0,3) errors : -13663.69\n",
      " Regression with ARIMA(1,0,1) errors : -13664.64\n",
      " Regression with ARIMA(1,0,3) errors : -13662.17\n",
      " Regression with ARIMA(3,0,1) errors : -13664.67\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13565.22\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13665.83\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13656.64\n",
      " Regression with ARIMA(0,0,0) errors : -10191.97\n",
      " Regression with ARIMA(1,0,0) errors : -13653.06\n",
      " Regression with ARIMA(0,0,1) errors : -11788.05\n",
      " Regression with ARIMA(0,0,0) errors : -8651.602\n",
      " Regression with ARIMA(1,0,2) errors : -13653.54\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13653.21\n",
      " Regression with ARIMA(2,0,3) errors : -13654.62\n",
      " Regression with ARIMA(1,0,1) errors : -13654.33\n",
      " Regression with ARIMA(1,0,3) errors : -13651.95\n",
      " Regression with ARIMA(3,0,1) errors : -13655.42\n",
      " Regression with ARIMA(3,0,3) errors : -13661.07\n",
      " Regression with ARIMA(4,0,3) errors : -13648.86\n",
      " Regression with ARIMA(3,0,4) errors : -13662.96\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13661.06\n",
      " Regression with ARIMA(4,0,5) errors : -13659.57\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13659.73\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13649.41\n",
      " Regression with ARIMA(0,0,0) errors : -10167.99\n",
      " Regression with ARIMA(1,0,0) errors : -13648.99\n",
      " Regression with ARIMA(0,0,1) errors : -11774.26\n",
      " Regression with ARIMA(0,0,0) errors : -8653.868\n",
      " Regression with ARIMA(1,0,2) errors : -13649.56\n",
      " Regression with ARIMA(0,0,2) errors : -12612.9\n",
      " Regression with ARIMA(1,0,1) errors : -13650.24\n",
      " Regression with ARIMA(2,0,1) errors : -13660.4\n",
      " Regression with ARIMA(2,0,0) errors : -13649.71\n",
      " Regression with ARIMA(3,0,1) errors : -13651.41\n",
      " Regression with ARIMA(3,0,0) errors : -13648.4\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13661.18\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13655.63\n",
      " Regression with ARIMA(0,0,0) errors : -10165.57\n",
      " Regression with ARIMA(1,0,0) errors : -13654.18\n",
      " Regression with ARIMA(0,0,1) errors : -11773.14\n",
      " Regression with ARIMA(0,0,0) errors : -8656.522\n",
      " Regression with ARIMA(1,0,2) errors : -13654.42\n",
      " Regression with ARIMA(2,0,1) errors : -13665.49\n",
      " Regression with ARIMA(1,0,1) errors : -13655.18\n",
      " Regression with ARIMA(2,0,0) errors : -13654.5\n",
      " Regression with ARIMA(3,0,1) errors : -13655.23\n",
      " Regression with ARIMA(3,0,0) errors : -13653.04\n",
      " Regression with ARIMA(3,0,2) errors : -13653.31\n",
      " Regression with ARIMA(2,0,1) errors : -13554.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13666.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13657.3\n",
      " Regression with ARIMA(0,0,0) errors : -10165.83\n",
      " Regression with ARIMA(1,0,0) errors : -13655.15\n",
      " Regression with ARIMA(0,0,1) errors : -11771.76\n",
      " Regression with ARIMA(0,0,0) errors : -8655.923\n",
      " Regression with ARIMA(1,0,2) errors : -13655.23\n",
      " Regression with ARIMA(2,0,1) errors : -13667.08\n",
      " Regression with ARIMA(1,0,1) errors : -13656.02\n",
      " Regression with ARIMA(2,0,0) errors : -13655.19\n",
      " Regression with ARIMA(3,0,1) errors : -13655.86\n",
      " Regression with ARIMA(3,0,0) errors : -13658.04\n",
      " Regression with ARIMA(3,0,2) errors : -13655.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13666.52\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13655.6\n",
      " Regression with ARIMA(0,0,0) errors : -10159.47\n",
      " Regression with ARIMA(1,0,0) errors : -13654.74\n",
      " Regression with ARIMA(0,0,1) errors : -11765.48\n",
      " Regression with ARIMA(0,0,0) errors : -8662.39\n",
      " Regression with ARIMA(1,0,2) errors : -13655.14\n",
      " Regression with ARIMA(2,0,1) errors : -13671.56\n",
      " Regression with ARIMA(1,0,1) errors : -13655.72\n",
      " Regression with ARIMA(2,0,0) errors : -13656.86\n",
      " Regression with ARIMA(3,0,1) errors : -13656.12\n",
      " Regression with ARIMA(3,0,0) errors : -13655.95\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13665.81\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13656.79\n",
      " Regression with ARIMA(0,0,0) errors : -10173.96\n",
      " Regression with ARIMA(1,0,0) errors : -13652.05\n",
      " Regression with ARIMA(0,0,1) errors : -11777.5\n",
      " Regression with ARIMA(0,0,0) errors : -8700.468\n",
      " Regression with ARIMA(1,0,2) errors : -13652.23\n",
      " Regression with ARIMA(2,0,1) errors : -13668.02\n",
      " Regression with ARIMA(1,0,1) errors : -13652.1\n",
      " Regression with ARIMA(2,0,0) errors : -13652.19\n",
      " Regression with ARIMA(3,0,1) errors : -13656.11\n",
      " Regression with ARIMA(3,0,0) errors : -13652.01\n",
      " Regression with ARIMA(3,0,2) errors : -13662.39\n",
      " Regression with ARIMA(2,0,1) errors : -13548.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13662.69\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13625.68\n",
      " Regression with ARIMA(0,1,0) errors : -13621.46\n",
      " Regression with ARIMA(1,1,0) errors : -13624.34\n",
      " Regression with ARIMA(0,1,1) errors : -13619.6\n",
      " Regression with ARIMA(0,1,0) errors : -13623.47\n",
      " Regression with ARIMA(1,1,2) errors : -13629.17\n",
      " Regression with ARIMA(0,1,2) errors : -13617.77\n",
      " Regression with ARIMA(1,1,1) errors : -13628.01\n",
      " Regression with ARIMA(1,1,3) errors : -13633.78\n",
      " Regression with ARIMA(0,1,3) errors : -13616.46\n",
      " Regression with ARIMA(2,1,3) errors : -13627.37\n",
      " Regression with ARIMA(1,1,4) errors : -13638.05\n",
      " Regression with ARIMA(0,1,4) errors : -13614.88\n",
      " Regression with ARIMA(2,1,4) errors : -13627.68\n",
      " Regression with ARIMA(1,1,5) errors : -13657.04\n",
      " Regression with ARIMA(0,1,5) errors : -13617.4\n",
      " Regression with ARIMA(2,1,5) errors : -13647.25\n",
      " Regression with ARIMA(1,1,5) errors : -13658.92\n",
      " Regression with ARIMA(0,1,5) errors : -13619.42\n",
      " Regression with ARIMA(1,1,4) errors : -13639.93\n",
      " Regression with ARIMA(2,1,5) errors : -13649.14\n",
      " Regression with ARIMA(0,1,4) errors : -13616.89\n",
      " Regression with ARIMA(2,1,4) errors : -13629.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,0) errors : -13628.45\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13669.46\n",
      " Regression with ARIMA(0,1,0) errors : -13667.96\n",
      " Regression with ARIMA(1,1,0) errors : -13665.88\n",
      " Regression with ARIMA(0,1,1) errors : -13666.47\n",
      " Regression with ARIMA(0,1,0) errors : -13669.95\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13678.82\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10272.74\n",
      " Regression with ARIMA(1,0,0) errors : -13772.01\n",
      " Regression with ARIMA(0,0,1) errors : -11891.74\n",
      " Regression with ARIMA(0,0,0) errors : -8843.671\n",
      " Regression with ARIMA(2,0,0) errors : -13770.9\n",
      " Regression with ARIMA(1,0,1) errors : -13771.44\n",
      " Regression with ARIMA(2,0,1) errors : -13785.75\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13772.19\n",
      " Regression with ARIMA(3,0,0) errors : -13772.31\n",
      " Regression with ARIMA(3,0,2) errors : -13785.11\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13783.28\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13764.52\n",
      " Regression with ARIMA(0,0,0) errors : -10268.04\n",
      " Regression with ARIMA(1,0,0) errors : -13761.23\n",
      " Regression with ARIMA(0,0,1) errors : -11885.1\n",
      " Regression with ARIMA(0,0,0) errors : -8858.715\n",
      " Regression with ARIMA(1,0,2) errors : -13761.55\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13782.76\n",
      " Regression with ARIMA(3,0,1) errors : -13780.45\n",
      " Regression with ARIMA(4,0,2) errors : -13778.02\n",
      " Regression with ARIMA(3,0,3) errors : -13780.93\n",
      " Regression with ARIMA(2,0,3) errors : -13762.9\n",
      " Regression with ARIMA(4,0,1) errors : -13774.34\n",
      " Regression with ARIMA(4,0,3) errors : -13775.95\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13775.78\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "[1] \"40 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13769.81\n",
      " Regression with ARIMA(0,0,0) errors : -10265.3\n",
      " Regression with ARIMA(1,0,0) errors : -13762.85\n",
      " Regression with ARIMA(0,0,1) errors : -11881.84\n",
      " Regression with ARIMA(0,0,0) errors : -8821.143\n",
      " Regression with ARIMA(1,0,2) errors : -13762.57\n",
      " Regression with ARIMA(2,0,1) errors : -13768.3\n",
      " Regression with ARIMA(3,0,2) errors : -13783.22\n",
      " Regression with ARIMA(3,0,1) errors : -13768.49\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13781.28\n",
      " Regression with ARIMA(2,0,3) errors : -13768.18\n",
      " Regression with ARIMA(4,0,1) errors : -13769.2\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13777.69\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13769.38\n",
      " Regression with ARIMA(0,0,0) errors : -10260.46\n",
      " Regression with ARIMA(1,0,0) errors : -13763.75\n",
      " Regression with ARIMA(0,0,1) errors : -11877.06\n",
      " Regression with ARIMA(0,0,0) errors : -8820.979\n",
      " Regression with ARIMA(1,0,2) errors : -13763.9\n",
      " Regression with ARIMA(2,0,1) errors : -13767.21\n",
      " Regression with ARIMA(3,0,2) errors : -13781.12\n",
      " Regression with ARIMA(3,0,1) errors : -13768.51\n",
      " Regression with ARIMA(4,0,2) errors : -13781.64\n",
      " Regression with ARIMA(4,0,1) errors : -13767.06\n",
      " Regression with ARIMA(5,0,2) errors : -13779.5\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13781.37\n",
      " Regression with ARIMA(5,0,1) errors : -13775.92\n",
      " Regression with ARIMA(5,0,3) errors : -13777.89\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,2) errors : -13774.84\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13730.6\n",
      " Regression with ARIMA(0,0,0) errors : -10252.14\n",
      " Regression with ARIMA(1,0,0) errors : -13734.15\n",
      " Regression with ARIMA(0,0,1) errors : -11865.14\n",
      " Regression with ARIMA(0,0,0) errors : -8811.741\n",
      " Regression with ARIMA(2,0,0) errors : -13732.86\n",
      " Regression with ARIMA(1,0,1) errors : -13733.55\n",
      " Regression with ARIMA(2,0,1) errors : -13745.03\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13733.84\n",
      " Regression with ARIMA(3,0,0) errors : -13732.77\n",
      " Regression with ARIMA(3,0,2) errors : -13730.31\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13733.34\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10248.64\n",
      " Regression with ARIMA(1,0,0) errors : -13726.11\n",
      " Regression with ARIMA(0,0,1) errors : -11859.38\n",
      " Regression with ARIMA(0,0,0) errors : -8814.75\n",
      " Regression with ARIMA(2,0,0) errors : -13726.2\n",
      " Regression with ARIMA(3,0,0) errors : -13726.52\n",
      " Regression with ARIMA(4,0,0) errors : -13725.54\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : -13736.42\n",
      " Regression with ARIMA(1,0,1) errors : -13725.25\n",
      " Regression with ARIMA(1,0,2) errors : -13725.96\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,0) errors : -13725.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10253.6\n",
      " Regression with ARIMA(1,0,0) errors : -13735.62\n",
      " Regression with ARIMA(0,0,1) errors : -11865.12\n",
      " Regression with ARIMA(0,0,0) errors : -8816.856\n",
      " Regression with ARIMA(2,0,0) errors : -13733.87\n",
      " Regression with ARIMA(1,0,1) errors : -13734.66\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13733.14\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13750.01\n",
      " Regression with ARIMA(0,0,0) errors : -10257.06\n",
      " Regression with ARIMA(1,0,0) errors : -13738.28\n",
      " Regression with ARIMA(0,0,1) errors : -11865.9\n",
      " Regression with ARIMA(0,0,0) errors : -8780.029\n",
      " Regression with ARIMA(1,0,2) errors : -13737.34\n",
      " Regression with ARIMA(2,0,1) errors : -13751.1\n",
      " Regression with ARIMA(1,0,1) errors : -13737.18\n",
      " Regression with ARIMA(2,0,0) errors : -13736.6\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,0) errors : -13736.27\n",
      " Regression with ARIMA(3,0,2) errors : -13732.63\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13735.84\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10256.83\n",
      " Regression with ARIMA(1,0,0) errors : -13730.95\n",
      " Regression with ARIMA(0,0,1) errors : -11861.77\n",
      " Regression with ARIMA(0,0,0) errors : -8779.258\n",
      " Regression with ARIMA(2,0,0) errors : -13729.15\n",
      " Regression with ARIMA(1,0,1) errors : -13729.46\n",
      " Regression with ARIMA(2,0,1) errors : -13743.66\n",
      " Regression with ARIMA(3,0,1) errors : -13740.11\n",
      " Regression with ARIMA(1,0,2) errors : -13729.66\n",
      " Regression with ARIMA(3,0,0) errors : -13731.65\n",
      " Regression with ARIMA(3,0,2) errors : -13742.18\n",
      " Regression with ARIMA(2,0,1) errors : -13618.71\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13744.27\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13704.92\n",
      " Regression with ARIMA(0,0,0) errors : -10273.67\n",
      " Regression with ARIMA(1,0,0) errors : -13706.69\n",
      " Regression with ARIMA(0,0,1) errors : -11878.39\n",
      " Regression with ARIMA(0,0,0) errors : -8797.955\n",
      " Regression with ARIMA(2,0,0) errors : -13704.19\n",
      " Regression with ARIMA(1,0,1) errors : -13704.98\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13577.35\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13704.77\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13513.55\n",
      " Regression with ARIMA(0,0,0) errors : -10068.34\n",
      " Regression with ARIMA(1,0,0) errors : -13520.38\n",
      " Regression with ARIMA(0,0,1) errors : -11654.6\n",
      " Regression with ARIMA(0,0,0) errors : -8614.487\n",
      " Regression with ARIMA(2,0,0) errors : -13517.43\n",
      " Regression with ARIMA(1,0,1) errors : -13518.38\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13517.53\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12970.83\n",
      " Regression with ARIMA(0,1,0) errors : -12930.49\n",
      " Regression with ARIMA(1,1,0) errors : -12945.11\n",
      " Regression with ARIMA(0,1,1) errors : -12947.22\n",
      " Regression with ARIMA(0,1,0) errors : -12932.5\n",
      " Regression with ARIMA(1,1,2) errors : -12962.91\n",
      " Regression with ARIMA(2,1,1) errors : -12971.71\n",
      " Regression with ARIMA(1,1,1) errors : -12955.51\n",
      " Regression with ARIMA(2,1,0) errors : -12969.84\n",
      " Regression with ARIMA(3,1,1) errors : -12974.24\n",
      " Regression with ARIMA(3,1,0) errors : -12974.64\n",
      " Regression with ARIMA(4,1,0) errors : -12978.76\n",
      " Regression with ARIMA(5,1,0) errors : -12976.29\n",
      " Regression with ARIMA(4,1,1) errors : -12976.71\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,0) errors : -12980.76\n",
      " Regression with ARIMA(3,1,0) errors : -12976.65\n",
      " Regression with ARIMA(5,1,0) errors : -12978.28\n",
      " Regression with ARIMA(4,1,1) errors : -12978.77\n",
      " Regression with ARIMA(3,1,1) errors : -12976.24\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,1,0) errors : -12980.2\n",
      "\n",
      " Best model: Regression with ARIMA(4,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12722.08\n",
      " Regression with ARIMA(0,1,0) errors : -12682.87\n",
      " Regression with ARIMA(1,1,0) errors : -12702.85\n",
      " Regression with ARIMA(0,1,1) errors : -12708.6\n",
      " Regression with ARIMA(0,1,0) errors : -12684.84\n",
      " Regression with ARIMA(1,1,2) errors : -12720.75\n",
      " Regression with ARIMA(2,1,1) errors : -12722.99\n",
      " Regression with ARIMA(1,1,1) errors : -12711.35\n",
      " Regression with ARIMA(2,1,0) errors : -12720.41\n",
      " Regression with ARIMA(3,1,1) errors : -12722.13\n",
      " Regression with ARIMA(3,1,0) errors : -12724.07\n",
      " Regression with ARIMA(4,1,0) errors : -12721.18\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -12726.05\n",
      " Regression with ARIMA(2,1,0) errors : -12722.38\n",
      " Regression with ARIMA(4,1,0) errors : -12723.17\n",
      " Regression with ARIMA(3,1,1) errors : -12724.11\n",
      " Regression with ARIMA(2,1,1) errors : -12724.96\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,0) errors : -12736.42\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12560.78\n",
      " Regression with ARIMA(0,1,0) errors : -12505.96\n",
      " Regression with ARIMA(1,1,0) errors : -12527.34\n",
      " Regression with ARIMA(0,1,1) errors : -12533.58\n",
      " Regression with ARIMA(0,1,0) errors : -12507.97\n",
      " Regression with ARIMA(1,1,2) errors : -12551.89\n",
      " Regression with ARIMA(2,1,1) errors : -12557.49\n",
      " Regression with ARIMA(3,1,2) errors : -12557.93\n",
      " Regression with ARIMA(2,1,3) errors : -12558.92\n",
      " Regression with ARIMA(1,1,1) errors : -12537.48\n",
      " Regression with ARIMA(1,1,3) errors : -12554.56\n",
      " Regression with ARIMA(3,1,1) errors : -12557.55\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12562.8\n",
      " Regression with ARIMA(1,1,2) errors : -12553.91\n",
      " Regression with ARIMA(2,1,1) errors : -12559.5\n",
      " Regression with ARIMA(3,1,2) errors : -12559.9\n",
      " Regression with ARIMA(2,1,3) errors : -12560.93\n",
      " Regression with ARIMA(1,1,1) errors : -12539.48\n",
      " Regression with ARIMA(1,1,3) errors : -12556.58\n",
      " Regression with ARIMA(3,1,1) errors : -12559.56\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12572.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12525.75\n",
      " Regression with ARIMA(0,1,0) errors : -12472.26\n",
      " Regression with ARIMA(1,1,0) errors : -12494.36\n",
      " Regression with ARIMA(0,1,1) errors : -12499.92\n",
      " Regression with ARIMA(0,1,0) errors : -12474.27\n",
      " Regression with ARIMA(1,1,2) errors : -12516.93\n",
      " Regression with ARIMA(2,1,1) errors : -12522.47\n",
      " Regression with ARIMA(3,1,2) errors : -12522.7\n",
      " Regression with ARIMA(2,1,3) errors : -12523.75\n",
      " Regression with ARIMA(1,1,1) errors : -12502.95\n",
      " Regression with ARIMA(1,1,3) errors : -12520.19\n",
      " Regression with ARIMA(3,1,1) errors : -12522.74\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12527.77\n",
      " Regression with ARIMA(1,1,2) errors : -12518.94\n",
      " Regression with ARIMA(2,1,1) errors : -12524.48\n",
      " Regression with ARIMA(3,1,2) errors : -12524.7\n",
      " Regression with ARIMA(2,1,3) errors : -12525.77\n",
      " Regression with ARIMA(1,1,1) errors : -12504.95\n",
      " Regression with ARIMA(1,1,3) errors : -12522.21\n",
      " Regression with ARIMA(3,1,1) errors : -12524.75\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12537.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12470.37\n",
      " Regression with ARIMA(0,1,0) errors : -12414.35\n",
      " Regression with ARIMA(1,1,0) errors : -12436.58\n",
      " Regression with ARIMA(0,1,1) errors : -12443.12\n",
      " Regression with ARIMA(0,1,0) errors : -12416.35\n",
      " Regression with ARIMA(1,1,2) errors : -12461.95\n",
      " Regression with ARIMA(2,1,1) errors : -12468.01\n",
      " Regression with ARIMA(3,1,2) errors : -12467.45\n",
      " Regression with ARIMA(2,1,3) errors : -12468.34\n",
      " Regression with ARIMA(1,1,1) errors : -12445.63\n",
      " Regression with ARIMA(1,1,3) errors : -12464.82\n",
      " Regression with ARIMA(3,1,1) errors : -12468.7\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12472.37\n",
      " Regression with ARIMA(1,1,2) errors : -12463.95\n",
      " Regression with ARIMA(2,1,1) errors : -12470\n",
      " Regression with ARIMA(3,1,2) errors : -12469.45\n",
      " Regression with ARIMA(2,1,3) errors : -12470.36\n",
      " Regression with ARIMA(1,1,1) errors : -12447.62\n",
      " Regression with ARIMA(1,1,3) errors : -12466.82\n",
      " Regression with ARIMA(3,1,1) errors : -12470.69\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12481.51\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12415.46\n",
      " Regression with ARIMA(0,1,0) errors : -12357.7\n",
      " Regression with ARIMA(1,1,0) errors : -12377.73\n",
      " Regression with ARIMA(0,1,1) errors : -12382.8\n",
      " Regression with ARIMA(0,1,0) errors : -12359.71\n",
      " Regression with ARIMA(1,1,2) errors : -12397.26\n",
      " Regression with ARIMA(2,1,1) errors : -12405.48\n",
      " Regression with ARIMA(3,1,2) errors : -12413.51\n",
      " Regression with ARIMA(2,1,3) errors : -12414.64\n",
      " Regression with ARIMA(1,1,1) errors : -12383.72\n",
      " Regression with ARIMA(1,1,3) errors : -12404.76\n",
      " Regression with ARIMA(3,1,1) errors : -12410.9\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12417.47\n",
      " Regression with ARIMA(1,1,2) errors : -12399.27\n",
      " Regression with ARIMA(2,1,1) errors : -12407.49\n",
      " Regression with ARIMA(3,1,2) errors : -12415.52\n",
      " Regression with ARIMA(2,1,3) errors : -12416.65\n",
      " Regression with ARIMA(1,1,1) errors : -12385.73\n",
      " Regression with ARIMA(1,1,3) errors : -12406.78\n",
      " Regression with ARIMA(3,1,1) errors : -12412.92\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12422.35\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12392.88\n",
      " Regression with ARIMA(0,1,0) errors : -12334.96\n",
      " Regression with ARIMA(1,1,0) errors : -12358.48\n",
      " Regression with ARIMA(0,1,1) errors : -12364.77\n",
      " Regression with ARIMA(0,1,0) errors : -12336.95\n",
      " Regression with ARIMA(1,1,2) errors : -12380.24\n",
      " Regression with ARIMA(2,1,1) errors : -12390.33\n",
      " Regression with ARIMA(3,1,2) errors : -12392.56\n",
      " Regression with ARIMA(2,1,3) errors : -12390.88\n",
      " Regression with ARIMA(1,1,1) errors : -12366.94\n",
      " Regression with ARIMA(1,1,3) errors : -12386.73\n",
      " Regression with ARIMA(3,1,1) errors : -12394.33\n",
      " Regression with ARIMA(3,1,0) errors : -12396.28\n",
      " Regression with ARIMA(2,1,0) errors : -12381.04\n",
      " Regression with ARIMA(4,1,0) errors : -12409.24\n",
      " Regression with ARIMA(5,1,0) errors : -12418.87\n",
      " Regression with ARIMA(5,1,1) errors : -12429.22\n",
      " Regression with ARIMA(4,1,1) errors : -12408.98\n",
      " Regression with ARIMA(5,1,2) errors : -12419\n",
      " Regression with ARIMA(4,1,2) errors : -12415.77\n",
      " Regression with ARIMA(5,1,1) errors : -12431.1\n",
      " Regression with ARIMA(4,1,1) errors : -12410.99\n",
      " Regression with ARIMA(5,1,0) errors : -12420.89\n",
      " Regression with ARIMA(5,1,2) errors : -12421.01\n",
      " Regression with ARIMA(4,1,0) errors : -12411.25\n",
      " Regression with ARIMA(4,1,2) errors : -12417.78\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,0) errors : -12408.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12405.22\n",
      " Regression with ARIMA(0,1,0) errors : -12342.22\n",
      " Regression with ARIMA(1,1,0) errors : -12369.17\n",
      " Regression with ARIMA(0,1,1) errors : -12375.11\n",
      " Regression with ARIMA(0,1,0) errors : -12344.23\n",
      " Regression with ARIMA(1,1,2) errors : -12390.01\n",
      " Regression with ARIMA(2,1,1) errors : -12397.17\n",
      " Regression with ARIMA(3,1,2) errors : -12404.33\n",
      " Regression with ARIMA(2,1,3) errors : -12403.26\n",
      " Regression with ARIMA(1,1,1) errors : -12376.7\n",
      " Regression with ARIMA(1,1,3) errors : -12397.27\n",
      " Regression with ARIMA(3,1,1) errors : -12402.52\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12407.23\n",
      " Regression with ARIMA(1,1,2) errors : -12392.02\n",
      " Regression with ARIMA(2,1,1) errors : -12399.19\n",
      " Regression with ARIMA(3,1,2) errors : -12406.34\n",
      " Regression with ARIMA(2,1,3) errors : -12405.28\n",
      " Regression with ARIMA(1,1,1) errors : -12378.71\n",
      " Regression with ARIMA(1,1,3) errors : -12399.28\n",
      " Regression with ARIMA(3,1,1) errors : -12404.53\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12418.09\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12479.1\n",
      " Regression with ARIMA(0,0,0) errors : -8904.547\n",
      " Regression with ARIMA(1,0,0) errors : -12457.86\n",
      " Regression with ARIMA(0,0,1) errors : -10586.67\n",
      " Regression with ARIMA(0,0,0) errors : -7757.971\n",
      " Regression with ARIMA(1,0,2) errors : -12470.62\n",
      " Regression with ARIMA(2,0,1) errors : -12467.78\n",
      " Regression with ARIMA(3,0,2) errors : -12535.04\n",
      " Regression with ARIMA(3,0,1) errors : -12486.22\n",
      " Regression with ARIMA(4,0,2) errors : -12504.23\n",
      " Regression with ARIMA(3,0,3) errors : -12504.59\n",
      " Regression with ARIMA(2,0,3) errors : -12501.85\n",
      " Regression with ARIMA(4,0,1) errors : -12505.69\n",
      " Regression with ARIMA(4,0,3) errors : -12533.86\n",
      " Regression with ARIMA(3,0,2) errors : -12438.48\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12506.31\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12465.71\n",
      " Regression with ARIMA(0,0,0) errors : -8892.805\n",
      " Regression with ARIMA(1,0,0) errors : -12446.23\n",
      " Regression with ARIMA(0,0,1) errors : -10571.36\n",
      " Regression with ARIMA(0,0,0) errors : -7709.597\n",
      " Regression with ARIMA(1,0,2) errors : -12458.34\n",
      " Regression with ARIMA(2,0,1) errors : -12455.94\n",
      " Regression with ARIMA(3,0,2) errors : -12524.46\n",
      " Regression with ARIMA(3,0,1) errors : -12471.77\n",
      " Regression with ARIMA(4,0,2) errors : -12490.22\n",
      " Regression with ARIMA(3,0,3) errors : -12489.3\n",
      " Regression with ARIMA(2,0,3) errors : -12488.4\n",
      " Regression with ARIMA(4,0,1) errors : -12491.45\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12529.33\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12465.29\n",
      " Regression with ARIMA(0,0,0) errors : -8894.651\n",
      " Regression with ARIMA(1,0,0) errors : -12445.35\n",
      " Regression with ARIMA(0,0,1) errors : -10573.51\n",
      " Regression with ARIMA(0,0,0) errors : -7703.577\n",
      " Regression with ARIMA(1,0,2) errors : -12457.79\n",
      " Regression with ARIMA(2,0,1) errors : -12455.34\n",
      " Regression with ARIMA(3,0,2) errors : -12521.44\n",
      " Regression with ARIMA(3,0,1) errors : -12471.75\n",
      " Regression with ARIMA(4,0,2) errors : -12489.95\n",
      " Regression with ARIMA(3,0,3) errors : -12489.87\n",
      " Regression with ARIMA(2,0,3) errors : -12487.74\n",
      " Regression with ARIMA(4,0,1) errors : -12490.93\n",
      " Regression with ARIMA(4,0,3) errors : -12517.07\n",
      " Regression with ARIMA(3,0,2) errors : -12443.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12527.75\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12457.74\n",
      " Regression with ARIMA(0,0,0) errors : -8888.053\n",
      " Regression with ARIMA(1,0,0) errors : -12438.77\n",
      " Regression with ARIMA(0,0,1) errors : -10568.72\n",
      " Regression with ARIMA(0,0,0) errors : -7699.325\n",
      " Regression with ARIMA(1,0,2) errors : -12450.59\n",
      " Regression with ARIMA(2,0,1) errors : -12447.71\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12479.45\n",
      " Regression with ARIMA(1,0,3) errors : -12482.41\n",
      " Regression with ARIMA(0,0,3) errors : -11655.39\n",
      " Regression with ARIMA(1,0,4) errors : -12480.42\n",
      " Regression with ARIMA(0,0,2) errors : -11226.37\n",
      " Regression with ARIMA(0,0,4) errors : -11987.9\n",
      " Regression with ARIMA(2,0,4) errors : -12508.61\n",
      " Regression with ARIMA(3,0,4) errors : -12510.98\n",
      " Regression with ARIMA(3,0,3) errors : -12480.89\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12508.89\n",
      " Regression with ARIMA(2,0,5) errors : -12511.16\n",
      " Regression with ARIMA(1,0,5) errors : -12481.3\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12511.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12454.54\n",
      " Regression with ARIMA(0,0,0) errors : -8881.322\n",
      " Regression with ARIMA(1,0,0) errors : -12434.91\n",
      " Regression with ARIMA(0,0,1) errors : -10562.75\n",
      " Regression with ARIMA(0,0,0) errors : -7707.396\n",
      " Regression with ARIMA(1,0,2) errors : -12446.19\n",
      " Regression with ARIMA(2,0,1) errors : -12444.84\n",
      " Regression with ARIMA(3,0,2) errors : -12469.19\n",
      " Regression with ARIMA(3,0,1) errors : -12458.01\n",
      " Regression with ARIMA(4,0,2) errors : -12484.21\n",
      " Regression with ARIMA(4,0,1) errors : -12483.69\n",
      " Regression with ARIMA(5,0,2) errors : -12502.19\n",
      " Regression with ARIMA(5,0,1) errors : -12498.17\n",
      " Regression with ARIMA(5,0,3) errors : -12504.05\n",
      " Regression with ARIMA(4,0,3) errors : -12482.32\n",
      " Regression with ARIMA(5,0,4) errors : -12490.42\n",
      " Regression with ARIMA(4,0,4) errors : -12481.71\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : -12506.66\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12464.6\n",
      " Regression with ARIMA(0,0,0) errors : -8887.118\n",
      " Regression with ARIMA(1,0,0) errors : -12445.24\n",
      " Regression with ARIMA(0,0,1) errors : -10561.18\n",
      " Regression with ARIMA(0,0,0) errors : -7708.215\n",
      " Regression with ARIMA(1,0,2) errors : -12456.91\n",
      " Regression with ARIMA(2,0,1) errors : -12455.73\n",
      " Regression with ARIMA(3,0,2) errors : -12528.24\n",
      " Regression with ARIMA(3,0,1) errors : -12470.67\n",
      " Regression with ARIMA(4,0,2) errors : -12491.02\n",
      " Regression with ARIMA(3,0,3) errors : -12487.94\n",
      " Regression with ARIMA(2,0,3) errors : -12488.17\n",
      " Regression with ARIMA(4,0,1) errors : -12491.62\n",
      " Regression with ARIMA(4,0,3) errors : -12490.61\n",
      " Regression with ARIMA(3,0,2) errors : -12436.46\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12488.78\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12482.33\n",
      " Regression with ARIMA(0,0,0) errors : -8891.815\n",
      " Regression with ARIMA(1,0,0) errors : -12463.17\n",
      " Regression with ARIMA(0,0,1) errors : -10569.71\n",
      " Regression with ARIMA(0,0,0) errors : -7717.256\n",
      " Regression with ARIMA(1,0,2) errors : -12475.08\n",
      " Regression with ARIMA(2,0,1) errors : -12474.77\n",
      " Regression with ARIMA(3,0,2) errors : -12536.91\n",
      " Regression with ARIMA(3,0,1) errors : -12489.05\n",
      " Regression with ARIMA(4,0,2) errors : -12507.21\n",
      " Regression with ARIMA(3,0,3) errors : -12507.02\n",
      " Regression with ARIMA(2,0,3) errors : -12506.61\n",
      " Regression with ARIMA(4,0,1) errors : -12508.71\n",
      " Regression with ARIMA(4,0,3) errors : -12506.62\n",
      " Regression with ARIMA(3,0,2) errors : -12453.39\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12508.55\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "[1] \"50 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12503.57\n",
      " Regression with ARIMA(0,0,0) errors : -8896.241\n",
      " Regression with ARIMA(1,0,0) errors : -12485.86\n",
      " Regression with ARIMA(0,0,1) errors : -10569.77\n",
      " Regression with ARIMA(0,0,0) errors : -7714.817\n",
      " Regression with ARIMA(1,0,2) errors : -12497.82\n",
      " Regression with ARIMA(2,0,1) errors : -12496.35\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12527.94\n",
      " Regression with ARIMA(1,0,3) errors : -12530.81\n",
      " Regression with ARIMA(0,0,3) errors : -11677.03\n",
      " Regression with ARIMA(1,0,4) errors : -12528.79\n",
      " Regression with ARIMA(0,0,2) errors : -11229.55\n",
      " Regression with ARIMA(0,0,4) errors : -12012.79\n",
      " Regression with ARIMA(2,0,4) errors : -12555.48\n",
      " Regression with ARIMA(3,0,4) errors : -12559.17\n",
      " Regression with ARIMA(3,0,3) errors : -12529.19\n",
      " Regression with ARIMA(4,0,4) errors : -12555.94\n",
      " Regression with ARIMA(3,0,5) errors : -12539.67\n",
      " Regression with ARIMA(2,0,5) errors : -12558.37\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -12560.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12499.29\n",
      " Regression with ARIMA(0,0,0) errors : -8896.211\n",
      " Regression with ARIMA(1,0,0) errors : -12479.6\n",
      " Regression with ARIMA(0,0,1) errors : -10569.06\n",
      " Regression with ARIMA(0,0,0) errors : -7726.249\n",
      " Regression with ARIMA(1,0,2) errors : -12491.43\n",
      " Regression with ARIMA(2,0,1) errors : -12490.08\n",
      " Regression with ARIMA(3,0,2) errors : -12549.65\n",
      " Regression with ARIMA(3,0,1) errors : -12505.95\n",
      " Regression with ARIMA(4,0,2) errors : -12523.02\n",
      " Regression with ARIMA(3,0,3) errors : -12522.73\n",
      " Regression with ARIMA(2,0,3) errors : -12520.84\n",
      " Regression with ARIMA(4,0,1) errors : -12524.79\n",
      " Regression with ARIMA(4,0,3) errors : -12548.68\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12521.78\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12522.71\n",
      " Regression with ARIMA(0,0,0) errors : -8912.717\n",
      " Regression with ARIMA(1,0,0) errors : -12499.7\n",
      " Regression with ARIMA(0,0,1) errors : -10598.43\n",
      " Regression with ARIMA(0,0,0) errors : -7791.064\n",
      " Regression with ARIMA(1,0,2) errors : -12511.99\n",
      " Regression with ARIMA(2,0,1) errors : -12511.69\n",
      " Regression with ARIMA(3,0,2) errors : -12565.33\n",
      " Regression with ARIMA(3,0,1) errors : -12529.16\n",
      " Regression with ARIMA(4,0,2) errors : -12545.66\n",
      " Regression with ARIMA(3,0,3) errors : -12545.28\n",
      " Regression with ARIMA(2,0,3) errors : -12543.96\n",
      " Regression with ARIMA(4,0,1) errors : -12547.58\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12526.08\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.95\n",
      " Regression with ARIMA(0,0,0) errors : -8942.089\n",
      " Regression with ARIMA(1,0,0) errors : -12527.3\n",
      " Regression with ARIMA(0,0,1) errors : -10625.79\n",
      " Regression with ARIMA(0,0,0) errors : -7815.365\n",
      " Regression with ARIMA(1,0,2) errors : -12539.1\n",
      " Regression with ARIMA(2,0,1) errors : -12537.44\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12568.26\n",
      " Regression with ARIMA(1,0,3) errors : -12570.63\n",
      " Regression with ARIMA(0,0,3) errors : -11727.96\n",
      " Regression with ARIMA(1,0,4) errors : -12568.62\n",
      " Regression with ARIMA(0,0,2) errors : -11285.05\n",
      " Regression with ARIMA(0,0,4) errors : -12063.02\n",
      " Regression with ARIMA(2,0,4) errors : -12594.01\n",
      " Regression with ARIMA(3,0,4) errors : -12602.32\n",
      " Regression with ARIMA(3,0,3) errors : -12568.74\n",
      " Regression with ARIMA(4,0,4) errors : -12567.01\n",
      " Regression with ARIMA(3,0,5) errors : -12578.76\n",
      " Regression with ARIMA(2,0,5) errors : -12598.99\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12467.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -12600.43\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12532.16\n",
      " Regression with ARIMA(0,0,0) errors : -8934.83\n",
      " Regression with ARIMA(1,0,0) errors : -12512.55\n",
      " Regression with ARIMA(0,0,1) errors : -10617.82\n",
      " Regression with ARIMA(0,0,0) errors : -7779.834\n",
      " Regression with ARIMA(1,0,2) errors : -12525.18\n",
      " Regression with ARIMA(2,0,1) errors : -12523.58\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12554.76\n",
      " Regression with ARIMA(1,0,3) errors : -12557.17\n",
      " Regression with ARIMA(0,0,3) errors : -11723.56\n",
      " Regression with ARIMA(1,0,4) errors : -12555.2\n",
      " Regression with ARIMA(0,0,2) errors : -11272.84\n",
      " Regression with ARIMA(0,0,4) errors : -12053.22\n",
      " Regression with ARIMA(2,0,4) errors : -12583\n",
      " Regression with ARIMA(3,0,4) errors : -12586.36\n",
      " Regression with ARIMA(3,0,3) errors : -12555.78\n",
      " Regression with ARIMA(4,0,4) errors : -12586.4\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12572.16\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12559.34\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,5) errors : -12569.81\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : -12587.09\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12509.71\n",
      " Regression with ARIMA(0,0,0) errors : -8923.006\n",
      " Regression with ARIMA(1,0,0) errors : -12490.06\n",
      " Regression with ARIMA(0,0,1) errors : -10606.06\n",
      " Regression with ARIMA(0,0,0) errors : -7778.001\n",
      " Regression with ARIMA(1,0,2) errors : -12503.3\n",
      " Regression with ARIMA(2,0,1) errors : -12501.4\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12532.82\n",
      " Regression with ARIMA(1,0,3) errors : -12535.75\n",
      " Regression with ARIMA(0,0,3) errors : -11707.59\n",
      " Regression with ARIMA(1,0,4) errors : -12533.75\n",
      " Regression with ARIMA(0,0,2) errors : -11261.54\n",
      " Regression with ARIMA(0,0,4) errors : -12037.84\n",
      " Regression with ARIMA(2,0,4) errors : -12562.35\n",
      " Regression with ARIMA(3,0,4) errors : -12563.64\n",
      " Regression with ARIMA(3,0,3) errors : -12534.12\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12540.3\n",
      " Regression with ARIMA(2,0,5) errors : -12565.8\n",
      " Regression with ARIMA(1,0,5) errors : -12534.53\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12565.48\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12497.83\n",
      " Regression with ARIMA(0,0,0) errors : -8905.257\n",
      " Regression with ARIMA(1,0,0) errors : -12479.66\n",
      " Regression with ARIMA(0,0,1) errors : -10592.39\n",
      " Regression with ARIMA(0,0,0) errors : -7770.197\n",
      " Regression with ARIMA(1,0,2) errors : -12491.59\n",
      " Regression with ARIMA(2,0,1) errors : -12491.59\n",
      " Regression with ARIMA(3,0,2) errors : -12541.44\n",
      " Regression with ARIMA(3,0,1) errors : -12505.67\n",
      " Regression with ARIMA(4,0,2) errors : -12524.33\n",
      " Regression with ARIMA(3,0,3) errors : -12524.65\n",
      " Regression with ARIMA(2,0,3) errors : -12523.33\n",
      " Regression with ARIMA(4,0,1) errors : -12525.8\n",
      " Regression with ARIMA(4,0,3) errors : -12554.64\n",
      " Regression with ARIMA(5,0,3) errors : -12551.24\n",
      " Regression with ARIMA(4,0,4) errors : -12549.94\n",
      " Regression with ARIMA(3,0,4) errors : -12553.02\n",
      " Regression with ARIMA(5,0,2) errors : -12548.7\n",
      " Regression with ARIMA(5,0,4) errors : -12528.29\n",
      " Regression with ARIMA(4,0,3) errors : -12482.77\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12554.1\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12497.83\n",
      " Regression with ARIMA(0,0,0) errors : -8898.064\n",
      " Regression with ARIMA(1,0,0) errors : -12477.67\n",
      " Regression with ARIMA(0,0,1) errors : -10586.17\n",
      " Regression with ARIMA(0,0,0) errors : -7763.444\n",
      " Regression with ARIMA(1,0,2) errors : -12489.24\n",
      " Regression with ARIMA(2,0,1) errors : -12490.62\n",
      " Regression with ARIMA(3,0,2) errors : -12555.3\n",
      " Regression with ARIMA(3,0,1) errors : -12503.83\n",
      " Regression with ARIMA(4,0,2) errors : -12522.97\n",
      " Regression with ARIMA(3,0,3) errors : -12522.77\n",
      " Regression with ARIMA(2,0,3) errors : -12522.46\n",
      " Regression with ARIMA(4,0,1) errors : -12524.5\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12474.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12523.61\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12513.83\n",
      " Regression with ARIMA(0,0,0) errors : -8943.164\n",
      " Regression with ARIMA(1,0,0) errors : -12488.42\n",
      " Regression with ARIMA(0,0,1) errors : -10621.1\n",
      " Regression with ARIMA(0,0,0) errors : -7868.129\n",
      " Regression with ARIMA(1,0,2) errors : -12499.53\n",
      " Regression with ARIMA(2,0,1) errors : -12510\n",
      " Regression with ARIMA(3,0,2) errors : -12538.21\n",
      " Regression with ARIMA(3,0,1) errors : -12522.06\n",
      " Regression with ARIMA(4,0,2) errors : -12545.22\n",
      " Regression with ARIMA(4,0,1) errors : -12546.86\n",
      " Regression with ARIMA(4,0,0) errors : -12546.27\n",
      " Regression with ARIMA(5,0,1) errors : -12549.63\n",
      " Regression with ARIMA(5,0,0) errors : -12550.19\n",
      " Regression with ARIMA(5,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,0) errors : -12530.49\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12537.41\n",
      " Regression with ARIMA(0,0,0) errors : -8980.404\n",
      " Regression with ARIMA(1,0,0) errors : -12515.87\n",
      " Regression with ARIMA(0,0,1) errors : -10652.29\n",
      " Regression with ARIMA(0,0,0) errors : -7878.327\n",
      " Regression with ARIMA(1,0,2) errors : -12530.48\n",
      " Regression with ARIMA(2,0,1) errors : -12528.68\n",
      " Regression with ARIMA(3,0,2) errors : -12554.48\n",
      " Regression with ARIMA(3,0,1) errors : -12543.44\n",
      " Regression with ARIMA(4,0,2) errors : -12559.77\n",
      " Regression with ARIMA(4,0,1) errors : -12561.17\n",
      " Regression with ARIMA(4,0,0) errors : -12562.64\n",
      " Regression with ARIMA(3,0,0) errors : -12534.45\n",
      " Regression with ARIMA(5,0,0) errors : -12560.32\n",
      " Regression with ARIMA(5,0,1) errors : -12583.89\n",
      " Regression with ARIMA(5,0,2) errors : -12582.7\n",
      " Regression with ARIMA(5,0,1) errors : -12494.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12584.44\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.24\n",
      " Regression with ARIMA(0,0,0) errors : -8985.481\n",
      " Regression with ARIMA(1,0,0) errors : -12523.97\n",
      " Regression with ARIMA(0,0,1) errors : -10655.97\n",
      " Regression with ARIMA(0,0,0) errors : -7884.878\n",
      " Regression with ARIMA(1,0,2) errors : -12538.88\n",
      " Regression with ARIMA(2,0,1) errors : -12537.23\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12566.95\n",
      " Regression with ARIMA(1,0,3) errors : -12569.82\n",
      " Regression with ARIMA(0,0,3) errors : -11754.84\n",
      " Regression with ARIMA(1,0,4) errors : -12567.97\n",
      " Regression with ARIMA(0,0,2) errors : -11299.19\n",
      " Regression with ARIMA(0,0,4) errors : -12073.38\n",
      " Regression with ARIMA(2,0,4) errors : -12592.97\n",
      " Regression with ARIMA(3,0,4) errors : -12597.31\n",
      " Regression with ARIMA(3,0,3) errors : -12567.29\n",
      " Regression with ARIMA(4,0,4) errors : -12596.6\n",
      " Regression with ARIMA(3,0,5) errors : -12570.58\n",
      " Regression with ARIMA(2,0,5) errors : -12597.68\n",
      " Regression with ARIMA(1,0,5) errors : -12568.02\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12597.69\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12546.78\n",
      " Regression with ARIMA(0,0,0) errors : -8970.223\n",
      " Regression with ARIMA(1,0,0) errors : -12525.95\n",
      " Regression with ARIMA(0,0,1) errors : -10649.53\n",
      " Regression with ARIMA(0,0,0) errors : -7878.626\n",
      " Regression with ARIMA(1,0,2) errors : -12540.83\n",
      " Regression with ARIMA(2,0,1) errors : -12539.25\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12568.27\n",
      " Regression with ARIMA(1,0,3) errors : -12571.19\n",
      " Regression with ARIMA(0,0,3) errors : -11751.13\n",
      " Regression with ARIMA(1,0,4) errors : -12569.31\n",
      " Regression with ARIMA(0,0,2) errors : -11296.38\n",
      " Regression with ARIMA(0,0,4) errors : -12067\n",
      " Regression with ARIMA(2,0,4) errors : -12594.34\n",
      " Regression with ARIMA(3,0,4) errors : -12595.54\n",
      " Regression with ARIMA(3,0,3) errors : -12568.5\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12574.84\n",
      " Regression with ARIMA(2,0,5) errors : -12598.8\n",
      " Regression with ARIMA(1,0,5) errors : -12569.08\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12597.59\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.79\n",
      " Regression with ARIMA(0,0,0) errors : -8964.909\n",
      " Regression with ARIMA(1,0,0) errors : -12525.68\n",
      " Regression with ARIMA(0,0,1) errors : -10646.25\n",
      " Regression with ARIMA(0,0,0) errors : -7885.222\n",
      " Regression with ARIMA(1,0,2) errors : -12540.83\n",
      " Regression with ARIMA(2,0,1) errors : -12539.59\n",
      " Regression with ARIMA(3,0,2) errors : -12603.07\n",
      " Regression with ARIMA(3,0,1) errors : -12554.12\n",
      " Regression with ARIMA(4,0,2) errors : -12569.57\n",
      " Regression with ARIMA(3,0,3) errors : -12569.71\n",
      " Regression with ARIMA(2,0,3) errors : -12568.45\n",
      " Regression with ARIMA(4,0,1) errors : -12570.93\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12494.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12570.9\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12548.69\n",
      " Regression with ARIMA(0,0,0) errors : -8959.862\n",
      " Regression with ARIMA(1,0,0) errors : -12529.05\n",
      " Regression with ARIMA(0,0,1) errors : -10643.71\n",
      " Regression with ARIMA(0,0,0) errors : -7886.635\n",
      " Regression with ARIMA(1,0,2) errors : -12544.11\n",
      " Regression with ARIMA(2,0,1) errors : -12544.13\n",
      " Regression with ARIMA(3,0,2) errors : -12571.06\n",
      " Regression with ARIMA(3,0,1) errors : -12561.51\n",
      " Regression with ARIMA(4,0,2) errors : -12576.07\n",
      " Regression with ARIMA(4,0,1) errors : -12578.07\n",
      " Regression with ARIMA(4,0,0) errors : -12579.62\n",
      " Regression with ARIMA(3,0,0) errors : -12551.25\n",
      " Regression with ARIMA(5,0,0) errors : -12579.64\n",
      " Regression with ARIMA(5,0,1) errors : Inf\n",
      " Regression with ARIMA(5,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,0) errors : -12575.23\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12551.97\n",
      " Regression with ARIMA(0,0,0) errors : -8967.683\n",
      " Regression with ARIMA(1,0,0) errors : -12529.69\n",
      " Regression with ARIMA(0,0,1) errors : -10653.67\n",
      " Regression with ARIMA(0,0,0) errors : -7896.484\n",
      " Regression with ARIMA(1,0,2) errors : -12544.97\n",
      " Regression with ARIMA(2,0,1) errors : -12543.7\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12573.37\n",
      " Regression with ARIMA(1,0,3) errors : -12575.68\n",
      " Regression with ARIMA(0,0,3) errors : -11753.95\n",
      " Regression with ARIMA(1,0,4) errors : -12573.8\n",
      " Regression with ARIMA(0,0,2) errors : -11300.67\n",
      " Regression with ARIMA(0,0,4) errors : -12074.69\n",
      " Regression with ARIMA(2,0,4) errors : -12591.45\n",
      " Regression with ARIMA(3,0,4) errors : -12595.99\n",
      " Regression with ARIMA(3,0,3) errors : -12573.8\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12580.86\n",
      " Regression with ARIMA(2,0,5) errors : -12597\n",
      " Regression with ARIMA(1,0,5) errors : -12573.86\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12603.04\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12556.25\n",
      " Regression with ARIMA(0,0,0) errors : -8962.755\n",
      " Regression with ARIMA(1,0,0) errors : -12535.8\n",
      " Regression with ARIMA(0,0,1) errors : -10648.64\n",
      " Regression with ARIMA(0,0,0) errors : -7898.839\n",
      " Regression with ARIMA(1,0,2) errors : -12550.14\n",
      " Regression with ARIMA(2,0,1) errors : -12548.54\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12578.72\n",
      " Regression with ARIMA(1,0,3) errors : -12581.63\n",
      " Regression with ARIMA(0,0,3) errors : -11752.88\n",
      " Regression with ARIMA(1,0,4) errors : -12579.7\n",
      " Regression with ARIMA(0,0,2) errors : -11299.22\n",
      " Regression with ARIMA(0,0,4) errors : -12072.91\n",
      " Regression with ARIMA(2,0,4) errors : -12605.06\n",
      " Regression with ARIMA(3,0,4) errors : -12603.2\n",
      " Regression with ARIMA(2,0,5) errors : -12609.26\n",
      " Regression with ARIMA(1,0,5) errors : -12579.72\n",
      " Regression with ARIMA(3,0,5) errors : -12582.04\n",
      " Regression with ARIMA(2,0,5) errors : -12540.55\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12607.82\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12570.6\n",
      " Regression with ARIMA(0,0,0) errors : -8967.56\n",
      " Regression with ARIMA(1,0,0) errors : -12549.25\n",
      " Regression with ARIMA(0,0,1) errors : -10654.34\n",
      " Regression with ARIMA(0,0,0) errors : -7906.854\n",
      " Regression with ARIMA(1,0,2) errors : -12564.03\n",
      " Regression with ARIMA(2,0,1) errors : -12563.91\n",
      " Regression with ARIMA(3,0,2) errors : -12627.87\n",
      " Regression with ARIMA(3,0,1) errors : -12577.27\n",
      " Regression with ARIMA(4,0,2) errors : -12593.34\n",
      " Regression with ARIMA(3,0,3) errors : -12593.82\n",
      " Regression with ARIMA(2,0,3) errors : -12593.22\n",
      " Regression with ARIMA(4,0,1) errors : -12594.72\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12522.09\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12594.39\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12576.56\n",
      " Regression with ARIMA(0,0,0) errors : -8968.532\n",
      " Regression with ARIMA(1,0,0) errors : -12555.14\n",
      " Regression with ARIMA(0,0,1) errors : -10657.19\n",
      " Regression with ARIMA(0,0,0) errors : -7936.331\n",
      " Regression with ARIMA(1,0,2) errors : -12569.91\n",
      " Regression with ARIMA(2,0,1) errors : -12570.88\n",
      " Regression with ARIMA(3,0,2) errors : -12594.83\n",
      " Regression with ARIMA(3,0,1) errors : -12583.62\n",
      " Regression with ARIMA(4,0,2) errors : -12601.21\n",
      " Regression with ARIMA(4,0,1) errors : -12602.62\n",
      " Regression with ARIMA(4,0,0) errors : -12603.98\n",
      " Regression with ARIMA(3,0,0) errors : -12574.44\n",
      " Regression with ARIMA(5,0,0) errors : -12601.82\n",
      " Regression with ARIMA(5,0,1) errors : -12626.33\n",
      " Regression with ARIMA(5,0,2) errors : -12625.22\n",
      " Regression with ARIMA(5,0,1) errors : -12547.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12620.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12601.85\n",
      " Regression with ARIMA(0,0,0) errors : -9048.224\n",
      " Regression with ARIMA(1,0,0) errors : -12582.93\n",
      " Regression with ARIMA(0,0,1) errors : -10732.82\n",
      " Regression with ARIMA(0,0,0) errors : -8067.123\n",
      " Regression with ARIMA(1,0,2) errors : -12598.44\n",
      " Regression with ARIMA(2,0,1) errors : -12601.12\n",
      " Regression with ARIMA(3,0,2) errors : -12619.05\n",
      " Regression with ARIMA(3,0,1) errors : -12618.74\n",
      " Regression with ARIMA(4,0,2) errors : -12650.56\n",
      " Regression with ARIMA(4,0,1) errors : -12652.27\n",
      " Regression with ARIMA(4,0,0) errors : -12652.06\n",
      " Regression with ARIMA(5,0,1) errors : -12662.55\n",
      " Regression with ARIMA(5,0,0) errors : -12658.45\n",
      " Regression with ARIMA(5,0,2) errors : -12663.08\n",
      " Regression with ARIMA(5,0,3) errors : -12661.14\n",
      " Regression with ARIMA(4,0,3) errors : -12649.44\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -12652.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12607.62\n",
      " Regression with ARIMA(0,0,0) errors : -9029.222\n",
      " Regression with ARIMA(1,0,0) errors : -12581.78\n",
      " Regression with ARIMA(0,0,1) errors : -10679.8\n",
      " Regression with ARIMA(0,0,0) errors : -7988.616\n",
      " Regression with ARIMA(1,0,2) errors : -12606.76\n",
      " Regression with ARIMA(2,0,1) errors : -12606.03\n",
      " Regression with ARIMA(3,0,2) errors : -12633.3\n",
      " Regression with ARIMA(3,0,1) errors : -12616.63\n",
      " Regression with ARIMA(4,0,2) errors : -12637.18\n",
      " Regression with ARIMA(4,0,1) errors : -12639.14\n",
      " Regression with ARIMA(4,0,0) errors : -12638.63\n",
      " Regression with ARIMA(5,0,1) errors : -12657.77\n",
      " Regression with ARIMA(5,0,0) errors : -12639.34\n",
      " Regression with ARIMA(5,0,2) errors : -12656.11\n",
      " Regression with ARIMA(5,0,1) errors : -12576.93\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12665.38\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12515.14\n",
      " Regression with ARIMA(0,1,0) errors : -12443.47\n",
      " Regression with ARIMA(1,1,0) errors : -12487.68\n",
      " Regression with ARIMA(0,1,1) errors : -12495.53\n",
      " Regression with ARIMA(0,1,0) errors : -12445.47\n",
      " Regression with ARIMA(1,1,2) errors : -12499.79\n",
      " Regression with ARIMA(2,1,1) errors : -12505.72\n",
      " Regression with ARIMA(3,1,2) errors : -12545.83\n",
      " Regression with ARIMA(3,1,1) errors : -12512.71\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -12547.75\n",
      " Regression with ARIMA(2,1,2) errors : -12517.15\n",
      " Regression with ARIMA(3,1,1) errors : -12514.72\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -12507.73\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12527.28\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12606.67\n",
      " Regression with ARIMA(0,0,0) errors : -9078.123\n",
      " Regression with ARIMA(1,0,0) errors : -12575.25\n",
      " Regression with ARIMA(0,0,1) errors : -10725.64\n",
      " Regression with ARIMA(0,0,0) errors : -8063.193\n",
      " Regression with ARIMA(1,0,2) errors : -12597.15\n",
      " Regression with ARIMA(2,0,1) errors : -12601.19\n",
      " Regression with ARIMA(3,0,2) errors : -12625.54\n",
      " Regression with ARIMA(3,0,1) errors : -12611.94\n",
      " Regression with ARIMA(4,0,2) errors : -12627.49\n",
      " Regression with ARIMA(4,0,1) errors : -12627.75\n",
      " Regression with ARIMA(4,0,0) errors : -12627.47\n",
      " Regression with ARIMA(5,0,1) errors : -12646.75\n",
      " Regression with ARIMA(5,0,0) errors : -12630.02\n",
      " Regression with ARIMA(5,0,2) errors : -12645.2\n",
      " Regression with ARIMA(5,0,1) errors : -12548.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12650.4\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12592.63\n",
      " Regression with ARIMA(0,0,0) errors : -9082.048\n",
      " Regression with ARIMA(1,0,0) errors : -12566.66\n",
      " Regression with ARIMA(0,0,1) errors : -10726.09\n",
      " Regression with ARIMA(0,0,0) errors : -8059.077\n",
      " Regression with ARIMA(1,0,2) errors : -12588.96\n",
      " Regression with ARIMA(2,0,1) errors : -12589.11\n",
      " Regression with ARIMA(3,0,2) errors : -12638.23\n",
      " Regression with ARIMA(3,0,1) errors : -12600.16\n",
      " Regression with ARIMA(4,0,2) errors : -12617.62\n",
      " Regression with ARIMA(3,0,3) errors : -12618.48\n",
      " Regression with ARIMA(2,0,3) errors : -12614.14\n",
      " Regression with ARIMA(4,0,1) errors : -12616.7\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12548.15\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12652.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12584\n",
      " Regression with ARIMA(0,0,0) errors : -9072.623\n",
      " Regression with ARIMA(1,0,0) errors : -12558.92\n",
      " Regression with ARIMA(0,0,1) errors : -10724.45\n",
      " Regression with ARIMA(0,0,0) errors : -8059.797\n",
      " Regression with ARIMA(1,0,2) errors : -12579.62\n",
      " Regression with ARIMA(2,0,1) errors : -12579.45\n",
      " Regression with ARIMA(3,0,2) errors : -12637.15\n",
      " Regression with ARIMA(3,0,1) errors : -12590.09\n",
      " Regression with ARIMA(4,0,2) errors : -12609.14\n",
      " Regression with ARIMA(3,0,3) errors : -12608.81\n",
      " Regression with ARIMA(2,0,3) errors : -12605.33\n",
      " Regression with ARIMA(4,0,1) errors : -12609.45\n",
      " Regression with ARIMA(4,0,3) errors : -12638.04\n",
      " Regression with ARIMA(5,0,3) errors : -12624.89\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12633.6\n",
      " Regression with ARIMA(5,0,2) errors : -12623.44\n",
      " Regression with ARIMA(5,0,4) errors : -12618.15\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12645.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "[1] \"60 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12597.56\n",
      " Regression with ARIMA(0,0,0) errors : -9087.133\n",
      " Regression with ARIMA(1,0,0) errors : -12572.15\n",
      " Regression with ARIMA(0,0,1) errors : -10736.93\n",
      " Regression with ARIMA(0,0,0) errors : -8079.117\n",
      " Regression with ARIMA(1,0,2) errors : -12594.14\n",
      " Regression with ARIMA(2,0,1) errors : -12593.03\n",
      " Regression with ARIMA(3,0,2) errors : -12658.36\n",
      " Regression with ARIMA(3,0,1) errors : -12603.77\n",
      " Regression with ARIMA(4,0,2) errors : -12622.07\n",
      " Regression with ARIMA(3,0,3) errors : -12622.59\n",
      " Regression with ARIMA(2,0,3) errors : -12619.12\n",
      " Regression with ARIMA(4,0,1) errors : -12620.82\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12548.61\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12655.81\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12610.85\n",
      " Regression with ARIMA(0,0,0) errors : -9095.509\n",
      " Regression with ARIMA(1,0,0) errors : -12584.86\n",
      " Regression with ARIMA(0,0,1) errors : -10749.33\n",
      " Regression with ARIMA(0,0,0) errors : -8097.852\n",
      " Regression with ARIMA(1,0,2) errors : -12606.97\n",
      " Regression with ARIMA(2,0,1) errors : -12608.39\n",
      " Regression with ARIMA(3,0,2) errors : -12658.34\n",
      " Regression with ARIMA(3,0,1) errors : -12619.38\n",
      " Regression with ARIMA(4,0,2) errors : -12636.67\n",
      " Regression with ARIMA(3,0,3) errors : -12637.2\n",
      " Regression with ARIMA(2,0,3) errors : -12634.49\n",
      " Regression with ARIMA(4,0,1) errors : -12636.79\n",
      " Regression with ARIMA(4,0,3) errors : -12679.01\n",
      " Regression with ARIMA(5,0,3) errors : -12665.31\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12669.72\n",
      " Regression with ARIMA(5,0,2) errors : -12665.96\n",
      " Regression with ARIMA(5,0,4) errors : -12644.1\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12661.83\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.42\n",
      " Regression with ARIMA(0,0,0) errors : -9117.955\n",
      " Regression with ARIMA(1,0,0) errors : -12604.61\n",
      " Regression with ARIMA(0,0,1) errors : -10769.78\n",
      " Regression with ARIMA(0,0,0) errors : -8106.906\n",
      " Regression with ARIMA(1,0,2) errors : -12626.91\n",
      " Regression with ARIMA(2,0,1) errors : -12625.67\n",
      " Regression with ARIMA(3,0,2) errors : -12690.09\n",
      " Regression with ARIMA(3,0,1) errors : -12637.43\n",
      " Regression with ARIMA(4,0,2) errors : -12655.81\n",
      " Regression with ARIMA(3,0,3) errors : -12655.49\n",
      " Regression with ARIMA(2,0,3) errors : -12652.79\n",
      " Regression with ARIMA(4,0,1) errors : -12654.8\n",
      " Regression with ARIMA(4,0,3) errors : -12693.24\n",
      " Regression with ARIMA(5,0,3) errors : -12662.02\n",
      " Regression with ARIMA(4,0,4) errors : -12671.03\n",
      " Regression with ARIMA(3,0,4) errors : -12677.48\n",
      " Regression with ARIMA(5,0,2) errors : -12662.99\n",
      " Regression with ARIMA(5,0,4) errors : -12675.56\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12692.59\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12641.13\n",
      " Regression with ARIMA(0,0,0) errors : -9120.512\n",
      " Regression with ARIMA(1,0,0) errors : -12614.69\n",
      " Regression with ARIMA(0,0,1) errors : -10777.29\n",
      " Regression with ARIMA(0,0,0) errors : -8113.97\n",
      " Regression with ARIMA(1,0,2) errors : -12636.3\n",
      " Regression with ARIMA(2,0,1) errors : -12634.97\n",
      " Regression with ARIMA(3,0,2) errors : -12703.57\n",
      " Regression with ARIMA(3,0,1) errors : -12648.05\n",
      " Regression with ARIMA(4,0,2) errors : -12667.51\n",
      " Regression with ARIMA(3,0,3) errors : -12666.81\n",
      " Regression with ARIMA(2,0,3) errors : -12663.2\n",
      " Regression with ARIMA(4,0,1) errors : -12665.98\n",
      " Regression with ARIMA(4,0,3) errors : -12703.17\n",
      " Regression with ARIMA(3,0,2) errors : -12608.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.93\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12643.6\n",
      " Regression with ARIMA(0,0,0) errors : -9119.216\n",
      " Regression with ARIMA(1,0,0) errors : -12616.26\n",
      " Regression with ARIMA(0,0,1) errors : -10777.52\n",
      " Regression with ARIMA(0,0,0) errors : -8101.041\n",
      " Regression with ARIMA(1,0,2) errors : -12637.47\n",
      " Regression with ARIMA(2,0,1) errors : -12640.52\n",
      " Regression with ARIMA(3,0,2) errors : -12680.71\n",
      " Regression with ARIMA(3,0,1) errors : -12652.57\n",
      " Regression with ARIMA(4,0,2) errors : -12672.29\n",
      " Regression with ARIMA(3,0,3) errors : -12671.04\n",
      " Regression with ARIMA(2,0,3) errors : -12668.46\n",
      " Regression with ARIMA(4,0,1) errors : -12671.99\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12605.13\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12704.4\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12641.82\n",
      " Regression with ARIMA(0,0,0) errors : -9125.129\n",
      " Regression with ARIMA(1,0,0) errors : -12617.13\n",
      " Regression with ARIMA(0,0,1) errors : -10783.88\n",
      " Regression with ARIMA(0,0,0) errors : -8122.685\n",
      " Regression with ARIMA(1,0,2) errors : -12638.09\n",
      " Regression with ARIMA(2,0,1) errors : -12636.93\n",
      " Regression with ARIMA(3,0,2) errors : -12695.39\n",
      " Regression with ARIMA(3,0,1) errors : -12649.51\n",
      " Regression with ARIMA(4,0,2) errors : -12667.03\n",
      " Regression with ARIMA(3,0,3) errors : -12667.49\n",
      " Regression with ARIMA(2,0,3) errors : -12664.06\n",
      " Regression with ARIMA(4,0,1) errors : -12666.82\n",
      " Regression with ARIMA(4,0,3) errors : -12707.83\n",
      " Regression with ARIMA(5,0,3) errors : -12686.77\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12686.56\n",
      " Regression with ARIMA(5,0,2) errors : -12685.94\n",
      " Regression with ARIMA(5,0,4) errors : -12670.08\n",
      " Regression with ARIMA(4,0,3) errors : -12637.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12704.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12640.83\n",
      " Regression with ARIMA(0,0,0) errors : -9124.201\n",
      " Regression with ARIMA(1,0,0) errors : -12614.79\n",
      " Regression with ARIMA(0,0,1) errors : -10783.44\n",
      " Regression with ARIMA(0,0,0) errors : -8122.209\n",
      " Regression with ARIMA(1,0,2) errors : -12635.64\n",
      " Regression with ARIMA(2,0,1) errors : -12634.86\n",
      " Regression with ARIMA(3,0,2) errors : -12695.41\n",
      " Regression with ARIMA(3,0,1) errors : -12647.57\n",
      " Regression with ARIMA(4,0,2) errors : -12665.91\n",
      " Regression with ARIMA(3,0,3) errors : -12665.62\n",
      " Regression with ARIMA(2,0,3) errors : -12662.3\n",
      " Regression with ARIMA(4,0,1) errors : -12664.73\n",
      " Regression with ARIMA(4,0,3) errors : -12708.36\n",
      " Regression with ARIMA(5,0,3) errors : -12683.74\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12676.17\n",
      " Regression with ARIMA(4,0,3) errors : -12636.53\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12702.9\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.35\n",
      " Regression with ARIMA(0,0,0) errors : -9121.854\n",
      " Regression with ARIMA(1,0,0) errors : -12613.51\n",
      " Regression with ARIMA(0,0,1) errors : -10782.18\n",
      " Regression with ARIMA(0,0,0) errors : -8117.61\n",
      " Regression with ARIMA(1,0,2) errors : -12633.27\n",
      " Regression with ARIMA(2,0,1) errors : -12632.06\n",
      " Regression with ARIMA(3,0,2) errors : -12698.45\n",
      " Regression with ARIMA(3,0,1) errors : -12643.7\n",
      " Regression with ARIMA(4,0,2) errors : -12660.83\n",
      " Regression with ARIMA(3,0,3) errors : -12661.66\n",
      " Regression with ARIMA(2,0,3) errors : -12658.11\n",
      " Regression with ARIMA(4,0,1) errors : -12659.62\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12597.25\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12700.82\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.09\n",
      " Regression with ARIMA(0,0,0) errors : -9116.676\n",
      " Regression with ARIMA(1,0,0) errors : -12611.67\n",
      " Regression with ARIMA(0,0,1) errors : -10780.74\n",
      " Regression with ARIMA(0,0,0) errors : -8116.581\n",
      " Regression with ARIMA(1,0,2) errors : -12630.99\n",
      " Regression with ARIMA(2,0,1) errors : -12629.63\n",
      " Regression with ARIMA(3,0,2) errors : -12699.18\n",
      " Regression with ARIMA(3,0,1) errors : -12641.18\n",
      " Regression with ARIMA(4,0,2) errors : -12658.75\n",
      " Regression with ARIMA(3,0,3) errors : -12659.44\n",
      " Regression with ARIMA(2,0,3) errors : -12655.65\n",
      " Regression with ARIMA(4,0,1) errors : -12657.53\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12615.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12699.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12639.03\n",
      " Regression with ARIMA(0,0,0) errors : -9117.537\n",
      " Regression with ARIMA(1,0,0) errors : -12615.18\n",
      " Regression with ARIMA(0,0,1) errors : -10783.7\n",
      " Regression with ARIMA(0,0,0) errors : -8118.136\n",
      " Regression with ARIMA(1,0,2) errors : -12634.65\n",
      " Regression with ARIMA(2,0,1) errors : -12633.24\n",
      " Regression with ARIMA(3,0,2) errors : -12699.98\n",
      " Regression with ARIMA(3,0,1) errors : -12645.33\n",
      " Regression with ARIMA(4,0,2) errors : -12662.46\n",
      " Regression with ARIMA(3,0,3) errors : -12663.29\n",
      " Regression with ARIMA(2,0,3) errors : -12659.28\n",
      " Regression with ARIMA(4,0,1) errors : -12661.46\n",
      " Regression with ARIMA(4,0,3) errors : -12704.33\n",
      " Regression with ARIMA(5,0,3) errors : -12680.72\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12676.03\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12672.54\n",
      " Regression with ARIMA(4,0,3) errors : -12599.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12703.36\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.78\n",
      " Regression with ARIMA(0,0,0) errors : -9113.603\n",
      " Regression with ARIMA(1,0,0) errors : -12610.36\n",
      " Regression with ARIMA(0,0,1) errors : -10781.97\n",
      " Regression with ARIMA(0,0,0) errors : -8111.354\n",
      " Regression with ARIMA(1,0,2) errors : -12629.21\n",
      " Regression with ARIMA(2,0,1) errors : -12627.93\n",
      " Regression with ARIMA(3,0,2) errors : -12693.18\n",
      " Regression with ARIMA(3,0,1) errors : -12639.63\n",
      " Regression with ARIMA(4,0,2) errors : -12657.34\n",
      " Regression with ARIMA(3,0,3) errors : -12657.78\n",
      " Regression with ARIMA(2,0,3) errors : -12654.23\n",
      " Regression with ARIMA(4,0,1) errors : -12656.4\n",
      " Regression with ARIMA(4,0,3) errors : -12699.31\n",
      " Regression with ARIMA(5,0,3) errors : -12674.55\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12675.54\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12667.95\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.07\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.46\n",
      " Regression with ARIMA(0,0,0) errors : -9119.245\n",
      " Regression with ARIMA(1,0,0) errors : -12613.96\n",
      " Regression with ARIMA(0,0,1) errors : -10785.81\n",
      " Regression with ARIMA(0,0,0) errors : -8116.382\n",
      " Regression with ARIMA(1,0,2) errors : -12632.76\n",
      " Regression with ARIMA(2,0,1) errors : -12631.28\n",
      " Regression with ARIMA(3,0,2) errors : -12700.56\n",
      " Regression with ARIMA(3,0,1) errors : -12643.51\n",
      " Regression with ARIMA(4,0,2) errors : -12660.35\n",
      " Regression with ARIMA(3,0,3) errors : -12660.75\n",
      " Regression with ARIMA(2,0,3) errors : -12657.34\n",
      " Regression with ARIMA(4,0,1) errors : -12659.28\n",
      " Regression with ARIMA(4,0,3) errors : -12705.25\n",
      " Regression with ARIMA(5,0,3) errors : -12677.25\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12659.26\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12674.2\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12701.28\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.91\n",
      " Regression with ARIMA(0,0,0) errors : -9115.346\n",
      " Regression with ARIMA(1,0,0) errors : -12609.25\n",
      " Regression with ARIMA(0,0,1) errors : -10783.59\n",
      " Regression with ARIMA(0,0,0) errors : -8119.022\n",
      " Regression with ARIMA(1,0,2) errors : -12628.07\n",
      " Regression with ARIMA(2,0,1) errors : -12626.55\n",
      " Regression with ARIMA(3,0,2) errors : -12695.08\n",
      " Regression with ARIMA(3,0,1) errors : -12639.09\n",
      " Regression with ARIMA(4,0,2) errors : -12655.57\n",
      " Regression with ARIMA(3,0,3) errors : -12655.97\n",
      " Regression with ARIMA(2,0,3) errors : -12652.64\n",
      " Regression with ARIMA(4,0,1) errors : -12654.48\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12608.86\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12697.61\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12634.77\n",
      " Regression with ARIMA(0,0,0) errors : -9112.722\n",
      " Regression with ARIMA(1,0,0) errors : -12611.67\n",
      " Regression with ARIMA(0,0,1) errors : -10782.69\n",
      " Regression with ARIMA(0,0,0) errors : -8118.407\n",
      " Regression with ARIMA(1,0,2) errors : -12630.3\n",
      " Regression with ARIMA(2,0,1) errors : -12628.79\n",
      " Regression with ARIMA(3,0,2) errors : -12698.97\n",
      " Regression with ARIMA(3,0,1) errors : -12640.78\n",
      " Regression with ARIMA(4,0,2) errors : -12656.92\n",
      " Regression with ARIMA(3,0,3) errors : -12657.7\n",
      " Regression with ARIMA(2,0,3) errors : -12654.48\n",
      " Regression with ARIMA(4,0,1) errors : -12655.94\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12604.1\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12699.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.36\n",
      " Regression with ARIMA(0,0,0) errors : -9119.25\n",
      " Regression with ARIMA(1,0,0) errors : -12613.66\n",
      " Regression with ARIMA(0,0,1) errors : -10784.04\n",
      " Regression with ARIMA(0,0,0) errors : -8121.82\n",
      " Regression with ARIMA(1,0,2) errors : -12632.84\n",
      " Regression with ARIMA(2,0,1) errors : -12631.38\n",
      " Regression with ARIMA(3,0,2) errors : -12686.69\n",
      " Regression with ARIMA(3,0,1) errors : -12643.65\n",
      " Regression with ARIMA(4,0,2) errors : -12661.74\n",
      " Regression with ARIMA(3,0,3) errors : -12661.05\n",
      " Regression with ARIMA(2,0,3) errors : -12657.15\n",
      " Regression with ARIMA(4,0,1) errors : -12661.45\n",
      " Regression with ARIMA(4,0,3) errors : -12661.55\n",
      " Regression with ARIMA(3,0,2) errors : -12592.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.86\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.03\n",
      " Regression with ARIMA(0,0,0) errors : -9124.803\n",
      " Regression with ARIMA(1,0,0) errors : -12611.58\n",
      " Regression with ARIMA(0,0,1) errors : -10785.79\n",
      " Regression with ARIMA(0,0,0) errors : -8120.735\n",
      " Regression with ARIMA(1,0,2) errors : -12631.26\n",
      " Regression with ARIMA(2,0,1) errors : -12629.83\n",
      " Regression with ARIMA(3,0,2) errors : -12695.7\n",
      " Regression with ARIMA(3,0,1) errors : -12642.68\n",
      " Regression with ARIMA(4,0,2) errors : -12659.94\n",
      " Regression with ARIMA(3,0,3) errors : -12660.68\n",
      " Regression with ARIMA(2,0,3) errors : -12655.54\n",
      " Regression with ARIMA(4,0,1) errors : -12658.46\n",
      " Regression with ARIMA(4,0,3) errors : -12702.36\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12659.16\n",
      " Regression with ARIMA(5,0,2) errors : -12657.49\n",
      " Regression with ARIMA(5,0,4) errors : -12659.7\n",
      " Regression with ARIMA(4,0,3) errors : -12584.34\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.35\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12639.64\n",
      " Regression with ARIMA(0,0,0) errors : -9126.097\n",
      " Regression with ARIMA(1,0,0) errors : -12614.91\n",
      " Regression with ARIMA(0,0,1) errors : -10785.02\n",
      " Regression with ARIMA(0,0,0) errors : -8116.995\n",
      " Regression with ARIMA(1,0,2) errors : -12635.07\n",
      " Regression with ARIMA(2,0,1) errors : -12633.58\n",
      " Regression with ARIMA(3,0,2) errors : -12700.58\n",
      " Regression with ARIMA(3,0,1) errors : -12646.01\n",
      " Regression with ARIMA(4,0,2) errors : -12662.46\n",
      " Regression with ARIMA(3,0,3) errors : -12663.22\n",
      " Regression with ARIMA(2,0,3) errors : -12659.45\n",
      " Regression with ARIMA(4,0,1) errors : -12661.32\n",
      " Regression with ARIMA(4,0,3) errors : -12707.82\n",
      " Regression with ARIMA(5,0,3) errors : -12680.87\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.94\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12674.86\n",
      " Regression with ARIMA(4,0,3) errors : -12602.62\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12703.26\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.76\n",
      " Regression with ARIMA(0,0,0) errors : -9126.664\n",
      " Regression with ARIMA(1,0,0) errors : -12610.17\n",
      " Regression with ARIMA(0,0,1) errors : -10784.22\n",
      " Regression with ARIMA(0,0,0) errors : -8120.924\n",
      " Regression with ARIMA(1,0,2) errors : -12630.62\n",
      " Regression with ARIMA(2,0,1) errors : -12629.52\n",
      " Regression with ARIMA(3,0,2) errors : -12694.59\n",
      " Regression with ARIMA(3,0,1) errors : -12642.09\n",
      " Regression with ARIMA(4,0,2) errors : -12658.44\n",
      " Regression with ARIMA(3,0,3) errors : -12658.75\n",
      " Regression with ARIMA(2,0,3) errors : -12655.04\n",
      " Regression with ARIMA(4,0,1) errors : -12657.14\n",
      " Regression with ARIMA(4,0,3) errors : -12704.19\n",
      " Regression with ARIMA(5,0,3) errors : -12674.9\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.25\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12664.74\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.55\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.01\n",
      " Regression with ARIMA(0,0,0) errors : -9129.67\n",
      " Regression with ARIMA(1,0,0) errors : -12606.43\n",
      " Regression with ARIMA(0,0,1) errors : -10786.26\n",
      " Regression with ARIMA(0,0,0) errors : -8109.689\n",
      " Regression with ARIMA(1,0,2) errors : -12626.33\n",
      " Regression with ARIMA(2,0,1) errors : -12625.7\n",
      " Regression with ARIMA(3,0,2) errors : -12685.15\n",
      " Regression with ARIMA(3,0,1) errors : -12638.15\n",
      " Regression with ARIMA(4,0,2) errors : -12654.36\n",
      " Regression with ARIMA(3,0,3) errors : -12654.53\n",
      " Regression with ARIMA(2,0,3) errors : -12651.32\n",
      " Regression with ARIMA(4,0,1) errors : -12653.1\n",
      " Regression with ARIMA(4,0,3) errors : -12701.37\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12653.24\n",
      " Regression with ARIMA(3,0,4) errors : -12676.54\n",
      " Regression with ARIMA(5,0,2) errors : -12652.64\n",
      " Regression with ARIMA(5,0,4) errors : -12668.09\n",
      " Regression with ARIMA(4,0,3) errors : -12590.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.56\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.77\n",
      " Regression with ARIMA(0,0,0) errors : -9125.562\n",
      " Regression with ARIMA(1,0,0) errors : -12610.64\n",
      " Regression with ARIMA(0,0,1) errors : -10785.7\n",
      " Regression with ARIMA(0,0,0) errors : -8108.179\n",
      " Regression with ARIMA(1,0,2) errors : -12630.51\n",
      " Regression with ARIMA(2,0,1) errors : -12629.36\n",
      " Regression with ARIMA(3,0,2) errors : -12694.15\n",
      " Regression with ARIMA(3,0,1) errors : -12642.13\n",
      " Regression with ARIMA(4,0,2) errors : -12658.37\n",
      " Regression with ARIMA(3,0,3) errors : -12658.83\n",
      " Regression with ARIMA(2,0,3) errors : -12655.24\n",
      " Regression with ARIMA(4,0,1) errors : -12657.12\n",
      " Regression with ARIMA(4,0,3) errors : -12704.42\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12679.15\n",
      " Regression with ARIMA(3,0,4) errors : -12677.56\n",
      " Regression with ARIMA(5,0,2) errors : -12656.96\n",
      " Regression with ARIMA(5,0,4) errors : -12670.89\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12699.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.76\n",
      " Regression with ARIMA(0,0,0) errors : -9119.29\n",
      " Regression with ARIMA(1,0,0) errors : -12609.83\n",
      " Regression with ARIMA(0,0,1) errors : -10782.32\n",
      " Regression with ARIMA(0,0,0) errors : -8104.093\n",
      " Regression with ARIMA(1,0,2) errors : -12629.02\n",
      " Regression with ARIMA(2,0,1) errors : -12627.65\n",
      " Regression with ARIMA(3,0,2) errors : -12693.41\n",
      " Regression with ARIMA(3,0,1) errors : -12640.24\n",
      " Regression with ARIMA(4,0,2) errors : -12657.4\n",
      " Regression with ARIMA(3,0,3) errors : -12657.65\n",
      " Regression with ARIMA(2,0,3) errors : -12654\n",
      " Regression with ARIMA(4,0,1) errors : -12655.98\n",
      " Regression with ARIMA(4,0,3) errors : -12700.63\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12678.52\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12666.19\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.72\n",
      " Regression with ARIMA(0,0,0) errors : -9127.533\n",
      " Regression with ARIMA(1,0,0) errors : -12608.51\n",
      " Regression with ARIMA(0,0,1) errors : -10784.58\n",
      " Regression with ARIMA(0,0,0) errors : -8099.693\n",
      " Regression with ARIMA(1,0,2) errors : -12627.71\n",
      " Regression with ARIMA(2,0,1) errors : -12626.53\n",
      " Regression with ARIMA(3,0,2) errors : -12687.4\n",
      " Regression with ARIMA(3,0,1) errors : -12638.82\n",
      " Regression with ARIMA(4,0,2) errors : -12655.24\n",
      " Regression with ARIMA(3,0,3) errors : -12655.99\n",
      " Regression with ARIMA(2,0,3) errors : -12651.92\n",
      " Regression with ARIMA(4,0,1) errors : -12654.76\n",
      " Regression with ARIMA(4,0,3) errors : -12698.43\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12654.62\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -12611.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12696.67\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.19\n",
      " Regression with ARIMA(0,0,0) errors : -9131.072\n",
      " Regression with ARIMA(1,0,0) errors : -12612.33\n",
      " Regression with ARIMA(0,0,1) errors : -10786.34\n",
      " Regression with ARIMA(0,0,0) errors : -8111.89\n",
      " Regression with ARIMA(1,0,2) errors : -12632.14\n",
      " Regression with ARIMA(2,0,1) errors : -12630.94\n",
      " Regression with ARIMA(3,0,2) errors : -12697.09\n",
      " Regression with ARIMA(3,0,1) errors : -12642.55\n",
      " Regression with ARIMA(4,0,2) errors : -12659.42\n",
      " Regression with ARIMA(3,0,3) errors : -12660.03\n",
      " Regression with ARIMA(2,0,3) errors : -12656.53\n",
      " Regression with ARIMA(4,0,1) errors : -12658.14\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12614.5\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12700.42\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.26\n",
      " Regression with ARIMA(0,0,0) errors : -9126.592\n",
      " Regression with ARIMA(1,0,0) errors : -12609.67\n",
      " Regression with ARIMA(0,0,1) errors : -10781.77\n",
      " Regression with ARIMA(0,0,0) errors : -8113.176\n",
      " Regression with ARIMA(1,0,2) errors : -12629.18\n",
      " Regression with ARIMA(2,0,1) errors : -12627.73\n",
      " Regression with ARIMA(3,0,2) errors : -12692.71\n",
      " Regression with ARIMA(3,0,1) errors : -12639.26\n",
      " Regression with ARIMA(4,0,2) errors : -12656.27\n",
      " Regression with ARIMA(3,0,3) errors : -12657.03\n",
      " Regression with ARIMA(2,0,3) errors : -12652.75\n",
      " Regression with ARIMA(4,0,1) errors : -12654.72\n",
      " Regression with ARIMA(4,0,3) errors : -12699.6\n",
      " Regression with ARIMA(5,0,3) errors : -12672.77\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12668.99\n",
      " Regression with ARIMA(4,0,3) errors : -12626.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12697.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "[1] \"70 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.51\n",
      " Regression with ARIMA(0,0,0) errors : -9120.766\n",
      " Regression with ARIMA(1,0,0) errors : -12607\n",
      " Regression with ARIMA(0,0,1) errors : -10776.09\n",
      " Regression with ARIMA(0,0,0) errors : -8111.103\n",
      " Regression with ARIMA(1,0,2) errors : -12626.77\n",
      " Regression with ARIMA(2,0,1) errors : -12625.53\n",
      " Regression with ARIMA(3,0,2) errors : -12685.73\n",
      " Regression with ARIMA(3,0,1) errors : -12637.75\n",
      " Regression with ARIMA(4,0,2) errors : -12654.14\n",
      " Regression with ARIMA(3,0,3) errors : -12654.51\n",
      " Regression with ARIMA(2,0,3) errors : -12650.91\n",
      " Regression with ARIMA(4,0,1) errors : -12654.37\n",
      " Regression with ARIMA(4,0,3) errors : -12686.13\n",
      " Regression with ARIMA(5,0,3) errors : -12700.25\n",
      " Regression with ARIMA(5,0,2) errors : -12654.47\n",
      " Regression with ARIMA(5,0,4) errors : -12662.71\n",
      " Regression with ARIMA(4,0,4) errors : -12698.47\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : -12673.47\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12629.83\n",
      " Regression with ARIMA(0,0,0) errors : -9123.342\n",
      " Regression with ARIMA(1,0,0) errors : -12606.52\n",
      " Regression with ARIMA(0,0,1) errors : -10778\n",
      " Regression with ARIMA(0,0,0) errors : -8105.722\n",
      " Regression with ARIMA(1,0,2) errors : -12626.01\n",
      " Regression with ARIMA(2,0,1) errors : -12624.6\n",
      " Regression with ARIMA(3,0,2) errors : -12689.93\n",
      " Regression with ARIMA(3,0,1) errors : -12636.27\n",
      " Regression with ARIMA(4,0,2) errors : -12652.8\n",
      " Regression with ARIMA(3,0,3) errors : -12653.27\n",
      " Regression with ARIMA(2,0,3) errors : -12649.98\n",
      " Regression with ARIMA(4,0,1) errors : -12652.27\n",
      " Regression with ARIMA(4,0,3) errors : -12694.07\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12670.15\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12654.04\n",
      " Regression with ARIMA(4,0,3) errors : -12618.5\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.06\n",
      " Regression with ARIMA(0,0,0) errors : -9131.681\n",
      " Regression with ARIMA(1,0,0) errors : -12608.01\n",
      " Regression with ARIMA(0,0,1) errors : -10782.66\n",
      " Regression with ARIMA(0,0,0) errors : -8107.119\n",
      " Regression with ARIMA(1,0,2) errors : -12628.11\n",
      " Regression with ARIMA(2,0,1) errors : -12626.67\n",
      " Regression with ARIMA(3,0,2) errors : -12693.49\n",
      " Regression with ARIMA(3,0,1) errors : -12638.11\n",
      " Regression with ARIMA(4,0,2) errors : -12655.3\n",
      " Regression with ARIMA(3,0,3) errors : -12655.92\n",
      " Regression with ARIMA(2,0,3) errors : -12652.11\n",
      " Regression with ARIMA(4,0,1) errors : -12653.8\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12610.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12696.06\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.24\n",
      " Regression with ARIMA(0,0,0) errors : -9131.239\n",
      " Regression with ARIMA(1,0,0) errors : -12606.95\n",
      " Regression with ARIMA(0,0,1) errors : -10780.44\n",
      " Regression with ARIMA(0,0,0) errors : -8112.5\n",
      " Regression with ARIMA(1,0,2) errors : -12627\n",
      " Regression with ARIMA(2,0,1) errors : -12625.5\n",
      " Regression with ARIMA(3,0,2) errors : -12689.64\n",
      " Regression with ARIMA(3,0,1) errors : -12638.39\n",
      " Regression with ARIMA(4,0,2) errors : -12654.7\n",
      " Regression with ARIMA(3,0,3) errors : -12654.57\n",
      " Regression with ARIMA(2,0,3) errors : -12650.34\n",
      " Regression with ARIMA(4,0,1) errors : -12654\n",
      " Regression with ARIMA(4,0,3) errors : -12691.8\n",
      " Regression with ARIMA(5,0,3) errors : -12674.84\n",
      " Regression with ARIMA(4,0,4) errors : -12670.68\n",
      " Regression with ARIMA(3,0,4) errors : -12676.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12662.77\n",
      " Regression with ARIMA(4,0,3) errors : -12620.21\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.43\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.92\n",
      " Regression with ARIMA(0,0,0) errors : -9128.861\n",
      " Regression with ARIMA(1,0,0) errors : -12610.07\n",
      " Regression with ARIMA(0,0,1) errors : -10783.53\n",
      " Regression with ARIMA(0,0,0) errors : -8110.608\n",
      " Regression with ARIMA(1,0,2) errors : -12629.79\n",
      " Regression with ARIMA(2,0,1) errors : -12628.8\n",
      " Regression with ARIMA(3,0,2) errors : -12690.81\n",
      " Regression with ARIMA(3,0,1) errors : -12640.88\n",
      " Regression with ARIMA(4,0,2) errors : -12657.06\n",
      " Regression with ARIMA(3,0,3) errors : -12657.59\n",
      " Regression with ARIMA(2,0,3) errors : -12654.11\n",
      " Regression with ARIMA(4,0,1) errors : -12656.04\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12597.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12697.96\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12634.62\n",
      " Regression with ARIMA(0,0,0) errors : -9126.781\n",
      " Regression with ARIMA(1,0,0) errors : -12610.65\n",
      " Regression with ARIMA(0,0,1) errors : -10781.97\n",
      " Regression with ARIMA(0,0,0) errors : -8113.142\n",
      " Regression with ARIMA(1,0,2) errors : -12630.54\n",
      " Regression with ARIMA(2,0,1) errors : -12629.23\n",
      " Regression with ARIMA(3,0,2) errors : -12696.42\n",
      " Regression with ARIMA(3,0,1) errors : -12641.18\n",
      " Regression with ARIMA(4,0,2) errors : -12657.47\n",
      " Regression with ARIMA(3,0,3) errors : -12658.27\n",
      " Regression with ARIMA(2,0,3) errors : -12654.69\n",
      " Regression with ARIMA(4,0,1) errors : -12656.72\n",
      " Regression with ARIMA(4,0,3) errors : -12703.68\n",
      " Regression with ARIMA(5,0,3) errors : -12677.09\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12669.72\n",
      " Regression with ARIMA(4,0,3) errors : -12577.74\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.4\n",
      " Regression with ARIMA(0,0,0) errors : -9125.689\n",
      " Regression with ARIMA(1,0,0) errors : -12612.41\n",
      " Regression with ARIMA(0,0,1) errors : -10783.44\n",
      " Regression with ARIMA(0,0,0) errors : -8112.957\n",
      " Regression with ARIMA(1,0,2) errors : -12632.37\n",
      " Regression with ARIMA(2,0,1) errors : -12631.02\n",
      " Regression with ARIMA(3,0,2) errors : -12698.98\n",
      " Regression with ARIMA(3,0,1) errors : -12642.99\n",
      " Regression with ARIMA(4,0,2) errors : -12659.39\n",
      " Regression with ARIMA(3,0,3) errors : -12660.05\n",
      " Regression with ARIMA(2,0,3) errors : -12656.41\n",
      " Regression with ARIMA(4,0,1) errors : -12658.4\n",
      " Regression with ARIMA(4,0,3) errors : -12705.73\n",
      " Regression with ARIMA(5,0,3) errors : -12677.06\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12682.47\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12672.68\n",
      " Regression with ARIMA(4,0,3) errors : -12592.32\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.68\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.3\n",
      " Regression with ARIMA(0,0,0) errors : -9115.868\n",
      " Regression with ARIMA(1,0,0) errors : -12611.51\n",
      " Regression with ARIMA(0,0,1) errors : -10777.8\n",
      " Regression with ARIMA(0,0,0) errors : -8111.841\n",
      " Regression with ARIMA(1,0,2) errors : -12631.09\n",
      " Regression with ARIMA(2,0,1) errors : -12629.64\n",
      " Regression with ARIMA(3,0,2) errors : -12698.43\n",
      " Regression with ARIMA(3,0,1) errors : -12641.39\n",
      " Regression with ARIMA(4,0,2) errors : -12658.34\n",
      " Regression with ARIMA(3,0,3) errors : -12658.92\n",
      " Regression with ARIMA(2,0,3) errors : -12655.53\n",
      " Regression with ARIMA(4,0,1) errors : -12657.54\n",
      " Regression with ARIMA(4,0,3) errors : -12704.55\n",
      " Regression with ARIMA(5,0,3) errors : -12677.45\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12671.36\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.66\n",
      " Regression with ARIMA(0,0,0) errors : -9124.945\n",
      " Regression with ARIMA(1,0,0) errors : -12612.72\n",
      " Regression with ARIMA(0,0,1) errors : -10780.08\n",
      " Regression with ARIMA(0,0,0) errors : -8108.834\n",
      " Regression with ARIMA(1,0,2) errors : -12632.51\n",
      " Regression with ARIMA(2,0,1) errors : -12631.82\n",
      " Regression with ARIMA(3,0,2) errors : -12694.27\n",
      " Regression with ARIMA(3,0,1) errors : -12643.59\n",
      " Regression with ARIMA(4,0,2) errors : -12660.23\n",
      " Regression with ARIMA(3,0,3) errors : -12660.57\n",
      " Regression with ARIMA(2,0,3) errors : -12657.73\n",
      " Regression with ARIMA(4,0,1) errors : -12659.39\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12588.55\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.13\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12627.74\n",
      " Regression with ARIMA(0,0,0) errors : -9117.039\n",
      " Regression with ARIMA(1,0,0) errors : -12604.36\n",
      " Regression with ARIMA(0,0,1) errors : -10772.74\n",
      " Regression with ARIMA(0,0,0) errors : -8100.168\n",
      " Regression with ARIMA(1,0,2) errors : -12624.03\n",
      " Regression with ARIMA(2,0,1) errors : -12622.73\n",
      " Regression with ARIMA(3,0,2) errors : -12688.87\n",
      " Regression with ARIMA(3,0,1) errors : -12635.29\n",
      " Regression with ARIMA(4,0,2) errors : -12652.41\n",
      " Regression with ARIMA(3,0,3) errors : -12652.42\n",
      " Regression with ARIMA(2,0,3) errors : -12648.98\n",
      " Regression with ARIMA(4,0,1) errors : -12651.73\n",
      " Regression with ARIMA(4,0,3) errors : -12695.02\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12668.42\n",
      " Regression with ARIMA(3,0,4) errors : -12666.86\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12662.55\n",
      " Regression with ARIMA(4,0,3) errors : -12583.67\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12692.62\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12629.95\n",
      " Regression with ARIMA(0,0,0) errors : -9111.839\n",
      " Regression with ARIMA(1,0,0) errors : -12606.59\n",
      " Regression with ARIMA(0,0,1) errors : -10768.97\n",
      " Regression with ARIMA(0,0,0) errors : -8094.359\n",
      " Regression with ARIMA(1,0,2) errors : -12626.11\n",
      " Regression with ARIMA(2,0,1) errors : -12624.99\n",
      " Regression with ARIMA(3,0,2) errors : -12691.49\n",
      " Regression with ARIMA(3,0,1) errors : -12636.29\n",
      " Regression with ARIMA(4,0,2) errors : -12654.61\n",
      " Regression with ARIMA(3,0,3) errors : -12655.25\n",
      " Regression with ARIMA(2,0,3) errors : -12651.79\n",
      " Regression with ARIMA(4,0,1) errors : -12653.54\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12606.28\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12694.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12625.86\n",
      " Regression with ARIMA(0,0,0) errors : -9104.057\n",
      " Regression with ARIMA(1,0,0) errors : -12602.52\n",
      " Regression with ARIMA(0,0,1) errors : -10763.32\n",
      " Regression with ARIMA(0,0,0) errors : -8093.859\n",
      " Regression with ARIMA(1,0,2) errors : -12621.83\n",
      " Regression with ARIMA(2,0,1) errors : -12620.75\n",
      " Regression with ARIMA(3,0,2) errors : -12688.22\n",
      " Regression with ARIMA(3,0,1) errors : -12631.52\n",
      " Regression with ARIMA(4,0,2) errors : -12652.06\n",
      " Regression with ARIMA(3,0,3) errors : -12650.46\n",
      " Regression with ARIMA(2,0,3) errors : -12647.56\n",
      " Regression with ARIMA(4,0,1) errors : -12651.23\n",
      " Regression with ARIMA(4,0,3) errors : -12681.28\n",
      " Regression with ARIMA(3,0,2) errors : -12603.68\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12690.63\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12618.91\n",
      " Regression with ARIMA(0,0,0) errors : -9103.363\n",
      " Regression with ARIMA(1,0,0) errors : -12597.31\n",
      " Regression with ARIMA(0,0,1) errors : -10765.68\n",
      " Regression with ARIMA(0,0,0) errors : -8091.292\n",
      " Regression with ARIMA(1,0,2) errors : -12615.19\n",
      " Regression with ARIMA(2,0,1) errors : -12613.85\n",
      " Regression with ARIMA(3,0,2) errors : -12682.31\n",
      " Regression with ARIMA(3,0,1) errors : -12625.35\n",
      " Regression with ARIMA(4,0,2) errors : -12644.79\n",
      " Regression with ARIMA(3,0,3) errors : -12644.37\n",
      " Regression with ARIMA(2,0,3) errors : -12640.45\n",
      " Regression with ARIMA(4,0,1) errors : -12643.65\n",
      " Regression with ARIMA(4,0,3) errors : -12682.08\n",
      " Regression with ARIMA(3,0,2) errors : -12580.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12684.69\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12615.06\n",
      " Regression with ARIMA(0,0,0) errors : -9099.58\n",
      " Regression with ARIMA(1,0,0) errors : -12592.84\n",
      " Regression with ARIMA(0,0,1) errors : -10762.48\n",
      " Regression with ARIMA(0,0,0) errors : -8087.004\n",
      " Regression with ARIMA(1,0,2) errors : -12610.83\n",
      " Regression with ARIMA(2,0,1) errors : -12609.67\n",
      " Regression with ARIMA(3,0,2) errors : -12677.21\n",
      " Regression with ARIMA(3,0,1) errors : -12621.08\n",
      " Regression with ARIMA(4,0,2) errors : -12640.17\n",
      " Regression with ARIMA(3,0,3) errors : -12640.85\n",
      " Regression with ARIMA(2,0,3) errors : -12636.93\n",
      " Regression with ARIMA(4,0,1) errors : -12638.83\n",
      " Regression with ARIMA(4,0,3) errors : -12684.27\n",
      " Regression with ARIMA(5,0,3) errors : -12658.04\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12639.53\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12654.82\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12680.01\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12613.46\n",
      " Regression with ARIMA(0,0,0) errors : -9099.695\n",
      " Regression with ARIMA(1,0,0) errors : -12591.66\n",
      " Regression with ARIMA(0,0,1) errors : -10763.22\n",
      " Regression with ARIMA(0,0,0) errors : -8089.962\n",
      " Regression with ARIMA(1,0,2) errors : -12609.68\n",
      " Regression with ARIMA(2,0,1) errors : -12608.39\n",
      " Regression with ARIMA(3,0,2) errors : -12677.01\n",
      " Regression with ARIMA(3,0,1) errors : -12619.63\n",
      " Regression with ARIMA(4,0,2) errors : -12638.73\n",
      " Regression with ARIMA(3,0,3) errors : -12639.14\n",
      " Regression with ARIMA(2,0,3) errors : -12635.44\n",
      " Regression with ARIMA(4,0,1) errors : -12637.36\n",
      " Regression with ARIMA(4,0,3) errors : -12681.2\n",
      " Regression with ARIMA(5,0,3) errors : -12656.69\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12660.48\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12652.18\n",
      " Regression with ARIMA(4,0,3) errors : -12597.54\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12678.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12615.16\n",
      " Regression with ARIMA(0,0,0) errors : -9100.818\n",
      " Regression with ARIMA(1,0,0) errors : -12593.22\n",
      " Regression with ARIMA(0,0,1) errors : -10765.31\n",
      " Regression with ARIMA(0,0,0) errors : -8091.06\n",
      " Regression with ARIMA(1,0,2) errors : -12611.24\n",
      " Regression with ARIMA(2,0,1) errors : -12609.93\n",
      " Regression with ARIMA(3,0,2) errors : -12679.3\n",
      " Regression with ARIMA(3,0,1) errors : -12621.06\n",
      " Regression with ARIMA(4,0,2) errors : -12639.78\n",
      " Regression with ARIMA(3,0,3) errors : -12640.43\n",
      " Regression with ARIMA(2,0,3) errors : -12636.97\n",
      " Regression with ARIMA(4,0,1) errors : -12638.66\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12594.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12679.67\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12617.12\n",
      " Regression with ARIMA(0,0,0) errors : -9109.583\n",
      " Regression with ARIMA(1,0,0) errors : -12595.07\n",
      " Regression with ARIMA(0,0,1) errors : -10771.08\n",
      " Regression with ARIMA(0,0,0) errors : -8093.37\n",
      " Regression with ARIMA(1,0,2) errors : -12613.21\n",
      " Regression with ARIMA(2,0,1) errors : -12611.88\n",
      " Regression with ARIMA(3,0,2) errors : -12678.72\n",
      " Regression with ARIMA(3,0,1) errors : -12623\n",
      " Regression with ARIMA(4,0,2) errors : -12641.23\n",
      " Regression with ARIMA(3,0,3) errors : -12641.89\n",
      " Regression with ARIMA(2,0,3) errors : -12638.42\n",
      " Regression with ARIMA(4,0,1) errors : -12640.06\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12592.8\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12681.68\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12619.74\n",
      " Regression with ARIMA(0,0,0) errors : -9112.072\n",
      " Regression with ARIMA(1,0,0) errors : -12597.43\n",
      " Regression with ARIMA(0,0,1) errors : -10771.67\n",
      " Regression with ARIMA(0,0,0) errors : -8099.27\n",
      " Regression with ARIMA(1,0,2) errors : -12615.95\n",
      " Regression with ARIMA(2,0,1) errors : -12614.81\n",
      " Regression with ARIMA(3,0,2) errors : -12684.97\n",
      " Regression with ARIMA(3,0,1) errors : -12626.06\n",
      " Regression with ARIMA(4,0,2) errors : -12644.83\n",
      " Regression with ARIMA(3,0,3) errors : -12645.37\n",
      " Regression with ARIMA(2,0,3) errors : -12641.62\n",
      " Regression with ARIMA(4,0,1) errors : -12643.67\n",
      " Regression with ARIMA(4,0,3) errors : -12690.35\n",
      " Regression with ARIMA(5,0,3) errors : -12663.66\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12668.79\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12658.85\n",
      " Regression with ARIMA(4,0,3) errors : -12609.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12685.05\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12619.78\n",
      " Regression with ARIMA(0,0,0) errors : -9111.436\n",
      " Regression with ARIMA(1,0,0) errors : -12596.51\n",
      " Regression with ARIMA(0,0,1) errors : -10769.82\n",
      " Regression with ARIMA(0,0,0) errors : -8099.19\n",
      " Regression with ARIMA(1,0,2) errors : -12615.12\n",
      " Regression with ARIMA(2,0,1) errors : -12615.29\n",
      " Regression with ARIMA(3,0,2) errors : -12677.01\n",
      " Regression with ARIMA(3,0,1) errors : -12626.47\n",
      " Regression with ARIMA(4,0,2) errors : -12646.5\n",
      " Regression with ARIMA(3,0,3) errors : -12647.04\n",
      " Regression with ARIMA(2,0,3) errors : -12642.14\n",
      " Regression with ARIMA(4,0,1) errors : -12644.59\n",
      " Regression with ARIMA(4,0,3) errors : -12686.33\n",
      " Regression with ARIMA(5,0,3) errors : -12661.66\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12668.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12657.53\n",
      " Regression with ARIMA(4,0,3) errors : -12608.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12683.18\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12616.6\n",
      " Regression with ARIMA(0,0,0) errors : -9093.993\n",
      " Regression with ARIMA(1,0,0) errors : -12593.32\n",
      " Regression with ARIMA(0,0,1) errors : -10754.58\n",
      " Regression with ARIMA(0,0,0) errors : -8057.969\n",
      " Regression with ARIMA(1,0,2) errors : -12612.81\n",
      " Regression with ARIMA(2,0,1) errors : -12611.61\n",
      " Regression with ARIMA(3,0,2) errors : -12678.85\n",
      " Regression with ARIMA(3,0,1) errors : -12622.82\n",
      " Regression with ARIMA(4,0,2) errors : -12641.44\n",
      " Regression with ARIMA(3,0,3) errors : -12642.14\n",
      " Regression with ARIMA(2,0,3) errors : -12638.25\n",
      " Regression with ARIMA(4,0,1) errors : -12639.95\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12583.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12680.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12583.96\n",
      " Regression with ARIMA(0,0,0) errors : -9092.613\n",
      " Regression with ARIMA(1,0,0) errors : -12563.7\n",
      " Regression with ARIMA(0,0,1) errors : -10747.78\n",
      " Regression with ARIMA(0,0,0) errors : -8051.218\n",
      " Regression with ARIMA(1,0,2) errors : -12580.28\n",
      " Regression with ARIMA(2,0,1) errors : -12579.03\n",
      " Regression with ARIMA(3,0,2) errors : -12646.7\n",
      " Regression with ARIMA(3,0,1) errors : -12589.65\n",
      " Regression with ARIMA(4,0,2) errors : -12606.27\n",
      " Regression with ARIMA(3,0,3) errors : -12606.89\n",
      " Regression with ARIMA(2,0,3) errors : -12603.05\n",
      " Regression with ARIMA(4,0,1) errors : -12604.75\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12556.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12648.35\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12577.66\n",
      " Regression with ARIMA(0,0,0) errors : -9095.204\n",
      " Regression with ARIMA(1,0,0) errors : -12557.4\n",
      " Regression with ARIMA(0,0,1) errors : -10745.91\n",
      " Regression with ARIMA(0,0,0) errors : -8037.239\n",
      " Regression with ARIMA(1,0,2) errors : -12573.72\n",
      " Regression with ARIMA(2,0,1) errors : -12572.35\n",
      " Regression with ARIMA(3,0,2) errors : -12641.2\n",
      " Regression with ARIMA(3,0,1) errors : -12583.1\n",
      " Regression with ARIMA(4,0,2) errors : -12600.41\n",
      " Regression with ARIMA(3,0,3) errors : -12601.11\n",
      " Regression with ARIMA(2,0,3) errors : -12597.21\n",
      " Regression with ARIMA(4,0,1) errors : -12599.03\n",
      " Regression with ARIMA(4,0,3) errors : -12644.07\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12622.13\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12612.01\n",
      " Regression with ARIMA(4,0,3) errors : -12563.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12642.54\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12575.52\n",
      " Regression with ARIMA(0,0,0) errors : -9101.37\n",
      " Regression with ARIMA(1,0,0) errors : -12554.94\n",
      " Regression with ARIMA(0,0,1) errors : -10747.52\n",
      " Regression with ARIMA(0,0,0) errors : -8033.351\n",
      " Regression with ARIMA(1,0,2) errors : -12571.38\n",
      " Regression with ARIMA(2,0,1) errors : -12570.05\n",
      " Regression with ARIMA(3,0,2) errors : -12638.35\n",
      " Regression with ARIMA(3,0,1) errors : -12581.07\n",
      " Regression with ARIMA(4,0,2) errors : -12598.59\n",
      " Regression with ARIMA(3,0,3) errors : -12599.01\n",
      " Regression with ARIMA(2,0,3) errors : -12595.34\n",
      " Regression with ARIMA(4,0,1) errors : -12597.11\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12519.88\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12639.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12565.83\n",
      " Regression with ARIMA(0,0,0) errors : -9101.364\n",
      " Regression with ARIMA(1,0,0) errors : -12545.42\n",
      " Regression with ARIMA(0,0,1) errors : -10744.99\n",
      " Regression with ARIMA(0,0,0) errors : -8028.435\n",
      " Regression with ARIMA(1,0,2) errors : -12561.69\n",
      " Regression with ARIMA(2,0,1) errors : -12560.33\n",
      " Regression with ARIMA(3,0,2) errors : -12625.38\n",
      " Regression with ARIMA(3,0,1) errors : -12571.55\n",
      " Regression with ARIMA(4,0,2) errors : -12589.48\n",
      " Regression with ARIMA(3,0,3) errors : -12589.91\n",
      " Regression with ARIMA(2,0,3) errors : -12585.25\n",
      " Regression with ARIMA(4,0,1) errors : -12587.54\n",
      " Regression with ARIMA(4,0,3) errors : -12629.39\n",
      " Regression with ARIMA(5,0,3) errors : -12606.27\n",
      " Regression with ARIMA(4,0,4) errors : -12632.75\n",
      " Regression with ARIMA(3,0,4) errors : -12604.33\n",
      " Regression with ARIMA(5,0,4) errors : -12602.45\n",
      " Regression with ARIMA(4,0,5) errors : -12606.94\n",
      " Regression with ARIMA(3,0,5) errors : -12601.51\n",
      " Regression with ARIMA(5,0,5) errors : -12608.1\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12629.36\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "[1] \"80 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12550.88\n",
      " Regression with ARIMA(0,0,0) errors : -9082.974\n",
      " Regression with ARIMA(1,0,0) errors : -12530.87\n",
      " Regression with ARIMA(0,0,1) errors : -10726.19\n",
      " Regression with ARIMA(0,0,0) errors : -7990.949\n",
      " Regression with ARIMA(1,0,2) errors : -12547.22\n",
      " Regression with ARIMA(2,0,1) errors : -12546.03\n",
      " Regression with ARIMA(3,0,2) errors : -12611.03\n",
      " Regression with ARIMA(3,0,1) errors : -12556.14\n",
      " Regression with ARIMA(4,0,2) errors : -12573.38\n",
      " Regression with ARIMA(3,0,3) errors : -12573.93\n",
      " Regression with ARIMA(2,0,3) errors : -12570.37\n",
      " Regression with ARIMA(4,0,1) errors : -12572.13\n",
      " Regression with ARIMA(4,0,3) errors : -12616.54\n",
      " Regression with ARIMA(5,0,3) errors : -12590.07\n",
      " Regression with ARIMA(4,0,4) errors : -12620.02\n",
      " Regression with ARIMA(3,0,4) errors : -12593.33\n",
      " Regression with ARIMA(5,0,4) errors : -12585.19\n",
      " Regression with ARIMA(4,0,5) errors : -12590.96\n",
      " Regression with ARIMA(3,0,5) errors : -12586.08\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12613.46\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12541.98\n",
      " Regression with ARIMA(0,0,0) errors : -9085.693\n",
      " Regression with ARIMA(1,0,0) errors : -12521.52\n",
      " Regression with ARIMA(0,0,1) errors : -10727.61\n",
      " Regression with ARIMA(0,0,0) errors : -7984.545\n",
      " Regression with ARIMA(1,0,2) errors : -12537.92\n",
      " Regression with ARIMA(2,0,1) errors : -12537.24\n",
      " Regression with ARIMA(3,0,2) errors : -12601.89\n",
      " Regression with ARIMA(3,0,1) errors : -12547.19\n",
      " Regression with ARIMA(4,0,2) errors : -12564.24\n",
      " Regression with ARIMA(3,0,3) errors : -12564.26\n",
      " Regression with ARIMA(2,0,3) errors : -12561.62\n",
      " Regression with ARIMA(4,0,1) errors : -12563.37\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12499.3\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12602.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.96\n",
      " Regression with ARIMA(0,0,0) errors : -9090.727\n",
      " Regression with ARIMA(1,0,0) errors : -12524.23\n",
      " Regression with ARIMA(0,0,1) errors : -10729.14\n",
      " Regression with ARIMA(0,0,0) errors : -7988.192\n",
      " Regression with ARIMA(1,0,2) errors : -12541.23\n",
      " Regression with ARIMA(2,0,1) errors : -12541.2\n",
      " Regression with ARIMA(3,0,2) errors : -12596.53\n",
      " Regression with ARIMA(3,0,1) errors : -12551.61\n",
      " Regression with ARIMA(4,0,2) errors : -12568.27\n",
      " Regression with ARIMA(3,0,3) errors : -12568.72\n",
      " Regression with ARIMA(2,0,3) errors : -12565.53\n",
      " Regression with ARIMA(4,0,1) errors : -12567.05\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12496.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12605.49\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12548.88\n",
      " Regression with ARIMA(0,0,0) errors : -9100.305\n",
      " Regression with ARIMA(1,0,0) errors : -12527.5\n",
      " Regression with ARIMA(0,0,1) errors : -10736.35\n",
      " Regression with ARIMA(0,0,0) errors : -7988.759\n",
      " Regression with ARIMA(1,0,2) errors : -12544.66\n",
      " Regression with ARIMA(2,0,1) errors : -12543.65\n",
      " Regression with ARIMA(3,0,2) errors : -12605.4\n",
      " Regression with ARIMA(3,0,1) errors : -12554.44\n",
      " Regression with ARIMA(4,0,2) errors : -12571.11\n",
      " Regression with ARIMA(3,0,3) errors : -12571.91\n",
      " Regression with ARIMA(2,0,3) errors : -12568.5\n",
      " Regression with ARIMA(4,0,1) errors : -12570.06\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12504.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12608.79\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.27\n",
      " Regression with ARIMA(0,0,0) errors : -9095.28\n",
      " Regression with ARIMA(1,0,0) errors : -12526.27\n",
      " Regression with ARIMA(0,0,1) errors : -10733.95\n",
      " Regression with ARIMA(0,0,0) errors : -7985.631\n",
      " Regression with ARIMA(1,0,2) errors : -12543.29\n",
      " Regression with ARIMA(2,0,1) errors : -12541.96\n",
      " Regression with ARIMA(3,0,2) errors : -12605.92\n",
      " Regression with ARIMA(3,0,1) errors : -12552.76\n",
      " Regression with ARIMA(4,0,2) errors : -12569.38\n",
      " Regression with ARIMA(3,0,3) errors : -12569.97\n",
      " Regression with ARIMA(2,0,3) errors : -12566.62\n",
      " Regression with ARIMA(4,0,1) errors : -12568.51\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12514.77\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12607.57\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12551.72\n",
      " Regression with ARIMA(0,0,0) errors : -9094.616\n",
      " Regression with ARIMA(1,0,0) errors : -12527.72\n",
      " Regression with ARIMA(0,0,1) errors : -10731.91\n",
      " Regression with ARIMA(0,0,0) errors : -7984.814\n",
      " Regression with ARIMA(1,0,2) errors : -12544.83\n",
      " Regression with ARIMA(2,0,1) errors : -12545.69\n",
      " Regression with ARIMA(3,0,2) errors : -12599.12\n",
      " Regression with ARIMA(3,0,1) errors : -12556.69\n",
      " Regression with ARIMA(4,0,2) errors : -12574.58\n",
      " Regression with ARIMA(3,0,3) errors : -12572.21\n",
      " Regression with ARIMA(2,0,3) errors : -12570.48\n",
      " Regression with ARIMA(4,0,1) errors : -12574.57\n",
      " Regression with ARIMA(4,0,3) errors : -12602.14\n",
      " Regression with ARIMA(5,0,3) errors : -12593.97\n",
      " Regression with ARIMA(4,0,4) errors : -12614.31\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12592.12\n",
      " Regression with ARIMA(4,0,5) errors : -12613.12\n",
      " Regression with ARIMA(3,0,5) errors : -12593.98\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -12615.97\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.25\n",
      " Regression with ARIMA(0,0,0) errors : -9103.285\n",
      " Regression with ARIMA(1,0,0) errors : -12525.6\n",
      " Regression with ARIMA(0,0,1) errors : -10740.02\n",
      " Regression with ARIMA(0,0,0) errors : -7987.126\n",
      " Regression with ARIMA(1,0,2) errors : -12542.63\n",
      " Regression with ARIMA(2,0,1) errors : -12541.09\n",
      " Regression with ARIMA(3,0,2) errors : -12595.27\n",
      " Regression with ARIMA(3,0,1) errors : -12553.61\n",
      " Regression with ARIMA(4,0,2) errors : -12567.35\n",
      " Regression with ARIMA(3,0,3) errors : -12568.1\n",
      " Regression with ARIMA(2,0,3) errors : -12564.84\n",
      " Regression with ARIMA(4,0,1) errors : -12567.61\n",
      " Regression with ARIMA(4,0,3) errors : -12599.93\n",
      " Regression with ARIMA(5,0,3) errors : -12585.25\n",
      " Regression with ARIMA(4,0,4) errors : -12587.13\n",
      " Regression with ARIMA(3,0,4) errors : -12586.59\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12587.56\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12603.94\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12563.76\n",
      " Regression with ARIMA(0,0,0) errors : -9114.748\n",
      " Regression with ARIMA(1,0,0) errors : -12542.44\n",
      " Regression with ARIMA(0,0,1) errors : -10750.26\n",
      " Regression with ARIMA(0,0,0) errors : -7996.79\n",
      " Regression with ARIMA(1,0,2) errors : -12559.52\n",
      " Regression with ARIMA(2,0,1) errors : -12557.88\n",
      " Regression with ARIMA(3,0,2) errors : -12623.24\n",
      " Regression with ARIMA(3,0,1) errors : -12569.07\n",
      " Regression with ARIMA(4,0,2) errors : -12584.06\n",
      " Regression with ARIMA(3,0,3) errors : -12584.83\n",
      " Regression with ARIMA(2,0,3) errors : -12581.2\n",
      " Regression with ARIMA(4,0,1) errors : -12583.59\n",
      " Regression with ARIMA(4,0,3) errors : -12622.16\n",
      " Regression with ARIMA(3,0,2) errors : -12529.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12623.55\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12571.66\n",
      " Regression with ARIMA(0,0,0) errors : -9119.255\n",
      " Regression with ARIMA(1,0,0) errors : -12550.63\n",
      " Regression with ARIMA(0,0,1) errors : -10754.38\n",
      " Regression with ARIMA(0,0,0) errors : -7999.828\n",
      " Regression with ARIMA(1,0,2) errors : -12567.56\n",
      " Regression with ARIMA(2,0,1) errors : -12565.97\n",
      " Regression with ARIMA(3,0,2) errors : -12623.38\n",
      " Regression with ARIMA(3,0,1) errors : -12577.61\n",
      " Regression with ARIMA(4,0,2) errors : -12592.71\n",
      " Regression with ARIMA(3,0,3) errors : -12593.33\n",
      " Regression with ARIMA(2,0,3) errors : -12589.24\n",
      " Regression with ARIMA(4,0,1) errors : -12591.99\n",
      " Regression with ARIMA(4,0,3) errors : -12628.14\n",
      " Regression with ARIMA(5,0,3) errors : -12611.42\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12608.22\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12601.46\n",
      " Regression with ARIMA(4,0,3) errors : -12518.46\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12632.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12570.69\n",
      " Regression with ARIMA(0,0,0) errors : -9115.278\n",
      " Regression with ARIMA(1,0,0) errors : -12549.82\n",
      " Regression with ARIMA(0,0,1) errors : -10753.47\n",
      " Regression with ARIMA(0,0,0) errors : -8003.712\n",
      " Regression with ARIMA(1,0,2) errors : -12566.64\n",
      " Regression with ARIMA(2,0,1) errors : -12564.99\n",
      " Regression with ARIMA(3,0,2) errors : -12627.12\n",
      " Regression with ARIMA(3,0,1) errors : -12576.67\n",
      " Regression with ARIMA(4,0,2) errors : -12592.86\n",
      " Regression with ARIMA(3,0,3) errors : -12593.53\n",
      " Regression with ARIMA(2,0,3) errors : -12588.09\n",
      " Regression with ARIMA(4,0,1) errors : -12591.37\n",
      " Regression with ARIMA(4,0,3) errors : -12631.06\n",
      " Regression with ARIMA(5,0,3) errors : -12608.52\n",
      " Regression with ARIMA(4,0,4) errors : -12636.78\n",
      " Regression with ARIMA(3,0,4) errors : -12595.05\n",
      " Regression with ARIMA(5,0,4) errors : -12606.13\n",
      " Regression with ARIMA(4,0,5) errors : -12611.46\n",
      " Regression with ARIMA(3,0,5) errors : -12589.1\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12631.52\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12578.38\n",
      " Regression with ARIMA(0,0,0) errors : -9111.17\n",
      " Regression with ARIMA(1,0,0) errors : -12558.92\n",
      " Regression with ARIMA(0,0,1) errors : -10753.78\n",
      " Regression with ARIMA(0,0,0) errors : -8020.573\n",
      " Regression with ARIMA(1,0,2) errors : -12574.68\n",
      " Regression with ARIMA(2,0,1) errors : -12573.05\n",
      " Regression with ARIMA(3,0,2) errors : -12623.18\n",
      " Regression with ARIMA(3,0,1) errors : -12586.14\n",
      " Regression with ARIMA(4,0,2) errors : -12599.85\n",
      " Regression with ARIMA(3,0,3) errors : -12600.52\n",
      " Regression with ARIMA(2,0,3) errors : -12595.7\n",
      " Regression with ARIMA(4,0,1) errors : -12599.55\n",
      " Regression with ARIMA(4,0,3) errors : -12630.95\n",
      " Regression with ARIMA(5,0,3) errors : -12614.41\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12610.87\n",
      " Regression with ARIMA(5,0,2) errors : -12611.96\n",
      " Regression with ARIMA(5,0,4) errors : -12609.33\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12639.79\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12589.89\n",
      " Regression with ARIMA(0,0,0) errors : -9118.887\n",
      " Regression with ARIMA(1,0,0) errors : -12570.44\n",
      " Regression with ARIMA(0,0,1) errors : -10762.54\n",
      " Regression with ARIMA(0,0,0) errors : -8023.134\n",
      " Regression with ARIMA(1,0,2) errors : -12586.06\n",
      " Regression with ARIMA(2,0,1) errors : -12584.58\n",
      " Regression with ARIMA(3,0,2) errors : -12650.24\n",
      " Regression with ARIMA(3,0,1) errors : -12595.09\n",
      " Regression with ARIMA(4,0,2) errors : -12610.13\n",
      " Regression with ARIMA(3,0,3) errors : -12611.25\n",
      " Regression with ARIMA(2,0,3) errors : -12607.47\n",
      " Regression with ARIMA(4,0,1) errors : -12610.04\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12562.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12652.57\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12605.76\n",
      " Regression with ARIMA(0,0,0) errors : -9124.298\n",
      " Regression with ARIMA(1,0,0) errors : -12585.84\n",
      " Regression with ARIMA(0,0,1) errors : -10776.69\n",
      " Regression with ARIMA(0,0,0) errors : -8072.897\n",
      " Regression with ARIMA(1,0,2) errors : -12601.79\n",
      " Regression with ARIMA(2,0,1) errors : -12600.13\n",
      " Regression with ARIMA(3,0,2) errors : -12662.69\n",
      " Regression with ARIMA(3,0,1) errors : -12612.34\n",
      " Regression with ARIMA(4,0,2) errors : -12629.9\n",
      " Regression with ARIMA(3,0,3) errors : -12629.01\n",
      " Regression with ARIMA(2,0,3) errors : -12623.63\n",
      " Regression with ARIMA(4,0,1) errors : -12627.83\n",
      " Regression with ARIMA(4,0,3) errors : -12662.1\n",
      " Regression with ARIMA(3,0,2) errors : -12538.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12668.81\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12617.98\n",
      " Regression with ARIMA(0,0,0) errors : -9103.826\n",
      " Regression with ARIMA(1,0,0) errors : -12597.39\n",
      " Regression with ARIMA(0,0,1) errors : -10769.07\n",
      " Regression with ARIMA(0,0,0) errors : -8071.78\n",
      " Regression with ARIMA(1,0,2) errors : -12613.58\n",
      " Regression with ARIMA(2,0,1) errors : -12612.03\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12634.81\n",
      " Regression with ARIMA(1,0,3) errors : -12637.74\n",
      " Regression with ARIMA(0,0,3) errors : -11857.74\n",
      " Regression with ARIMA(1,0,4) errors : -12635.79\n",
      " Regression with ARIMA(0,0,2) errors : -11425.89\n",
      " Regression with ARIMA(0,0,4) errors : -12183.34\n",
      " Regression with ARIMA(2,0,4) errors : -12660.74\n",
      " Regression with ARIMA(3,0,4) errors : -12661.91\n",
      " Regression with ARIMA(3,0,3) errors : -12639.57\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12664.79\n",
      " Regression with ARIMA(1,0,5) errors : -12637.48\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12662.8\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12648.96\n",
      " Regression with ARIMA(0,0,0) errors : -9121.032\n",
      " Regression with ARIMA(1,0,0) errors : -12628.13\n",
      " Regression with ARIMA(0,0,1) errors : -10785.99\n",
      " Regression with ARIMA(0,0,0) errors : -8086.924\n",
      " Regression with ARIMA(1,0,2) errors : -12643.58\n",
      " Regression with ARIMA(2,0,1) errors : -12645.29\n",
      " Regression with ARIMA(3,0,2) errors : -12693.39\n",
      " Regression with ARIMA(3,0,1) errors : -12657.07\n",
      " Regression with ARIMA(4,0,2) errors : -12674.99\n",
      " Regression with ARIMA(3,0,3) errors : -12674.05\n",
      " Regression with ARIMA(2,0,3) errors : -12670.13\n",
      " Regression with ARIMA(4,0,1) errors : -12673.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12586.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12712.63\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12660.79\n",
      " Regression with ARIMA(0,0,0) errors : -9128.864\n",
      " Regression with ARIMA(1,0,0) errors : -12639.5\n",
      " Regression with ARIMA(0,0,1) errors : -10794.45\n",
      " Regression with ARIMA(0,0,0) errors : -8086.79\n",
      " Regression with ARIMA(1,0,2) errors : -12656.36\n",
      " Regression with ARIMA(2,0,1) errors : -12654.67\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12681.02\n",
      " Regression with ARIMA(1,0,3) errors : -12683.93\n",
      " Regression with ARIMA(0,0,3) errors : -11882.7\n",
      " Regression with ARIMA(1,0,4) errors : -12681.93\n",
      " Regression with ARIMA(0,0,2) errors : -11451.05\n",
      " Regression with ARIMA(0,0,4) errors : -12222.24\n",
      " Regression with ARIMA(2,0,4) errors : -12708.43\n",
      " Regression with ARIMA(3,0,4) errors : -12700.64\n",
      " Regression with ARIMA(2,0,5) errors : -12711.77\n",
      " Regression with ARIMA(1,0,5) errors : -12684.46\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12635.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12712.16\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12663.87\n",
      " Regression with ARIMA(0,0,0) errors : -9125.032\n",
      " Regression with ARIMA(1,0,0) errors : -12642.83\n",
      " Regression with ARIMA(0,0,1) errors : -10795.06\n",
      " Regression with ARIMA(0,0,0) errors : -8088.558\n",
      " Regression with ARIMA(1,0,2) errors : -12659.49\n",
      " Regression with ARIMA(2,0,1) errors : -12657.96\n",
      " Regression with ARIMA(3,0,2) errors : -12717.9\n",
      " Regression with ARIMA(3,0,1) errors : -12671.05\n",
      " Regression with ARIMA(4,0,2) errors : -12688.31\n",
      " Regression with ARIMA(3,0,3) errors : -12688.66\n",
      " Regression with ARIMA(2,0,3) errors : -12684.8\n",
      " Regression with ARIMA(4,0,1) errors : -12687.93\n",
      " Regression with ARIMA(4,0,3) errors : -12724.73\n",
      " Regression with ARIMA(5,0,3) errors : -12705.98\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12706.33\n",
      " Regression with ARIMA(5,0,2) errors : -12704.8\n",
      " Regression with ARIMA(5,0,4) errors : -12707.76\n",
      " Regression with ARIMA(4,0,3) errors : -12626.28\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12711.43\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12675.17\n",
      " Regression with ARIMA(0,0,0) errors : -9127.822\n",
      " Regression with ARIMA(1,0,0) errors : -12652.69\n",
      " Regression with ARIMA(0,0,1) errors : -10797.32\n",
      " Regression with ARIMA(0,0,0) errors : -8122.42\n",
      " Regression with ARIMA(1,0,2) errors : -12669.49\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12695.32\n",
      " Regression with ARIMA(1,0,3) errors : -12697.68\n",
      " Regression with ARIMA(0,0,3) errors : -11885.17\n",
      " Regression with ARIMA(1,0,4) errors : -12695.67\n",
      " Regression with ARIMA(0,0,2) errors : -11454.21\n",
      " Regression with ARIMA(0,0,4) errors : -12223.07\n",
      " Regression with ARIMA(2,0,4) errors : -12724.02\n",
      " Regression with ARIMA(3,0,4) errors : -12727\n",
      " Regression with ARIMA(3,0,3) errors : -12699.87\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12728.15\n",
      " Regression with ARIMA(1,0,5) errors : -12698.24\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12723.48\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12683.94\n",
      " Regression with ARIMA(0,0,0) errors : -9138.188\n",
      " Regression with ARIMA(1,0,0) errors : -12661.92\n",
      " Regression with ARIMA(0,0,1) errors : -10809.04\n",
      " Regression with ARIMA(0,0,0) errors : -8146.342\n",
      " Regression with ARIMA(1,0,2) errors : -12678.66\n",
      " Regression with ARIMA(2,0,1) errors : -12676.73\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12704.85\n",
      " Regression with ARIMA(1,0,3) errors : -12707.91\n",
      " Regression with ARIMA(0,0,3) errors : -11899.86\n",
      " Regression with ARIMA(1,0,4) errors : -12705.92\n",
      " Regression with ARIMA(0,0,2) errors : -11462.84\n",
      " Regression with ARIMA(0,0,4) errors : -12239.61\n",
      " Regression with ARIMA(2,0,4) errors : -12733.61\n",
      " Regression with ARIMA(3,0,4) errors : -12727.8\n",
      " Regression with ARIMA(2,0,5) errors : -12736.88\n",
      " Regression with ARIMA(1,0,5) errors : -12708.11\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12658.61\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12738.19\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12707.9\n",
      " Regression with ARIMA(0,0,0) errors : -9146.696\n",
      " Regression with ARIMA(1,0,0) errors : -12685.85\n",
      " Regression with ARIMA(0,0,1) errors : -10816.31\n",
      " Regression with ARIMA(0,0,0) errors : -8145.991\n",
      " Regression with ARIMA(1,0,2) errors : -12701.98\n",
      " Regression with ARIMA(2,0,1) errors : -12702.83\n",
      " Regression with ARIMA(3,0,2) errors : -12752.59\n",
      " Regression with ARIMA(3,0,1) errors : -12716.78\n",
      " Regression with ARIMA(4,0,2) errors : -12776.93\n",
      " Regression with ARIMA(4,0,1) errors : -12738.81\n",
      " Regression with ARIMA(5,0,2) errors : -12750.69\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -12740.15\n",
      " Regression with ARIMA(5,0,1) errors : -12807.17\n",
      " Regression with ARIMA(5,0,0) errors : -12741.34\n",
      " Regression with ARIMA(4,0,0) errors : -12738.7\n",
      " Regression with ARIMA(5,0,1) errors : -12728.9\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12760.88\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12912.84\n",
      " Regression with ARIMA(0,0,0) errors : -9287.558\n",
      " Regression with ARIMA(1,0,0) errors : -12838.23\n",
      " Regression with ARIMA(0,0,1) errors : -10970.44\n",
      " Regression with ARIMA(0,0,0) errors : -8334.607\n",
      " Regression with ARIMA(1,0,2) errors : -12850.07\n",
      " Regression with ARIMA(2,0,1) errors : -12896.83\n",
      " Regression with ARIMA(3,0,2) errors : -12886.59\n",
      " Regression with ARIMA(2,0,3) errors : -12920.49\n",
      " Regression with ARIMA(1,0,3) errors : -12869.31\n",
      " Regression with ARIMA(3,0,3) errors : -12922.93\n",
      " Regression with ARIMA(4,0,3) errors : -12951.22\n",
      " Regression with ARIMA(4,0,2) errors : -12979.64\n",
      " Regression with ARIMA(4,0,1) errors : -12919.17\n",
      " Regression with ARIMA(5,0,2) errors : -13016.01\n",
      " Regression with ARIMA(5,0,1) errors : -12918.05\n",
      " Regression with ARIMA(5,0,3) errors : -13009.45\n",
      " Regression with ARIMA(5,0,2) errors : -12924.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -12851.52\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13340.53\n",
      " Regression with ARIMA(0,0,0) errors : -9896.247\n",
      " Regression with ARIMA(1,0,0) errors : -13321.04\n",
      " Regression with ARIMA(0,0,1) errors : -11543.52\n",
      " Regression with ARIMA(0,0,0) errors : -8940.049\n",
      " Regression with ARIMA(1,0,2) errors : -13322.44\n",
      " Regression with ARIMA(2,0,1) errors : -13321.63\n",
      " Regression with ARIMA(3,0,2) errors : -13355.77\n",
      " Regression with ARIMA(3,0,1) errors : -13337\n",
      " Regression with ARIMA(4,0,2) errors : -13354.79\n",
      " Regression with ARIMA(3,0,3) errors : -13380.32\n",
      " Regression with ARIMA(2,0,3) errors : -13333.79\n",
      " Regression with ARIMA(4,0,3) errors : -13412.84\n",
      " Regression with ARIMA(5,0,3) errors : -13428.89\n",
      " Regression with ARIMA(5,0,2) errors : -13429.21\n",
      " Regression with ARIMA(5,0,1) errors : -13348.63\n",
      " Regression with ARIMA(4,0,1) errors : -13348.07\n",
      " Regression with ARIMA(5,0,2) errors : -13296.63\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13383.36\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13638.8\n",
      " Regression with ARIMA(0,1,0) errors : -13557.1\n",
      " Regression with ARIMA(1,1,0) errors : -13569.73\n",
      " Regression with ARIMA(0,1,1) errors : -13568.98\n",
      " Regression with ARIMA(0,1,0) errors : -13559.1\n",
      " Regression with ARIMA(1,1,2) errors : -13569.88\n",
      " Regression with ARIMA(2,1,1) errors : -13572.21\n",
      " Regression with ARIMA(3,1,2) errors : -13655.74\n",
      " Regression with ARIMA(3,1,1) errors : -13608.61\n",
      " Regression with ARIMA(4,1,2) errors : -13690.96\n",
      " Regression with ARIMA(4,1,1) errors : -13635.24\n",
      " Regression with ARIMA(5,1,2) errors : -13685.37\n",
      " Regression with ARIMA(4,1,3) errors : -13668.95\n",
      " Regression with ARIMA(3,1,3) errors : -13656.78\n",
      " Regression with ARIMA(5,1,1) errors : -13674.36\n",
      " Regression with ARIMA(5,1,3) errors : -13699.07\n",
      " Regression with ARIMA(5,1,4) errors : -13798\n",
      " Regression with ARIMA(4,1,4) errors : -13766.7\n",
      " Regression with ARIMA(5,1,5) errors : -13796.13\n",
      " Regression with ARIMA(4,1,5) errors : -13791.29\n",
      " Regression with ARIMA(5,1,4) errors : -13800.01\n",
      " Regression with ARIMA(4,1,4) errors : -13768.68\n",
      " Regression with ARIMA(5,1,3) errors : -13701.1\n",
      " Regression with ARIMA(5,1,5) errors : -13798.15\n",
      " Regression with ARIMA(4,1,3) errors : -13669.36\n",
      " Regression with ARIMA(4,1,5) errors : -13793.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,4) errors : -13627.14\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13856.97\n",
      " Regression with ARIMA(0,1,0) errors : -13830.28\n",
      " Regression with ARIMA(1,1,0) errors : -13844.83\n",
      " Regression with ARIMA(0,1,1) errors : -13841.77\n",
      " Regression with ARIMA(0,1,0) errors : -13832.29\n",
      " Regression with ARIMA(1,1,2) errors : -13852.88\n",
      " Regression with ARIMA(2,1,1) errors : -13857.98\n",
      " Regression with ARIMA(1,1,1) errors : -13853.24\n",
      " Regression with ARIMA(2,1,0) errors : -13857.59\n",
      " Regression with ARIMA(3,1,1) errors : -13856.45\n",
      " Regression with ARIMA(3,1,0) errors : -13855.79\n",
      " Regression with ARIMA(3,1,2) errors : -13853.87\n",
      " Regression with ARIMA(2,1,1) errors : -13859.99\n",
      " Regression with ARIMA(1,1,1) errors : -13855.24\n",
      " Regression with ARIMA(2,1,0) errors : -13859.61\n",
      " Regression with ARIMA(3,1,1) errors : -13858.47\n",
      " Regression with ARIMA(2,1,2) errors : -13858.99\n",
      " Regression with ARIMA(1,1,0) errors : -13846.84\n",
      " Regression with ARIMA(1,1,2) errors : -13854.88\n",
      " Regression with ARIMA(3,1,0) errors : -13857.8\n",
      " Regression with ARIMA(3,1,2) errors : -13855.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : -13852.22\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,1) errors \n",
      "\n",
      "[1] \"90 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13947.36\n",
      " Regression with ARIMA(0,1,0) errors : -13900.86\n",
      " Regression with ARIMA(1,1,0) errors : -13932.84\n",
      " Regression with ARIMA(0,1,1) errors : -13911.73\n",
      " Regression with ARIMA(0,1,0) errors : -13902.87\n",
      " Regression with ARIMA(1,1,2) errors : -13939.01\n",
      " Regression with ARIMA(2,1,1) errors : -13943.65\n",
      " Regression with ARIMA(3,1,2) errors : -13959.09\n",
      " Regression with ARIMA(3,1,1) errors : -13956.45\n",
      " Regression with ARIMA(4,1,2) errors : -14000.17\n",
      " Regression with ARIMA(4,1,1) errors : -13952.05\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : -14004.61\n",
      " Regression with ARIMA(3,1,3) errors : -13984.19\n",
      " Regression with ARIMA(5,1,3) errors : -14058.98\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : -14034.52\n",
      " Regression with ARIMA(5,1,3) errors : -14060.9\n",
      " Regression with ARIMA(4,1,3) errors : -14006.63\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : -14002.15\n",
      " Regression with ARIMA(4,1,4) errors : -14036.43\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : -13974.19\n",
      "\n",
      " Best model: Regression with ARIMA(4,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14051.09\n",
      " Regression with ARIMA(0,1,0) errors : -14017.53\n",
      " Regression with ARIMA(1,1,0) errors : -14026.02\n",
      " Regression with ARIMA(0,1,1) errors : -14026.4\n",
      " Regression with ARIMA(0,1,0) errors : -14019.51\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14049.92\n",
      " Regression with ARIMA(3,1,2) errors : -14072.45\n",
      " Regression with ARIMA(3,1,1) errors : -14060.26\n",
      " Regression with ARIMA(4,1,2) errors : -14078.94\n",
      " Regression with ARIMA(4,1,1) errors : -14061.76\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : -14126.2\n",
      " Regression with ARIMA(2,1,3) errors : -14050.56\n",
      " Regression with ARIMA(3,1,4) errors : -14077.3\n",
      " Regression with ARIMA(2,1,4) errors : -14048.58\n",
      " Regression with ARIMA(4,1,4) errors : -14193.59\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14215.31\n",
      " Regression with ARIMA(2,1,5) errors : -14059.26\n",
      " Regression with ARIMA(3,1,5) errors : -14216.42\n",
      " Regression with ARIMA(2,1,5) errors : -14061.28\n",
      " Regression with ARIMA(3,1,4) errors : -14177.43\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14050.61\n",
      " Regression with ARIMA(4,1,4) errors : -14194.71\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -14036.04\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14232.72\n",
      " Regression with ARIMA(0,1,0) errors : -14162.77\n",
      " Regression with ARIMA(1,1,0) errors : -14185.38\n",
      " Regression with ARIMA(0,1,1) errors : -14173.07\n",
      " Regression with ARIMA(0,1,0) errors : -14164.75\n",
      " Regression with ARIMA(1,1,2) errors : -14207.81\n",
      " Regression with ARIMA(2,1,1) errors : -14224.23\n",
      " Regression with ARIMA(3,1,2) errors : -14248.4\n",
      " Regression with ARIMA(3,1,1) errors : -14225.86\n",
      " Regression with ARIMA(4,1,2) errors : -14270.04\n",
      " Regression with ARIMA(4,1,1) errors : -14226.79\n",
      " Regression with ARIMA(5,1,2) errors : -14276.69\n",
      " Regression with ARIMA(5,1,1) errors : -14239.31\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : -14278.66\n",
      " Regression with ARIMA(4,1,2) errors : -14272.05\n",
      " Regression with ARIMA(5,1,1) errors : -14241.32\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : -14228.77\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,1) errors : -14188.43\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14269.51\n",
      " Regression with ARIMA(1,1,0) errors : -14280.67\n",
      " Regression with ARIMA(0,1,1) errors : -14275.99\n",
      " Regression with ARIMA(0,1,0) errors : -14271.49\n",
      " Regression with ARIMA(2,1,0) errors : -14280.26\n",
      " Regression with ARIMA(1,1,1) errors : -14283.64\n",
      " Regression with ARIMA(2,1,1) errors : -14282.63\n",
      " Regression with ARIMA(1,1,2) errors : -14281.81\n",
      " Regression with ARIMA(0,1,2) errors : -14276.35\n",
      " Regression with ARIMA(1,1,1) errors : -14285.62\n",
      " Regression with ARIMA(0,1,1) errors : -14277.97\n",
      " Regression with ARIMA(1,1,0) errors : -14282.66\n",
      " Regression with ARIMA(2,1,1) errors : -14284.63\n",
      " Regression with ARIMA(1,1,2) errors : -14283.8\n",
      " Regression with ARIMA(0,1,2) errors : -14278.33\n",
      " Regression with ARIMA(2,1,0) errors : -14282.25\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14292.77\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14392.52\n",
      " Regression with ARIMA(0,1,0) errors : -14319.87\n",
      " Regression with ARIMA(1,1,0) errors : -14323.95\n",
      " Regression with ARIMA(0,1,1) errors : -14324.28\n",
      " Regression with ARIMA(0,1,0) errors : -14321.88\n",
      " Regression with ARIMA(1,1,2) errors : -14328.67\n",
      " Regression with ARIMA(2,1,1) errors : -14322.2\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14396.05\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14397.58\n",
      " Regression with ARIMA(1,1,4) errors : -14325.55\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14409.11\n",
      " Regression with ARIMA(0,1,5) errors : -14329.22\n",
      " Regression with ARIMA(0,1,4) errors : -14322.36\n",
      " Regression with ARIMA(1,1,5) errors : -14410.56\n",
      " Regression with ARIMA(0,1,5) errors : -14331.23\n",
      " Regression with ARIMA(1,1,4) errors : -14327.56\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(0,1,4) errors : -14324.37\n",
      " Regression with ARIMA(2,1,4) errors : -14399.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,5) errors : -14340.4\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14414.39\n",
      " Regression with ARIMA(0,1,0) errors : -14347.05\n",
      " Regression with ARIMA(1,1,0) errors : -14351.5\n",
      " Regression with ARIMA(0,1,1) errors : -14351.98\n",
      " Regression with ARIMA(0,1,0) errors : -14349.06\n",
      " Regression with ARIMA(1,1,2) errors : -14355.74\n",
      " Regression with ARIMA(2,1,1) errors : -14357.14\n",
      " Regression with ARIMA(3,1,2) errors : -14356.58\n",
      " Regression with ARIMA(2,1,3) errors : -14416.78\n",
      " Regression with ARIMA(1,1,3) errors : -14352.44\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14426.08\n",
      " Regression with ARIMA(1,1,4) errors : -14352.46\n",
      " Regression with ARIMA(3,1,4) errors : -14359.23\n",
      " Regression with ARIMA(2,1,5) errors : -14433.08\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14448.43\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14449.79\n",
      " Regression with ARIMA(2,1,5) errors : -14434.5\n",
      " Regression with ARIMA(3,1,4) errors : -14361.25\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14427.62\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14373.05\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14467.17\n",
      " Regression with ARIMA(0,1,0) errors : -14387.79\n",
      " Regression with ARIMA(1,1,0) errors : -14392.42\n",
      " Regression with ARIMA(0,1,1) errors : -14393.12\n",
      " Regression with ARIMA(0,1,0) errors : -14389.79\n",
      " Regression with ARIMA(1,1,2) errors : -14393.52\n",
      " Regression with ARIMA(2,1,1) errors : -14392.46\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14467.02\n",
      " Regression with ARIMA(1,1,1) errors : -14394.63\n",
      " Regression with ARIMA(1,1,3) errors : -14391.52\n",
      " Regression with ARIMA(3,1,1) errors : -14450.2\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -14468.77\n",
      " Regression with ARIMA(1,1,2) errors : -14395.53\n",
      " Regression with ARIMA(2,1,1) errors : -14394.46\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14468.52\n",
      " Regression with ARIMA(1,1,1) errors : -14396.63\n",
      " Regression with ARIMA(1,1,3) errors : -14393.52\n",
      " Regression with ARIMA(3,1,1) errors : -14452.03\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : -14406.82\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11132.19\n",
      " Regression with ARIMA(1,0,0) errors : -14540.36\n",
      " Regression with ARIMA(0,0,1) errors : -12745.99\n",
      " Regression with ARIMA(0,0,0) errors : -9972.371\n",
      " Regression with ARIMA(2,0,0) errors : -14537.54\n",
      " Regression with ARIMA(1,0,1) errors : -14538.45\n",
      " Regression with ARIMA(2,0,1) errors : -14542.87\n",
      " Regression with ARIMA(3,0,1) errors : -14558.56\n",
      " Regression with ARIMA(3,0,0) errors : -14548.35\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -14559.21\n",
      " Regression with ARIMA(4,0,2) errors : -14555.78\n",
      " Regression with ARIMA(3,0,3) errors : -14558.89\n",
      " Regression with ARIMA(2,0,3) errors : -14545.56\n",
      " Regression with ARIMA(4,0,3) errors : -14553.54\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14560.17\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11151.48\n",
      " Regression with ARIMA(1,0,0) errors : -14551.11\n",
      " Regression with ARIMA(0,0,1) errors : -12768.97\n",
      " Regression with ARIMA(0,0,0) errors : -9991.611\n",
      " Regression with ARIMA(2,0,0) errors : -14548.25\n",
      " Regression with ARIMA(1,0,1) errors : -14549.23\n",
      " Regression with ARIMA(2,0,1) errors : -14552.94\n",
      " Regression with ARIMA(3,0,1) errors : -14567.66\n",
      " Regression with ARIMA(3,0,0) errors : -14558.46\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,0) errors : -14557.43\n",
      " Regression with ARIMA(4,0,2) errors : -14572.3\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -14567.45\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,1) errors : -14571.65\n",
      " Regression with ARIMA(5,0,3) errors : -14591.07\n",
      " Regression with ARIMA(5,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -14588.65\n",
      " Regression with ARIMA(5,0,3) errors : -14466.83\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -14592.39\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14560.15\n",
      " Regression with ARIMA(0,0,0) errors : -11132.88\n",
      " Regression with ARIMA(1,0,0) errors : -14543.96\n",
      " Regression with ARIMA(0,0,1) errors : -12748.49\n",
      " Regression with ARIMA(0,0,0) errors : -9916.669\n",
      " Regression with ARIMA(1,0,2) errors : -14552.05\n",
      " Regression with ARIMA(2,0,1) errors : -14544.14\n",
      " Regression with ARIMA(3,0,2) errors : -14551.85\n",
      " Regression with ARIMA(2,0,3) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -14542.09\n",
      " Regression with ARIMA(1,0,3) errors : -14551.93\n",
      " Regression with ARIMA(3,0,1) errors : -14569.13\n",
      " Regression with ARIMA(3,0,0) errors : -14553.2\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -14542.46\n",
      " Regression with ARIMA(4,0,0) errors : -14553.19\n",
      " Regression with ARIMA(4,0,2) errors : -14568.72\n",
      " Regression with ARIMA(3,0,1) errors : -14400.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -14566.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11155.69\n",
      " Regression with ARIMA(1,0,0) errors : -14548.92\n",
      " Regression with ARIMA(0,0,1) errors : -12768.48\n",
      " Regression with ARIMA(0,0,0) errors : -9907.063\n",
      " Regression with ARIMA(2,0,0) errors : -14546.07\n",
      " Regression with ARIMA(1,0,1) errors : -14546.93\n",
      " Regression with ARIMA(2,0,1) errors : -14550.78\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -14554.96\n",
      " Regression with ARIMA(0,0,2) errors : -13588.57\n",
      " Regression with ARIMA(1,0,3) errors : -14555.05\n",
      " Regression with ARIMA(0,0,3) errors : -13929.67\n",
      " Regression with ARIMA(2,0,3) errors : -14552.73\n",
      " Regression with ARIMA(1,0,4) errors : -14561.38\n",
      " Regression with ARIMA(0,0,4) errors : -14217.43\n",
      " Regression with ARIMA(2,0,4) errors : -14559.98\n",
      " Regression with ARIMA(1,0,5) errors : -14560.36\n",
      " Regression with ARIMA(0,0,5) errors : -14327\n",
      " Regression with ARIMA(2,0,5) errors : -14558.11\n",
      " Regression with ARIMA(1,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,4) errors : -14560.62\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14379.34\n",
      " Regression with ARIMA(1,1,0) errors : -14383.72\n",
      " Regression with ARIMA(0,1,1) errors : -14382.54\n",
      " Regression with ARIMA(0,1,0) errors : -14381.35\n",
      " Regression with ARIMA(2,1,0) errors : -14382.72\n",
      " Regression with ARIMA(1,1,1) errors : -14384.5\n",
      " Regression with ARIMA(2,1,1) errors : -14382.23\n",
      " Regression with ARIMA(1,1,2) errors : -14382.66\n",
      " Regression with ARIMA(0,1,2) errors : -14382.21\n",
      " Regression with ARIMA(1,1,1) errors : -14386.51\n",
      " Regression with ARIMA(0,1,1) errors : -14384.55\n",
      " Regression with ARIMA(1,1,0) errors : -14385.73\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : -14384.54\n",
      " Regression with ARIMA(0,1,2) errors : -14384.22\n",
      " Regression with ARIMA(2,1,0) errors : -14384.73\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14397.22\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14483.22\n",
      " Regression with ARIMA(0,0,0) errors : -11017.35\n",
      " Regression with ARIMA(1,0,0) errors : -14460.22\n",
      " Regression with ARIMA(0,0,1) errors : -12640.36\n",
      " Regression with ARIMA(0,0,0) errors : -9780.733\n",
      " Regression with ARIMA(1,0,2) errors : -14467.99\n",
      " Regression with ARIMA(2,0,1) errors : -14461.13\n",
      " Regression with ARIMA(3,0,2) errors : -14483.56\n",
      " Regression with ARIMA(3,0,1) errors : -14483.17\n",
      " Regression with ARIMA(4,0,2) errors : -14480.81\n",
      " Regression with ARIMA(3,0,3) errors : -14482.96\n",
      " Regression with ARIMA(2,0,3) errors : -14464.37\n",
      " Regression with ARIMA(4,0,1) errors : -14477.63\n",
      " Regression with ARIMA(4,0,3) errors : -14478.99\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14477.22\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14498.8\n",
      " Regression with ARIMA(0,0,0) errors : -11029\n",
      " Regression with ARIMA(1,0,0) errors : -14478.15\n",
      " Regression with ARIMA(0,0,1) errors : -12661.86\n",
      " Regression with ARIMA(0,0,0) errors : -9798.577\n",
      " Regression with ARIMA(1,0,2) errors : -14485.32\n",
      " Regression with ARIMA(2,0,1) errors : -14479.56\n",
      " Regression with ARIMA(3,0,2) errors : -14498.67\n",
      " Regression with ARIMA(2,0,3) errors : -14482.25\n",
      " Regression with ARIMA(1,0,1) errors : -14476.18\n",
      " Regression with ARIMA(1,0,3) errors : -14486.49\n",
      " Regression with ARIMA(3,0,1) errors : -14499.33\n",
      " Regression with ARIMA(3,0,0) errors : -14485.04\n",
      " Regression with ARIMA(4,0,1) errors : -14493.81\n",
      " Regression with ARIMA(2,0,0) errors : -14475.19\n",
      " Regression with ARIMA(4,0,0) errors : -14489\n",
      " Regression with ARIMA(4,0,2) errors : -14497.35\n",
      " Regression with ARIMA(3,0,1) errors : -14328.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -14499.04\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14499.82\n",
      " Regression with ARIMA(0,0,0) errors : -11030.92\n",
      " Regression with ARIMA(1,0,0) errors : -14479.83\n",
      " Regression with ARIMA(0,0,1) errors : -12666.18\n",
      " Regression with ARIMA(0,0,0) errors : -9815.953\n",
      " Regression with ARIMA(1,0,2) errors : -14487.24\n",
      " Regression with ARIMA(2,0,1) errors : -14480.13\n",
      " Regression with ARIMA(3,0,2) errors : -14499.16\n",
      " Regression with ARIMA(2,0,3) errors : -14482.98\n",
      " Regression with ARIMA(1,0,1) errors : -14477.85\n",
      " Regression with ARIMA(1,0,3) errors : -14488.5\n",
      " Regression with ARIMA(3,0,1) errors : -14497.61\n",
      " Regression with ARIMA(3,0,3) errors : -14499.03\n",
      " Regression with ARIMA(2,0,2) errors : -14337.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14481.43\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14520.82\n",
      " Regression with ARIMA(0,0,0) errors : -11039.14\n",
      " Regression with ARIMA(1,0,0) errors : -14493.69\n",
      " Regression with ARIMA(0,0,1) errors : -12672\n",
      " Regression with ARIMA(0,0,0) errors : -9822.197\n",
      " Regression with ARIMA(1,0,2) errors : -14500.76\n",
      " Regression with ARIMA(2,0,1) errors : -14497.56\n",
      " Regression with ARIMA(3,0,2) errors : -14524.84\n",
      " Regression with ARIMA(3,0,1) errors : -14518.61\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -14524.22\n",
      " Regression with ARIMA(2,0,3) errors : -14520.02\n",
      " Regression with ARIMA(4,0,1) errors : -14521.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14510.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14421.28\n",
      " Regression with ARIMA(1,1,0) errors : -14438.68\n",
      " Regression with ARIMA(0,1,1) errors : -14424.25\n",
      " Regression with ARIMA(0,1,0) errors : -14423.29\n",
      " Regression with ARIMA(2,1,0) errors : -14439.8\n",
      " Regression with ARIMA(3,1,0) errors : -14439.79\n",
      " Regression with ARIMA(2,1,1) errors : -14444.89\n",
      " Regression with ARIMA(1,1,1) errors : -14446.77\n",
      " Regression with ARIMA(1,1,2) errors : -14444.79\n",
      " Regression with ARIMA(0,1,2) errors : -14423.33\n",
      " Regression with ARIMA(1,1,1) errors : -14448.78\n",
      " Regression with ARIMA(0,1,1) errors : -14426.26\n",
      " Regression with ARIMA(1,1,0) errors : -14440.69\n",
      " Regression with ARIMA(2,1,1) errors : -14446.9\n",
      " Regression with ARIMA(1,1,2) errors : -14446.8\n",
      " Regression with ARIMA(0,1,2) errors : -14425.34\n",
      " Regression with ARIMA(2,1,0) errors : -14441.81\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14440.01\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14553.28\n",
      " Regression with ARIMA(0,1,0) errors : -14483.96\n",
      " Regression with ARIMA(1,1,0) errors : -14484.77\n",
      " Regression with ARIMA(0,1,1) errors : -14485.54\n",
      " Regression with ARIMA(0,1,0) errors : -14485.96\n",
      " Regression with ARIMA(1,1,2) errors : -14488.25\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14562.68\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14567.68\n",
      " Regression with ARIMA(1,1,4) errors : -14484.21\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14585.28\n",
      " Regression with ARIMA(1,1,5) errors : -14492.24\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14586.81\n",
      " Regression with ARIMA(1,1,5) errors : -14494.25\n",
      " Regression with ARIMA(2,1,4) errors : -14569.27\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : -14485.81\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14504.5\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14595.43\n",
      " Regression with ARIMA(0,1,0) errors : -14527.09\n",
      " Regression with ARIMA(1,1,0) errors : -14529.37\n",
      " Regression with ARIMA(0,1,1) errors : -14529.7\n",
      " Regression with ARIMA(0,1,0) errors : -14529.09\n",
      " Regression with ARIMA(1,1,2) errors : -14533.99\n",
      " Regression with ARIMA(2,1,1) errors : -14543.6\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14601.94\n",
      " Regression with ARIMA(1,1,3) errors : -14532.49\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14605.78\n",
      " Regression with ARIMA(1,1,4) errors : -14530.67\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14537.39\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14607.58\n",
      " Regression with ARIMA(1,1,4) errors : -14532.67\n",
      " Regression with ARIMA(2,1,3) errors : -14603.75\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : -14534.49\n",
      " Regression with ARIMA(1,1,5) errors : -14539.39\n",
      " Regression with ARIMA(3,1,3) errors : -14598.8\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14549.06\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14516.87\n",
      " Regression with ARIMA(1,1,0) errors : -14525.36\n",
      " Regression with ARIMA(0,1,1) errors : -14520.46\n",
      " Regression with ARIMA(0,1,0) errors : -14518.88\n",
      " Regression with ARIMA(2,1,0) errors : -14523.87\n",
      " Regression with ARIMA(1,1,1) errors : -14523.58\n",
      " Regression with ARIMA(2,1,1) errors : -14528.44\n",
      " Regression with ARIMA(3,1,1) errors : -14605.73\n",
      " Regression with ARIMA(3,1,0) errors : -14522.73\n",
      " Regression with ARIMA(4,1,1) errors : -14552.02\n",
      " Regression with ARIMA(3,1,2) errors : -14601.37\n",
      " Regression with ARIMA(4,1,0) errors : -14523.8\n",
      " Regression with ARIMA(4,1,2) errors : -14570.42\n",
      " Regression with ARIMA(3,1,1) errors : -14607.28\n",
      " Regression with ARIMA(2,1,1) errors : -14530.46\n",
      " Regression with ARIMA(3,1,0) errors : -14524.74\n",
      " Regression with ARIMA(4,1,1) errors : -14553.78\n",
      " Regression with ARIMA(3,1,2) errors : -14602.92\n",
      " Regression with ARIMA(2,1,0) errors : -14525.88\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,0) errors : -14525.81\n",
      " Regression with ARIMA(4,1,2) errors : -14572.1\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14535.51\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11250.18\n",
      " Regression with ARIMA(1,0,0) errors : -14656.36\n",
      " Regression with ARIMA(0,0,1) errors : -12862.56\n",
      " Regression with ARIMA(0,0,0) errors : -10027.92\n",
      " Regression with ARIMA(2,0,0) errors : -14654.03\n",
      " Regression with ARIMA(1,0,1) errors : -14654.36\n",
      " Regression with ARIMA(2,0,1) errors : -14660.84\n",
      " Regression with ARIMA(3,0,1) errors : -14661.21\n",
      " Regression with ARIMA(3,0,0) errors : -14664.08\n",
      " Regression with ARIMA(4,0,0) errors : -14664.12\n",
      " Regression with ARIMA(5,0,0) errors : -14670.91\n",
      " Regression with ARIMA(5,0,1) errors : -14674.19\n",
      " Regression with ARIMA(4,0,1) errors : -14674.78\n",
      " Regression with ARIMA(4,0,2) errors : -14678.29\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : -14693.27\n",
      " Regression with ARIMA(5,0,3) errors : -14691.32\n",
      " Regression with ARIMA(4,0,3) errors : -14661.91\n",
      " Regression with ARIMA(5,0,2) errors : -14579.72\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -14701.58\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11249.56\n",
      " Regression with ARIMA(1,0,0) errors : -14656.24\n",
      " Regression with ARIMA(0,0,1) errors : -12864.81\n",
      " Regression with ARIMA(0,0,0) errors : -10027.74\n",
      " Regression with ARIMA(2,0,0) errors : -14657.78\n",
      " Regression with ARIMA(3,0,0) errors : -14666.92\n",
      " Regression with ARIMA(4,0,0) errors : -14666.09\n",
      " Regression with ARIMA(3,0,1) errors : -14664.16\n",
      " Regression with ARIMA(2,0,1) errors : -14658.57\n",
      " Regression with ARIMA(4,0,1) errors : -14666.46\n",
      " Regression with ARIMA(3,0,0) errors : -14546.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,0) errors : -14662.78\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m03.3 <- my.tsCV.2(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                      xreg.msize=hori,\n",
    "                      xreg=trainx[,2:4],\n",
    "                      sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfd95132-f6b6-449a-80b4-b9750616bde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-01-24\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m03.3\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53f2b51-a9df-4dbd-bdd6-d77af2fe524f",
   "metadata": {},
   "source": [
    "## Compare Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed9c467c-feac-4461-816b-ac6a0abcae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "my.figsize(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e499e5ce-1237-49e0-a787-a1be8de29cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94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\nQgAAgCkhBAAAmBJCAACAKSEEAACYCgs5jTZ7aestAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- new.get_result(result.m03.1, '1. ARIMA')\n",
    "errors.2 <- new.get_result(result.m03.2, '2. ARIMA Errors 2')\n",
    "n <- paste('3. ARIMA Errors (future regressor mean of', hori ,'days)', sep=' ')\n",
    "errors.3 <- new.get_result(result.m03.3, n)\n",
    "\n",
    "x <- rbind(errors.1, errors.2)\n",
    "x <- rbind(x, errors.3)\n",
    "\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b58831-3950-4988-b3bf-3f5313d409f9",
   "metadata": {},
   "source": [
    "### save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab39eccc-4453-4c0e-b430-b46b51c21e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- result.m03.1\n",
    "write.csv(x, file = \"arima_result_m0301.csv\")\n",
    "x <- result.m03.2\n",
    "write.csv(x, file = \"arima_result_m0302.csv\")\n",
    "x <- result.m03.3\n",
    "write.csv(x, file = \"arima_result_m0303.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c35829-53d8-47e0-b381-71b6dfd0d856",
   "metadata": {},
   "source": [
    "### load result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c522e476-b850-4a80-8d6f-4d52ec6b5ae5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.m03.1 <- read.csv(file = 'arima_result_m0301.csv')\n",
    "result.m03.2 <- read.csv(file = 'arima_result_m0302.csv')\n",
    "result.m03.3 <- read.csv(file = 'arima_result_m0303.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f0a8df7-b56a-46aa-9af5-d6702ae1057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m03 <- result.m03.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88acae2-994b-4716-b170-6ce34970d63e",
   "metadata": {},
   "source": [
    "# ARIMA+GARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748e4290-f9bd-441f-a136-17269a33122d",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f191fab1-f27c-4776-857e-0122f16923dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast <- function(x, h, \n",
    "                        mxreg=NULL, mxreg.msize=NULL, \n",
    "                        vxreg=NULL, vxreg.msize=NULL,\n",
    "                        order=NULL) {\n",
    "    forc <- ag2.forecast(x, h, \n",
    "                         mxreg=mxreg, mxreg.msize=mxreg.msize, \n",
    "                         vxreg=vxreg, vxreg.msize=vxreg.msize, \n",
    "                         out.sample=0, order=order)\n",
    "    if (!is.na(forc)) {\n",
    "        fc <- list(method = \"ARIMA+GARCH Forecasting\", mean=forc@forecast$seriesFor[,1],\n",
    "                   arima.order=forc@users$arima.order)\n",
    "        attr(fc$mean, \"names\") <- NULL\n",
    "        return(fc)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab8d0cf9-7d7d-4ee6-bc28-10f3982ef4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast.2 <- function(x, h, \n",
    "                          mxreg=NULL, mxreg.msize=NULL, \n",
    "                          vxreg=NULL, vxreg.msize=NULL, \n",
    "                          sample.n=0) \n",
    "{\n",
    "    result.rmse <- c()\n",
    "    result.mape <- c()\n",
    "    train.len <- length(x) - h\n",
    "    my.subset <- function(x, s, e) {\n",
    "        if (!is.null(x)) {\n",
    "            x <- subset(ts(x), start=s, end=e)\n",
    "        }\n",
    "        return(x)\n",
    "    }\n",
    "    idx <- 0:(h-1)\n",
    "    if ((sample.n>0) & (sample.n<h)) {\n",
    "        idx <- sort(sample(idx, sample.n))\n",
    "    }\n",
    "    \n",
    "    order <- NULL\n",
    "    for (i in seq_along(idx)) {\n",
    "        trlen <- train.len+idx[i]\n",
    "        x.train <- my.subset(x, 1, trlen)\n",
    "        mxreg.train <- my.subset(mxreg, 1, trlen)\n",
    "        vxreg.train <- my.subset(vxreg, 1, trlen)\n",
    "        \n",
    "        fc <- cv.forecast(x.train, 1, \n",
    "                          mxreg=mxreg.train, mxreg.msize=mxreg.msize, \n",
    "                          vxreg=vxreg.train, vxreg.msize=vxreg.msize, \n",
    "                          order=order)\n",
    "        if (i==1) { # reuse param for the rest of periods\n",
    "            order <- fc$arima.order\n",
    "        }\n",
    "        \n",
    "        result.rmse[i] <- sqrt(mean((fc$mean - x[trlen+1])^2))\n",
    "        result.mape[i] <- mean(abs(1 - fc$mean / x[trlen+1]))\n",
    "    }\n",
    "    e <- list(rmse.mean=mean(result.rmse), rmse.sigma=sd(result.rmse), \n",
    "              mape.mean=mean(result.mape), mape.sigma=sd(result.mape))\n",
    "    return(e)\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8dd1a8-1213-4b11-be11-ed86fa7e0ac2",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fc5c70c-df6f-49dd-b5a3-d09dcd858c0e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"10 % done.\"\n",
      "[1] \"20 % done.\"\n",
      "[1] \"30 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"40 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"50 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"60 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"70 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"80 % done.\"\n",
      "[1] \"90 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n"
     ]
    }
   ],
   "source": [
    "result.m04.1 <- my.tsCV.2(train, cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          silent=F,\n",
    "                          sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4916d16-6a26-4c9c-bb1b-30988b39aa2a",
   "metadata": {},
   "source": [
    "## Regressors for mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce4d19cd-012a-426c-bd7f-9d312c363316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"10 % done.\"\n",
      "[1] \"20 % done.\"\n",
      "[1] \"30 % done.\"\n",
      "[1] \"40 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"50 % done.\"\n",
      "[1] \"60 % done.\"\n",
      "[1] \"70 % done.\"\n",
      "[1] \"80 % done.\"\n",
      "[1] \"90 % done.\"\n"
     ]
    }
   ],
   "source": [
    "result.m04.2 <- my.tsCV.2(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          mxreg=trainx[,2:4], silent=F,\n",
    "                          sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b54ebef-c351-4357-8f97-9c524bd47711",
   "metadata": {},
   "source": [
    "## Regressors for variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "665586fb-e4bf-4356-86fb-2be0133969fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"10 % done.\"\n",
      "[1] \"20 % done.\"\n",
      "[1] \"30 % done.\"\n",
      "[1] \"40 % done.\"\n",
      "[1] \"50 % done.\"\n",
      "[1] \"60 % done.\"\n",
      "[1] \"70 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"80 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"90 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n"
     ]
    }
   ],
   "source": [
    "result.m04.3 <- my.tsCV.2(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          vxreg=trainx[,2:4], silent=F,\n",
    "                          sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26215cf2-deb9-45fa-be1f-ea72448a97b7",
   "metadata": {},
   "source": [
    "## Regressors for both of mean & variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "048f72f1-594f-416e-8dc4-a12ecb877efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"10 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"20 % done.\"\n",
      "[1] \"30 % done.\"\n",
      "[1] \"40 % done.\"\n",
      "[1] \"50 % done.\"\n",
      "[1] \"60 % done.\"\n",
      "[1] \"70 % done.\"\n",
      "[1] \"80 % done.\"\n",
      "[1] \"90 % done.\"\n"
     ]
    }
   ],
   "source": [
    "result.m04.4 <- my.tsCV.2(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          mxreg=trainx[,2:4], vxreg=trainx[,2:4], \n",
    "                          silent=F,\n",
    "                          sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4805d3a-1bc0-47e4-95f8-d358940ab858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-02-09\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m04.4\n",
    "from <- x[!is.na(x[,'forecast_start']),][,1][1]\n",
    "from <- index(trainx[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8c970c-798b-4d41-9930-01e336c80952",
   "metadata": {},
   "source": [
    "## Compare Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "624fa65b-7533-4f86-86de-0c335271b0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94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\n",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- new.get_result(result.m04.1, '1.AG')\n",
    "errors.2 <- new.get_result(result.m04.2, '2.AG with mxreg')\n",
    "errors.3 <- new.get_result(result.m04.3, '3.AG with vxreg')\n",
    "errors.4 <- new.get_result(result.m04.4, '4.AG with m&v xreg')\n",
    "\n",
    "x <- rbind(errors.1, errors.2)\n",
    "x <- rbind(x, errors.3)\n",
    "x <- rbind(x, errors.4)\n",
    "\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec0491-dff8-4c4b-8965-bcbfbecf1375",
   "metadata": {},
   "source": [
    "### save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4121890e-a78d-4c57-a282-e65c742ce8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- result.m04.1\n",
    "write.csv(x, file = \"agarch_result_m0401.csv\")\n",
    "x <- result.m04.2\n",
    "write.csv(x, file = \"agarch_result_m0402.csv\")\n",
    "x <- result.m04.3\n",
    "write.csv(x, file = \"agarch_result_m0403.csv\")\n",
    "x <- result.m04.4\n",
    "write.csv(x, file = \"agarch_result_m0404.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ddbbe0-2e37-4bbc-b30e-eb93048e1f1a",
   "metadata": {},
   "source": [
    "### load result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "199edcd6-5769-43b7-84e5-7169ce2ca863",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.m04.1 <- read.csv(file = 'agarch_result_m0401.csv')\n",
    "result.m04.2 <- read.csv(file = 'agarch_result_m0402.csv')\n",
    "result.m04.3 <- read.csv(file = 'agarch_result_m0403.csv')\n",
    "result.m04.4 <- read.csv(file = 'agarch_result_m0404.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ab8b4ec-19dc-42d8-bdcf-2c6d98936fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m04 <- result.m04.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b679ca19-bc28-4b63-a30c-4307392c4bca",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f404eb3-7cf4-4a6f-9bce-53f24d25335e",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95a2368e-5d93-401d-850b-5d8eb60df189",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26450ef3-ca0d-435c-b61b-67fabb48a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.eval <- function(\n",
    "    train.label, train.features, test.label, test.features,\n",
    "    nrounds = 1000, early_stopping_rounds = 3,\n",
    "    max_depth = 6, \n",
    "    eta = 0.3, # learning rate\n",
    "    # In linear regression task, this simply corresponds to minimum number of instances needed to be in each node. \n",
    "    # The larger min_child_weight is, the more conservative the algorithm will be. range: [0,?]\n",
    "    #min_child_weight = 1 ,\n",
    "    # Minimum loss reduction required to make a further partition on a leaf node of the tree. \n",
    "    # The larger gamma is, the more conservative the algorithm will be. range: [0,?]\n",
    "    #gamma = 0,\n",
    "    verbose=0,\n",
    "    sample.n=0\n",
    ") \n",
    "{\n",
    "    if (is.null(dim(test.features))) {\n",
    "        # conver to matrix for the case of 1 day prediction\n",
    "        test.features <- t(test.features)\n",
    "    }\n",
    "    model <- xgboost(data = train.features,\n",
    "                     label = train.label,\n",
    "                     nrounds = nrounds,\n",
    "                     objective = \"reg:squarederror\",\n",
    "                     early_stopping_rounds = early_stopping_rounds,\n",
    "                     max_depth = max_depth,\n",
    "                     eta = eta,\n",
    "                     verbose=verbose)\n",
    "\n",
    "    pred <- predict(model, test.features)\n",
    "    \n",
    "    h = length(pred)\n",
    "    idx = 1:h\n",
    "    if ((sample.n>0) & (sample.n<h)) {\n",
    "        idx <- sort(sample(idx, sample.n))\n",
    "    }\n",
    "        \n",
    "    # calc errors\n",
    "    rmse <- sqrt((pred[idx] - test.label[idx])^2)\n",
    "    mape <- abs(1 - pred[idx] / test.label[idx])\n",
    "    result <- list(rmse.mean=mean(rmse), rmse.sigma=sd(rmse), \n",
    "                   mape.mean=mean(mape), mape.sigma=sd(mape))\n",
    "    return(result)\n",
    "}\n",
    "\n",
    "\n",
    "xgb.gridsearch <- function(label, features, test.h, hyper_grid, verbose=1) {\n",
    "    len <- length(label)\n",
    "    idx.train <- 1:(len-test.h)\n",
    "    idx.test <- (len-test.h+1):(len)\n",
    "    train.label <- label[idx.train]\n",
    "    train.features <- features[idx.train,]\n",
    "    test.label <- label[idx.test]\n",
    "    test.features <- features[idx.test,]\n",
    "    \n",
    "    xgb_test_rmse <- NULL\n",
    "    xgb_test_mape <- NULL\n",
    "\n",
    "    for (j in 1:nrow(hyper_grid)) {\n",
    "        #set.seed(123)\n",
    "        \n",
    "        errors <- xgb.eval(train.label, train.features, test.label, test.features,\n",
    "                            nrounds = 1000, early_stopping_rounds = 3,\n",
    "                            max_depth = hyper_grid$max_depth[j], \n",
    "                            eta = hyper_grid$eta[j],\n",
    "                            verbose=0)\n",
    "        # calc errors\n",
    "        xgb_test_rmse[j] <- errors$rmse.mean\n",
    "        xgb_test_mape[j] <- errors$mape.mean\n",
    "    }\n",
    "\n",
    "    #ideal hyperparamters\n",
    "    r <- hyper_grid[which.min(xgb_test_rmse), ]\n",
    "    if (verbose>0) {\n",
    "        print(r)\n",
    "    }\n",
    "    return(r)\n",
    "}\n",
    "\n",
    "\n",
    "xgb.tsCV <- function (label, features, max_depth = 6, eta = .25,\n",
    "                      h = 1, window = NULL, initial = 0, step = 1, \n",
    "                      count.freq=0.1, ...) \n",
    "{\n",
    "    y <- as.ts(label)\n",
    "    n <- length(y)\n",
    "    step <- round(step)\n",
    "    step_ind <- seq(step, n - 1L, by = step)\n",
    "\n",
    "    if (initial >= n) \n",
    "        stop(\"initial period too long\")\n",
    "\n",
    "    xreg <- ts(as.matrix(features))\n",
    "    if (NROW(xreg) != length(y)) \n",
    "        stop(\"features must be of the same size as label\")\n",
    "    tsp(xreg) <- tsp(y)\n",
    " \n",
    "    if (is.null(window)) {\n",
    "        indx <- seq(1 + initial, n - 1L)\n",
    "    } else {\n",
    "        indx <- seq(window + initial, n - 1L, by = 1L)\n",
    "    }\n",
    "    indx <- intersect(indx, step_ind)\n",
    "\n",
    "    e.cols <- c('forecast_start', 'forecast_end', \n",
    "                'rmse.mean', 'rmse.sigma', 'mape.mean', 'mape.sigma')\n",
    "    e <- ts(matrix(NA_real_, nrow = floor(n/step), ncol = length(e.cols)))\n",
    "    colnames(e) <- e.cols\n",
    "    \n",
    "    ###\n",
    "    hyper_grid <- expand.grid(max_depth = max_depth, eta = eta)\n",
    "    if (nrow(hyper_grid)>1) {\n",
    "        hyper_grid.flag <- TRUE\n",
    "    } else {\n",
    "        hyper_grid.flag <- FALSE\n",
    "    }\n",
    "    \n",
    "\n",
    "    cnt <- 0\n",
    "    print.when <- seq(0, length(indx), by=round(count.freq*length(indx)))\n",
    "    for (i in indx) {\n",
    "        # get new start of subset of y & xreg\n",
    "        if (is.null(window)) {\n",
    "            start <- 1L\n",
    "        } else {\n",
    "            if (i - window >= 0L) {\n",
    "                start <- i - window + 1L\n",
    "            } else {\n",
    "                stop(\"small window\")\n",
    "            }\n",
    "        }\n",
    "        train.label <- subset(y, start=start, end = i)\n",
    "        train.features <- as.matrix(subset(xreg, start=start, end=i))\n",
    "        \n",
    "        # get test data\n",
    "        start <- i+1\n",
    "        end <- i+h\n",
    "        if (end <= nrow(xreg)) {\n",
    "            test.label <- subset(y, start=start, end=end)\n",
    "            test.features <- as.matrix(subset(xreg, start=start, end=end))\n",
    "        } else {\n",
    "            next\n",
    "        }\n",
    "        \n",
    "        # tune hyperparams\n",
    "        if (hyper_grid.flag) {\n",
    "            res <- xgb.gridsearch(train.label, train.features, h, hyper_grid)\n",
    "            max_depth.best <- res$max_depth\n",
    "            eta.best <- res$eta\n",
    "        } else {\n",
    "            max_depth.best <- max_depth\n",
    "            eta.best <- eta\n",
    "        }\n",
    "        \n",
    "        # train model\n",
    "        errors <- xgb.eval(train.label, train.features, test.label, test.features,\n",
    "                    nrounds = 1000, early_stopping_rounds = 3,\n",
    "                    max_depth = max_depth.best,\n",
    "                    eta = eta.best, ...)\n",
    "        # calc errors\n",
    "        e[i/step, ] <- c(start, end, errors$rmse.mean, errors$rmse.sigma, \n",
    "                                     errors$mape.mean, errors$mape.sigma)\n",
    "\n",
    "        cnt <- cnt + 1\n",
    "        if (cnt %in% print.when) {\n",
    "            print(sprintf(\"%0.0f %% done.\", 100*cnt/length(indx)))\n",
    "        }\n",
    "    }\n",
    "    #return(na.omit(e)) # times of NA kept in e as attr(na.action)\n",
    "    return(e)\n",
    "}\n",
    "\n",
    "\n",
    "xgb.tsCV.mean <- function(label, features, cols=c(1,2,3,5), ...) {\n",
    "    e <- xgb.tsCV(label, features, ...)\n",
    "    result <- e[,cols]\n",
    "    colnames(result) <- c('forecast_start', 'forecast_end', 'rmse', 'mape')\n",
    "    return(result)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9ef27a-3429-4873-81bd-39c5a8842043",
   "metadata": {},
   "source": [
    "### set label & features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41c44a85-e47f-47bb-b011-36242e342e1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             logret_fwd     logret      rsi    bbands        macd\n",
       "1991-02-19 -0.003987479 0.10602550 72.59254 0.8419486 -0.03641515\n",
       "1991-02-20  0.003935860 0.09798126 66.25313 0.7706927 -0.18551057\n",
       "1991-02-21  0.006853764 0.10585688 66.00481 0.7330987 -0.30953562\n",
       "1991-02-22  0.011366830 0.10194779 66.54491 0.7402938 -0.39546732\n",
       "1991-02-25  0.024316594 0.09259647 67.84742 0.7305630 -0.43573971\n",
       "1991-02-26  0.033979664 0.07655978 60.80133 0.6379610 -0.55105032"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "            logret_fwd       logret      rsi    bbands       macd\n",
       "1991-03-20 0.043297723 -0.003987479 52.32729 0.2955472 -0.5878001\n",
       "1991-03-21 0.038451421  0.003935860 50.29479 0.3135024 -0.6182388\n",
       "1991-03-22 0.038123240  0.006853764 51.65309 0.2490278 -0.6049896\n",
       "1991-03-25 0.034364782  0.011366830 55.10298 0.4057512 -0.5386086\n",
       "1991-03-26 0.007808953  0.024316594 62.94322 0.6945332 -0.3702197\n",
       "1991-03-27 0.009730005  0.033979664 61.25189 0.8281562 -0.2741769"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.ml <- merge(lag.xts(trainx$y, -lookahead), trainx, join='left', fill=NA)\n",
    "colnames(train.ml) <- c('logret_fwd', 'logret', 'rsi','bbands','macd')\n",
    "train.ml <- na.omit(train.ml)\n",
    "\n",
    "x <- head(train.ml, lookahead+6)\n",
    "head(x)\n",
    "tail(x)\n",
    "#tail(train.ml)\n",
    "\n",
    "idx.label <- 1\n",
    "idx.feautres <- 2:5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5a72f7-a53b-4172-9753-65db6e1810b9",
   "metadata": {},
   "source": [
    "## Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df96df9e-dc59-4ec1-89d5-b364e10ca18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"10 % done.\"\n",
      "[1] \"20 % done.\"\n",
      "[1] \"30 % done.\"\n",
      "[1] \"40 % done.\"\n",
      "[1] \"50 % done.\"\n",
      "[1] \"61 % done.\"\n",
      "[1] \"71 % done.\"\n",
      "[1] \"81 % done.\"\n",
      "[1] \"91 % done.\"\n"
     ]
    }
   ],
   "source": [
    "result.m05.1 <- xgb.tsCV(train.ml[,idx.label], train.ml[,idx.feautres], \n",
    "                         h=hori, window=wind, step=peri,\n",
    "                         sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc486be0-bde8-476d-9bdb-aaddc7d822d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-02-09\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m05.1\n",
    "from <- x[!is.na(x[,'forecast_start']),][,1][1]\n",
    "from <- index(trainx[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf56a93b-2659-491f-aeb0-639ca5afcc61",
   "metadata": {},
   "source": [
    "## Tuning params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a5f7df4-0ca0-4beb-9270-5d8804fe7460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "12"
      ],
      "text/latex": [
       "12"
      ],
      "text/markdown": [
       "12"
      ],
      "text/plain": [
       "[1] 12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_depth <- seq(5, 7, 1)\n",
    "eta <- seq(.1, .4, .1)\n",
    "x <- expand.grid(max_depth = max_depth, eta = eta)\n",
    "nrow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abe039a1-18cb-4a44-9909-88f34afdb9c4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   max_depth eta\n",
      "10         5 0.4\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "   max_depth eta\n",
      "10         5 0.4\n",
      "  max_depth eta\n",
      "6         7 0.2\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "  max_depth eta\n",
      "8         6 0.3\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "  max_depth eta\n",
      "2         6 0.1\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "  max_depth eta\n",
      "6         7 0.2\n",
      "  max_depth eta\n",
      "2         6 0.1\n",
      "  max_depth eta\n",
      "8         6 0.3\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "  max_depth eta\n",
      "8         6 0.3\n",
      "  max_depth eta\n",
      "8         6 0.3\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "  max_depth eta\n",
      "6         7 0.2\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "  max_depth eta\n",
      "1         5 0.1\n",
      "[1] \"10 % done.\"\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "  max_depth eta\n",
      "4         5 0.2\n",
      "  max_depth eta\n",
      "7         5 0.3\n",
      "  max_depth eta\n",
      "8         6 0.3\n",
      "  max_depth eta\n",
      "9         7 0.3\n",
      "  max_depth eta\n",
      "8         6 0.3\n",
      "  max_depth eta\n",
      "6         7 0.2\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "  max_depth eta\n",
      "1         5 0.1\n",
      "  max_depth eta\n",
      "7         5 0.3\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "  max_depth eta\n",
      "2         6 0.1\n",
      "  max_depth eta\n",
      "8         6 0.3\n",
      "  max_depth eta\n",
      "4         5 0.2\n",
      "  max_depth eta\n",
      "9         7 0.3\n",
      "   max_depth eta\n",
      "10         5 0.4\n",
      "  max_depth eta\n",
      "6         7 0.2\n",
      "   max_depth eta\n",
      "10         5 0.4\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "   max_depth eta\n",
      "10         5 0.4\n",
      "[1] \"20 % done.\"\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "  max_depth eta\n",
      "2         6 0.1\n",
      "  max_depth eta\n",
      "7         5 0.3\n",
      "  max_depth eta\n",
      "9         7 0.3\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "  max_depth eta\n",
      "4         5 0.2\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "  max_depth eta\n",
      "1         5 0.1\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "  max_depth eta\n",
      "9         7 0.3\n",
      "   max_depth eta\n",
      "10         5 0.4\n",
      "   max_depth eta\n",
      "10         5 0.4\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "  max_depth eta\n",
      "2         6 0.1\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "  max_depth eta\n",
      "4         5 0.2\n",
      "  max_depth eta\n",
      "1         5 0.1\n",
      "   max_depth eta\n",
      "10         5 0.4\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "  max_depth eta\n",
      "8         6 0.3\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "   max_depth eta\n",
      "10         5 0.4\n",
      "  max_depth eta\n",
      "1         5 0.1\n",
      "[1] \"30 % done.\"\n",
      "  max_depth eta\n",
      "6         7 0.2\n",
      "  max_depth eta\n",
      "9         7 0.3\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "  max_depth eta\n",
      "4         5 0.2\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "  max_depth eta\n",
      "7         5 0.3\n",
      "  max_depth eta\n",
      "6         7 0.2\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "  max_depth eta\n",
      "8         6 0.3\n",
      "  max_depth eta\n",
      "7         5 0.3\n",
      "  max_depth eta\n",
      "6         7 0.2\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "  max_depth eta\n",
      "9         7 0.3\n",
      "  max_depth eta\n",
      "1         5 0.1\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "  max_depth eta\n",
      "8         6 0.3\n",
      "  max_depth eta\n",
      "9         7 0.3\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "  max_depth eta\n",
      "7         5 0.3\n",
      "[1] \"40 % done.\"\n",
      "  max_depth eta\n",
      "2         6 0.1\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "  max_depth eta\n",
      "1         5 0.1\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "  max_depth eta\n",
      "6         7 0.2\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "  max_depth eta\n",
      "4         5 0.2\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "  max_depth eta\n",
      "1         5 0.1\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "  max_depth eta\n",
      "2         6 0.1\n",
      "  max_depth eta\n",
      "4         5 0.2\n",
      "  max_depth eta\n",
      "1         5 0.1\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "  max_depth eta\n",
      "8         6 0.3\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "  max_depth eta\n",
      "9         7 0.3\n",
      "  max_depth eta\n",
      "8         6 0.3\n",
      "  max_depth eta\n",
      "6         7 0.2\n",
      "[1] \"50 % done.\"\n",
      "  max_depth eta\n",
      "2         6 0.1\n",
      "   max_depth eta\n",
      "10         5 0.4\n",
      "   max_depth eta\n",
      "10         5 0.4\n",
      "  max_depth eta\n",
      "7         5 0.3\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "  max_depth eta\n",
      "8         6 0.3\n",
      "  max_depth eta\n",
      "6         7 0.2\n",
      "  max_depth eta\n",
      "7         5 0.3\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "  max_depth eta\n",
      "9         7 0.3\n",
      "  max_depth eta\n",
      "2         6 0.1\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "  max_depth eta\n",
      "7         5 0.3\n",
      "  max_depth eta\n",
      "6         7 0.2\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "  max_depth eta\n",
      "1         5 0.1\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "  max_depth eta\n",
      "7         5 0.3\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "[1] \"61 % done.\"\n",
      "  max_depth eta\n",
      "2         6 0.1\n",
      "  max_depth eta\n",
      "6         7 0.2\n",
      "  max_depth eta\n",
      "1         5 0.1\n",
      "  max_depth eta\n",
      "7         5 0.3\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "   max_depth eta\n",
      "10         5 0.4\n",
      "  max_depth eta\n",
      "1         5 0.1\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "  max_depth eta\n",
      "7         5 0.3\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "  max_depth eta\n",
      "9         7 0.3\n",
      "  max_depth eta\n",
      "2         6 0.1\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "  max_depth eta\n",
      "2         6 0.1\n",
      "[1] \"71 % done.\"\n",
      "  max_depth eta\n",
      "9         7 0.3\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "  max_depth eta\n",
      "8         6 0.3\n",
      "  max_depth eta\n",
      "7         5 0.3\n",
      "  max_depth eta\n",
      "1         5 0.1\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "  max_depth eta\n",
      "8         6 0.3\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "  max_depth eta\n",
      "9         7 0.3\n",
      "  max_depth eta\n",
      "2         6 0.1\n",
      "  max_depth eta\n",
      "9         7 0.3\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "  max_depth eta\n",
      "7         5 0.3\n",
      "  max_depth eta\n",
      "6         7 0.2\n",
      "  max_depth eta\n",
      "6         7 0.2\n",
      "   max_depth eta\n",
      "10         5 0.4\n",
      "  max_depth eta\n",
      "4         5 0.2\n",
      "  max_depth eta\n",
      "2         6 0.1\n",
      "  max_depth eta\n",
      "4         5 0.2\n",
      "[1] \"81 % done.\"\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "   max_depth eta\n",
      "10         5 0.4\n",
      "   max_depth eta\n",
      "10         5 0.4\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "  max_depth eta\n",
      "7         5 0.3\n",
      "  max_depth eta\n",
      "6         7 0.2\n",
      "  max_depth eta\n",
      "1         5 0.1\n",
      "  max_depth eta\n",
      "2         6 0.1\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "  max_depth eta\n",
      "7         5 0.3\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "  max_depth eta\n",
      "4         5 0.2\n",
      "  max_depth eta\n",
      "8         6 0.3\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "  max_depth eta\n",
      "2         6 0.1\n",
      "  max_depth eta\n",
      "2         6 0.1\n",
      "  max_depth eta\n",
      "9         7 0.3\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "  max_depth eta\n",
      "8         6 0.3\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "  max_depth eta\n",
      "9         7 0.3\n",
      "[1] \"91 % done.\"\n",
      "  max_depth eta\n",
      "4         5 0.2\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "  max_depth eta\n",
      "7         5 0.3\n",
      "  max_depth eta\n",
      "8         6 0.3\n",
      "  max_depth eta\n",
      "8         6 0.3\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "  max_depth eta\n",
      "3         7 0.1\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "  max_depth eta\n",
      "7         5 0.3\n",
      "  max_depth eta\n",
      "4         5 0.2\n",
      "  max_depth eta\n",
      "1         5 0.1\n",
      "  max_depth eta\n",
      "4         5 0.2\n",
      "   max_depth eta\n",
      "11         6 0.4\n",
      "  max_depth eta\n",
      "1         5 0.1\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "  max_depth eta\n",
      "5         6 0.2\n",
      "   max_depth eta\n",
      "12         7 0.4\n",
      "   max_depth eta\n",
      "12         7 0.4\n"
     ]
    }
   ],
   "source": [
    "result.m05.2 <- xgb.tsCV(train.ml[,idx.label], train.ml[,idx.feautres], \n",
    "                         h=hori, window=wind, step=peri,\n",
    "                         max_depth = max_depth, eta = eta,\n",
    "                         sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dc8e1c-2053-444f-84cb-5bd9132cecf3",
   "metadata": {},
   "source": [
    "## Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "82ffd869-5005-4fdb-8977-7712eac50d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my.figsize(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12fa005b-99d2-4390-8adc-0eaf9f019ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94\nAAAgAElEQVR4nOzdeXhMd///8fds2fdERCQidmJfg6LU1liKUltLLW350VZrr7WWb2u5K6po\n1V4tequqXZW60VI7tZVYsxFBElllMvP7Y9ppBDGJjJGc5+O6r/vKfLZ5H42JV845n6MyGo0C\nAAAAAFAeta0LAAAAAADYBoEQAAAAABSKQAgAAAAACkUgBAAAAACFIhACAAAAgEIRCAEAAABA\noQiEAAAAAKBQBEIAAAAAUCitrQuwrnv37un1eltXAViXq6uriNy7d8/WhQBAgdFqtc7OzhkZ\nGenp6bauBbAuT09PW5cARSvigdBgMGRlZdm6CsC6VCqVSqXiWx1AUaJWq9VqtYjw4QYAVsUl\nowAAAACgUARCAAAAAFAoAiEAAAAAKBSBEAAAAAAUikAIAAAAAApFIAQAAAAAhSIQAgAAAIBC\nEQgBAAAAQKEIhAAAAACgUARCAAAAAFAoAiEAAAAAKBSBEAAAAAAUikAIAAAAAApFIAQAAAAA\nhSIQAgAAAIBCaa26enJy8qJFiw4fPqzX66tWrTp48GBfX98cYyIjI5ctW3b+/HmDwRAcHNy3\nb99KlSrlMteSNQEAAAAAT2TdM4Th4eHXr1+fOnXqnDlzNBrNlClTDAZD9gGZmZnjx493dXWd\nNWvWnDlzihcvPnny5LS0tFzmPnFNAAAAAIAlrBgI4+PjDx069N5775UrVy4gIGDYsGHR0dEn\nT57MPiY1NbVTp06DBg0qWbJkiRIlunXrlpqaeuPGjcfNtWRNAAAAAIAlrBgIL168aGdnFxwc\nbHrp4uISGBh48eLF7GPc3d07d+7s6OgoIvfu3du4cWNAQEBAQMDj5lqyJgAAAADAEla8hzAp\nKcnV1VWlUplb3N3dExMTHx5pMBi6du2q1+tDQkKmTZum0+keN9fd3T33NQ8ePPjJJ5+YX378\n8cfVqlUr4AMDnjMajUZEPD09bV0IABQY0896BwcHOzs7W9cCAEWZde8hzJ7cRMRoND66CLV6\n7ty506dPd3FxGTduXEpKSi5zLVwTAAAAAJA7K54h9PDwSEpKMhqN5giXmJj4uJMYgYGBgYGB\nVapU6dOnz549e3x8fB4594lrhoaG/vTTT+aXiYmJd+/etcrhAc8NT09PlUrFtzqAokSn07m7\nu6enp5t+TQwUYT4+PrYuAYpmxTOEFSpUyMzMjIiIML1MTEyMjIw0PVLC7OTJk2+//XZ6evrf\n1ajVKpXKaDQ+bq4lawIAAAAALKGZPHmylZZ2dHSMjIz85Zdfypcvn5KSMn/+fFdX1969e6tU\nqp07d549e7ZixYqurq4bN268fPlyUFBQWlramjVr/vrrr/79+/v6+j5ybi5rPrKGjIwMHkqB\nIs/R0VGlUpme1wIARYNGo3FwcNDr9ZmZmbauBbAuJycnW5cARVNZ9R681NTUr7/++sCBAwaD\noVatWoMGDTJd3jlr1qykpKSpU6eKyLVr11asWPHXX39lZWUFBQX17t27evXqucx9XPsjJSYm\n8oMERZ7pktE7d+7YuhAAKBg3b97cvHlzbGysp6dns2bNqlatauuKACviklHYlnUDoc0RCKEE\nBEIARcm5c+fGjBmTkZFhbhk4cGDXrl1tWBJgVQRC2JZ1dxkFAACwnMFgmDlzZvY0KCIrVqyI\nioqyVUkAULQRCAEAwPMiNjY2NjY2R2NmZuaxY8dsUg8AFHkEQgAA8Lx43I0eWVlZz7gSAFAI\nAiEAAHhelCxZ0tXV9eF2HjEFAFZCIAQAAM8LnU43ZMiQHI1t2rSpXLmyTeoBgCJPa+sCAAAA\n/vXiiy+6urquW7fu+vXrPj4+LVq0aN++va2LAoAii8dOAIUej50AUPTodDp3d/e0tLSUlBRb\n1wJYF4+dgG1xySgAAAAAKBSBEAAAAAAUikAIAAAAAApFIAQAAAAAhSIQAgAAAIBCEQgBAAAA\nQKEIhAAAAACgUARCAAAAAFAoAiEAAAAAKBSBEAAAAAAUikAIAAAAAApFIAQAAAAAhSIQAgAA\nAIBCEQgBAAAAQKEIhAAAAACgUARCAAAAAFAoAiEAAAAAKBSBEAAAAAAUikAIAAAAAApFIAQA\nAAAAhSIQAgAAAIBCEQgBAAAAQKG0ti4AAAAgp/v370dHR+t0OrWaX14DgBXxIQsUbmfOnFm2\nbNmyZcv+/PNPW9cCAAXm7Nmzr7zyyurVq21dCAAUcZwhBAoro9E4Z86cn3/+2dzy0ksvjRgx\nQqVS2bAqAAAAFCKcIQQKq59//jl7GhSRXbt2bdq0yVb1AAAAoNAhEAKF1Z49ex5u/PXXX595\nIQAAACisCIRAYZWcnPxwY2pq6rOvBAAAAIUUgRAorEqVKmVhIwAAAPBIBEKgsOrVq5ejo2P2\nFgcHh9dff91W9QAAAKDQIRAChVXJkiWnT59esWJFlUqlUqnKly8/bdq0oKAgW9cFAACAQoPH\nTgCFWJUqVebOnWtvb69SqdLT021dDgAAAAoZAiFQ6Dk5OREIAQAAkA9cMgoAAAAACkUgBAAA\nAACFIhACAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgA\nAAAACkUgBAAAAACFIhACAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQ\nAAAAABRKa+sCrMvOzs7Ozs7WVQDWpVarRcTZ2dnWhQBAgTH9+Far1Xy4AYBVFfFAaDAYDAaD\nrasArMtoNKpUKr1eb+tCAKDAmH58G41GPtwAwKqKeCDU6/WZmZm2rgKwLicnJxHJyMiwdSEA\nUGBMOdBoNPLhhiLP1dXV1iVA0biHEAAAAAAUqoifIQSUIDk5WaVS2boKAAAAFD6cIQQKvTfe\neKNr1662rgIAAACFD4EQAAAAABSKQAgAAAAACkUgBAAAAACFIhACAAAAgEIRCAEAAABAoQiE\nAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAACkUgBAAAAACFIhACAAAAgEIR\nCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAACkUgBAAAAACF\nIhACAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAA\nCkUgBAAAAACFIhACAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAA\nABSKQAgAAAAACkUgBAAAAACFIhACAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAA\nAAAoFIEQAAAAABSKQAgAAAAACkUgBAAAAACFIhACAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIA\nAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAACkUgBAAAAACFIhACAAAAgEIRCAEAAABAobRW\nXT05OXnRokWHDx/W6/VVq1YdPHiwr6/vw8Oio6PnzJkTERGxYcOGJ861cE0AAAAAQO6se4Yw\nPDz8+vXrU6dOnTNnjkajmTJlisFgyDFm3759H330UUBAgIVzLVkTAAAAAPBEVgyE8fHxhw4d\neu+998qVKxcQEDBs2LDo6OiTJ0/mGJaZmTl79uzQ0FBL5lq4JgAAAADgiax4yejFixft7OyC\ng4NNL11cXAIDAy9evFirVq3sw1q0aCEily5dsmRuenp67mvq9frU1FTzOgaDQaVSWef4gOcL\n3+oAihLzZxofbgBgVVYMhElJSa6urtk/x93d3RMTE59mrru7e+5r7tu3b+TIkeaXCxYsqF+/\n/lMdBlBIeHt727oEACgwTk5OIqLVavlwAwCrsu6mMjl+q2c0Gp9+bu5r+vr6tmzZ0vzSzc0t\nIyPD8jcFCi++1QEUJXq9XkSMRiMfbijy7O3tbV0CFM2KgdDDwyMpKcloNJojXGJioqen59PM\nfeKaISEhn376qfllYmLivXv3CuZ4gOcb3+oAihJTDszKyuLDDUUegRC2ZcVNZSpUqJCZmRkR\nEWF6mZiYGBkZWalSpaeZ+zRrAgAAAACys2Ig9PT0bNy48bx58yIiIiIjIz/77LNy5cqFhISI\nyM6dOzdt2mQadvfu3fj4eNPv/+Lj4+Pj49PT0x83N5c1AQAAAAB5Yt17CIcOHfr111+PHz/e\nYDDUqlVr2LBhpks9T5w4kZSU1KFDBxEZOXJkXFycaXz//v1FZODAgR07dnzc3Me1AwAAAADy\nRJWnjV4KncTExMzMTFtXAVhX//7909PTv/vuO1sXAgAF5syZM8OHD3/jjTd69+5t61oA6/Lx\n8bF1CVA0K14yCgAAAAB4nhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAA\nFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAA\nACgUgRAAAAAAFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAA\nAABQKAIhAAAAACgUgRAAAAAAFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQA\nAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAAFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEI\nAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAAFIpACAAAAAAKRSAEAAAAAIUi\nEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAAFIpACAAAAAAK\nRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAA\nFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAA\nACgUgRAAAAAAFEpr6wKsy8HBwcHBwdZVAM+Cq6urrUsAgAJjb28vIhqNhg83ALCqIh4I79+/\nn5WVZesqgGchLS3N1iUAQIHJzMwUkaysLD7cUOSZfv0B2EoRD4QGg0Gv19u6CuBZ4FsdQFFi\nMBhMX/DhBgBWxT2EAAAAAKBQBEIAAAAAUKgifskoAEAhEhISzpw5Y77OEIVdZGSkiFy7dm3f\nvn22rgUFplSpUkFBQbauAsADCIQAgKJg3rx5v/32m62rQAHbu3fv3r17bV0FCoyjo+P69etV\nKpWtCwHwLwIhAKAoSE1NFZGYNmFGLT/agOdRsd/3y907RqORQAg8V/ipCQAoOm42fdHABu7A\nc8n99J92d+/YugoAObGpDAAAAAAoFIEQAAAAABSKQAgAAAAACkUgBAAAAACFIhACAAAAgEIR\nCAEAAABAoXjshOJcuHBh+PDhmZmZti4EBaxt27a2LgEFRqfTffrppyEhIbYuBAAAFHEEQsWJ\njo7OzMz0tbfzsrezdS0AHiHhfuaN9IzIyEgCIQAAsDYCoUL1CirZLbCErasA8AibYm5+eu6S\nrasAAACKwD2EAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAACkUgBAAAAACF\nIhACAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAAABRKa+sCAABA\nEXL5kiz+Sv48JZmZElxWXn9DGjd52sHRUTKgr9g7yE9bLJ37x0H57hu58JeISMVKMvAdqVqt\noA4RAIoSzhACAIACEhUl7w2RyOsy8B0ZPkpcnGXCR7J/31MNNhpl9gzJyMjD3D27ZexISU6W\nQUNk0BBJSpIP35O/zhf00QJAUcAZQgAAUEBWLJUsvYTPF29vEZGXWsnb/WXBPGn8gqhU+Ry8\nZZOcPSN16srFi5bOXbRQvH1k/lfi4CAi0qqNvNFDFi2U/8y15sEDQKHEGUIAAFAQDAb5fb+E\nNvo7pImIWi1twyQ2Ri5F5HPw7Xj5coH07iPF/Syde/eOxMZK4xf+ToMi4uQkrdvK8eNyL6mg\njxkACj0CIQAAKAixMZKaKuXKPdBYvoKIPCIQWjh4zn/E11d6vZ6HuXq9iIid3QO9vsXFaJAr\nV/J0QACgBFwyCgAACsLt2yIinl4PNHp4/NuV18F7dsvvv8mCL0WrzcNcbx9xdpGTJx7oPX9O\nRCQxwfKjAQCF4AwhAAAoCPfvi4hodQ80ms7UmbryNPheksydI692lUpV8jZXrZYOr8iFvyT8\nPxITLXFxsnypHD4kIn+fPAQAZMMZQsBmTt+6PXHv779HxWZkZVUt5j0qtG6H8mXyN3jPtagZ\nB4+ciovXG7LKe3kOqV2jR0hF854M685fnH/05F+37943ZJV2d3u9auXBtavbazSW9AKApUyR\nLPPB7GcKb/b2eR78xefi4CAD3s7PGw0YKPeSZONP8tOPIiJ168vAt2XWp+LomNdjAoAij0AI\n2EbE3YSXvltXzMnp46YN3ezsVp0599qPW9Z2btfxUZkw98FbIq50+3FLDV+f8Y3ra1Sqtecu\n9Nvy85XEpI8a1RORuYePj/51f88qFcc1rm+n1vx6LXLsr/v/iI5d3Snsib0AkAc+PiIid+48\n0Gi6vNPUZfngI4dk5w6Z9okYjZKWJiKSlSUikpYmGs2T30irkxGj5a1BEhsj3t5SzFfW/1dE\npIT/Ux4iABQ9BELANqb/dkhvMP7Ss4ufi7OIvFalQsMVa0b/ur9D+TIPbc3+hMET9x4Icnfb\n3buro1YrIv1qhNRZ+t3cw8fGNqqnElly8kywh/vS9q1NyzYtVfJM/O0fL1y6m57h6WCfe++z\n++MAUASUKCGurnLhwcf9nTsrIlKhYt4Gb1gvRqOMG5NzVlgrCW0k//epRW/k7i7u7n9/feyY\nuLlLYKm8HxUAFHEEQsAGsozGzRFXXi5b2hTwRESjUr1RtfLI3ftOxd2q4VvM8sHVivn0qxFS\n2t3N8Z9NF3RqdQN/v29On0vNzHTW6Ry0Gk3WA8//crbTaVQq00WhufcCQB6o1NL0Rfl5u9yI\nFb8SIiL378vWzVKmrASVztvg13pIi5YPjF+9Sk6dkk9mipvbk99o5idy8oQsXyU6nYjIpQg5\n8Jt0flXUbJ0AADnxyQjYwNWEpHv371fzfeAaqprFi4nIn3HxeRqsVqmG1qnRvlywucsocjb+\ndoCri7NOJyLD6tU6d/vOJwcOx6WkJmbc33Dh0oa/Lg2qXd1Jp31iLwDkTZ9+4uQkH7wn676X\nzRvl/aFy84YMff/v3t/3y0tN/756M/fBJfylWvUH/ufpJRqNVKv+d+TL/Y2aNJPYGBnxgWzf\nKmtXy4hhUry49Hnzmf5RAEAhwb/5ABu4kZIiIsWdnLI3FnNyFJHY5NT8Dc7IyopLSY1JTvny\n2Kk/b91e0aGNqb1XSCU7jWbQ9l0f7zsoImqVanRo3YlNQi3pBYC88fWVeQvlywWybIlkZUmF\nCjJrjtSq/XevwSgGgxiMFg1+mjdq2EgmTJbvVkn4f8TBQRqEytv/T9zcc10RABSKQAjYQLo+\nS0TsNA+cojddpZmRlXNXdAsH/xYVE7Z2g4iUcnNd0yksrGxpU/v+yOjB23c3DSw5oEZVR512\n+6WrMw8esdNqxjas98ReAMizwFIy/dNHd73QRH7db+ngHEaOkZEP3lKY+9zmL0nzlyxaGQCU\njUAI2ICD1hTnsrI3pmdliYiDNuffSgsH1/D1+aFL+/i0tF1XI7uu3zyiQZ0pTRsajMa3tu0q\n5+m+rkt7tUolIi2CAvUG49T9f3SrVL6Mh3suveU8Paxx7AAAAHh+cA8hYAMlXJxF5EbKA1eH\n3khOEZGSLi75G+zt6NiuXHDfalVWdmjzQf1aMw8eORJ781pi0pWExFbBQepsG8e0KB1oMBr/\niLmRe29BHSwAAACeWwRCwAZKu7t5OtgfvxGXvfFw7E0RqeVXLE+Db6WmfX3itOmlWaOS/iJy\n+tZt04nE+w+eXcz4pzH33qc5QAAAABQKBELABtQqVacK5XZcvnYtMcnUkq7PWn7qbLViPpW8\nvfI02E6j+fCX/43d85vBaDRP+fVapIiUcnct5+nhbm+388r17L27r0aKSB2/4rn3WuXIAQAA\n8Dyx6B7C5OTkbdu27dix4/jx47du3UpISPDw8ChWrFjNmjXbtm378ssvuzx0kRuA3I1rXH/j\nxcut1/w4tE4NZ51u2akz15PubXntFVPv5ogr3X/cMrNFkyF1auQ+2N3eblRo3em/H2q5en2X\niuXsNZr9kdHfn7vQwN/vxVIBapVq4guhw3ftfWXdxn7VQ5x02l+uXF9+6ky3SuWr+/qISO69\nAAAAKNqeEAjT09PnzZs3c+bM+Ph4Ozu7ihUrli9f3sPDIyEh4datW6tWrVq6dKmPj8/o0aOH\nDh3q4ODwbIoGioAAV5dfe7/60Z7fpu7/Q2801Czuu+W1V5qVCjD1GozGLKPRfOIu98ETXmhQ\nztPjy+On/u+3Q/cNWUFubhObhL5bp6bpzsAhdWoUd3aad+TEwK079QZjsIfbxCahH9b/e3P2\n3HsBAABQtOUWCK9cudKlS5dTp05169atb9++zZo1c3rwSWgpKSn/+9//VqxYMXr06O++++6H\nH34IDg5+3GoAcqjg5bmuS/tHdnUsXyZ91LsWDhaRniEVe4ZUfFxv10rlu1Yqn79eAAAAFGG5\nBcI6derUrFnz9OnTlStXfuQAZ2fnsLCwsLCwc+fODRkypE6dOnfu3LFOnQAAAACAApbbpjJD\nhgzZuXPn49JgdpUrV965c+f/+3//r+AKAwAAAABYV25nCKdOnZr9ZVpa2tGjR6Ojo1966SUf\nHx+9Xq/N9lBsjUYzbdo0a5UJAAAAACholj52YtasWX5+fk2aNOnRo0dERISITJo0qX///lk8\nrAwAAAAACieLAuHixYtHjRr14osvfvnll+bGihUrfvPNN7NmzbJabQAAAAAAK7IoEH7xxReD\nBg366aef+vbta27s06fPyJEjv/nmG6vVBgAAAACwIosC4fnz51999dWH25s1a3blypWCLgkA\nAAAA8CxYFAh1Ol1aWtrD7Tdv3tTpdAVdEgAAAADgWbAoENavXz88PDwjIyN7Y0JCwqxZs0JD\nQ61TGAAAAADAunJ77ITZpEmTXnrppSpVqrRp00ZEFi1a9OWXX27YsCE1NTX7NjMAAAAAgELE\nojOETZs23bFjh4eHx8KFC0Vk2bJlK1asqFix4s6dOxs3bmzlCgEAAAAAVmHRGUIRadGixdGj\nR+Pj4yMjI1UqVVBQkKenp1UrAwAAAABYlaWB0MTHx8fHx8dKpQAAAAAAnqXcAmGlSpUsWeL8\n+fMFVAwAAE+l1E/rjWqL7oYA8Iw53Llt6xIAPEJugfDpTwYmJycvWrTo8OHDer2+atWqgwcP\n9vX1tXBMZGTksmXLzp8/bzAYgoOD+/btawqolqwJAFAm70MHbV0CAACFSW6BcP/+/blPTklJ\niYmJyWVAeHh4fHz81KlTHRwcli9fPmXKlM8//1z94O9uHzkmKytr/PjxNWvWnDVrllqtXrt2\n7eTJk5ctW+bo6GjJmgAAAACAJ8rbPYQ5HDx4sE+fPtHR0Y/sjY+PP3ToUHh4eJkyZURk2LBh\nb7zxxsmTJ2vVqvXEMWXKlOnUqVPbtm0dHR1FpFu3brt3775x44arq+sT1wQAKFaWo5OobF0E\ngEfRpGeIIcvWVQDIydJAuGXLltWrV1+/ft1gMJhasrKyzpw5Y29v/7gpFy9etLOzCw4ONr10\ncXEJDAy8ePFi9vCWy5jOnTubGu/du7dx48aAgICAgIAjR47kvua9e/eioqLM63t7e9vZ2Vl4\njAqh0WhsXQKAJ1Or1VrtU/3OTmlUKpWInBo/2fD4H0wAbKjivHCXa1e0Wi0XdgHPFYv+tbFm\nzZqePXtqtVo/P7+oqCh/f//ExMSUlJTmzZsPHz78cbOSkpJcXV1NP6FN3N3dExMTLR9jMBi6\ndu2q1+tDQkKmTZum0+meuOaRI0dGjhxpfrlgwYL69etbcozK4eTkJCJbYuNOJSTZuhYAjxCT\nniEiTk5OHh4etq6lMCE/A4WCh4cHgRB4rlj043P27NlhYWFr1qxxdXV1cHDYtWtXuXLlFi9e\nvH79+mbNmuUyMXtyExGj0ZinMWq1eu7cuQkJCRs3bhw3btzs2bOfuGbJkiW7dOlifunp6Zme\nnv7kI1SSzMxMEbl4L+XivRRb1wLgsTIzM/n4yhPzBSwAnmfp6ekEwhwcHBxsXQIUzaJAeOHC\nhY8//tjV1fXfaVrtoEGDLl26NHr06Pnz5z9yloeHR1JSktFoNEe4xMTEHI+zf+KYwMDAwMDA\nKlWq9OnTZ8+ePT4+PrmPr1ChwkcffWR+mZiYmJycbMkxKgf/xAQKhYyMDD6+8iQri3uTgEIg\nOTmZQJgDgRC2ZVEgVKvV5gBmZ2d3794909cdO3Z87bXXHhcIK1SokJmZGRERUb58eRFJTEyM\njIzM8WzDx405efLk/PnzP//8c9PfEFMBRqPRkjVhCXed1pnLq4DnUqpen5Cpt3UVAABAESyK\nBJUqVVq2bFmrVq10Op2/v/+ePXvq1asnIrdv3zaHw4d5eno2btx43rx57733nr29/eLFi8uV\nKxcSEiIiO3fuTE9P79Chw+PGpKamZmRkzJ07t1evXjqdbtOmTenp6bVr185lTeRJv+DAboEl\nbF0FgEfYFHPz03OXbF0FAABQBItO2b///vvr1q3r0KGDiLRp02bChAnvv//+lClThgwZUqNG\njVwmDh06tGzZsuPHjx8+fLiDg8O4ceNMZxpPnDhx6NChXMY4OztPmTIlIyNjzJgxw4YNi4iI\nmDhxor+/fy5rAgAAADCZPHmySqXy9fU17R+Rw1tvvaVSqV544YX8Ld6jRw8XF1aIGBkAACAA\nSURBVBdLRr7wwgtczfecs+gMYc+ePdVq9fXr10Vk8uTJ586d+/zzz0UkMDBw7ty5uUx0cnJ6\n//3333///Rzt2TcCfdyYoKCgiRMnWr4mAAAAADO1Wn3nzp1t27Z17Ngxe3t6evp///tfns0G\nE0vvIuvevbvpC09Pz59//jkmJiYpKals2bI6nc5qtQEAAADIJ7Va3aBBg+XLl+cIhBs3bkxJ\nSalbt66tCsNzxdJdnmJjY+fNm2d+qdPpvv/++/j4eOtUBQAAAOCp6PX6Tp06bdmy5fbt29nb\nV65c2bx58xxnCLdt29a0aVNXV1dHR8eqVat+9tln5qe7GY3GKVOmBAYGOjg4VKtWbd26dTnu\n2Prtt99atWrl5ubm6OhYq1atpUuXPrKe2NjYt956KygoyMHBwc/P79VXXz1//nyBHjHyw6JA\n+Ndff9WuXXvEiBHmltTU1EmTJtWpUyciIsJqtQEAAADIv86dO+v1+tWrV5tb4uLiduzY0aNH\nj/v375sbN2zY0K5dOxFZvnz5Tz/91KhRo+HDh5tv8po1a9akSZOaNGmyadOmcePGTZo06fjx\n4+a5e/bsad68eWZm5qpVqzZu3BgaGjpgwADT88Nz6NKly+bNmydOnLh169bZs2dfuHChWbNm\nqamp1jp4WMaiS0bHjBnj4uKyceNGc0tQUNDZs2c7duw4ZsyYdevWWa08AAAAAPlUsmTJFi1a\nLF++fOjQoaaW1atX63S6bt26LVq0yDxs7NixAQEBO3futLe3F5HWrVvHx8d//vnnY8eO9fLy\nmjt3bkhIyLfffms6Mdi0adPSpUubTzCOGDEiICBgx44dprmtWrWKiYmZNm3akCFDHB0dzW+R\nlJR08ODB0aNHDxgwwNTSuHHjNWvWJCQkODk5PZM/DDyaRWcI9+3b99FHH5keNWFWuXLlkSNH\n7t271zqFAQAAAHhab7755tGjR8+cOWN6uXLlyk6dOrm6upoHxMTEnD9//uWXXzYlOpN27dpl\nZmYePHgwMjIyJiamRYsW5stE/f39zfcfxsfHHz16tG3btkajMf0fYWFhiYmJR48ezV6Gk5OT\nj4/PmjVrdu3aZTAYRCQ4OHjs2LGm5wjAhiwKhCkpKdm/P8y0Wm1KSkpBlwQAAACgYHTu3NnV\n1XX58uUicvbs2WPHjvXp0yf7gOjoaBEJCAjI3mjKabGxsTdu3BARX1/fh3tFJDIyUkQWLlzo\nmM2gQYPMy5pptdqtW7eqVKqWLVsWK1ase/fuq1evzsrKKuCjRd5ZFAhr1aq1YsUKU5Q3S0lJ\n+fLLL2vWrGmdwgAAAAA8LScnp27duq1atSorK2vlypUlSpRo1apV9gGmU3/ZbykUEdOOMiqV\nyry1THbmIGea269fvwMPeemll3LMqlevXkRExO7duwcOHHju3LlevXo1bdo0IyOj4I4V+WHR\nPYQTJkxo3759lSpVWrVqVbx48fT09KioqE2bNiUkJGzZssXaJQIAAADIt759+y5dunT//v1r\n1qzp1auXRqPJ3hsYGCj/nOszi4qKEpGAgIBixYqJyM2bN7P3Xr161fRFqVKlRMRgMISGhlpS\niUajad68efPmzWfMmPHVV18NGjRo7dq1Oc5Y4hmz6Azhyy+/vGnTJnt7+y+++GLChAnTp09f\nsWJFYGDgpk2b2rZta+0SAQAAAORbkyZNypQpM2vWrGvXrj2cvooXL16tWrXNmzenpaWZGzds\n2ODk5NSwYcPSpUv7+PiYb/wTkfPnz586dcr0tZeXV/369Tds2JCQkGCeu3LlyvHjx+v1+uzv\ncuTIkR49esTFxZlbTCcqs7fAJix9DmFYWNjJkyfj4uKOHTt27NixW7dunThxIiwszKrFAQAA\nAHhKKpWqT58+W7ZsqVGjRvXq1R8e8Mknn9y9e7dVq1Y//PDDpk2bevXqtW3btgkTJri5uanV\n6sGDB587d65Lly7r1q1bsGBB27Zt69SpY547c+bM1NTUJk2afPPNNz///POECRMGDhwYExOj\n1T5wKWLJkiW3b9/eqlWrpUuX7ty5c/Xq1a+//rq9vX2HDh2sfvzIlUWXjIpIampqYmJiiRIl\nihUrlp6evnbt2lu3bnXs2LFChQpWrQ8AAADAU+rTp8/HH3/8uIsz27Vrt3Xr1unTp/ft21ev\n11epUmXp0qX9+vUz9U6aNCkzM3P58uXbtm2rWLFieHj4nj17Tpw4Yept1qzZ7t27p0yZMmTI\nkMzMzODg4ClTppifYWhWokSJvXv3TpkyZdy4cXfu3PH29q5fv/7evXsrVqxovaOGJR59n2gO\n58+fb9as2QcffDBmzBi9Xt+0adMDBw6IiIODw/79+7P/huB5k5iYmJmZaesqni+//vrrjBkz\nhlUI7hZYwta1AHiETTE3Pz13adiwYVyTnydjx449fvz48ekzDY/aFhuAzVWcF+5y7crWrVvV\nakuvUFMIHx8fW5cARbPoL+S4ceP8/Py6d+8uImvXrj1w4MCiRYsuXbpUq1at6dOnW7lCAAAA\nAIBVWHTJ6P79++fMmRMcHCwiP/30U/Xq1d966y0RGTp06KhRo6xbIAAAUJqLF2TZYvnrvKSn\ni39J6fCKtO8o5tNKx4/KqpVyKUL0WRIYKF26SsvWolJJcrJ0eMx59amfyAtNnln5AFCIWBQI\nExISSpQoISIGg2HXrl0DBw40tRcrViw+Pt6K1QF4kuM3b03df/DojbjUTH0ZD/eBNav2rxGi\nUalMvXuuRc04eORUXLzekFXey3NI7Ro9QiqqRBIyMvzmLnrkgt93btexfJlneAQA8KAzp+WD\nd8WnmHTvJU5O8r89Mme2xETLoCEiIr//JuPHSrly0re/qNWy+xf5v6kSGyt93hQHexkxOudq\nRw7L//bIPw/RBgDkYFEgLF68+OXLl5s3b/7rr7/euXPn5ZdfNrVHRkZ6e3tbszwAufkj5kbr\n1ev9XV0+qF/b1U7341+X3v3518sJiZ+82FhEtkRc6fbjlhq+PuMb19eoVGvPXei35ecriUkf\nNarnpNUubNsix2q7rkau/ysi2MPNFocCAP9Y/JXY28v8L8XTS0SkXXt5Z6Bs+FHeGiQajSz+\nSvz8ZN5CMd0s2q6D9O8j36+RN/qKViftHtyuMCVZli2RVzpJmbI2OBAAKAwsCoStW7ceP378\nxYsX16xZU7p06SZNmohIXFzc3LlzGzdubOUKATzWhL2/O2q1/+vd1dfZSUT6VQ9pvHLtV8dP\nTW3aUKtWT9x7IMjdbXfvro5arYj0qxFSZ+l3cw8fG9uonp1G0696SPalEjPuT9n/x9u1qlUr\nxq3tAJ7OB+9Kpl5GjJIv5sqZ02JvL7Vqy7sfiJeXGI2SlPToWRqNuLiIiLRqI+07/p0GRUSl\nliohcvGC3Lsn7m7SroOUKCHmrYO0WgmpKtu3SkaGODjkXHPJ15KllwFvW+MoAaBosCgQTp06\n9cyZMzNmzChWrNi2bds0Go2IvPfee9evX//222+tXCFQlLVes/5+lmFBmxYjdu39I+aGg1b7\nYqmSn7VsVtzZyShyJ9vzYbPTqNUe9vYi0qtKpf7VtaY0KCJqlaq+v9/xm7cS0jO8HB361Qgp\n7e7m+M9TgHRqdQN/v29On0vNzHTW6XKsOXnfgUyDYXKTUKsdKwDF0OokJlpm/J/07SejP5Jz\nZ2Xqx3L/vkyfIXfvyqsdHz0rsJSs/E5EJKx9zq7oKHF3F3c3Uanl1W4PdBmNcuWy+Po+Ig1e\nuyobN8j7H/6dMwEAj2JRICxRosSBAweSkpKcnJzMj5gcMWJEeHi4n5+fNcsDijg7teby3cS3\nt/0yrlH9r319DsXe7LtpR3pW1g9d2selpAbNX/LIWRW8PE8NfF1E3qxeJUdXxN0Eb0dHL0cH\ntUo1tE6N7F1GkbPxtwNcXR5Og+du3/n6xOnwls082K8fwNNTqSQuTsaMl1q1RUSK+Ur9bXL0\niBiN4uYqs8MfPevhRGey51c5cljeHiyqbFujZ2bK3Tty65ZsWC+XLsmESY+YuORrKVEi50Wk\nAIAHWfpgehFxc3vgzqK6desWdDGA4qhUEnUveUm7Vs1KBYhIZ1eXVcGldl+NNIp4Othv7d7p\nkbMeTnQmP/wVsetq5LRmjdT/bCojIhlZWXEpqTHJKV8eO/XnrdsrOrR5eOLH+w6WdnfrVyPk\n4S4AyA+dTmrW+velTzHJyJD7GWLvIHXy8u+Hg7/Lp9OlYSPp0fOB9lMnZcQwEZHifjJlujRs\nlHPitauyf698OFJ45B0A5CoPgRCANdhrNE1LBZhf+rs4p+n1aZl6J522RVCg5etsu3T1ra07\nw8qW/rB+7eztv0XFhK3dICKl3FzXdAoLK1s6x8Rzt+/8dOHSF22aa7LFSAB4Ku4ekv0jxZTK\nDMa8LbJhvcwLl6bNZNzEB04Piki58jJ9hiQmyJHDMm6M9OotA9/JOdfRUV5qlb/yAUA5CISA\njXk7OmbPYRq1WkQMxrz9s+nLY6eG79rbqULZZe1bqx/MdTV8fX7o0j4+LW3X1ciu6zePaFBn\nStOG2Qd8dfxPFzu77pUr5vsQAMBSlmwqYzL/c1n3vfR6XQa+Iw//usrdXRo1FhF5uZ34Fpdv\nv5EXmkqlyn/3ZmXJr7ukfqg4Ohb4EQBAEUMgBJ5TlmwqYzJy9755R06MDK0zpWmjh8/xeTs6\ntisXLCJ9q1UJdHOZefBIx/Jl6pYoburVGwz/PXexTZkgF7tHX4YKAAXJkk1lRGTxIvlhnQwf\nJe0fHJxwV/b+TypUkErZ7qCuVl3WfCuXL/0bCM+ekcREacAuWVCue/fuWWNZV1dXaywL2yIQ\nAs8pSzaVEZFJew/MP3pyfpvmA2pUzT7mVmrahguXahYvVu+f7CcijUr6/0eOnb512xwID8Xc\nuJ2W1qZMkHUOAgAeZMmmMkcOy7cr5d1hOdOgiOh0Mi9cqlSV8M//vYj02BERkeLZdrk786eI\nSLnyBVc3UDQZDIaUlBRinsIRCIHnlCWbyuy6Gjnj4JHPWjbNkQZFxE6j+fCX/zUoWeLnHp3N\nF5H+ei1SREq5//u5fyD6hohU9+XZgwCeCa3uCZvKZGXJ3M/E3V3s7WXLpge66taT4n7S6w1Z\nuUzeHyrNmotOJ6dOyO5dElJVame7ffr6dRER/5JWOACgSPniiy927Njxww8/ODxum18ogEWB\nUKfT2T9mM3qVSuXm5lazZs0RI0Y0b968QGsDFM1Oo8l9Uxm9wTDslz3ejo6OWu2yU2eyd71U\nulQpN9dRoXWn/36o5er1XSqWs9do9kdGf3/uQgN/vxez7WHz1507IlLGw91KRwEAeZOcLFGR\nIiKzZ+TsmvqJFPeTfgMkIEB++lFWLBN9pviVkH4DpetrD+w6k5ggKjU3EAJPdOvWrdTU1NTU\nVAKhklkUCAcPHvzHH38cOnSoSpUqFStWVKlUFy5cOH369AsvvFCqVKm4uLj9+/dv3759y5Yt\nbdu2tXbFAEwSMzIu3kkQkcHbd+fo+r5zu1JurhNeaFDO0+PL46f+77dD9w1ZQW5uE5uEvlun\nZvZdZ26npatVKhc7u2daOoCibeZ/cra8/6G8/6FFc93d5df9TxjTqo20esQTdP41/aEwCQB4\nDIsCYYcOHTZu3Pj77783bPjv5oQHDhzo27dveHh4nTp1EhMTW7duPX36dAIhkCebur2SoyW8\nZbPwls0smevt6Jg+6t3cx/QMqdgzJLftQ3/o0t6S9wIAAECRZFEgHD169LRp07KnQRFp2LDh\nmDFjhg8fvmfPHnd392HDhr311lvWKRIAAABA3pw5c+aLL74wGAyPGxATEyMio0aN0mg0jxtT\nu3btd95553G9KAIsCoRnzpwpXrz4w+3+/v6HDx82fe3k5KTiqdYAAADA8+HYsWPnz5930mq0\nj/lXulrETae9df3a41ZI1mfdvXuXQFi0WRQIixUrtnjx4pYtW+aIfKtXr3Z2dhYRvV7/1Vdf\nVapUySo1AgAAAMgjo9EoIh+HVGjk45m/FTrvP2Is0JLwHFI/eYjIgAEDvv/+++rVq3/44Yez\nZs2aPXv26NGjGzRosHLlyh49eojIa6+9tm3btuHDh1u5WgAAAADPqb/++is0NFSrze2c0/Xr\n1wcPHhwcHGxvb+/l5dW4ceMVK1aYe+vWrav6h4eHR7169b799tscvcePH8++oF6v9/PzU6lU\ner0+fyUpnEV/NJMmTdJqtV988cWcOXPMje7u7h988MGnn34qIs2aNevWrZspHAIAAABQmrVr\n137wwQetWrU6cuTI48acPXu2SZMmAQEBn3zySeXKldPS0jZv3vz2229fvHhx2rRppjFvvvnm\n1KlTRSQxMXHlypVvvPFGhQoV6tWrZ+r19fVdsmTJF198YV5z69atj7tP0pKSYFEgVKvVEyZM\nGD9+/LVr1+Li4oxGo7e3d3BwsPn20/fff9+aRQIAAAB4rmVkZBw8ePDYsWPZz+nlMGjQIH9/\n/yNHjuh0OlNLaGho7dq1//zzT4PBoFarRcTZ2TkgIEBEAgICpk+fPnv27LNnz5oDYVhY2Lff\nfjt79mzzsxOXLl3asmXL1atX568kWHTJqMmdO3dOnz598uTJ06dPX7p0KTU11XplAQAAAChE\n+vTpU6pUqVwGxMbG7tu3b8yYMeY0aNKlS5dJkyaZ0mB29+/fX7hwoZubW8uWLc2NderU8fb2\nXr9+vellXFzc9u3bX3311fyVBLHwDKHBYBg+fPj8+fMzMzPNjc7OzpMmTRo5cqTVagMAAACQ\nT/fu3RORH6Ju7I+/m88V9Fna9PSCqufy5csiEhISkvuwRYsWLV++XERSU1O9vLxWrlxZsmTJ\n7AP69++/ZMmSXr16icg333zTvHnzHAOQJxYFws8++yw8PLxLly5hYWH+/v5GozEqKmr9+vWj\nRo0qXrx4nz59rF0lAAAAgDy5ceOGiBy8nc80aKJNSyugcsTOzk5Esm/94uHhkZycbPp6/fr1\nHTt2FJHu3btPmjRJRFJTUw8fPtyvX7/p06dnf/TFm2++OXny5MuXL5cpU2bZsmWmwcg3iwLh\nsmXL3nnnnS+//DJ749tvv92jR4+5c+cSCAEAAIDnTfny5ffv3z+2crnanm75W2HQkT9Vbu4F\nVU/ZsmU1Gs3x48fr1q1rajlw4EBWVpaINGrUyLwxjLu7e7ly5UxfV69ePS4ubuLEidkDob+/\nf5s2bZYuXfrKK6/cuHHjlVdeOXbsWEEVqUAWBcJLly6Fh4c/3N6rVy92FgUAAACeW152On9H\nh/zN1ahUxsc81D4/lXh5tWvXbvr06b169TI9zLxy5coi8rg9Qk2MRuPDz5MYMGDA6NGjk5OT\ne/fubTrxiHyzKBBqtVrTJcg53L9/37zRKAAAAADFunHjhl6vv337tohERUWJiIeHh4uLy5Il\nS5KTk01PJViwYEHDhg0bNWo0fvz4GjVqZGRkHDt2bMGCBe7u7lWrVjWtk5KSYpqenp5+9OjR\nOXPmdO/ePcd7tW/fftCgQatWrdq1a1c+Sir4gy/MLNpltFatWnPnzr1//372xrS0tPDw8Nq1\na1unMAAAAACFRmhoaGBg4MCBA7OysgIDAwMDAxcvXiwiO3fu3LRpk2lMyZIlT5w40bZtW1Mg\nbNy48fz58zt16nT69GnzZaLLly83Ta9aterEiRPffffd7M9CN9FqtX369AkKCqpRo0Y+SkJ2\nFp0hHDt2bPv27cuXL9+2bduAgID79+9HRkZu3rw5ISFh+/bt1i4RAAAAwHPu6tWrj2xfs2ZN\n9pdeXl4zZsyYMWPGIwfn/gT57L0zZ840fx0aGmo0Gi0vCdlZFAjDwsLWr18/duzYRYsWmRur\nV6/+zTffZH8qCAAAAIDnysHbd29lZORvbrrBYF+w1eD5Y1EgFJFOnTp16tQpJiYmOjpapVIF\nBgYWL17cqpUBAAAAyDcHBwcR+SHqxtMsEmBPJCziLA2EJv7+/v7+/lYqBQAAAEBB6dixo5+f\nXy57eK5du/b8+fPDhw/PZZ+V0qVLW6U4PDdyC4SVKlWyZInz588XUDF4dn65GX8lpcAeMwqg\nAF1LTbV1CQCAosDBwaFp06a5DDBt0dmoUSMvL69nVRSeO7kFQh8fn2dWB54Z01/404n3Tic+\n4lEiAJ4T/GwGAADPQG6BcP/+/c+sDjwzNWrUWLVq1cPP90ThNXr06IyMjPDwcFsXggKj0WiK\nFStm6yoAAEWcSqUy/z8UK7dA2L9///nz5zs6OlqyUFpa2tChQ5csWVJAhcGKOPdbxGg0GrVa\n7efnZ+tCANsL+c+MR+w7DuA5oEtKtHUJyKl9+/Z+fn4eHh62LgS2lFsg3L17d4MGDT7//PMX\nX3wx91X27ds3dOjQxET+ngMAbKN27dqxsbG2rgIFJjMz8/bt2y4uLrnsdYFCxscnKChIrVbb\nug78q379+vXr17d1FbCx3ALh0aNHe/bs2bx582bNmvXt27dVq1YBAQHZB0RHR+/atWvFihW7\nd+9u1arV7t27rVwtAACP1q1bt27dutm6ChSYM2fODB8+vHPnzr1797Z1LQBQlOUWCL29vbdv\n3/7dd999/PHH/fv3F5FixYr5+vq6u7snJibeunUrLi5ORMqXL79q1aqePXvyKx8AAAAAKESe\n8BxCtVr9+uuv9+zZ8/fff9+xY8fJkydv3bp1584dDw+PMmXK1KhRo02bNg0bNtRoNM+mXAAA\nAAAF4u7duzExMSEhIbYuBLZk0YPpNRpNkyZNmjRpYu1qAAAAADwbCxYs2L17908//cTNukrG\nRZ4AAACAEqWnpxsMhvv379u6ENgSgRAAAAAAFMqiS0YLLycnJ7a6gUJ4enraugQAKDBOTk4i\notVq+XADAKsq4oEwLS0tMzPT1lUAz0JCQoKtSwCAApOWliYier2eDzcUed7e3lZaee/evR9/\n/LHBYMh92KuvvppLb/369WfMmFGgdeH5UsQDodFoNBqNtq4CeBb4VgdQlJg/0/hwA/Lt6tWr\nBoMh1b+k3tk5fyu4XLl85cqVgq0Kz5siHggBAAAAJYt5uV1i5Xw+WKLatEkFWwys4erVq8HB\nwX/++WfVqlXzMZ376wAAAAA8rZiYmN69e/v6+rq7uzdr1uzQoUOPHHb9+vXBgwcHBwfb29t7\neXk1btx4xYoV5t66deuq/uHh4VGvXr1vv/02R+/x48ezL6jX6/38/FQqlV6vt9KhPaXdu3cf\nOXLE1lU8FoEQAAAAwNN65ZVXoqKifv7556NHj/r7+7dv3z4lJSXHmLNnz9aqVev333//5JNP\nDh06tHXr1ubNm7/99tvjx483j3nzzTcjIyMjIyN/++23Fi1avPHGG4cPHzb3+vr6LlmyJPua\nW7dufeJ9knlVsLuQfPbZZwRCAAAAAEXWnTt3SpcuvWjRopo1a5YrV27GjBm3bt06ffp0jmGD\nBg3y9/c/cuRIjx49atSoERoaOm3atNWrV+t0OnOoc3Z2DggICAgICAkJmT59ukqlOnv2rHmF\nsLCwb7/9Nj093dyydOnSli1bPlxSenq6SqVasmRJ06ZNAwICKleuvHHjRlPX2bNnW7du7enp\n6eHh0aZNm4iICBHJzMxUqVTLli0LDg7u37//44YZjUaVSrVq1aqmTZuWKFGiWrVqf/7554cf\nflipUqXixYs/vAFPixYttm7dOmzYsDp16iQnJ6tUqj179pi6IiIiVCpVRESEac3vv/++devW\n5cqVCwoKWrlypWnMzZs3u3fv7uHh4e3t3bp16zNnzpjaT5w40aBBA2dn5+rVqx88eDDv/8X+\nRSAEAAAA8FS8vLz++9//VqxY0fQyOjparVaXLFky+5jY2Nh9+/aNGTNGp9Nlb+/SpcukSZMe\nflbc/fv3Fy5c6Obmlj3v1alTx9vbe/369aaXcXFx27dvf+RGqVqtVkTmzp27bt26qKioYcOG\nde3a9dq1ayLSrVs3Pz+/69evX79+3cXFpW/fviKi0+lUKtXChQt//PHH+fPnP26YSqXSaDQL\nFy7ctGlTZGSku7t78+bN69Wrd/78+cWLF48bNy4uLi57Gbt37y5VqlR4ePjRo0cf96dnWvPT\nTz9dtmxZRETEqFGjBg8ebDq/2rt3bxG5fPlyVFRU/fr1W7ZsmZqaajAYOnfuXKlSpZs3b27a\ntGnhwoW5/Kd5ojxsKpOWlnb06NHo6OiXXnrJx8dHr9eb/pQBAAAAPG9MySTwpx/9d2zL3wq6\ne/dS7O3zOuvOnTsDBgx47733AgICsrdfvnxZREJCnrDDzaJFi5YvXy4iqampXl5eK1euzBEs\n+/fvv2TJkl69eonIN99807x58xwDsnvzzTd9fX1FZODAgaNGjdq6devgwYP37t3r4ODg7Ows\nIr169erZs6fpHJ1are7YsWPNmjVNcx83TERef/11d3d3EXnhhReuXr3as2dPEWnevHlWVtaV\nK1dM75hXffr0MR1I+/bthw4devXqVRHZtWvXjRs3vLy8RGTKlCnz58/fvHlzQEDA1atXf/nl\nFxcXFxcXlw8++GDv3r35eEcTSxPdrFmzpk2blpSUJCIHDhzw8fGZNGlSbGzs119/rdFo8v32\nAAAAAKwhIyNDRHT3krSpOe/ls5DKYMjKysrTlPPnz3fo0KFly5b/+c9/cnTZ2dmJSPatXzw8\nPJKTk01fr1+/vmPHjiLSvXv3SZMmiUhqaurhw4f79es3ffr0d955xzzrzTffnDx58uXLl8uU\nKbNs2TLT4McpW7as6QuNRlOiRInIyEgROX78+Keffnr58mWDwWB6bnlWVpbpXFf58uXNc3MZ\nZs66Dg4O5jjq4OAg/zxGNR+CgoJMX9jb25vWiYqKEhE/P7/swy5fvmzKpaVLlza1VKhQIX/v\naGJRIFy8ePGoUaM6duwYFhY2aNAgU2PFihVnzpxZoUKFMWPGPE0FAAAA+7Gu9QAAIABJREFU\nAApcYGCgiFx+ve/TPHai2IOXd+Zu165d3bt3nzx58tChQx/uLVu2rEajOX78eN26dU0tBw4c\n+P/t3Xl4VOXBP+4z2diJgbAHAUVRFCgWEVRqQWmxKCC21VZlUVrwcqmvilpFUZDWijXw1oJC\nC8riUmmLIKCilLq8eKmo2KLURCqkLEIMhCUsWeb3x1zNNz9QDMpkkpz7/ivnmefMfEZwmE+e\ns8QK59lnn11+DmF6enrHjh1jP3ft2nXbtm333HNPxULYunXr73//+7NmzRo8ePDWrVsHDx78\n7rvvflmkioW2tLS0bt26GzZsuOiii8aPH7906dK0tLRFixYNHjy4fE6d/66IHnlabJ3w8J+P\nyiHXwjn8eWIjRUVF9erVqzhefoZhzDe8vGqlziF85JFHxowZ89xzz8UOnI0ZNmzY2LFj586d\n+01eHgAAqAVef/31H//4x/PmzfvCNhgEQZMmTQYOHDhp0qTyq4+eeuqpp59+eufOnY/wtNFo\n9PDCc8011zz77LPz58+/4oorYguPX+bjjz+O/XDgwIHNmze3bdv27bffLi0tveOOO2I7ftn1\nPys57ajUqVMnEokcPHgwthk7KPQIYsuV77//fvlI7LDbrKysaDS6cePG2GD5lWa+nkoVwnXr\n1n3hmZrnnXfev//972/y8gAAQE23b9++4cOH33TTTaeffvp//itW/P74xz9OnTo1Nm3atGll\nZWVnn332s88++/HHH//jH/944oknevfunZ6eXn5T9b1798Z2z83NfeaZZ7Kzsy+77LJDXu6i\niy4qLCycN29e7HKgRzB37twPPvjgwIEDkydPLisrGzRoUFZWVklJyWuvvVZWVvbUU0+tWLEi\nCILNmzcfsmMlp1VG/fr1c3NzP//889TU1I4dO77wwgtBEOzZs+eRRx458o6dO3fu16/frbfe\nmpeXV1xcPH369C5dumzdurV3795Nmza97777duzY8dFHH33l8xxZpQphamrqFx4L+9lnn6Ue\nzSIyAABQ+/zf//3f+vXr77nnnrYVzJ49OwiC5cuXL168ODatTZs277///oABA8aNG9etW7dz\nzjnn97///ZAhQ/75z3+WHyb6+OOPx3Y//fTT77nnnhtuuCE7O/uQl0tJSRk2bFi7du26det2\n5GDXXXfdddddl5GR8eSTT/7lL39p2rRpr169xo4dO2TIkObNm69YsWLx4sXdu3fv0aPHIet1\nlZxWGaNHj54+fXrPnj2DIJg+ffrSpUs7dOhwwQUX3HDDDcFXHfA5f/78rKysLl26ZGRkzJ07\nd9myZS1btqxXr96SJUv+8Y9/tG7d+rLLLovdxfFr3zsxEo1Gv3LS+eefHwTB0qVLo9FovXr1\nVq1a1atXr507d/bp06d169Yvvvji13vtKlBYWHhsbysJ1dDVV1+9f//+J598MtFBAI6ZtWvX\n3nLLLVdddVXskutQi2VmZh7z59y9e3cQBHPmzJk9e3buNT//JucQtklN/dOf/hTbbNSo0TGL\nGH8lJSWpqanLli0bMGBAorNUa5W6qMz48ePPP//8zp07f//73w+CYMaMGY8++ujChQuLiooe\nffTROCcEAAC+puZvvHbc2kNvEF9JKfv2BY4HrO0qVQi/853vvPjii2PHjo3d9DC2+NuzZ88H\nH3zwnHPOiW9AAADg6MVuXtd43Uff5EkyMjKOURyqqcreh7Bfv36rV6/Oz8/Py8uLRCLt2rXz\nlwMAAKqtiy66qEePHkc4Qezhhx9+5513pk2bdtxxx33ZnCM8VM2lpKRU5uQ4KlsIi4qKCgsL\nW7VqlZmZuX///meeeWb79u2DBg36hrdBBAAA4uSQe5ofInYj9RYtWsTWEgmnyt52okOHDk88\n8UQQBCUlJf369RsxYsTYsWO7deu2evXqOCcEAAAgLipVCO+6666WLVvGbgDyzDPPrFq1asaM\nGZ988kn37t0nTZoU54QAAMCxl5ycHARBSkpljxmkVqrUH//rr7+enZ3doUOHIAiee+65rl27\n/uxnPwuC4Prrr7/tttviGxAAAIiDESNG9OnTp3HjxokOQiJVqhDu3LmzVatWQRCUlZW98sor\no0aNio03a9YsPz8/jukAAID4aN++ffv27ROdggSrVCFs0aLF+vXr+/bt+7e//a2goODCCy+M\njefl5TVt2jSe8QAAgKNTs+4gT2JVqhB+73vfGzduXE5OztNPP92+ffs+ffoEQbBt27apU6e6\nDyEAAEANValCOHHixLVr1/7mN79p1qzZsmXLYqef3njjjRs3bpw/f36cEwIAABAXlSqErVq1\nWrVq1a5du+rXr19+GaJbb711ypQpR763CQAAANXWUVxktkGDBnv37i0rK4ttduzYMQiCnTt3\nHnfccXGJBgAAQDxVqhDm5OSMGjVq1apVxcXFhz8ajUaPdSoAAADirlKFcPTo0e+9994Pf/jD\n1q1bu3MlAABA7VCpdvfWW289++yz5XebAAAAoBZIqsykhg0bnnjiifGOAgAAQFWqVCEcPnz4\n7Nmz4x0FAACAqlSpQ0YnTZp06aWX9u7d+9xzz23atOkhj95xxx1xCAYAAEB8VaoQTpkyZdGi\nRUEQvPnmm4c/qhACAADURJUqhNnZ2RdeeOEdd9zhKqMAAAC1RqXa3eeff/7b3/721FNPjXca\nAAAAqkylLirTpUuXzz//PN5RAAAAqEqVKoSPPPLIuHHjVq9eHe80AAAAVJlKHTJ66623bty4\nsUePHg0bNjz8KqOffvrpsc8FAABAnFWqECYlJXXs2PGkk06KdxoAAACqTKUK4d///vd45wAA\nAKCKffU5hAcPHjzzzDOff/75KkgDAABAlfnqQpiWlrZ58+bc3NwqSAMAAECVqdRVRh977LE/\n/OEPf/3rX0tKSuIdCAAAgKpRqXMIJ0+enJycPHTo0JSUlGbNmqWlpVV81FVGAQAAaqJKFcKS\nkpKMjIzzzz8/3mkAAACoMpUqhG+88Ua8cwAAAFDFKnUOIQAAALWPQggAABBSCiEAAEBIKYQA\nAAAhpRACAACElEIIAAAQUgohAABASCmEAAAAIaUQAgAAhJRCCAAAEFIpcX32PXv2zJgx4+23\n3y4pKTn99NOvvfba5s2bV37Opk2bsrOzc3NzFy5ceFTPCQAAwFeK7wrhlClTNm7cOHHixOzs\n7OTk5AkTJpSVlVVyzmuvvXbnnXdmZWV9jecEAADgK8WxEObn57/11ls33nhjx44ds7Kybrrp\npk2bNq1Zs6aSc4qLix966KFevXod7XMCAABQGXEshDk5OWlpaR06dIhtNmzYsG3btjk5OZWc\n069fv2bNmn2N5wQAAKAy4ngO4a5duxo1ahSJRMpH0tPTCwsLj3bOUc3fvHnzm2++Wb7Zo0eP\nJk2afMM3AjVC3bp1Ex0B4JhJSUkJgiASifhwA4ir+F5UpmJzC4IgGo1+vTmVn/+vf/3rV7/6\nVfnmtGnTjj/++EqmhRqtYcOGiY4AcMzUqVMnCILk5GQfbgBxFcdCeNxxx+3atSsajZZXuMLC\nwoyMjKOdc1TzO3XqdOedd5ZvtmzZcs+ePcfqHUF15q86UJscOHAgCILS0lIfbtR6futBYsWx\nEJ588snFxcW5ubknnXRSEASFhYV5eXmnnHLK0c45qvmtW7ceOnRo+WZhYeH+/fuP+VuDashf\ndaA2KSkpCYIgGo36cKPWUwhJrDheVCYjI+Occ8753e9+l5ubm5eX9/DDD3fs2PG0004LgmD5\n8uWLFy8+8pwdO3bk5+fv3r07CIL8/Pz8/Pz9+/cfYT4AAABHJb7nEF5//fUzZ84cN25cWVlZ\n9+7db7rpptihnu+///6uXbsuvvjiI8wZO3bstm3bYs9z9dVXB0EwatSoQYMGfdl8AAAAjkrk\nKy/iUqMVFhYWFxcnOgXE19VXX71///4nn3wy0UEAjpm1a9fecsstV1111RVXXJHoLBBfmZmZ\niY5AqMXxkFEAAACqM4UQAAAgpBRCAACAkFIIAQAAQkohBAAACCmFEAAAIKQUQgAAgJBSCAEA\nAEJKIQQAAAgphRAAACCkFEIAAICQUggBAABCSiEEAAAIKYUQAAAgpBRCAACAkFIIAQAAQkoh\nBAAACCmFEAAAIKQUQgAAgJBSCAEAAEJKIQQAAAgphRAAACCkFEIAAICQUggBAABCSiEEAAAI\nKYUQAAAgpBRCAACAkFIIAQAAQkohBAAACCmFEAAAIKQUQgAAgJBSCAEAAEJKIQQAAAgphRAA\nACCkFEIAAICQUggBAABCSiEEAAAIKYUQAAAgpBRCAACAkFIIAQAAQkohBAAACCmFEAAAIKQU\nQgAAgJBSCAEAAEJKIQQAAAgphRAAACCkFEIAAICQUggBAABCSiEEAAAIKYUQAAAgpBRCAACA\nkFIIAQAAQkohBAAACCmFEAAAIKQUQgAAgJBSCAEAAEJKIQQAAAgphRAAACCkFEIAAICQUggB\nAABCSiEEAAAIKYUQAAAgpBRCAACAkEpJdID4ql+/flKS0ksoZGRkJDoCwDFTv379IAhSUlJ8\nuAHEVS0vhEVFRcXFxYlOAVVhx44diY4AcMwUFRUFQVBSUuLDjVovMzMz0REINatnAAAAIaUQ\nAgAAhJRCCAAAEFIKIQAAQEgphAAAACGlEAIAAISUQggAABBStfw+hBAGDRo0SEnx/zIAAEfN\nl0io8ebNmxeJRAoKChIdBACAGsYhowAAACGlEAIAAISUQggAABBSCiEAAEBIKYQAAAAhpRAC\nAACElEIIAAAQUgohAABASCmEAAAAIaUQAgAAhJRCCAAAEFIKIQAAQEgphAAAACGlEAIAAISU\nQggAABBSCiEAAEBIKYQAAAAhpRACAACElEIIAAAQUgohAABASCmEAAAAIaUQAgAAhJRCCAAA\nEFIKIQAAQEgphAAAACGlEAIA1cuOHTteeumlIAjeeeednJycRMcBqM0i0Wg00RniqLCwsLi4\nONEpIL4yMjIikUhBQUGigwAcAzk5ObfffntRUVH5yHXXXXfxxRcnMBLEVWZmZqIjEGpWCAGA\n6iIajU6ePLliGwyCYObMmVu2bElUJIDaTSEEAKqLLVu2bNy48ZDBgwcPrl69OiF5AGo9hRAA\nqC4OHjx4VOMAfEMKIQBQXbRp06ZBgwaHj3fq1KnqwwCEgUIIAFQXqampo0ePPmSwX79+p512\nWkLyANR6CiEAUI2ccsopFRcJk5KSunfvnsA8ALWbQggAVCOTJ0/eu3dv+WZZWdm0adO2b9+e\nwEgAtZhCCABUF5999tnhd6Lft2/f22+/nZA8ALWeQggAVBeH3IGw3L59+6o4CUBIKIQAQHXR\nunXrOnXqHD5+wgknVH0YgDBQCAGA6qJOnTojRow4ZLBXr17f+ta3EhEHoPZLSXQAAID/Z8iQ\nIXXq1FmwYMGWLVsaN258wQUXXHnllZFIJNG5AGqnSDQaTXSGOCosLCwuLk50CoivjIyMSCRS\nUFCQ6CAAx0xqamq9evVKS0srXnEUaqXMzMxERyDUHDIKAFRHaWlpiY4AUPsphAAAACGlEAIA\nAISUQggAABBSCiEAAEBIKYQAAAAhpRACAACElEIIAAAQUgohAABASKUkOgDwjezevTsnJycI\nghYtWjRu3DjRcQAAqEkUQqjBnn/++T/+8Y/79u0LgqBu3bojR44cPHhwokMBAFBjOGQUaqr3\n3nvvkUceibXBIAj2798/ffr0t956K7GpAACoQRRCqKmee+65wwcXLlxY9UkAAKih4nvI6J49\ne2bMmPH222+XlJScfvrp1157bfPmzSs558vG8/LyZs+evW7durKysg4dOgwfPvyUU06J67uA\n6ik/P//wwe3bt1d9EgAAaqj4rhBOmTJl48aNEydOzM7OTk5OnjBhQllZWSXnfOF4cXHxuHHj\nGjVqNHny5Ozs7BYtWtx7773lh8xBqDRr1uzwwcN/5wIAAF8mjoUwPz//rbfeuvHGGzt27JiV\nlXXTTTdt2rRpzZo1lZnzZeNFRUVDhgwZM2ZMmzZtWrVq9aMf/aioqGjr1q3xexdQbV1yySWH\nDw4dOrTqkwAAUEPFsRDm5OSkpaV16NAhttmwYcO2bdvGro//lXO+bDw9Pf2SSy6pV69eEAS7\nd+9etGhRVlZWVlZW/N4FVFtdu3a96aabGjRoENusV6/edddd9+1vfzuxqQAAqEHieA7hrl27\nGjVqFIlEykfS09MLCwsrMyc9Pf0I+5aVlf3whz8sKSk57bTT7r///tTU1PJp69evX7JkSfnm\nD37wg9atWx/ztwbVxKWXXjpgwIBPP/00dkptw4YNE50I4NhISkoKgiA1NbX8114AxEN8LypT\nsdEFQRCNRis/5wj7JiUlTZ06defOnYsWLbrrrrseeuih8n8tNmzY8MQTT5TPPOuss0488cRv\n9iag+tq0adP999+/du3aaDTauXPnu+666/jjj090KIBjJiUlJSXFPZMB4iiOH7LHHXfcrl27\notFoebUrLCzMyMiozJyv3Ldt27Zt27bt3LnzsGHDVq5cOXDgwNh4t27dpk2bVnHaIWuSUGsU\nFBRceeWVBw4ciG2uXr36sssumzt37hdebAagZklJSWnQoMGBAwf279+f6CwQX+np6YmOQKjF\nsRCefPLJxcXFubm5J510UhAEhYWFeXl5h9wi4svmtGnT5gvH16xZ8/vf//5///d/69atGwRB\nUlJSJBKpuHjYpEmTnj17lm8WFhYWFxfH7z1CAk2cOLG8DcYUFxffd9992dnZiYoEcGzFLjCe\n6BQAtVkcLyqTkZFxzjnn/O53v8vNzc3Ly3v44Yc7dux42mmnBUGwfPnyxYsXH2HOl4137Njx\nwIEDU6dOzcvL27p16x/+8If9+/efccYZ8XsXUG3l5uYePrh+/fqqTwIAQA0V+cLz+o6VoqKi\nmTNnrlq1qqysrHv37mPGjIkd9jl58uRdu3ZNnDjxCHO+bDx2luC//vWv0tLSdu3aXXHFFV27\ndv2yAFYIqcUuueSSw2/CmZaWtmjRooTkATiGUlNT09PT9+3bt3fv3kRngfjKzMxMdARCLb6F\nMOEUQmqx66+//vBFwnbt2j322GMJyQNwDCmEhIdCSGLF8ZBRIK5uv/325OTkiiNJSUm33357\novIAAFDjKIRQU7Vt2/Y3v/lNixYtYpvNmzd/4IEHTjjhhMSmAgCgBnHIKNR4aWlpQRAcPHgw\n0UEAjhmHjBIeDhklsawQQo3XoEGDhg0bJjoFAAA1j0IIAAAQUgohAABASCmEAAAAIaUQAgAA\nhJRCCAAAEFIKIQAAQEgphAAAACGlEAIAAISUQggAABBSCiEAAEBIKYQAAAAhpRACAACElEII\nAAAQUgohAABASCmEAAAAIaUQAgAAhJRCCAAAEFIKIQAAQEgphAAAACGlEAIAAISUQggAABBS\nCiEAAEBIKYQAAAAhlZLoAMDXt23btieeeGLt2rVlZWWdO3ceOXJkixYtEh0KAIAaQyGEmmrn\nzp033XRTQUFBbHPbtm3vvffe9OnTmzRpkthgAADUFA4ZhZpq/vz55W0wprCw8PHHH09QHAAA\nah6FEGqqf/3rX4cPfvzxx1WfBACAGkohhJoqNTX18MG0tLSqTwIAQA2lEEJNddZZZx0+2LNn\nz6pPAgBADaUQQk01dOjQLl26VBzp3LnzZZddlqg8AADUOJFoNJroDHFUWFhYXFyc6BQQL2Vl\nZS+//PK6deui0WinTp369++fnJyc6FAAx0Bqamp6evq+ffv27t2b6CwQX5mZmYmOQKgphFDj\nZWRkRCKRQ644ClCjKYSEh0JIYjlkFAAAIKQUQgAAgJBSCAEAAEJKIQQAAAgphRAAACCkFEIA\nAICQUggBAABCSiEEAAAIKYUQAAAgpBRCAACAkFIIAQAAQkohBAAACCmFEAAAIKQUQgAAgJBS\nCAEAAEJKIQQAAAgphRAAACCkFEIAAICQUggBAABCSiEEAAAIKYUQAAAgpBRCAACAkFIIAQAA\nQkohBAAACCmFEAAAIKQUQgAAgJBKSXSA+EpKSkpOTk50CoivSCQSBIG/6kBtkpSUFARBJBLx\n4QYQV5FoNJroDHF04MCB2L8oUIulpKREIpHi4uJEBwE4ZiKRSEpKSllZWWlpaaKzQHylpqYm\nOgKhVstXCPfv3+9bMrVeRkZGJBIpLCxMdBCAYyY1NTU9Pf3AgQN79+5NdBaIr8zMzERHINSs\nngEAAISUQggAABBSCiEAAEBIKYQAAAAhpRACAACEVC2/yigAUBN9/PHH+fn5jRs3PuGEE1yU\nHyB+FEIAoBrZvXv3r371q/feey+22bp16zvuuOPkk09ObCqA2sohowBANTJ16tTyNhgEwebN\nmydNmlRUVJTASAC1mEIIAFQXO3fufOONNw4Z/Oyzz958882E5AGo9RRCAKC6KCgoiEajh49/\n/vnnVR8GIAwUQgCgusjMzExK+oIvJ61atar6MABhoBACANVF48aNBwwYcMhgu3btevbsmZA8\nALWeq4wCANXI6NGji4uLly9fHts89dRTb7311rS0tMSmAqitIl94pH6tUVhYWFxcnOgUEF8Z\nGRmRSKSgoCDRQQCOmd27d+/YsaNhw4axj7hEx4E4yszMTHQEQs0KIQBQ7TRp0qRDhw779u3b\nu3dvorMA1GbOIQQAAAgphRAAACCkFEIAAICQUggBAABCSiEEAAAIKYUQAAAgpBRCAACAkFII\nAQAAQkohBAAACCmFEAAAIKQUQgAAgJBSCAEAAEJKIQQAAAgphRAAACCkFEIAAICQUggBAABC\nSiEEAAAIKYUQAAAgpBRCAACAkFIIAQAAQkohBAAACCmFEAAAIKQUQgAAgJBSCAEAAEIqEo1G\nE50B+EamTZtWXFz8i1/8ItFBAI6ZDRs2zJ8/v3fv3n379k10FoDazAoh1HgvvPDCkiVLEp0C\n4Fjavn37X/7ylw8//DDRQQBqOYUQAAAgpBRCAACAkFIIAQAAQspFZQAAAELKCiEAAEBIKYQA\nAAAhpRACABxj27ZtGzRo0IYNGxIdBOArpCQ6AITUpk2bsrOzc3NzFy5c+GVztm/fvmDBgtWr\nVxcUFNStWzcrK2vAgAH9+vWLPXrzzTfn5ubGfq5fv37r1q0HDRr03e9+t+KjU6ZMOeGEE8qf\nsLS0dOTIkTt37vzrX/+anJz8NSIBNUtBQcHs2bPff//94uLiDh06jBw58uSTTz58WhV/2lQH\nH3zwQf369Tt27JjoIAAJphBCArz22mt/+MMfunfvXv4d63B5eXl33HFH06ZNhw8fnpWVdfDg\nwbfffvuRRx7ZvHnzlVdeGZtz/vnnX3HFFUEQFBUVrVixIjs7u02bNieddFLs0fT09OXLl48e\nPbr8OVevXv1l15GqTCSgxrn//vvr1Klz33331atXb968eRMnTpw5c2bdunUrzqniT5uvrbS0\n9Bh2y4ULF5555pkKIYBCCAlQXFz80EMPffLJJytXrvyyOdOmTWvSpEl2dnb5F6BOnTqdeOKJ\nn376aTQajUQiQRDUrVs3MzMz9uhVV13117/+NS8vr/wrWo8ePVauXDly5Mi0tLTYyPLly7t1\n6/bqq69+vUhAzbJ79+4WLVpceeWVbdq0CYJgxIgR11xzzcaNGw9ZJKzKT5uDBw/+8Ic/vOGG\nG1asWLF169Z69eqNGDGiZ8+eQRDk5eXNnDkzJycnGo126tRpzJgxrVq1Ki0tveSSS2688can\nn366c+fON9988xdOi0ajgwcPvvnmm1988cXNmzc3btz41ltvffnll9955509e/YMGTLk0ksv\nrRjjrrvu+uc//7lmzZqXXnrp17/+9Y9//ONJkyZ16dIlCIItW7aMHj36sccea9my5eDBg2+7\n7baXXnpp69atpaWlV1xxRWzVdOfOnTNmzHj33XeTk5NPPPHEUaNGHX/88UEQrF+/ftq0aRs2\nbGjZsuWPf/zjY/hHCRA/ziGEBOjXr1+zZs2OMGHHjh1r16699NJLD/l1eO/evX/yk5/Evp9V\nVFJSsmzZsvr163fr1q18sGPHjo0aNVq1alVss7Cw8N133z377LO/XiSgxmnUqNHtt98ea4NB\nEHz++eeRSKRJkyYV51Txp03sVRYtWnTHHXfMnj170KBBv/71r7dt2xYEwQMPPJCRkTFr1qxZ\ns2bVrVs3Ozs7Nj8SiSxbtuzOO+8cM2bMl02LRCJJSUlLly69++67Z82aVb9+/TvvvPOkk06a\nPn36DTfcMHfu3MLCwooxJk2a1KxZs1GjRsV2/0Kx51ywYMEvfvGLGTNmDB06dPr06fv37w+C\n4Le//W0QBDNnzpw9e/bJJ5989913HzhwIBqN/upXv8rKypo7d+7dd9+9dOnSI/zRAFQfVgih\nOtq6dWsQBLFfOR/BCy+88MorrwRBcODAgYYNG/7P//xP06ZNK07o37//8uXLzzvvvCAI/va3\nv3Xp0uWQCUBI7N69+3e/+93FF19cvtAXk5BPm/PPPz89PT0Igu9973uPP/746tWrL7zwwgce\neCA1NTV2OOt55503efLk2PpkJBLp2bNn+QmKXzYtCIK+ffvWr18/CILOnTtv27btO9/5ThAE\nXbt2LSsr++yzz2KveLT69esXeyNnnnnmY489Fuuua9asmTNnTqNGjYIguOKKK5YsWfL2229n\nZmZu27bt8ssvr1u3bt26dQcPHrx27dqv8YoAVUwhhOooJSUlCIKysrLykcsvvzz2m+kgCO68\n887YEVZ9+vT5yU9+EgTBgQMHcnJypk6detVVVw0YMKB8r/PPP//JJ5/cunVry5YtX3755dhk\nIGz+85//TJw48Vvf+tY111xzyEMJ+bRp1apV7IekpKSMjIzt27cHQbB+/foFCxZs3bo1Go0e\nOHCgtLS0rKwstqLYunXr8n2PMK28gqalpZX/nJqaGot9tP/RYsoRrJ5lAAAJ+0lEQVQPnYg9\nz8GDB/Pz84MgGDZsWMVpsTyRSKR58+axkfKFWYBqTiGE6qhly5ZJSUmffPJJ+QUPJk+eHPvG\ndtttt5V/dWvQoEH596r27dsXFhbOnz+/4le0Jk2anHHGGS+//PJZZ521Y8eOs84665NPPqna\ntwIk2Jo1ax588MGf/vSnAwcOPPzRhHzaVOyfZWVlaWlp27ZtmzBhwk9+8pPx48enpKS89dZb\n999/f/mcWBkLguDI0w4/wPVrqJjtC58zNrJgwYLyEyZjVqxYUXGztLT0m4cBqALOIYTqqFGj\nRj169Hj22WfLf0/ftm3bdu3aHfmwrmg0eshXmSAI+vfv/8Ybb6xcufK73/1ubCkACI8PP/zw\nwQcfvOWWW76wDQYJ+rTZtGlT7Ifi4uKCgoLMzMycnJyysrJLL700tmNOTs4X7ljJaUclNTU1\nEomUlJTENmMHhR5BbLly/fr15SOxw24zMzOj0WhstTMIgo0bN37zbABVQCGEBNixY0d+fv7u\n3buDIMjPz8/Pz499FVu+fPnixYtjc6699tqysrLbbrvtjTfe2LRp04YNG1asWDF27NgGDRq0\na9cuNmf//v2x3bds2fLaa68999xz55577iGvdeaZZ+7du3flypUXXHDB14gE1FwHDx6cMmXK\noEGDjj/++Pz/SvinTRAEf/vb3z799NPi4uK//OUv0Wj0rLPOyszMLC0t/fDDD6PR6KuvvvrB\nBx8EQVBQUHDIjpWcVhl16tTZsmXL7t27k5OTW7Vq9e6778be5pIlS468Y9u2bbt27Tpr1qz8\n/PzS0tJly5bdcMMNO3bsOOWUUxo1avTUU0/t2bMnLy/v+eef/xqpAKqe5QJIgLFjx5b/Evrq\nq68OgmDUqFGDBg16//33d+3adfHFFwdB0LRp06lTp/75z3+eN2/e9u3bk5OTs7Kyevfu/YMf\n/CB21YQgCF555ZXYZR5SU1ObN29+0UUXHXJp9SAIkpOT+/Xrt2bNmg4dOnyNSMfybQNV66OP\nPtq6dev8+fPnz59fPjh69OiBAwcm8NMmCIKBAwc++uijubm5LVq0+OUvf9moUaNOnToNHTp0\n0qRJkUikd+/ed99997hx426++ebY9TzLVXJaZQwYMGDOnDlvvvnmjBkzrr322kcffXTVqlXH\nHXfclVde+dZbbx35gM9bbrll5syZ119/fVlZWfv27e+9996MjIwgCMaPHz99+vQRI0a0atVq\nxIgR9913nwNHgeovcszvGwsA8IVi9xW89957zzjjjERnASAIHDIKAAAQWgohAABASDlkFAAA\nIKSsEAIAAISUQggAABBSCiEAAEBIKYQAAAAhpRAC1Fr33ntvJBJp3rx5cXHx4Y/+7Gc/i0Qi\n55577td78ssvv7xhw4aVmXnuueeecsopX+9VAIC4UggBarOkpKSCgoJly5YdMr5///5nn302\nLS0tIakAgGpCIQSozZKSknr16vX4448fMr5o0aK9e/eeccYZiQgFAFQXCiFAbVZSUjJkyJAl\nS5Z8/vnnFcfnzJnTt2/fQ1YIly1b9p3vfKdRo0b16tU7/fTTH3744fJ71Uaj0QkTJrRt27Zu\n3bpdunRZsGBBJBKpuO8bb7zRv3//xo0b16tXr3v37rNmzfrCPFu2bPnZz37Wrl27unXrtmzZ\n8tJLL123bt0xfccAwFFQCAFquUsuuaSkpOSpp54qH9m2bduLL754+eWXHzx4sHxw4cKFAwcO\nDILg8ccff+65584+++xbbrll7NixsUcnT548fvz4Pn36LF68+K677ho/fvx7771Xvu/KlSv7\n9u1bXFw8b968RYsW9erV65prrnnooYcODzN06NDnn3/+nnvuWbp06UMPPfTxxx+fd955RUVF\n8XrzAMARRcp/+wtALXPvvffed999+/btu/jii3fs2PHOO+/ExqdOnfrLX/7ys88+69+/f0pK\nyuuvvx4Ewamnnrp3796cnJw6derEpsXK25YtW5o0aZKVlZWRkfGPf/wjtjC4efPm9u3bp6Wl\n7dmzJwiCHj16FBQUfPTRR+X7Dh48+O9///uWLVvq1at37rnn5ufnr1u3bteuXenp6bfffvsD\nDzwQm/bvf//76aefHj58eOvWrav4Pw4AEFghBAiDESNGrF69eu3atbHNOXPmDBkypFGjRuUT\nNm/evG7dugsvvLC80QVBMHDgwOLi4jfffDMvL2/z5s39+vUrP0y0devWPXr0iP2cn5+/evXq\nAQMGRKPR/f/1gx/8oLCwcPXq1RVj1K9fPzMz8+mnn37llVfKysqCIOjQocMvf/lLbRAAEkUh\nBKj9LrnkkkaNGsUuLfPhhx++++67w4YNqzhh06ZNQRBkZWVVHIz1tC1btmzdujUIgubNmx/+\naBAEeXl5QRBMnz69XgVjxowpf9pyKSkpS5cujUQiF1xwQbNmzS677LKnnnqqtLT0GL9bAKDS\nUhIdAIC4q1+//o9+9KN58+Y98MADc+bMadWqVf/+/StOiC39VTylMAiC2DkFkcgXn1xQXuRi\n+44cOfLnP//5IXM6dux4yMiZZ56Zm5v76quvvvDCC8uWLfvTn/70yCOPrFixouLKJABQZRRC\ngFAYPnz4rFmzXn/99aeffvqnP/1pcnJyxUfbtm0b/Hetr9x//vOfIAiysrKaNWsWBMFnn31W\n8dFPP/009sPxxx8fBEFZWVmvXr0qkyQ5Oblv3759+/b9zW9+89hjj40ZM+aZZ545ZMUSAKga\nDhkFCIU+ffqccMIJkydP3rBhw+Htq0WLFl26dHn++ef37dtXPrhw4cL69ev37t27ffv2mZmZ\n5Sf+BUGwbt26Dz74IPZzkyZNevbsuXDhwp07d5bvO2fOnHHjxpWUlFR8lXfeeefyyy/ftm1b\n+UhsobLiCABQlRRCgFCIRCLDhg1bsmRJt27dunbteviEX//61zt27Ojfv/+f//znxYsX//Sn\nP122bNndd9/duHHjpKSka6+99qOPPho6dOiCBQumTZs2YMCAb3/72+X7Pvjgg0VFRX369Jk7\nd+5LL7109913jxo1avPmzSkp/7/jUNq0afPCCy/0799/1qxZy5cvf+qpp6688so6depcfPHF\ncX//AMAXccgoQFgMGzbsvvvu+7KDMwcOHLh06dJJkyYNHz68pKSkc+fOs2bNGjlyZOzR8ePH\nFxcXP/7448uWLevUqdOUKVNWrlz5/vvvxx4977zzVqxYMWHChOuuu664uLhDhw4TJkwov4dh\nuVatWr366qsTJky46667CgoKmjZt2rNnz1dffbVTp07xe9cAwBG4DyEAAEBIOWQUAAAgpBRC\nAACAkFIIAQAAQkohBAAACCmFEAAAIKQUQgAAgJBSCAEAAEJKIQQAAAgphRAAACCkFEIAAICQ\nUggBAABC6v8DGNbAAO7dFrwAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- new.get_result(result.m05.1, '1.GBM 1')\n",
    "errors.2 <- new.get_result(result.m05.2, '2.GBM param tuned')\n",
    "\n",
    "x <- errors.1\n",
    "x <- rbind(x, errors.2)\n",
    "\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6d5142-2f6f-4a02-a902-047b11d9a798",
   "metadata": {},
   "source": [
    "### save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "120fef0e-57e6-41e7-ae91-5608745ac02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x <- result.m05.1\n",
    "#write.csv(x, file = \"gbm_result_m0501.csv\")\n",
    "x <- result.m05.2\n",
    "write.csv(x, file = \"gbm_result_m0502.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8a8c50-2cdd-4346-9796-f3fa26f85ebf",
   "metadata": {},
   "source": [
    "### load result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2934e69f-478c-4b34-9e90-2334ec83da27",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.m05.1 <- read.csv(file = 'gbm_result_m0501.csv')\n",
    "result.m05.2 <- read.csv(file = 'gbm_result_m0502.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec947a05-e8a1-497a-8ce4-36da525d0607",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m05 <- result.m05.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb209ef-30c2-4407-b353-1a388b17d202",
   "metadata": {},
   "source": [
    "# Model Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9a63c6f-09de-4820-a6e8-a454f4973d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.1 <- new.get_result(result.m01, '1. Prophet')\n",
    "errors.2 <- new.get_result(result.m02, '2. BSTS')\n",
    "errors.3 <- new.get_result(result.m03, '3. ARIMA')\n",
    "errors.4 <- new.get_result(result.m04, '4. ARIMA+GARCH')\n",
    "errors.5 <- new.get_result(result.m05, '5. Gradient Boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27d10fd6-6a42-4cc0-8441-08220c600b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAAJYCAIAAAD9hIhNAAAACXBIWXMAABJ0AAASdAHeZh94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\nSCkEhAAAAAAAAFLq/wB3rWDX9x2ldAAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 300,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.list <- list(errors.1, errors.2, errors.3, errors.4, errors.5)\n",
    "x <- errors.list[[1]]\n",
    "for (e in errors.list[2:length(errors.list)]) {\n",
    "    x <- rbind(x, e)\n",
    "}\n",
    "\n",
    "my.figsize(10, 5)\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d4f22d9-79fa-4da9-a7fe-e1d6e0ea5a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "write.csv(x, file = \"result_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d936bf5f-28e1-4d22-a9cf-5a14c33be20e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
