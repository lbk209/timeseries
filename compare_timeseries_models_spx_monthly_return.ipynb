{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403b7c49-b1e4-4567-b300-d0cf4343f1ef",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589d964f-db11-4ee9-b31e-43a56aa2ed1c",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c83acee-3f1c-4594-883d-7c9aa7615e83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: xts\n",
      "\n",
      "Loading required package: zoo\n",
      "\n",
      "\n",
      "Attaching package: ‘zoo’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n",
      "\n",
      "Loading required package: TTR\n",
      "\n",
      "Registered S3 method overwritten by 'quantmod':\n",
      "  method            from\n",
      "  as.zoo.data.frame zoo \n",
      "\n",
      "Loading required package: parallel\n",
      "\n",
      "\n",
      "Attaching package: ‘rugarch’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    sigma\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(quantmod)\n",
    "library(forecast)\n",
    "library(rugarch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f76fd154-b6aa-4ba4-aac9-d547d3227669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Rcpp\n",
      "\n",
      "Loading required package: rlang\n",
      "\n",
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:xts’:\n",
      "\n",
      "    first, last\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Loading required package: BoomSpikeSlab\n",
      "\n",
      "Loading required package: Boom\n",
      "\n",
      "Loading required package: MASS\n",
      "\n",
      "\n",
      "Attaching package: ‘MASS’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    select\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘Boom’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    rWishart\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘BoomSpikeSlab’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    knots\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘bsts’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:BoomSpikeSlab’:\n",
      "\n",
      "    SuggestBurn\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘xgboost’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    slice\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(prophet)\n",
    "library(dplyr)\n",
    "\n",
    "library(bsts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a36dd52-ad96-4245-9985-ef4ee04f7323",
   "metadata": {},
   "source": [
    "### user's defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c1cae5f-cb19-423f-9f75-23355f2b58d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path <- '~/works/utils/r'\n",
    "source(paste(path, \"myutils.r\", sep='/'))\n",
    "source(paste(path, \"myarimagarch.r\", sep='/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1ca76d8-f191-41d9-b2f7-320cad9fd35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new.get_result <- function(x, group, group.col='Models',\n",
    "                          #errors=c('rmse','mape'), # unconditional forecast\n",
    "                          errors=c('rmse.mean','mape.mean') # daily forecast\n",
    "                          ) \n",
    "{\n",
    "    y <- my.get_result(x, group, errors=errors, group.col=group.col)\n",
    "    colnames(y) <- c('rmse','mape',group.col)\n",
    "    return(y)\n",
    "}\n",
    "\n",
    "new.plot_errors <- function(x, group.col='Models', ...) {\n",
    "    my.plot_errors(x, metrics=c('rmse'), group.col=group.col, ...)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81965efe-0310-4a8f-bab8-f7d92d9d839f",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b7c1c3-673b-420b-9e3c-c94ac7936b24",
   "metadata": {},
   "source": [
    "### S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae10fdf1-3592-4ea5-8ae2-d5917a507e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start <- '1991-01-01'\n",
    "train_end <- '2019-12-31'\n",
    "\n",
    "test_start <- '2020-01-01'\n",
    "test_end <- '2020-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee333ae3-056f-4986-aef5-64e8a03fcc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'^GSPC'"
      ],
      "text/latex": [
       "'\\textasciicircum{}GSPC'"
      ],
      "text/markdown": [
       "'^GSPC'"
      ],
      "text/plain": [
       "[1] \"^GSPC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from <- train_start\n",
    "to <- test_end\n",
    "getSymbols(\"^GSPC\", from=from, to=to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "214a3960-5dd7-47be-90ef-2e258d043250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spx <- GSPC\n",
    "colnames(spx) <- c('o','h','l','c','v','a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019dcc7f-aabe-4e1a-bced-ba8dcc21036b",
   "metadata": {},
   "source": [
    "### Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8becee7d-33dc-4db2-bab9-71e87158d6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookahead <- 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb9af71-95b5-4285-93a0-0e5913510963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               logret\n",
       "1991-01-31 0.05216129\n",
       "1991-02-01 0.06360416\n",
       "1991-02-04 0.08173788\n",
       "1991-02-05 0.10755822\n",
       "1991-02-06 0.12847341\n",
       "1991-02-07 0.13502311"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spx.ret <- diff(log(spx$a), lookahead)\n",
    "spx.ret <- na.omit(spx.ret)\n",
    "colnames(spx.ret) <- 'logret'\n",
    "head(spx.ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "651c6501-6ff3-4d97-a129-65e3ee317cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train <- window(spx.ret, end=as.Date(train_end))\n",
    "test <- window(spx.ret, start=as.Date(test_start), end=as.Date(test_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf7c574-fcaf-41e8-a22e-97b2caadd84a",
   "metadata": {},
   "source": [
    "## CV Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ad305fe-7f89-4186-a651-1873d64ef6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR <- 252\n",
    "\n",
    "#hori <- floor(YEAR/2)\n",
    "#hori <- floor(YEAR/6)\n",
    "hori <- floor(YEAR/12)\n",
    "\n",
    "#peri <- floor(hori/2)\n",
    "#peri <- hori*2\n",
    "peri <- hori\n",
    "\n",
    "#wind <- 5*YEAR\n",
    "#wind <- 7*YEAR\n",
    "wind <- 9*YEAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f16cf2d-16cb-45ad-adb3-4dfc8bcfda22",
   "metadata": {},
   "source": [
    "### testing\n",
    "- rerun Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6af023f6-9782-43de-ad8a-60f12ef422a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start <- '1991-01-01'\n",
    "train_end <- '2000-12-31'\n",
    "#train_end <- '1998-12-31'\n",
    "#train_end <- '1997-12-31'\n",
    "train <- window(spx.ret, start=as.Date(train_start), end=as.Date(train_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "493d63b9-0a03-4771-9aa1-53e0d58166f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"number of iterations: 476\"\n"
     ]
    }
   ],
   "source": [
    "sample.r <- 0.1\n",
    "#sample.r <- 0.05\n",
    "\n",
    "n <- (nrow(train) - wind - hori)/floor(peri) * round(hori * sample.r)\n",
    "print(paste('number of iterations: ', round(n), sep=''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a0b3d6-8fa4-4911-9127-b372ec88ba57",
   "metadata": {},
   "source": [
    "## Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f87d6209-3593-4659-b754-eef50734902f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x <- RSI(spx$a)\n",
    "trainx <- merge(train, x, join='left', fill=NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "063c43c3-688b-49ac-a6e2-89690219b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use close instead of adjusted to make consistent with \"un-adjusted\" high & low\n",
    "x <- BBands(spx[,c('h','l','c')])\n",
    "x <- x$pctB\n",
    "trainx <- merge(trainx, x, join='left', fill=NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff082501-d546-4510-bf61-43cfec923f72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x <- MACD(spx$a)\n",
    "x <- x$macd - x$signal\n",
    "trainx <- merge(trainx, x, join='left', fill=NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "befa6d49-0a1c-4bc7-8083-45ac91a02823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    y      rsi    bbands        macd\n",
       "1991-02-19 0.10602550 72.59254 0.8419486 -0.03641515\n",
       "1991-02-20 0.09798126 66.25313 0.7706927 -0.18551057\n",
       "1991-02-21 0.10585688 66.00481 0.7330987 -0.30953562\n",
       "1991-02-22 0.10194779 66.54491 0.7402938 -0.39546732\n",
       "1991-02-25 0.09259647 67.84742 0.7305630 -0.43573971\n",
       "1991-02-26 0.07655978 60.80133 0.6379610 -0.55105032"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                    y      rsi    bbands       macd\n",
       "2019-12-23 0.03808252 76.15462 0.9680588 0.15430304\n",
       "2019-12-24 0.03571448 75.83204 0.9028770 0.14089335\n",
       "2019-12-26 0.03335029 78.41506 0.9189083 0.14916039\n",
       "2019-12-27 0.03119111 78.43159 0.8946206 0.13732115\n",
       "2019-12-30 0.02122778 68.77901 0.7837726 0.07574999\n",
       "2019-12-31 0.02818876 70.74366 0.7500170 0.04243151"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colnames(trainx) <- c('y','rsi','bbands','macd')\n",
    "trainx <- na.omit(trainx)\n",
    "head(trainx)\n",
    "tail(trainx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5049d74b-5700-4b0c-af48-c2d74dc6d9cd",
   "metadata": {},
   "source": [
    "# Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9653be84-20b9-4aad-b230-55cfa4fc581c",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "2842860f-ca3a-4757-9d7e-a0f608b8b9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast <- function(x, h, xreg=NULL, xreg.msize=NULL, result.error=TRUE) {\n",
    "    \n",
    "    check.ds <- function(x) {\n",
    "        d <- try(as.POSIXct(x$ds, format = \"%Y-%m-%d\"), silent=T)\n",
    "        if ((sum(is.na(d))>0) | (is.element(\"try-error\", class(d))))  {\n",
    "            #print(\"That wasn't correct!\")\n",
    "            x$ds <- seq(as.Date('1901-01-01'), length.out=length(x$ds), by=1)\n",
    "        }\n",
    "        return(x)\n",
    "    }\n",
    "    \n",
    "    model <- prophet()\n",
    "\n",
    "    if (!is.null(xreg)) {\n",
    "        ### convert data for prophet\n",
    "        #x <- ifelse(is.null(dim(x)), data.frame(x), x) # not works\n",
    "        if (is.null(dim(x))) {x <- data.frame(x)}\n",
    "        colnames(x) <- 'y'\n",
    "        x.train <- cbind(x, xreg)\n",
    "        x.train <- as.data.frame(x.train)\n",
    "        x.train <- cbind(ds=rownames(x.train), x.train)\n",
    "        rownames(x.train) <- NULL\n",
    "        x.train <- check.ds(x.train)\n",
    "\n",
    "        ### add regressors before fitting\n",
    "        for (c in colnames(xreg)) {\n",
    "            model <- add_regressor(model, c)\n",
    "        }\n",
    "\n",
    "        ### fit: must run after add_regressor and before make_future_dataframe\n",
    "        model <- fit.prophet(model, x.train)\n",
    "\n",
    "        ### prepare future ds\n",
    "        future <- make_future_dataframe(model, periods=h)\n",
    "\n",
    "        # regessor assumption for future\n",
    "        if (is.null(xreg.msize)) {\n",
    "            xreg.m <- xreg # calc mean for future with all the xreg\n",
    "        } else {\n",
    "            # calc mean for future with xreg of length xreg.mszie\n",
    "            xreg.m <- tail(xreg, n=xreg.msize)\n",
    "        }\n",
    "        \n",
    "        if (is.null(dim(xreg))) {\n",
    "            xreg.h <- mean(xreg.m)\n",
    "        } else {\n",
    "            xreg.h <- colMeans(xreg.m)  \n",
    "        }\n",
    "\n",
    "        # rbind history & future of xreg\n",
    "        xreg.all <- data.frame(xreg)\n",
    "        xreg.coln <- colnames(xreg.all) # save name for the case of single xreg\n",
    "\n",
    "        xreg.h <- data.frame(xreg.h)\n",
    "        colnames(xreg.h) <- colnames(NA)\n",
    "        xreg.h <- t(xreg.h)\n",
    "        xreg.h <- as.ts(xreg.h[rep(seq_len(nrow(xreg.h)), h), ])\n",
    "        xreg.h <- data.frame(xreg.h) # convert to frame for the case of single xreg\n",
    "        \n",
    "        # update future\n",
    "        if ((dim(xreg.h)[2]==1) & (dim(xreg.h)[1]==length(xreg.coln))) {\n",
    "            xreg.h <- t(xreg.h) # the case of h==1\n",
    "        }\n",
    "        colnames(xreg.h) <- xreg.coln # match name to rbind\n",
    "        #xreg.all <- rbind(xreg.all, xreg.h)\n",
    "        xreg.all <- rbind(as.matrix(xreg.all), xreg.h) \n",
    "        xreg.all <- data.frame(xreg.all, row.names = NULL) \n",
    "        xreg.all$ds <- future$ds\n",
    "        future <- xreg.all\n",
    "\n",
    "    } else {\n",
    "        x.train <- data.frame(ds=index(x), y=as.numeric(x))\n",
    "        x.train <- check.ds(x.train)\n",
    "        model <- fit.prophet(model, x.train)\n",
    "        future <- make_future_dataframe(model, periods=h)\n",
    "    }\n",
    "\n",
    "    fc <- predict(model, future)\n",
    "    if (result.error) {\n",
    "        fc <- list(method = \"Prophet Forecasting\", mean=tail(fc$yhat, h))\n",
    "    } else {\n",
    "        fc <- list(model=model, pred=fc)\n",
    "    }\n",
    "    return(fc)\n",
    "} \n",
    "\n",
    "prophet.forecast <- cv.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39380c4f-4777-4631-8192-1023e1350df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc error of prediction of sample.n selected from h period \n",
    "cv.forecast.2 <- function(x, h, xreg=NULL, xreg.msize=NULL, sample.n=0) \n",
    "{\n",
    "    result.rmse <- c()\n",
    "    result.mape <- c()\n",
    "    train.len <- length(x) - h\n",
    "    my.subset <- function(x, s, e) {\n",
    "        if (!is.null(x)) {\n",
    "            #x <- subset(x, start=s, end=e)\n",
    "            #x <- subset(as.ts(x), start=s, end=e)\n",
    "            x <- subset(ts(x), start=s, end=e)\n",
    "        }\n",
    "        return(x)\n",
    "    }\n",
    "    idx <- 0:(h-1)\n",
    "    if ((sample.n>0) & (sample.n<h)) {\n",
    "        idx <- sort(sample(idx, sample.n))\n",
    "    }\n",
    "    for (i in seq_along(idx)) {\n",
    "        trlen <- train.len+idx[i]\n",
    "        x.train <- my.subset(x, 1, trlen)\n",
    "        xreg.train <- my.subset(xreg, 1, trlen)\n",
    "        fc <- cv.forecast(x.train, 1, xreg=xreg.train, xreg.msize=xreg.msize)\n",
    "        result.rmse[i] <- sqrt(mean((fc$mean - x[trlen+1])^2))\n",
    "        result.mape[i] <- mean(abs(1 - fc$mean / x[trlen+1]))\n",
    "    }\n",
    "    e <- list(rmse.mean=mean(result.rmse), rmse.sigma=sd(result.rmse), \n",
    "              mape.mean=mean(result.mape), mape.sigma=sd(result.mape))\n",
    "    return(e)\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e0fb38-d451-44d8-8834-ba4d69d19781",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dd96713-bac0-45e7-acee-91b3db181205",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"10 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"20 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"30 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"40 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"50 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"60 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"70 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"80 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"90 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m01.1 <- my.tsCV.2(train, cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          silent=F,\n",
    "                          sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ac8981d-15bf-408c-9638-7b4754cbf984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-01-24\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m01.1\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c1ddd0-be96-456c-878f-5386005d6092",
   "metadata": {},
   "source": [
    "## Additional regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5003bce6-1677-46e3-a84f-18b57b7872bc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"10 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"20 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"30 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"40 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"50 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"60 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"70 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"80 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"90 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m01.2 <- my.tsCV.2(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          xreg=trainx[,2:4], \n",
    "                          sample.n=round(hori*sample.r),\n",
    "                          silent=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2d5fe22-e405-4131-96d3-1cf18723f552",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"10 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"20 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"30 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"40 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"50 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"60 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"70 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"80 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"90 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m01.3 <- my.tsCV.2(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          xreg=trainx[,3], \n",
    "                          silent=F,\n",
    "                          sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ba326e3-2a59-4a52-ab62-c7b71ccb9ea8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"10 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"20 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"30 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"40 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"50 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"60 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"70 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"80 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"90 % done.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n",
      "Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m01.4 <- my.tsCV.2(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                         xreg=trainx[,2:4], \n",
    "                         sample.n=round(hori*sample.r),\n",
    "                         xreg.msize=hori)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfe1cb3-5728-4fd8-a0ef-2593535940f5",
   "metadata": {},
   "source": [
    "## Compare Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "729703b7-0e13-4ac8-9014-dbab6d2d5acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my.figsize(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88224355-62cb-4480-b79c-b2791413a8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94\nAAAgAElEQVR4nOzdd2BTVf/H8U/SppMuKB1Q9pS995a9RBQRRBEFBUXBRxBQER8BEfERFEFQ\nHID8BERAFFmyUUCmLBllFsoqo0BLS9Pm90ewtAVLGCFt7/v1V3POuTffG2PIJ/fcc002m00A\nAAAAAOMxu7oAAAAAAIBrEAgBAAAAwKAIhAAAAABgUARCAAAAADAoAiEAAAAAGBSBEAAAAAAM\nikAIAAAAAAZFIAQAAAAAg3J3dQHOdfnyZavV6uoqjMLf3z8lJeXKlSuuLgQ5lqenp5eXV3x8\nfFJSkqtrQY4VEBCQnJzMRxmcx/5RFhcXx1eUByYoKMjVJQBZVw4PhCkpKcnJya6uwijMZrMk\nXnA4j81mM5vN/H8Np+I9hgeAtxmArIMpowAAAABgUARCAAAAADAoAiEAAAAAGBSBEAAAAAAM\nikAIAAAAAAZFIAQAAAAAgyIQAgAAAIBBEQgBAAAAwKAIhAAAAABgUARCAAAAADAoAiEAAAAA\nGBSBEAAAAAAMikAIAAAAAAZFIAQAAAAAgyIQAgAAAIBBEQgBAAAAwKAIhAAAAABgUARCAAAA\nADAoAiEAAAAAGBSBEAAAAAAMikAIAAAAAAZFIAQAAAAAgyIQAgAAAIBBEQgBAAAAwKDcXV0A\nADhk7969K1asOH/+fFhYWOvWrfPly+fqigAAALI9AiGAbGDhwoXjx49PffjTTz+99957lStX\ndmFJAAAAOQBTRgFkdWfPnp08eXLalqSkpI8++shqtbqqJAAAgJyBQAggq9uxY8e1a9cyNJ47\nd+7QoUMuqQcAACDHIBACyOr+7UxgcnLyA64EAAAghyEQAsjqSpUqdXOjl5dX4cKFH3gtAAAA\nOQqBEEBWV7hw4Q4dOmRofOGFF7y9vV1SDwAAQI7BKqMAsoEXXnihYMGCS5cuPXv2bERExKOP\nPlqrVi1XFwUAAJDtEQgBZANms7l169aPPfaYr6/vpUuXbl5jBgAAAHeBKaMAAAAAYFAEQgAA\nAAAwKAIhAAAAABgUgRAAAAAADIpACAAAAAAGRSDEffPCCy+8+eabrq4CAAAAgKO47QTum337\n9oWGhrq6CgAAAACO4gwhAAAAABgUgRAAAAAADIpACAAAAAAGRSAEAAAAAIMiEAIAAACAQREI\nAQAAAMCgCIQAAAAAYFAEQgAAAAAwKAIhAAAAABgUgRAAAAAADIpACAAAAAAG5e7qAgDAUZGR\nkQcPHixXrlzu3LldXQsAAEBOwBlCANnGxo0b33///cjISFcXAgAAkEMQCAEAAADAoAiEAAAA\nAGBQBEIAAAAAMCgCIQAAAAAYFIEQAAAAAAyKQAgAAAAABkUgBAAAAACDIhACAAAAgEERCAEA\nAADAoAiEAAAAAGBQBEIAAAAAMCgCIQAAAAAYFIEQAAAAAAyKQAgAAAAABkUgBAAAAACDIhAC\nAAAAgEERCAEAAADAoAiEAAAAAGBQBEIAAG6YMGHCnDlzXF0FAAAPCIEQAIAbpk6dunDhQldX\nAQDAA0IgBAAAAACDIhACAAAAgEERCAEAAADAoNxdXQAAAICBJCYmWq1Wq9Xq6kIAQOIMIQAA\nwIM0Y8aMJk2abN++3dWFAIBEIAQAAAAAwyIQAgAAAIBBEQgBAAAAwKAIhAAAAABgUARCAAAA\nADAoAiEAAAAAGBSBEAAAAAAMikAIAAAAAAZFIAQAAAAAgyIQAgAAAIBBEQgBAAAAwKAIhAAA\nAABgUARCAAAAADAoAiEAAAAAGBSBEAAAAAAMikAIAAAAAAZFIAQAAAAAgyIQAgAAAIBBEQgB\nAAAAwKAIhAAAAABgUARCAAAAADAoAiEAAAAAGBSBEAAAAAAMikAIAAAAAAZFIAQAAAAAgyIQ\nAgAAAIBBEQgBAAAAwKAIhAAAAABgUARCAAAAADAoAiEAAAAAGBSBEAAAAAAMikAIAAAAAAZF\nIAQAAAAAgyIQAgAAAIBBEQgBAAAAwKAIhAAAAABgUARCAAAAADAod6fu/cqVK1988cWmTZus\nVmu5cuX69OkTEhJy87ATJ06MHTs2MjJy/vz5t93WwX0CAAAAADLn3DOE48aNO3bs2PDhw8eO\nHevm5vbee++lpKRkGLN27do333wzIiLCwW0d2ScAAAAA4LacGAhjYmL+/PPPV199tXjx4hER\nEf379z9x4sRff/2VYVhSUtJHH31Uq1YtR7Z1cJ8AAAAAgNty4pTRAwcOeHh4FClSxP4wV65c\nBQoUOHDgQOXKldMOa9KkiaSDBw86sm1CQkLm+7RarfHx8an7SUlJMZlMzjk+3BovOJzH/u4y\nmUy8zeBsvMfgPHyUAchSnBgIL1265Ofnl/bDLiAgIDY29l62DQgIyHyfa9euHThwYOrDiRMn\n1qhR454OA3fCZDLlyZPH1VUgx7JYLJK8vb15m8Gp+CiDU7m7u0vy8fHhbQYgK3DuojIZfvqy\n2Wz3vm3m+8ydO3faBOjj45OUlOT4k+Le8YLDeewXDKekpPA2g7PxHoPz2L+6JCcn8zZ7YOy/\nJwK4JScGwsDAwEuXLtlsttQIFxsbGxQUdC/b3nafFStWnDhxYurD2NhYB89J4r6w2Wy84HAe\nq9UqKSEhgbcZnIqPMjgVH2UPXnBwsKtLALIuJy4qU7JkyaSkpMjISPvD2NjYqKio0qVL38u2\n97JPAAAAAEBaTgyEQUFBdevWHT9+fGRkZFRU1Mcff1y8ePGyZctKWrZs2c8//2wfduHChZiY\nmMuXL0uKiYmJiYlJSEj4t20z2ScAAAAA4I449xrCvn37fvnll2+//XZKSkrlypX79+9vn+q5\nffv2S5cutWvXTtLAgQPPnDljH//cc89J6tmzZ/v27f9t239rBwAAAADcEecGQh8fn379+vXr\n1y9De9qFQKdMmXJH2/5bOwAAAADgjjhxyigAAAAAICsjEAIAAACAQREIAQAAAMCgCIQAAAAA\nYFAEQgAAAAAwKAIhAAAAABgUgRAAAAAADIpACAAAAAAGRSAEAAAAAIMiEAIAAACAQREIAQAA\nAMCgCIQAAAAAYFAEQgAAAAAwKAIhAAAAABgUgRAAAAAADIpACAAAAAAGRSAEAAAAAIMiEAIA\nAACAQREIAQAAAMCgCIQAAAAAYFAEQgAAAAAwKAIhAAAAABgUgRAAAAAADIpACAAAAAAGRSAE\nAAAAAIMiEAIAAACAQREIAQAAAMCgCIQAAAAAYFAEQgAAAAAwKAIhAAAAABgUgRAAAAAADIpA\nCAAAAAAGRSAEAAAAAIMiEAIAAACAQREIAQAAAMCgCIQAAAAAYFAEQgAAAAAwKAIhAAAAABgU\ngRAAAAAADIpACAAAAAAGRSAEAAAAAIMiEAIAAACAQREIAQAAAMCgCIQAAAAAYFAEQgAAAAAw\nKAIhAAAAABgUgRAAAAAADIpACAAAAAAGRSAEAAAAAIMiEAIAAACAQREIAQAAAMCgCIQAAAAA\nYFAEQgAAAAAwKAIhAAAAABgUgRAAAAAADIpACAAAAAAGRSAEAAAAAIMiEAIAAACAQREIAQAA\nAMCgCIQAAAAAYFAEQgAAAAAwKAIhAAAAABgUgRAAAAAADIpACAAAAAAGRSAEAAAAAIMiEAIA\nAACAQREIAQAAAMCgCIQAAAAAYFAEQgAAAAAwKAIhAAAAABgUgRAAAAAADIpACAAAAAAGRSAE\nAAAAAIMiEAIAAACAQREIAQAAAMCgCIQAAAAAYFAEQgAAAAAwKAIhAAAAABgUgRAAAAAADIpA\nCAAAAAAG5e7qAgDcH5cuXYqPj3d1Fc51+fJlSRcuXDh16pSra3EuPz8/X19fV1cBAAByPgIh\nkBPExsZ269YtKSnJ1YU8CGPHjnV1CU6XJ0+eGTNmuLoKAACQ8xEIgZzgypUrSUlJvrkT8xS+\n7OpacK9O7wu8cOGCq6sAAACGQCAEco7A/FfKtjrq6ipwr2JPeSdd9XB1FQAAwBAIhA/CDz/8\n8NVXX7m6igfh8OHDLVu2dHUVzmU2mwcNGtSwYUNXFwIAAADcKwLhg3D06FFJ5QL8vMws65q9\nXbZa912Os/8HBQAAALI7AuGD83aZEgV8vFxdBe7JpvOx/bftdnUVAAAAwP3BCSsAAAAAMCgC\nIQAAAAAYFIEQAAAAAAyKQAgAAAAABsWiMgAAhyQmJh47dszVVTidzWZLSEg4cOCAqwtxLrPZ\nXKRIETNrXwOA4REIAQAOmTx58q+//urqKh6Ew4cPv/LKK66uwuleffXV1q1bu7oKAICLEQgB\nAA65fPmypLN16iV7erq6FtwTr5iYwJ1/Xbp0ydWFAABcj0AIALgDp5o0uxYY6OoqcE8Cd+8M\n3PmXq6sAAGQJXDwAAAAAAAZFIAQAAAAAgyIQAgAAAIBBEQgBAAAAwKAIhAAAAABgUARCAAAA\nADAobjsBwOnOHNXKGYr6W9YkhRRSvcdUssZdDj6yU7//qNNHlGxVnnyq3kblG0gmJcTpo6dv\nvcNOg1SqZrqW8yf1xWuyeOr1qffj8AAAALItAiEA5zp/UlPfkm+AGj0lT2/tXKXZo9XpjYwh\nzZHBBzZp9gcKLaL6T8hs1u51+ukTXTyj+p1k8VSblzLu7fBf+vsPBYWlb7Vp4eeyXpOFm6sD\nAADDIxACcK41s5SSomdGKFeQJJWrrykD9Nu3KlVDMt3Z4BUzFBiiZ9+Xu4ckVW6myf214SfV\nf1xu7qrcNN2uEuO1ZqaqtlRIoXTtW5fpxD4VqaBTh511yAAAANkF1xACcCJbivZvUomq1wOe\nJJNZFZvowmmdPnJng202VW6qZs9dT4OSzG6KKKXEeCUl3uKpV/2fkq1q1DVd4+XzWj5NdR9X\nQMj9OkQAAIBsjEAIwIkunNa1qwotnK4xtIikWwTCzAebTKrRViWrp+mz6cxR+QfL4pVxVzFR\n2rJEjbrKyzdd+6Iv5B+suh3v6mAAAAByHKaMGt2us+feWfPHH8dPJiYnl8ub541a1dqVKHp3\ng1cdPT56w+YdZ2KsKcklcge9XKXik2VLmRzrXXLo6IcbNm8/fVZSlbCQ9xrUrp0/3FnHjAfo\nygVJ8g1I12h/aO+6i8HJSboSq8vntHmRzhzVo6/d4nlXfa/AkIyTSPf8rgOb1OMDmd3u/EgA\nAAByIs4QGlrkhYsP/9+c/ecv/rdB7Yktmvh7ejwxb+GCA4fuYvDCyMOtZ8+/mJDwdt0awxvU\n8XRz67Fw6ag/NjnSO2fvgQ5zFlxKvDaqUd1Rjeqev5rQcua8LafOPIBXAM5mTZIkN0u6RvtD\ne9ddDD72t8a/oG+HKOpvPf6GStfOuJ+YKO3dqFqPyJTmE+7qFS2ZouptlK/E3R4MAABAjsMZ\nQkMb+fuf1hTbb106huXylfREmZK1p84ctHJduxJFb1rs4zaD31mzvlCA/4qnHvd2d5fUo2LZ\nql//3yebtg6pU/22vW+v/iM8V65V3R73tVgkdSlbqtyX099e/ceizh0e7OuB+8/9Vtkv+Zqk\nG5cC3ung0MLqPERxl3T4L80epTod1fipdJtsXiwPL5VrkK5x2deyeKpx+ksKAQAADI4zhMaV\nbLP9Enm4VbHC9oAnyc1kerrcQ4cvxu44c/aOBqfYbD0qlh3TpL4970mymM0184XFJl6LT0rK\nvPdMXPyR2EttSxSxp0FJfh4eT5UtvfrY8fMJCU5/FeBkfrklKS797NDLF2503cVgH3+VqK5K\nD+vR/6hWB/3+o6Ijb/SmJGvP7ypeRR5pLiw8tF07Vqv587JJ1xJ0LUEpyZJ0LeEWJyoBAACM\ngzOExnXk4qXL166VDwlO21gpNK+knWdiKobkvaPBfatWTNtlk/bEnIvwy2WPeZn0XkxIlOTl\nlu6irgL+fik2298x5+tG5Lv3I4ULBYbKK5dOpp+GHH1AksKL3dnguFjt3aDwounmfBYsrfXS\nmSPKV/x6y4n9ir+kYpXT7WT/Jsmm2aMyPuOHXVW8qp58624ODQAAIAcgEBrXqbg4SaE+Pmkb\n8/p4Szp5Jf7uBicmJ5+Ji4++Ejdp646dZ89Nbdci7fhb9obl8g3w9Fh3PDrtyM0nT0s6G3/1\nXg8SrmYy6aFa2rFaF88oMESSrEnavlwhhRQccWeDE+O1ZIoiSunp4TL9M6f58E5J6e4hcXyv\nJIUVSbfnmu1Vtl66lj/m6dgePfmWvHPdt4MFAADIdgiExpVgTZbk4ZZu2rCnm5ukxGTr3Q3+\n/Xh061nzJRX095vZoXXrYoXTjr9lr5vJ1LNSuf9t3PrqslX9q1f2cHP7dsfuZUeOSUpKSbk/\nhwqXqv+E9v2p795RjbayeGrbb4o9q67Drvfu36QfRqt5D1Vvc5vBnj6q+5jWzta0t/VQbblZ\ndGyPdq9TRCkVLn/j6WJOSFJQWLoagkIVFJquxXelzG4q8JDTDhsP2KGDmjJZO3coKUlFiqnb\n06pb/y4Hb9ui76bpYKSsySpQQB0fV9PmN36EOLBf30zRvr1KSFC+/Gr3iNq2lznNZ+PxKI34\nr/bt1djxqpT+VDUAAFkPgdC4vNztcS45bWNCcrIkL/eMbwwHB1cMCf6xY9uYq1eXH4l6fO4v\nA2pWfa9B7dv2DqtX6/zVxCnbd32xbaekpoULvle/du/Fy3NZ0i83iezJP1jdR2r5NK2eqZRk\nhRVV12EqXO56ry1FthTZbA4Nbvikcodry2Ktna1kqwJC1OhJ1Wh347u6pPjLMpnSXUCInO/4\ncb36soIC1fNF+fho6WINfVPvva96t8qEmQ/+43e9PUTFi6v7czKbteI3vT9cJ0/qmWclafcu\nvfaKgvOqc1f5+Gj1Ko39SNEn1Pvl6ztfMF8TP1OA/wM68BwnISFh1KhR58+fd3UhzmU/wPHj\nx3t7e7u6FicymUwVKlTo2bOnqwsBcBsEQuMKz+Ur6VRcutmhp67EScqfK+MsOgcH5/H2blO8\niKTu5csU8M/14YbN7UsUrRYemnmvh5vb5y2bjGhY+/DFS+G5fPP75Zqw5S9JhQP5UpVD5Mmv\nJ4bcuqtUTb0919HBkso3VPmGmT1X53/fNq22L6ntSw6NRDYw9WslWzVugvLkkaSHm+mF5zRx\nvOrWS/drgSODp0xWWJjGfy5PT0lq007PPaPZM/V09+u9np6aMElBuSWpTVu92FPz56lXb7m5\nafcuTfhUffrKy0uj33+QL0COER0dvXHjRldX8YAcP37c1SU4XVRUFIEQyPoIhMZVOMA/yMtz\nW/rb/W06eVpS5bC8dzT4bPzV+fsPVgrNWz38xrS8Ovnz/U9bd509VyjAP5PetHExzz+/la46\ndjy3t1fJ3EH37WgB5FQpKfpjnWrVuR7wJJnNatlaEz7VwUgVL3EHg4sVU5t2Cg+/ngYlubur\nbDkt/lWJifLyUrMWatv+ehqUZDKrTFkd2K/LlxUYqMBAff6lihbT4l8fwHHnYPUKPvZkWcd+\n2kEWNnJt54vJ0bcfB8DVuO2EcZlNpg4liy85dPRo7CV7S4I1+dsde8rnDS6dJ+MNATIf7OHm\n9p/fVg9Z9XtK6sw/aeXRKEkFA/wy75X04qLlZb6YljofdceZmF8jD3ctU8rt5p/2ASCDk9GK\nj1fx4ukaS5SUpIORdzbYZNZjnVQnzQJENpsOH1JIiLy8JKl1Wz3cLN22J44rIOD6HNH8ESp6\n0+K5AABkbZwhNLS36tZYcOBQ85nz+lat6GuxfLNj97FLlxc+8Yi995fIw53nLfywSf2Xq1bM\nfHCAp8cbtaqN/OPPpt/P7ViquKeb27qoE7P/3l8zX1ijghFmkymTXkmPlCw2beeeNrN/6l7+\noZj4q//7c2sBf78369Rw4SsDINs4d07SjbN2doGBN7ruYnBSki6c19mzmj9XBw9q6DDd0qqV\n2rxJL/SRiV9XAQDZFYHQ0CL8cq186rE3V/0+fN1Gqy2lUmjIwiceaVjw+t0AUmy2ZJst9bRe\n5oOH1qtZPChw0rYd7//+57WU5EL+/u/Ur/VK1Upmk+m2va2LFZ7WvuVHG7a8unSVj8XSomih\n9xvWye3NqiAAHHDtmiS5p1+DysPjRtddDN7xlwb0l6TQML03UrXr3OJ5N/yhD0aqdh092eUe\nqgcAwMUIhEZXMnfQnI5tb9nVvkTRhDdecXCwpC5lS3UpW+ruejuVLtGpdIl/6wWAf2WPc0np\ns5893aVeCning4uX0MjRir2ozZv01mB1fUo9X0y3yfy5Gj9ODRrqrXc4PQgAyNYIhACA7Cw4\nWJIy3KjAPv/T3nUXgwMCVKeuJLVqo5BQzZiueg1U+p/bVk74VHNmq2s39XzxFquYAgCQrfC7\nJgAgOwsPl5+f9u9N1/j3HkkqedOshMwHX7ygBfO1d0+63vIVJOnQwesPp3yhH+fo9TfUqzdp\nEACQAxAIAQDZmcmsBo20cYNOnbzecu2afv1FRYupUOE7G2yxaPw4fT5RtpQbm2zdLEmhYZK0\neZNmTFPfV9W2vVOPCQCAB4YpowCAbO6ZHlq3Rq+9qsc6yctLC3/R6VMaM/Z67x/rNPRNvfyK\nOna6zWDfXOr6tKZ9o3591bCxLBbt2K4Vy1W2nKpUUXKyPvlYAQHy9NTCn9MVUK26QsO0a6eO\nHpGk3bskacMfOnFckqpUVXi+B/RSAABwhwiEAIBsLiRE4z/XpIn65islJ6tkSY0Zq8pVrvem\n2JSSohSbQ4N7PK+ICP00T1O/kTVJYeHq0VOPPyGTWVdidTxKkj4anbGA4aMUGqali/XzTzca\nZ31//Y+h7xIIAQBZFoEQAJD9FSiokR/cuqtefa1c5+hgSc1aqFmLW7QHBGTcTwb/Gaj/DLxt\npQAAZCk5PBBaLBZ3d9cfo5ubm6tLwP1ksVi8vb1dXUU6Xl7ctjGnyWrvMfFRluNkwY8yz5vv\nFIJsLqu9xwDczPVhydls/9xXHbhfbDZbVntfZbV6cO/4b4oHIKu9zbJaPbh3/DcFsr4cHgiT\nkpKSkpJcXYWSk5NdXQLuJ6vVmpCQ4Ooq0klMTHR1CbjPstp7THyU5ThJSUlZ7W127do1V5eA\n+yyLvMdy5crl6hKArIvbTgAAAACAQREIAQAAAMCgcviUUcBQrl11jz3p4+oqcK+Sk/ipDgAA\nPCAEQiDnOBsZcDYywNVV4D4wEwkBAMADwZcOAAAA4M68++67JpMpJCTklusX9urVy2Qy1atX\n7+52/uSTTzq4EE69evVKly59d88C2BEIAQAAgDtmNpvPnz+/aNGiDO0JCQk//PCDh4eHS6oC\n7hRTRoGcI3fBy4WqnXV1FbhX+1bmT4jlVs4AkNWZzeaaNWt+++237du3T9u+YMGCuLi4atWq\nuaow4I44FAivXLmyaNGiJUuWbNu27ezZsxcvXgwMDMybN2+lSpVatmzZqlUr7u4CZAXeAdfC\nHrrg6ipwrw5tCE2IdXURAG5y8MzOz1e++VfUuiRrYrGQ8t3rvdmg5CN3N3jfqa1frh629+Tm\nq9fi8gcVe7TKi49U6WU2udl7rSlJ034ftfCvb89ejg4NKPBI5V5P1R5okulKwsVmHwXd8ulG\nd5rXoFSH+3u8uC2r1dqhQ4e33nrr3LlzefLkSW2fNm1a48aNExMT096+ddGiRaNGjdq2bZvV\nai1WrNhzzz332muvmUwmSTabbfjw4V9++eXZs2dLlCgxbNgwe3uq33///d133924cWNSUlLp\n0qVfeeWV55577uZ6Tp48+c477yxduvT06dOBgYF169YdOXIkE0pxW7cJhAkJCePHj//www9j\nYmI8PDxKlSpVokSJwMDAixcvnj179rvvvvv666+Dg4MHDRrUt29fLy+vB1N0NnUm8Zqb6fbD\nkJWd46bJAGBIUecP9J5aP8g3pHejkb6e/ot2Ths8+9EPOs29ZQzLfPCu4+tfmt44xD9/11oD\nfDz8Vu398cNFfU5cONi36Rj75sPmPbVq79wuNV8rFV5l0+HlE5YPSky6+nyDYZ4WnyFtvszw\nXH8eXrby7zn5goo6+xXALT366KODBg36/vvv+/bta285c+bMkiVLJk+e/OWXX7q5XQ/58+fP\n79ixY7169b799ls/P785c+a8/vrr0dHRH330kaQxY8YMGzasS5cuPXr0OHfu3LBhw9ImyVWr\nVjVv3rxOnTrfffedt7f33Llzn3/++fPnzw8YMCBDMR07djxy5MiIESOKFCkSHR09evTohg0b\nHj582MeHFciRmcwC4eHDhzt27Lhjx45OnTp17969YcOGGd5PcXFxq1evnjp16qBBg/7v//7v\nxx9/LFKkiJMLzsZe3brL1SUAAIC78dWa/yanWCc+szo4V7ik5uW6PDul6qe/vV6/1CMmZfy5\nN/PBn69809Pi/cWzf+T2DZXUvnLP576q/uOWiX2ajHIzu288uGTF3z/0bz6uc41+kpqV7RKX\nGLvl6Mrn9I7FzaN95Z5pn+hKYuyXa4Z1rNqneEiFB/RCIL38+fM3adLk22+/TQ2E33//vcVi\n6dSp0xdffJE6bMiQIREREcuWLfP09JTUvHnzmJiYTz/9dMiQIblz5/7kk0/Kli07Y8YM+4nB\nBg0aFC5cOPUSxAEDBkRERCxZssS+bbNmzaKjo0eMGPHyyy97e9+4vuDSpUsbNmwYNGjQ888/\nb2+pW7fuzJkzL168SCBE5jJbVKZq1apBQUG7du2aOXNmq1atbn4z+fr6tm7detasWbt27QoM\nDKxataozSwUAAHCBFFvy2v0L6pRoYw94kswmtzYVnz1x4VDk6b/udHDL8t0GtpxgT4OSzCZz\nuYhaCUnxlxMuSFq4Y2ouz4COVXun7nDkYz9MfHrVzbFT0uRVb1uTk15sNOJ+HzHuwLPPPrtl\ny5bdu3fbH06bNq1Dhw5+fn6pA6Kjo/fu3duqVSt7orNr06ZNUlLShg0boqKioqOjmzRpkjpN\nNF++fKnXH8bExGzZsqVly5Y2my3hH61bt46Njd2yZUvaMnx8fIKDg2fOnLl8+bsdN3gAACAA\nSURBVPKUlBRJRYoUGTJkSL58+Zx6+MgBMguEL7/88rJlyx566KHb7uWhhx5atmzZSy+9dP8K\nAwAAyBKiLxyOv3a5RGjFtI0lQytLOnBTILzt4HaVnm9ermva3qjzBwJ9gv2980jadWJ92Yha\nFjdPSSm2lEyqOhyzZ96WSS82Gp7LK/CuDw337tFHH/Xz8/v2228l7dmzZ+vWrc8880zaASdO\nnJAUERGRttGe006ePHnq1ClJISEhN/dKioqKkvT55597p9G7d+/U3aZyd3f/9ddfTSZT06ZN\n8+bN27lz5++//z7t1FPg32Q2ZXT48OFpH169enXLli0nTpx4+OGHg4ODrVaru/uNzd3c3EaM\n4AeqzPQsWjC3B8u6Zm9H4q7Ojjrp6ioAAA9UzJWTklLP6dkF+Yakdt31YEkr/v7hz0PLXmry\ngdlkTrGlnLp4tGbRFj9t+/K79R+eOH8wl1fgw2WeeKXpGB8PvwwbfrFqaL7AIhkmkeLB8/Hx\n6dSp03fffffBBx9MmzYtPDy8WbNmaQfYT/1dS78Mgc1ms3fZ/8ggNcjZt+3Ro8cLL7yQYUzx\n4sUztFSvXj0yMnLNmjWLFy9etGjR7NmzP/vssxUrVqQ9MwnczNF8MmbMmBEjRly6dEnS+vXr\ng4ODhw0bdvLkybTXyyJzTUODC/iw7k72tul8LIEQAIzmmjVBkrtbutvK2U/i2bvuevDvkQuH\nL3i2bom2T9UeKCkxKd4m25+Hlu47tfXFRiP8vXL/eWjp9xvHHr8QOf6p39JueDhmz+q9895o\nPSl1bVK4UPfu3b/++ut169bNnDmza9euGb4bFyhQQP+c60t1/PhxSREREXnz5pV0+vTptL1H\njhyx/1GwYEFJKSkptWrVcqQSNze3xo0bN27cePTo0ZMnT+7du/esWbMynLEEMnAoEE6ZMuWN\nN95o375969at7SepJZUqVerDDz8sWbLk4MGDnVkhACALKT9imKtLAB40D3cvSUnWxLSN15IT\nJHm6Z7xrqOOD52yeMHZJv0alO77b4TuzySzJ3c0iKf7a5Wm9tvt6+kuqUbRZsi155saxu09s\nLJu/Zuq2czdP9PbI1SL91FO4Sv369YsWLTpmzJijR4/enL5CQ0PLly//yy+/XL16NXUZmPnz\n5/v4+NSuXTtXrlzBwcH2C//MZrOkvXv37tixwz4yd+7cNWrUmD9/vv2ub/Ztp02btn///nff\nfTftZL3Nmzd/9NFHn376aersU/uJyjNnzjj56JHtZXYNYarPPvusd+/eP/30U/fu3VMbn3nm\nmYEDB06fPt1ptQEAALheXr98ks7FnUrbeO7ySUl5/fLf3eBxS1/73+K+3WoPHPHYLMs/pxMt\nbp6+nv7FQsrb06BdzaLNJR08szO1JTnF+tueWbWLt/L24EbQWYLJZHrmmWcWLlxYsWLFChVu\nseLrqFGjLly40KxZsx9//PHnn3/u2rXrokWLhg4d6u/vbzab+/Tp8/fff3fs2HHOnDkTJ05s\n2bJl2pUaP/zww/j4+Pr160+fPn3p0qVDhw7t2bNndHR02jQoKX/+/IsXL27WrNnXX3+9bNmy\n77//vlu3bp6enu3atXP68SObcygQ7t2797HHHru53X5vk/tdEgAAQBYSHljEzyto78l0izru\nif5TUunwjEusOzJ40sq3ftj06aDWk/s0GZVh+dCSYZXPXo5O25KUfE2Sxf3GZWC7Tmy4GB9T\nu1irezwu3EfPPPOMPRbesrdNmza//vqr2Wzu3r17p06d9u7d+/XXX6dOshs2bNjgwYM3btz4\n1FNPTZo0ady4cXXq1Em95rBhw4YrVqwIDw9/+eWXH3nkkR9//PG999778suMd6QMDw9fs2ZN\niRIl3nrrrbZt277++ushISFr1qwpVaqU844aOYNDU0YtFsvVq1dvbj99+rTFYrnfJQEAsq6z\ndeolsz5BNucZczZo5w5XV5GdmE3mxg89tmjH9JMXj4QHFpZ0zZqwYPtXxUMqFA7OuBj7bQf/\neWjZ1N/f/0+LTztUybhMiKSmZTqPWfTSxkNL7ScGJS3fM1tSufw3LiHbefwPSSXDKjnhWOGo\nd99999133019WKRIEfvNHlJt2LAh7cMWLVq0aNHilrtyc3MbNWrUqFGjUls6dOgwbty41If1\n6tVbunTpLbddt25d6t8VKlSYM2fOHRwDIMnBQFijRo1x48Y1b948bePFixfHjBnj4BWuAICc\n4VSTZtcCWeM+ewvcvZNAeKeeq//Omn3zX/6uceca/bwsvgu2TTkVe/STrte/o6/dv2DwDx37\nNf/4ieqvZj44OcX6v8V9A32CPd29F2ybkvYpahRtFhZQqF2l53/e/tXgHx7tUvM/+YKKbji4\nePme2W0r9iiQu0TqyKMxeyXlDyr24I4fQM7lUCAcNmzYww8/XKZMGfsPG1988cWkSZPmz58f\nHx8/adIkJ1cIAADgYqH+BSZ3X/fZ8je+XD0sOcVaKqzKJ12XVi3c2N5rs6Wk2JJt/9w2MJPB\nlxMuHju/X9Kohb0yPMXoTvPCAgpZ3Dw+fWrZpJVvLdg+JTb+XGhAwRcbjXi6zqC0Iy/Gx5hN\nZi4gBHBfOBQIGzRosGTJkoEDB37++eeSvvnmG0k1atT48MMP69at69wCAQAAsoCCeUp9+MRP\nt+xqUKrD+rdtjgwO9AnOMPJmfl5BA1tNHNhq4r8NGNN5gQP1AoBDHL0PYZMmTbZs2RITExMV\nFWUymQoVKhQUFOTUygAAAAAATuVoILQLDg4ODg52UikAAAAAgAcps0BYunRpR3axd+/e+1QM\nAAAAAODBySwQcjIQAAAAAHKwzAJh2hub3FJcXFx0dHTmYwAAAAAAWZP5XjbesGFDo0aN7lMl\nAAAAAIAHytFFZRYuXPj9998fO3YsJeX6PXaSk5N3797t6enptNoAAAAAAE7kUCCcOXNmly5d\n3N3dw8LCjh8/ni9fvtjY2Li4uMaNG7/++uvOLhEAJJ06pNUzdTJS1xIVFKYqzVWlmUz/zHI4\nslO//6jTR5RsVZ58qt5G5RtIpuu9e37XpoWKOa5kqwJDVaGxqreSm8VVhwIAyN4uX77sjN36\n+fk5Y7dA5hyaMvrRRx+1bt36/PnzUVFRnp6ey5cvv3jx4ueff+7u7t6wYUNnlwgAx/fpmyGK\niVKtDmraXb4BWjRZy6df7z2wSTPe1dUrqv+EmnSTu4d++kRr51zv3bhAc/+ngBA9+h91flMl\na+i3qZo3zlWHAgAAkIU4FAj379//0ksvpf3Rwt3dvXfv3hUrVhw0aJDTagOA61bOkMVDz45S\nrfaq0lxdhiqsqLYsVkqyJK2YocAQPfu+qrdW1Zbq9l/lya8NP0k2Sdq6TEGh6tBPRSupUDk1\n6qJSNbR3vRKuuPaYAAA536uvvjplyhRXVwFkxqEpo2az2WS6PvXKw8Mj9Sx5+/btn3jiiQkT\nJjirOgA5xfR3lGxVmz5a+pWO75fFQ4XKqUVP5QqUbIr/l6k3Zjd5+UpS+Qaq3Ey+gdfbTSZF\nlNSpQ0qIk7efKjdVYKjcPW5sFVFKf61QUqIsXnK3KNl8Y/qoJA8vmcxMGQUAOJfVat25c2fq\nt2gga3IoEJYuXfqbb75p1qyZxWLJly/fqlWrqlevLuncuXNOmkINIIdxc9eFU/p5vBp0VrvC\nit6veWNlTVLnIboSq3HP3XqrPPnVZ7wkVWqasev8Sfn4y9tPJpNqtE3fZ9OZo/IPlsVLkmo9\nop8+0bofVLmZ3D10eIf+Xq9qrWRhSSwAAGB4DgXCfv36de3a9fLly4sXL27RosXQoUOPHz+e\nJ0+eyZMnV6xY0dklAsgBTNKlGLV/VYXLSZJ/bRVdpcN/STZ559JT7956q3/LbH//oUN/qcnT\nSvura3KSrsTq8jltXqQzR/Xoa9fbyzeUm7t+maBV30uSyaS6j6vRk/fryAAAALIxhwJhly5d\nzGbzsWPHJL377rt///33p59+KqlAgQKffPKJcwsEkFO4WVS47I2H/rllvaaka7J4qkiFO9hP\n5BYtGK8S1VS7Q7r2Y39rxruSFJBXj7+hEtX+ad+jXyaqUDlVaSZ3T0Vu0e8/yt1d9Trd2/EA\nAAxvzZo1mzdv/rde+93aTpw48fHHH2eykw4dOhQtWvT+Fwc4xtH7EHbu3Nn+R1BQ0NKlS6Oj\noy9dulSsWDGLhatwADjExy/dhXz2O0bYbHe2k82LtOQrla6lDv2V4aKM0MLqPERxl3T4L80e\npTod1fgp2Wz6ebxyh+uJIdfHF6mglGStnqky9ZQ7/B6PCQBgaNOnT4+MjMx8zLlz537++edM\nBnh5eb300kv3tS7gDjgaCE+ePDlnzpxXXnnF/tBiscyePbtXr17h4XyfAnBvHFhUxm7p1/rz\nF9XpqCZPpcuWdj7+KlFdkio9LP+8+v1Hlaopbz9dOK26j6VLj0UqatOvOr6PQAgAuCc2m83T\nbP6uVqW723z/5bi3du6z3emPoy7i7u4+Z86cDh063H4oshWHAuG+ffsaNWp0/vz51EAYHx8/\nbNiwSZMmrVmzpnjx4s6sEEAO58iiMpJWztCmhWrdW1WapxsTF6u9GxReVPlK3GgsWFrrpTNH\nFFFKkpKT0m1if5hsvU8HgBzjwH59M0X79iohQfnyq90jatte5n/uz7Rti76bpoORsiarQAF1\nfFxNm9/4pWHVCv34g44elTVJ4fnUopUefUxMogEMwGRSPm+vu9v2wrWk2w9KY9++fd27d9+8\nebPVeut/w6pVq7Zlyxb73xaLpWDBgl27dn3zzTe9vO6ywnuxYsUKf3//atWq3X4oXMqhQDh4\n8OBcuXItWLAgtaVQoUJ79uxp37794MGD58yZk8m2AJA5RxaVOfSXfv9RLXpmTIOS3C1aMkUR\npfT08Btfzg/vlKSAEOXOJ08fHdyuh21pendIUj5+y0Jau3fptVcUnFedu8rHR6tXaexHij6h\n3i9L0h+/6+0hKl5c3Z+T2awVv+n94Tp5Us88K0k/zNTEz9S0ubr3kLtFWzdr0gTt3qX/jnDp\nIQHIUWbNmvXaa681a9Ysk6sWJT377LPDhw+XlJiYuHnz5r59+54/f/6zzz5LOyYpKekBXPb1\n8ccft23blkCY9TkUCNeuXTtmzBj7rSZSPfTQQwMHDnz77bedUxgAo3Bzv82iMinJWvylfPzl\n7qFtv6XrKlpRAXlV9zGtna1pb+uh2nKz6Nge7V6niFIqXF4mkxp10ZKvNHO4KjWTxVOHtmvb\nbypTV6GFnXlUyHamTJanpyZMUlBuSWrTVi/21Px56tVbbm6aMllhYRr/uTw9JalNOz33jGbP\n1NPdZTLp5wUKz6c3h17/1aFSZR0+pDWrdPmy/PxceVDZ06krh9Ydm+vqKnCv4pMuyXz7YXBc\nYmLihg0btm7dOmPGjEyG+fr6RkRE2P8uVqzYkSNH/ve//3322WdJSUkeHh5ff/31e++9V69e\nvenTp58+fbp///6rV69OTEysVKnS2LFjK1SokJCQ4O3tPWXKlKlTpx46dMjPz2/06NHt27e3\n7/DcuXOtWrVavXp1cHDwiBEjnnnmGUmnT59+9dVXlyxZ4ubmVrVq1bFjx5YtW7ZJkyarVq36\n7bffvvzyy9STlsiaHAqEcXFxnp63WP3d3d09Li7ufpcEAOkkxOl8tCQtnJixq9MgBeRVwyeV\nO1xbFmvtbCVbFRCiRk+qRrvrX86rt5FvoP78RQs+VUqyAkPVqEvGFUqRE7z2ipKsGvCGPvtE\nu3fJ01OVq+iV15Q7t2w2Xbp0663c3JQrlyQ1a6G27a+nQUkms8qU1YH9unxZAf5q007h4Ur9\np9DdXWXLafGvSkyUl5c8PGQ2p7tQ1dtHZrM8mDJ6NyLPb4s8v83VVeA+cMk0xRzMnr62bt16\nR1t5eXklJydLslgsJpPp888/nzdvnn1R00ceeSRPnjzbtm3z9fUdNmxYw4YNIyMjAwICJH3y\nySe//fZbSEjI5MmTH3/88QMHDhQqVMjePmnSpHnz5v33v//t3bv3Y4895uvr+9RTT+XJk+fQ\noUPe3t4jR45s2rTpwYMHV6xYUbhw4cGDB/fu3fv+vxa4rxwKhJUrV546deqTTz5pNt/4qScu\nLm7SpEmVKt3lRbTISbadPjt83YYtp87EJ1mLBgb0rFTuuYpl3f75brTq6PHRGzbvOBNjTUku\nkTvo5SoVnyxbKvV705y9ByZs+WvfuQvXUpILB/h3K/dQnyoVPN3cXHUscJIu72RsadlLLXs5\ntK2Pv96+3dmC8g1VvuG/9papqzJ1HXouZGPuFkWf0Oj31b2HBr2pv/do+H917ZpGjtaFC3qs\n/a23KlBQ0/5Pklq3zdh14rgCAhTgL5NZj6W/S4nNpsOHFBIi+/fdJ7po1HBNn6q27eThoa1b\ntGaVOjwmT74NAzlcYmKiNcX204lTd7d59NVE+07ua1HX2Wy2nTt3jh8//pFHHrG3mM3m9u3b\n27+9b9u2bePGjbt27QoNDZU0fPjwzz//fMGCBU8//bSkZ599NiQkRFLPnj3feOONX3/9tU+f\nPpK6detWp04dSS+88MIHH3xw5MgRScuXLz916lTu3LklvffeexMmTPjll1+eeOIJZxwUnMGh\nQDh06NC2bduWKVOmWbNmoaGhCQkJx48f//nnny9evLhw4UJnl4gsbmP0qebfz83nl+u1GlX8\nPCzz9h18ZenKQxdjRzWqK2lh5OFO8xZWDAl+u24NN5Np1t/7eyxcejj20pt1qkv6ZNO2QSvX\ndSlT6q26NTzMbiuPRg1ZuW7jiZPfd2jt6sMCkN2YTDpzRoPfVuUqkpQ3RDUWactm2Wzy99NH\n42691b+dwVi1Ups36YU+12+QYpeUpAvndfas5s/VwYMaOux6e/MW8rDow1H6+ktJMpnV7Wn1\n6HnfDg1AVhUTE2O12T7ce+hednLw4MH7VY+kL7744ttvv5WUlJSUkpLStWvXceNufACWKFEi\n9UlNJlOpUqXsD318fPLnz59aSbFixex/uLm5hYeHR0VF2R+mriXp7e0t6erVq8ePH5cUFhaW\ntoZDh+7pBcED5lAgbNWq1c8//zxkyJC0F6RWrFhx+vTpLVu2dFptyB6GrvnD29199VOPh/j6\nSOpRoWzdabMmb9sxvEFtd7P5nTXrCwX4r3jqcW93d0k9Kpat+vX/fbJp65A61U3SV3/tLhIY\n8HXb5vYThg0K5t8dc27e/oMXEhKDvG4xSxkAMmOxqFLlGw+D8yoxUdcS5emlqneyqsGGP/TB\nSNWuoye7pGvf8ZcG9Jek0DC9N1K16/zTvl1jPlClymr7iDw9tXG9ZkyXxUNPd7/HAzKmavla\nti3Rx9VV4F5N3Pzq5ZQzrq7C6UJCQk4ej3qnbMm72/x4/NXJB4+lhrT7onPnzsOGDZPk7u4e\nERHh7p7u236Gq8DS3vHCZrOZ/pneZZ9lmvp36uzftLMF7eybxMfH2yMisiNH70PYunXr1q1b\nnz171v4zQIECBYKDg51ZGB6c5jPnXktOmdiiyYDlazZGn/Jyd29UMP/HTRuG+vrYpPNXr95y\nKzezOdDTU1LXMqWfq+BuT4OSzCZTjXxh206fvZiQmNvbq0fFsoUD/L3/+TCymM0184VN3/V3\nfFKSr8Xi5e7mlpzu7uK+HhY3k4kpowDuRkBgugv57F9cUu7wBl/z52r8ODVoqLfeSXd6UFLx\nEho5WrEXtXmT3hqsrk+p54uypeiD95U/QiM/uD6+ajUlJ+ubr9T4Yf2ztAMc5+XuG+yT39VV\n4F65mRz9kpmtWSwWN5OpSUieu9t8d+xl+07uY0kBAQGO3BOuRIkSNptt79695cuXl3TlypUT\nJ06kRtP9+/fb/0hMTIyOji5QoEAm+5G0ffv22rVr21sOHTpkv0YR2YWj/6/Gx8fHxsaGh4fn\nzZs3ISFh1qxZZ8+ebd++fcmSd/mLCLIOD7PboQuxLyz67a06Nb4MCf7z5OnuPy9JSE7+sWPb\nM3HxhSZ8dcutSuYO2tGzm6RnK5TJ0BV54WIeb+/c3l5mk6lv1Yppu2zSnphzEX65fC0WSf2r\nV35u4bJR6zc9X6Gsp7v7yqNR8/cd7F2lgo/FEP+KAHhAHFlUxm7Cp5ozW127qeeL6bKlXUCA\n6tSVpFZtFBKqGdNVr4ECAnQyWk89nS49Vq2muXO0ZxeBEMD9curUKavVeu7cOUn2MzSBgYG5\ncuX66quvrly50q9fvzvaW8WKFevUqTN48OBvv/3W09NzyJAh/v7+qTednz59euvWrUuVKjVm\nzJiUlJTUVUZvVqZMmSZNmgwYMGDmzJlhYWFTpkwZMGDAwYMHw8LCfHx8IiMjz507lyfPXQZm\nPBgOfe3eu3dvw4YNX3vttcGDB1ut1iZNmqxfv17S0KFD161bV7VqVScXCecymXT88pWv2jRr\nWDBC0qN+ub4rUnDFkSibFOTl+WvnW6/G6Psvv2b9uC9y+ZGoEQ3rmNN8l0pMTj4TFx99JW7S\n1h07z56b2q6Fvb1r2dIebm69Fy//79oNkswm06Ba1d6pX+s+HyEAg3NkURlJU77Qj3P0+htq\nm37wxQtas1olS6p0mt+/ylfQzBk6dFBly0lSUvq7S9tvNp10Z7ecBoBM1KpV6+jRo/a/7afs\nxo4d279//2XLlsXExNxpIJQ0c+bMV155pWjRop6enjVr1ly7dq2/v7/9lvcvv/zyyy+/vGXL\nlsKFC8+dOzfzRDdjxox+/fqVL1/earVWqFBh0aJF9ksKX3zxxTfffHPevHn39yJJ3HcOBcK3\n3norLCysc+fOkmbNmrV+/fovvvji4Ycf7tat28iRI+fO5WZB2Z6nm1uDgjd+xs6Xy/eq1Xo1\nyepjcW9S6F8nCdxs0cEjvX5d1rpY4f/UqJK2/ffj0a1nzZdU0N9vZofWrYsVtrevizrRZ/GK\nBgXyP1+xnLfFffHBIx9u2Ozh7jakdvWbdw4Ad8mRRWU2b9KMaXqlf8Y0KMli0fhxKlNO4z69\ncRpw62ZJCg1T/gj55tKmP9U75Ubvlk2SVPqh+3oYAAzNvqTnzWbOnJn6d+b3rLeHvVQFChSY\nP3/+LUcWLVp07dq1mWweFhaWev1hWFjYrFmzbt5Jv3797iKm4sFzKBCuW7du7NixRYoUkfTT\nTz9VqFChV69ekvr27fvGG284t0A8EHm8vdNOjXIzmyWl2O7swptJW3e8vnxNh5LFvmnb3Jx+\nqlXFkOAfO7aNuXp1+ZGox+f+MqBm1fca1E6x2XotWl48KGBOx7b28U0KFbCm2Iav29ipdIni\nQYH3flwAIEnultssKpOcrE8+VkCAPD218Od0XdWqKzRMXZ/WtG/Ur68aNpbFoh3btWK5ypZT\nlSoymfXc8xr/iQYNVJu28vLSpj/16y9q/LCK3f4yHgDZXYrNtvfSlbvb9mj8rVdqAB4khwLh\nxYsXw8PDJaWkpCxfvrxnz+tLaefNmzcmJsaJ1cHVHFlUxm7girXjN28fWKvqew3q3HTZjfJ4\ne7cpXkRS9/JlCvjn+nDD5vYliubx9jp8MfaNWtXSpscmhQtM3PrXxuhTBEIAD86VKzoeJUkf\njc7YNXyUQsPU43lFROineZr6jaxJCgtXj556/InrpwQ7dlLuPJozW6NGKjlZ+fLpuZ7q3PVB\nHwWAB85kMl1LsT2/ace97OTmpTuBB8mhQBgaGnro0KHGjRuvXLny/PnzrVq1srdHRUVxkWjO\n5siiMpKGrVk/YctfE1o0fr5iubRjzsZfnb//YKXQvNXDQ1Mb6+TP9z9t3XX2XM38YZKupVnX\nWFJicvLNjQBwex/+L2NLv/+o338c2jYgQCvX3WZMsxZq1uJfexs1UaMmDj0XgBykV69e27dv\n/7felJSUWbNm5c2bt2nTpv82xmQypX61zgrc3d1tdzhHDNmdQ4GwefPmb7/99oEDB2bOnFm4\ncOH69etLOnPmzCeffFK3bl0nVwhXcmRRmeVHokZv2Pxx0wYZ0qAkDze3//y2umb+8KVPPpp6\nGnDl0ShJBQP8igcFBnh6LDt87P1GttTeFUeiJFUNCxUAAEDWVqNGjRo1avxbr9VqnTVrVnh4\n+AsvvPAgqwLuiEOBcPjw4bt37x49enTevHkXLVrk5uYm6dVXXz127NiMGTOcXCFcycPNLfNF\nZawpKf1/W5XH29vb3f2bHbvTdj1cuGBBf783alUb+cefTb+f27FUcU83t3VRJ2b/vb9mvrBG\nBSPMJtM79Wq9vnzNI3MW9KhQ1sfi/tvhY9/u2N2pdIkKIdzlEgAAAHA6hwJheHj4+vXrL126\n5OPj4/7PHcYHDBgwbtw4+6qyMKzYxMQD5y9K6rN4RYau2Y+2KejvN7RezeJBgZO27Xj/9z+v\npSQX8vd/p36tV6pWsp8SfLlqxVBfn/Gbt/f8dZk1xVYk0P+d+rUyrFAKAAAAwEnu4Pbf/v7+\naR9Wq5bpim3IPn7u9EiGlnFNG45r2tCRbfN4eye88UrmY7qULdWlbKl/6328dInHS5dw5LkA\nAACyEXd391q1apUpU+b2QwHXuYNACAAAAMBxo0aNcnUJwG2wyi0AAAAAGBSBEAAAAAAMikAI\nAAAAOEV8fHxSUpKrqwAyQyAEAAAA7j+bzdatW7cPPvjA1YUAmXFoURmLxeLp6XnLLpPJ5O/v\nX6lSpQEDBjRu3Pi+1gYAAABkV8nJyRcuXIiJiXF1IUBmHDpD2KdPn7Jly8bFxRUqVKh58+Yt\nWrQoUqRIXFxc5cqV27dvX6ZMmXXr1jVt2nTx4sXOLhcAAAAAcL84dIawXbt2CxYs+OOPP2rX\nrp3auH79+u7du48bN65q1aqxsbHNmzcfOXJky5YtnVYqAAAAAOB+cigQDho0aMSIEWnToKTa\ntWsPHjz49ddfX7VqVUBAQP/+/Xv16uWcIgEAAIAs57vv/p+9e4+P8cz/LEEiLgAAIABJREFU\nP37NTCaHSeQgCUEODnGIQ0nirERJUqxiu0rVsXGsULaN0iqKonWoUMoqRdFqF7WKrqqgsaUp\nG1VRWxKHHJqURBI5Z5L5/XHvzje/zGRMQmaSmdfzsX/MXHNd9/25b9k077mv+772xsbGGu5z\n48aN6dOnV/WpTCabPHlyt27dnnRpgLGMCoQJCQmNGzfWbW/atOlPP/0kvVapVDKZ7EmWBqCa\nMv7jdnazk7mrwOMqyrM1dwkAAKOcOXMmMSlRaV9WVQelg1CLvFvJv+r9tLxMlJUo4uLiCIQw\nI6MCoaen5/bt20NDQytFvs8//9zR0VEIoVar//a3v7Vr165WagTwKO7u7gEBAQ8ePDB3IbUr\nPz//4cOHbm5uVT3myjI424uWLVuauwoAgFEUNuWhr12u2djsVMfzu+rN3882NjYHDhwYMWJE\nre5FrVYrlcqTJ0+Ghoaafu/WyahAOHny5GXLll27di0sLKxJkyYymezevXtnzpyJi4ubPXu2\nEGLUqFHffPPN559/XsvVAtDP3t5+/fr15q6i1h06dGjbtm1//etfu3fvbu5aAKAm/pP+74/P\nLrn++8XCkvxmbq3+HDR9eNBUuUwhfXrxdszuf628mfGzuqzUx73NqG6vPttprEz89+v4U9e+\n/PKnjbfv/1paVtLUtcWQpya+0G2WUmHJX5ChorS0tHnz5p08ebK4uLhLly5r1qzR/a9h165d\nL126JL1WKpW+vr4vvfTSW2+9ZW9vb/J6RUxMjLOzc9euXas1SqFQnD59unPnzjXYQsXDF0I0\nbNgwMDDw3Xff7dmzZ7VqsDZGBcIlS5bY2Nhs2rSp4l+cLi4uf/3rX6WVVUJCQl544YUXX3yx\ntsoEAACo566mnJ+555lGzs1e6hmlsm1w5vrB1d+8kvogcVboGiHEuRtfz/9yROvGXSb3XSKX\nK04mfL70H+PTsm9F9F0khPj8xw82nnz92Y5jI/ouVipsL946tem7eVdTzq8cecDchwUTGT58\nuEql+vbbb52cnBYtWjR06NBbt25Jk/UqmjRp0vLly4UQxcXFFy9enDVrVlZW1qZNmyr2KS0t\nVSqVtV3wBx98MHTo0OoGQplM1r9//xpvQXv4QoiMjIx169aFhYVduXKlRYsW1SqjEtOcMVPu\nqCKjlp2Qy+WLFi1KT0+/devWjz/+eOHChRs3bmRmZn7wwQe2trZCiDlz5owZM6aWSwUAAKjH\ntpx+y07psG3SDy/1fH1E0LQPxnzT1ivo4KWPysrVQogtMW81cW3+t0nnRnab9XzwKx+OO+Xr\n3vbzC+s0QiOEOPzvbc3cWi4ZsadHy/Agv/7T+i/v23b46esHHxZZ+M0CkGRlZTVv3nzbtm1d\nunTx9/d///337927d/XqVd2ejo6O3t7e3t7erVq1Gj16dFRU1JdffimEKC0tlclkO3fubNGi\nRUREhBAiIyNjzJgxTZs2dXd3Hzhw4JUrV4QQRUVFMplsx44d/fr18/b2DggIOHLkiHbjmZmZ\ngwcPVqlUvr6+n376qdSYkZExevRoV1dXd3f38PDwhIQEIcSAAQOOHz8+d+7c4ODgiuX5+flp\nBy5cuFAmk925c0d6GxISsmLFCrVaLZPJvvvuO90t6N17VYfv7e0dHBwsdTt27JiBUoUQ8fHx\nPXv2dHJyCg4OjomJkclk8fHxes+Y3uG7du0KCAhwcHDw8vKaOXNmUVFRVY16z7nujvSOrT1G\nBUJJVlbW1atXf/7556tXryYmJhYUFNReWQAAAHVN5J5npu3qk3Qv4dV9YQPedxr8gefCg6My\n89KFEBqhyS64r/d/eUXZ0vBBncbNG7S5oeN/H9Qnl8k7evcsKi14WPSgXFM+LHDKnLD1djYO\n0qc2cmUn7155xTlFpQVCCDsbe1uFvXb6qBBCZesklymYMmolGjZs+Pe//71t27bS29TUVLlc\n3qxZs0cOtLe3LysrE0IolUqZTLZly5avvvpq8+bNQojhw4fn5ubGx8ffuXOnS5cuISEhmZmZ\nNjY2QogNGzYcOHAgJSVl7ty5I0eO1Ga2DRs2LFq0KCsra+zYsTNmzMjPzxdCjB07VgiRlJSU\nkpLSvXv30NDQgoKCmJgYX1/f6OjoinM4hRBhYWHff/+99Pr06dMdO3aU3hYVFf3444/PPvus\ntqfuFvTu3TCFQqFQKNRqtfRWb6nFxcWDBw8OCAhIT0///PPPFyxYIJ0u3TOmd3hSUlJERMSm\nTZvy8vLi4uJ++umn9evX622s6pxX2lFVY2uPUVNGy8vLX3/99c2bN5eWlmobHR0dlyxZMm/e\nvFqrDQBQ57j8mqBWVZ6hhPpFlXzX3CXUV0qFbeqDxHe/fnlyvyVvP7czIe3HJV+9VKIuWjP6\nSFZextDoJnpH+bq3/eKV60KI57pMrvRRctYNV5WHs4O7XCYf3X1OxY80QpP0x9XGzj4OSkch\nxJiery/7x4Sd594dHjjV1sb+4q1Tp389OLJrpL1SVTvHCqPk5+dryuQJ3/jVbHhxvo0QIjc3\nt1qjsrKyJk+e/Oqrr3p7exvoptFofvnllw8//HD48OFSi1wuHzZsWJcuXYQQ8fHxP/7449Wr\nV6WlBJYvX75ly5YjR46MHz9eCDFp0qRGjRoJIaZMmfLGG28cP378lVdeEUKMGzeud+/eQohp\n06a99957t2/fFkKcOnUqPT29YcOGQohly5Zt3rz56NGjo0aN0ltVWFjYokWLhBB5eXkJCQkr\nV648e/bs+PHjz58/36BBg6CgoPLy8qqOSHfvHTp0MHAG8vLyli5dWlBQMHToUCFEQkKC3lIb\nNWqUkZGxZMkSJyenNm3azJ49e8KECbpnrKrhvr6+Go3Gzc1NoVD4+vpeuHBBoVBcuHBBt7Gq\nc/7yyy9X3NG1a9d0xxo4zMdnVCD84IMPoqOjn3/++SFDhjRt2lSj0aSkpBw6dOiNN95o3Lix\n9pQBACyYdFeD78EvzV0Ingzppg9Uj0yWkZu8aNju4ObPCCEaOXsfb/nsT7e+0wiNs0PDjWNP\n6h0kJTpdMb/+PS7p5MwB78ll/zdjq7SsOCsv497D1AMXN9/848rSP38mtQ/uNN5WYbfi6ORt\nZxYJIeQy+cQ+b03tv+wJHyCqKTc3t7xc3P23x+NsJD093fjO169ff+6550JDQ9etW6e3w7Zt\n23bt2iWEKC0tLS8vf+mll6Kjo7Wftm7dWnqRmJgok8m0lxxVKlWzZs0SExOlt61atZJeKBSK\nJk2aJCcnS2/9/f2lFw4ODkKIwsLClJQUIYSXl1fFGpKSkqqqPzQ09KWXXkpPT798+XJgYOCA\nAQOk8s6cORMWFiaXyw0EQt29Gzh8IUR+fn6HDh0OHz4sDbxx44beUouKihQKhZ/ff1N9jx49\nKnbQnrGqhr/wwguRkZE9evSQrhmOGTOmXbt2PXr00G00fM61O9I7tqpz8kQYFQh37tw5ffr0\nrVu3VmycNm3aiy++uGHDBgIhAFiDiRMntmzZ0sB/qi3Dzp07PT09pa+TLZi9vf3AgQPNXUW9\npFTYBTXvr33r6dysWF1YXFpor1R1axFa9bjK/nXz2PIjk/q0Hjq21/832ery3dhX94UJIbxc\n/FaNPNin9dD/tX+/8uiUIL/+I4Km2dk4/HDz+O5/rVLa2L389NtP4KhQU15eXneSbz497VrN\nhj9MV/37YEttEnikU6dOjR49+p133pk1a1ZVfUaPHr1kyRIhhI2Njbe3tzQFVKvSuk0ajabi\na+0Kc9IsU+1r7UNK5fLKt5tJQwoKCqSQ9kju7u6BgYGxsbEXL14MCQkJCAjIzs5OS0s7c+aM\ndPucAbp716U9/Nzc3NDQ0JkzZw4ZMsRwqbt37664tF6lZfa0Z8zAkW7atGn+/PnHjh07evTo\nqlWr9u7dO2rUKN1Gqf6qznnFHend4COPvcaMCoSJiYkVv1rQeumll3iyKABYicaNG48cOdLc\nVdS6Xbt2ubu71+p/elGvuao8Kt7Ip5AphBAaTfW+KDlwcfP6E3P6t3v+nRF7K14eFEK0btxl\nzegj2fn34m6dfOPL4eN6z3/lmZXlmvJ3v37Zp2Hr1aP+IfXv1iK0rFy9/eyS0PajfRoaGyfw\nxEl/zatci2s2vCTfRugkkKqcO3du1KhR+/btGzRokIFuLi4u2itpBrRu3Vqj0Vy/fr1Tp05C\niLy8vNTUVG00/e2336QXxcXFaWlpPj4+BrYjhLh8+XKvXr2klqSkJMOr6YaHh8fGxl64cEFa\nraBPnz4nTpyIi4vbv3//I8t+pIqHv3HjxmnTpvXv3799+/YGSm3atKlarU5NTZWm4MbFxVXr\nSNVq9YMHD3x8fGbMmDFjxoy5c+d+9NFHzz//vG7jhg0bDJxzLb0brNX/Khn1UBkbG5uHDx/q\ntpeUlNT2lFYAAIC6z5iHykiiv/3run/OGtdr3rt/+UKpqDxx11Xl8XTr54Z2iVj2589f6hn1\n6b9W/Zr20+/Zt1MfJPVo9WzF9NitRWi5pvxqynlTHB7MrbCwcOLEiXPnzu3YsWPK/0hPVdmx\nY8eGDRuqu8HOnTv37t17wYIF9+7dy83NnT9/vrOzs3bZ9z179ly5cqW4uHjNmjXl5eXDhg2r\najvt27cfMGBAVFRUcnJyaWnpli1bOnXqJE2CValUN2/ezMzMrDQkLCzsu+++u3r1qpSs+vbt\nGx0d3aZNmyZNKt+FW9UWjDRu3LjBgwePGTOmuLjYQKm9e/d2cXFZuXJlQUHBb7/9tmXLlmod\n6e7du4OCgi5dulReXp6RkXH16tVWrVrpbTR8zrX0jq3ZGTCSUYEwMDBww4YNJSUlFRsLCwuj\no6ODgoJqpzAAAIB6IysvY/AHnnr/N3nn/y2KvfX0wr//tHH+kL+9MmBVxSuND/L/+OrS1mtp\n/9+lic6+Twshbv5xpaSsSAihLvv//hIrLSsWQpT+/42wVD/88ENSUtLixYt9Kti5c6cQ4uTJ\nk19//XUNtrl//36lUtmyZcuWLVvevn07NjbW2dlZ+igyMjIyMtLNze2zzz47dOiQu7u7ge3s\n27fP29u7U6dObm5ue/bs+eabb6Qb7aZPn75ly5bu3btX6t+nT5+7d+8GBwdLcy/79u175cqV\n8PBw3S1XtQXjbd26NT09ff78+QZKdXR0PHz4cGxsrKenZ0REhDTjVO/0VL3DIyIipk6dOnLk\nSJVK1blzZx8fn3Xr1ultFAbPuVZVY2uPUVNG33zzzaFDh7Zu3XrQoEHe3t4lJSXJyclHjx7N\nzs7+5z//Wav1AQAA1H3GPFQmLunk7n+tfO3ZjSOCplXqo7Sx++DEqx29e20ef1p7GfDirVNC\nCC8XP5+GrZ3sXC4knogcuFr76U+3vhNCBDTtVhuHg7pm4MCBFe89q6jiTMuLFy8a2Ih29QWJ\nj4/P4cOH9fZs2bJlbGysgeFeXl7aery8vL744gvdjcyZM2fOnDm67ba2tnl5edq33bt3r3ho\nNjY22rcVt1DV3ivSPXxPT8+MjIyKA/WW+vTTT1+6dEl61NaFCxeEENL00UpnTO9wmUy2ePHi\nxYsXV2rX21jVOa+4o6o2WHuMCoRDhgw5dOjQm2++uW3bNm3jU089tWfPntDQatw/DQAAYJGU\nClvDD5UpK1ev++csV5WHnY3DkfjtFT/q3jLMy8VvQp83P4ldNvPTkGcCRtoq7OLvfv9dwv6O\n3r2Cmw+Qy+RT+y9bf2LOa/uHDOsyxV6pikv69kj8jtD2o1s37lzLR4ZH0JTLavyU0cIclpE0\nP41G06FDh969e69fv76wsHDp0qX9+/fXvXBnwYwKhEKIESNGjBgxIi0tLTU1VSaT+fj4SAto\nAAAA4JEeFmXfzfpNCLHq2NRKH73/wldeLn5TQ5b6NGx98NJHn8QuKy0raeLSfGr/ZS92nytd\nEhzV7VV3R6/9cdHLj0wsK1c3dW05rf+ySk8ohenZ2dmVl8lqvA6hdiNPqh7UgEwmO3DggLSu\no4ODQ//+/bdv3/7oYRbE2EAoadq0adOmTWupFAAAgLosekzlO2VeH7Tp9UGbjBnrqvI4/7b+\nKX9agzqNG9RpXFWfDmw/amB7nn9bt7z55ps3b96s6tPy8vLly5f7+flNmjSpqj4ymSw4OLhW\niquRijM2rUenTp1Onz5t7irMxlAgNHINxOvXrz+hYgAAAIB6w9vbW7rZTC/pxjAXF5f+/fub\nriagmgwFQg+PGs6HBgAAAADUfYYC4blz50xWBwAAAGBJpBXnjVx3HjAXQ4EwIiJi8+bN0goh\nj1RYWDhr1qwdO3Y8ocIs0JG0DBdl9W7aRF2TXFBo7hIAAED9oFAoJkyY0Lx5c3MXAhhiKJ/E\nxMT06NFj48aNj5z3HBsbO2vWrJycnCdZmgWxt7cXQnx2J9XcheDJ4GlgAADAGC+//LK5SwAe\nwVAgvHTp0pgxY5555pmQkJCJEyeGhYVVums2NTX11KlTu3fvjomJCQsLi4mJqeVq66uJEyd2\n6dLF4h/ZtHbtWhcXl6lTKz9N28LIZLJu3VgFGAAAAJbAUCB0d3f/5z//+dlnny1dujQiIkII\n4enp2ahRIxcXl5ycnHv37v3xxx9CiNatW+/du3fMmDFyudxEVdc3DRo0ePrpp81dRa1bv369\no6Nj3759zV0IAAAAAKM84pY2uVw+bty4MWPG/PDDDydOnPj555/v3buXlZXl6urasmXLzp07\nP/vss7169VIoFKYpFwAAAKgvbty44erq6unpae5CgCoZ9YwThULRt29frvwAAAAARiovL581\na1aXLl3ef/99c9cCVIlJngAAAMCTV15eXlJSUlRUZO5CAEMIhAAAAABgpQiEAAAAAGClWCcd\nAAAAqIkVK1Z89913hvtcuXLlmWeeqepTmUz2+uuv/+lPf3rSpQHGIhACAAAANXHr1i2NTPbQ\nv3XNhiuKihyT796+ffuJFgVUD4EQAAAAqCGNjfLG9MiajXW8c7vdh+ufbD21x8bG5sCBAyNG\njKjVvajVaqVSefLkydDQUNPv3TpxDyEAAABQ1127dm3o0KENGzZ0cXEJCQn54YcfdPt07dpV\n9j+2trb+/v6LFy8212NOY2JiLl68WN1RCoXi9OnTwcHBNdvCf/7zn549e9rYVHnRq+Ipkslk\n7u7uoaGhFy5cqG6dloRACAAAANRpxcXFoaGhDRs2PH/+/KVLl5o3bz548OCHDx/q9pw0aVJy\ncnJycvKvv/66YsWKLVu2REVFVepTWlpqgpo/+OCDGgRCmUzWv39/Nze3Gmzhiy++eOaZZ9q2\nbWu4m/YUJScnf/vtt40aNQoLC7t161Z1S63ENGe1NnZEIAQAAADqtNzc3Ndee23z5s1t27b1\n9/dfuHBhbm5uUlKSbk9HR0dvb29vb+9WrVqNHj06Kirqyy+/FEKUlpbKZLKdO3e2aNEiIiJC\nCJGRkTFmzJimTZu6u7sPHDjwypUrQoiioiKZTLZjx45+/fp5e3sHBAQcOXJEu/HMzMzBgwer\nVCpfX99PP/1UaszIyBg9erSrq6u7u3t4eHhCQoIQYsCAAcePH587d650rU/Lz89PO3DhwoUy\nmezOnTvS25CQkBUrVqjVaplM9t133+luQe/eKyouLr5w4cKf//xnwydTe4q8vb2Dg4OlTR07\ndszA4Qgh4uPje/bs6eTkFBwcHBMTI5PJ4uPj9Z5VvcN37doVEBDg4ODg5eU1c+ZM6bKt3ka9\n/y66O3qCCIQAAABAnebp6RkVFdWgQQMhRFZWVnR0dLt27dq1a/fIgfb29mVlZUIIpVIpk8m2\nbNny1Vdfbd68WQgxfPjw3Nzc+Pj4O3fudOnSJSQkJDMzU5psuWHDhgMHDqSkpMydO3fkyJHa\nzLZhw4ZFixZlZWWNHTt2xowZ+fn5QoixY8cKIZKSklJSUrp37x4aGlpQUBATE+Pr6xsdHX3p\n0qWK9YSFhX3//ffS69OnT3fs2FF6W1RU9OOPPz777LPanrpb0Lv3iiZMmODr61vdc6tQKBQK\nhVqtlt7qPZzi4uLBgwcHBASkp6d//vnnCxYskE6p7lnVOzwpKSkiImLTpk15eXlxcXE//fTT\n+vXr9TZW9e+iu6MnqBoPlSksLLx06VJqaurAgQM9PDzUarWB6bkAAACAZcvOzparSwOi19Zs\nuLykRAiRnp5uZP+ysjKVSlVSUtKvX79Tp07Z2dkZ6KzRaH755ZcPP/xw+PDh/92dXD5s2LAu\nXboIIeLj43/88cerV682btxYCLF8+fItW7YcOXJk/PjxQohJkyY1atRICDFlypQ33njj+PHj\nr7zyihBi3LhxvXv3FkJMmzbtvffek56PeurUqfT09IYNGwohli1btnnz5qNHj44aNUpvVWFh\nYYsWLRJC5OXlJSQkrFy58uzZs+PHjz9//nyDBg2CgoLKy8urOiLdvXfo0MHIU1eVvLy8pUuX\nFhQUDB06VAiRkJCg93AaNWqUkZGxZMkSJyenNm3azJ49e8KECbpntarhvr6+Go3Gzc1NoVD4\n+vpeuHBBoVBcuHBBt7Gqf5eXX3654o6eLGOvEK5Zs8bLy6tv374vvvjizZs3hRBLliyJiIiQ\nvnIAAAAArI10N5ddVmbN/mebmyOEKC4uNnJ3CoXi8uXLMTExbm5uzzzzTHZ2tm6fbdu2OTk5\nOTk52dvbBwcH9+nTJzo6Wvtp69b/XSEjMTFRJpNpb7dTqVTNmjVLTEyU3rZq1Uq7xyZNmiQn\nJ0tv/f39pRcODg5CiMLCwhs3bgghvLy8pGe0KBSK7OxsvXNZJaGhoYmJienp6efOnQsMDBww\nYMDZs2eFEGfOnAkLC5PLDWUT3b0bOllV054iJyenBg0afPPNN4cPH5Y2XtXh3L17V6FQ+Pn5\nSVvo0aNHxQ1qz2pVw3v06BEZGdmjR48+ffosWbJE6qa30fC/i3ZHT5ZRl/i2b9/+xhtvDBs2\nbMiQITNmzJAa27Ztu3r16jZt2kjXTAEAAACr4unpmV1YdHnZqpoNl5ad0MYMYwQEBAQEBPTt\n29fLy2vv3r2zZs2q1GH06NFLliwRQtjY2Hh7e1ea0FfpoqJGo6n4WiaTSa8rXvIpKyuzt7eX\nXusGNmlIQUGBFNIeyd3dPTAwMDY29uLFiyEhIQEBAdnZ2WlpaWfOnHnkrXGG46LxtKcoNzc3\nNDR05syZQ4YMkT6q6nB2796tPTnablras2rgbGzatGn+/PnHjh07evToqlWr9u7dO2rUKN1G\n6Rir+ncxfE24xow6rZs2bZoxY8Y//vGPiRMnahsnTJgwb968PXv21EZZAAAAACSnTp3y9/fX\n3jWnUChkMlnF2KDl4uLi7+/v7+/fvHlzA7d3tW7dWqPRXL9+XXqbl5eXmpqqvQD122+/SS+K\ni4vT0tJ8fHwMbEcIcfnyZW2LgcuDkvDw8NjY2NOnT4eEhAgh+vTpc+LEibi4uPDwcMMDnxTt\nKQoKCtq4cWNUVNS1a9ekj6o6nKZNm6rV6tTUVKkxLi5O75arGq5Wq+/du+fj4zNjxoyjR4/O\nnDnzo48+0tto+N+llhh1hfD69etr1+qZGx0SElLxGjQAAMBjOnf34Lm7B81dBZ4AIy8ZwRjB\nwcH5+fmTJk1aunSpvb39xo0b8/LyBg0aJITYsWNHXl7enDlzqrXBzp079+7de8GCBbt27bKz\ns3vzzTednZ21y77v2bNnyJAhbdu2XbNmTXl5+bBhw6raTvv27QcMGBAVFbV//34vL6/t27dH\nRUUlJiZ6eXmpVKqbN29mZma6u7tXHBIWFhYZGXn79u1evXoJIfr27RsdHd2mTZsmTZpU2nhV\nW6hKenq6Wq3OzMwUQqSkpAghXF1dnZycDAwZN27cV199NWbMmLi4ODs7u6oOp3fv3i4uLitX\nrly7dm1KSsqWLVuqdTaOHTv2zjvvHD58ODAw8N69e1evXm3VqtXu3bt1Gw3/u9QSowKhUqnU\nO0k3IyNDqVQ+6ZIAAIA1atasWb9+/fQurWZJ0tPTf//9d39/f+mJkRasTZs25i7Bcri6up48\neXLBggV9+/ZVq9WdOnU6duyYdOHo5MmT9+/fr24gFELs379/9uzZLVu2tLOz69GjR2xsrLOz\ns/SwzcjIyMjISGnBw0OHDhnOY/v27ZszZ06nTp3UavVTTz31zTffeHl5CSGmT5/+1ltvffXV\nV9pb4CR9+vS5e/ducHCw9JVB3759o6KidBdLNLCFqvTs2VP7QFTpqub69evnzp1reNTWrVs7\nduw4f/586UJXVYdz+PDh2bNne3p6BgYGLlmyJDw8XO8UVr3DIyIiUlNTR44c+fvvv7u6ug4e\nPHjdunUuLi66jaKKfxdjDr/G9F9rrmTgwIFCiOPHj2s0GgcHh/Pnz/fs2TM7O7tv375NmzY9\nceJErZb4OHJycky2RiSef/75xo0bV/WVCfD4Dh06tG3btmXLlnXv3t3ctcBiSV+KS8/+BmrD\n/v37d+3a9f7773fu3NnctVgLDw+PJ7tB7dcWU6ZMuXE3OX7VmpptR7qHcOTIkZGRkUKIuvAd\ngVqtViqV33zzjXT5EVpqtbq8vNzW1lYIceHChV69euXk5NR2VDMNo64QLlmyZODAge3bt5fW\nBtm2bdvWrVsPHz5cUFCwdevWWq4QAAAAqKNkZWq/A1/UbKxNnoVfD7cYGo2mQ4cOvXv3Xr9+\nfWFh4dKlS/v3728ZaVAYGQj79et34sSJefPmSRd/du7cKYTo3r376tWr+/TpU7sFAgAAAHWS\nm5ubLDHR48IPj7MRac061GUymezAgQOvvvqqt7e3g4ND//79t2/fbu6inhhjV5YfMGDApUuX\n7t+/n5ycLJPJ/Pz83NzcarUyAAAAoC579913s7KyqvpUrVZPmDChXbt2ixcvrqqPTCaTloCv\nI2xsbIy5ocwKderU6fTp0+auolYYGwgLCgpycnKaNGni4eFRVFS6uJsPAAAgAElEQVT0xRdf\n3Lt3b9iwYdwuDAAAAOtkZ2en+2xMLekBLba2tgb6AGZn1DqE169fb9Gixe7du4UQarV6wIAB\nkyZNmjdvXufOnS9dulTLFQIAAAAAaoVRgXDhwoVeXl6jR48WQnzxxRfnz5/ftm1bYmJiYGDg\nihUrarlCAAAAoP6Ry+VyudzA6vBAXWDUD+i5c+fWr1/fokULIcQ//vGPp556aurUqUKIWbNm\nvfHGG7VbIAAAAFAPyeXyJUuWSKvYAXWWUYEwOztbmvpcXl5+6tSpKVOmSO2enp7379+vxeoA\nAACAeqtfv37mLgF4BKOmjDZu3DgpKUkIcfr06aysrMGDB0vtycnJ7u7utVgdAAAAAKDWGHWF\nMDw8/O23375x48b+/fubN2/et29fIcQff/yxYcMG1iEEAAAAgHrKqCuEy5cvb968+fvvv19Q\nUHDgwAGFQiGEePXVV+/evWtgWRUAAADAmp04ceKXX34xdxWAIUYFwiZNmpw/fz4nJyctLS04\nOFhqjIqK+vXXXzt27Fib5QEAAAD1Unl5+erVqz/55BNzFwIYUo3H4Do6Oubn55eXl0tv/f39\nhRDZ2dmurq61UhoAAABQb5X/j7kLAQwxKhDeuHFjypQp58+fLy0t1f1Uo9E86aoAAAAAALXO\nqEA4ffr0+Pj4kSNHNm3alLU1AQAAACFEXl5eWlpaVZ+q1WohRGFh4W+//VZVH5lM1rJlS+kJ\nHYBZGJXu4uLi/v73v2tXmwAAAACwePHi+Ph4w31u3Lgxffp0Ax0iIiLGjx//ROsCqsGoQOjk\n5NSqVavaLgUAAACoR3JzcxUymwEtxtZseE7Rvbi047m5uU+2KqBajAqEEydO3Llz56pVq2q7\nGgAAAKAeUchthredXbOxt7J/iUs7/mTrqT02NjYHDhwYMWJEre5FrVYrlcqTJ0+Ghoaafu91\nU3Fxce/evSdNmjR7tv6ftHnz5l2/fv3IkSMymawG2zdq2YkVK1Zcu3atV69e8+bNe09HDfYK\nAAAAoAZ27dolk8kOHz6s+1HXrl1l/2Nra+vv77948eKioiLTFymEiImJuXjxYnVHKRSK06dP\nSwvdVXcLFQ9fJpO5u7uHhoZeuHChujXUNfPnz2/cuLGUBtPS0saOHduoUSMXF5eQkJC4uDgh\nxMqVK5OTk6Ojo2u2faOuEEZHRx85ckQIofeELliwoGb7BgAAAGC8jIyMBQsWODg4VNVh0qRJ\ny5cvF0IUFxdfvHhx1qxZWVlZmzZtqtintLRUqVTWdqkffPDB0KFDu3btWq1RMpmsf//+Nd6C\n9vCFEBkZGevWrQsLC7ty5UqLFi2qVUYlpjljend0+/btLVu2aFPY8OHDVSrVt99+6+TktGjR\noqFDh966dcvR0fGdd96ZPHnylClTGjRoUN2dGnWFcP369YMHDz579uyNGzdu6TAwMC8v74MP\nPhgzZswLL7ywdOnSP/74o1p9UlNTo6KiKl0aNmabAAAAgOWJjIycMGGCs7NzVR0cHR29vb29\nvb1btWo1evToqKioL7/8UghRWloqk8l27tzZokWLiIgIIURGRsaYMWOaNm3q7u4+cODAK1eu\nCCGKiopkMtmOHTv69evn7e0dEBAgXRaSZGZmDh48WKVS+fr6fvrpp1JjRkbG6NGjXV1d3d3d\nw8PDExIShBADBgw4fvz43LlzpWt9Wn5+ftqBCxculMlkd+7ckd6GhISsWLFCrVbLZLLvvvtO\ndwt6917V4Xt7ewcHB0vdjh07ZqBUIUR8fHzPnj2dnJyCg4NjYmJkMll8fLzeM6Z3+K5duwIC\nAhwcHLy8vGbOnCldktXbqPec6+6ooq1bt3br1i0wMFAIkZWV1bx5823btnXp0sXf3//999+/\nd+/e1atXxf+C4r59+6r6wTDAqECYmZm5bt26fv36+fv7N9dhYGB0dPTdu3eXL1++fv16hUKx\nbNky3aU5q+oTGxv71ltveXt712CbAAAAgIU5dOjQ5cuXly5davwQe3v7srIyIYRSqZTJZFu2\nbPnqq682b94shBg+fHhubm58fPydO3e6dOkSEhKSmZkprTC3YcOGAwcOpKSkzJ07d+TIkdrM\ntmHDhkWLFmVlZY0dO3bGjBn5+flCiLFjxwohkpKSUlJSunfvHhoaWlBQEBMT4+vrGx0dfenS\npYr1hIWFff/999Lr06dPd+zYUXpbVFT0448/Pvvss9qeulvQu3fDFAqFQqGQ1v+oqtTi4uLB\ngwcHBASkp6d//vnn0uRHpVKpe8b0Dk9KSoqIiNi0aVNeXl5cXNxPP/20fv16vY1VnXPdHVX0\n7bffhoWFSa8bNmz497//vW3bttLb1NRUuVzerFkzIYRMJhs4cODJkycfeU50GTVltFOnTpmZ\nmdXd9P379+Pi4qKjo1u2bCmEmDt37vjx43/++Wcp4D6yT2lp6dq1axMTE8+cOVOtbQIAAAAm\n8Mcff5SUFc36pnqzIiu5ffu2Md0ePHgwa9aszz77zMB80Yo0Gs0vv/zy4YcfDh8+XGqRy+XD\nhg3r0qWLECI+Pv7HH3+8evVq48aNhRDLly/fsmXLkSNHpAUwJk2a1KhRIyHElClT3njjjePH\nj7/yyitCiHHjxvXu3VsIMW3atPfee0+q/NSpU+np6Q0bNhRCLFu2bPPmzUePHh01apTeqsLC\nwhYtWiSEyMvLS0hIWLly5dmzZ8ePH3/+/PkGDRoEBQUZuNKju/cOHToYOAN5eXlLly4tKCgY\nOnSoECIhIUFvqY0aNcrIyFiyZImTk1ObNm1mz549YcIE3TNW1XBfX1+NRuPm5qZQKHx9fS9c\nuKBQKC5cuKDbWNU5f/nllyvuqJKEhIS3335btz0rK2vy5Mmvvvqq9vrZU0899be//c3ACamK\nUYFw06ZN8+fPX7duXaVrvobduHHD1tZWO2HXycnJx8fnxo0bFcObgT4DBgwQQiQmJlZ3mwAA\nAIAJ2NrayoS8jXsNA2GhOu9uzjVHR0djOr/22mvPPfec9v66qmzbtm3Xrl1CiNLS0vLy8pde\neqnis0Zat24tvUhMTJTJZNprTSqVqlmzZto/vLULzikUiiZNmiQnJ0tv/f39pRdSKC0sLExJ\nSRFCeHl5VawhKSmpqvJCQ0Nfeuml9PT0y5cvS3/wS+WdOXMmLCxMLpcbCIS6ezdw+EKI/Pz8\nDh06HD58WBp448YNvaUWFRUpFAo/Pz+ppUePHhU7aM9YVcNfeOGFyMjIHj16SNcMx4wZ065d\nux49eug2Gj7n2h1VlJubW1JS4uHhUan9+vXrzz33XGho6Lp167SN7u7u9+/f13PiHsWoQBgV\nFXX37t2uXbs6OTm5u7tX+rSqbzVyc3MbNGhQ8eGnLi4uOTk51e1Trf4///xzxWQ8c+ZM7UmH\nCchkMhcXF3NXAYslzWOxt7fnxwy1il9lqFX8KrMkrq6uD7PzZ3f/qGbDb2X/su78y56eno/s\nefLkydOnT0u3nBk2evToJUuWCCFsbGy8vb2lnzctOzu7im81Gk3F19q/saVZptrX9vb20mu5\nvPLtZtKQgoICI69buru7BwYGxsbGXrx4MSQkJCAgIDs7Oy0t7cyZM7q3z1Wiu3dd2sPPzc0N\nDQ2dOXPmkCFDDJe6e/fuiuGi0soN2jNm4Eili2fHjh07evToqlWr9u7dO2rUKN1Gqf6qznml\nf5qKKpV06tSp0aNHv/POO7NmzTLQzXhGBUK5XO7v7683thpWqayKx1+tPsb3z8rKkp6+Kpk0\naZJpnggELU44ao/0m1Qul/NjhtrGzxhqj/SXjEKh4McMxvvkk08yMjKke6aEEFlZWRMmTAgL\nCzt48GClni4uLtoraQa0bt1ao9Fcv369U6dOQoi8vLzU1FTtX/u//fab9KK4uDgtLc3Hx8fA\ndoQQly9f7tWrl9SSlJSkrVOv8PDw2NjYCxcuSMvX9enT58SJE3Fxcfv3739k2Y9U8fA3btw4\nbdq0/v37t2/f3kCpTZs2VavVqamp0tzLilHCmCNVq9UPHjzw8fGZMWPGjBkz5s6d+9FHHz3/\n/PO6jRs2bDBwzvVydna2tbW9d++etuXcuXOjRo3at2/foEGDKnW+f/++MV8u6DIqEJ49e7YG\nm3Z1dc3Nza0YfHNyctzc3Krbp1r9n3nmmYrLleTk5NTsyilqRqPRcMJRe0pKSoQQBQUF/Jih\nVvGrDLWqtLRUCJGfn8+PmcnozrirdzZv3rxmzRrt26CgoFWrVkk3B+7YsSMvL2/OnDnV2mDn\nzp179+69YMGCXbt22dnZvfnmm87Oztpn++/Zs2fIkCFt27Zds2ZNeXn5sGHDqtpO+/btBwwY\nEBUVtX//fi8vr+3bt0dFRSUmJnp5ealUqps3b2ZmZlaaYBgWFhYZGXn79m0pWfXt2zc6OrpN\nmzZNmjSptPGqtmCkcePGffXVV2PGjImLi7Ozs6uq1N69e7u4uKxcuXLt2rUpKSlbtmyp1pEe\nO3bsnXfeOXz4cGBgoPTMz1atWu3evVu30fA5r0qHDh1++eWX559/XghRWFg4ceLEuXPnduzY\nUZqsK4Rwc3OTZh1fuXLF8E2VVXn0hdeSkpJu3bodPXq0uptu06ZNaWnpzZs3pbc5OTnJycnt\n2rWrbp/H6Q8AAADUdw0bNvSuQC6Xu7u7S0H35MmTX3/9dQ22uX//fqVS2bJly5YtW96+fTs2\nNla7mkVkZGRkZKSbm9tnn3126NAhw3ls37593t7enTp1cnNz27NnzzfffCPdaDd9+vQtW7Z0\n7969Uv8+ffrcvXs3ODhYmnvZt2/fK1euhIeH6265qi0Yb+vWrenp6fPnzzdQqqOj4+HDh2Nj\nYz09PSMiIqQZp3qnp+odHhERMXXq1JEjR6pUqs6dO/v4+Kxbt05vozB4zqsSHh6ufXboDz/8\nkJSUtHjxYp8Kdu7cKYTQaDSnTp2q+JhW4z36CqGtrW1aWpo2gxnPzc2tT58+H3744auvvmpn\nZ7d9+3Z/f38ptp48ebKoqOi5554z0OfBgwdlZWUPHz4UQkhfoTk5ORnoDwAAAFiD9PR07euK\nMy0rTpTTpV19QeLj43P48GG9PVu2bBkbG2tguJeXl/a+LS8vry+++EJ3I3PmzNF73dLW1jYv\nL0/7tnv37hVvAbOxsdG+rbiFqvZeke7he3p6ZmRkVByot9Snn3760qVLtra2QghpCXhp+mil\nM6Z3uEwmW7x48eLFiyu1622s6pxX2lFFM2bMWL9+fXx8fGBg4MCBA6u6ve4f//hHYWHhmDFj\nqtqOAUZNGf3b3/62YMECPz+/5557rtKdqYbNmjXr448/fvvtt8vLywMDA+fOnStN9bx8+XJu\nbu5zzz1noM+8efO0i85L95hOmTJl2LBhVfUHAAAATExdXrL6h/E1G1us1vOcTJiYRqPp0KFD\n7969169fX1hYuHTp0v79+z/ywp3JNG/e/JVXXlm4cOHx48er6lNaWrp06dK33367QYMGNdiF\nUeluzZo1CoXi+eeft7Gx8fT0lNKzloG1U1Qqld7vBubNm/fIPtu3b6/WNgEAAABTat++/R9/\n/PGgPKWqDg8fPlQoFCqVSv/HctGgQYM2bdrUVn0wgkwmO3DggLSgn4ODQ//+/auKIeby/vvv\n9+7de+PGja+++qreDgsXLmzWrFmN85FRgVCtVru5uQ0cOLBm+wAAAAAsz2uvvfbaa69V9ala\nrQ4LC+vQocOGDRtMWdXjqDhj03p06tTp9OnT5q6iSnZ2dpcuXTLQYfXq1Y+zfaMC4b/+9a/H\n2QcAAAAAoA569FNGAQAAAAAWiUAIAAAAPHlyudze3r7KGwiBuqEajwwFAAAAYCS5XL5t2zYn\nJydzFwIYQiAEAAAAaoWPj4+5SwAegUAIAAAAVEPNVnsD6ibuIQQAAAAAK0UgBAAAAAArRSAE\nAAAAACtFIAQAAAAAK0UgBAAAAAArRSAEAAAAACtFIAQAAAAAK0UgBAAAAAArRSAEAAAAACtF\nIAQAAAAAK0UgBAAAAAArRSAEAAAAACtFIAQAAAAAK0UgBAAAAAArRSAEAAAAACtFIAQAAAAA\nK0UgBAAAAAArRSAEAAAAACtFIAQAAAAAK0UgBAAAAAArRSAEAAAAACtFIAQAAAAAK0UgBAAA\nAAArRSAEAAAAACtFIAQAAAAAK0UgBAAAAAArRSAEAAAAACtFIAQAAAAAK0UgBAAAAAArRSAE\nAAAAACtFIAQAAAAAK0UgBAAAAAArRSAEAAAAACtFIAQAAAAAK0UgBAAAAAArRSAEAAAAACtF\nIAQAAAAAK0UgBAAAAAArRSAEAAAAACtFIAQAAAAAK0UgBAAAAAArRSAEAAAAACtFIAQAAAAA\nK0UgBAAAAAArRSAEAAAAACtFIAQAAAAAK0UgBAAAAAArRSAEAAAAACtFIAQAAAAAK0UgBAAA\nAAArRSAEAAAAACtFIAQAAAAAK0UgBAAAAAArRSAEAAAAACtFIAQAAAAAK0UgBAAAAAArRSAE\nAAAAACtFIAQAAAAAK0UgBAAAAAArRSAEAAAAACtFIAQAAAAAK0UgBAAAAAArRSAEAAAAACtF\nIAQAAAAAK0UgBAAAAAArRSAEAAAAACtFIAQAAAAAK0UgBAAAAAArRSAEAAAAACtFIAQAAAAA\nK0UgBAAAAAArRSAEAAAAACtFIAQAAAAAK0UgBAAAAAArRSAEAAAAACtFIAQAAAAAK0UgBAAA\nAAArRSAEAAAAACtFIAQAAAAAK0UgBAAAAAArRSAEAAAAACtFIAQAAAAAK0UgBAAAAAArRSAE\nAAAAACtlY+4CAACoQyZOnOju7m7uKgAAMBECIQAA/ycyMlKtVmdnZ5u7EAAATIEpowAAAABg\npQiEAOoNW1tbZ2dnpVJp7kIAAAAsBIEQQP1QWlraokWLuXPnqlQqjUZj7nJgscrKysxdAgAA\npsM9hADqgcTExBUrVqSlpUlvAwIC3n77bZ78gSfr2rVr27dvv3HjhlKpDAwMnDp1qpeXl7mL\nAgCgdnGFEEBdV1xc/O6772rToBDi119/Xbt2rRlLguVJTExcsGDBtWvXSktLCwoK/vWvf82b\nN+/hw4fmrgsAgNpFIARQ18XHx//++++6jampqWapBxZpx44dJSUlFVvu3bt34MABc9UDAIBp\nEAgB1HVZWVnVagdqICkpSbcxMTHR9JUAAGBKBEIAdV1V93E1adLExJXAgtnY6Lmp3tbW1vSV\nAABgSgRCAHVd586dAwICKjWGhoZ6eHiYpR5YJL2BUC7nv5IAAAvHf+oA1HUKheKtt94KCgqS\n3spksrCwsMjISPNWBQtTVFRkZCMAAJaEZScA1AOenp4rV67Mzc19+PChm5ubSqUyd0WwNHZ2\ndkY2AgBgSbhCCKDeaNy4cefOnV1dXc1dCCyQ3p+rRo0amb4SAABMiUAIAIDIzc3VbeRJtgAA\ni0cgBABAFBQU6Dbm5+ebvhIAAEyJQAgAgPDz89NtbN68uckLAQDApAiEAACISZMmKRSKii2O\njo4jR440Vz0AAJgGgRAAAJGbm1tWVlaxpaysjCmjAACLRyAEAEDs37+/UktRUdHhw4fNUgwA\nACZDIAQAQKSlpRnZCACAJSEQAgAg3NzcdBsbNmxo+koAADAlAiEAAGLIkCG6jYMGDTJ9JQAA\nmBKBEAAAMWzYsD/96U/at7a2tjNnzuzQoYMZSwIAwARszF0AAADmJ5PJZs+ePXz48JSUFKVS\n2aJFCw8PD3MXBQBArSMQAqgfzp07991332VmZjZp0mTEiBHt27c3d0WwQL6+vkFBQWq1Ojs7\n29y1AABgCgRCAPXA3r179+7dK72+cePG999//9Zbb/Xr18+8VQEAANR33EMIoK5LTU3VpkGt\nDz/8sKSkxCz1AAAAWAwCIYC6LiEhQbfx4cOHiYmJpi8GAADAkhAIAdR1MpmsWu0AAAAwEoEQ\nQF3XsWNH3UZnZ+dWrVqZvhgAAABLQiAEUNc1adJk0qRJlRrnzJmjVCrNUQ4AAIDl4CmjAOqB\nF198sVWrVidPnpSWnRg+fHjr1q3NXRQAAEC9RyAEUD9069atX79+jo6Oubm5PF8UAADgiWDK\nKAAAAABYKQu/QiiXyxUKhbmrsC6ccNQeuVwu+P81TIKfMdQe6QnJ/CoDUEdYeCC0tbW1t7c3\ndxVWRCaTOTk5mbsKWCwpEDo4ONjZ2Zm7FlgyhULBrzLUHikH2tra8mMGoC6w8EBYVFRUWlpq\n7iqsiEajycnJMXcVsFgODg6Ojo75+fncQ4ja4+HhUVZWxq8y1B61Wi2EKCoq4sfMZDw8PMxd\nAlB3cQ8hAAAAAFgpAiEAAAAAWCkCIQAAAABYKQIhAAAAAFgpAiEAAAAAWCkLf8ooTGnYsGE8\nQRsAAACoRwiEeGJef/318vLyBw8emLsQAAAAAEZhyigAAAAAWCkCIQAAAABYKQIhAAAAAFgp\n7iEEUD9oNJrU1NSHDx+6ubk5OzubuxwAqKGmTZt2796d32MA6giZRqMxdw21KCcnp7S01NxV\nWAt3d3ceKoNakpGRsXbt2l9++UV6GxISMmfOHJVKZd6qYJE8PDzUanV2dra5C4HFUqlUKpWK\nP1FMycPDw9wlAHUXU0YB1HVqtXrFihXaNCiEOHv27MaNG81YEgAAgGUgEAKo637++efffvut\nUuOZM2f++OMPs9QDAABgMQiEAOq6jIyMarUDAADASARCAHVdw4YN9bZzTwgAAMBj4imjeAI0\nGs358+dv376tUCjatWvXuXNnc1cEixIUFOTt7Z2SklKxsWvXrk2aNDFXSQAAAJaBQIjHpVar\nFy9e/O9//1vbEh4e/tprr5mxJFgYW1vbt99+e9WqVXfu3JFaOnXqFBUVZd6qAAAALACBEI/r\nyy+/rJgGhRDffvtt586dBw4caK6SYHmaN2++efPmW7duZWdne3h4tGjRwtwVAQAAWAICIR7X\n999/r7eRQIgny8bG5qmnnnJ0dMzNzS0pKTF3OQAAAJaAh8rgcRUWFuo2FhQUmL4SAAAAANVC\nIMTj0jt5jxl9AAAAQN1HIMTjmjRpkq2tbcUWFxeXF1980Vz1AAAAADASgRCPq3nz5u+//35A\nQICNjY2trW3Xrl1Xr15d1cJxAAAAAOoOmUajMXcNtSgnJ6e0tNTcVVgLZ2dnIURubq65C4El\nKygocHR0tOxfXDAvDw8PtVqdnZ1t7kJgsVQqlUql4k8UU/Lw8DB3CUDdxVNG8cQolcry8nJz\nVwHLlJOTs3Xr1jNnzmg0GqVSOWzYsEmTJimVSnPXBQAAUL8RCAHUdeXl5e+99158fLz0trS0\n9ODBg6WlpTNnzjRvYQAAAPUd9xACqOuuXr2qTYNaR48effDggVnqAQAAsBgEQgB1XUpKim5j\neXm53nYAAAAYjymjAOo66XlFulxcXExcCSye9EWDQqHgDlUAgJUgEAKo64KCgjw8PO7fv1+x\nMSAgwNfX11wlwSLFxMRs27ZNer6on5/fnDlz2rdvb+6iAACoXUwZBVDXqVSqN998083NTdvi\n4+Mzf/58M5YEy3Pp0qXVq1drV5u4c+fOokWLMjIyzFsVAAC1jSuEAOqBDh067Nix4+eff37w\n4IGHh0dQUJCNDb++8CTt27evUkt+fv7Bgwd5mC0AwLLxFxWA+kGlUg0YMMDR0TE3N7ekpMTc\n5cDS6H1GUWpqqukrAQDAlAiEAAAIV1fX3Nxc3UazFANLVVJS8sUXX8TExNy7d8/Hx2fkyJED\nBw40d1EArB33EAIAIMLCwoxsBGps7dq1+/bt+/3339Vq9a1bt9asWfP111+buygA1o5ACKDe\nyM7O/s9//pOfn2/uQmCB/vKXv1S8VqNUKidPntylSxczlgQLc/Xq1e+//75S444dO4qLi81S\nDwBImDIKoB7IzMz88MMPL1y4IISQy+WDBg2aPn26nZ2dueuC5ZDL5fPmzRsxYoS0DmGbNm28\nvLzMXRQsSmJiom5jUVFRcnKyv7+/6esBAAmBEEBdV15evnLlyoSEBO3b48ePl5WV/fWvfzVv\nYbA8rVu37tWrl1qt1q4/ATwpVX2HZW9vb+JKAKAipowCqOt+/vlnbRrU+vbbbystVQ8AdVlw\ncLBuJvTz82vWrJlZ6gEACYEQQF33+++/6zZqNBq97QBQN3l6ekZGRiqVSm1LgwYN5s+fL5PJ\nzFgVADBlFEBdV9Wj/xs2bGjiSgDgcYSHh7dt2/bcuXMPHjxo0qRJWFiYs7OzuYsCYO0IhADq\nuqCgoMaNG2dkZFRs7NSpE/OsANQ7fn5+AQEBKpUqJyentLTU3OUAAFNGAdR59vb2CxcubNy4\nsbbF399//vz5ZiwJAADAMnCFEEA90KZNm48//jghISE7O9vT07N9+/ZyOd9nAQAAPC4CIYD6\nwdbWtnfv3o6Ojrm5uSUlJeYuBwAAwBLwFTsAAAAAWCkCIQAAAABYKQIhAAAAAFgpAiEAAAAA\nWCkCIQAAAABYKQIhgHqjrKzs/v37Go3G3IUAAABYCJadAFAP5OXlffLJJydPniwtLXVwcPjL\nX/7y4osv2tjwGwwAAOCx8OcUgLpOo9GsXr06Li5OeltYWLh3797i4uLJkyebtzAAAID6jimj\nAOq6hIQEbRrUOnjwYHZ2tlnqAQAAsBhcIQRQ1929e1e3sby8PCUlxdXV1fT1wFKVl5efPXv2\n9u3bSqWyQ4cOgYGB5q4IAIBaRyAEUNfZ29vrbW/QoIGJK4EFKykpmT9//q+//qptGTRo0Ny5\nc81YEgAAJsCUUQB1nUwm09uuUChMXAks2KeffloxDQoh/vnPf549e9Zc9QAAYBoEQgB1XWFh\nod72Bw8emLgSWLBz584Z2QgAgCUhEAKo67y8vHQbZTJZkyZNTF8MLFVRUZFuY1VfRgAAYDEI\nhADqus6dO7dv375SY2hoqIeHh1nqgUVq2bKlbqO/v7/pK8lyyvAAABubSURBVAEAwJQIhADq\nOoVC8dZbbwUHB0tv5XJ5eHj4zJkzzVsVLMyUKVNsbW0rtnh6ev7lL38xVz0AAJiGTKPRmLuG\nWpSTk1NaWmruKqyFu7t7eXk5t3Wh9uTl5eXm5jZs2LCq544Cj+PXX3/95JNP/vOf/yiVyi5d\nukydOlXvdGXgMalUKpVKxZ8opsSMEsAAAiGeGAIhapuDg4Ojo2Nubm5JSYm5a4HFcnNz02g0\n2dnZ5i4EFotAaHoEQsAApowCAPB/WM4EAGBVCIQAAAAAYKUIhAAAAABgpQiEAAAAAGClCIQA\nAAAAYKUIhAAAAABgpQiEAAAAAGClCIQAAAAAYKUIhAAAAABgpQiEAAAAAGClCIQAAAAAYKUI\nhAAAAABgpQiEAAAAAGClbMxdAAAAdUJqauquXbtu3rxpY2MTGBg4btw4Z2dncxcFAEDtIhAC\nACDS0tJmzZpVWFgovU1OTr58+fLGjRvt7e3NWxgAALWKKaMAAIiPP/5YmwYld+/ePXTokLnq\nAQDANAiEAACI69ev6zb++uuvpq8EAABTIhACACCUSqVuo62trekrAQDAlAiEAACIrl276jZ2\n69bN9JUAAGBKBEIAAERERESzZs0qtvTo0SM8PNxc9QAAYBo8ZRQAAOHk5PTRRx99/fXXSUlJ\ntra2nTp1euaZZ+RyvjYFAFg4AiEAAEIIYWdnN3LkSA8PD7VanZ2dbe5yAAAwBb77BAAAAAAr\nRSAEAAAAACvFlFEAAABTKC4u3r9/f0xMzP379729vV944YWBAwfKZDJz1wXAqhEIAQAATGHt\n2rWxsbHS6zt37qxdu7agoGDYsGHmrQqAlWPKKAAAQK375ZdftGlQa8eOHUVFRWapBwAkBEIA\nAIBal5SUpNtYXFyckpJi+mIAQItACAAAUOvs7Oz0tjs4OJi4EgCoiEAIAABQ64KDg+3t7Ss1\nNm/evGnTpmapBwAkBEIAAIBa5+npGRkZqVQqtS3Ozs5vvPEGTxkFYF48ZRQAAMAUwsLC2rZt\ne+7cuezsbC8vr7CwsAYNGpi7KADWjkAIAABgIr6+vlOmTFGpVDk5OaWlpeYuBwCYMgoAAAAA\n1opACAAAAABWikAIAAAAAFaKQAgAAAAAVopACAAAAABWiqeMAgDwXxkZGZcvX7axsfH19XV2\ndjZ3OQAA1DoCIQAAQgjx8ccfHzlyRFoJQKVSzZgxIzw83NxFAQBQu5gyCgCAOH78+MGDB7Xr\nwhUUFHz44YfXr183b1UAANQ2AiEAAOLrr7+u1FJaWnr8+HGzFAMAgMkQCAEAEJmZmUY2AgBg\nSQiEAAAILy8vIxsBALAkBEIAAMQLL7xQqcXOzm7YsGFmKQYAAJMhEAIAIPr27Tt9+nQHBwfp\nrYeHx8KFC/38/MxbFQAAtY1lJwAAEEKIP//5z4MGDcrOzpbL5Q0bNlQqleauCACAWkcgBADg\nvxwcHHx8fNRqdXZ2trlrAQDAFJgyCgAAAABWikAIAAAAAFaKQAgAAAAAVopACAAAAABWikAI\nAAAAAFaKQAgAAID/1969hzVxpX8AP0kwIcGAIKDcFBAVrwtVKd16KVS6KCsVL48gPAgLCN1q\nn1XrVkQUQR9ZSYuUXVfBAqJdqVqXBWvculLWult3vRTEKgVqKcilaYQEBCEX8vtjtnnyIyEi\nEgKZ7+evyck5M+eceZ+ZvJmZBABoCgkhAAAAAAAATSEhBAAAAAAAoCkkhAAAAAAAADSFhBAA\nAAAAAICmkBACAAAAAADQFBJCAAAAAAAAmkJCCAAAAAAAQFNICAEAAAAAAGjKzKBrf/LkSU5O\nzs2bNxUKxdy5c9966y17e/tB1tHTtqmpKTMzs66urri42KD9BwAAAAAAMGGGvUJ45MiRhoaG\ntLS0zMxMFouVmpra19c3yDoDlX/55Ze7d+92dnY2aM8BAAAAAABMngETQrFY/N///vedd97x\n8PBwdnb+3e9+19TUVFlZOZg6etrK5XKBQODr62u4ngMAAAAAANCBARPC2tpaNpvt5uZGvRw/\nfryLi0ttbe1g6uhp6+/vb2dnZ7huAwAAAAAA0IQBnyHs6Ojg8/kMBkNdYmVlJZVKB1PHysrq\nmW11amho+OKLL9Qvly5dqv3UIhgOg8HgcrnG7gWYrHHjxhFC2Gw2i8Uydl/AlDGZTBzKwHCo\nQxmHwzEzM+xPOQAADIZhj0SaGR0hRKVSDb7OYNpq++6777Kzs9UvZ82apb7MCCOAwWBYWFgY\nuxdg4szNzY3dBTBxTCYThzIwNBzKAGCUMGBCOGHChI6ODpVKpU7tpFKptbX1YOoMpq1Oc+bM\nSU9PV790cnLq7OwcnvHAs4wfP16lUnV1dRm7I2Cy2Gw2h8N5+vSpQqEwdl/AZPH5fKVS2d3d\nbeyOgMnicDhsNhuHspHE5/ON3QWA0cuACeGMGTPkcnldXd306dMJIVKptLGx0dPTczB1nJyc\nntlWJ3t7++XLl6tfSqXS3t7eYR4YDIBKCDHhYDhMJpPD4cjlcplMZuy+gMni8/k4lIFBsVgs\nNpstk8nkcrmx+0IXSAgB9DDgj8pYW1u/+uqr2dnZdXV1jY2NH3zwgYeHx5w5cwghV65cKS0t\n1VNHT9v29naxWExd9xOLxWKxuKenx3CjAAAAAAAAMFWMQT6bNzTd3d25ublfffVVX1+ft7d3\nQkICddtnRkZGR0dHWlqanjoDlcfGxopEIs2txMbGBgcH6+yAVCrF128jZuLEiX19fe3t7cbu\nCJgsLpdrYWHR0dGBK4RgOLa2tgqFQiKRGLsjYLJ4PB6Px8NHlJFka2tr7C4AjF6GTQiBVgQC\ngaWl5ebNm43dETBZ//73v8vLy9etWzdjxgxj9wVM1qFDhyZPnhwdHW3sjoDJunbt2vXr10ND\nQ93d3Y3dFwAAQ94yCnRTUlLyj3/8w9i9AFNWU1Nz4cKF5uZmY3cETNlf//pXzb8vAhh2Dx48\nuHDhQr/bnQAAjAUJIQAAAAAAAE0hIQQAAAAAAKApJIQAAAAAAAA0hR+VAQAAAAAAoClcIQQA\nAAAAAKApJIQAAAAAAAA0hYQQRtrq1atv3Lhh7F7ACxmZnahUKoODgysrK42ydTAWRBcMOwSV\nscjl8m3btl28eHGgCvn5+WlpaXh8CcC4zIzdATCCpqamzMzMurq64uJinRW2b99eV1dHLbNY\nLDs7u2XLlq1fv57NZo9gN//n7t27PB7Pw8Nj5Dc9arW1teXn51dUVMjlcjc3t+joaO0/ajeB\nnchkMg8ePOjm5jaENWgOnxDC5/Pd3d0jIiJmzpz5XH2gocbGxvz8/Orq6r6+Pjc3t02bNnl6\nevarQ/PoIs95FCWIwJ9dvXo1Kytr9+7dvr6+/d6ieVCZasAUFBRMmDDh17/+NRngzBUZGbl9\n+/aSkpI333zT2J0FoC8khLTz5ZdfnjhxwtvbW/Pco+31118PDw8nhCgUitra2uPHjz958iQ+\nPl6zjlKpZLFYhu0uIcXFxYsWLUJCqOnAgQMcDmf//v1cLvf06dNpaWm5ubnm5ub9qo31nchg\nMObNmzfkNaiHTwiRSCTFxcXJycnZ2dmTJk16rm70MzIzNpIb0iSXy/fs2ePl5ZWRkcFkMj/5\n5JOUlJT8/Hwul9uvJp2j63mPogQRSAghRCKRnDx5Uk+CR+egIqYYMCKRSCgUCgQC6uVAZ66w\nsLDs7Ow33nhD+zgDACMDCSHtyOVygUDw3XfflZeX66lmbm5ua2tLLU+ePFkkEhUXF8fHxyuV\nypCQkHfeeaeoqGj27Nnbt2+XSCS5ubn37t1TKBRubm6xsbGurq4ymWzdunVbt24tKytrbW3l\ncrlRUVE+Pj7UCjs7O1NSUu7du2dpaRkREeHv708IkUgkOTk5d+7cYbFY06ZNi42NnTJlSlJS\n0r179yorKz///PPMzEwDz83Y0NnZOWnSpIiICCcnJ0JIVFRUTExMQ0OD9kXCUb4TY2JiwsPD\nqYanTp06d+7ciRMn7O3tCSGJiYne3t5r164NCQlJS0s7e/ZsvzXo3Lqe4dva2m7bti0sLOzW\nrVtBQUEDdZUQ8vDhw6NHjzY0NDg5OUVHR+/Zs+fIkSNTp07VnjGdza9evfrpp5+KRCIej/fK\nK6/ExMSw2WydhTrnXHvX6Gw7fNHUX3d39+rVqwMDA6lPZuvXr6f2PnXRY6DppVt0DeEoOnYj\ncAhRNJBjx475+/uXlZUNZsboFlTEFANGKBROnz7d3d2d6D1zvfzyyzk5OeXl5StWrBhaaAHA\nC8IzhLTj7+9vZ2f3vK3YbHZfXx8hhMViMRgMoVC4e/fuhIQEQsiBAweePn2alZX10Ucfubu7\nJyYmdnZ2Ul8TlpSU7Nq1Kz8/Pzg4+NChQyKRiFpbSUlJaGjoX/7yl9dee+3o0aM9PT2EkPff\nf58Qkpubm5+fP2PGjOTk5N7e3oMHD9rZ2cXGxiIbVOPz+e+99x51TiWEPH78mMFg2NjYPLPh\naNuJXl5e33zzDbVcVVU1depU6qVMJqupqXnppZfUNbXXoHPr+jGZTCaTqVQqqZc6uyqXy1NS\nUlxcXAoLC999992TJ09S06U9Yzqbt7a2fvjhh/Hx8WfPnn3//fdra2tLSkp0FuqZc80NDdTW\ncKysrEJCQqhssLOzs6SkxNnZ2dnZ+ZkNaRVdQzuKjsUIfN4x6vHVV189fPhw48aNg29Cq6DS\nZgIB8/XXX3t5eVHLes5cDAZj/vz5FRUVz5wTADAQJITwDCqVqr6+vrS09OWXX6ZKGAyGj4+P\nu7s7j8d7+PBhTU1NVFTUhAkTzM3Nw8PD5XL5f/7zH6rm66+/bmVlRQh54403OBzO7du3qXI/\nPz9PT082m/2rX/1KJpOJRKKGhobKysrNmzfz+Xw2mx0eHi6TyW7evGmUIY8hnZ2d2dnZq1at\nUn+vrNPo3InqT1c9PT0NDQ2BgYH37t0jhHz77bdcLnfatGl6RqS9df0T1dPTU1BQ0Nvbu2jR\nIkLIQF2trq6WSCRhYWHm5uZOTk7Ucy/aMzZQc6lUqlKpxo8fz2Qy7ezsBALBunXrdBbqmXPN\nDelsq3+kw6Kvr2/NmjXh4eENDQ0HDhwYN26cnsqIrsEYoxH44gOnPHny5NixY1u3bh3k9W0E\nlWkETENDg6urq/botM9crq6uDQ0N+ucEAAwHt4yCbpcvX7569SohRKFQqFSqZcuWxcbGqt91\ndHSkFlpaWhgMhvo7Pw6HM3HixNbWVuqlg4MDtcBkMq2trX/66ad+5dSHA5lMJhaLCSGRkZGa\nfVCvB3R69OhRWlqal5dXTEyMzgqjfCd6eXkJBIL29vbvv//e3d19/vz51PfQVVVVXl5eDAZD\nz9i1t65n+ISQnp4e6k4wqmFzc7POrspkMuozEFXS7y5c9YwN1PzVV18NCgp69913p0+f7uXl\ntXTpUmdn5xkzZmgX6p9z9YZ0ttUzLcOFyWRmZWVJJJKSkpKkpCSBQGBhYdGvDs2jazBMIAKH\ny0cffeTj46N+vm4gNA8qEwuY7u5uhUJhaWnZr1znmcvS0rKjo0PXzAHASEBCCLotWbIkLCyM\nEMJisSZOnNjvSXE9VwxUKpX6vEjd7aNeVn83rH3ipErOnz9vlB+UG4sqKysPHz68ceNG6vES\nnUb5TuTz+dOmTbt//35tbe3cuXNdXFy6urra2tqqqqoCAgL0t9X/2YuiHn53d3dycvLKlSsX\nLlyov6tlZWWaa+63FfWM6RlpfHz82rVrb968efPmzXPnzu3YsWPx4sXahdr915xzzQ3pXOEz\nx/7iXFxcXFxcZs+eHRkZWV5erh1mNI+uwTCBCBwWFRUVVVVVH3744TNr0jyo6BAwgzlzAcDI\nwy2joJuFhYWDg4ODg4O9vb2eHyhzdHRUqVSPHj2iXvb09LS1tam/Cm1qaqIW5HJ5W1ubntsa\nqe8XHz58qC7B5UE97t+/f/jw4R07dug/p47+nUjdglVVVTV37lxCyKxZs+7cuVNbW+vt7a2/\n4WCohz9t2rTNmzfn5eU1Njbq76qNjY1SqXz8+DFVWFNTo3PNAzVXKpVSqdTW1nbFihV79+5d\nuXLlpUuXdBbqn3M1nW1ffGb0oO4rUz/gxGQyGQyGzr8Io3l0DYYJROCwuHLlikQiiYuLCw8P\nDw8Pl0qlmZmZhw4d0q5J86AysYDh8XhmZmaa1/30nLk6Ojq0ryUCwIhBQkg77e3tYrG4s7OT\nECIWi8ViMfXh78qVK6Wlpc+7Njc3N09Pz5MnT0ql0u7u7oKCAi6Xq/6DqS+++KK+vl4ul1+4\ncEGlUqmfBtHm4uIyf/78vLw8sVisVCqFQuHWrVvb29sJIRwOp6WlheowEEJkMtmRI0eCg4On\nTJki/tkY3Yne3t6VlZU//PAD9U93c+bMKSkpcXR0tLa27lfzBcPgtddeW7BgQUZGhlwu19NV\nT09PHo937ty53t7epqYmoVD4XCMtKyvbtm1bXV2dSqWSSCQNDQ2TJ0/WWah/ztV0th3aDAyS\nh4dHb29vVlZWY2Nja2vriRMnenp6qF/LQHSpDXQU1WOMRuCwSEhIOHbsWNbPLC0tY2Nj3377\nbYKgGphpBMyUKVPq6+upZT1nLkJIfX099aunAGAUuGWUdnbu3Kl+nP03v/kNISQ2NjY4OLii\noqKjo2PVqlXPu8Lf//73x48fj4uLGzdu3MyZM9PT03k8HvXDaEFBQceOHaurq5s0aVJiYiKf\nz9eznh07duTm5m7ZsqWvr8/V1TUlJYU6xQYGBhYWFt64cSMnJ2coAzY5Dx48aG1t/fjjjz/+\n+GN1YXx8fFBQ0JjbibNmzfrpp588PDyoG5lmz56dl5cXEhKiveYXD4Pf/va3W7ZsKSgoiIuL\n09PVpKSknJyciIgId3f3sLCwvXv3Mpk6vjjT2Xz58uWPHz9OT09vb2+3sLBYsGBBTEwMj8fT\nLhxozvttRecKhzb8QbKwsEhNTT158uSuXbuUSuXUqVP37t1LXV5AdKkNdBTV32osRuCw4PP5\nmnuWwWDw+XzqchCCSg8TCBhvb++KigrqPlg9Zy6VSnX37t0NGzYMbaIA4MXpvhcI4AVR/02U\nkpKi+UvcMLbQcycqlUqVSmVmZkYI+fbbb3fu3FlUVGSgD8p0Rs/oGgxE4JDRM6hGc8CIRKKE\nhASBQED9FeFAbty4kZ2dfeLECfwxPYCx4JZRAID/UalUW7Zs+dOf/tTV1dXe3n7mzJl58+aN\nko9WQAeIQHguozxg7O3tV6xYcerUKT11lEplUVHRhg0bkA0CGBESQgCA/2EwGLt27RKJRNHR\n0Vu3buVyudu3bzd2p4BGEIHwXEZ/wERFRUkkEj1Pip46dcrGxmYItw0DwDDCLaMAAAAAAAA0\nhSuEAAAAAAAANIWEEAAAAAAAgKaQEAIAAAAAANAUEkIAAAAAAACaQkIIADCKpKSkMBgMe3t7\nuVyu/W5cXByDwVi8ePHQVh4aGjp+/PjB1Fy8eLGnp+fQtgIAAABjCBJCAIDRhclktrW1CYXC\nfuU9PT3nzp1js9lG6RUAAACYJCSEAACjC5PJ9PX1LSgo6FdeUlLS1dX10ksvGaNTAAAAYJqQ\nEAIAjC4KhWL16tWfffbZ48ePNcsLCwv9/Pz6XSEUCoVLly7l8/lcLnfu3LkffPCB+t9lVSpV\namqqi4uLubn5vHnzzp8/z2AwNNv+61//CggIsLS05HK53t7eeXl5OvvT0tISFxc3depUc3Pz\nyZMnr127trq6elhHDAAAAEaDhBAAYNQJCQlRKBRnzpxRl4hEor///e+hoaEymUxdWFxcHBQU\nRAgpKCj429/+9stf/nLHjh07d+6k3s3IyNi3b9+SJUtKS0uTkpL27dv39ddfq9uWl5f7+fnJ\n5fLTp0+XlJT4+vrGxMQIBALtzqxZs+bixYt79+69dOmSQCCoqalZtmxZd3e3oQYPAAAAI4ih\n/i4ZAACMLiUlZf/+/U+fPl21alV7e/utW7eo8qysrMTExB9//DEgIMDMzOz69euEkFmzZnV1\nddXW1nI4HKoalby1tLTY2Ng4OztbW1tXVVVRFwabm5tdXV3ZbPaTJ08IIQsXLmxra3vw4IG6\n7ZtvvvnPf/6zpaWFy+UuXrxYLBZXV1d3dHRYWVm999576enpVLXvv/++qKho06ZNjo6OIzw5\nAAAAMOxwhRAAYDSKioq6ffv2N998Q70sLCxcvXo1n89XV2hubq6url6xYoU6oyOEBAUFyeXy\nGzduNDY2Njc3+/v7q28TdXR0XLhwIbUsFotv374dGBioUql6frZy5UqpVHr79m3NbvB4PFtb\n26KioqtXr/b19RFC3NzcEhMTkQ0CAACYBiSEAACjUUhICJ/Pp35a5v79+3fu3ImMjNSs0NTU\nRAhxdnbWLKTytJaWltbWVkKIvb299ruEkMbGRkLIn//8Z66GhIQE9WrVzMzMLl26xGAwli9f\nbmdnt2HDhjNnziiVymEeLQAAABiJmbE7AAAAOvB4vPXr158+fTo9Pb2wsNDBwSEgIECzAnXp\nT/ORQkII9RQAg6H7cQB1Ike1jY6O3rx5c786Hh4e/UoWLVpUV1d37dq1y5cvC4XCs2fP/vGP\nfywrK9O8MgkAAABjFBJCAIBRatOmTXl5edevXy8qKtq4cSOLxdJ818XFhfx8rU/t0aNHhBBn\nZ2c7OztCyI8//qj5bn19PbUwZcoUQkhfX5+vr+9gesJisfz8/Pz8/P7whz8cP348ISHhk08+\n6XfFEgAAAMYi3DIKADBKLVmyxN3dPSMj44cfftDOviZNmjRv3ryLFy8+ffpUXVhcXMzj8V55\n5RVXV1dbW1v1g3+EkOrq6rt371LLNjY2Pj4+xcXFEolE3bawsHDPnj0KhUJzK7du3QoNDRWJ\nROoS6kKlZgkAAACMXUgIAQBGKQaDERkZ+dlnn/3iF7+YP3++doVDhw61t7cHBAR8+umnpaWl\nGzduFAqFycnJlpaWTCbzrbfeevDgwZo1a86fP3/06NHAwMAFCxao2x4+fLi7u3vJkiWnTp36\n/PPPk5OTY2Njm5ubzcz+350jTk5Oly9fDggIyMvLu3LlypkzZyIiIjgczqpVqww+fgAAADA8\n3DIKADB6RUZG7t+/f6CbM4OCgi5dunTw4MFNmzYpFIrZs2fn5eVFR0dT7+7bt08ulxcUFAiF\nwpkzZx45cqS8vLyiooJ6d9myZWVlZampqW+//bZcLndzc0tNTVX/h6Gag4PDtWvXUlNTk5KS\n2traJk6c6OPjc+3atZkzZxpu1AAAADBi8D+EAAAAAAAANIVbRgEAAAAAAGgKCSEAAAAAAABN\nISEEAAAAAACgKSSEAAAAAAAANIWEEAAAAAAAgKaQEAIAAAAAANAUEkIAAAAAAACaQkIIAAAA\nAABAU0gIAQAAAAAAaAoJIQAAAAAAAE0hIQQAAAAAAKCp/wNTagcgePnxJAAAAABJRU5ErkJg\ngg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- new.get_result(result.m01.1, '1.Prophet')\n",
    "errors.2 <- new.get_result(result.m01.2, '2.Prophet with Regressors')\n",
    "errors.3 <- new.get_result(result.m01.3, '3.Prophet with 1 Regressor')\n",
    "errors.4 <- new.get_result(result.m01.4, '4.Prophet with Regressor (2)')\n",
    "\n",
    "x <- rbind(errors.1, errors.2)\n",
    "x <- rbind(x, errors.3)\n",
    "x <- rbind(x, errors.4)\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8351dcbc-33db-44ea-a47d-550e48cc6e6c",
   "metadata": {},
   "source": [
    "### save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b27ae32-b956-4e94-9aec-d07bfd72a72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- result.m01.1\n",
    "write.csv(x, file = \"prophet_result_m0101.csv\")\n",
    "x <- result.m01.2\n",
    "write.csv(x, file = \"prophet_result_m0102.csv\")\n",
    "x <- result.m01.3\n",
    "write.csv(x, file = \"prophet_result_m0103.csv\")\n",
    "x <- result.m01.4\n",
    "write.csv(x, file = \"prophet_result_m0104.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c5f45-45d6-4303-82e4-1a2f9d7fbd8c",
   "metadata": {},
   "source": [
    "### load result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2e2b68b-2e54-484a-9d72-6d74422bd9c6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.m01.1 <- read.csv(file = 'prophet_result_m0101.csv')\n",
    "result.m01.2 <- read.csv(file = 'prophet_result_m0102.csv')\n",
    "result.m01.3 <- read.csv(file = 'prophet_result_m0103.csv')\n",
    "result.m01.4 <- read.csv(file = 'prophet_result_m0104.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cb8d98e-9491-400a-abd5-6a4694dfe9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m01 <- result.m01.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d38357-ca19-4a00-a9f3-88f56e5a4726",
   "metadata": {},
   "source": [
    "# BSTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b1a082-dca7-457f-a151-90f7518efe7a",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "92d8cf60-d4b2-4d74-b586-01285de500da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast <- function(x, h, xreg=NULL, xreg.msize=NULL, expected.model.size=0,\n",
    "                        model=NULL, niter=1000) \n",
    "{\n",
    "    if (!is.null(xreg)) {\n",
    "        ### set params for fitting\n",
    "        # organize data for fitting\n",
    "        if (is.null(dim(x))) {x <- data.frame(x)}\n",
    "        colnames(x) <- 'y'\n",
    "        x.train <- cbind(x, xreg)\n",
    "        x.train <- as.data.frame(x.train)\n",
    "        \n",
    "        if (is.null(model)) {\n",
    "            n <- ncol(x.train)\n",
    "            if ((expected.model.size < 1) | (expected.model.size > n)) {\n",
    "                expected.model.size <- n\n",
    "            }\n",
    "            ss <- AddSemilocalLinearTrend(list(), x.train$y)\n",
    "            model <- bsts(y ~ .,\n",
    "                          state.specification = ss,\n",
    "                          niter = niter,\n",
    "                          data = x.train,\n",
    "                          expected.model.size = expected.model.size)  # Passed to SpikeSlabPrior.\n",
    "            olddata <- NULL\n",
    "        } else {\n",
    "            olddata <- x.train\n",
    "        }\n",
    "        \n",
    "        ### set params for prediction\n",
    "        # regessor assumption for future\n",
    "        if (is.null(xreg.msize)) {\n",
    "            xreg.m <- xreg # calc mean for future with all the xreg\n",
    "        } else {\n",
    "            # calc mean for future with xreg of length xreg.mszie\n",
    "            xreg.m <- tail(xreg, n=xreg.msize)\n",
    "        }\n",
    "\n",
    "        if (is.null(dim(xreg))) {\n",
    "            xreg.h <- mean(xreg.m)\n",
    "        } else {\n",
    "            xreg.h <- colMeans(xreg.m)  \n",
    "        }\n",
    "\n",
    "        xreg.all <- data.frame(xreg)\n",
    "        xreg.coln <- colnames(xreg.all) # save name for the case of single xreg\n",
    "        xreg.h <- data.frame(xreg.h)\n",
    "        colnames(xreg.h) <- colnames(NA)\n",
    "        xreg.h <- t(xreg.h)\n",
    "        xreg.h <- as.ts(xreg.h[rep(seq_len(nrow(xreg.h)), h), ])\n",
    "        xreg.h <- data.frame(xreg.h) # convert to frame for the case of single xreg\n",
    "        \n",
    "        if ((dim(xreg.h)[2]==1) & (dim(xreg.h)[1]==length(xreg.coln))) {\n",
    "            xreg.h <- t(xreg.h) # the case of h==1\n",
    "        } else {\n",
    "            xreg.h <- as.ts(xreg.h) # convert to ts as xreg is ts\n",
    "        }\n",
    "        \n",
    "        colnames(xreg.h) <- xreg.coln # match name to rbind\n",
    "        \n",
    "    } else {\n",
    "        if (is.null(model)) {\n",
    "            ss <- AddSemilocalLinearTrend(list(), x)\n",
    "            model <- bsts(x, state.specification = ss, niter=niter)\n",
    "            olddata <- NULL\n",
    "        } else {\n",
    "            olddata <- x\n",
    "        }\n",
    "        xreg.h <- NULL\n",
    "    }\n",
    "    # predict\n",
    "    fc <- predict(model, horizon=h, newdata=xreg.h, olddata=olddata)\n",
    "    fc$model <- model\n",
    "    return(fc)\n",
    "}\n",
    "\n",
    "bsts.forecast <- cv.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da073aa9-90be-43a4-a317-965c6c100ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main difference with cv.forecast is that cv.forecase.2 need data for forecasting\n",
    "cv.forecast.2 <- function(x, h, xreg=NULL, xreg.msize=NULL, sample.n=0) \n",
    "{\n",
    "    result.rmse <- c()\n",
    "    result.mape <- c()\n",
    "    train.len <- length(x) - h\n",
    "    my.subset <- function(x, s, e) {\n",
    "        if (!is.null(x)) {\n",
    "            x <- subset(ts(x), start=s, end=e)\n",
    "        }\n",
    "        return(x)\n",
    "    }\n",
    "    idx <- 0:(h-1)\n",
    "    if ((sample.n>0) & (sample.n<h)) {\n",
    "        idx <- sort(sample(idx, sample.n))\n",
    "    }\n",
    "    \n",
    "    model <- NULL\n",
    "    for (i in seq_along(idx)) {\n",
    "        trlen <- train.len+idx[i]\n",
    "        x.train <- my.subset(x, 1, trlen)\n",
    "        xreg.train <- my.subset(xreg, 1, trlen)\n",
    "        \n",
    "        fc <- cv.forecast(x.train, 1, xreg=xreg.train, xreg.msize=xreg.msize, \n",
    "                          #expected.model.size=0,\n",
    "                          model=model, niter=1000) \n",
    "        \n",
    "        if (i==1) { # reuse model for the rest of periods\n",
    "            model <- fc$model\n",
    "        }\n",
    "        \n",
    "        result.rmse[i] <- sqrt(mean((fc$mean - x[trlen+1])^2))\n",
    "        result.mape[i] <- mean(abs(1 - fc$mean / x[trlen+1]))\n",
    "    }\n",
    "    e <- list(rmse.mean=mean(result.rmse), rmse.sigma=sd(result.rmse), \n",
    "              mape.mean=mean(result.mape), mape.sigma=sd(result.mape))\n",
    "    return(e)\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d8fc5f-8e48-4ea2-b707-e1f062d6b634",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0bae75e-ad34-40a9-aceb-7542fa7c13fd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:49:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:49:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:49:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:49:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:49:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:49:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:49:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:49:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:49:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:49:48 2022 =-=-=-=-=\n",
      "[1] \"8 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:49:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:49:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:49:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:50:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:50:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:50:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:50:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:50:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:50:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:50:18 2022 =-=-=-=-=\n",
      "[1] \"17 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:50:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:50:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:50:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:50:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:50:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:50:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:50:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:50:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:50:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:50:48 2022 =-=-=-=-=\n",
      "[1] \"25 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:50:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:50:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:50:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:51:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:51:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:51:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:51:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:51:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:51:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:51:19 2022 =-=-=-=-=\n",
      "[1] \"33 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:51:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:51:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:51:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:51:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:51:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:51:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:51:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:51:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:51:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:51:48 2022 =-=-=-=-=\n",
      "[1] \"42 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:51:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:51:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:51:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:52:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:52:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:52:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:52:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:52:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:52:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:52:18 2022 =-=-=-=-=\n",
      "[1] \"50 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:52:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:52:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:52:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:52:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:52:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:52:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:52:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:52:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:52:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:52:48 2022 =-=-=-=-=\n",
      "[1] \"58 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:52:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:52:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:52:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:53:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:53:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:53:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:53:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:53:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:53:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:53:18 2022 =-=-=-=-=\n",
      "[1] \"67 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:53:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:53:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:53:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:53:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:53:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:53:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:53:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:53:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:53:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:53:48 2022 =-=-=-=-=\n",
      "[1] \"75 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:53:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:53:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:53:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:54:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:54:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:54:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:54:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:54:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:54:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:54:20 2022 =-=-=-=-=\n",
      "[1] \"83 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 01:54:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 01:54:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 01:54:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 01:54:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 01:54:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 01:54:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 01:54:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 01:54:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 01:54:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 01:54:50 2022 =-=-=-=-=\n",
      "[1] \"92 % done.\"\n"
     ]
    }
   ],
   "source": [
    "result.m02.1 <- my.tsCV.2(train, cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "602a90d7-2081-46eb-8cf8-ca09307501bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-01-24\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m02.1\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b296acaf-74d0-4185-b130-b6512bbf03be",
   "metadata": {},
   "source": [
    "## Regression with spike and slab priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ecce414-f5fc-4f70-9f89-4908c5fe4e9a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Thu Sep 22 12:54:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 12:54:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 12:54:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 12:55:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 12:55:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 12:55:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 12:55:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 12:55:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 12:55:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 12:55:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 12:55:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 12:55:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 12:55:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 12:55:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 12:55:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 12:55:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 12:55:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 12:55:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 12:56:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 12:56:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 12:56:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 12:56:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 12:56:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 12:56:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 12:56:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 12:56:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 12:56:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 12:56:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 12:56:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 12:56:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 12:56:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 12:56:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 12:57:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 12:57:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 12:57:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 12:57:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 12:57:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 12:57:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 12:57:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 12:57:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 12:57:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 12:57:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 12:57:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 12:57:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 12:57:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 12:57:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 12:57:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 12:58:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 12:58:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 12:58:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 12:58:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 12:58:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 12:58:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 12:58:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 12:58:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 12:58:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 12:58:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 12:58:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 12:58:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 12:58:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 12:58:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 12:59:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 12:59:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 12:59:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 12:59:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 12:59:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 12:59:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 12:59:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 12:59:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 12:59:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 12:59:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 12:59:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 12:59:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 12:59:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 12:59:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 12:59:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 12:59:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:00:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:00:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:00:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:00:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:00:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:00:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:00:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:00:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:00:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:00:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:00:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:00:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:00:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:00:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:01:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:01:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:01:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:01:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:01:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:01:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:01:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:01:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:01:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:01:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:01:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:01:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:01:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:01:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:01:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:01:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:02:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:02:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:02:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:02:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:02:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:02:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:02:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:02:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:02:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:02:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:02:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:02:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:02:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:03:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:03:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:03:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:03:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:03:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:03:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:03:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:03:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:03:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:03:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:03:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:03:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:03:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:03:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:03:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:03:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:04:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:04:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:04:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:04:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:04:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:04:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:04:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:04:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:04:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:04:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:04:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:04:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:04:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:04:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:05:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:05:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:05:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:05:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:05:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:05:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:05:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:05:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:05:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:05:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:05:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:05:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:05:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:05:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:05:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:06:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:06:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:06:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:06:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:06:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:06:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:06:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:06:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:06:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:06:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:06:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:06:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:06:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:06:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:06:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:07:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:07:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:07:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:07:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:07:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:07:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:07:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:07:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:07:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:07:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:07:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:07:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:07:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:07:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:07:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:08:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:08:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:08:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:08:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:08:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:08:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:08:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:08:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:08:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:08:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:08:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:08:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:08:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:08:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:08:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:09:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:09:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:09:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:09:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:09:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:09:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:09:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:09:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:09:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:09:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:09:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:09:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:09:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:09:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:10:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:10:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:10:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:10:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:10:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:10:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:10:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:10:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:10:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:10:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:10:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:10:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:10:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:10:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:10:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:10:59 2022 =-=-=-=-=\n",
      "[1] \"10 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:11:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:11:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:11:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:11:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:11:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:11:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:11:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:11:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:11:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:11:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:11:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:11:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:11:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:11:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:12:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:12:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:12:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:12:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:12:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:12:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:12:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:12:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:12:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:12:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:12:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:12:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:12:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:12:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:12:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:13:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:13:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:13:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:13:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:13:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:13:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:13:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:13:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:13:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:13:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:13:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:13:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:13:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:13:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:14:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:14:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:14:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:14:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:14:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:14:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:14:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:14:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:14:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:14:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:14:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:14:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:14:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:14:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:14:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:14:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:15:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:15:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:15:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:15:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:15:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:15:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:15:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:15:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:15:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:15:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:15:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:15:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:15:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:15:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:16:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:16:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:16:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:16:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:16:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:16:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:16:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:16:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:16:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:16:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:16:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:16:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:16:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:16:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:16:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:17:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:17:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:17:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:17:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:17:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:17:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:17:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:17:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:17:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:17:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:17:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:17:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:17:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:17:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:18:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:18:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:18:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:18:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:18:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:18:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:18:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:18:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:18:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:18:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:18:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:18:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:18:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:18:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:18:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:19:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:19:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:19:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:19:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:19:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:19:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:19:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:19:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:19:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:19:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:19:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:19:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:19:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:20:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:20:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:20:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:20:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:20:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:20:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:20:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:20:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:20:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:20:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:20:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:20:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:20:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:20:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:20:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:21:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:21:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:21:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:21:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:21:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:21:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:21:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:21:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:21:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:21:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:21:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:21:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:21:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:21:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:21:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:22:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:22:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:22:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:22:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:22:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:22:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:22:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:22:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:22:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:22:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:22:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:22:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:22:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:22:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:23:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:23:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:23:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:23:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:23:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:23:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:23:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:23:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:23:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:23:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:23:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:23:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:23:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:23:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:23:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:24:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:24:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:24:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:24:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:24:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:24:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:24:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:24:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:24:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:24:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:24:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:24:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:24:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:25:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:25:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:25:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:25:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:25:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:25:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:25:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:25:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:25:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:25:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:25:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:25:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:25:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:25:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:25:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:26:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:26:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:26:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:26:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:26:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:26:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:26:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:26:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:26:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:26:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:26:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:26:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:26:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:26:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:27:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:27:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:27:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:27:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:27:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:27:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:27:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:27:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:27:29 2022 =-=-=-=-=\n",
      "[1] \"20 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:27:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:27:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:27:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:27:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:27:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:27:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:28:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:28:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:28:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:28:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:28:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:28:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:28:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:28:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:28:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:28:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:28:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:28:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:28:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:28:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:29:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:29:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:29:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:29:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:29:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:29:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:29:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:29:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:29:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:29:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:29:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:29:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:29:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:29:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:29:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:30:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:30:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:30:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:30:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:30:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:30:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:30:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:30:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:30:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:30:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:30:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:30:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:30:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:30:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:30:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:31:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:31:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:31:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:31:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:31:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:31:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:31:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:31:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:31:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:31:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:31:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:31:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:31:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:31:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:32:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:32:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:32:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:32:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:32:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:32:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:32:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:32:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:32:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:32:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:32:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:32:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:32:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:32:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:32:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:33:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:33:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:33:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:33:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:33:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:33:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:33:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:33:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:33:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:33:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:33:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:33:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:33:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:33:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:33:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:34:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:34:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:34:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:34:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:34:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:34:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:34:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:34:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:34:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:34:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:34:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:34:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:34:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:34:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:34:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:35:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:35:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:35:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:35:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:35:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:35:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:35:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:35:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:35:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:35:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:35:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:35:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:35:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:35:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:36:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:36:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:36:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:36:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:36:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:36:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:36:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:36:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:36:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:36:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:36:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:36:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:36:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:36:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:36:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:36:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:37:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:37:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:37:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:37:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:37:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:37:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:37:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:37:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:37:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:37:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:37:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:37:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:37:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:37:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:38:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:38:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:38:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:38:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:38:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:38:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:38:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:38:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:38:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:38:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:38:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:38:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:38:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:38:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:38:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:39:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:39:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:39:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:39:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:39:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:39:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:39:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:39:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:39:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:39:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:39:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:39:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:39:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:39:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:40:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:40:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:40:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:40:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:40:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:40:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:40:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:40:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:40:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:40:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:40:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:40:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:40:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:40:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:40:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:41:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:41:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:41:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:41:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:41:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:41:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:41:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:41:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:41:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:41:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:41:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:41:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:41:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:41:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:42:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:42:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:42:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:42:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:42:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:42:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:42:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:42:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:42:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:42:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:42:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:42:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:42:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:42:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:42:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:42:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:43:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:43:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:43:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:43:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:43:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:43:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:43:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:43:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:43:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:43:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:43:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:43:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:43:50 2022 =-=-=-=-=\n",
      "[1] \"30 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:44:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:44:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:44:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:44:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:44:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:44:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:44:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:44:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:44:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:44:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:44:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:44:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:44:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:44:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:44:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:44:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:45:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:45:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:45:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:45:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:45:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:45:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:45:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:45:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:45:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:45:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:45:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:45:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:45:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:45:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:46:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:46:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:46:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:46:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:46:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:46:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:46:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:46:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:46:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:46:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:46:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:46:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:46:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:46:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:46:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:47:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:47:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:47:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:47:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:47:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:47:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:47:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:47:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:47:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:47:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:47:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:47:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:47:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:47:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:47:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:48:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:48:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:48:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:48:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:48:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:48:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:48:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:48:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:48:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:48:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:48:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:48:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:48:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:48:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:49:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:49:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:49:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:49:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:49:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:49:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:49:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:49:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:49:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:49:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:49:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:49:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:49:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:49:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:49:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:49:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:50:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:50:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:50:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:50:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:50:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:50:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:50:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:50:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:50:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:50:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:50:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:50:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:50:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:50:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:50:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:51:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:51:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:51:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:51:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:51:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:51:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:51:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:51:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:51:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:51:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:51:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:51:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:51:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:51:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:51:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:52:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:52:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:52:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:52:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:52:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:52:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:52:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:52:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:52:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:52:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:52:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:52:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:52:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:52:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:53:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:53:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:53:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:53:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:53:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:53:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:53:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:53:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:53:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:53:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:53:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:53:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:53:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:53:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:53:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:54:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:54:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:54:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:54:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:54:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:54:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:54:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:54:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:54:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:54:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:54:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:54:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:54:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:54:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:55:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:55:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:55:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:55:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:55:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:55:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:55:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:55:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:55:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:55:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:55:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:55:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:55:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:55:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:55:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:55:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:56:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:56:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:56:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:56:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:56:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:56:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:56:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:56:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:56:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:56:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:56:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:56:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:56:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:57:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:57:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:57:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:57:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:57:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:57:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:57:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:57:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:57:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:57:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:57:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:57:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:57:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:57:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:57:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:57:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:58:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:58:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:58:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:58:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:58:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:58:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:58:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:58:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:58:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:58:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:58:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:58:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:58:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:58:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:59:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:59:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:59:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:59:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:59:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 13:59:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 13:59:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 13:59:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 13:59:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 13:59:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 13:59:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 13:59:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 13:59:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 13:59:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 13:59:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:00:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:00:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:00:08 2022 =-=-=-=-=\n",
      "[1] \"40 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:00:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:00:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:00:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:00:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:00:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:00:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:00:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:00:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:00:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:00:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:00:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:01:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:01:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:01:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:01:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:01:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:01:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:01:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:01:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:01:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:01:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:01:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:01:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:01:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:01:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:01:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:02:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:02:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:02:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:02:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:02:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:02:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:02:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:02:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:02:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:02:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:02:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:02:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:02:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:02:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:03:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:03:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:03:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:03:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:03:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:03:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:03:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:03:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:03:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:03:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:03:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:03:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:03:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:03:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:03:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:03:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:04:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:04:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:04:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:04:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:04:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:04:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:04:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:04:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:04:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:04:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:04:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:04:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:04:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:04:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:05:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:05:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:05:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:05:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:05:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:05:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:05:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:05:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:05:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:05:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:05:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:05:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:05:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:05:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:05:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:06:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:06:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:06:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:06:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:06:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:06:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:06:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:06:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:06:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:06:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:06:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:06:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:06:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:06:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:06:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:07:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:07:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:07:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:07:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:07:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:07:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:07:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:07:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:07:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:07:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:07:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:07:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:07:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:07:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:07:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:08:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:08:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:08:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:08:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:08:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:08:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:08:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:08:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:08:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:08:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:08:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:08:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:08:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:08:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:08:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:09:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:09:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:09:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:09:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:09:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:09:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:09:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:09:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:09:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:09:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:09:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:09:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:09:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:09:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:09:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:10:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:10:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:10:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:10:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:10:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:10:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:10:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:10:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:10:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:10:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:10:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:10:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:10:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:10:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:10:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:11:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:11:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:11:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:11:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:11:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:11:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:11:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:11:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:11:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:11:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:11:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:11:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:11:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:11:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:11:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:12:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:12:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:12:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:12:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:12:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:12:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:12:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:12:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:12:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:12:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:12:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:12:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:12:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:12:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:12:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:13:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:13:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:13:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:13:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:13:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:13:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:13:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:13:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:13:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:13:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:13:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:13:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:13:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:13:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:14:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:14:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:14:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:14:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:14:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:14:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:14:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:14:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:14:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:14:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:14:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:14:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:14:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:14:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:14:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:14:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:15:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:15:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:15:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:15:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:15:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:15:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:15:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:15:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:15:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:15:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:15:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:15:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:15:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:15:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:16:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:16:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:16:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:16:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:16:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:16:19 2022 =-=-=-=-=\n",
      "[1] \"50 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:16:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:16:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:16:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:16:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:16:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:16:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:16:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:16:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:16:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:17:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:17:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:17:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:17:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:17:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:17:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:17:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:17:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:17:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:17:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:17:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:17:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:17:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:17:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:18:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:18:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:18:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:18:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:18:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:18:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:18:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:18:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:18:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:18:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:18:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:18:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:18:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:18:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:18:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:18:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:19:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:19:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:19:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:19:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:19:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:19:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:19:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:19:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:19:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:19:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:19:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:19:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:19:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:19:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:20:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:20:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:20:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:20:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:20:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:20:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:20:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:20:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:20:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:20:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:20:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:20:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:20:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:20:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:20:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:20:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:21:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:21:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:21:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:21:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:21:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:21:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:21:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:21:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:21:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:21:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:21:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:21:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:21:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:22:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:22:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:22:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:22:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:22:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:22:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:22:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:22:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:22:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:22:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:22:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:22:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:22:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:22:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:22:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:22:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:23:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:23:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:23:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:23:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:23:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:23:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:23:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:23:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:23:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:23:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:23:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:23:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:23:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:23:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:24:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:24:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:24:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:24:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:24:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:24:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:24:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:24:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:24:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:24:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:24:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:24:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:24:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:24:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:25:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:25:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:25:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:25:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:25:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:25:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:25:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:25:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:25:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:25:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:25:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:25:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:25:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:25:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:26:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:26:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:26:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:26:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:26:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:26:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:26:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:26:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:26:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:26:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:26:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:26:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:26:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:26:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:26:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:27:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:27:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:27:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:27:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:27:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:27:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:27:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:27:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:27:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:27:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:27:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:27:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:27:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:27:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:27:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:28:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:28:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:28:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:28:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:28:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:28:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:28:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:28:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:28:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:28:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:28:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:28:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:28:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:28:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:28:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:29:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:29:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:29:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:29:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:29:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:29:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:29:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:29:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:29:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:29:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:29:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:29:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:29:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:29:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:29:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:30:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:30:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:30:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:30:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:30:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:30:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:30:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:30:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:30:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:30:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:30:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:30:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:30:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:30:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:31:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:31:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:31:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:31:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:31:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:31:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:31:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:31:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:31:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:31:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:31:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:31:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:31:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:31:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:31:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:32:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:32:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:32:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:32:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:32:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:32:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:32:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:32:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:32:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:32:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:32:41 2022 =-=-=-=-=\n",
      "[1] \"60 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:32:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:32:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:32:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:33:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:33:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:33:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:33:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:33:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:33:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:33:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:33:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:33:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:33:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:33:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:33:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:33:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:33:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:33:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:33:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:34:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:34:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:34:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:34:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:34:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:34:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:34:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:34:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:34:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:34:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:34:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:34:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:34:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:35:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:35:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:35:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:35:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:35:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:35:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:35:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:35:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:35:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:35:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:35:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:35:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:35:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:35:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:35:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:35:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:36:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:36:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:36:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:36:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:36:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:36:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:36:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:36:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:36:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:36:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:36:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:36:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:36:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:36:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:37:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:37:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:37:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:37:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:37:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:37:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:37:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:37:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:37:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:37:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:37:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:37:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:37:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:37:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:37:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:37:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:38:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:38:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:38:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:38:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:38:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:38:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:38:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:38:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:38:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:38:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:38:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:38:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:38:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:39:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:39:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:39:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:39:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:39:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:39:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:39:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:39:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:39:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:39:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:39:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:39:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:39:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:39:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:39:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:39:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:40:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:40:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:40:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:40:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:40:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:40:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:40:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:40:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:40:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:40:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:40:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:40:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:40:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:41:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:41:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:41:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:41:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:41:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:41:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:41:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:41:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:41:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:41:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:41:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:41:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:41:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:41:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:41:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:41:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:42:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:42:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:42:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:42:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:42:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:42:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:42:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:42:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:42:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:42:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:42:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:42:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:42:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:42:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:43:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:43:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:43:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:43:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:43:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:43:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:43:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:43:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:43:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:43:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:43:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:43:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:43:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:43:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:43:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:44:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:44:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:44:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:44:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:44:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:44:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:44:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:44:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:44:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:44:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:44:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:44:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:44:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:44:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:44:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:45:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:45:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:45:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:45:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:45:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:45:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:45:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:45:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:45:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:45:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:45:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:45:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:45:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:45:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:45:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:46:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:46:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:46:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:46:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:46:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:46:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:46:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:46:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:46:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:46:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:46:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:46:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:46:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:46:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:46:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:47:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:47:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:47:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:47:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:47:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:47:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:47:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:47:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:47:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:47:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:47:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:47:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:47:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:47:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:48:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:48:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:48:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:48:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:48:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:48:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:48:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:48:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:48:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:48:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:48:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:48:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:48:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:48:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:48:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:49:00 2022 =-=-=-=-=\n",
      "[1] \"70 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:49:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:49:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:49:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:49:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:49:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:49:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:49:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:49:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:49:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:49:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:49:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:49:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:49:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:50:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:50:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:50:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:50:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:50:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:50:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:50:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:50:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:50:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:50:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:50:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:50:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:50:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:50:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:50:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:51:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:51:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:51:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:51:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:51:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:51:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:51:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:51:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:51:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:51:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:51:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:51:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:51:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:51:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:52:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:52:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:52:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:52:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:52:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:52:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:52:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:52:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:52:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:52:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:52:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:52:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:52:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:52:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:52:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:53:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:53:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:53:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:53:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:53:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:53:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:53:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:53:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:53:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:53:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:53:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:53:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:53:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:53:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:54:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:54:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:54:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:54:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:54:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:54:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:54:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:54:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:54:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:54:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:54:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:54:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:54:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:54:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:54:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:54:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:55:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:55:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:55:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:55:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:55:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:55:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:55:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:55:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:55:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:55:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:55:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:55:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:55:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:55:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:56:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:56:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:56:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:56:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:56:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:56:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:56:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:56:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:56:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:56:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:56:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:56:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:56:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:56:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:56:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:57:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:57:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:57:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:57:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:57:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:57:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:57:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:57:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:57:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:57:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:57:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:57:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:57:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:57:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:58:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:58:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:58:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:58:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:58:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:58:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:58:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:58:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:58:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:58:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:58:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:58:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:58:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:58:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:58:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:58:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:59:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:59:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:59:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:59:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 14:59:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 14:59:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 14:59:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 14:59:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 14:59:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 14:59:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 14:59:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 14:59:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 14:59:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 14:59:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:00:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:00:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:00:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:00:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:00:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:00:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:00:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:00:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:00:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:00:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:00:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:00:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:00:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:00:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:00:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:01:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:01:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:01:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:01:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:01:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:01:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:01:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:01:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:01:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:01:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:01:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:01:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:01:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:01:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:01:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:02:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:02:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:02:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:02:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:02:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:02:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:02:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:02:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:02:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:02:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:02:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:02:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:02:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:02:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:02:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:03:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:03:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:03:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:03:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:03:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:03:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:03:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:03:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:03:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:03:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:03:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:03:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:03:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:03:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:03:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:04:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:04:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:04:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:04:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:04:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:04:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:04:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:04:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:04:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:04:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:04:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:04:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:04:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:04:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:04:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:05:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:05:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:05:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:05:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:05:14 2022 =-=-=-=-=\n",
      "[1] \"80 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:05:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:05:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:05:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:05:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:05:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:05:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:05:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:05:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:05:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:05:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:06:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:06:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:06:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:06:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:06:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:06:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:06:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:06:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:06:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:06:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:06:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:06:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:06:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:06:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:06:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:07:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:07:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:07:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:07:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:07:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:07:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:07:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:07:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:07:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:07:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:07:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:07:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:07:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:07:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:07:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:08:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:08:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:08:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:08:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:08:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:08:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:08:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:08:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:08:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:08:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:08:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:08:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:08:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:08:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:08:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:09:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:09:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:09:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:09:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:09:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:09:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:09:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:09:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:09:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:09:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:09:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:09:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:09:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:09:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:09:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:10:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:10:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:10:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:10:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:10:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:10:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:10:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:10:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:10:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:10:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:10:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:10:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:10:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:10:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:11:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:11:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:11:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:11:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:11:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:11:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:11:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:11:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:11:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:11:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:11:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:11:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:11:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:11:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:11:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:11:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:12:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:12:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:12:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:12:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:12:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:12:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:12:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:12:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:12:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:12:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:12:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:12:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:12:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:12:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:13:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:13:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:13:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:13:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:13:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:13:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:13:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:13:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:13:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:13:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:13:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:13:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:13:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:13:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:13:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:14:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:14:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:14:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:14:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:14:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:14:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:14:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:14:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:14:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:14:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:14:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:14:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:14:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:14:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:15:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:15:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:15:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:15:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:15:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:15:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:15:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:15:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:15:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:15:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:15:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:15:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:15:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:15:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:15:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:16:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:16:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:16:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:16:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:16:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:16:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:16:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:16:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:16:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:16:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:16:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:16:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:16:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:16:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:17:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:17:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:17:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:17:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:17:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:17:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:17:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:17:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:17:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:17:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:17:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:17:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:17:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:17:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:17:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:17:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:18:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:18:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:18:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:18:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:18:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:18:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:18:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:18:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:18:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:18:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:18:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:18:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:18:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:19:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:19:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:19:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:19:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:19:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:19:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:19:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:19:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:19:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:19:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:19:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:19:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:19:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:19:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:19:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:19:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:20:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:20:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:20:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:20:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:20:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:20:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:20:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:20:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:20:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:20:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:20:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:20:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:20:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:21:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:21:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:21:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:21:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:21:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:21:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:21:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:21:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:21:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:21:32 2022 =-=-=-=-=\n",
      "[1] \"90 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:21:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:21:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:21:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:21:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:21:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:21:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:22:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:22:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:22:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:22:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:22:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:22:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:22:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:22:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:22:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:22:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:22:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:22:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:22:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:22:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:23:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:23:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:23:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:23:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:23:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:23:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:23:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:23:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:23:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:23:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:23:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:23:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:23:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:23:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:24:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:24:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:24:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:24:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:24:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:24:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:24:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:24:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:24:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:24:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:24:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:24:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:24:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:24:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:24:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:24:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:25:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:25:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:25:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:25:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:25:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:25:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:25:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:25:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:25:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:25:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:25:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:25:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:25:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:25:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:26:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:26:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:26:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:26:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:26:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:26:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:26:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:26:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:26:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:26:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:26:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:26:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:26:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:26:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:26:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:27:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:27:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:27:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:27:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:27:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:27:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:27:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:27:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:27:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:27:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:27:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:27:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:27:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:28:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:28:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:28:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:28:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:28:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:28:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:28:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:28:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:28:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:28:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:28:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:28:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:28:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:28:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:28:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:28:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:28:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:29:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:29:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:29:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:29:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:29:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:29:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:29:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:29:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:29:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:29:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:29:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:29:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:29:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:30:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:30:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:30:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:30:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:30:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:30:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:30:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:30:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:30:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:30:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:30:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:30:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:30:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:30:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:30:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:30:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:31:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:31:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:31:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:31:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:31:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:31:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:31:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:31:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:31:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:31:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:31:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:31:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:31:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:32:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:32:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:32:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:32:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:32:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:32:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:32:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:32:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:32:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:32:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:32:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:32:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:32:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:32:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:32:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:32:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:33:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:33:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:33:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:33:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:33:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:33:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:33:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:33:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:33:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:33:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:33:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:33:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:33:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:34:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:34:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:34:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:34:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:34:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:34:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:34:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:34:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:34:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:34:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:34:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:34:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:34:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:34:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:34:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:34:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:35:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:35:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:35:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:35:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:35:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:35:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:35:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:35:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:35:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:35:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:35:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:35:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:35:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:35:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:36:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:36:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:36:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:36:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:36:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:36:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:36:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:36:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:36:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:36:34 2022 =-=-=-=-=\n"
     ]
    }
   ],
   "source": [
    "result.m02.2 <- my.tsCV.2(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          xreg=trainx[,2:4], \n",
    "                          silent=F,\n",
    "                          sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb72044a-8da0-45cc-8d68-0119fe090cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-02-09\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m02.2\n",
    "from <- x[!is.na(x[,'forecast_start']),][,1][1]\n",
    "from <- index(trainx[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc2e74d7-8d59-4a62-be63-137bc65d7e26",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:36:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:36:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:36:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:36:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:36:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:37:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:37:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:37:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:37:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:37:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:37:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:37:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:37:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:37:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:37:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:37:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:37:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:37:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:37:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:37:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:38:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:38:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:38:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:38:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:38:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:38:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:38:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:38:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:38:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:38:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:38:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:38:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:38:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:38:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:39:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:39:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:39:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:39:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:39:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:39:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:39:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:39:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:39:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:39:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:39:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:39:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:39:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:39:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:39:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:39:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:40:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:40:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:40:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:40:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:40:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:40:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:40:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:40:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:40:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:40:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:40:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:40:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:40:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:40:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:41:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:41:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:41:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:41:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:41:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:41:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:41:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:41:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:41:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:41:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:41:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:41:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:41:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:41:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:41:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:41:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:42:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:42:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:42:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:42:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:42:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:42:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:42:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:42:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:42:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:42:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:42:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:42:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:42:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:43:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:43:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:43:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:43:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:43:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:43:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:43:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:43:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:43:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:43:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:43:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:43:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:43:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:43:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:43:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:43:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:44:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:44:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:44:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:44:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:44:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:44:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:44:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:44:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:44:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:44:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:44:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:44:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:44:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:44:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:45:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:45:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:45:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:45:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:45:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:45:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:45:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:45:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:45:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:45:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:45:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:45:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:45:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:45:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:45:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:45:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:46:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:46:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:46:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:46:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:46:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:46:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:46:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:46:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:46:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:46:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:46:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:46:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:46:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:47:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:47:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:47:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:47:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:47:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:47:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:47:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:47:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:47:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:47:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:47:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:47:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:47:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:47:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:47:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:47:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:48:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:48:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:48:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:48:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:48:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:48:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:48:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:48:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:48:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:48:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:48:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:48:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:48:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:48:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:49:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:49:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:49:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:49:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:49:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:49:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:49:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:49:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:49:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:49:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:49:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:49:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:49:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:49:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:49:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:49:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:50:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:50:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:50:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:50:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:50:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:50:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:50:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:50:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:50:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:50:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:50:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:50:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:50:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:50:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:51:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:51:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:51:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:51:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:51:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:51:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:51:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:51:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:51:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:51:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:51:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:51:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:51:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:51:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:51:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:52:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:52:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:52:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:52:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:52:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:52:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:52:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:52:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:52:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:52:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:52:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:52:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:52:48 2022 =-=-=-=-=\n",
      "[1] \"10 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:52:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:53:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:53:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:53:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:53:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:53:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:53:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:53:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:53:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:53:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:53:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:53:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:53:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:53:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:53:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:53:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:53:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:54:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:54:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:54:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:54:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:54:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:54:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:54:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:54:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:54:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:54:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:54:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:54:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:54:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:55:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:55:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:55:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:55:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:55:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:55:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:55:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:55:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:55:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:55:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:55:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:55:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:55:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:55:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:55:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:55:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:56:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:56:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:56:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:56:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:56:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:56:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:56:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:56:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:56:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:56:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:56:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:56:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:56:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:56:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:57:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:57:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:57:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:57:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:57:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:57:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:57:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:57:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:57:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:57:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:57:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:57:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:57:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:57:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:57:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:58:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:58:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:58:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:58:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:58:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:58:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:58:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:58:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:58:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:58:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:58:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:58:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:58:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:58:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:58:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:59:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:59:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:59:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:59:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:59:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 15:59:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 15:59:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 15:59:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 15:59:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 15:59:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 15:59:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 15:59:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 15:59:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 15:59:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 15:59:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:00:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:00:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:00:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:00:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:00:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:00:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:00:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:00:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:00:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:00:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:00:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:00:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:00:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:00:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:00:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:01:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:01:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:01:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:01:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:01:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:01:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:01:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:01:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:01:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:01:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:01:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:01:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:01:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:01:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:02:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:02:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:02:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:02:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:02:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:02:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:02:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:02:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:02:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:02:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:02:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:02:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:02:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:02:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:02:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:03:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:03:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:03:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:03:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:03:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:03:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:03:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:03:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:03:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:03:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:03:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:03:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:03:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:03:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:04:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:04:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:04:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:04:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:04:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:04:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:04:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:04:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:04:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:04:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:04:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:04:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:04:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:04:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:04:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:05:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:05:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:05:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:05:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:05:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:05:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:05:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:05:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:05:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:05:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:05:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:05:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:05:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:05:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:06:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:06:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:06:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:06:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:06:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:06:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:06:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:06:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:06:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:06:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:06:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:06:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:06:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:06:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:06:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:07:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:07:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:07:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:07:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:07:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:07:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:07:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:07:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:07:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:07:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:07:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:07:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:07:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:07:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:08:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:08:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:08:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:08:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:08:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:08:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:08:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:08:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:08:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:08:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:08:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:08:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:08:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:08:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:08:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:09:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:09:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:09:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:09:11 2022 =-=-=-=-=\n",
      "[1] \"20 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:09:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:09:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:09:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:09:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:09:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:09:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:09:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:09:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:09:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:09:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:10:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:10:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:10:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:10:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:10:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:10:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:10:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:10:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:10:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:10:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:10:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:10:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:10:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:10:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:10:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:10:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:10:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:11:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:11:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:11:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:11:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:11:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:11:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:11:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:11:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:11:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:11:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:11:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:11:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:11:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:11:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:12:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:12:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:12:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:12:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:12:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:12:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:12:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:12:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:12:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:12:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:12:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:12:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:12:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:12:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:12:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:12:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:12:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:13:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:13:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:13:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:13:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:13:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:13:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:13:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:13:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:13:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:13:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:13:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:13:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:13:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:13:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:14:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:14:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:14:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:14:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:14:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:14:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:14:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:14:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:14:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:14:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:14:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:14:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:14:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:14:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:14:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:14:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:15:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:15:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:15:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:15:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:15:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:15:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:15:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:15:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:15:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:15:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:15:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:15:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:15:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:16:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:16:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:16:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:16:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:16:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:16:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:16:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:16:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:16:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:16:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:16:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:16:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:16:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:16:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:16:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:17:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:17:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:17:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:17:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:17:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:17:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:17:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:17:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:17:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:17:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:17:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:17:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:17:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:17:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:18:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:18:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:18:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:18:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:18:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:18:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:18:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:18:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:18:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:18:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:18:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:18:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:18:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:18:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:18:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:18:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:19:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:19:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:19:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:19:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:19:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:19:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:19:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:19:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:19:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:19:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:19:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:19:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:19:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:19:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:20:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:20:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:20:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:20:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:20:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:20:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:20:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:20:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:20:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:20:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:20:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:20:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:20:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:20:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:20:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:20:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:21:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:21:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:21:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:21:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:21:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:21:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:21:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:21:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:21:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:21:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:21:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:21:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:21:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:21:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:22:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:22:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:22:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:22:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:22:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:22:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:22:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:22:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:22:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:22:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:22:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:22:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:22:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:22:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:22:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:23:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:23:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:23:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:23:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:23:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:23:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:23:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:23:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:23:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:23:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:23:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:23:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:23:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:23:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:23:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:24:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:24:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:24:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:24:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:24:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:24:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:24:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:24:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:24:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:24:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:24:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:24:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:24:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:24:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:24:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:25:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:25:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:25:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:25:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:25:16 2022 =-=-=-=-=\n",
      "[1] \"30 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:25:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:25:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:25:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:25:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:25:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:25:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:25:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:25:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:25:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:25:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:26:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:26:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:26:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:26:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:26:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:26:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:26:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:26:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:26:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:26:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:26:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:26:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:26:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:26:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:27:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:27:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:27:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:27:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:27:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:27:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:27:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:27:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:27:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:27:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:27:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:27:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:27:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:27:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:27:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:27:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:28:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:28:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:28:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:28:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:28:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:28:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:28:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:28:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:28:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:28:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:28:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:28:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:28:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:28:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:29:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:29:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:29:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:29:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:29:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:29:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:29:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:29:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:29:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:29:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:29:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:29:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:29:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:29:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:29:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:30:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:30:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:30:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:30:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:30:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:30:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:30:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:30:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:30:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:30:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:30:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:30:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:30:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:30:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:31:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:31:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:31:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:31:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:31:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:31:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:31:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:31:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:31:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:31:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:31:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:31:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:31:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:31:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:31:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:31:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:32:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:32:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:32:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:32:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:32:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:32:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:32:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:32:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:32:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:32:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:32:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:32:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:32:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:33:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:33:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:33:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:33:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:33:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:33:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:33:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:33:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:33:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:33:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:33:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:33:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:33:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:33:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:33:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:33:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:33:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:34:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:34:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:34:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:34:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:34:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:34:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:34:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:34:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:34:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:34:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:34:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:34:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:34:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:34:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:35:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:35:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:35:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:35:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:35:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:35:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:35:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:35:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:35:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:35:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:35:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:35:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:35:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:35:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:35:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:35:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:36:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:36:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:36:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:36:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:36:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:36:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:36:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:36:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:36:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:36:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:36:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:36:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:36:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:37:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:37:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:37:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:37:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:37:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:37:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:37:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:37:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:37:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:37:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:37:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:37:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:37:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:37:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:37:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:37:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:38:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:38:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:38:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:38:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:38:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:38:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:38:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:38:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:38:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:38:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:38:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:38:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:38:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:38:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:39:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:39:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:39:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:39:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:39:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:39:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:39:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:39:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:39:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:39:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:39:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:39:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:39:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:39:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:39:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:40:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:40:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:40:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:40:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:40:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:40:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:40:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:40:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:40:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:40:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:40:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:40:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:40:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:40:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:41:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:41:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:41:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:41:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:41:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:41:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:41:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:41:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:41:28 2022 =-=-=-=-=\n",
      "[1] \"40 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:41:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:41:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:41:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:41:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:41:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:41:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:41:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:42:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:42:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:42:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:42:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:42:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:42:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:42:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:42:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:42:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:42:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:42:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:42:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:42:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:43:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:43:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:43:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:43:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:43:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:43:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:43:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:43:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:43:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:43:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:43:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:43:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:43:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:43:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:43:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:43:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:44:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:44:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:44:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:44:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:44:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:44:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:44:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:44:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:44:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:44:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:44:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:44:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:44:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:44:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:45:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:45:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:45:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:45:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:45:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:45:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:45:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:45:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:45:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:45:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:45:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:45:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:45:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:45:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:45:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:46:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:46:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:46:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:46:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:46:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:46:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:46:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:46:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:46:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:46:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:46:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:46:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:46:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:46:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:46:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:47:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:47:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:47:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:47:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:47:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:47:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:47:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:47:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:47:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:47:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:47:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:47:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:47:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:47:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:47:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:48:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:48:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:48:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:48:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:48:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:48:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:48:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:48:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:48:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:48:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:48:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:48:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:48:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:48:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:48:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:49:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:49:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:49:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:49:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:49:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:49:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:49:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:49:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:49:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:49:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:49:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:49:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:49:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:49:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:49:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:49:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:50:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:50:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:50:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:50:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:50:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:50:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:50:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:50:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:50:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:50:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:50:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:50:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:50:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:50:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:51:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:51:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:51:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:51:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:51:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:51:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:51:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:51:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:51:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:51:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:51:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:51:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:51:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:51:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:51:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:52:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:52:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:52:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:52:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:52:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:52:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:52:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:52:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:52:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:52:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:52:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:52:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:52:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:52:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:52:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:53:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:53:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:53:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:53:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:53:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:53:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:53:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:53:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:53:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:53:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:53:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:53:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:53:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:53:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:53:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:54:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:54:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:54:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:54:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:54:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:54:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:54:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:54:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:54:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:54:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:54:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:54:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:54:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:54:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:54:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:55:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:55:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:55:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:55:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:55:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:55:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:55:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:55:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:55:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:55:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:55:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:55:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:55:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:55:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:55:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:56:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:56:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:56:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:56:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:56:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:56:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:56:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:56:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:56:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:56:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:56:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:56:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:56:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:56:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:56:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:57:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:57:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:57:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:57:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:57:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:57:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:57:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:57:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:57:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:57:35 2022 =-=-=-=-=\n",
      "[1] \"50 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:57:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:57:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:57:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:57:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:57:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:58:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:58:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:58:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:58:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:58:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:58:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:58:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:58:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:58:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:58:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:58:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:58:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:58:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:58:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:58:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:59:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:59:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:59:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:59:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 16:59:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 16:59:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 16:59:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 16:59:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 16:59:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 16:59:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 16:59:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 16:59:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 16:59:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 16:59:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:00:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:00:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:00:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:00:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:00:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:00:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:00:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:00:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:00:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:00:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:00:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:00:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:00:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:00:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:00:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:00:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:01:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:01:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:01:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:01:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:01:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:01:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:01:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:01:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:01:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:01:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:01:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:01:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:01:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:01:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:02:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:02:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:02:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:02:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:02:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:02:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:02:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:02:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:02:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:02:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:02:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:02:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:02:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:02:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:02:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:02:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:03:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:03:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:03:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:03:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:03:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:03:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:03:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:03:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:03:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:03:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:03:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:03:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:03:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:03:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:04:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:04:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:04:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:04:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:04:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:04:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:04:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:04:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:04:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:04:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:04:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:04:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:04:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:04:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:04:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:05:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:05:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:05:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:05:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:05:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:05:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:05:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:05:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:05:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:05:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:05:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:05:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:05:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:05:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:06:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:06:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:06:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:06:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:06:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:06:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:06:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:06:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:06:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:06:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:06:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:06:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:06:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:06:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:06:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:07:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:07:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:07:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:07:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:07:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:07:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:07:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:07:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:07:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:07:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:07:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:07:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:07:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:07:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:08:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:08:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:08:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:08:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:08:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:08:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:08:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:08:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:08:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:08:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:08:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:08:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:08:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:08:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:08:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:08:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:09:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:09:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:09:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:09:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:09:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:09:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:09:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:09:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:09:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:09:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:09:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:09:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:09:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:09:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:10:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:10:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:10:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:10:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:10:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:10:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:10:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:10:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:10:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:10:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:10:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:10:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:10:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:10:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:10:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:11:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:11:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:11:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:11:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:11:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:11:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:11:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:11:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:11:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:11:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:11:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:11:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:11:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:11:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:12:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:12:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:12:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:12:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:12:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:12:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:12:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:12:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:12:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:12:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:12:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:12:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:12:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:12:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:12:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:12:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:13:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:13:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:13:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:13:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:13:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:13:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:13:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:13:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:13:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:13:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:13:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:13:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:13:51 2022 =-=-=-=-=\n",
      "[1] \"60 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:14:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:14:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:14:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:14:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:14:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:14:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:14:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:14:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:14:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:14:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:14:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:14:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:14:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:14:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:14:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:14:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:15:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:15:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:15:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:15:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:15:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:15:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:15:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:15:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:15:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:15:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:15:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:15:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:15:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:15:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:16:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:16:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:16:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:16:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:16:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:16:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:16:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:16:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:16:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:16:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:16:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:16:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:16:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:16:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:16:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:17:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:17:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:17:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:17:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:17:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:17:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:17:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:17:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:17:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:17:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:17:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:17:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:17:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:17:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:17:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:18:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:18:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:18:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:18:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:18:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:18:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:18:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:18:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:18:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:18:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:18:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:18:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:18:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:18:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:18:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:19:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:19:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:19:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:19:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:19:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:19:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:19:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:19:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:19:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:19:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:19:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:19:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:19:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:19:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:19:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:20:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:20:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:20:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:20:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:20:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:20:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:20:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:20:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:20:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:20:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:20:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:20:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:20:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:20:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:21:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:21:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:21:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:21:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:21:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:21:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:21:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:21:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:21:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:21:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:21:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:21:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:21:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:21:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:21:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:21:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:22:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:22:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:22:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:22:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:22:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:22:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:22:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:22:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:22:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:22:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:22:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:22:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:22:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:23:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:23:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:23:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:23:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:23:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:23:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:23:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:23:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:23:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:23:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:23:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:23:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:23:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:23:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:23:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:23:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:24:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:24:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:24:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:24:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:24:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:24:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:24:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:24:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:24:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:24:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:24:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:24:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:24:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:25:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:25:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:25:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:25:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:25:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:25:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:25:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:25:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:25:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:25:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:25:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:25:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:25:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:25:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:25:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:25:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:26:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:26:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:26:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:26:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:26:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:26:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:26:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:26:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:26:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:26:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:26:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:26:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:26:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:26:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:27:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:27:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:27:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:27:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:27:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:27:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:27:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:27:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:27:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:27:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:27:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:27:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:27:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:27:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:27:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:27:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:28:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:28:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:28:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:28:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:28:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:28:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:28:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:28:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:28:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:28:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:28:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:28:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:28:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:29:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:29:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:29:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:29:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:29:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:29:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:29:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:29:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:29:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:29:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:29:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:29:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:29:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:29:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:29:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:29:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:30:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:30:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:30:08 2022 =-=-=-=-=\n",
      "[1] \"70 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:30:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:30:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:30:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:30:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:30:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:30:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:30:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:30:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:30:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:30:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:30:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:31:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:31:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:31:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:31:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:31:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:31:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:31:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:31:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:31:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:31:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:31:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:31:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:31:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:31:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:31:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:32:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:32:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:32:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:32:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:32:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:32:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:32:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:32:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:32:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:32:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:32:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:32:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:32:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:32:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:33:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:33:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:33:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:33:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:33:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:33:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:33:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:33:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:33:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:33:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:33:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:33:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:33:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:33:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:33:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:33:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:34:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:34:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:34:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:34:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:34:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:34:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:34:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:34:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:34:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:34:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:34:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:34:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:34:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:34:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:35:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:35:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:35:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:35:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:35:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:35:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:35:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:35:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:35:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:35:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:35:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:35:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:35:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:35:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:35:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:35:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:36:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:36:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:36:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:36:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:36:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:36:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:36:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:36:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:36:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:36:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:36:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:36:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:36:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:36:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:37:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:37:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:37:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:37:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:37:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:37:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:37:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:37:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:37:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:37:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:37:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:37:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:37:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:37:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:37:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:38:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:38:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:38:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:38:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:38:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:38:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:38:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:38:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:38:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:38:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:38:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:38:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:38:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:38:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:38:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:39:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:39:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:39:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:39:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:39:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:39:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:39:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:39:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:39:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:39:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:39:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:39:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:39:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:39:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:40:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:40:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:40:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:40:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:40:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:40:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:40:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:40:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:40:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:40:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:40:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:40:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:40:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:40:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:40:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:40:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:41:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:41:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:41:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:41:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:41:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:41:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:41:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:41:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:41:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:41:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:41:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:41:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:41:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:41:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:42:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:42:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:42:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:42:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:42:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:42:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:42:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:42:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:42:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:42:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:42:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:42:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:42:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:42:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:42:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:42:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:43:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:43:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:43:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:43:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:43:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:43:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:43:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:43:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:43:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:43:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:43:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:43:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:43:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:43:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:44:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:44:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:44:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:44:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:44:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:44:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:44:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:44:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:44:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:44:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:44:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:44:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:44:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:44:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:44:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:44:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:45:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:45:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:45:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:45:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:45:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:45:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:45:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:45:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:45:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:45:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:45:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:45:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:45:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:46:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:46:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:46:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:46:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:46:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:46:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:46:20 2022 =-=-=-=-=\n",
      "[1] \"80 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:46:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:46:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:46:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:46:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:46:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:46:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:46:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:46:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:46:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:47:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:47:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:47:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:47:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:47:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:47:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:47:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:47:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:47:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:47:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:47:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:47:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:47:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:47:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:48:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:48:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:48:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:48:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:48:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:48:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:48:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:48:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:48:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:48:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:48:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:48:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:48:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:48:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:48:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:48:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:49:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:49:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:49:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:49:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:49:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:49:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:49:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:49:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:49:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:49:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:49:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:49:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:49:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:49:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:50:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:50:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:50:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:50:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:50:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:50:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:50:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:50:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:50:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:50:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:50:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:50:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:50:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:50:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:50:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:51:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:51:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:51:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:51:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:51:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:51:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:51:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:51:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:51:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:51:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:51:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:51:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:51:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:51:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:52:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:52:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:52:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:52:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:52:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:52:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:52:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:52:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:52:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:52:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:52:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:52:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:52:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:52:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:52:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:52:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:53:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:53:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:53:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:53:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:53:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:53:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:53:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:53:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:53:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:53:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:53:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:53:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:53:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:53:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:54:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:54:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:54:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:54:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:54:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:54:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:54:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:54:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:54:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:54:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:54:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:54:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:54:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:54:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:54:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:54:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:55:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:55:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:55:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:55:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:55:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:55:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:55:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:55:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:55:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:55:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:55:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:55:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:55:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:56:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:56:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:56:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:56:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:56:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:56:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:56:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:56:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:56:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:56:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:56:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:56:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:56:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:56:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:56:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:56:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:57:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:57:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:57:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:57:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:57:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:57:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:57:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:57:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:57:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:57:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:57:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:57:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:57:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:57:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:58:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:58:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:58:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:58:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:58:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:58:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:58:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:58:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:58:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:58:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:58:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:58:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:58:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:58:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:58:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:59:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:59:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:59:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:59:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 17:59:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 17:59:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 17:59:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 17:59:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 17:59:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 17:59:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 17:59:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 17:59:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 17:59:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 17:59:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:00:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:00:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:00:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:00:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:00:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:00:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:00:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:00:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:00:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:00:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:00:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:00:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:00:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:00:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:00:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:00:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:01:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:01:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:01:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:01:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:01:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:01:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:01:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:01:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:01:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:01:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:01:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:01:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:01:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:01:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:02:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:02:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:02:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:02:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:02:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:02:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:02:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:02:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:02:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:02:34 2022 =-=-=-=-=\n",
      "[1] \"90 % done.\"\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:02:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:02:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:02:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:02:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:02:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:02:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:03:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:03:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:03:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:03:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:03:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:03:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:03:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:03:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:03:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:03:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:03:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:03:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:03:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:03:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:04:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:04:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:04:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:04:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:04:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:04:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:04:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:04:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:04:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:04:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:04:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:04:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:04:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:04:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:04:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:04:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:05:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:05:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:05:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:05:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:05:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:05:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:05:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:05:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:05:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:05:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:05:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:05:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:05:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:05:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:06:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:06:07 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:06:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:06:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:06:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:06:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:06:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:06:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:06:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:06:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:06:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:06:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:06:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:06:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:06:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:07:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:07:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:07:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:07:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:07:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:07:26 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:07:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:07:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:07:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:07:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:07:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:07:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:07:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:07:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:07:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:08:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:08:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:08:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:08:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:08:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:08:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:08:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:08:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:08:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:08:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:08:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:08:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:08:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:08:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:08:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:09:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:09:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:09:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:09:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:09:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:09:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:09:30 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:09:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:09:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:09:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:09:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:09:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:09:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:09:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:09:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:10:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:10:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:10:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:10:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:10:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:10:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:10:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:10:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:10:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:10:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:10:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:10:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:10:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:10:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:11:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:11:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:11:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:11:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:11:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:11:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:11:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:11:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:11:36 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:11:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:11:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:11:46 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:11:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:11:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:11:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:12:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:12:10 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:12:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:12:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:12:20 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:12:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:12:27 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:12:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:12:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:12:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:12:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:12:51 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:12:54 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:12:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:13:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:13:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:13:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:13:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:13:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:13:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:13:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:13:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:13:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:13:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:13:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:13:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:13:48 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:13:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:13:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:13:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:14:02 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:14:11 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:14:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:14:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:14:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:14:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:14:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:14:32 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:14:35 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:14:39 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:14:42 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:14:52 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:14:56 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:14:59 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:15:03 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:15:06 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:15:09 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:15:13 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:15:16 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:15:19 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:15:23 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:15:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:15:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:15:40 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:15:43 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:15:47 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:15:50 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:15:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:15:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:16:00 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:16:04 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:16:14 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:16:17 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:16:21 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:16:24 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:16:28 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:16:31 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:16:34 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:16:38 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:16:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:16:44 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 0 Thu Sep 22 18:16:55 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Thu Sep 22 18:16:58 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Thu Sep 22 18:17:01 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Thu Sep 22 18:17:05 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Thu Sep 22 18:17:08 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Thu Sep 22 18:17:12 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Thu Sep 22 18:17:15 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Thu Sep 22 18:17:18 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Thu Sep 22 18:17:22 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Thu Sep 22 18:17:25 2022 =-=-=-=-=\n"
     ]
    }
   ],
   "source": [
    "result.m02.3 <- my.tsCV.2(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                        xreg=trainx[,2:4], silent=F,\n",
    "                        xreg.msize=hori,\n",
    "                        sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc65fefd-60b9-4ab4-a840-d24018cef2fc",
   "metadata": {},
   "source": [
    "## Compare Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58355e11-c950-44f5-b241-665c8d6aa2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my.figsize(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f874535-9c29-405a-add4-9bbce090b23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94\nAAAgAElEQVR4nOzde3zO9f/H8dd12rXzzM6zjTmfMueGkDMjOeRUIkKUpJ9zJYWOlCUdHBIS\n6huJRBYVSmRETmGY2cYMOx+vw++PS2uGucYul+3zuN/6Y9f7835/rtcnu9hz7/fn/VGZzWYB\nAAAAACiP2t4FAAAAAADsg0AIAAAAAApFIAQAAAAAhSIQAgAAAIBCEQgBAAAAQKEIhAAAAACg\nUARCAAAAAFAoAiEAAAAAKJTW3gXYVnp6usFgsHcVsDmNRuPq6pqXl5ednW3vWoCyQaVSubu7\nGwyGzMxMe9cClBnu7u4mkykjI8PeheBe8PT0tHcJwL1QzgOhyWQyGo32rgL3glqtFhH+uAEr\nqVQqPjVASfGpAVD+sGQUAAAAABSKQAgAAAAACkUgBAAAAACFIhACAAAAgEIRCAEAAABAoQiE\nAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAACkUgBAAAAACFIhACAAAAgEIR\nCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAACkUgBAAAAACF\nIhACAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAAAAAolNbeBQAAANzv8vLyNm7c\nGBMTo9Fo6tWr17lzZ7Wa36oDKA8IhAAAAMXJzs4eP358bGys5WVUVNSvv/76xhtvkAkBlAP8\nRQYAAFCc5cuXF6RBiwMHDmzYsMFe9QBAKSIQAoBCmc1me5cAlA1//vmnlY0AUOawZBQAFOev\nv/5avnx5TEyMk5NT8+bNhw0bVrFiRXsXBdy/DAbDjY1Go/HeVwIApY5ACADKcvjw4alTp1q+\nzsvLi4qKOnHixPz58/V6vX0LA+5bderUuXjxYpHG2rVr26UYAChdLBkFAGVZuHBhkZbY2NhN\nmzbZpRigTBg+fLibm1vhloCAgAEDBtirHgAoRcwQAoCCmM3m06dP39geExNz74sBygpfX98P\nP/xwxYoVx48f12q1YWFhgwcPdnJysnddAFAKCIQAoCAqlUqv12dlZRVpd3R0tEs9QFnh7+8/\nefJkLy8vk8l09epVe5cDAKWGJaMAoCytWrW6sbFly5b3vhIAAGB3BEIAUJZRo0ZVrly5cMtj\njz3WpEkTe9UDAADsiCWjAKAsbm5uCxYs2L59e2xsrJOTU6NGjerXr2/vogAAgH0QCAFAcXQ6\nXdeuXb28vPLy8tLS0uxdDgAAsBuWjAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKAIh\nAAAAACgUgRAAAAAAFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAE\nQgAAAABQKAIhAAAAACgUgRAAAAAAFIpACAAAAAAKpbXp2TMyMhYtWvTnn38aDIb69euPGTPG\n19f3xm7x8fHz5s07derU+vXrbzvWynMCAAAAAIpn2xnCyMjIc+fOzZo1a968eRqNZubMmSaT\nqUifnTt3vvTSS0FBQVaOteacAAAAAIDbsmEgTE5O3rt377hx46pXrx4UFDR+/Pj4+PiDBw8W\n6Zafnz937tzw8HBrxlp5TgBA8QwGw08//fTXX3/ZuxAAAGBPNgyEJ0+edHBwCA0Ntbx0dXUN\nDg4+efJkkW7t27f38fGxcqyV5wQAFC8nJ2fq1KkrVqywdyEAAMCebHgPYVpampubm0qlKmjx\n8PBITU29m7EeHh7Fn3PXrl2vvvpqwcs5c+Y0btz4ri4DZYejo6Ner7d3FUDZ4ODgICJqtdrL\ny8vetQBlhkql0mg0fGoAlCe23VSmcHITEbPZfPdjiz+nVqt1c3MreKnRaLjDUAlUKpVKpTKb\nzfxxA1Yq+LDwqQGsp9Fo+LdGOTQajb1LAO4FGwbCChUqpKWlmc3mggiXmprq6el5N2Nve87w\n8PDvvvuu4GVqaurVq1dL53pwH9NoNJ6enrm5uRkZGfauBSgbMjMzRcRkMvGXJGA9Ly8vPjXK\n4e3tbe8SgHvBhvcQ1qxZMz8//9SpU5aXqampcXFxtWvXvpuxd3NOAAAAAEBhNpwh9PT0bNWq\n1Ycffjhu3Di9Xr9kyZLq1avXq1dPRKKionJych555BERuXr1qtFoTE9PF5Hk5GQRcXV1vdVY\nlUp1q3NCsYxG4++//37hwgU3N7ewsDCeSwkAAABYSVWi+/pKKisra/Hixbt37zaZTI0aNRo9\nerRleeecOXPS0tJmzZolIiNGjEhKSio8asSIET179rzV2Fu131Rqamp+fr7tLhB2l5qaOm3a\ntNOnT1te6vX6cePGdejQwb5VAfe/zMzMvn37hoeHv/baa/auBSgzWDKqKCwZhULYNhDaHYGw\n3Js9e/auXbsKt+j1+k8++SQwMNBeJQFlAoEQuAMEQkUhEEIhbHgPIWBr2dnZv//+e5HG3Nzc\nIhERAAAAwE0RCFGGZWVl3XTvb8stqQAAAACKRyBEGebp6Vn4sZMFQkJC7n0xAAAAQJlDIEQZ\nplarhw4dWqSxatWqDz/8sD3KAQAAAMoYGz52ArgHevToYTKZVq1alZKSotFoWrRoMXr0aJ1O\nZ++6AAAAgDKAQIgyr2fPnr179zYYDI6Ojrm5ufYuBwAAACgzWDKKcsLHx4eJQQCATbVt23bQ\noEH2rgIAShOBEAAAAAAUikAIAAAAAApFIAQAAAAAhSIQAgAAAIBCEQgBAAAAQKEIhAAAAACg\nUARCAAAAAFAoAiEAAAAAKBSBEAAAAAAUikAIAAAAAApFIAQAAAAAhSIQAgAAAIBCae1dAFAK\nMjMzo6Ojvb29g4KC7F0LAAAAUGYwQ4jy4NKlS1OnTv3uu+/sXQgAAABQlhAIAQAAAEChCIQA\nAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAAFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEI\nAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAAFIpACAAAAAAKRSAEAAAAAIUi\nEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAAFIpACAAAAAAK\nRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAA\nFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAA\nACgUgRAAAAAAFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAA\nAABQKAIhAAAAACgUgRAAAAAAFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQA\nAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAAFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEI\nAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAAFIpACAAAAAAKRSAEAAAAAIUi\nEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAAFIpACAAAAAAK\nRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAA\nFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAA\nACgUgRAAAAAAFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChtPYuAABKwdmzZ48e\nPWrvKsqS3NxcEbl48eIPP/xg71rKEr1e36JFC2dnZ3sXAgBA6SAQAigP3n777bNnz9q7irLn\nzJkz8+fPt3cVZcxTTz01cOBAe1cBAEDpIBACKA/y8/NNDhLXXWPvQlCeOV0S313GvLw8excC\nAECpIRACKCdMWkluzn3RsCH3U2bfXfYuAgCAUsUPTwAAAACgUARCAAAAAFAolowCAKBEp0+f\n3rdvn72rKGMMBkNKSsrXX39t70LKEpVK1aZNGz8/P3sXAuDmCIQAACjRZ599Fh0dbe8qyp4r\nV64sXbrU3lWUMYmJiePGjbN3FQBujkAIAIASGY1GEQnuMFOtcbB3LSi38jKSEn9/32Aw2LsQ\nALdUzgOhWq3WaNiGvvxTq6/dDcsft2KpVCp7lwClKDf/slg+NR5V26u1jvauBeVWztUzib+X\nn08NUC6V80Do4ODg6Mi/c+Wfk5OTiKjValdXV3vXAvsgEOKecXBwKB9/1fADOu4ZrVZbPj41\nQLlUzgNhTk5Ofn6+vauAzWVmZoqIyWRKTU21dy2wD5PJZO8SoBQ5OTnl468aVvHhnsnLyyuL\nnxpvb297lwDcCzx2AgAAAAAUqpzPEAJAeXMmS5bGyZF0yTdJFWcZVElaet5h51OZsvy8nMyQ\nbJMEOkp3X4nwFfW/i28NZlkTL1svyeV88XGQCF/pFygFK3P/SpPV8XI6UwxmCXKSXv7S3ltY\ntwsAQFnDDCEAlB3xOfJ/R+R8tgwLlvFVxUUjr/8jv1+5k85H0+WFI3IuSx4LlGcqSwWtzD8j\nn537b/jbp2RlvLSuKBOrSgN3WXJOVp6/duiPqzLlqKQbZHCQDA8RnUreOSWr4m155QAAwCaY\nIQSAsuOL82I0y3v1pKJORKSdlzz7tyyMlRYVbzI7V3znz+NEr5bI+uKpExHp5ivP/S0bLsrw\nENGoZF+K7LgsY6pIb38RkXbekmmQg2kyWEQlsjRO/PUyr57o1dfGjjok3yTI45WYJAQAoGxh\nhhAAygiTWXZflQc9rwU8EVGrpLOPJObK6cwSd+7gLWOrXEuDIqISqeMquSbJMIiIRCWLi0Z6\n+P53wuk1ZW5dUYmYRbr5yugq19KgiGhVUtdVMo2Sy9Y+AACUMcwQAkAZcSFXso1S1fm6xuou\nIiKns6SaS8k6d/WVIuJzxEMr7joRkaPpUsdNdGoREbNcN++nkmvThgXMImezxMdBHPklIwAA\nZQyBEADKiCv5IvLfnJ5FBZ2IyOUbnq9Tos4isuOy7E+Vp0OuzQEm5UrTCvJDknydIIk54qKV\ntl4yKkScCj25Lt8kV/MlOU82XJTTWTKtxl1dHQAAsAcCIQCUEXkmERHt9bNwlkm8/BvWapao\n854UmRMjD3pK/0ARkRyjmEWiU+RUpgwLFjetRKfI2guSkCPv1Plv1N/pMvWYiIifXmbUlAdv\nvdkpAAC4XxEIAaCMcLhZnLMEP4cb1mpa33nDRfn4rDxUUaZWv7Y0VKsSEck2yqcNxFkjItLY\nQ4wi6xLleIbUdr02sJqLzKwlqfkSnSqv/iMDKsnw4Lu8RAAAcI8RCAGgjLBsD3P1+gWfV/JE\nRLwd7rDzp7GyLlEGBsqwkP9uFNSpxVkjVZyvpUGLJh6yLlHOZP0XCD20Eu4pItLFV3z1siZe\nWnlKLVcBAABlBxsAAEAZEeAorlo5cf2Gov9kiIjUcLmTzp/HybeJMr6qDA8p+riI6i5FbzU0\nmEVEdGpJyZfvL147VYH6biIiZ7JKeEkAAMDOmCEEgDJCJdK6ovyULBdzxU8vIpJnki2XpKqz\nhDiVuPP+VFkdL89WkYgbthsVkbZe8uEZiU6VJh7XWn69LCJSx1V0avn4rNRxu/YUCosDqSIi\nvvrSvWKgVFw9/3f0upcuntplNORWrPRAg+4vhTR89M46X47df+C7Gcmx+wy5mW4+1Wq1faZW\nm5EqtUZEDmx47a8Nrxc5W0CdDl0n/HTbowBgRwRCACg7BgfJ71dk4lHp7S+OGtmcJBdz5e1/\nN3rZfVVePyGjK0sv/9t0NpplwRnx0IpeLZuTrnuLxh7ip5duvrIlSV77R/oGSICj7EuRXy9L\nFx+p5CgiMrCSrDwvE45Iay/RqeTvdPklWeq6SSMPAe4zaRdP/vBOa0d33ya939A5uZ/6fcW2\nj3p3eHZdSKNeJe2cFLN7y5x2zp6V6neZqHN0i41eu3vlmPRLMc36zRGR/OxUlUrdcsjCwid0\nrlDJ8kXxRwHAjgiEAFB2+DjIvHqy+JysOC9Gs9RwkbfrSJj7taNms5jMYjLfvnOGUc7niIjM\nO130LV6rKX560arknTryeZxsSZI0g/jq5algGRB4rc+QIKnkKBsvysrzYjCLn16GBktv/6Lr\nToH7wF8bXzeZDN0m/+rsESAiVZsP2jCryd6vJ4Q0fFRURb9li+8cve4ljYNT92m/O7n7iUjN\n1iM2zm52/OePm/R9S63W5mWl6hzdarYecdMyij8KAHZEIASAMiXISV6vdfNDLSvK1nCrOnto\ni/a8katWng+V50NvfrSDt3Twvm2xgH2ZTcZzf20IbtDdEvBERKXWVG/51N6vXrxy/mDF4IYl\n6lwtfHCtNiMtaVBEVCq1T9Xwy7H78zKvOrr55GWn6pzc5RaKPwoAdsSmMgAAoHxKTz6Tn5Ne\nMSiscKNXSCMRuRJ3sKSda7Z+uuqDjxc+mnbxpKOrt97VSyyRz/Fa5DPmZRc5efFHAcCOmCEE\nAADlU3Zqoog4/junZ+Ho7isiWamJd9NZRM7u+1/C0aimfd9WqdQikp+dajLk7ljyZNzBjXnZ\nqXpXr2oPPtGkz5tavcttjwKAHREIAQBA+WTMzxERjfa6B3VqtPqCQ3fcOe7Qpp1Lnwpu0KN+\n10mWlryslLRLMX4127QcslCl1sbuX3d02/yrCUcs+4gWfxQA7IhACAAAyieNzlFEjIbcwo2W\ndKfVFX1Yi/Wdj/380Z7VL1Ru3KftiJWW6UER6TrpZ7Va6+Thb3lZpUlfjVZ/8rfPE4//HFC7\nXfFHS+lyAeBOcA8hAAAon5wrBIpIduqFwo2WpaHOnkUf+WBl571fvfjHl2Mf6DKp3TNfqQtN\nJ7p4BhXkPYvQZv3l3/sPiz8KAHbEDCEAACifXL1DHZw9k2OjCzdeOrNXRLwqN7mDztHfvnz0\np/kthyys1WZUkeH52WkiUngr0fzcTBHR6p1vexQA7IgZQgAAUD6pVOoqTfrG/705I/mspcWY\nn3Ni52eeQQ0qBNQpaeeEo1GHNr354MDIG9NgduqFL1+o+OviJwo3nvrtc1Gp/Gu2Kf5oqV0t\nANwRZggBAEC51fCRV88dWL95bru6HV7Q6V1O7FySeTm28/9ttRw999eG7R/3aT7g/bodxhXf\n2WQy7P5yrKOrt8bB6cTOJYXfIrBuJ1evyrXbPXts24db53Wt3KSPyZB3NnrthX9+qdPheQ//\n2iJS/FEAsCMCIQAAKLdcKgZHTN2175vJBzbMMBsNXpUbd/6/rf/t42I2mU1Gs8l02855WSlp\nF0+IyG/LRxZ5iw7PfevqVfnBgZEe/rVO7vzsz/9NMhnzKwTULbyytPijAGBHBEIA5YQmV2p8\nZrB3FSjPtFn2rgB3xMO/Voex3930UEijXsOWmK3p7OjqXaRnESqVuk675+q0e+4OjgKAHREI\nAZQTKqO4nyruxzUAAAAUwaYyAAAAAKBQzBACKCfMaskOUNm7CpRnmlzRJzMLDQAoVwiEAMoJ\no6McG8vfabAh91Nm7lMFAJQzLBkFAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAA\nAABQKAIhAAAAACgUgRAAAAAAFIpACAAAAAAKxUOcAQBQrmMruomo7F0Fyi+zyd4VALgNAiEA\nAMplzE23dwkAAHtiySgAAAAAKBQzhAAAKJdH1Xai0ti7CpRbprzM9Ljd9q4CQHEIhAAAKFdw\nh1lqraO9q0C5lXP1TPqafvauAkBxWDIKAAAAAApFIAQAAAAAhSIQAgAAAIBCEQgBAAAAQKEI\nhAAAAACgUARCAAAAAFAoAiEAAAAAKBTPIQQA5TmVKcvPy8kMyTZJoKN095UIX1Grrh39K01W\nx8vpTDGYJchJevlLe2/596D8elnWX5Bz2WIwi79eOvnIo36i49eLAACUSQRCAFCYo+ky6Zh4\n6+SxQHHWyM7LMv+MJObIyMoiIn9clRn/SDUXGRwkapX8nCzvnJILufJEJRGRtYmyMFbae8vg\nINGq5ECqLI6VY+kyvaZ9rwkAANwZAiEAKMzncaJXS2R98dSJiHTzlef+lg0XZXiIaFSyNE78\n9TKvnujV146OOiTfJMjjlUQlsilJAvQypfq1CcMwdzmbLTuvSIZBXPkHBQCAsod/vwGgrJl0\nVPLN8mJV+eSsHE0XvVrCPOTZKlJRJ2aRNMPNR2nkWmbr4C3d1NfSoIioROq4yqlMyTCIu066\n+Yq//loaFBGtSuq6ytZLkmsSR7U4qMSo/m/5qIg4qUWtYskoAABlFIEQAMoarUoScmRujAwO\nkonV5FiGvHVS8kwys5ZczZeB0TcfFeQkS8NERLr6Fj0UnyMeWnHXiUqkt/91h8wiZ7PEx0Ec\n1SIijwXKu6dkVbx08xUHtRxIlV1XpKfffwESAACUKQRCAChrVCq5lCeTq0uYu4hI64oSVUEO\npIpZxF0rb9e5+SjHW2S2HZdlf6o8HXLdvF++Sa7mS3KebLgop7NkWo1r7R29RaeS90/LsjgR\nEZXIoEoyNLi0rgwAANxjBEIAKIN0amng/t9LbwfJNUmeSfRqaexRgvPsSZE5MfKgp/QPvK79\n73SZekxExE8vM2rKg57/tqfJ+6elgbt09xUHtexNkTUJ4qCWxyvd5QUBAAC7IBACQBnkob1u\nQs8y+Wcyl+wkGy7Kx2floYoytfp1ZxORai4ys5ak5kt0qrz6jwyoJMODxSwyN0YqOcrMWtf6\nN/YQk1mWx0lbL6nkeBfXAwAA7INACADliDWbylh8GivrEmVgoAwLKZoGRcRDK+GeIiJdfMVX\nL2vipZWnuOskMVcGel/Xv5GHrL8gR9MJhAAAlEUEQgAoR6zZVEZEPo+TbxNlfFWJuH6DmZR8\n2XVFarhILdf/Guu7ydciZ7KkjpuIiMF03ZB8k4iIoYSTkwAA4P5AIASAcsSaTWX2p8rqeHm2\nStE0KCI6tXx8Vuq4ydy6/00DHkgVEfHVSyVHcdHIvlQZKf8d3Z8qItcFSKA8uhy7/8B3M5Jj\n9xlyM918qtVq+0ytNiNVao3laOLx7Qc3vXk17qDJmO/uV7Nux3HVHnxCVNc+J2f+/Protvmp\nicdMhjxXn9DqLYfWaT9Wo9Xb72oA4D8EwvvRli1bTpw4Ye8qypKMjAwROXTo0Pz58+1dS1ni\n4uLSt2/fChUq2LsQlB6t6jabyhjNsuCMeGhFr5bNSdcdauwhfnoZWElWnpcJR6S1l+hU8ne6\n/JIsdd2kkYeoRIYGy8dn5eXj0s1X9GqJTpEtl6Stl1R1tullAfaVFLN7y5x2zp6V6neZqHN0\ni41eu3vlmPRLMc36zRGRuIMbty3oVTGkYcOeM1Rqzek9q3cseTI9+UzDHtNF5MjW9/d+PaFa\n+BMNH3lVo3VIOLbtz/9NuhSzu92Yb+x9WQAgQiC8Py1cuDA7O9veVZQ9sbGxsbGx9q6ijAkK\nCurSpYu9q8A9lGGU8zkiIvNOFz30Wk3x08uQIKnkKBsvysrzYjCLn16GBktv/2tTgr38xVMn\n316Qd0+J0SwBjjI0SPoFFj0VUL5Er3tJ4+DUfdrvTu5+IlKz9YiNs5sd//njJn3fUqu10ete\ncvWu0n3KLo2Dk+Xo+hkPHPnxvYbdXxGV6p8di9x8qrZ5+gvLhKF/rYevxh8+G702L+uqg7Pn\nbd4YAGyPQHg/MhqNwc5Or9WrcfuuwJ36Lfnq0jNxRqPR3oWg5N6sXbRlbKiMDbVqrIdWtobf\npk8Hb+ngfcujbb2krZdV7wXcNzbPaWcy5LUaumjPmvFJMbu1Oif/2u3CB8138vAXszkn8/JN\nR6nVWgfnCiJSLXxwrTYjLWlQRFQqtU/V8Mux+/Myr+pdvWq2HuHqHWpJgyKi1uh8q7U4+dsy\nQ16WVu+i0Tmq1JqC5aMiotO7qtQaNUtGAdwfCIT3KUeNurY79+TAhmIys+xdAgDcIxqtQ/ql\nmJ1LhzXsOeOhYZ9fOr3n18WPG/NzOj6/ITvt4poJATcd5eFfq8/s4yJSs/XTRQ6lXTzp6Oqt\nd/VSqdR1O75w3TGz+Wr8YZeKwVq9i4jU7zxhx2dDDn4/u2abkRqdY+KxbWf3r63T7jmtAwut\nAdwXCIQAAKDcU2VeiWs9fHlA7XYi4tIk6NTvXRKO/SRms96lYpf/i7rpGEuiu9HZff9LOBrV\ntO/bKpW6oNFoyM1Ju5h5Nf74zx9dOX+o7chVlvZqLZ5Ua/W/LXt6//rpIqJSqRt0f6nxozNL\n+foA4E4RCAEAQPmn0eoDaj1c8NLFs5IxL9uQn611cA6s29H688Qd2rRz6VPBDXrU7zqpcPvF\nEzt/fL+TiLh6VW7/7NrgBj0s7RdO7Pht+Qj/Wg/XajtKo3M6//cPh354S6PVh/V4pRSuCgDu\nGoEQAACUf3o378I38qlUGhExm023HnETx37+aM/qFyo37tN2xMrC04MiUjGkYcfnN+SkX4o/\nGrXtw0cf6DalSZ83zWbTrs+HufvV6PD8d5b+gXU7mkyGA9/NCG02wN2PzQIA2B+BEAAAKJgV\nm8pY7P3qxSNRkQ26TW3S583C2dLC0dU7OOwREanx0PB9FUMO/fBW5ca99S5e6ZdON4iYVjg9\nBtbpeGzbh0kxuwmEAO4HBEIAAKBc1mwqIyLR37589Kf5LYcsrNVmVOE+OelJZ6PXeVVu7BPa\nvKDRr8ZDf29590rcId9qLUTEZMgrPMRkyBURk/G6RgCwFwIhAABQLms2lUk4GnVo05vhg+YX\nSYMiotbq96we51utRddJPxdMAyYc2yYirl6V3f1qODh5xB/5san53f+OHv1JRLyrNLPF5QBA\nSREIAQCAcqm1DsVvKmMyGXZ/OdbR1Vvj4HRi55LChwLrdnL1qtwgYtpfG2dufk9byhsAACAA\nSURBVLdtlSaPqbX6iyd2nP5zjW+1FgF12qtU6ka9Zu5Z/UJUZETNNiO0Ds7xR7ae2PVZaLMB\nFYPDbHxlAGAVAiEAAMAt5WWlpF08ISK/LR9Z5FCH57519arc6NHX3f1qHP/54782zjQZ8ly9\nqzR+dGbdTuMtU4J1O4xzcvc/+lPkzs+GmkwGN++qjR+dWWSHUgCwIwIhAAAo5zq/uKVIS/gT\nC8KfWGDNWEdX72FLzMX3qRY+uFr44FsdDW3WP7RZf2veCwDuPfXtuwAAAAAAyiMCIQAAAAAo\nFIEQAAAAABSKQAgAAAAACmXVpjIZGRmbN2/+8ccfDxw4cOnSpZSUlAoVKvj4+DRs2LBr167d\nunVzdXW1daEAAAAAgNJ1mxnCnJycOXPmhIaG9u/f/4svvsjPz69Ro0anTp1q1KiRn5+/cuXK\n/v37h4aGzp07Nycn595UDAAAAAAoFcXNEJ45c6ZPnz6HDh3q16/f0KFD27Zt6+zsXLhDZmbm\nr7/+unz58ilTpqxatWrt2rWhoaE2LhgAAAAAUDqKC4RNmjRp2LDh4cOH69Spc9MOLi4uERER\nERERx44de+6555o0aXLlyhXb1AkAAAAAKGXFLRl97rnnoqKibpUGC6tTp05UVNSzzz5beoUB\nAAAAAGyruBnCWbNmFX6ZnZ0dHR0dHx/foUMHb29vg8Gg1f43XKPRzJ4921ZlAgAAAABKm1W7\njIrInDlzZs+enZaWJiK7d+/29vaeMWNGYmLi4sWLNRqNLSsEAKuo86Tyt0Z7V4HyTJdmtncJ\nAACUMqsC4ZIlSyZPntyzZ8+IiIjRo0dbGmvVqvXuu+/WrFlz6tSptqwQ5dnhS5df3fH77+cT\nc43G+j5ek8ObPlKj6h13Pnkl5anvf4y+kLR1YJ82IZVuepKYq6lNP1/lpNMmPD/S0jL7tz2z\nf9tbpFu7ysGbB/S6u4vDPeXh4REfH++912TvQlD+eXh42LsEAABKjVWBcMGCBaNHj/7kk09y\ncnIKAuGQIUOOHz/+xRdfEAhxZ05dTemw6hsfZ+fX27Rwd3BYeeRY/283fdW7e8+bZcLbdl78\n1+EpP++s6OhYzDuaRcb8uC3bYHDS/fedn5qbp1apPurSrnDPQB6tWda8/vrrFy5csHcVZUl2\ndvbkyZMfeOCBUaNG2buWskSj0VSpUsXeVQAAUGqsCoTHjx+fO3fuje1t27aNjIws7ZKgFG/8\nttdgMv80qI+/q4uI9K9bs8XyNVN+3vVIjaqqEnbek3Bh0vYdbz/8kIuDbuQPP93qHZcePLw3\n4UL7ysF/JV0qaEzNzXVz0A1rUM8W14h7xs3Nzc3Nzd5VlCWZmZki4uLiUqNGDXvXAgAA7OY2\nD6a30Ol02dnZN7ZfvHhRp9OVdklQBKPZ/P2pM92qVbEEPBHRqFRP1q9zJiX1UKG0ZmVnbyen\nnU/2H924QTHvmJiR+dIvv00ObxbicV1sSMvNc3NwKLULAwAAAMoOqwJh8+bNIyMjc3NzCzem\npKTMmTMnPDzcNoWhnDubkpael/eAr3fhxoZ+PiLyd1JySTtX8/R4wMdbijUu6pcgN7dJ4U2K\ntKfm5rnrrwXCbIOhxFcCAAAAlFlWBcIZM2bs2LGjbt26//d//yciixYteuqpp6pUqfLPP/+8\n+uqrNq4Q5dOFzEwR8XN2Ltzo4+wkIokZWXfT+aa+OX5y06kzn3broFMX/Z5Py83NNRqHbdrq\n98FCz/c/Cfxw8YRtOzLz80t2PQAAAFZ47bXXVCqVr69v/s1+2Bg5cqRKpXrooYfu7OQDBw50\ntW4fhIceeqh27dp39i4oZ6wKhG3atPnxxx8rVKjwySefiMjnn3++fPnyWrVqRUVFtWrVysYV\nonzKMRhFxEFz3XegXqMRkVxj0Wm6EnW+0ZWcnBd/+vW5JmHNAvxuPJqSm3v6aqqDWrOgS/vV\nvSI6h4Z8FH3wsXWbSnY9AAAA1lGr1VeuXNm8eXOR9pycnP/9738O3MmCe8va5xC2b98+Ojo6\nOTk5Li5OpVJVrlzZ09PTppWhfHPUWuLcdU+NyzEaRcRRW/TbskSdbzRp205nne611jdf3rx1\nYB+tWu3ncm36sXfNag4azYq/j/167nzbkCArLwcAyqiM+H1qDT99wlbyM9j/+SbUavWDDz64\nbNmynj17Fm7fsGFDZmZm06ZN7VUYlMnaQGjh7e3t7X2bO7UAawS4uojIhczrFnxeyMgUkUo3\nLHUoUecifjp7btWR4//r08Nsloy8fBExmMwikpGXr1WrHbWaSm5Fz/BY7Ror/j52KCmZQAig\nHNNoNCJy9ofx9i4E5Z/lmw0FDAZDr169Xn755cuXL3t5eRW0r1ixol27drm5ucZCvwTfvHnz\nW2+9deDAAYPBUK1ateHDh7/44osqlUpEzGbzrFmzFi9efOnSpRo1asyYMcPSXuC333577bXX\n9uzZk5+fX7t27eeff3748OE31pOYmPjqq69u3br14sWLFSpUaNWq1RtvvMGCUuUoLhBa+X1w\n/PjxUioGClLFw93TUX/gQlLhxj8TL4pII3+fu+lcxPenzphFHlv3fZF278hPu1Wr8m3fR9Ly\n8kTEvdDyjMx8g4g460r26xIAKFuGDRsWFhZm7yrKmJUrV7q6uvbq1cvehZQxd3xHXDnWu3fv\nKVOmrF69euzYsZaWpKSkH3/8ceHChYsXLy6I0OvXr+/Tp89DDz20bNkyNze3b775ZsKECQkJ\nCZYHws2ZM2fGjBmDBg0aNmzY5cuXZ8yYUThJ/vLLL507d27ZsuXKlSudnJzWrVv39NNPX7ly\nZeLEiUWK6dOnz9mzZ2fPnh0aGpqQkPDOO++0bdv2zJkzztdv34DyqrgfeZkMhO2oVapeNauv\nOnI8NjWtsoe7iOQYjMsOHX3Ax7u2V8W76VzEC00b9q993WPW5u6J/u18wrd9H/F0cryYmVX1\n46VdqlZe1/eRgg4r/j6qEnkoqFLpXCoA3JeqV69evXp1e1dRxqxZs6ZChQr9+/e3dyEo8ypV\nqtS+fftly5YVBMLVq1frdLp+/fotWrSooNu0adOCgoKioqL0er2IdO7cOTk5ef78+dOmTatY\nseIHH3xQr169L7/80jIx2KZNmypVqhTcgjhx4sSgoKAff/zRMrZTp04JCQmzZ89+7rnnnJyc\nCt4iLS3tjz/+mDJlytNPP21padWq1Zo1a1JSUgiEClFcINy1a1fxgzMzMxMSEkq1HijIy62a\nbzh5uvOab8c2CXPR6T4/dORcWvqm/o9ajn5/6syAbze92771c03Cbtt5d3zi8ctXLF+IyObT\nZ2NSUkTk4ZCg0AoeoRU8Cr+v7+FjGrW6ZVCg5eUzjRp8vP/gI//7rlfNanlG07cnTu04F/9s\n47BaXtwlCwAAbOWpp54aPHjwkSNH6tWrJyIrVqzo1auXm9t/T0tOSEg4fvz4qFGjLInOonv3\n7t9+++0ff/zxwAMPJCQk9O3bt2CZaGBgYNOmTQ8dOiQiycnJ0dHRY8aMMZvNOTk5lg4REREb\nNmyIjo4uPGfr7Ozs7e29Zs2aTp06tWvXTq1Wh4aGTps27R78H8B9wqpdRm/ljz/+ePjhh0up\nEihOkJvrz0/0fcDHa9auPRO379BpNJv6P1pw257JbDaazSaz2ZrOXx45PmbL9jFbtq/4+5iI\nzNu73/LSsqy0eHM7tI7s2PZSVva0n3976ZffMvLyP+rS7v2ObWxz0QAAACIivXv3dnNzW7Zs\nmYgcPXp0//79Q4YMKdwhPj5eRIKCrtvRIDAwUEQSExMvXLggIr6+vjceFZG4uDgR+eSTT5wK\nGT16dMFpC2i12h9++EGlUnXs2NHHx2fAgAGrV682Xr+TH8o3a++S2rRp0+rVq8+dO2cymSwt\nRqPxyJEjhX9jAZRUzYqe3/TpcdNDPWtUzZn8vJWdF3Rut6BzOyvf9NOuHT7t2qHgpVqlGt24\nwejGDawcDgAAcPecnZ379eu3cuXKt99+e8WKFQEBAZ06dSrcwTL1l5eXV7jRbDZbDpn//aV5\nYQVBzjJ22LBho0aNKtLnxrXizZo1O3Xq1I4dO7Zs2bJ58+avv/56wYIF27dv5+d8hbAqEK5Z\ns2bQoEFardbf3//8+fOBgYGpqamZmZnt2rWbMGGCrUsEAAAAyp+hQ4cuXbp0165da9asefzx\nx4tsxxocHCz/zvUVOH/+vIgEBQX5+PiIyMWL1y2GOnv2rOWLkJAQETGZTOHhN3/sVhEajaZd\nu3bt2rV75513Fi5cOHr06K+++qrIjCXKK6uWjM6dOzciIuLKlStxcXF6vX7btm0pKSmffPKJ\nVqtt27atrUsEAAAAyp/WrVtXrVp1zpw5sbGxN6YvPz+/Bx544Pvvv8/Ozi5oXL9+vbOzc4sW\nLapUqeLt7b1t27aC5XvHjx+33EAoIhUrVmzevPn69etTUlIKxq5YseKVV14xGAyF32Xfvn0D\nBw5MSvpvL3fLRGXhFpRvVgXCEydOPPvss4VvctVqtaNHjw4LC5syZYrNagMAAADKLZVKNWTI\nkE2bNoWFhTVocJO7V956662rV6926tRp7dq1GzdufPzxxzdv3jx9+nR3d3e1Wj1mzJhjx471\n6dPnm2+++fjjj7t27dqkSZOCse+++25WVlbr1q2/+OKLrVu3Tp8+fcSIEQkJCVrtdSsEK1Wq\ntGXLlk6dOi1dujQqKmr16tWDBw/W6/WPPPLIDeWgfLIqEKrV6oL9ixwcHNLT0y1f9+zZc926\ndbYqDQAAACjXhgwZYomFNz3avXv3H374Qa1WDx06tF+/fsePH1+6dOnUqVMtR2fMmDF16tQ9\ne/Y88cQTn376aWRkZMuWLQvuOWzbtu327dsDAgKee+65Rx99dO3atTNnzly8eHGRtwgICNix\nY0eNGjVefvnlHj16TJgwwdfXd8eOHbVq1bLdVeO+cvMbUosIDw8PDg5etWqVTqerXbv2008/\nPWnSJBFZv3794MGDMzIybF/nHUpNTc3Pz7d3FSXWs2fPynrdsuY8Lxg2tCkx6c2jp8aNGxcR\nEWHvWmAHmZmZffv2DQ8Pf+211+xdC1Bm9OnTx9/f/+OPP7Z3IbgXeCI3FMKqTWVeeOGFxx9/\nPD09fcuWLV26dJk+ffr58+e9vLwWLlwYFkZoAQAAAIAyyapAOGjQILVafe7cORF57bXXjh07\nNn/+fBEJDg7+4IMPbFsgAAAAAMA2rH0O4YABAyxfeHp6bt26NSEhIS0trVq1ajqdzma1AQAA\nAABsyKpNZUQkMTHxww8/LHip0+m+/vrr5ORk21QFAAAAALA5qwLhP//807hx44kTJxa0ZGVl\nzZgxo0mTJqdOnbJZbQAAAAAAG7IqEE6dOtXV1XXXrl0FLZUrVz569KiLi0vBvrcAAAAAgLLF\nqkC4c+fOl156qVmzZoUb69SpM2nSpB07dtimMAAAAACAbVkVCDMzM/V6/Y3tWq02MzOztEsC\nAAAAANwLVgXCRo0aLV++3GQyFW7MzMz89NNPGzZsaJvCAAAAAAC2ZdVjJ6ZPn96jR4+6det2\n6tTJz88vJyfn/PnzGzduTElJ2bRpk61LBAAAAMqB9PR0W5zWzc3NFqeFQlgVCLt167Zx48Zp\n06YtWLCgoDEsLOyLL77o2rWrzWoDAAAAANiQtQ+mj4iIiIiIuHTp0vnz50UkODjY29vbloUB\nAAAASnTy5MmjR48++uij9i4EimBtIMzKykpNTQ0ICPDx8cnJyfnqq68uXbrUs2fPmjVr2rQ+\nAAAAQFFWrly5Y8eOhx9+2MPDw961oPyzalOZ48ePh4aGLl++XEQMBkP79u2feuqpSZMmhYWF\nRUdH27hCAAAAQEEsWzkajUZ7FwJFsCoQvvzyy/7+/gMGDBCRr776avfu3YsWLYqJiWnUqNEb\nb7xh4woBAAAAADZh1ZLRXbt2zZs3LzQ0VES+++67Bg0ajBw5UkTGjh07efJk2xaoVPkmc0J2\njr2rQHmWkp9v7xIAAFAik8l0+vTpIk90KywjI0NEYmJikpOTb9XHz8+PBaUoFVYFwpSUlICA\nABExmUzbtm0bMWKEpd3Hx6eYb1PcjbOZWf1+32/vKgAAAFDKNm7cGBkZedtuxc+7VKtWbcmS\nJaVXFJTLqkDo5+d3+vTpdu3a/fzzz1euXOnWrZulPS4uzsvLq5iBGRkZixYt+vPPPw0GQ/36\n9ceMGePr62t9n/j4+Hnz5p06dWr9+vUlOicAAABwf0pNTRWRdr5elZwc7+wM685fSEtLK9Wi\noFxWBcLOnTu/8sorJ0+eXLNmTZUqVVq3bi0iSUlJH3zwQatWrYoZGBkZmZycPGvWLEdHx2XL\nls2cOXP+/PlqtdqaPjt37lyyZEmjRo1OnTpV0nMCAAAA97OIAN+W3p53NnbrhUvm0q0GCmZV\nIJw1a9aRI0feeecdHx+fzZs3azQaERk3bty5c+e+/PLLW41KTk7eu3dvZGRk1apVRWT8+PFP\nPvnkwYMHGzVqZE2f/Pz8uXPnxsTE/PLLLyU6Z/ngq3d4KjTI3lWgPPs7NX1z4iV7VwEAAGzu\nn3/+GTp06L59+wwGw007NG3atODZAR4eHjVq1Bg/fvwTTzxhaTEYDO++++6qVatiY2PNZnPl\nypWffPLJyZMnq9Xqxx57bO3atTeecOjQocuWLStmoI2uFHfAqkAYEBCwe/futLQ0Z2dnrfba\nkIkTJ0ZGRvr7+99q1MmTJx0cHCxb0YiIq6trcHDwyZMnC4e3Yvq0b99eRGJiYkp0zitXrhSe\nUQwODnZ2drbmGu83Hg66Ryvd8v8tcPe0avXmxEsajUan09m7FtiB5c9dpVLxDQCUFJ8alC1f\nffXViy++2KlTp3379hXT7amnnpo1a5aIpKamrlix4sknn6xZs2azZs1E5OWXX165cuWiRYua\nNm1qNpu3b9/+7LPP5ubmzpgxY8GCBW+//baIHD58uHfv3j/++KNl2sbd3b34gffiymEdax9M\nL//+uRZo2rRp8f3T0tLc3NxUKlVBi4eHh2XNdIn6lKj/wYMHJ02aVPDy448/bt68efF13ocK\nXyBgU05OTuxRpkyW386qVCq+AYAS4VODMic3N/ePP/7Yv39/MSv7RMTFxSUoKEhEgoKC3njj\njblz5x49etQSCKOiogYPHty9e3dLz8cff9zLy8tsNotIweRQSkqKiISEhFSvXr3gnMUMxP2j\nBIHwDhQJNjf947emj/X9K1euPHTo0IKXXl5e2dnZVlYLKFB+fj6fEWXKyckREbPZzDcAUFJ8\nahTCycnJ3iWUjiFDhojI/v3Wbl+fl5e3cOFCd3f3jh07WloaNGjwzTffDBgwoHHjxpaWLl26\nWHOqOx6Ie8mGgbBChQppaWlms7kgwqWmpnp6epa0T4n6V61a9fnnny94mZqampmZWVpXdM/w\nixPcM7m5uWXxM4K7l5WVJSJms5lvAKBE+NQoh+0C4dmzZ0Vk0sFjd3MSh1svqbszixYtWrZs\nmYhkZWVVrFhxxYoVlSpVshyaN2/es88+27x585CQkFatWrVu3bpXr17W7PN/xwNxL9nwhs6a\nNWvm5+cX3NGXmpoaFxdXu3btkva5m/4AAADAfcXV1VVEari6NPX0uLP/dCpVwb4epWXAgAF/\n/eudd94ZNmzYwoULLYc8PT1Xr1594cKF9957z9/fPzIyMiQk5IsvvrjtOe94IO4lG84Qenp6\ntmrV6sMPPxw3bpxer1+yZEn16tXr1asnIlFRUTk5OY888kgxfa5evWo0GtPT00UkOTlZRFxd\nXYvpDwAAANz/vL29RWRUtZA7fuxE7137zC4upVqUeHh4FNz+16BBg6SkpFdfffWZZ54p6ODt\n7d27d+/evXvPmTPnxRdfHDNmzKBBg6zJpXc8EPeGbbd8HTt2bLVq1V555ZUJEyY4Ojq+/PLL\nlqWef/311969e4vvM2nSpOHDh3/44Ycmk2n48OHDhw/funVrMf0BAAAAlAqz2Wx5RsW5c+cG\nDRoUGxtb+GibNm0yMzMtMze3cscDcY9ZFc11Op1er7/pIZVK5e7u3rBhw4kTJ7Zr167IUWdn\n5xdeeOGFF14o0l54I9Bb9VmyZMlN3/FW/QEAAAAUceHCBYPBcPnyZRE5f/68iFSoUMHV1fWz\nzz7LyMgo+KE6MzPTcjQnJyc6OnrevHkDBgwQkUqVKh09erRHjx5vvvlmWFiYyWQ6cODAxIkT\nO3XqVMzGH3czEPeYVYFwzJgxe/bs2bt3b926dWvVqqVSqU6cOHH48OGHHnooJCQkKSlp165d\nW7Zs2bRpU9euXW1dMQAAAAArhYeHF0zTBQcHi8i8efPGjx8fFRWVnJxcEAiXLVtm2VRGr9dX\nrlz5+eefnzJliohoNJpffvll9uzZEyZMiI+P12g0ll39X3zxxeLf944H4h6zKhA+8sgjGzZs\n+P3331u0aFHQuHv37qFDh0ZGRjZp0iQ1NbVz585vvPEGgRAAAAC4f1g2Nb3RmjVrCr4u/pn1\nnp6e77333nvvvVdMH8uj5+9gIOzOqkA4ZcqU2bNnF06DItKiRYupU6dOmDDhl19+8fDwGD9+\n/MiRI21TJAAAAFCufHDyzGdn4u5s7NV8Q4XSrQYKZlUgPHLkiJ+f343tgYGBf/75p+VrZ2dn\nNncBAAAAilejRg13d/dUszn1Fk+ezs7ONhgMrq6ut/rp2tHFpW7dujYsEUpiVSD08fFZsmRJ\nx44di3xTrl692sXFRUQMBsPChQt5HiAAAABQvBYtWnz33XfFdJg+ffquXbuWL19esWLFe1YV\nFMuqQPj000/PnDnz6NGjnTp1CggIUKlUly5d+uWXX/bu3fv888+LSP/+/Tdv3rx69WobVwsA\nAAAAKDVWBcIZM2ZotdoFCxbMmzevoNHDw+PFF198++23RaRt27b9+vUbOHCgrcoEAAAAAJQ2\nqwKhWq2ePn36K6+8Ehsbm5SUZDabvby8QkNDNRqNpQNPBQQAAABKhbOzs1ardXR0tHchUASr\nAqHFlStXDh8+nJiYqFarg4KC/Pz83NzcbFcZAAAAoEBjx44dOHCgs7OzvQuBIlgVCE0m04QJ\nEz766KP8/PyCRhcXlxkzZkyaNMlmtQEAAACK4+bmxrwL7hmrAuH7778fGRnZp0+fiIiIwMBA\ns9l8/vz5devWTZ482c/Pb8iQIbauEijGgYuXZu36I/pCUla+oWoFjxEN6w8Pq6f5d0fcX2LP\nv/PHvkNJyQaTsUZFz+cahw2sV6tgt9xvjp/8KPrgP5ev5pmMVTzcB9evM6ZxA/2/a6EBAACA\n8s2qQPj5558/88wzn376aeHGUaNGDRw48IMPPiAQwo72JFzovHpdoJvri80buznovv0n5vmt\nP59OSX3r4VYisunUmX7fbgrz9X6lVXONSvXVsRPDNm09k5r2UstmIvLBnwem/LxrUN1aL7dq\n7qDW/BwbN+3nXXviE1f3irD3ZQEAAAD3glWBMCYmJjIy8sb2xx9/nJ1FYV/Td/zupNX++sRj\nvi7OIjKsQb1WK75aeODQrDYttGr1qzt2V/Zw3/7EY05arYgMC6vXZOmqD/7cP61lM5XIZweP\nhFbwWNqjs2XCsE1IpSPJl789EXM1J9fTUW/XywIAAMq1Y8eOPXv2TJgwQa1W27sWlH9WBUKt\nVpuenn5je15enobFdbg7ndesyzOaPu7SfuK2HXsSLjhqtQ+HVHq/Y1s/F2ezyJXs7JuO0qjV\nFfR6EXm8bu3hDbSWNCgiapWqeaD/gYuXUnJyKzo5DgurV8XD3ZIGRUSnVj8Y6P/F4WNZ+fku\nOp2jVqMxqlSFTuvioNOoVCwZBQAAdhQVFbVr164RI0Z4enrauxaUf1YFwkaNGn3wwQc9evRw\ncHAoaMzOzo6MjGzcuLHNaoMiOKg1p6+mjtr808stmy/29d6beHHoxh9zjMa1fXokZWZV/uiz\nm46qWdHz0IjBIvJUg7pFDp26muLl5FTRyVGtUo1tElb4kFnkaPLlIDdXF51ORMY3azR8U9Rb\nu/98ukE9vVb7c2zc+n9iRjdu4Kwrwe67AAAAtmA2m+1dAhTBqh98p02b1qNHjxo1anTt2jUo\nKCgvLy8uLu77779PSUnZsmWLrUtE+aZSyfn0jM+6d2obEiQivd1cV4aGbD8bZxbxdNT/MKDX\nTUdZEt2N1v5zatvZuNltW6oLzfzlGo1JmVkJGZmf7j/096XLyx/pYml/vF5tB41m9JZtr+/8\nQ0TUKtWU8Kavtg4v5SsEAAAA7ldWBcKIiIh169ZNmzZt0aJFBY0NGjT44osvOnbsaLPaoBR6\njaZNSFDBy0BXl2yDITvf4KzTtq8cbP15NsecHflDVES1Kv/X/LqJ69/OJ0R8tV5EQtzd1vSK\niKhWxdK+Ky5+zJbtbYIrPR1W30mn3RJz9t0/9jloNdNaNCuFqwIAALiZzMzMX3/91Wg03qrD\nhQsXRGTr1q0uLi636lOzZs1atWrZpD4ojLVL43r16tWrV6+EhIT4+HiVShUcHOzn52fTyqAc\nXk5OhW/k06jVImIq4TKJT/cfmrBtR6+a1T7v0Vl93Y2BEubrvbZPj+Ts7G1n4x5b9/3EB5vM\nbNPCZDaP3LytuqfHN316WPq3rxxsMJln7drTr3aN6p4V7v66AAAAbrRx48aFCxfetlvxfQIC\nAlatWlV6RUG5SnavVGBgYGBgoI1KAYqwZlMZi0nbd364769J4U1mtmmpuqGzl5NT9+qhIjL0\ngbrB7q7v/rGvZ42qXk6OZ1JSJ4c3LZwe21cJ/nj/wT0JFwiEAADARvLy8kQkqYU62//GH1us\nErTFZDAYSrUoKFdxgbB27drWnOL48eOlVAxwHWs2lRGRGTt2fxR98KMu7Z4Oq1+4z6Ws7PUn\nYhr6+TQL+G82u2WlwPdk/+FLlx+s5C8iedev1sg1Gm9sBAAAKHVpNdWpEhJ1SwAAIABJREFU\nte8wEAZsV+LPKtHR0Z06dUpOTuZpHKWruP+b3ta5Z7VCaSybytz0v8UR125e3XY27p0/9s3t\n0LpIGpT/Z+/O46Iq////X8MAyibiCKIsouKCLIKYO+IC5lZqWkbuWy6pLWrWm9zTLPWtpkYu\nb3F9q2lpqJkprqSkkWhuCZKCKCoiIJsMMt8/zuc9P34s42jAOJzH/dYfM9dc1zmvwTk0T65z\nriOEuVL50ZETnx7/tejZp8duJQkhXG1t3O1q2lYzP/x3YtFXj95MEkL4O3I6NAAAqCLu3Lkz\nePBgBwcHW1vbwMDAs2fPluzTqlUrxf/UrFnzlVde2bZtm/bVgoKChQsXenl52djYWFtbe3p6\nLlq0qLCwUAgxcOBARWlGjBihe+ALOHLkSJcuXYqlwaKVKxQKlUoVFBQUHR39YruQJ10zhFFR\nUZVWB1CSuVKpe1GZgsLCD44cV1lYWJiahl+8XPSlbm6urjVsPm7basHps0Hbf3ijqXs1pTIq\nKfm7q9fb1HPs7OpsolDM6th2auTJvrsjRvp4WpqZHvk7cePFy282a+zjwJ85AABAFdG3b19L\nS8tffvnF2tp65syZffr0+fvvv0suVzNixIj58+cLITIyMjZv3jx06NAmTZq88sorQojQ0NCt\nW7euXbu2VatWGo3m6NGjEydOfPLkyezZs1etWrVo0SIhxKVLl/r373/o0KGGDRsKIWrUqKF7\n4Au8kSNHjrzxxhsl27WVCyHu3bu3dOnS4ODgixcvNmjQ4AX2oqVWq83KWNa+fFXajsqia4Zw\n1KhRuWVcwVVSbm7u6NGjy6MkQF8ZT57EpaU/zM2d8PPRYv/F3nsghJjZsU147+5PCwsX/nr2\n0+NRlx48nBXQ9sBb/aTrBt/zb7H19R6ZT/LH/HT4rT0/Hb6ZOCug7YY+3Q39tgAAAMpHWlqa\nm5vb2rVrfX193d3dv/zyywcPHly6dKlkTysrK2dnZ2dnZ09PzwULFigUiitXrkgvHT58eMiQ\nIb17965Tp46jo+M777yzc+fONm3aCCEcHR3d3d3d3d2dnZ2FEK6urtJTBwcH3QOLql+//ubN\nm6XHoaGhCoXi1q1b0tPAwMAFCxYIIfLy8qKiokq9wYG2cmdnZ39/f2lTBw4ckF69d+/eoEGD\natasqVKpunfvfvny/00hnD9/vm3bttbW1v7+/kePHlUoFOfPn1er1QqFIjw8vEGDBqNGjdIx\nfOPGjR4eHhYWFo6OjhMnTszLyyur8d69eyEhIfXq1VOpVN26dbt48aIQouSOSh1bOXTNEB49\nerRNmzZff/11586ddW/l1KlTkyZNysjIKM/SIA/73uxbrGV5UODyoEB9xqosLPI+nqy7T4hn\n0xDPMhdlHtis8cBmjfXZFwAAQLmQ7jhf7aHGMvkFt6B4KvQ88bJWrVq7du3SPk1OTjYxMXFy\nctIxJD8/f82aNTVq1NCmLx8fn927dw8aNKhly/+7s9err76qz971HBgcHHzy5Mlhw4YJIY4d\nO+bl5XXy5MmhQ4fm5eX99ttvS5cuFUJERUU5ODg0bvzsr21KpVKpVGoX3Rk8eLBKpUpISLCw\nsFiwYEFQUNCNGzeUSmXPnj179ux55MiRO3fuDBkyRAhhZmZmZmamUCjCwsL27NkjTXWWOjwl\nJWXUqFGHDx/u3LlzcnLygAEDli1bNmjQoJKNn376ad++fVUq1fnz562srGbPnh0YGBgfH69S\nqYruKCEhodSx+vyQ/zldgTAmJiYkJKRLly6BgYHDhw8PDg6Wor9WcnJyZGTkpk2bjh49Ghwc\nfPTo0QquFgAAADBu169fF0K47P9HC8Nk5D33TExaWtro0aOnTJlS7Cu9ZO3atRs3bhRC5OTk\n1KpVa/PmzdrcuGzZsokTJ7Zu3drV1bVDhw4BAQH9+vWT5gB103NgcHDwzJkzhRBZWVmXL19e\nuHDhiRMnhg4deubMGRsbGylMHjlyRJ/7n2dlZc2dOzcnJ6dPnz5CiMuXL0dGRqakpNSqVUsI\nMW/evNWrV+/fv9/BweHevXuzZ8+2trZu0qTJ5MmTpTgqhDAxMXn99dd9fX11DHd1ddVoNHZ2\ndkql0tXVNTo6WqlURkdHl2w8f/78b7/9dunSJemOffPnzw8LC4uIiBg5cmTRHV25cqXk2Ge+\n2fKi65RRlUr1888/b9myJTk5edSoUS4uLg4ODl5eXh06dPDy8qpTp46zs/Pw4cOTkpK2bt36\n888/q1SqSqsbAAAAMEZSHnvkZZIS+IL/Pa0mLC0tn2un165da9OmTWBgoDThVtKgQYNi/+fL\nL78cOXKk9kaIdnZ227dvT0lJWbp0qaOj4/Lly11dXbds2fLMneo5UDvtFhUV5efn17Vr1xMn\nTgghjh8/HhwcLK0ic/jw4bIC4dq1a63/x8bG5uDBg3v37nV3dxdCxMXFCSEcHR2lJWeUSmV6\nenpCQkJiYqJSqaxfv760hWJnsWrnIcsa3qZNm/fee69NmzYdOnSYPXu21K3Uxhs3bigUiqZN\n/+9sNUtLSycnpxs3bhTbUaljK80z1mw1MTEZMmTItWvXTp48GRoa2qZNG2tr67S0NBsbmzZt\n2nz22WenTp26evXq4MGDWf4VAAAAeCZpQZeH/ibJPZQv9t/T6qJakRsyP1NkZGTHjh3ff//9\nsLCwsr6029raSpf/+fj4jB49eurUqbNmzSraoXbt2v3791+8ePGVK1cmTJgwYcIEPe+F+MyB\nKpXKz8/v1KlTx44dCwwM9PDwSE9Pv3PnzvHjx6VTTNPS0i5cuNCtW7dSt6+NsidPnrSzs5s4\ncWKvXr2klxQKhRAiJydHU8Qnn3yi0WgURe5EXfSxEP/fz7as4QqFYtWqVQkJCUOHDo2JifHx\n8fnuu+9KbZS2oymypn3RXRfdUVljK4FeKU6pVAYEBHz++ef79u2Ljo6+evXqmTNnIiIi5s+f\n37Fjx8qc0AQAAACgv6ioqLfeemvr1q2TJk3Sf5RGo5FiW2JiYkhIiHaVF0mnTp2ys7MfP36s\nYwvPNbB79+7aQCiE6NChw6FDh86ePdu9e3chRGRkpKenZ1knqWqjbMuWLb/++utp06Zpl8OR\npuBiY2O1nRMSEoQQ9erVKygoSE7+v4s4S70Vh47hBQUFDx48cHFxGT9+/P79+ydOnPjNN9+U\n2ti4cWONRqO9bXtWVlZycnLJKyFLHVvWD7bcMa0HAAAAVE25ubnDhw//4IMPvLy8bv9Pdna2\nEOI///nPihUrtD2zs7OlV+Pj43fu3CmtkiKEcHJyunLlSp8+ffbt25eYmHjz5s09e/ZMmzYt\nODjYzs5Ox66fa2BwcPCRI0cuXbrUrl07IURAQMDy5cubNGlSt25dofN80WKGDBnSs2fPkJCQ\nJ0+eCCGaN2/etWvXadOmJSUlqdXqsLAwb2/vlJSU9u3b29raLly4MCcn5/r162FhYaVurazh\nmzZtatmyZUxMTGFh4b179y5dutSoUaNSG1u0aNG+fftPPvnkwYMHmZmZM2bMqFGjRr9+/Yrt\nqNSx+rzfckEgBAAAAKqm06dPJyQkzJo1y6WI8PBwIcThw4f37dun7blx40bpVS8vr1mzZk2e\nPHnZsmVCCKVSefz48e7du0+dOtXDw8PHx2fWrFnDhw///vvvde/6uQZ26NAhMTHR39/fwsJC\nCBEQEHDx4kVpelDovaKM5Ntvv01JSZkxY4b0dNu2bc7Ozt7e3nZ2dlu2bDl48KCjo6OVldXe\nvXtPnTplb28/atQo6b6IpZ5MW+rwUaNGjR07duDAgZaWli1atHBxcVm6dGmpjUKIHTt2mJmZ\nNWzYsGHDhjdv3jx16pR0k8aiyhpbORRFT2mtejIyMtRqtaGreG6vv/56/WpmG1u3MHQhqMoO\n3L2/8Er8lClTtOfZQ1ays7MHDBjQtm3bOXPmGLoWwGi88cYbjo6OlXkqFwyodu3a5b5N6VTJ\nzZs3h4eHxw83zWimeOaQUnkvUjuZ22svM7OxsSm3EmWjoKCgsLDQ3NxcCBEdHd2uXbuMjIyS\nUU0OdN12AgAAAED5ktYUcd+k14osZbIvn2LkSaPReHp6tm/fftmyZbm5uXPnzu3cubM806Ag\nEAIAAACVqXXr1hcvXtRxmt6NGzfS09N9fHzMzMzK6uPt7V0x1cmCQqHYvXu3dEtGCwuLzp07\nr1+/3tBFGQyBEAAAAKg8TZs2Xbx4sY4OM2fOjIqKmj17tnQ/dFQEb2/vY8eOGbqKlwKLygAA\nAACATBEIAQAAAECmCIQAAADAS8TR0bFGjRpWVlaGLgSyQCAEAAAAXiITJ07ctWtXtWrVDF0I\nZOE5AmFubm5UVNTOnTtTU1OFEAUF/2ypXAAAAAAlKBQK6f54QCXQNxAuXrzY0dExICDg7bff\njo+PF0LMnj171KhRT58+rcjyAAAAAAAVRa9AuH79+o8//rhz587ffvuttrFp06ZbtmzRvWYu\nAAAAAOClpVcgXLVq1fjx43/88cfhw4drG4cNGzZ9+vQtW7ZUWG0AAACA7OzYsWPs2LFqtdrQ\nhUAW9AqE165dGzBgQMn2wMDAv//+u7xLAgAAAOTr8uXL8fHxjx8/NnQhkAVTfTqZmZnl5uaW\nbL93756ZmVl5lwQhhLjxOLvnybOGrgJVWX5hoRBCoVAYuhAAAAAYjF6BsHXr1suXL+/evXvR\nxvT09MWLF7dt27ZiCpO1bt26SSv3QE/5+fm3bt2qWbOmvb29oWsxJqamph4eHoauAgAAAAaj\nVyCcPXt2t27dmjdv/uqrrwoh1q5d++233+7duzcnJ6foMjMoL++//76hSzAySUlJY8eODQgI\neO+99wxdCwAAgC537tz57rvvCgsLy+ogTQysWbNGx60Ivby8is3WAC9Gr0DYqVOnQ4cOTZ8+\nPSwsTAgRHh4uhGjduvVXX33VoUOHii0QAAAAqEKOHj36448/PrPbL7/8ouPV3377jUCIcqFX\nIBRCdO3aNSYmJjU1NSkpSaFQ1K9f387OrkIrAwAAAKoeaW7QufNMa6dWL7aFG3tGazSaci3K\nCMTExAQHB6emppqY6Hsr9SrmyZMn7du3HzFixOTJk0vtMH369GvXrkVERDzXIhH6/jRzcnLu\n3r1bu3ZtPz+/Zs2aRURELFmy5Pr16/rvCQAAAIDE1FJlXsPpxf4TJkr9d3TlypU+ffrUqlXL\n1tY2MDDw9OnTJfu0atVK8T81a9Z85ZVXtm3bpn21oKBg4cKFXl5eNjY21tbWnp6eixYtkmLt\nwIEDFaUZMWKE7oEv4MiRI126dCmWBotWrlAoVCpVUFBQdHT0i+3iJTdjxow6depIafDOnTuD\nBw92cHCQ/lnPnj0rhFi4cGFSUtLy5cufa7P63naiQYMGmzZtEkIUFBR07dp1xIgR06dPb9Gi\nRUxMzPO/FwAAAAAV7smTJ0FBQbVq1Tpz5kxMTIybm1vPnj1LvaHFiBEjkpKSkpKSfv31165d\nuw4dOvTcuXPSS6GhoatXr/7yyy/j4+Pj4+NDQ0MXLVo0f/58IcSqVavi4uLi4uL27NkjhDh0\n6JD09KuvvtI98AUcOXIkKChIR+VJSUm//PKLg4NDcHDwP783XqXdB1LPHd28eTMsLGzBggXS\n0759+96+ffuXX36JiYmpV69enz59srOzzczM5syZ8/nnnz/XPUv0CoShoaGOjo6DBg0SQuzc\nufPMmTNr1669ceOGn5+ftiYAAAAAL5XMzMyPPvpo9erVTZs2dXd3Dw0NzczMTEhIKNnTysrK\n2dnZ2dnZ09NzwYIFCoXiypUr0kuHDx8eMmRI796969Sp4+jo+M477+zcubNNmzZCCEdHR3d3\nd3d3d2dnZyGEq6ur9NTBwUH3wKLq16+/efNm6XFoaKhCobh165b0NDAwUIobeXl5UVFRpQZC\nbeXOzs7+/v7Spg4cOCC9eu/evUGDBtWsWVOlUnXv3v3y5ctS+/nz59u2bWttbe3v73/06FGF\nQnH+/Hm1Wq1QKMLDwxs0aDBq1Cgdwzdu3Ojh4WFhYeHo6Dhx4sS8vLyyGu/duxcSElKvXj2V\nStWtW7eLFy8KIUruqNSxRX377bevvPKKn5+fECItLc3NzW3t2rW+vr7u7u5ffvnlgwcPLl26\nJITo27evpaVl0QneZ9IrEEZFRc2YMaNBgwZCiB9//NHHx2fs2LENGzacNGmSNDsJAAAA4GVj\nb28/bdo0GxsbIURaWtry5cubNWvWrFkzHUPy8/PDwsJq1KihTV8+Pj67d+/+448/tH1effXV\nHj16PHPveg4MDg4+efKk9PjYsWNeXl7S07y8vN9++026zUFUVJSDg0Pjxo2fuVOlUqlUKgsK\nCqSngwcPFkIkJCTcvn27devWQUFBOTk5T5486dmzp4eHR0pKyvbt2z/55BMhhJmZmZmZmUKh\nCAsL27Nnz+rVq8sanpCQMGrUqFWrVmVlZZ09e/bcuXPLli0rtVEI0bdv38zMzPPnz9+6dcvX\n1zcwMPDhw4fFdlTW2KJ++eWX4OBg6XGtWrV27drVtGlT6WlycrKJiYmTk5MQQqFQdOvW7fDh\nw8/8QWnptahMenp63bp1hRCFhYWRkZFjxoyR2u3t7VNTU/XfGQAAACBz+fn5QojHiafV2fdf\nbAuF6pwCM33XhhRCPH361NLSMj8/v1OnTpGRkaXezWLt2rUbN24UQuTk5NSqVWvz5s1SwBBC\nLFu2bOLEia1bt3Z1de3QoUNAQEC/fv2kOUDd9BwYHBw8c+ZMIURWVtbly5cXLlx44sSJoUOH\nnjlzxsbGpmXLlqLs80WLycrKmjt3bk5OTp8+fYQQly9fjoyMTElJqVWrlhBi3rx5q1ev3r9/\nv4ODw71792bPnm1tbd2kSZPJkycPGzZM2oKJicnrr7/u6+urY7irq6tGo7Gzs1Mqla6urtHR\n0UqlMjo6umTj+fPnf/vtt0uXLtWpU0cIMX/+/LCwsIiIiJEjRxbd0ZUrV0qOLfbWLl++/Nln\nn5V8y2lpaaNHj54yZYo0SSuE8PHxWbNmzTN/Vlp6fZLq1KmTkJDQpUuXY8eOpaWl9ezZU2pP\nSkpSqVT67wwAAACQuRs3bgghHl767p9sJLPgOdaVUSqVsbGxKSkpK1as6NKly2+//VazZs1i\nfQYNGjR79mwhRE5Ozrlz50aOHLlgwYJx48YJIezs7LZv375y5cpTp06dPn16+fLlU6ZMWbdu\n3dChQ3XvV8+BQUFB77zzTkpKSmxsrJ+fX9euXaVlUY4fPx4cHCytInP48OFp06aVuhdtlBVC\nZGdne3p67t27193dXQgRFxcnhHB0dCzaPyEhIS8vT6lU1q9fX2opdhardh6yrOFvvvnme++9\n16ZNG2nOMCQkpFmzZm3atCnZeOPGDYVCoZ3Ks7S0dHJykj4ARXdU6tiiO83MzMzPz69du3ax\n937t2rXXXnstKCho6dKl2kaVSvVck3Z6BcLu3bt/9tlncXFxO3bscHNzCwgIEELcv39/xYoV\n3IcQAAAA0F/jxo2jo6Pt/UZY2us6dVOH2ye/sLV8jkAohPDw8PDw8AgICHB0dNy6deukSZOK\ndbC1tZVClBDCx8fn/v37s2bNkgKhpHbt2v379+/fv//ixYs//PDDCRMmhISEmJo+O008c6BK\npfLz8zt16tTvv/8eGBjo4eGRnp5+586d48ePS9fXpaWlXbhwoVu3bqVuXxtlMzMzg4KCJk6c\n2KtXL+kl6e4LOTk5FhYWRYds2rSp6I0Zit2kQTuDWtZwIcSqVatmzJhx4MCB/fv3f/HFF1u3\nbn3rrbdKNkpptug9QjQajXZ3RXdU6gaL7bRYnZGRkYMGDZozZ06xf83nuueE0PMawvnz57u5\nuX355Zc5OTm7d++WZjCnTJmSmJg4a9as59ofAAAAIGdSFrKq62vbKOjF/jMxrV7ylMJSRUZG\nuru7Z2dnS0+VSqVCodDnHoYajUa6DC8xMTEkJES7youkU6dO2dnZupeyfK6B3bt3P3Xq1LFj\nxwIDA4UQHTp0OHTo0NmzZ7t37y69C09Pz7JOUpWirLu7e8uWLb/++utp06Zpl8ORpuBiY2O1\nnaUFderVq1dQUJCcnCw1lrUqSlnDCwoKHjx44OLiMn78+P3790+cOPGbb74ptbFx48Yajeba\ntWvS8KysrOTk5JJXQpY6tmiHGjVqmJubP3jwQNsSFRX11ltvlZrtU1NT7e3tS31HpdIrENat\nW/fMmTMZGRl37tzx9/eXGqdNm3b16lUvLy/9dwYAAACg0vj7+2dnZ48YMeLKlSsJCQkffvhh\nVlaWtKzLf/7znxUrVmh7Zmdn3759+/bt2/Hx8Tt37ly2bJl0iwEnJyfpTob79u1LTEy8efPm\nnj17pk2bFhwcbGdnp2PXzzUwODj4yJEjly5dateunRAiICBg+fLlTZo0kdYxOXz4sD4XEAoh\nhgwZ0rNnz5CQkCdPngghmjdv3rVr12nTpiUlJanV6rCwMG9v75SUlPbt29va2i5cuDAnJ+f6\n9ethYWGlbq2s4Zs2bWrZsmVMTExhYeG9e/cuXbrUqFGjUhtbtGjRvn37Tz755MGDB5mZmTNm\nzKhRo0a/fv2K7ajUscX6eHp6/vnnn9Lj3Nzc4cOHf/DBB15eXrf/Rxv7L1686Onpqc+PS6Lv\njemFEFZWVjk5Oen/4+7uXr169fT0dP23AAAAAKDS1KxZ8/Dhw7m5uQEBAX5+fr///vuBAwek\nGarDhw/v27dP23Pjxo0uLi4uLi5eXl6zZs2aPHmytNClUqk8fvx49+7dp06d6uHh4ePjM2vW\nrOHDh3///fe6d/1cAzt06JCYmOjv7y+dnBkQEHDx4kVpelDovaKM5Ntvv01JSZkxY4b0dNu2\nbc7Ozt7e3nZ2dlu2bDl48KCjo6OVldXevXtPnTplb28/atQo6YzTYre81zF81KhRY8eOHThw\noKWlZYsWLVxcXJYuXVpqoxBix44dZmZmDRs2bNiw4c2bN0+dOlWjRo1ieylrbFHdu3fXrh16\n+vTphISEWbNmuRQRHh4uhNBoNJGRkdLSrHrSa8o4Li5uzJgxZ86cKfW2ifpswVAyMjIq7Z6S\nMKCkpKSxY8e+9tpr7733nqFrAYxDdnb2gAED2rZtO2fOHEPXAhiNN954w9HRsdipXKiqSi7g\n8c9Jp0pu3rw5PDzcrdfyGvU7vth2rm7pXdOi8Lvv/m9ZGumuEnguBQUFhYWF5ubmQojo6Oh2\n7dplZGSUjGovj5s3bzZt2jQ6Olq6FWFZ9u7dO2bMmL///lv/T4Vei8qMGzfu/PnzAwcOrFev\nnj5XjgIAAADQIT8jKffB1Rcbq3mqFuL5FpVBURqNxtPTs3379suWLcvNzZ07d27nzp1f5jQo\nhHBzc5swYUJoaOhPP/1UVh+1Wj137tzPPvvsuf5GoFe6O3v27K5du7R3mwAAAADwYqT1YO78\nWvycwOeisHn2bQBRFoVCsXv3bunefRYWFp07d16/fr2hi3q2L7/8sn379l9//fWUKVNK7RAa\nGurk5PT+++8/12b1CoTW1tYlr2sEAAAA8LyCg4Nzc3MLCwvL6nDq1Knbt2/379+/evXqZfUp\ndp86PC9vb+9jx44ZuornU61atZiYGB0dvvrqqxfYrF6BcPjw4eHh4V988cUL7AAAAACAloOD\nw5gxY3R0SEpKun379pAhQ2rVqlVpVUG29AqECxYsGDBgQLt27Tp27KhSqYq9+sknn1RAYQAA\nAACAiqVXIFy+fHlERIQQIjo6uuSrBEIAAAAAMEZ6BcJly5b17Nnzk08+YZVRAAAAoEK1bNny\n8ePHL/mil6gy9Ep3Dx8+XLp0qYeHR0VXAwAAAMhc//79+/fvb+gqIBcm+nTy9vZ++PBhRZcC\nAAAAAKhMes0Qrlq1asaMGUuXLvX396/oggAAAIAq6bluFw5UDr0C4bRp0xITE1u1amVtbV1y\nldGbN2+Wf10AAAAAgAqmVyA0MTFxd3dv3LhxRVcDAAAAAKg0egXCEydOVHQdAAAAAIBK9uxF\nZfLz81955ZX9+/dXQjUAAAAAgErz7EBobm5+586d+Pj4SqgGAAAAAFBp9LrtxJo1a9avX79n\nz56CgoKKLggAAAAAUDn0uoZw8eLFSqXyjTfeMDU1tbe3Nzc3L/oqq4wCAAAAgDHSKxAWFBTY\n2dl169atoqsBAAAAAFQavQLhr7/+WtF1AAAAAAAqmV7XEAIAAAAAqh4CIQAAAADIFIEQAAAA\nAGSKQAgAAAAAMkUgBAAAAACZIhACAAAAgEwRCAEAAABApgiEAAAAACBTBEIAAAAAkCkCIQAA\nAADIFIEQAAAAAGSKQAgAAAAAMkUgBAAAAACZIhACAAAAgEwRCAEAAABApgiEAAAAACBTBEIA\nkJ2YmJgZM2aYmppeunRp0aJFqamphq4IAAAYhqmhCwAAVKqLFy+GhoZKj7Oyso4fP37jxo2V\nK1dWr17dsIUBAIDKxwwhAMjLmjVrirUkJSXt37/fIMUAAADDIhACgIxoNJqbN2+WbE9ISKj0\nWgAAgOERCAFARhQKRamnhlpYWFR+MQAAwOAIhAAgLx07dtSzEQAAVHkEQgCQl3fffbdBgwZF\nWwYNGuTn52eoegAAgAGxyigAyIuVldXKlStPnDiRmJhYvXp1X19fDw8PQxcFAAAMg0AIALJj\namoaFBSkUqny8/MzMzMNXQ4AADAYThkFAAAAAJkiEAIAADxDYmLivHnzcnNzExMTly5dmpqa\nauiKAKB8cMooAACALikpKR988EFOTo4QoqCg4PDhwxcvXly9erW1tbWhSwOAf4oZQgAAAF3W\nr18vpUGte/fu7dy501D1AEA5IhACAADoEhcXV7Lx+vXrlV8JAJQ7AiEAAIAu5ubmJRvNzMwq\nvxIAKHcEQgAAAF3atm1bsrFdu3aVXwkAlDsCIQAAgC5Dhgxp1KiaTdK1AAAgAElEQVRR0ZY2\nbdr07NnTUPUAQDlilVEAAABdqlWrtmLFil9++SU+Pt7U1NTT07NTp04KhcLQdQFAOSAQAgAA\nPIOpqWmvXr1UKlVhYeGjR48MXQ4AlBtOGQUAAAAAmSIQAgAAAIBMccooAMhOenr6d999d/Pm\nTUtLy5YtW/bo0cPEhL8PAgAgRwRCAJCXe/fuTZo06fHjx9LTqKios2fPzp49mxUyAACQIf4k\nDADysnr1am0alERHRx8/ftxA5QAAAEMiEAKAvMTGxpZsPH/+fOVXAgAADK6KnzJqZmZmalrF\n3yOEENWqVRNCKBQKCwsLQ9cCvNQ0Gk2p7SYmJhw+gD74fw2AKqbqh6Wyvv2gKtH+K/PPDTyT\nt7d3TExMscYWLVpw+AB64mABUJVU8UCoVqvVarWhq0CFy8/PF0JoNJq8vDxD1wK87CZMmDB5\n8uTc3FxtS4sWLQIDAzl8gGeysrLi/zXyYW1tbegSgMpQxQMhAKAYZ2fnb7/99r///W9CQoKl\npaW/v3///v257QQAAPJEIAQA2alTp85HH32kUqny8/MzMzMNXQ4AADAY/iQMAAAAADLFDCEA\nAMCzpaenX79+3cTEpG7dulZWVoYuBwDKB4EQAADgGXbs2LFt2zZppTpra+tx48YFBwcbuigA\nKAecMgoAAKDLiRMnNm7cqF23PCsr6+uvv75y5YphqwKAckEgBAAA0OXHH38s1qJWq/ft22eQ\nYgCgfBEIAQAAdHnw4IGejQBgdAiEAAAAutSuXbtkY506dSq/EgAodwRCAAAAXV599dViLQqF\nomfPngYpBgDKF4EQAABAlz///LNYi0ajiY2NNUgxAFC+CIQAAAC6XL58uWTjpUuXKr8SACh3\nBEIAAABdlEqlno0AYHQIhAAAALq0bNlSz0YAMDoEQgAAAF2GDx9et27doi0eHh59+/Y1VD0A\nUI5MDV0AAADAS83a2vqbb77Zu3fvX3/9ZWZm5uXl1atXL1NTvkQBqAr4XQYAAPAMFhYWISEh\nKpWqsLDw0aNHhi4HAMoNp4wCAAAAgEwRCAEAAABApgiEAAAAACBTBEIAAAAAkCkWlQEA2VGr\n1ZGRkbdv365evbqvr6+Xl5ehKwIAAIZBIAQAecnKypo6deqtW7ekp1u3bh04cOCYMWMMWxUA\nADAIThkFAHlZs2aNNg1Kdu/eHRMTY6h6AACAAREIAUBeTp8+XbLx119/rfxKAACAwREIAUBG\nNBpNXl5eyfYnT55UfjEAAMDgCIQAICMKhaJhw4Yl2xs1alT5xQAAAIMjEAKAvIwbN65YS/36\n9Xv37m2QYgAAgGERCAFAXry8vBYtWtS8eXMzM7MaNWoEBwd/8cUX1apVM3RdAADAALjtBADI\njq+vr5+fn52dXUFBQWZmpqHLAQAABsMMIQDIlIkJ/wsAAEDu+DYAAAAAADJFIAQAAAAAmSIQ\nAgAAAIBMEQgBAAAAQKYIhAAAAAAgUwRCAAAAAJApAiEAAAAAyBSBEAAAAABkikAIAAAAADJF\nIAQAAAAAmSIQAgAAAIBMEQgBAAAAQKYIhAAAAAAgUwRCAAAAAJApAiEAAAAAyBSBEAAAAABk\nikAIAAAAADJFIAQAAAAAmSIQAgAAAIBMEQgBAAAAQKYIhAAAAAAgUwRCAAAAAJApAiEAAAAA\nyBSBEAAAAABkikAIAAAAADJFIAQAAAAAmSIQAgAAAIBMEQgBAAAAQKYIhAAAAAAgUwRCAAAA\nAJApAiEAAAAAyBSBEAAAAABkikAIAAAAADJFIAQAAAAAmSIQAgAAAIBMEQgBAAAAQKYIhAAA\nAAAgU6aGLgAoB3Z2dpMnT65fv76hCwEAAACMCYEQVYGtre3w4cPz8vKysrIMXQsAAABgNDhl\nFAAAAABkikAIAAAAADJFIAQAAAAAmSIQAgAAAIBMEQgBAAAAQKYIhAAAAAAgUwRCAAAAAJAp\nAiEAAAAAyBSBEAAAAABkikAIAAAAADJFIAQAAAAAmSIQAgAAAIBMEQgBAAAAQKYIhAAAAAAg\nUwRCAAAAAJApAiEAAAAAyBSBEAAAAABkikAIAAAAADJFIAQAAAAAmSIQAgAAAIBMEQgBAAAA\nQKYIhAAAAAAgUwRCAAAAAJApAiEAAAAAyBSBEAAAAABkikAIAAAAADJFIAQAAAAAmSIQAgAA\nAIBMEQgBAAAAQKYIhAAAAAAgUwRCAAAAAJApAiEAAAAAyBSBEAAAAABkikAIAAAAADJFIAQA\nAAAAmSIQAgAAAIBMEQgBAAAAQKYIhAAAAAAgUwRCAAAAAJApAiEAAAAAyBSBEAAAAABkikAI\nAAAAADJFIAQAAAAAmSIQAgAAAIBMEQgBAAAAQKYIhAAAAAAgUwRCAAAAAJApAiEAAAAAyJSp\noQsA/im1Wh0ZGZmSkmJjY+Pv7+/k5GToigAAAADjULGBMCsra+3atefOnSsoKPDy8powYYKD\ng4OefXSMTU5OXrZsWXx8/N69eyu0frz80tLSpk+fnpycLD01MzObOHFiz549DVsVAAAAYBQq\n9pTR5cuXJyYmzp8/f9myZUqlct68eYWFhXr2Kav91KlT//rXv5ydnSu0chiLFStWaNOgEEKt\nVoeFhSUmJhqwJAAAAMBYVGAgTE1NPXv27JQpU9zd3Z2dnT/44IPk5OQLFy7o00fHWLVavWTJ\nkrZt21Zc5TAWubm5586dK9aYn59/+vRpg9QDAAAAGJcKDIRxcXHm5uYNGjSQnlpbW7u4uMTF\nxenTR8fYrl272tvbV1zZMCK5ubkl55yFEDk5OZVfDAAAAGB0KvAawszMTBsbG4VCoW2xtbXN\nyMjQp4+tre0zx5bq+vXru3fv1j598803XVxc/tHbwEvM0tKyZs2a6enpxdqbNWtmbW1tkJIA\n42JqasrBAuhPoVCYmJhw1ACoSip2UZmiiU4IodFo9O+jz9iSkpOTf/jhB+3ToKCgxo0b61kt\njNH7778/d+7coi3NmjXr1auXqSkr6ALPZmJiUr16dUNXARgThULBUQOgKqnAL801a9bMzMzU\naDTaaJeRkWFnZ6dPH33GlqpVq1ZbtmzRPlWpVCWnj1CVZGdnF2spKChIT08nEAK6KRQKW1tb\ntVpd8iACUBZbW9vCwsLHjx8buhBUhpo1axq6BKAyVOCX5iZNmqjV6vj4eGmOLiMjIykpqVmz\nZvr0cXJyeubYUtnY2Hh4eGifZmRkqNXqcn5jeGkUFhauW7euWGN8fHxkZGS3bt0MUhJgLKQ/\nt2k0moKCAkPXAhgZjhoAVUkFLipjZ2fXoUOHlStXxsfHJyUl/fvf/3Z3d/f09BRCHD58eN++\nfTr66Bj76NGj1NRU6Y9zqampqampeXl5Ffcu8DJ79OhRqVeW3rp1q/KLAQAAAIyOQs9r815M\nTk7OunXrzpw5U1hY6OfnN378eOm0z8WLF2dmZs6fP19Hn7Lax4wZc//+/aJ7GTNmzOuvv15q\nAcwQVm25ubkDBgwoudDoiBEj3n77bYOUBBgLhUKhUqny8/MzMzMNXQtgNFQqVWFh4aNHjwxd\nCCpD7dq1DV0CUBkqNhAaHIGwypszZ050dHTRFnNz89WrV7O6LKAbgRB4AQRCWSEQQiYq8JRR\noBK8//77zs7O2qdmZmYTJ04kDQIAAAD6YIYQRk+tVkdFRd29e9fa2trf39/JycnQFQFGgBlC\n4Lk8fvx49+7dcXFxSqXSy8urf//+5ubmhi4KFYsZQsgEgRBVgVKptLOzy8vLy8rKMnQtgHEg\nEAL6y8zMnDRpUtElDJo0abJ06VIzMzMDVoWKRiCETHDKKAAAgC7h4eHFFrS7fv36Dz/8YKh6\nAKAcEQgBAAB0uXDhgp6NAGB0CIQAAAC6lHp9TdW+6AaAfBAIAQAAdPH29i7Z2KJFi8qvBADK\nHYEQAABAl1GjRtWqVatoS4MGDQYMGGCoegCgHJkaugAAAICXWs2aNcPCwnbs2PHXX3+Zmpr6\n+PgMHDiQJUYBVA0EQgAAgGewtbUdN26cSqUqLCx89OiRocsBgHLDKaMAAAAAIFMEQgAAAACQ\nKQIhAAAAAMgUgRAAAAAAZIpACAAAAAAyRSAEAAAAAJkiEAIAAACATBEIAQAAAECmCIQAAAAA\nIFMEQgAAAACQKQIhAAAAAMgUgRAAAAAAZIpACAAAAAAyRSAEAAAAAJkiEAIAAACATBEIAQAA\nAECmCIQAAAAAIFMEQgAAAACQKQIhAAAAAMgUgRAAAAAAZIpACAAAAAAyRSAEAAAAAJkiEAIA\nAACATBEIAQAAAECmCIQAAAAAIFMEQgAAAACQKQIhAAAAAMgUgRAAAAAAZIpACAAAAAAyRSAE\nAAAAAJkiEAIAAACATBEIAQAAAECmCIQAAAAAIFOmhi4A+KfUavWxY8fu3r1rbW3dqlWrevXq\nGboiAAAAwDgQCGHcHj16NH369Nu3b0tPzczM3nvvvR49ehi2KgAAAMAocMoojNuKFSu0aVAI\noVarv/nmm6SkJAOWBAAAABgLAiGMWG5u7tmzZ4s15ufn//rrrwapBwAAADAuBEIYsZycnMLC\nwlLbK78YAAAAwOgQCGHE7OzsbG1tS7bXr1+/8osBAAAAjA6BEEbMxMRk9OjRxRqbNGkSGBho\nkHoAAAAA48IqozBu3bt312g0//3vf+/du1etWrWOHTuOHTvW1JQPNgAAAPBsCo1GY+gaKlBG\nRoZarTZ0FahwSqXS3NxcoVBw9SCgJ4VCoVKp8vPzMzMzDV0LYDRUKlVhYeGjR48MXQgqQ+3a\ntQ1dAlAZOGUUVYSVlZWJCZ9nAAAA4DnwBRoAAAAAZIpACAAAAAAyxdobqAr+/vvvs2fPWllZ\nubm5Va9e3dDlAAAAAMaBQAjj9uTJk6+++urXX3+VntauXXv69OktWrQwbFUAAACAUeCUURi3\ndevWadOgECI1NXXBggWs/wYAAADog0AII6ZWqw8dOlSsMTMz88SJEwapBwAAADAuBEIYsbLu\nM/nw4cPKLwYAAAAwOgRCGDFbW9tSl5CpU6dO5RcDAAAAGB0CIYyYmZlZv379ijU6ODh07tzZ\nEOUAAAAARoZVRmHchg4dmpOTExERIT1t2LDhtGnTrK2tDVsVAAAAYBQUGo3G0DVUoLKuMUMV\nk5WVlZaWZmlpWatWLRMT5r2BZ1MoFCqVKj8/PzMz09C1AEZDpVIVFhaylrVM1K5d29AlAJWB\nGUJUBba2tm5ubnl5eVlZWYauBQAAADAazKUAAAAAgEwRCAEAAABApgiEAAAAACBTBEIAAAAA\nkCkCIQAAAADIFIEQAAAAAGSKQAgAAAAAMkUgBAAAAACZIhACAAAAgEwRCAEAAABApgiEAAAA\nACBTBEIAAAAAkCkCIQAAAADIFIEQAAAAAGSKQAgAAAAAMkUgBAAAAACZIhACAAAAgEwRCAEA\nAABApgiEAAAAACBTBEIAAAAAkCkCIQAAAADIFIEQAAAAAGSKQAgAAAAAMkUgBAAAAACZUmg0\nGkPXAPxTDx48WLduna+vb69evQxdC2Ac8vLy/v3vfzds2PDtt982dC2A0Vi8eLGtre27775r\n6EIAoNwwQ4iqIDMz84cffvjjjz8MXQhgNNRq9Q8//HD69GlDFwIYk3379kVGRhq6CgAoTwRC\nAAAAAJApAiEAAAAAyBSBEAAAAABkikVlAAAAAECmmCEEAAAAAJkiEAIAAACATBEIAUAu4uPj\n33nnHa4UALQ4KNRq9Ycffrh///6yOoSHh8+fP1/OPyKgyjM1dAGASE5OXrZsWXx8/N69e0vt\n8NFHH8XHx0uPLS0t69Wr9/rrr3fu3Flqefr06Q8//HDixIn79+8LIezt7bt06TJgwACFQrFo\n0aJSb7PWtWvXDz74QMfAinibMF5paWnh4eGxsbFqtbpBgwYjR45s0qRJsT5G8Sm9cOGCt7d3\nsbFFKxdC2NjYNGzYcMiQIU2bNn2BXUAmkpKSwsPDr127VlhY2KBBg+HDhzdr1qxYHw4Ko7Bx\n48aaNWv26dNHlPG7btiwYR999FFERETfvn0NXSyACkEghIGdOnVq/fr1fn5+Rf/vW1K3bt0G\nDx4shMjJyTl69OiyZcucnJwaN24shNiyZcvx48cnTZrk7u6u0WguXrwYFhamVqtDQkLGjRs3\nfPhwIcStW7cWLlw4d+5cR0dHIYSlpaXugZXxzmE8Pv/882rVqs2dO9fCwmLr1q3z589ft25d\n9erVi3V7+T+lsbGx7du3L9murVwIkZ6evnfv3pkzZ65cubJOnTovsBetp0+fKpXKf7KFl21H\nkKjV6s8++8zX13fx4sUmJiY7d+6cM2dOeHi4hYVFsZ4cFMW8bAfF/fv3Dx48uGTJEulpWb/r\nQkJCVq5c2b1795L/xACqAAIhDEytVi9ZsuTGjRvHjx/X0a169eq1a9eWHg8dOnTPnj1JSUnS\nt4rY2NjOnTu3atVKejUwMNDGxkZ6bGdnJz3Izs4WQtjb29etW1e7TR0DAa3Hjx/XqVNnyJAh\nTk5OQogRI0aMHj06MTGx5CShAT+lo0ePHjx4cNeuXYUQW7Zs2bVr1/r16x0cHIQQn376qZ+f\n31tvvZWfn3/16tUJEyaUHF608tq1a3/44YchISG///577969hRDp6elr1679448/lEplo0aN\nxowZ4+rqKoRISEj45ptvEhMTnZycRo4c+dlnny1fvrx+/fr9+/efMmXKjh07mjdv/tFHH5U1\nPDIy8vvvv79//76lpWW7du1Gjx5tbm5eamN6evq6desuXbpUUFDQoEGDMWPGuLm5PX36tNiO\nSh37fP/Y0E9OTk6/fv169OghxYM333zz6NGjKSkpDRo0KNaTg+IlPygOHjzYuHHjhg0bCp2/\n69q0abN27drjx4/37Nnz2Z8PAMaGawhhYF27drW3t9e/f0FBwcGDBy0tLVu0aCG1uLm5nT59\n+saNG9o+LVu2bNmy5TM39cIDISs2NjYzZsyQviEJIR4+fKhQKGrVqqVjSOV/Sn19fS9fviw9\n/vPPP+vXry89zc/Pv379utT/6tWrtra29erVe+ZOTUxMTExMnj59Kj1dunSpEGLdunXh4eFN\nmjSZOXPmkydP1Gr1nDlzXFxcNm/ePG3atE2bNgkhlEqlUqlUKBQHDx7817/+NX78+LKGp6Sk\nfP311+PGjfvuu++WLl0aFxcXERFRaqMQ4vPPP8/NzV2xYsV//vOfhg0bfvrpp48fPy62o7LG\noiLY2tr2799fSoOPHz+OiIhwdnZ2dnbWMYSD4uU8KM6fP+/r6ys91vG7TqFQ+Pj4xMbGPvMH\nBcAYMUMI4/Dzzz9HRkYKIZ48eWJtbf3hhx+qVCrppTFjxoSFhU2dOtXe3t7Dw8PT07Nt27a2\ntrbP3OYLD4RsPX78eOXKla+99pp26qAoA35KfX19t23bJoTIy8tLTEwcOnTopUuXunTp8tdf\nf1lYWDRq1EgIERsbq/0urkNeXt727dufPHnyyiuvCCESExMvXLiwefNmaRJm8ODBBw4cOHfu\nnK2tbXp6ekhISPXq1Z2cnPr06bNs2TJpCwqFonXr1tKcQ1nD7e3tNRqNtbW1iYmJvb39kiVL\nTExM/vrrr5KNCQkJ169fX7VqVc2aNaUt/PTTT7/99ltQUFDRHSUlJZUc+8w3i3+isLBw4MCB\nBQUFnp6en3/+uZmZWck+HBTSFl7agyIxMXHQoEEl33LJ33Vubm6HDh165s8KgDEiEMI4BAQE\nSNeHPHnyJC4ubsWKFUOHDu3Ro4cQwtraevr06ePGjbt8+fK1a9ciIiLWrl07adKkLl266N7m\nCw+EPN2+fXv+/Pm+vr6jR48utYMBP6W+vr5Llix59OjR33//3bBhQx8fH2kq4M8///T19ZUW\nzIiNje3fv3+pe9F+axdC5OXlubq6hoaGSifp3blzRwgxbNiwov1TUlLy8/Olb5lSS7ETaLVT\nLmUN79ChQ+/evadNm9a4cWNfX99OnTo5Ozs3adKkZOPdu3cVCoV21qJatWoqlSolJaXYjkod\nq/tni3/IxMRkxYoV6enpERERoaGhS5YssbKyKtaHg0LrJTwocnJyCgoKatSoUey9l/q7rkaN\nGpmZmaX+rAAYOwIhjIOVlZX2GhI3N7eMjIxt27ZJ3yokNWrUaNeuXbt27UaOHLl+/fqwsLBO\nnTrpc0n9Cw+ErFy4cOGrr7565513pCuISmXAT6mNjU2jRo2uXLkSFxfn5eXl4uKSnZ2dlpb2\n559/BgcHCyEeP378999/lzUZov3WnpOTM3PmzF69emkv0JK+N+/evbvYpUdHjx4tujBjsUUa\ntZNFZQ0XQowbN27AgAHnzp07d+7crl27pk6d2rFjx5KNJZeO1Gg02saiOyp1g8/4yeKfcXFx\ncXFxad68+bBhw44fP17y6OCg0DKWg0Kf33UAqhjOqIFR0mg0hYWFQogHDx4sXrxYWnxcy9PT\nMy8vLzc3V8cWXnggZOjKlStfffXV1KlTn+sbUiV/SqUrpv78808vLy8hhIeHxx9//BEXF+fn\n5yeEuHjxoqura1nn40nf2uvWrduoUaN33313w4YNSUlJ0kvSbENCQoK2szQRUatWradPnz58\n+FBqvH79eqlbLmv406dPMzIyateu3bNnz1mzZvXq1eunn34qtbFevXoajeb27dvS8Ly8vLS0\ntKJLjEhKHVvWDxb/0IULF9599928vDzpqYmJiUKh0Oc+dRwUOoZX/kFhaWlpampadN5Px++6\nzMzMknOJAKoGAiEM7NGjR6mpqY8fPxZCpKampqamSl8yDh8+vG/fPm23vLw86dW7d++eOnXq\nxx9/lP7MqVKpkpKS5s+ff/bs2QcPHty/f//MmTPh4eG+vr7W1tY69vvCAyE3+fn5y5cvf/31\n111dXVP/5yX8lPr5+V24cOHWrVvS7eA8PT0jIiLq1asnLdgYGxurXTpCt86dO/v7+y9evFit\nVgshXFxcfHx8NmzYkJqa+vTp04MHD06ePPnRo0fNmjWztLTctWvXkydPkpOTDx48WOrWyhp+\n9OjRDz/8MD4+XqPRpKenJyYmOjo6ltrYoEGDZs2abdq0KSMjIycnZ+PGjRYWFm3bti22o1LH\n6vN+8QLc3d2fPHmyYsWKpKSklJSU9evX5+XlScu0cFAY10Hh6up68+ZN6bGO33VCiJs3b0pL\noQKoejhlFAY2ffp07d96R40aJYQYM2bM66+/Hhsbm5mZ+dprr0kvRUZGSpdzmJmZOTg49OnT\nZ8CAAUIIExOThQsXfvfddxs2bHj48KGJiYmDg0PXrl2fef/cFx4Iubl69WpKSsq2bdukBSok\n48aN692790v1KfXw8Hjw4IG7u7t0Hlrz5s03bNigvT4qNjZWWt5QHxMnTpw0adLGjRvHjh0r\nhJg6deq6desmTZpUWFjo5uY2Z84c6ft0aGjo2rVrhwwZ0rBhw5CQkFmzZpW6jkupw4OCgh4+\nfLho0aJHjx5ZWVn5+/uPHj3a0tKyZKMQ4uOPP16zZs3YsWPNzMyaNm26aNEi6X50RZW6QT3f\nL56XlZXVvHnzNm3a9Mknnzx9+rR+/fqzZs2SJr44KIzroPDz84uNjZVOjtXxu06632Opy88A\nqAL0OscDAIBinj59qtFoTE1NhRB//fXX9OnTd+zYUfJbKSAfRndQ3L9/f/z48UuWLJEWJi1L\ndHT0ypUr169fz43pgSqJU0YBAM9No9FMmjRp9erV2dnZjx492r59u7e398v8xReoaMZ4UDg4\nOPTs2XPLli06+jx9+nTHjh2DBg0iDQJVFTOEAIAXcevWrbVr18bFxZmbm3t7e48ZM0Z7izlA\nnozxoFCr1R9//HHXrl21J/oWs3HjxsTExJkzZ5Zc3RRA1UAgBAAAAACZ4pRRAAAAAJApAiEA\nAAAAyBSBEAAAAABkikAIAAAAADJFIAQA4zBnzhyFQuHg4KBWq0u+OnbsWIVC0bFjxxfb+Ntv\nv21tba1Pz44dOzZr1uzF9gIAAF42BEIAMBomJiZpaWkHDx4s1p6Xl7dr1y5zc3ODVAUAAIwX\ngRAAjIaJiUnbtm03btxYrD0iIiI7O7tly5aGKAoAABgxAiEAGI2CgoJ+/fodOHDg4cOHRds3\nb97cpUuXYjOEBw8e7NSpk42NjYWFhZeX17///W/tjWc1Gs28efNcXFyqV6/u7e29e/fuYrec\n/vXXX4ODg2vUqGFhYeHn57dhw4ZS67l79+7YsWPr169fvXp1R0fHAQMGXLt2rVzfMQAAqFgE\nQgAwJv379y8oKNi+fbu25f79+4cOHXr77bfz8/O1jXv37u3du7cQYuPGjT/++GP79u2nTp06\nffp06dXFixfPnj07ICBg3759oaGhs2fPPn/+vHbs8ePHu3Tpolart27dGhER0bZt29GjRy9Z\nsqRkMW+88cb+/ftnzZr1008/LVmy5Pr164GBgTk5ORX15gEAQHlTaP9gDAB4mc2ZM2fu3Lm5\nubmvvfbao0ePfv/9d6l9xYoVn3766b1794KDg01NTaOiooQQHh4e2dnZcXFx1apVk7pJ4e3u\n3bu1atVydna2s7P7888/pYnBO3fuuLm5mZubZ2VlCSFatWqVlpZ29epV7di+ffueOHHi7t27\nFhYWHTt2TE1NvXbtWmZmpq2t7YwZMxYtWiR1+/vvv3fs2DF8+PB69epV8g8HAAC8GGYIAcDI\njBgxIiYm5vLly9LTzZs39+vXz8bGRtvhzp07165d69mzpzbRCSF69+6tVqujo6OTkpLu3LnT\ntWtX7Wmi9erVa9WqlfQ4NTU1JiamR48eGo0m73969eqVkZERExNTtAxLS8vatWvv2LEjMjKy\nsLBQCNGgQYNPP/2UNAgAgBEhEAKAkenfv7+NjY20tMyVK1f++OOPYcOGFe2QnJwshHB2di7a\nKOW0u3fvpqSkCCEcHBxKviqESEpKEkKEhYVZFDF+/HjtZu0SepYAAALiSURBVLVMTU1/+ukn\nhUIRFBRkb28/aNCg7du3P336tJzfLQAAqEimhi4AAPB8LC0t33zzza1bty5atGjz5s1169YN\nDg4u2kGa+it6SaEQQrpAQKEo/UoBbZCTxo4cOfLdd98t1sfd3b1YyyuvvBIfH3/y5Mmff/75\n4MGD33333apVq44ePVp0ZhIAALzMCIQAYHyGDx++YcOGqKioHTt2vPPOO0qlsuirLi4u4n9z\nfVq3b98WQjg7O9vb2wsh7t27V/TVmzdvSg9cXV2FEIWFhW3bttWnEqVS2aVLly5dunz55Zdr\n1qwZP378zp07i81YAgCAlxanjAKA8QkICGjYsOHixYtv3bpVMn3VqVPH29t7//79ubm52sa9\ne/daWlq2a9fOzc2tdu3a2gv/hBDXrl27ePGi9LhWrVqtW7feu3dvenq6duzmzZs/++yzgoKC\nonv5/fff33777fv372tbpInKoi0AAOAlRyAEAOOjUCiGDRt24MCBFi1a+Pj4lOzwxRdfPHr0\nKDg4+Pvvv9+3b98777xz8ODBmTNn1qhRw8TEZMKECVevXn3jjTd27979zTff9OjRw9/fXzv2\nq6++ysnJCQgI2LJlyy+//DJz5swxY8bcuXPH1PT/d1KJk5PTzz//HBwcvGHDhsOHD2/fvn3I\nkCHVqlV77bXXKvz9AwCAcsIpowBglIYNGzZ37tyyTs7s3bv3Tz/9tGDBguHDhxcUFDRv3nzD\nhg0jR46UXp09e7Zard64cePBgwebNm26fPny48ePx8bGSq8GBgYePXp03rx57733nlqtbtCg\nwbx587T3MNSqW7fuyZMn582bFxoampaWplKpWrduffLkyaZNm1bcuwYAAOWL+xACAAAAgExx\nyigAAADw/9qvAwEAAAAAQf7Wg1wWwZQQAgAATAkhAADAlBACAABMCSEAAMCUEAIAAEwJIQAA\nwJQQAgAATAkhAADAlBACAABMCSEAAMBUZ2GtjEJQADgAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- new.get_result(result.m02.1, '1.BSTS')\n",
    "errors.2 <- new.get_result(result.m02.2, '2.BSTS w/ Regressors')\n",
    "errors.3 <- new.get_result(result.m02.3, '3.BSTS w/ Regressors (2)')\n",
    "\n",
    "#x <- errors.1\n",
    "x <- rbind(errors.1, errors.2)\n",
    "x <- rbind(x, errors.3)\n",
    "\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78dcd688-1d13-455f-a104-9ce887522de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m02 <- result.m02.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18309db-511c-4dca-aae2-184266480211",
   "metadata": {},
   "source": [
    "### save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90ba8638-887a-4a67-868c-d3612e3556db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x <- result.m02.1\n",
    "#write.csv(x, file = \"bsts_result_m0201.csv\")\n",
    "x <- result.m02.2\n",
    "write.csv(x, file = \"bsts_result_m0202.csv\")\n",
    "x <- result.m02.3\n",
    "write.csv(x, file = \"bsts_result_m0203.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d128253-162e-4222-b582-fb0ee3ef80e7",
   "metadata": {},
   "source": [
    "### load result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bb1bd39-9ed6-4fb6-8abe-4d35c9b83632",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.m02.1 <- read.csv(file = 'bsts_result_m0201.csv')\n",
    "result.m02.2 <- read.csv(file = 'bsts_result_m0202.csv')\n",
    "result.m02.3 <- read.csv(file = 'bsts_result_m0203.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69617942-9647-4c39-9fab-68b25004a5f6",
   "metadata": {},
   "source": [
    "# ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714a4470-8e12-439a-b2ef-3b3e4d106e65",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1649827c-2f89-40f9-939c-5a35daceab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast <- function(x, h, xreg=NULL, xreg.msize=NULL, order=NULL) {\n",
    "    \n",
    "    if (!is.null(xreg)) {\n",
    "        \n",
    "        if (is.null(xreg.msize)) {\n",
    "            xreg.m <- xreg # calc mean for future with all the xreg\n",
    "        } else {\n",
    "            # calc mean for future with xreg of length xreg.mszie\n",
    "            xreg.m <- tail(xreg, n=xreg.msize)\n",
    "        }\n",
    "        \n",
    "        if (is.null(dim(xreg))) {\n",
    "            xreg.h <- mean(xreg.m)\n",
    "        } else {\n",
    "            xreg.h <- colMeans(xreg.m)  \n",
    "        }\n",
    "        \n",
    "        xreg.h <- data.frame(xreg.h)\n",
    "        colnames(xreg.h) <- colnames(NA)\n",
    "        #colnames(xreg.h) <- colnames(xreg) # error with multiple xreg\n",
    "        xreg.h <- t(xreg.h)\n",
    "        xreg.h <- as.ts(xreg.h[rep(seq_len(nrow(xreg.h)), h), ])\n",
    "        \n",
    "        ## added for single day forecast\n",
    "        xreg.coln <- colnames(xreg)\n",
    "        xreg.h <- data.frame(xreg.h) # convert to frame for the case of single xreg\n",
    "        if ((dim(xreg.h)[2]==1) & (dim(xreg.h)[1]==length(xreg.coln))) {\n",
    "            xreg.h <- t(xreg.h) # the case of h==1\n",
    "        } else {\n",
    "            xreg.h <- as.ts(xreg.h) # convert to ts as xreg is ts\n",
    "        }\n",
    "        \n",
    "    } else {\n",
    "        xreg.h <- NULL\n",
    "    }\n",
    "    if (is.null(order)) {\n",
    "        fc <- forecast(auto.arima(x, trace=TRUE, ic='aicc', seasonal=FALSE, \n",
    "                                  xreg=xreg, \n",
    "                                  #lambda=\"auto\" # not for negative value\n",
    "                                  ), h=h, xreg=xreg.h)\n",
    "    } else {\n",
    "        fc <- forecast(Arima(x, order=order, seasonal=FALSE, \n",
    "                                  xreg=xreg, \n",
    "                                  ), h=h, xreg=xreg.h)\n",
    "    }\n",
    "    return(fc)\n",
    "}\n",
    "\n",
    "arima.forecast <- cv.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "712a592c-6bca-47e8-a995-1fc75b0e0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main difference with cv.forecast is that cv.forecase.2 need data for forecasting\n",
    "cv.forecast.2 <- function(x, h, xreg=NULL, xreg.msize=NULL, sample.n=0) \n",
    "{\n",
    "    result.rmse <- c()\n",
    "    result.mape <- c()\n",
    "    train.len <- length(x) - h\n",
    "    my.subset <- function(x, s, e) {\n",
    "        if (!is.null(x)) {\n",
    "            #x <- subset(x, start=s, end=e)\n",
    "            #x <- subset(as.ts(x), start=s, end=e)\n",
    "            x <- subset(ts(x), start=s, end=e)\n",
    "        }\n",
    "        return(x)\n",
    "    }\n",
    "    idx <- 0:(h-1)\n",
    "    if ((sample.n>0) & (sample.n<h)) {\n",
    "        idx <- sort(sample(idx, sample.n))\n",
    "    }\n",
    "    \n",
    "    order <- NULL\n",
    "    for (i in seq_along(idx)) {\n",
    "        trlen <- train.len+idx[i]\n",
    "        x.train <- my.subset(x, 1, trlen)\n",
    "        xreg.train <- my.subset(xreg, 1, trlen)\n",
    "        \n",
    "        fc <- cv.forecast(x.train, 1, xreg=xreg.train, xreg.msize=xreg.msize,\n",
    "                          order=order)\n",
    "        if (i==1) { # reuse param for the rest of periods\n",
    "            p <- fc$model$arma[1]\n",
    "            d <- fc$model$arma[6]\n",
    "            q <- fc$model$arma[2]\n",
    "            order <- c(p, d, q)\n",
    "        }\n",
    "        \n",
    "        result.rmse[i] <- sqrt(mean((fc$mean - x[trlen+1])^2))\n",
    "        result.mape[i] <- mean(abs(1 - fc$mean / x[trlen+1]))\n",
    "    }\n",
    "    e <- list(rmse.mean=mean(result.rmse), rmse.sigma=sd(result.rmse), \n",
    "              mape.mean=mean(result.mape), mape.sigma=sd(result.mape))\n",
    "    return(e)\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0145d7-e293-4fdd-8dbb-f62c0d26e658",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b05b4a06-7253-42c9-b6f0-28b182f99b79",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -8729.901\n",
      " ARIMA(1,0,0) with non-zero mean : -13486.9\n",
      " ARIMA(0,0,1) with non-zero mean : -10820.55\n",
      " ARIMA(0,0,0) with zero mean     : -8407.697\n",
      " ARIMA(2,0,0) with non-zero mean : -13491.63\n",
      " ARIMA(3,0,0) with non-zero mean : -13491.75\n",
      " ARIMA(4,0,0) with non-zero mean : -13496.44\n",
      " ARIMA(5,0,0) with non-zero mean : -13502.01\n",
      " ARIMA(5,0,1) with non-zero mean : -13509.96\n",
      " ARIMA(4,0,1) with non-zero mean : -13504.29\n",
      " ARIMA(5,0,2) with non-zero mean : -13507.99\n",
      " ARIMA(4,0,2) with non-zero mean : -13508.66\n",
      " ARIMA(5,0,1) with zero mean     : -13497.02\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,1) with non-zero mean : -13497.21\n",
      "\n",
      " Best model: ARIMA(5,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -13377.54\n",
      " ARIMA(1,1,0) with drift         : -13378.28\n",
      " ARIMA(0,1,1) with drift         : -13376.14\n",
      " ARIMA(0,1,0)                    : -13379.49\n",
      " ARIMA(1,1,1) with drift         : -13377.51\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -13388.23\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -13351.94\n",
      " ARIMA(0,1,0) with drift         : -13329.65\n",
      " ARIMA(1,1,0) with drift         : -13329.34\n",
      " ARIMA(0,1,1) with drift         : -13328.48\n",
      " ARIMA(0,1,0)                    : -13331.64\n",
      " ARIMA(1,1,2) with drift         : -13333.18\n",
      " ARIMA(2,1,1) with drift         : -13367.24\n",
      " ARIMA(1,1,1) with drift         : -13327.34\n",
      " ARIMA(2,1,0) with drift         : -13329.21\n",
      " ARIMA(3,1,1) with drift         : -13330.64\n",
      " ARIMA(3,1,0) with drift         : -13332.29\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1)                    : -13368.81\n",
      " ARIMA(1,1,1)                    : -13329.32\n",
      " ARIMA(2,1,0)                    : -13331.19\n",
      " ARIMA(3,1,1)                    : -13332.67\n",
      " ARIMA(2,1,2)                    : -13353.95\n",
      " ARIMA(1,1,0)                    : -13331.32\n",
      " ARIMA(1,1,2)                    : -13348.06\n",
      " ARIMA(3,1,0)                    : -13334.28\n",
      " ARIMA(3,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,1)                    : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -13393.73\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -13234.71\n",
      " ARIMA(1,1,0) with drift         : -13232.87\n",
      " ARIMA(0,1,1) with drift         : -13233.97\n",
      " ARIMA(0,1,0)                    : -13236.7\n",
      " ARIMA(1,1,1) with drift         : -13231.87\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -13245.39\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13263.35\n",
      " ARIMA(0,0,0) with non-zero mean : -8706.059\n",
      " ARIMA(1,0,0) with non-zero mean : -13255.84\n",
      " ARIMA(0,0,1) with non-zero mean : -10773.99\n",
      " ARIMA(0,0,0) with zero mean     : -8448.555\n",
      " ARIMA(1,0,2) with non-zero mean : -13260.91\n",
      " ARIMA(2,0,1) with non-zero mean : -13259.89\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -13259.02\n",
      " ARIMA(1,0,1) with non-zero mean : -13262.92\n",
      " ARIMA(1,0,3) with non-zero mean : -13261.08\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -13255.47\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13263\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13234.55\n",
      " ARIMA(0,0,0) with non-zero mean : -8691.834\n",
      " ARIMA(1,0,0) with non-zero mean : -13229.55\n",
      " ARIMA(0,0,1) with non-zero mean : -10751.25\n",
      " ARIMA(0,0,0) with zero mean     : -8433.02\n",
      " ARIMA(1,0,2) with non-zero mean : -13235.37\n",
      " ARIMA(0,0,2) with non-zero mean : -11866.88\n",
      " ARIMA(1,0,1) with non-zero mean : -13237.32\n",
      " ARIMA(2,0,1) with non-zero mean : -13225.93\n",
      " ARIMA(2,0,0) with non-zero mean : -13237.39\n",
      " ARIMA(3,0,0) with non-zero mean : -13234.61\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(2,0,0) with zero mean     : -13228.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,0) with non-zero mean : -13235.12\n",
      "\n",
      " Best model: ARIMA(2,0,0) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13226.64\n",
      " ARIMA(0,0,0) with non-zero mean : -8693.681\n",
      " ARIMA(1,0,0) with non-zero mean : -13220.86\n",
      " ARIMA(0,0,1) with non-zero mean : -10750.64\n",
      " ARIMA(0,0,0) with zero mean     : -8430.203\n",
      " ARIMA(1,0,2) with non-zero mean : -13226.25\n",
      " ARIMA(2,0,1) with non-zero mean : -13226.06\n",
      " ARIMA(3,0,2) with non-zero mean : -13309.63\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -13307.61\n",
      " ARIMA(2,0,3) with non-zero mean : -13226.59\n",
      " ARIMA(4,0,1) with non-zero mean : -13224.04\n",
      " ARIMA(4,0,3) with non-zero mean : -13224.26\n",
      " ARIMA(3,0,2) with zero mean     : -13300.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,2) with non-zero mean : -13225.89\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13223.46\n",
      " ARIMA(0,0,0) with non-zero mean : -8692.073\n",
      " ARIMA(1,0,0) with non-zero mean : -13216.09\n",
      " ARIMA(0,0,1) with non-zero mean : -10746.36\n",
      " ARIMA(0,0,0) with zero mean     : -8438.64\n",
      " ARIMA(1,0,2) with non-zero mean : -13219.99\n",
      " ARIMA(2,0,1) with non-zero mean : -13219.26\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -13218.58\n",
      " ARIMA(1,0,1) with non-zero mean : -13221.81\n",
      " ARIMA(1,0,3) with non-zero mean : -13219.71\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -13215.75\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13222.6\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -8686.987\n",
      " ARIMA(1,0,0) with non-zero mean : -13209.96\n",
      " ARIMA(0,0,1) with non-zero mean : -10738.7\n",
      " ARIMA(0,0,0) with zero mean     : -8426.26\n",
      " ARIMA(2,0,0) with non-zero mean : -13214.47\n",
      " ARIMA(3,0,0) with non-zero mean : -13211.74\n",
      " ARIMA(2,0,1) with non-zero mean : -13212.45\n",
      " ARIMA(1,0,1) with non-zero mean : -13215.28\n",
      " ARIMA(1,0,2) with non-zero mean : -13213.51\n",
      " ARIMA(0,0,2) with non-zero mean : -11840.92\n",
      " ARIMA(1,0,1) with zero mean     : -13207.44\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -13213.63\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13183.35\n",
      " ARIMA(0,0,0) with non-zero mean : -8605.008\n",
      " ARIMA(1,0,0) with non-zero mean : -13178.74\n",
      " ARIMA(0,0,1) with non-zero mean : -10671.87\n",
      " ARIMA(0,0,0) with zero mean     : -8372.744\n",
      " ARIMA(1,0,2) with non-zero mean : -13181.28\n",
      " ARIMA(2,0,1) with non-zero mean : -13180.26\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -13179.48\n",
      " ARIMA(1,0,1) with non-zero mean : -13183.22\n",
      " ARIMA(1,0,3) with non-zero mean : -13180.78\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -13173.21\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13183.36\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13157.75\n",
      " ARIMA(0,0,0) with non-zero mean : -8599.633\n",
      " ARIMA(1,0,0) with non-zero mean : -13156.4\n",
      " ARIMA(0,0,1) with non-zero mean : -10657.5\n",
      " ARIMA(0,0,0) with zero mean     : -8371.167\n",
      " ARIMA(1,0,2) with non-zero mean : -13159.03\n",
      " ARIMA(0,0,2) with non-zero mean : -11765.46\n",
      " ARIMA(1,0,1) with non-zero mean : -13161.04\n",
      " ARIMA(2,0,1) with non-zero mean : -13159.02\n",
      " ARIMA(2,0,0) with non-zero mean : -13160.94\n",
      " ARIMA(1,0,1) with zero mean     : -13153.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -13157.39\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13118.41\n",
      " ARIMA(0,0,0) with non-zero mean : -8582.353\n",
      " ARIMA(1,0,0) with non-zero mean : -13116.65\n",
      " ARIMA(0,0,1) with non-zero mean : -10629.58\n",
      " ARIMA(0,0,0) with zero mean     : -8368.258\n",
      " ARIMA(1,0,2) with non-zero mean : -13119.21\n",
      " ARIMA(0,0,2) with non-zero mean : -11723.45\n",
      " ARIMA(1,0,1) with non-zero mean : -13121.15\n",
      " ARIMA(2,0,1) with non-zero mean : -13118.75\n",
      " ARIMA(2,0,0) with non-zero mean : -13120.42\n",
      " ARIMA(1,0,1) with zero mean     : -13115.91\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -13113.39\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13071.29\n",
      " ARIMA(0,0,0) with non-zero mean : -8638.881\n",
      " ARIMA(1,0,0) with non-zero mean : -13070.54\n",
      " ARIMA(0,0,1) with non-zero mean : -10684.56\n",
      " ARIMA(0,0,0) with zero mean     : -8450.488\n",
      " ARIMA(1,0,2) with non-zero mean : -13073.57\n",
      " ARIMA(0,0,2) with non-zero mean : -11760.84\n",
      " ARIMA(1,0,1) with non-zero mean : -13074.77\n",
      " ARIMA(2,0,1) with non-zero mean : -13072.43\n",
      " ARIMA(2,0,0) with non-zero mean : -13073.94\n",
      " ARIMA(1,0,1) with zero mean     : -13068.78\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -13073.39\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13020.07\n",
      " ARIMA(0,0,0) with non-zero mean : -8626.698\n",
      " ARIMA(1,0,0) with non-zero mean : -13019.34\n",
      " ARIMA(0,0,1) with non-zero mean : -10666.27\n",
      " ARIMA(0,0,0) with zero mean     : -8430.999\n",
      " ARIMA(1,0,2) with non-zero mean : -13022.74\n",
      " ARIMA(0,0,2) with non-zero mean : -11728.64\n",
      " ARIMA(1,0,1) with non-zero mean : -13023.48\n",
      " ARIMA(2,0,1) with non-zero mean : -13021.47\n",
      " ARIMA(2,0,0) with non-zero mean : -13022.39\n",
      " ARIMA(1,0,1) with zero mean     : -13018.08\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -13022.46\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12895.32\n",
      " ARIMA(1,1,0) with drift         : -12892.39\n",
      " ARIMA(0,1,1) with drift         : -12893.4\n",
      " ARIMA(0,1,0)                    : -12897.3\n",
      " ARIMA(1,1,1) with drift         : -12891.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12905.83\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12860.21\n",
      " ARIMA(0,1,0) with drift         : -12826.47\n",
      " ARIMA(1,1,0) with drift         : -12823.83\n",
      " ARIMA(0,1,1) with drift         : -12824.58\n",
      " ARIMA(0,1,0)                    : -12828.46\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : -12831.77\n",
      " ARIMA(3,1,2) with drift         : -12826.3\n",
      " ARIMA(2,1,3) with drift         : -12865.48\n",
      " ARIMA(1,1,3) with drift         : -12829.73\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : -12864.1\n",
      " ARIMA(1,1,4) with drift         : -12827.86\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -12866.89\n",
      " ARIMA(1,1,3)                    : -12831.68\n",
      " ARIMA(2,1,2)                    : -12861.71\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : -12865.52\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,4)                    : -12829.85\n",
      " ARIMA(3,1,2)                    : -12828.31\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3)                    : -12840.65\n",
      "\n",
      " Best model: ARIMA(1,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -8273.531\n",
      " ARIMA(1,0,0) with non-zero mean : -12881.86\n",
      " ARIMA(0,0,1) with non-zero mean : -10351.3\n",
      " ARIMA(0,0,0) with zero mean     : -8122.831\n",
      " ARIMA(2,0,0) with non-zero mean : -12882.19\n",
      " ARIMA(3,0,0) with non-zero mean : -12880.27\n",
      " ARIMA(2,0,1) with non-zero mean : -12880.5\n",
      " ARIMA(1,0,1) with non-zero mean : -12883.25\n",
      " ARIMA(1,0,2) with non-zero mean : -12881.73\n",
      " ARIMA(0,0,2) with non-zero mean : -11451.56\n",
      " ARIMA(1,0,1) with zero mean     : -12879.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -12882.2\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12871.42\n",
      " ARIMA(0,0,0) with non-zero mean : -8262.48\n",
      " ARIMA(1,0,0) with non-zero mean : -12871.81\n",
      " ARIMA(0,0,1) with non-zero mean : -10340.93\n",
      " ARIMA(0,0,0) with zero mean     : -8109.969\n",
      " ARIMA(2,0,0) with non-zero mean : -12874.6\n",
      " ARIMA(3,0,0) with non-zero mean : -12872.38\n",
      " ARIMA(2,0,1) with non-zero mean : -12873.19\n",
      " ARIMA(1,0,1) with non-zero mean : -12874.05\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(2,0,0) with zero mean     : -12871.34\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,0) with non-zero mean : -12872.16\n",
      "\n",
      " Best model: ARIMA(2,0,0) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12770.64\n",
      " ARIMA(1,1,0) with drift         : -12768.42\n",
      " ARIMA(0,1,1) with drift         : -12768.88\n",
      " ARIMA(0,1,0)                    : -12772.63\n",
      " ARIMA(1,1,1) with drift         : -12767.46\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12781.1\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12763.47\n",
      " ARIMA(1,1,0) with drift         : -12760.68\n",
      " ARIMA(0,1,1) with drift         : -12761.67\n",
      " ARIMA(0,1,0)                    : -12765.47\n",
      " ARIMA(1,1,1) with drift         : -12759.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12773.95\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12720.9\n",
      " ARIMA(1,1,0) with drift         : -12718.16\n",
      " ARIMA(0,1,1) with drift         : -12719.09\n",
      " ARIMA(0,1,0)                    : -12722.86\n",
      " ARIMA(1,1,1) with drift         : -12716.81\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12731.32\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12666.53\n",
      " ARIMA(1,1,0) with drift         : -12663.76\n",
      " ARIMA(0,1,1) with drift         : -12664.79\n",
      " ARIMA(0,1,0)                    : -12668.52\n",
      " ARIMA(1,1,1) with drift         : -12662.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12676.95\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12648.97\n",
      " ARIMA(1,1,0) with drift         : -12646.42\n",
      " ARIMA(0,1,1) with drift         : -12647.47\n",
      " ARIMA(0,1,0)                    : -12650.97\n",
      " ARIMA(1,1,1) with drift         : -12645.43\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12659.4\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12632.45\n",
      " ARIMA(0,1,0) with drift         : -12633.22\n",
      " ARIMA(1,1,0) with drift         : -12630.63\n",
      " ARIMA(0,1,1) with drift         : -12631.67\n",
      " ARIMA(0,1,0)                    : -12635.23\n",
      " ARIMA(1,1,1) with drift         : -12629.76\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12643.64\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "[1] \"10 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12619.17\n",
      " ARIMA(1,1,0) with drift         : -12616.45\n",
      " ARIMA(0,1,1) with drift         : -12617.47\n",
      " ARIMA(0,1,0)                    : -12621.17\n",
      " ARIMA(1,1,1) with drift         : -12615.73\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12629.58\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12599.68\n",
      " ARIMA(1,1,0) with drift         : -12597.63\n",
      " ARIMA(0,1,1) with drift         : -12597.91\n",
      " ARIMA(0,1,0)                    : -12601.68\n",
      " ARIMA(1,1,1) with drift         : -12597.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12610.08\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12585.52\n",
      " ARIMA(1,1,0) with drift         : -12583.61\n",
      " ARIMA(0,1,1) with drift         : -12583.79\n",
      " ARIMA(0,1,0)                    : -12587.53\n",
      " ARIMA(1,1,1) with drift         : -12582.95\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12595.92\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12575.75\n",
      " ARIMA(1,1,0) with drift         : -12573.03\n",
      " ARIMA(0,1,1) with drift         : -12574\n",
      " ARIMA(0,1,0)                    : -12577.75\n",
      " ARIMA(1,1,1) with drift         : -12572.21\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12586.14\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12556.22\n",
      " ARIMA(0,1,0) with drift         : -12555.96\n",
      " ARIMA(1,1,0) with drift         : -12553.13\n",
      " ARIMA(0,1,1) with drift         : -12554.03\n",
      " ARIMA(0,1,0)                    : -12557.96\n",
      " ARIMA(1,1,1) with drift         : -12552.09\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12566.34\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12536.16\n",
      " ARIMA(0,1,0) with drift         : -12534.17\n",
      " ARIMA(1,1,0) with drift         : -12531.56\n",
      " ARIMA(0,1,1) with drift         : -12532.27\n",
      " ARIMA(0,1,0)                    : -12536.16\n",
      " ARIMA(1,1,1) with drift         : -12530.62\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12544.53\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12493.21\n",
      " ARIMA(0,1,0) with drift         : -12492.02\n",
      " ARIMA(1,1,0) with drift         : -12489.42\n",
      " ARIMA(0,1,1) with drift         : -12490.39\n",
      " ARIMA(0,1,0)                    : -12494.01\n",
      " ARIMA(1,1,1) with drift         : -12488.94\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12502.36\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12363.39\n",
      " ARIMA(1,1,0) with drift         : -12361.92\n",
      " ARIMA(0,1,1) with drift         : -12362.83\n",
      " ARIMA(0,1,0)                    : -12365.4\n",
      " ARIMA(1,1,1) with drift         : -12361.31\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12373.69\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12316.14\n",
      " ARIMA(0,1,0) with drift         : -12318.09\n",
      " ARIMA(1,1,0) with drift         : -12316.48\n",
      " ARIMA(0,1,1) with drift         : -12317.45\n",
      " ARIMA(0,1,0)                    : -12320.08\n",
      " ARIMA(1,1,1) with drift         : -12315.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12328.35\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12249.54\n",
      " ARIMA(0,1,0) with drift         : -12252.65\n",
      " ARIMA(1,1,0) with drift         : -12251.38\n",
      " ARIMA(0,1,1) with drift         : -12252.12\n",
      " ARIMA(0,1,0)                    : -12254.65\n",
      " ARIMA(1,1,1) with drift         : -12249.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12262.9\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12188.61\n",
      " ARIMA(0,1,0) with drift         : -12192.2\n",
      " ARIMA(1,1,0) with drift         : -12190.99\n",
      " ARIMA(0,1,1) with drift         : -12191.78\n",
      " ARIMA(0,1,0)                    : -12194.2\n",
      " ARIMA(1,1,1) with drift         : -12189.56\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12202.42\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12173.86\n",
      " ARIMA(0,1,0) with drift         : -12177.26\n",
      " ARIMA(1,1,0) with drift         : -12175.8\n",
      " ARIMA(0,1,1) with drift         : -12176.9\n",
      " ARIMA(0,1,0)                    : -12179.26\n",
      " ARIMA(1,1,1) with drift         : -12174.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12187.48\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12149.5\n",
      " ARIMA(0,1,0) with drift         : -12153.1\n",
      " ARIMA(1,1,0) with drift         : -12151.82\n",
      " ARIMA(0,1,1) with drift         : -12152.63\n",
      " ARIMA(0,1,0)                    : -12155.1\n",
      " ARIMA(1,1,1) with drift         : -12150.29\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12163.3\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12128.62\n",
      " ARIMA(1,1,0) with drift         : -12127.02\n",
      " ARIMA(0,1,1) with drift         : -12127.98\n",
      " ARIMA(0,1,0)                    : -12130.62\n",
      " ARIMA(1,1,1) with drift         : -12125.41\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12138.81\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12094.83\n",
      " ARIMA(1,1,0) with drift         : -12093.74\n",
      " ARIMA(0,1,1) with drift         : -12093.52\n",
      " ARIMA(0,1,0)                    : -12096.83\n",
      " ARIMA(1,1,1) with drift         : -12091.74\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12105.01\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12082.79\n",
      " ARIMA(0,1,0) with drift         : -12069.6\n",
      " ARIMA(1,1,0) with drift         : -12068.53\n",
      " ARIMA(0,1,1) with drift         : -12068.08\n",
      " ARIMA(0,1,0)                    : -12071.6\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : -12069.65\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -12085.65\n",
      " ARIMA(1,1,3) with drift         : -12069.73\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : -12083.73\n",
      " ARIMA(1,1,4) with drift         : -12068.47\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -12087.68\n",
      " ARIMA(1,1,3)                    : -12071.71\n",
      " ARIMA(2,1,2)                    : -12068.25\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : -12085.75\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,4)                    : -12070.48\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(1,1,3)                    : -12081.21\n",
      "\n",
      " Best model: ARIMA(1,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12082.77\n",
      " ARIMA(0,1,0) with drift         : -12062.29\n",
      " ARIMA(1,1,0) with drift         : -12059.83\n",
      " ARIMA(0,1,1) with drift         : -12060.73\n",
      " ARIMA(0,1,0)                    : -12064.29\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -12058.07\n",
      " ARIMA(1,1,3) with drift         : -12062.87\n",
      " ARIMA(3,1,1) with drift         : -12071.37\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12093.41\n",
      "\n",
      " Best model: ARIMA(2,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12051.59\n",
      " ARIMA(0,1,0) with drift         : -12056.79\n",
      " ARIMA(1,1,0) with drift         : -12054.21\n",
      " ARIMA(0,1,1) with drift         : -12055.13\n",
      " ARIMA(0,1,0)                    : -12058.79\n",
      " ARIMA(1,1,1) with drift         : -12052.52\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12066.95\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12040.97\n",
      " ARIMA(0,1,0) with drift         : -12045.69\n",
      " ARIMA(1,1,0) with drift         : -12043.05\n",
      " ARIMA(0,1,1) with drift         : -12043.96\n",
      " ARIMA(0,1,0)                    : -12047.7\n",
      " ARIMA(1,1,1) with drift         : -12041.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12055.85\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12035.51\n",
      " ARIMA(1,1,0) with drift         : -12032.9\n",
      " ARIMA(0,1,1) with drift         : -12033.73\n",
      " ARIMA(0,1,0)                    : -12037.51\n",
      " ARIMA(1,1,1) with drift         : -12030.9\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12045.67\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12023.14\n",
      " ARIMA(0,1,0) with drift         : -12028.48\n",
      " ARIMA(1,1,0) with drift         : -12025.73\n",
      " ARIMA(0,1,1) with drift         : -12026.67\n",
      " ARIMA(0,1,0)                    : -12030.49\n",
      " ARIMA(1,1,1) with drift         : -12023.73\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12038.64\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12061.44\n",
      " ARIMA(0,1,0) with drift         : -12023.42\n",
      " ARIMA(1,1,0) with drift         : -12020.51\n",
      " ARIMA(0,1,1) with drift         : -12021.52\n",
      " ARIMA(0,1,0)                    : -12025.42\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : -12021.41\n",
      " ARIMA(3,1,2) with drift         : -12033.17\n",
      " ARIMA(2,1,3) with drift         : -12067.9\n",
      " ARIMA(1,1,3) with drift         : -12035.78\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : -12066.17\n",
      " ARIMA(1,1,4) with drift         : -12034.04\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -12069.61\n",
      " ARIMA(1,1,3)                    : -12037.79\n",
      " ARIMA(2,1,2)                    : -12021.24\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : -12067.88\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,4)                    : -12036.05\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(1,1,3)                    : -12046.92\n",
      "\n",
      " Best model: ARIMA(1,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12015.63\n",
      " ARIMA(0,1,0) with drift         : -12021.2\n",
      " ARIMA(1,1,0) with drift         : -12018.3\n",
      " ARIMA(0,1,1) with drift         : -12019.28\n",
      " ARIMA(0,1,0)                    : -12023.2\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12031.34\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12019.53\n",
      " ARIMA(1,1,0) with drift         : -12016.78\n",
      " ARIMA(0,1,1) with drift         : -12017.59\n",
      " ARIMA(0,1,0)                    : -12021.53\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12029.68\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "[1] \"20 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12017.38\n",
      " ARIMA(1,1,0) with drift         : -12014.64\n",
      " ARIMA(0,1,1) with drift         : -12015.43\n",
      " ARIMA(0,1,0)                    : -12019.38\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12027.53\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12013.54\n",
      " ARIMA(1,1,0) with drift         : -12010.62\n",
      " ARIMA(0,1,1) with drift         : -12011.59\n",
      " ARIMA(0,1,0)                    : -12015.55\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12023.69\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12010.11\n",
      " ARIMA(1,1,0) with drift         : -12007.44\n",
      " ARIMA(0,1,1) with drift         : -12008.17\n",
      " ARIMA(0,1,0)                    : -12012.11\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12020.25\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12001.03\n",
      " ARIMA(1,1,0) with drift         : -11998.11\n",
      " ARIMA(0,1,1) with drift         : -11999.06\n",
      " ARIMA(0,1,0)                    : -12003.03\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12011.17\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11991.51\n",
      " ARIMA(0,1,0) with drift         : -11995.98\n",
      " ARIMA(1,1,0) with drift         : -11993.05\n",
      " ARIMA(0,1,1) with drift         : -11994.03\n",
      " ARIMA(0,1,0)                    : -11997.99\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12006.12\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11996.07\n",
      " ARIMA(1,1,0) with drift         : -11993.21\n",
      " ARIMA(0,1,1) with drift         : -11994.15\n",
      " ARIMA(0,1,0)                    : -11998.07\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12006.21\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11996.85\n",
      " ARIMA(1,1,0) with drift         : -11994.15\n",
      " ARIMA(0,1,1) with drift         : -11994.92\n",
      " ARIMA(0,1,0)                    : -11998.85\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12006.98\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12016.73\n",
      " ARIMA(0,1,0) with drift         : -11995.59\n",
      " ARIMA(1,1,0) with drift         : -11992.68\n",
      " ARIMA(0,1,1) with drift         : -11993.67\n",
      " ARIMA(0,1,0)                    : -11997.59\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12006.39\n",
      " ARIMA(3,1,1) with drift         : -12004.19\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12027.23\n",
      "\n",
      " Best model: ARIMA(2,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12012.2\n",
      " ARIMA(0,1,0) with drift         : -11990.52\n",
      " ARIMA(1,1,0) with drift         : -11987.63\n",
      " ARIMA(0,1,1) with drift         : -11988.63\n",
      " ARIMA(0,1,0)                    : -11992.52\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12001.17\n",
      " ARIMA(3,1,1) with drift         : -11999.02\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12022.54\n",
      "\n",
      " Best model: ARIMA(2,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12043.99\n",
      " ARIMA(0,1,0) with drift         : -11987.17\n",
      " ARIMA(1,1,0) with drift         : -11984.55\n",
      " ARIMA(0,1,1) with drift         : -11985.26\n",
      " ARIMA(0,1,0)                    : -11989.17\n",
      " ARIMA(1,1,2) with drift         : -12023.86\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11982.54\n",
      " ARIMA(1,1,3) with drift         : -11995.32\n",
      " ARIMA(3,1,1) with drift         : -11994.67\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12006.86\n",
      "\n",
      " Best model: ARIMA(1,1,3) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11981.5\n",
      " ARIMA(1,1,0) with drift         : -11979.09\n",
      " ARIMA(0,1,1) with drift         : -11979.6\n",
      " ARIMA(0,1,0)                    : -11983.5\n",
      " ARIMA(1,1,1) with drift         : -11977.09\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11991.63\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11978.9\n",
      " ARIMA(1,1,0) with drift         : -11976.01\n",
      " ARIMA(0,1,1) with drift         : -11977.01\n",
      " ARIMA(0,1,0)                    : -11980.91\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11989.03\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11981.39\n",
      " ARIMA(1,1,0) with drift         : -11978.69\n",
      " ARIMA(0,1,1) with drift         : -11979.53\n",
      " ARIMA(0,1,0)                    : -11983.39\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11991.52\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11986.98\n",
      " ARIMA(1,1,0) with drift         : -11984.6\n",
      " ARIMA(0,1,1) with drift         : -11985.09\n",
      " ARIMA(0,1,0)                    : -11988.99\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11997.12\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11992.9\n",
      " ARIMA(1,1,0) with drift         : -11989.96\n",
      " ARIMA(0,1,1) with drift         : -11990.96\n",
      " ARIMA(0,1,0)                    : -11994.9\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12003.04\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12013.09\n",
      " ARIMA(0,1,0) with drift         : -11992.3\n",
      " ARIMA(1,1,0) with drift         : -11989.52\n",
      " ARIMA(0,1,1) with drift         : -11990.35\n",
      " ARIMA(0,1,0)                    : -11994.3\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12002.95\n",
      " ARIMA(3,1,1) with drift         : -12001.79\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12024.89\n",
      "\n",
      " Best model: ARIMA(2,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11988.37\n",
      " ARIMA(1,1,0) with drift         : -11985.73\n",
      " ARIMA(0,1,1) with drift         : -11986.38\n",
      " ARIMA(0,1,0)                    : -11990.37\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11998.5\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11987.63\n",
      " ARIMA(1,1,0) with drift         : -11984.66\n",
      " ARIMA(0,1,1) with drift         : -11985.63\n",
      " ARIMA(0,1,0)                    : -11989.63\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -11997.77\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12008.82\n",
      " ARIMA(0,1,0) with drift         : -11994.44\n",
      " ARIMA(1,1,0) with drift         : -11992.07\n",
      " ARIMA(0,1,1) with drift         : -11992.44\n",
      " ARIMA(0,1,0)                    : -11996.43\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : -11991.26\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12004.44\n",
      " ARIMA(3,1,1) with drift         : -12005.12\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(3,1,1) with drift         : -12014.85\n",
      "\n",
      " Best model: ARIMA(3,1,1) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12059.59\n",
      " ARIMA(0,1,0) with drift         : -12000.97\n",
      " ARIMA(1,1,0) with drift         : -11998.47\n",
      " ARIMA(0,1,1) with drift         : -11998.97\n",
      " ARIMA(0,1,0)                    : -12002.96\n",
      " ARIMA(1,1,2) with drift         : -12039.27\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12008.38\n",
      " ARIMA(3,1,1) with drift         : -12007.62\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -12061.58\n",
      " ARIMA(1,1,2)                    : -12041.15\n",
      " ARIMA(2,1,1)                    : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(1,1,1)                    : Inf\n",
      " ARIMA(1,1,3)                    : -12010.39\n",
      " ARIMA(3,1,1)                    : -12009.59\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(1,1,3)                    : -12023.37\n",
      "\n",
      " Best model: ARIMA(1,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12004.31\n",
      " ARIMA(1,1,0) with drift         : -12001.41\n",
      " ARIMA(0,1,1) with drift         : -12002.33\n",
      " ARIMA(0,1,0)                    : -12006.31\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12014.45\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12001.45\n",
      " ARIMA(1,1,0) with drift         : -11998.66\n",
      " ARIMA(0,1,1) with drift         : -11999.47\n",
      " ARIMA(0,1,0)                    : -12003.45\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12011.58\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -11997.55\n",
      " ARIMA(1,1,0) with drift         : -11995.35\n",
      " ARIMA(0,1,1) with drift         : -11995.58\n",
      " ARIMA(0,1,0)                    : -11999.55\n",
      " ARIMA(1,1,1) with drift         : -11996.94\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12007.69\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12000.21\n",
      " ARIMA(1,1,0) with drift         : -11997.28\n",
      " ARIMA(0,1,1) with drift         : -11998.26\n",
      " ARIMA(0,1,0)                    : -12002.22\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12010.35\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "[1] \"30 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12023.7\n",
      " ARIMA(0,1,0) with drift         : -12005.68\n",
      " ARIMA(1,1,0) with drift         : -12003.47\n",
      " ARIMA(0,1,1) with drift         : -12003.75\n",
      " ARIMA(0,1,0)                    : -12007.68\n",
      " ARIMA(1,1,2) with drift         : -12005.34\n",
      " ARIMA(2,1,1) with drift         : -12003.68\n",
      " ARIMA(3,1,2) with drift         : -12015.1\n",
      " ARIMA(2,1,3) with drift         : -12015.95\n",
      " ARIMA(1,1,1) with drift         : -12032.52\n",
      " ARIMA(0,1,2) with drift         : -12004.11\n",
      " ARIMA(2,1,0) with drift         : -12003.5\n",
      " ARIMA(1,1,1)                    : -12034.31\n",
      " ARIMA(0,1,1)                    : -12005.76\n",
      " ARIMA(1,1,0)                    : -12005.48\n",
      " ARIMA(2,1,1)                    : -12005.7\n",
      " ARIMA(1,1,2)                    : -12035.81\n",
      " ARIMA(0,1,2)                    : -12006.11\n",
      " ARIMA(2,1,2)                    : -12025.67\n",
      " ARIMA(1,1,3)                    : -12006.67\n",
      " ARIMA(0,1,3)                    : -12007.76\n",
      " ARIMA(2,1,3)                    : -12017.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,1)                    : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -12028.35\n",
      "\n",
      " Best model: ARIMA(2,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12046.07\n",
      " ARIMA(0,1,0) with drift         : -12011.57\n",
      " ARIMA(1,1,0) with drift         : -12009.1\n",
      " ARIMA(0,1,1) with drift         : -12009.67\n",
      " ARIMA(0,1,0)                    : -12013.57\n",
      " ARIMA(1,1,2) with drift         : -12038.51\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12020.19\n",
      " ARIMA(3,1,1) with drift         : -12017.76\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -12048.07\n",
      " ARIMA(1,1,2)                    : -12040.13\n",
      " ARIMA(2,1,1)                    : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(1,1,1)                    : Inf\n",
      " ARIMA(1,1,3)                    : -12022.21\n",
      " ARIMA(3,1,1)                    : -12019.74\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(1,1,2)                    : Inf\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(1,1,3)                    : -12034.44\n",
      "\n",
      " Best model: ARIMA(1,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12018.83\n",
      " ARIMA(1,1,0) with drift         : -12015.98\n",
      " ARIMA(0,1,1) with drift         : -12016.99\n",
      " ARIMA(0,1,0)                    : -12020.83\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12028.97\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(0,1,0) with drift         : -12024.85\n",
      " ARIMA(1,1,0) with drift         : -12022.27\n",
      " ARIMA(0,1,1) with drift         : -12022.98\n",
      " ARIMA(0,1,0)                    : -12026.85\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(0,1,0)                    : -12035\n",
      "\n",
      " Best model: ARIMA(0,1,0)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -12098.61\n",
      " ARIMA(0,1,0) with drift         : -12045.53\n",
      " ARIMA(1,1,0) with drift         : -12043.15\n",
      " ARIMA(0,1,1) with drift         : -12043.76\n",
      " ARIMA(0,1,0)                    : -12047.51\n",
      " ARIMA(1,1,2) with drift         : Inf\n",
      " ARIMA(2,1,1) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : -12073.39\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : Inf\n",
      " ARIMA(1,1,3) with drift         : -12054.62\n",
      " ARIMA(3,1,1) with drift         : -12044.52\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -12065.34\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(1,1,3) with drift         : -12066.73\n",
      "\n",
      " Best model: ARIMA(1,1,3) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12144.36\n",
      " ARIMA(0,0,0) with non-zero mean : -7379.697\n",
      " ARIMA(1,0,0) with non-zero mean : -12138.61\n",
      " ARIMA(0,0,1) with non-zero mean : -9450.926\n",
      " ARIMA(0,0,0) with zero mean     : -7370.04\n",
      " ARIMA(1,0,2) with non-zero mean : -12135.74\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12143.93\n",
      " ARIMA(1,0,1) with non-zero mean : -12137.74\n",
      " ARIMA(1,0,3) with non-zero mean : -12133.76\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -12146.18\n",
      " ARIMA(1,0,2) with zero mean     : -12137.45\n",
      " ARIMA(2,0,1) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -12145.78\n",
      " ARIMA(1,0,1) with zero mean     : -12139.45\n",
      " ARIMA(1,0,3) with zero mean     : -12135.48\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12147.75\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12147.26\n",
      " ARIMA(0,0,0) with non-zero mean : -7401.445\n",
      " ARIMA(1,0,0) with non-zero mean : -12140.99\n",
      " ARIMA(0,0,1) with non-zero mean : -9469.226\n",
      " ARIMA(0,0,0) with zero mean     : -7394.298\n",
      " ARIMA(1,0,2) with non-zero mean : -12138.1\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -12195.99\n",
      " ARIMA(3,0,1) with non-zero mean : -12147.37\n",
      " ARIMA(4,0,2) with non-zero mean : -12145.28\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,1) with non-zero mean : -12147.34\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -12195.39\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,1) with non-zero mean : -12148.48\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12157.48\n",
      " ARIMA(0,0,0) with non-zero mean : -7410.828\n",
      " ARIMA(1,0,0) with non-zero mean : -12147.29\n",
      " ARIMA(0,0,1) with non-zero mean : -9478.417\n",
      " ARIMA(0,0,0) with zero mean     : -7404.159\n",
      " ARIMA(1,0,2) with non-zero mean : -12144.29\n",
      " ARIMA(2,0,1) with non-zero mean : -12154.72\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(1,0,1) with non-zero mean : -12146.3\n",
      " ARIMA(1,0,3) with non-zero mean : -12142.28\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -12159.07\n",
      " ARIMA(1,0,2) with zero mean     : -12145.95\n",
      " ARIMA(2,0,1) with zero mean     : -12156.33\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -12158.89\n",
      " ARIMA(1,0,1) with zero mean     : -12147.96\n",
      " ARIMA(1,0,3) with zero mean     : -12143.94\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12157.53\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12176.38\n",
      " ARIMA(0,0,0) with non-zero mean : -7415.23\n",
      " ARIMA(1,0,0) with non-zero mean : -12168.98\n",
      " ARIMA(0,0,1) with non-zero mean : -9487.159\n",
      " ARIMA(0,0,0) with zero mean     : -7406.617\n",
      " ARIMA(1,0,2) with non-zero mean : -12166.19\n",
      " ARIMA(2,0,1) with non-zero mean : -12172.69\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(1,0,1) with non-zero mean : -12168.2\n",
      " ARIMA(1,0,3) with non-zero mean : -12164.18\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12174.04\n",
      " ARIMA(2,0,2) with zero mean     : -12178.13\n",
      " ARIMA(1,0,2) with zero mean     : -12167.84\n",
      " ARIMA(2,0,1) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -12178.04\n",
      " ARIMA(1,0,1) with zero mean     : -12169.85\n",
      " ARIMA(1,0,3) with zero mean     : -12165.83\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -12175.41\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12178.54\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12191.2\n",
      " ARIMA(0,0,0) with non-zero mean : -7418.218\n",
      " ARIMA(1,0,0) with non-zero mean : -12177.16\n",
      " ARIMA(0,0,1) with non-zero mean : -9490.666\n",
      " ARIMA(0,0,0) with zero mean     : -7409.668\n",
      " ARIMA(1,0,2) with non-zero mean : -12174.36\n",
      " ARIMA(2,0,1) with non-zero mean : -12187.67\n",
      " ARIMA(3,0,2) with non-zero mean : -12192.93\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -12199.74\n",
      " ARIMA(4,0,1) with non-zero mean : -12195.36\n",
      " ARIMA(5,0,2) with non-zero mean : -12202.29\n",
      " ARIMA(5,0,1) with non-zero mean : -12201.86\n",
      " ARIMA(5,0,3) with non-zero mean : -12200.54\n",
      " ARIMA(4,0,3) with non-zero mean : -12197.97\n",
      " ARIMA(5,0,2) with zero mean     : -12203.38\n",
      " ARIMA(4,0,2) with zero mean     : -12201.32\n",
      " ARIMA(5,0,1) with zero mean     : -12203.33\n",
      " ARIMA(5,0,3) with zero mean     : -12202\n",
      " ARIMA(4,0,1) with zero mean     : -12196.89\n",
      " ARIMA(4,0,3) with zero mean     : -12199.44\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,2) with zero mean     : -12194.79\n",
      "\n",
      " Best model: ARIMA(5,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12230.95\n",
      " ARIMA(0,0,0) with non-zero mean : -7432.886\n",
      " ARIMA(1,0,0) with non-zero mean : -12217.68\n",
      " ARIMA(0,0,1) with non-zero mean : -9511.6\n",
      " ARIMA(0,0,0) with zero mean     : -7420.807\n",
      " ARIMA(1,0,2) with non-zero mean : -12215.37\n",
      " ARIMA(2,0,1) with non-zero mean : -12225.89\n",
      " ARIMA(3,0,2) with non-zero mean : -12228.34\n",
      " ARIMA(2,0,3) with non-zero mean : -12230.77\n",
      " ARIMA(1,0,1) with non-zero mean : -12217.34\n",
      " ARIMA(1,0,3) with non-zero mean : -12213.4\n",
      " ARIMA(3,0,1) with non-zero mean : -12229.7\n",
      " ARIMA(3,0,3) with non-zero mean : -12227.59\n",
      " ARIMA(2,0,2) with zero mean     : -12232.43\n",
      " ARIMA(1,0,2) with zero mean     : -12216.89\n",
      " ARIMA(2,0,1) with zero mean     : -12227.44\n",
      " ARIMA(3,0,2) with zero mean     : -12229.35\n",
      " ARIMA(2,0,3) with zero mean     : -12232.29\n",
      " ARIMA(1,0,1) with zero mean     : -12218.86\n",
      " ARIMA(1,0,3) with zero mean     : -12214.92\n",
      " ARIMA(3,0,1) with zero mean     : -12231.19\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12227.28\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12256.5\n",
      " ARIMA(0,0,0) with non-zero mean : -7445.42\n",
      " ARIMA(1,0,0) with non-zero mean : -12257.49\n",
      " ARIMA(0,0,1) with non-zero mean : -9535.569\n",
      " ARIMA(0,0,0) with zero mean     : -7434.489\n",
      " ARIMA(2,0,0) with non-zero mean : -12258.72\n",
      " ARIMA(3,0,0) with non-zero mean : -12256.04\n",
      " ARIMA(2,0,1) with non-zero mean : -12256.73\n",
      " ARIMA(1,0,1) with non-zero mean : -12258.14\n",
      " ARIMA(3,0,1) with non-zero mean : -12262.6\n",
      " ARIMA(4,0,1) with non-zero mean : -12265.56\n",
      " ARIMA(4,0,0) with non-zero mean : -12253.08\n",
      " ARIMA(5,0,1) with non-zero mean : -12257.65\n",
      " ARIMA(4,0,2) with non-zero mean : -12266.8\n",
      " ARIMA(3,0,2) with non-zero mean : -12306.42\n",
      " ARIMA(3,0,3) with non-zero mean : -12267.78\n",
      " ARIMA(2,0,3) with non-zero mean : -12256.89\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -12308.34\n",
      " ARIMA(2,0,2) with zero mean     : -12257.99\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -12268.17\n",
      " ARIMA(3,0,3) with zero mean     : -12269.37\n",
      " ARIMA(2,0,1) with zero mean     : -12258.26\n",
      " ARIMA(2,0,3) with zero mean     : -12258.42\n",
      " ARIMA(4,0,1) with zero mean     : -12267.17\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,1) with zero mean     : -12267.77\n",
      "\n",
      " Best model: ARIMA(4,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12267.03\n",
      " ARIMA(0,0,0) with non-zero mean : -7448.715\n",
      " ARIMA(1,0,0) with non-zero mean : -12270.76\n",
      " ARIMA(0,0,1) with non-zero mean : -9539.854\n",
      " ARIMA(0,0,0) with zero mean     : -7436.768\n",
      " ARIMA(2,0,0) with non-zero mean : -12271.22\n",
      " ARIMA(3,0,0) with non-zero mean : -12269.75\n",
      " ARIMA(2,0,1) with non-zero mean : -12279.57\n",
      " ARIMA(1,0,1) with non-zero mean : -12271.36\n",
      " ARIMA(3,0,1) with non-zero mean : -12277.62\n",
      " ARIMA(1,0,2) with non-zero mean : -12269.4\n",
      " ARIMA(3,0,2) with non-zero mean : -12277.69\n",
      " ARIMA(2,0,1) with zero mean     : -12271.86\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with non-zero mean : -12276.5\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12284.93\n",
      " ARIMA(0,0,0) with non-zero mean : -7471.436\n",
      " ARIMA(1,0,0) with non-zero mean : -12282\n",
      " ARIMA(0,0,1) with non-zero mean : -9557.207\n",
      " ARIMA(0,0,0) with zero mean     : -7461.747\n",
      " ARIMA(1,0,2) with non-zero mean : -12280.56\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -12291.07\n",
      " ARIMA(3,0,1) with non-zero mean : -12291.38\n",
      " ARIMA(3,0,0) with non-zero mean : -12279.73\n",
      " ARIMA(4,0,1) with non-zero mean : -12289.84\n",
      " ARIMA(2,0,0) with non-zero mean : -12282.65\n",
      " ARIMA(4,0,0) with non-zero mean : -12276.77\n",
      " ARIMA(4,0,2) with non-zero mean : -12288.12\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -12289.07\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12288.43\n",
      " ARIMA(0,0,0) with non-zero mean : -7491.792\n",
      " ARIMA(1,0,0) with non-zero mean : -12281.96\n",
      " ARIMA(0,0,1) with non-zero mean : -9570.926\n",
      " ARIMA(0,0,0) with zero mean     : -7486.785\n",
      " ARIMA(1,0,2) with non-zero mean : -12280.72\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -12278.07\n",
      " ARIMA(2,0,3) with non-zero mean : -12287.42\n",
      " ARIMA(1,0,1) with non-zero mean : -12282.58\n",
      " ARIMA(1,0,3) with non-zero mean : -12278.8\n",
      " ARIMA(3,0,1) with non-zero mean : -12291.64\n",
      " ARIMA(3,0,0) with non-zero mean : -12279.17\n",
      " ARIMA(4,0,1) with non-zero mean : -12289.74\n",
      " ARIMA(2,0,0) with non-zero mean : -12281.9\n",
      " ARIMA(4,0,0) with non-zero mean : -12276.18\n",
      " ARIMA(4,0,2) with non-zero mean : -12287.82\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -12289.87\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12285.11\n",
      " ARIMA(0,0,0) with non-zero mean : -7496.174\n",
      " ARIMA(1,0,0) with non-zero mean : -12281.29\n",
      " ARIMA(0,0,1) with non-zero mean : -9575.749\n",
      " ARIMA(0,0,0) with zero mean     : -7491.335\n",
      " ARIMA(1,0,2) with non-zero mean : -12279.85\n",
      " ARIMA(2,0,1) with non-zero mean : -12280.01\n",
      " ARIMA(3,0,2) with non-zero mean : -12290.63\n",
      " ARIMA(3,0,1) with non-zero mean : -12291.52\n",
      " ARIMA(3,0,0) with non-zero mean : -12279.18\n",
      " ARIMA(4,0,1) with non-zero mean : -12286.39\n",
      " ARIMA(2,0,0) with non-zero mean : -12282.04\n",
      " ARIMA(4,0,0) with non-zero mean : -12276.54\n",
      " ARIMA(4,0,2) with non-zero mean : -12293.13\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12289.1\n",
      " ARIMA(5,0,1) with non-zero mean : -12281.77\n",
      " ARIMA(5,0,3) with non-zero mean : -12288.54\n",
      " ARIMA(4,0,2) with zero mean     : -12294.75\n",
      " ARIMA(3,0,2) with zero mean     : -12292.38\n",
      " ARIMA(4,0,1) with zero mean     : -12288.01\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,1) with zero mean     : -12293.2\n",
      " ARIMA(3,0,3) with zero mean     : -12290.83\n",
      " ARIMA(5,0,1) with zero mean     : -12283.48\n",
      " ARIMA(5,0,3) with zero mean     : -12290.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,2) with zero mean     : -12297.18\n",
      "\n",
      " Best model: ARIMA(4,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12288.25\n",
      " ARIMA(0,0,0) with non-zero mean : -7487.697\n",
      " ARIMA(1,0,0) with non-zero mean : -12283.46\n",
      " ARIMA(0,0,1) with non-zero mean : -9569.537\n",
      " ARIMA(0,0,0) with zero mean     : -7481.002\n",
      " ARIMA(1,0,2) with non-zero mean : -12282.02\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12287.41\n",
      " ARIMA(1,0,1) with non-zero mean : -12283.88\n",
      " ARIMA(1,0,3) with non-zero mean : -12280.08\n",
      " ARIMA(3,0,1) with non-zero mean : -12291.9\n",
      " ARIMA(3,0,0) with non-zero mean : -12281.24\n",
      " ARIMA(4,0,1) with non-zero mean : -12283.79\n",
      " ARIMA(2,0,0) with non-zero mean : -12284.01\n",
      " ARIMA(4,0,0) with non-zero mean : -12279.07\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -12293\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12304.9\n",
      " ARIMA(0,0,0) with non-zero mean : -7489.45\n",
      " ARIMA(1,0,0) with non-zero mean : -12294.5\n",
      " ARIMA(0,0,1) with non-zero mean : -9570.78\n",
      " ARIMA(0,0,0) with zero mean     : -7482.208\n",
      " ARIMA(1,0,2) with non-zero mean : -12292.56\n",
      " ARIMA(2,0,1) with non-zero mean : -12299.81\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12303.87\n",
      " ARIMA(1,0,1) with non-zero mean : -12294.41\n",
      " ARIMA(1,0,3) with non-zero mean : -12290.57\n",
      " ARIMA(3,0,1) with non-zero mean : -12303.05\n",
      " ARIMA(3,0,3) with non-zero mean : -12300.62\n",
      " ARIMA(2,0,2) with zero mean     : -12306.73\n",
      " ARIMA(1,0,2) with zero mean     : -12294.33\n",
      " ARIMA(2,0,1) with zero mean     : -12301.66\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -12305.7\n",
      " ARIMA(1,0,1) with zero mean     : -12296.18\n",
      " ARIMA(1,0,3) with zero mean     : -12292.33\n",
      " ARIMA(3,0,1) with zero mean     : -12304.74\n",
      " ARIMA(3,0,3) with zero mean     : -12302.28\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12305.7\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12296.47\n",
      " ARIMA(0,0,0) with non-zero mean : -7512.433\n",
      " ARIMA(1,0,0) with non-zero mean : -12293.41\n",
      " ARIMA(0,0,1) with non-zero mean : -9590.106\n",
      " ARIMA(0,0,0) with zero mean     : -7507.644\n",
      " ARIMA(1,0,2) with non-zero mean : -12291.22\n",
      " ARIMA(2,0,1) with non-zero mean : -12290.49\n",
      " ARIMA(3,0,2) with non-zero mean : -12349.06\n",
      " ARIMA(3,0,1) with non-zero mean : -12288.8\n",
      " ARIMA(4,0,2) with non-zero mean : -12302.23\n",
      " ARIMA(3,0,3) with non-zero mean : -12348.81\n",
      " ARIMA(2,0,3) with non-zero mean : -12290.13\n",
      " ARIMA(4,0,1) with non-zero mean : -12303.48\n",
      " ARIMA(4,0,3) with non-zero mean : -12301.4\n",
      " ARIMA(3,0,2) with zero mean     : -12350.91\n",
      " ARIMA(2,0,2) with zero mean     : -12291.96\n",
      " ARIMA(3,0,1) with zero mean     : -12304.11\n",
      " ARIMA(4,0,2) with zero mean     : -12304.06\n",
      " ARIMA(3,0,3) with zero mean     : -12350.67\n",
      " ARIMA(2,0,1) with zero mean     : -12292.34\n",
      " ARIMA(2,0,3) with zero mean     : -12291.95\n",
      " ARIMA(4,0,1) with zero mean     : -12305.28\n",
      " ARIMA(4,0,3) with zero mean     : -12303.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,1) with zero mean     : -12302.9\n",
      "\n",
      " Best model: ARIMA(4,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12294.73\n",
      " ARIMA(0,0,0) with non-zero mean : -7523.726\n",
      " ARIMA(1,0,0) with non-zero mean : -12282.66\n",
      " ARIMA(0,0,1) with non-zero mean : -9599.263\n",
      " ARIMA(0,0,0) with zero mean     : -7518.565\n",
      " ARIMA(1,0,2) with non-zero mean : -12280.27\n",
      " ARIMA(2,0,1) with non-zero mean : -12290.51\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12293.89\n",
      " ARIMA(1,0,1) with non-zero mean : -12282.22\n",
      " ARIMA(1,0,3) with non-zero mean : -12278.26\n",
      " ARIMA(3,0,1) with non-zero mean : -12292.79\n",
      " ARIMA(3,0,3) with non-zero mean : -12290.64\n",
      " ARIMA(2,0,2) with zero mean     : -12296.31\n",
      " ARIMA(1,0,2) with zero mean     : -12281.96\n",
      " ARIMA(2,0,1) with zero mean     : -12292.13\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -12295.48\n",
      " ARIMA(1,0,1) with zero mean     : -12283.92\n",
      " ARIMA(1,0,3) with zero mean     : -12279.96\n",
      " ARIMA(3,0,1) with zero mean     : -12294.58\n",
      " ARIMA(3,0,3) with zero mean     : -12292.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with zero mean     : -12292.19\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12310.49\n",
      " ARIMA(0,0,0) with non-zero mean : -7579.667\n",
      " ARIMA(1,0,0) with non-zero mean : -12312.78\n",
      " ARIMA(0,0,1) with non-zero mean : -9644.894\n",
      " ARIMA(0,0,0) with zero mean     : -7568.096\n",
      " ARIMA(2,0,0) with non-zero mean : -12313.95\n",
      " ARIMA(3,0,0) with non-zero mean : -12311.6\n",
      " ARIMA(2,0,1) with non-zero mean : -12311.94\n",
      " ARIMA(1,0,1) with non-zero mean : -12311.83\n",
      " ARIMA(3,0,1) with non-zero mean : -12308.85\n",
      " ARIMA(2,0,0) with zero mean     : -12315.33\n",
      " ARIMA(1,0,0) with zero mean     : -12314.23\n",
      " ARIMA(3,0,0) with zero mean     : -12312.98\n",
      " ARIMA(2,0,1) with zero mean     : -12313.26\n",
      " ARIMA(1,0,1) with zero mean     : -12313.27\n",
      " ARIMA(3,0,1) with zero mean     : -12310.2\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,0) with zero mean     : -12312.02\n",
      "\n",
      " Best model: ARIMA(2,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -7575.447\n",
      " ARIMA(1,0,0) with non-zero mean : -12376.55\n",
      " ARIMA(0,0,1) with non-zero mean : -9658.299\n",
      " ARIMA(0,0,0) with zero mean     : -7561.632\n",
      " ARIMA(2,0,0) with non-zero mean : -12375.94\n",
      " ARIMA(1,0,1) with non-zero mean : -12375.92\n",
      " ARIMA(2,0,1) with non-zero mean : -12393.48\n",
      " ARIMA(3,0,1) with non-zero mean : -12385.09\n",
      " ARIMA(1,0,2) with non-zero mean : -12374.8\n",
      " ARIMA(3,0,0) with non-zero mean : -12373.92\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -12395.1\n",
      " ARIMA(1,0,1) with zero mean     : -12377.4\n",
      " ARIMA(2,0,0) with zero mean     : -12377.45\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(2,0,2) with zero mean     : Inf\n",
      " ARIMA(1,0,0) with zero mean     : -12378.05\n",
      " ARIMA(1,0,2) with zero mean     : -12376.26\n",
      " ARIMA(3,0,0) with zero mean     : -12375.41\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with zero mean     : -12385.55\n",
      "\n",
      " Best model: ARIMA(2,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12383.96\n",
      " ARIMA(0,0,0) with non-zero mean : -7636.592\n",
      " ARIMA(1,0,0) with non-zero mean : -12385.34\n",
      " ARIMA(0,0,1) with non-zero mean : -9698.714\n",
      " ARIMA(0,0,0) with zero mean     : -7631.109\n",
      " ARIMA(2,0,0) with non-zero mean : -12387.27\n",
      " ARIMA(3,0,0) with non-zero mean : -12385.41\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(1,0,1) with non-zero mean : -12383.83\n",
      " ARIMA(3,0,1) with non-zero mean : -12396.18\n",
      " ARIMA(4,0,1) with non-zero mean : -12382.81\n",
      " ARIMA(3,0,2) with non-zero mean : -12395.78\n",
      " ARIMA(4,0,0) with non-zero mean : -12384.08\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -12389.8\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12386.98\n",
      " ARIMA(0,0,0) with non-zero mean : -7665.854\n",
      " ARIMA(1,0,0) with non-zero mean : -12379.12\n",
      " ARIMA(0,0,1) with non-zero mean : -9722.335\n",
      " ARIMA(0,0,0) with zero mean     : -7662.672\n",
      " ARIMA(1,0,2) with non-zero mean : -12376.91\n",
      " ARIMA(2,0,1) with non-zero mean : -12385.12\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -12385.91\n",
      " ARIMA(1,0,1) with non-zero mean : -12377.7\n",
      " ARIMA(1,0,3) with non-zero mean : -12375.44\n",
      " ARIMA(3,0,1) with non-zero mean : -12385.99\n",
      " ARIMA(3,0,3) with non-zero mean : -12396.33\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -12394.71\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -12398.09\n",
      " ARIMA(2,0,3) with zero mean     : -12387.69\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -12388.8\n",
      " ARIMA(2,0,4) with zero mean     : -12377.08\n",
      " ARIMA(4,0,2) with zero mean     : -12396.46\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with zero mean     : -12397.04\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "[1] \"40 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12372.1\n",
      " ARIMA(0,0,0) with non-zero mean : -7638.056\n",
      " ARIMA(1,0,0) with non-zero mean : -12367.87\n",
      " ARIMA(0,0,1) with non-zero mean : -9696.992\n",
      " ARIMA(0,0,0) with zero mean     : -7638.917\n",
      " ARIMA(1,0,2) with non-zero mean : -12365.83\n",
      " ARIMA(2,0,1) with non-zero mean : -12370.39\n",
      " ARIMA(3,0,2) with non-zero mean : -12376.09\n",
      " ARIMA(3,0,1) with non-zero mean : -12376.91\n",
      " ARIMA(3,0,0) with non-zero mean : -12364.17\n",
      " ARIMA(4,0,1) with non-zero mean : -12371.52\n",
      " ARIMA(2,0,0) with non-zero mean : -12365.48\n",
      " ARIMA(4,0,0) with non-zero mean : -12363.21\n",
      " ARIMA(4,0,2) with non-zero mean : -12384.24\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,1) with non-zero mean : -12363.16\n",
      " ARIMA(5,0,3) with non-zero mean : -12358.93\n",
      " ARIMA(4,0,2) with zero mean     : -12386.23\n",
      " ARIMA(3,0,2) with zero mean     : -12377.81\n",
      " ARIMA(4,0,1) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -12399.98\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -12386.19\n",
      "\n",
      " Best model: ARIMA(4,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12382.29\n",
      " ARIMA(0,0,0) with non-zero mean : -7629.492\n",
      " ARIMA(1,0,0) with non-zero mean : -12385.42\n",
      " ARIMA(0,0,1) with non-zero mean : -9699.086\n",
      " ARIMA(0,0,0) with zero mean     : -7630.842\n",
      " ARIMA(2,0,0) with non-zero mean : -12384.88\n",
      " ARIMA(1,0,1) with non-zero mean : -12384.14\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(1,0,0) with zero mean     : -12387.41\n",
      " ARIMA(2,0,0) with zero mean     : -12386.87\n",
      " ARIMA(1,0,1) with zero mean     : -12386.14\n",
      " ARIMA(0,0,1) with zero mean     : -9700.538\n",
      " ARIMA(2,0,1) with zero mean     : -12384.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,0) with zero mean     : -12386.2\n",
      "\n",
      " Best model: ARIMA(1,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12379.96\n",
      " ARIMA(0,0,0) with non-zero mean : -7632.211\n",
      " ARIMA(1,0,0) with non-zero mean : -12374.22\n",
      " ARIMA(0,0,1) with non-zero mean : -9700.155\n",
      " ARIMA(0,0,0) with zero mean     : -7634.093\n",
      " ARIMA(1,0,2) with non-zero mean : -12371.66\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -12387.1\n",
      " ARIMA(3,0,1) with non-zero mean : -12370.64\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12375.05\n",
      " ARIMA(2,0,3) with non-zero mean : -12382.17\n",
      " ARIMA(4,0,1) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -12424.22\n",
      " ARIMA(5,0,3) with non-zero mean : -12430.73\n",
      " ARIMA(5,0,2) with non-zero mean : -12370.49\n",
      " ARIMA(5,0,4) with non-zero mean : -12414.34\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : -12412.76\n",
      "\n",
      " Best model: ARIMA(5,0,4) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12372.17\n",
      " ARIMA(0,0,0) with non-zero mean : -7632.978\n",
      " ARIMA(1,0,0) with non-zero mean : -12362.63\n",
      " ARIMA(0,0,1) with non-zero mean : -9696.85\n",
      " ARIMA(0,0,0) with zero mean     : -7634.852\n",
      " ARIMA(1,0,2) with non-zero mean : -12359.87\n",
      " ARIMA(2,0,1) with non-zero mean : -12370.59\n",
      " ARIMA(3,0,2) with non-zero mean : -12380.13\n",
      " ARIMA(3,0,1) with non-zero mean : -12365.23\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12378.26\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,1) with non-zero mean : -12369.57\n",
      " ARIMA(4,0,3) with non-zero mean : -12413.15\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -12404.7\n",
      " ARIMA(3,0,4) with non-zero mean : -12380.06\n",
      " ARIMA(5,0,2) with non-zero mean : -12357.86\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -12415.18\n",
      " ARIMA(3,0,3) with zero mean     : -12380.26\n",
      " ARIMA(4,0,2) with zero mean     : -12379.48\n",
      " ARIMA(5,0,3) with zero mean     : -12402.01\n",
      " ARIMA(4,0,4) with zero mean     : -12404.73\n",
      " ARIMA(3,0,2) with zero mean     : -12382.14\n",
      " ARIMA(3,0,4) with zero mean     : -12382.08\n",
      " ARIMA(5,0,2) with zero mean     : -12359.88\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -12381.67\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12370.68\n",
      " ARIMA(0,0,0) with non-zero mean : -7632.239\n",
      " ARIMA(1,0,0) with non-zero mean : -12374.84\n",
      " ARIMA(0,0,1) with non-zero mean : -9694.237\n",
      " ARIMA(0,0,0) with zero mean     : -7634.062\n",
      " ARIMA(2,0,0) with non-zero mean : -12372.61\n",
      " ARIMA(1,0,1) with non-zero mean : -12373.2\n",
      " ARIMA(2,0,1) with non-zero mean : -12370.81\n",
      " ARIMA(1,0,0) with zero mean     : -12376.82\n",
      " ARIMA(2,0,0) with zero mean     : -12374.6\n",
      " ARIMA(1,0,1) with zero mean     : -12375.19\n",
      " ARIMA(0,0,1) with zero mean     : -9696.14\n",
      " ARIMA(2,0,1) with zero mean     : -12372.8\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,0) with zero mean     : -12374.11\n",
      "\n",
      " Best model: ARIMA(1,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12380.54\n",
      " ARIMA(0,0,0) with non-zero mean : -7616.551\n",
      " ARIMA(1,0,0) with non-zero mean : -12374.77\n",
      " ARIMA(0,0,1) with non-zero mean : -9683.817\n",
      " ARIMA(0,0,0) with zero mean     : -7618.513\n",
      " ARIMA(1,0,2) with non-zero mean : -12371.59\n",
      " ARIMA(2,0,1) with non-zero mean : -12379.25\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(1,0,1) with non-zero mean : -12373.11\n",
      " ARIMA(1,0,3) with non-zero mean : -12370.14\n",
      " ARIMA(3,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12386.46\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -12385\n",
      " ARIMA(2,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -12393.23\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : -12407.97\n",
      " ARIMA(3,0,5) with non-zero mean : -12418.55\n",
      " ARIMA(2,0,5) with non-zero mean : -12380.2\n",
      " ARIMA(3,0,5) with zero mean     : -12420.47\n",
      " ARIMA(2,0,5) with zero mean     : -12382.22\n",
      " ARIMA(3,0,4) with zero mean     : -12391.04\n",
      " ARIMA(4,0,5) with zero mean     : -12409.98\n",
      " ARIMA(2,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : -12395\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with zero mean     : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -12394.39\n",
      "\n",
      " Best model: ARIMA(3,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -7593.37\n",
      " ARIMA(1,0,0) with non-zero mean : -12357.29\n",
      " ARIMA(0,0,1) with non-zero mean : -9659.48\n",
      " ARIMA(0,0,0) with zero mean     : -7594.572\n",
      " ARIMA(2,0,0) with non-zero mean : -12355.13\n",
      " ARIMA(1,0,1) with non-zero mean : -12355.44\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(1,0,0) with zero mean     : -12359.26\n",
      " ARIMA(2,0,0) with zero mean     : -12357.09\n",
      " ARIMA(1,0,1) with zero mean     : -12357.41\n",
      " ARIMA(0,0,1) with zero mean     : -9660.873\n",
      " ARIMA(2,0,1) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,0) with zero mean     : -12357.88\n",
      "\n",
      " Best model: ARIMA(1,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12358.85\n",
      " ARIMA(0,0,0) with non-zero mean : -7612.88\n",
      " ARIMA(1,0,0) with non-zero mean : -12352.73\n",
      " ARIMA(0,0,1) with non-zero mean : -9667.962\n",
      " ARIMA(0,0,0) with zero mean     : -7614.768\n",
      " ARIMA(1,0,2) with non-zero mean : -12349.17\n",
      " ARIMA(2,0,1) with non-zero mean : -12359.18\n",
      " ARIMA(1,0,1) with non-zero mean : -12350.72\n",
      " ARIMA(2,0,0) with non-zero mean : -12349.76\n",
      " ARIMA(3,0,1) with non-zero mean : -12352.18\n",
      " ARIMA(3,0,0) with non-zero mean : -12348.2\n",
      " ARIMA(3,0,2) with non-zero mean : -12402.73\n",
      " ARIMA(4,0,2) with non-zero mean : -12357.4\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,1) with non-zero mean : -12353.57\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -12403.67\n",
      " ARIMA(2,0,2) with zero mean     : -12360.86\n",
      " ARIMA(3,0,1) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -12359.45\n",
      " ARIMA(3,0,3) with zero mean     : -12405.32\n",
      " ARIMA(2,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -12404.75\n",
      " ARIMA(2,0,4) with zero mean     : -12351.32\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -12360.99\n",
      "\n",
      " Best model: ARIMA(2,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12245.28\n",
      " ARIMA(0,0,0) with non-zero mean : -7579.394\n",
      " ARIMA(1,0,0) with non-zero mean : -12250.31\n",
      " ARIMA(0,0,1) with non-zero mean : -9614.418\n",
      " ARIMA(0,0,0) with zero mean     : -7580.618\n",
      " ARIMA(2,0,0) with non-zero mean : -12248.88\n",
      " ARIMA(1,0,1) with non-zero mean : -12248.42\n",
      " ARIMA(2,0,1) with non-zero mean : -12247.28\n",
      " ARIMA(1,0,0) with zero mean     : -12252.25\n",
      " ARIMA(2,0,0) with zero mean     : -12250.84\n",
      " ARIMA(1,0,1) with zero mean     : -12250.37\n",
      " ARIMA(0,0,1) with zero mean     : -9615.668\n",
      " ARIMA(2,0,1) with zero mean     : -12249.09\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,0) with zero mean     : -12249.31\n",
      "\n",
      " Best model: ARIMA(1,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11918.13\n",
      " ARIMA(0,0,0) with non-zero mean : -7093.706\n",
      " ARIMA(1,0,0) with non-zero mean : -11917.05\n",
      " ARIMA(0,0,1) with non-zero mean : -9189.946\n",
      " ARIMA(0,0,0) with zero mean     : -7089.844\n",
      " ARIMA(1,0,2) with non-zero mean : -11919.1\n",
      " ARIMA(0,0,2) with non-zero mean : -10255.34\n",
      " ARIMA(1,0,1) with non-zero mean : -11919.47\n",
      " ARIMA(2,0,1) with non-zero mean : -11926.69\n",
      " ARIMA(2,0,0) with non-zero mean : -11918.19\n",
      " ARIMA(3,0,1) with non-zero mean : -11918.52\n",
      " ARIMA(3,0,0) with non-zero mean : -11918.52\n",
      " ARIMA(3,0,2) with non-zero mean : -11964.9\n",
      " ARIMA(4,0,2) with non-zero mean : -11921.13\n",
      " ARIMA(3,0,3) with non-zero mean : -11919.65\n",
      " ARIMA(2,0,3) with non-zero mean : -11921.89\n",
      " ARIMA(4,0,1) with non-zero mean : -11922.48\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11965.73\n",
      " ARIMA(2,0,2) with zero mean     : -11919.78\n",
      " ARIMA(3,0,1) with zero mean     : -11920.19\n",
      " ARIMA(4,0,2) with zero mean     : -11922.77\n",
      " ARIMA(3,0,3) with zero mean     : -11921.72\n",
      " ARIMA(2,0,1) with zero mean     : -11928.33\n",
      " ARIMA(2,0,3) with zero mean     : -11923.53\n",
      " ARIMA(4,0,1) with zero mean     : -11924.09\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11982.88\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11592.45\n",
      " ARIMA(0,1,0) with drift         : -11555.24\n",
      " ARIMA(1,1,0) with drift         : -11572.02\n",
      " ARIMA(0,1,1) with drift         : -11577.1\n",
      " ARIMA(0,1,0)                    : -11557.22\n",
      " ARIMA(1,1,2) with drift         : -11589.93\n",
      " ARIMA(2,1,1) with drift         : -11592.45\n",
      " ARIMA(1,1,1) with drift         : -11581.25\n",
      " ARIMA(2,1,0) with drift         : -11591.47\n",
      " ARIMA(3,1,1) with drift         : -11590.91\n",
      " ARIMA(3,1,0) with drift         : -11592.77\n",
      " ARIMA(4,1,0) with drift         : -11594.37\n",
      " ARIMA(5,1,0) with drift         : -11597.15\n",
      " ARIMA(5,1,1) with drift         : -11624.61\n",
      " ARIMA(4,1,1) with drift         : -11595.39\n",
      " ARIMA(5,1,2) with drift         : -11634.3\n",
      " ARIMA(4,1,2) with drift         : -11650.69\n",
      " ARIMA(3,1,2) with drift         : -11589.14\n",
      " ARIMA(4,1,3) with drift         : -11594.46\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(5,1,3) with drift         : -11642.34\n",
      " ARIMA(4,1,2)                    : -11652.57\n",
      " ARIMA(3,1,2)                    : -11591.12\n",
      " ARIMA(4,1,1)                    : -11597.4\n",
      " ARIMA(5,1,2)                    : -11636.3\n",
      " ARIMA(4,1,3)                    : -11596.53\n",
      " ARIMA(3,1,1)                    : -11592.9\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(5,1,1)                    : Inf\n",
      " ARIMA(5,1,3)                    : -11644.74\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(5,1,3)                    : Inf\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(5,1,2)                    : Inf\n",
      " ARIMA(5,1,2) with drift         : Inf\n",
      " ARIMA(5,1,1) with drift         : -11640.1\n",
      "\n",
      " Best model: ARIMA(5,1,1) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11415.47\n",
      " ARIMA(0,1,0) with drift         : -11362.54\n",
      " ARIMA(1,1,0) with drift         : -11389.78\n",
      " ARIMA(0,1,1) with drift         : -11394.48\n",
      " ARIMA(0,1,0)                    : -11364.55\n",
      " ARIMA(1,1,2) with drift         : -11409.16\n",
      " ARIMA(2,1,1) with drift         : -11412.81\n",
      " ARIMA(3,1,2) with drift         : -11412.71\n",
      " ARIMA(2,1,3) with drift         : -11413.64\n",
      " ARIMA(1,1,1) with drift         : -11398.6\n",
      " ARIMA(1,1,3) with drift         : -11410.51\n",
      " ARIMA(3,1,1) with drift         : -11412.09\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11417.47\n",
      " ARIMA(1,1,2)                    : -11411.16\n",
      " ARIMA(2,1,1)                    : -11414.81\n",
      " ARIMA(3,1,2)                    : -11414.69\n",
      " ARIMA(2,1,3)                    : -11415.64\n",
      " ARIMA(1,1,1)                    : -11400.6\n",
      " ARIMA(1,1,3)                    : -11412.52\n",
      " ARIMA(3,1,1)                    : -11414.08\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11425.36\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11353.65\n",
      " ARIMA(0,1,0) with drift         : -11294.89\n",
      " ARIMA(1,1,0) with drift         : -11324.01\n",
      " ARIMA(0,1,1) with drift         : -11330.99\n",
      " ARIMA(0,1,0)                    : -11296.89\n",
      " ARIMA(1,1,2) with drift         : -11345.36\n",
      " ARIMA(2,1,1) with drift         : -11350.29\n",
      " ARIMA(3,1,2) with drift         : -11350.17\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11334.27\n",
      " ARIMA(1,1,3) with drift         : -11347.22\n",
      " ARIMA(3,1,1) with drift         : -11349.78\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11355.66\n",
      " ARIMA(1,1,2)                    : -11347.37\n",
      " ARIMA(2,1,1)                    : -11352.3\n",
      " ARIMA(3,1,2)                    : -11352.16\n",
      " ARIMA(2,1,3)                    : -11353.71\n",
      " ARIMA(1,1,1)                    : -11336.27\n",
      " ARIMA(1,1,3)                    : -11349.22\n",
      " ARIMA(3,1,1)                    : -11351.79\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11365.31\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11320.7\n",
      " ARIMA(0,1,0) with drift         : -11261.92\n",
      " ARIMA(1,1,0) with drift         : -11289.31\n",
      " ARIMA(0,1,1) with drift         : -11296.15\n",
      " ARIMA(0,1,0)                    : -11263.9\n",
      " ARIMA(1,1,2) with drift         : -11312.32\n",
      " ARIMA(2,1,1) with drift         : -11317.17\n",
      " ARIMA(3,1,2) with drift         : -11317.32\n",
      " ARIMA(2,1,3) with drift         : -11318.7\n",
      " ARIMA(1,1,1) with drift         : -11299.93\n",
      " ARIMA(1,1,3) with drift         : -11314.09\n",
      " ARIMA(3,1,1) with drift         : -11316.82\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11322.69\n",
      " ARIMA(1,1,2)                    : -11314.3\n",
      " ARIMA(2,1,1)                    : -11319.15\n",
      " ARIMA(3,1,2)                    : -11319.28\n",
      " ARIMA(2,1,3)                    : -11320.61\n",
      " ARIMA(1,1,1)                    : -11301.9\n",
      " ARIMA(1,1,3)                    : -11316.07\n",
      " ARIMA(3,1,1)                    : -11318.8\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11331.48\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11266.31\n",
      " ARIMA(0,1,0) with drift         : -11205.21\n",
      " ARIMA(1,1,0) with drift         : -11233.03\n",
      " ARIMA(0,1,1) with drift         : -11240.17\n",
      " ARIMA(0,1,0)                    : -11207.21\n",
      " ARIMA(1,1,2) with drift         : -11254.87\n",
      " ARIMA(2,1,1) with drift         : -11261.21\n",
      " ARIMA(3,1,2) with drift         : -11262.81\n",
      " ARIMA(2,1,3) with drift         : -11264.32\n",
      " ARIMA(1,1,1) with drift         : -11242.56\n",
      " ARIMA(1,1,3) with drift         : -11258.05\n",
      " ARIMA(3,1,1) with drift         : -11262.14\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11268.32\n",
      " ARIMA(1,1,2)                    : -11256.88\n",
      " ARIMA(2,1,1)                    : -11263.21\n",
      " ARIMA(3,1,2)                    : -11264.84\n",
      " ARIMA(2,1,3)                    : -11266.33\n",
      " ARIMA(1,1,1)                    : -11244.57\n",
      " ARIMA(1,1,3)                    : -11260.06\n",
      " ARIMA(3,1,1)                    : -11264.14\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11277.31\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11262.05\n",
      " ARIMA(0,1,0) with drift         : -11192.23\n",
      " ARIMA(1,1,0) with drift         : -11226.71\n",
      " ARIMA(0,1,1) with drift         : -11231.46\n",
      " ARIMA(0,1,0)                    : -11194.21\n",
      " ARIMA(1,1,2) with drift         : -11247.34\n",
      " ARIMA(2,1,1) with drift         : -11252.98\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11305.6\n",
      " ARIMA(1,1,3) with drift         : -11251.68\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : -11261.91\n",
      " ARIMA(1,1,4) with drift         : -11257.86\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11307.46\n",
      " ARIMA(1,1,3)                    : -11253.67\n",
      " ARIMA(2,1,2)                    : -11264.03\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : -11263.89\n",
      " ARIMA(1,1,2)                    : -11249.32\n",
      " ARIMA(1,1,4)                    : -11259.86\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,4)                    : -11294.48\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(2,1,2)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(2,1,2) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4)                    : -11267.25\n",
      "\n",
      " Best model: ARIMA(1,1,4)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11328.07\n",
      " ARIMA(0,0,0) with non-zero mean : -6737.816\n",
      " ARIMA(1,0,0) with non-zero mean : -11296.4\n",
      " ARIMA(0,0,1) with non-zero mean : -8758.488\n",
      " ARIMA(0,0,0) with zero mean     : -6726.062\n",
      " ARIMA(1,0,2) with non-zero mean : -11320.74\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11400.22\n",
      " ARIMA(3,0,1) with non-zero mean : -11334.05\n",
      " ARIMA(4,0,2) with non-zero mean : -11349.24\n",
      " ARIMA(3,0,3) with non-zero mean : -11349.61\n",
      " ARIMA(2,0,3) with non-zero mean : -11343.52\n",
      " ARIMA(4,0,1) with non-zero mean : -11346.17\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11401.72\n",
      " ARIMA(2,0,2) with zero mean     : -11329.9\n",
      " ARIMA(3,0,1) with zero mean     : -11335.87\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11351.36\n",
      " ARIMA(2,0,1) with zero mean     : -11314.01\n",
      " ARIMA(2,0,3) with zero mean     : -11345.27\n",
      " ARIMA(4,0,1) with zero mean     : -11347.94\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11350.88\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11324.39\n",
      " ARIMA(0,0,0) with non-zero mean : -6739.838\n",
      " ARIMA(1,0,0) with non-zero mean : -11291.47\n",
      " ARIMA(0,0,1) with non-zero mean : -8753.561\n",
      " ARIMA(0,0,0) with zero mean     : -6728.901\n",
      " ARIMA(1,0,2) with non-zero mean : -11317.24\n",
      " ARIMA(2,0,1) with non-zero mean : -11314.87\n",
      " ARIMA(3,0,2) with non-zero mean : -11397.8\n",
      " ARIMA(3,0,1) with non-zero mean : -11330.92\n",
      " ARIMA(4,0,2) with non-zero mean : -11345.12\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11338.13\n",
      " ARIMA(4,0,1) with non-zero mean : -11342.03\n",
      " ARIMA(4,0,3) with non-zero mean : -11399.92\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11398.25\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11401.72\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11346.63\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11399.42\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11405.72\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11314.12\n",
      " ARIMA(0,0,0) with non-zero mean : -6723.367\n",
      " ARIMA(1,0,0) with non-zero mean : -11283.77\n",
      " ARIMA(0,0,1) with non-zero mean : -8741.907\n",
      " ARIMA(0,0,0) with zero mean     : -6711.968\n",
      " ARIMA(1,0,2) with non-zero mean : -11307.4\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11381.18\n",
      " ARIMA(3,0,1) with non-zero mean : -11320.77\n",
      " ARIMA(4,0,2) with non-zero mean : -11332\n",
      " ARIMA(3,0,3) with non-zero mean : -11332.98\n",
      " ARIMA(2,0,3) with non-zero mean : -11328.13\n",
      " ARIMA(4,0,1) with non-zero mean : -11331.31\n",
      " ARIMA(4,0,3) with non-zero mean : -11383.32\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11382.31\n",
      " ARIMA(3,0,4) with non-zero mean : -11359.17\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11384.72\n",
      " ARIMA(3,0,3) with zero mean     : -11334.68\n",
      " ARIMA(4,0,2) with zero mean     : -11333.85\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11382.66\n",
      " ARIMA(3,0,4) with zero mean     : -11360.21\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with zero mean     : -11440.78\n",
      " ARIMA(5,0,5) with zero mean     : -11456.27\n",
      " ARIMA(4,0,5) with zero mean     : Inf\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,5) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11396.91\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11305.83\n",
      " ARIMA(0,0,0) with non-zero mean : -6670.167\n",
      " ARIMA(1,0,0) with non-zero mean : -11278.25\n",
      " ARIMA(0,0,1) with non-zero mean : -8697.836\n",
      " ARIMA(0,0,0) with zero mean     : -6663.345\n",
      " ARIMA(1,0,2) with non-zero mean : -11300.93\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11382.19\n",
      " ARIMA(3,0,1) with non-zero mean : -11312.28\n",
      " ARIMA(4,0,2) with non-zero mean : -11324.03\n",
      " ARIMA(3,0,3) with non-zero mean : -11324.58\n",
      " ARIMA(2,0,3) with non-zero mean : -11320.3\n",
      " ARIMA(4,0,1) with non-zero mean : -11323.14\n",
      " ARIMA(4,0,3) with non-zero mean : -11382.62\n",
      " ARIMA(5,0,3) with non-zero mean : -11391.42\n",
      " ARIMA(5,0,2) with non-zero mean : -11375.24\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11388.66\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11299.77\n",
      " ARIMA(0,0,0) with non-zero mean : -6664.974\n",
      " ARIMA(1,0,0) with non-zero mean : -11273.07\n",
      " ARIMA(0,0,1) with non-zero mean : -8693.479\n",
      " ARIMA(0,0,0) with zero mean     : -6658.911\n",
      " ARIMA(1,0,2) with non-zero mean : -11295.08\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11384.49\n",
      " ARIMA(3,0,1) with non-zero mean : -11305.45\n",
      " ARIMA(4,0,2) with non-zero mean : -11318.63\n",
      " ARIMA(3,0,3) with non-zero mean : -11318.26\n",
      " ARIMA(2,0,3) with non-zero mean : -11313.84\n",
      " ARIMA(4,0,1) with non-zero mean : -11316.33\n",
      " ARIMA(4,0,3) with non-zero mean : -11379.31\n",
      " ARIMA(3,0,2) with zero mean     : -11386.24\n",
      " ARIMA(2,0,2) with zero mean     : -11301.64\n",
      " ARIMA(3,0,1) with zero mean     : -11307.33\n",
      " ARIMA(4,0,2) with zero mean     : -11320.49\n",
      " ARIMA(3,0,3) with zero mean     : -11320.1\n",
      " ARIMA(2,0,1) with zero mean     : -11294.37\n",
      " ARIMA(2,0,3) with zero mean     : -11315.67\n",
      " ARIMA(4,0,1) with zero mean     : -11318.18\n",
      " ARIMA(4,0,3) with zero mean     : -11381.1\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11385.3\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11310.13\n",
      " ARIMA(0,0,0) with non-zero mean : -6682.719\n",
      " ARIMA(1,0,0) with non-zero mean : -11283.7\n",
      " ARIMA(0,0,1) with non-zero mean : -8709.728\n",
      " ARIMA(0,0,0) with zero mean     : -6679.951\n",
      " ARIMA(1,0,2) with non-zero mean : -11305.28\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11394.4\n",
      " ARIMA(3,0,1) with non-zero mean : -11315.74\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11324.19\n",
      " ARIMA(4,0,1) with non-zero mean : -11326.94\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : -11394.4\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11318.53\n",
      " ARIMA(0,0,0) with non-zero mean : -6684.289\n",
      " ARIMA(1,0,0) with non-zero mean : -11291.02\n",
      " ARIMA(0,0,1) with non-zero mean : -8709.777\n",
      " ARIMA(0,0,0) with zero mean     : -6682.252\n",
      " ARIMA(1,0,2) with non-zero mean : -11313.56\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11407.09\n",
      " ARIMA(3,0,1) with non-zero mean : -11326.07\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -11411.55\n",
      " ARIMA(2,0,3) with non-zero mean : -11332.96\n",
      " ARIMA(4,0,3) with non-zero mean : -11406.01\n",
      " ARIMA(3,0,4) with non-zero mean : -11393.61\n",
      " ARIMA(2,0,4) with non-zero mean : -11372\n",
      " ARIMA(4,0,4) with non-zero mean : -11408.79\n",
      " ARIMA(3,0,3) with zero mean     : -11413.52\n",
      " ARIMA(2,0,3) with zero mean     : -11334.9\n",
      " ARIMA(3,0,2) with zero mean     : -11409.07\n",
      " ARIMA(4,0,3) with zero mean     : -11407.69\n",
      " ARIMA(3,0,4) with zero mean     : -11393.81\n",
      " ARIMA(2,0,2) with zero mean     : -11320.49\n",
      " ARIMA(2,0,4) with zero mean     : -11373.96\n",
      " ARIMA(4,0,2) with zero mean     : -11342.57\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11404.21\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11332.95\n",
      " ARIMA(0,0,0) with non-zero mean : -6690.754\n",
      " ARIMA(1,0,0) with non-zero mean : -11305.57\n",
      " ARIMA(0,0,1) with non-zero mean : -8717.595\n",
      " ARIMA(0,0,0) with zero mean     : -6690.452\n",
      " ARIMA(1,0,2) with non-zero mean : -11328.33\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11416.47\n",
      " ARIMA(3,0,1) with non-zero mean : -11342.34\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -11418.63\n",
      " ARIMA(2,0,3) with non-zero mean : -11348.62\n",
      " ARIMA(4,0,3) with non-zero mean : -11414.74\n",
      " ARIMA(3,0,4) with non-zero mean : -11416.61\n",
      " ARIMA(2,0,4) with non-zero mean : -11388.3\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11420.66\n",
      " ARIMA(2,0,3) with zero mean     : -11350.61\n",
      " ARIMA(3,0,2) with zero mean     : -11418.51\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -11418.65\n",
      " ARIMA(2,0,2) with zero mean     : -11334.95\n",
      " ARIMA(2,0,4) with zero mean     : -11390.32\n",
      " ARIMA(4,0,2) with zero mean     : -11357.1\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11415.5\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "[1] \"50 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11356.17\n",
      " ARIMA(0,0,0) with non-zero mean : -6690.499\n",
      " ARIMA(1,0,0) with non-zero mean : -11329.91\n",
      " ARIMA(0,0,1) with non-zero mean : -8719.031\n",
      " ARIMA(0,0,0) with zero mean     : -6690.897\n",
      " ARIMA(1,0,2) with non-zero mean : -11352.13\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11428.68\n",
      " ARIMA(3,0,1) with non-zero mean : -11362.48\n",
      " ARIMA(4,0,2) with non-zero mean : -11375.33\n",
      " ARIMA(3,0,3) with non-zero mean : -11375.66\n",
      " ARIMA(2,0,3) with non-zero mean : -11371.34\n",
      " ARIMA(4,0,1) with non-zero mean : -11374.63\n",
      " ARIMA(4,0,3) with non-zero mean : -11431.51\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11412.53\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11433.45\n",
      " ARIMA(3,0,3) with zero mean     : -11377.55\n",
      " ARIMA(4,0,2) with zero mean     : -11376.63\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11430.46\n",
      " ARIMA(3,0,4) with zero mean     : -11376.2\n",
      " ARIMA(5,0,2) with zero mean     : -11414.43\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -11432.83\n",
      "\n",
      " Best model: ARIMA(4,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11368.76\n",
      " ARIMA(0,0,0) with non-zero mean : -6688.274\n",
      " ARIMA(1,0,0) with non-zero mean : -11342.11\n",
      " ARIMA(0,0,1) with non-zero mean : -8719.819\n",
      " ARIMA(0,0,0) with zero mean     : -6687.667\n",
      " ARIMA(1,0,2) with non-zero mean : -11363.98\n",
      " ARIMA(2,0,1) with non-zero mean : -11362.28\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11383.19\n",
      " ARIMA(1,0,3) with non-zero mean : -11385.67\n",
      " ARIMA(0,0,3) with non-zero mean : -10195.6\n",
      " ARIMA(1,0,4) with non-zero mean : -11384.18\n",
      " ARIMA(0,0,2) with non-zero mean : -9651.636\n",
      " ARIMA(0,0,4) with non-zero mean : -10619.64\n",
      " ARIMA(2,0,4) with non-zero mean : -11413.52\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11423.72\n",
      " ARIMA(1,0,5) with non-zero mean : -11388.13\n",
      " ARIMA(3,0,5) with non-zero mean : -11416.08\n",
      " ARIMA(2,0,5) with zero mean     : -11425.66\n",
      " ARIMA(1,0,5) with zero mean     : -11390.15\n",
      " ARIMA(2,0,4) with zero mean     : -11415.42\n",
      " ARIMA(3,0,5) with zero mean     : -11418.12\n",
      " ARIMA(1,0,4) with zero mean     : -11386.19\n",
      " ARIMA(3,0,4) with zero mean     : -11485.51\n",
      " ARIMA(3,0,3) with zero mean     : -11390.06\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -11385.19\n",
      " ARIMA(4,0,3) with zero mean     : -11445.33\n",
      " ARIMA(4,0,5) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,5) with zero mean     : -11430.84\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11379.91\n",
      " ARIMA(0,0,0) with non-zero mean : -6735.304\n",
      " ARIMA(1,0,0) with non-zero mean : -11354.43\n",
      " ARIMA(0,0,1) with non-zero mean : -8758.988\n",
      " ARIMA(0,0,0) with zero mean     : -6737.172\n",
      " ARIMA(1,0,2) with non-zero mean : -11375.63\n",
      " ARIMA(2,0,1) with non-zero mean : -11373.84\n",
      " ARIMA(3,0,2) with non-zero mean : -11461.55\n",
      " ARIMA(3,0,1) with non-zero mean : -11386.02\n",
      " ARIMA(4,0,2) with non-zero mean : -11400.26\n",
      " ARIMA(3,0,3) with non-zero mean : -11400.01\n",
      " ARIMA(2,0,3) with non-zero mean : -11395.61\n",
      " ARIMA(4,0,1) with non-zero mean : -11398.44\n",
      " ARIMA(4,0,3) with non-zero mean : -11457.4\n",
      " ARIMA(3,0,2) with zero mean     : -11463.57\n",
      " ARIMA(2,0,2) with zero mean     : -11381.74\n",
      " ARIMA(3,0,1) with zero mean     : -11388.02\n",
      " ARIMA(4,0,2) with zero mean     : -11402.26\n",
      " ARIMA(3,0,3) with zero mean     : -11402.03\n",
      " ARIMA(2,0,1) with zero mean     : -11375.86\n",
      " ARIMA(2,0,3) with zero mean     : -11397.63\n",
      " ARIMA(4,0,1) with zero mean     : -11400.45\n",
      " ARIMA(4,0,3) with zero mean     : -11459.4\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11399.38\n",
      "\n",
      " Best model: ARIMA(4,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11418.83\n",
      " ARIMA(0,0,0) with non-zero mean : -6770.192\n",
      " ARIMA(1,0,0) with non-zero mean : -11389.52\n",
      " ARIMA(0,0,1) with non-zero mean : -8798.915\n",
      " ARIMA(0,0,0) with zero mean     : -6772.157\n",
      " ARIMA(1,0,2) with non-zero mean : -11413.24\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11497.24\n",
      " ARIMA(3,0,1) with non-zero mean : -11425.94\n",
      " ARIMA(4,0,2) with non-zero mean : -11440.64\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11432.73\n",
      " ARIMA(4,0,1) with non-zero mean : -11439.86\n",
      " ARIMA(4,0,3) with non-zero mean : -11482.5\n",
      " ARIMA(3,0,2) with zero mean     : -11499.25\n",
      " ARIMA(2,0,2) with zero mean     : -11420.85\n",
      " ARIMA(3,0,1) with zero mean     : -11427.95\n",
      " ARIMA(4,0,2) with zero mean     : -11442.65\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -11434.74\n",
      " ARIMA(4,0,1) with zero mean     : -11441.87\n",
      " ARIMA(4,0,3) with zero mean     : -11484.67\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11438.64\n",
      "\n",
      " Best model: ARIMA(4,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11414.32\n",
      " ARIMA(0,0,0) with non-zero mean : -6776.125\n",
      " ARIMA(1,0,0) with non-zero mean : -11387.21\n",
      " ARIMA(0,0,1) with non-zero mean : -8799.227\n",
      " ARIMA(0,0,0) with zero mean     : -6777.222\n",
      " ARIMA(1,0,2) with non-zero mean : -11409.82\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11486.69\n",
      " ARIMA(3,0,1) with non-zero mean : -11419.62\n",
      " ARIMA(4,0,2) with non-zero mean : -11432.54\n",
      " ARIMA(3,0,3) with non-zero mean : -11432.11\n",
      " ARIMA(2,0,3) with non-zero mean : -11428.57\n",
      " ARIMA(4,0,1) with non-zero mean : -11432.22\n",
      " ARIMA(4,0,3) with non-zero mean : -11426.07\n",
      " ARIMA(3,0,2) with zero mean     : -11488.4\n",
      " ARIMA(2,0,2) with zero mean     : -11416.24\n",
      " ARIMA(3,0,1) with zero mean     : -11421.53\n",
      " ARIMA(4,0,2) with zero mean     : -11434.45\n",
      " ARIMA(3,0,3) with zero mean     : -11434.02\n",
      " ARIMA(2,0,1) with zero mean     : Inf\n",
      " ARIMA(2,0,3) with zero mean     : -11430.48\n",
      " ARIMA(4,0,1) with zero mean     : -11434.15\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11433.84\n",
      "\n",
      " Best model: ARIMA(4,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11396.28\n",
      " ARIMA(0,0,0) with non-zero mean : -6767.655\n",
      " ARIMA(1,0,0) with non-zero mean : -11366.24\n",
      " ARIMA(0,0,1) with non-zero mean : -8786.68\n",
      " ARIMA(0,0,0) with zero mean     : -6768.269\n",
      " ARIMA(1,0,2) with non-zero mean : -11391.4\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11410.85\n",
      " ARIMA(1,0,3) with non-zero mean : -11413.2\n",
      " ARIMA(0,0,3) with non-zero mean : -10241.8\n",
      " ARIMA(1,0,4) with non-zero mean : -11411.5\n",
      " ARIMA(0,0,2) with non-zero mean : -9706.747\n",
      " ARIMA(0,0,4) with non-zero mean : -10664.67\n",
      " ARIMA(2,0,4) with non-zero mean : -11450.27\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11458.58\n",
      " ARIMA(1,0,5) with non-zero mean : -11415.38\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with zero mean     : -11460.53\n",
      " ARIMA(1,0,5) with zero mean     : -11417.36\n",
      " ARIMA(2,0,4) with zero mean     : -11452.21\n",
      " ARIMA(3,0,5) with zero mean     : -11458.99\n",
      " ARIMA(1,0,4) with zero mean     : -11413.48\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,5) with zero mean     : -11459.53\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11379.85\n",
      " ARIMA(0,0,0) with non-zero mean : -6769.06\n",
      " ARIMA(1,0,0) with non-zero mean : -11350.52\n",
      " ARIMA(0,0,1) with non-zero mean : -8784.121\n",
      " ARIMA(0,0,0) with zero mean     : -6770.196\n",
      " ARIMA(1,0,2) with non-zero mean : -11374.77\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11440.14\n",
      " ARIMA(3,0,1) with non-zero mean : -11385.46\n",
      " ARIMA(4,0,2) with non-zero mean : -11398.72\n",
      " ARIMA(3,0,3) with non-zero mean : -11399.1\n",
      " ARIMA(2,0,3) with non-zero mean : -11395.62\n",
      " ARIMA(4,0,1) with non-zero mean : -11397.24\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11442.2\n",
      " ARIMA(2,0,2) with zero mean     : -11381.87\n",
      " ARIMA(3,0,1) with zero mean     : -11387.48\n",
      " ARIMA(4,0,2) with zero mean     : -11400.7\n",
      " ARIMA(3,0,3) with zero mean     : -11401.11\n",
      " ARIMA(2,0,1) with zero mean     : -11375.84\n",
      " ARIMA(2,0,3) with zero mean     : -11397.63\n",
      " ARIMA(4,0,1) with zero mean     : -11399.24\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11400.25\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11368.58\n",
      " ARIMA(0,0,0) with non-zero mean : -6755.177\n",
      " ARIMA(1,0,0) with non-zero mean : -11340.91\n",
      " ARIMA(0,0,1) with non-zero mean : -8775.252\n",
      " ARIMA(0,0,0) with zero mean     : -6756.647\n",
      " ARIMA(1,0,2) with non-zero mean : -11363.4\n",
      " ARIMA(2,0,1) with non-zero mean : -11362.12\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11383.49\n",
      " ARIMA(1,0,3) with non-zero mean : -11385.66\n",
      " ARIMA(0,0,3) with non-zero mean : -10228.52\n",
      " ARIMA(1,0,4) with non-zero mean : -11383.84\n",
      " ARIMA(0,0,2) with non-zero mean : -9695.095\n",
      " ARIMA(0,0,4) with non-zero mean : -10649.52\n",
      " ARIMA(2,0,4) with non-zero mean : -11413.73\n",
      " ARIMA(3,0,4) with non-zero mean : -11467.64\n",
      " ARIMA(3,0,3) with non-zero mean : -11386.95\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : -11449.17\n",
      " ARIMA(2,0,5) with non-zero mean : -11419.96\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -11459.53\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11424.77\n",
      "\n",
      " Best model: ARIMA(2,0,5) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11384.56\n",
      " ARIMA(0,0,0) with non-zero mean : -6817.572\n",
      " ARIMA(1,0,0) with non-zero mean : -11356.29\n",
      " ARIMA(0,0,1) with non-zero mean : -8815.3\n",
      " ARIMA(0,0,0) with zero mean     : -6819.524\n",
      " ARIMA(1,0,2) with non-zero mean : -11378.77\n",
      " ARIMA(2,0,1) with non-zero mean : -11376.91\n",
      " ARIMA(3,0,2) with non-zero mean : -11457.48\n",
      " ARIMA(3,0,1) with non-zero mean : -11390.32\n",
      " ARIMA(4,0,2) with non-zero mean : -11401.89\n",
      " ARIMA(3,0,3) with non-zero mean : -11402.85\n",
      " ARIMA(2,0,3) with non-zero mean : -11397.85\n",
      " ARIMA(4,0,1) with non-zero mean : -11401.42\n",
      " ARIMA(4,0,3) with non-zero mean : -11408.13\n",
      " ARIMA(3,0,2) with zero mean     : -11459.44\n",
      " ARIMA(2,0,2) with zero mean     : -11386.54\n",
      " ARIMA(3,0,1) with zero mean     : -11392.27\n",
      " ARIMA(4,0,2) with zero mean     : -11403.82\n",
      " ARIMA(3,0,3) with zero mean     : -11404.78\n",
      " ARIMA(2,0,1) with zero mean     : -11378.84\n",
      " ARIMA(2,0,3) with zero mean     : -11399.82\n",
      " ARIMA(4,0,1) with zero mean     : -11403.36\n",
      " ARIMA(4,0,3) with zero mean     : -11401.82\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -11429.81\n",
      "\n",
      " Best model: ARIMA(4,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11412.64\n",
      " ARIMA(0,0,0) with non-zero mean : -6848.389\n",
      " ARIMA(1,0,0) with non-zero mean : -11381.79\n",
      " ARIMA(0,0,1) with non-zero mean : -8850.215\n",
      " ARIMA(0,0,0) with zero mean     : -6849.878\n",
      " ARIMA(1,0,2) with non-zero mean : -11405.42\n",
      " ARIMA(2,0,1) with non-zero mean : -11408.53\n",
      " ARIMA(3,0,2) with non-zero mean : -11426.53\n",
      " ARIMA(3,0,1) with non-zero mean : -11419.05\n",
      " ARIMA(4,0,2) with non-zero mean : -11428.85\n",
      " ARIMA(4,0,1) with non-zero mean : -11428.66\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -11427.82\n",
      " ARIMA(5,0,1) with non-zero mean : -11459.29\n",
      " ARIMA(5,0,0) with non-zero mean : -11427.85\n",
      " ARIMA(4,0,0) with non-zero mean : -11430.59\n",
      " ARIMA(5,0,1) with zero mean     : -11461.27\n",
      " ARIMA(4,0,1) with zero mean     : -11430.65\n",
      " ARIMA(5,0,0) with zero mean     : -11429.84\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,0) with zero mean     : -11432.58\n",
      " ARIMA(4,0,2) with zero mean     : -11431.03\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,1) with zero mean     : -11456.59\n",
      "\n",
      " Best model: ARIMA(5,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11417.39\n",
      " ARIMA(0,0,0) with non-zero mean : -6856.506\n",
      " ARIMA(1,0,0) with non-zero mean : -11388.09\n",
      " ARIMA(0,0,1) with non-zero mean : -8862.562\n",
      " ARIMA(0,0,0) with zero mean     : -6858.168\n",
      " ARIMA(1,0,2) with non-zero mean : -11413.18\n",
      " ARIMA(2,0,1) with non-zero mean : -11411.51\n",
      " ARIMA(3,0,2) with non-zero mean : -11436.07\n",
      " ARIMA(3,0,1) with non-zero mean : -11423.64\n",
      " ARIMA(4,0,2) with non-zero mean : -11435.75\n",
      " ARIMA(3,0,3) with non-zero mean : -11435.89\n",
      " ARIMA(2,0,3) with non-zero mean : -11430.71\n",
      " ARIMA(4,0,1) with non-zero mean : -11434.25\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11438.08\n",
      " ARIMA(2,0,2) with zero mean     : -11419.4\n",
      " ARIMA(3,0,1) with zero mean     : -11425.65\n",
      " ARIMA(4,0,2) with zero mean     : -11437.77\n",
      " ARIMA(3,0,3) with zero mean     : -11437.9\n",
      " ARIMA(2,0,1) with zero mean     : -11413.52\n",
      " ARIMA(2,0,3) with zero mean     : -11432.72\n",
      " ARIMA(4,0,1) with zero mean     : -11436.26\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11434.82\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11423.12\n",
      " ARIMA(0,0,0) with non-zero mean : -6855.742\n",
      " ARIMA(1,0,0) with non-zero mean : -11392.02\n",
      " ARIMA(0,0,1) with non-zero mean : -8862.21\n",
      " ARIMA(0,0,0) with zero mean     : -6857.312\n",
      " ARIMA(1,0,2) with non-zero mean : -11417.26\n",
      " ARIMA(2,0,1) with non-zero mean : -11416.16\n",
      " ARIMA(3,0,2) with non-zero mean : -11493.1\n",
      " ARIMA(3,0,1) with non-zero mean : -11428.28\n",
      " ARIMA(4,0,2) with non-zero mean : -11437.52\n",
      " ARIMA(3,0,3) with non-zero mean : -11438.52\n",
      " ARIMA(2,0,3) with non-zero mean : -11434.97\n",
      " ARIMA(4,0,1) with non-zero mean : -11437.01\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11495.07\n",
      " ARIMA(2,0,2) with zero mean     : -11425.08\n",
      " ARIMA(3,0,1) with zero mean     : -11430.27\n",
      " ARIMA(4,0,2) with zero mean     : -11439.6\n",
      " ARIMA(3,0,3) with zero mean     : -11440.51\n",
      " ARIMA(2,0,1) with zero mean     : -11418.15\n",
      " ARIMA(2,0,3) with zero mean     : -11436.96\n",
      " ARIMA(4,0,1) with zero mean     : -11438.99\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11438.77\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11430.97\n",
      " ARIMA(0,0,0) with non-zero mean : -6848.48\n",
      " ARIMA(1,0,0) with non-zero mean : -11402.64\n",
      " ARIMA(0,0,1) with non-zero mean : -8856.769\n",
      " ARIMA(0,0,0) with zero mean     : -6849.649\n",
      " ARIMA(1,0,2) with non-zero mean : -11427.39\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11502.31\n",
      " ARIMA(3,0,1) with non-zero mean : -11437.26\n",
      " ARIMA(4,0,2) with non-zero mean : -11447.51\n",
      " ARIMA(3,0,3) with non-zero mean : -11448.73\n",
      " ARIMA(2,0,3) with non-zero mean : -11443.78\n",
      " ARIMA(4,0,1) with non-zero mean : -11446.63\n",
      " ARIMA(4,0,3) with non-zero mean : -11509.92\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -11446.8\n",
      " ARIMA(5,0,2) with non-zero mean : -11447.79\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11511.9\n",
      " ARIMA(3,0,3) with zero mean     : -11450.67\n",
      " ARIMA(4,0,2) with zero mean     : -11449.59\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11504.14\n",
      " ARIMA(3,0,4) with zero mean     : -11448.79\n",
      " ARIMA(5,0,2) with zero mean     : -11449.75\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11448.04\n",
      "\n",
      " Best model: ARIMA(3,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11440.69\n",
      " ARIMA(0,0,0) with non-zero mean : -6856.218\n",
      " ARIMA(1,0,0) with non-zero mean : -11411.42\n",
      " ARIMA(0,0,1) with non-zero mean : -8866.494\n",
      " ARIMA(0,0,0) with zero mean     : -6856.027\n",
      " ARIMA(1,0,2) with non-zero mean : -11436.86\n",
      " ARIMA(2,0,1) with non-zero mean : -11435.31\n",
      " ARIMA(3,0,2) with non-zero mean : -11514.58\n",
      " ARIMA(3,0,1) with non-zero mean : -11446.49\n",
      " ARIMA(4,0,2) with non-zero mean : -11454.49\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11453.31\n",
      " ARIMA(4,0,1) with non-zero mean : -11454.65\n",
      " ARIMA(4,0,3) with non-zero mean : -11488.67\n",
      " ARIMA(3,0,2) with zero mean     : -11516.38\n",
      " ARIMA(2,0,2) with zero mean     : -11442.63\n",
      " ARIMA(3,0,1) with zero mean     : -11448.44\n",
      " ARIMA(4,0,2) with zero mean     : -11456.57\n",
      " ARIMA(3,0,3) with zero mean     : -11457.42\n",
      " ARIMA(2,0,1) with zero mean     : -11437.26\n",
      " ARIMA(2,0,3) with zero mean     : -11455.25\n",
      " ARIMA(4,0,1) with zero mean     : -11456.59\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -11493.26\n",
      "\n",
      " Best model: ARIMA(4,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11441.76\n",
      " ARIMA(0,0,0) with non-zero mean : -6867.168\n",
      " ARIMA(1,0,0) with non-zero mean : -11412.83\n",
      " ARIMA(0,0,1) with non-zero mean : -8874.459\n",
      " ARIMA(0,0,0) with zero mean     : -6868.118\n",
      " ARIMA(1,0,2) with non-zero mean : -11438.26\n",
      " ARIMA(2,0,1) with non-zero mean : -11439.57\n",
      " ARIMA(3,0,2) with non-zero mean : -11460.46\n",
      " ARIMA(3,0,1) with non-zero mean : -11452.45\n",
      " ARIMA(4,0,2) with non-zero mean : -11460.15\n",
      " ARIMA(3,0,3) with non-zero mean : -11460.42\n",
      " ARIMA(2,0,3) with non-zero mean : -11457.03\n",
      " ARIMA(4,0,1) with non-zero mean : -11460.67\n",
      " ARIMA(4,0,0) with non-zero mean : -11462.52\n",
      " ARIMA(3,0,0) with non-zero mean : -11445.99\n",
      " ARIMA(5,0,0) with non-zero mean : -11460.51\n",
      " ARIMA(5,0,1) with non-zero mean : -11490.28\n",
      " ARIMA(5,0,2) with non-zero mean : -11489.45\n",
      " ARIMA(5,0,1) with zero mean     : -11492.28\n",
      " ARIMA(4,0,1) with zero mean     : -11462.63\n",
      " ARIMA(5,0,0) with zero mean     : -11462.47\n",
      " ARIMA(5,0,2) with zero mean     : -11491.47\n",
      " ARIMA(4,0,0) with zero mean     : -11464.49\n",
      " ARIMA(4,0,2) with zero mean     : -11462.11\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,1) with zero mean     : -11489.3\n",
      "\n",
      " Best model: ARIMA(5,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11450.16\n",
      " ARIMA(0,0,0) with non-zero mean : -6876.022\n",
      " ARIMA(1,0,0) with non-zero mean : -11420.01\n",
      " ARIMA(0,0,1) with non-zero mean : -8882.957\n",
      " ARIMA(0,0,0) with zero mean     : -6875.829\n",
      " ARIMA(1,0,2) with non-zero mean : -11445.95\n",
      " ARIMA(2,0,1) with non-zero mean : -11444.35\n",
      " ARIMA(3,0,2) with non-zero mean : -11466.46\n",
      " ARIMA(3,0,1) with non-zero mean : -11456.16\n",
      " ARIMA(4,0,2) with non-zero mean : -11465.03\n",
      " ARIMA(3,0,3) with non-zero mean : -11466.1\n",
      " ARIMA(2,0,3) with non-zero mean : -11463.41\n",
      " ARIMA(4,0,1) with non-zero mean : -11464.87\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11468.34\n",
      " ARIMA(2,0,2) with zero mean     : -11452.05\n",
      " ARIMA(3,0,1) with zero mean     : -11458.07\n",
      " ARIMA(4,0,2) with zero mean     : -11466.92\n",
      " ARIMA(3,0,3) with zero mean     : -11468.01\n",
      " ARIMA(2,0,1) with zero mean     : -11446.24\n",
      " ARIMA(2,0,3) with zero mean     : -11465.3\n",
      " ARIMA(4,0,1) with zero mean     : -11466.76\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11467.86\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11459.35\n",
      " ARIMA(0,0,0) with non-zero mean : -6885.081\n",
      " ARIMA(1,0,0) with non-zero mean : -11430.32\n",
      " ARIMA(0,0,1) with non-zero mean : -8894.963\n",
      " ARIMA(0,0,0) with zero mean     : -6883.912\n",
      " ARIMA(1,0,2) with non-zero mean : -11455.26\n",
      " ARIMA(2,0,1) with non-zero mean : -11453.41\n",
      " ARIMA(3,0,2) with non-zero mean : -11478.09\n",
      " ARIMA(3,0,1) with non-zero mean : -11465.83\n",
      " ARIMA(4,0,2) with non-zero mean : -11476.69\n",
      " ARIMA(3,0,3) with non-zero mean : -11477.8\n",
      " ARIMA(2,0,3) with non-zero mean : -11472.47\n",
      " ARIMA(4,0,1) with non-zero mean : -11475.17\n",
      " ARIMA(4,0,3) with non-zero mean : -11529.99\n",
      " ARIMA(5,0,3) with non-zero mean : -11474.61\n",
      " ARIMA(4,0,4) with non-zero mean : -11559.37\n",
      " ARIMA(3,0,4) with non-zero mean : -11492.22\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : -11504.37\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,4) with non-zero mean : -11508.64\n",
      "\n",
      " Best model: ARIMA(4,0,4) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11473.67\n",
      " ARIMA(0,0,0) with non-zero mean : -6904.305\n",
      " ARIMA(1,0,0) with non-zero mean : -11442.86\n",
      " ARIMA(0,0,1) with non-zero mean : -8909.573\n",
      " ARIMA(0,0,0) with zero mean     : -6902.564\n",
      " ARIMA(1,0,2) with non-zero mean : -11467.87\n",
      " ARIMA(2,0,1) with non-zero mean : -11468.18\n",
      " ARIMA(3,0,2) with non-zero mean : -11488.61\n",
      " ARIMA(3,0,1) with non-zero mean : -11478.94\n",
      " ARIMA(4,0,2) with non-zero mean : -11488.89\n",
      " ARIMA(4,0,1) with non-zero mean : -11488.23\n",
      " ARIMA(5,0,2) with non-zero mean : -11530.04\n",
      " ARIMA(5,0,1) with non-zero mean : -11514.48\n",
      " ARIMA(5,0,3) with non-zero mean : -11533.06\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,1) with non-zero mean : -11515.81\n",
      "\n",
      " Best model: ARIMA(5,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11497.17\n",
      " ARIMA(0,0,0) with non-zero mean : -7026.856\n",
      " ARIMA(1,0,0) with non-zero mean : -11463.53\n",
      " ARIMA(0,0,1) with non-zero mean : -8998.064\n",
      " ARIMA(0,0,0) with zero mean     : -7018.215\n",
      " ARIMA(1,0,2) with non-zero mean : -11490.08\n",
      " ARIMA(2,0,1) with non-zero mean : -11479.81\n",
      " ARIMA(3,0,2) with non-zero mean : -11511.03\n",
      " ARIMA(3,0,1) with non-zero mean : -11502\n",
      " ARIMA(4,0,2) with non-zero mean : -11515.83\n",
      " ARIMA(4,0,1) with non-zero mean : -11517.05\n",
      " ARIMA(4,0,0) with non-zero mean : -11516.32\n",
      " ARIMA(5,0,1) with non-zero mean : -11532.81\n",
      " ARIMA(5,0,0) with non-zero mean : -11533.61\n",
      " ARIMA(5,0,0) with zero mean     : -11534.97\n",
      " ARIMA(4,0,0) with zero mean     : -11517.84\n",
      " ARIMA(5,0,1) with zero mean     : -11534.17\n",
      " ARIMA(4,0,1) with zero mean     : -11518.5\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,0) with zero mean     : -11510.2\n",
      "\n",
      " Best model: ARIMA(5,0,0) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11522.36\n",
      " ARIMA(0,0,0) with non-zero mean : -6976.397\n",
      " ARIMA(1,0,0) with non-zero mean : -11483.5\n",
      " ARIMA(0,0,1) with non-zero mean : -8955.384\n",
      " ARIMA(0,0,0) with zero mean     : -6973.519\n",
      " ARIMA(1,0,2) with non-zero mean : -11518.05\n",
      " ARIMA(2,0,1) with non-zero mean : -11502.5\n",
      " ARIMA(3,0,2) with non-zero mean : -11539.76\n",
      " ARIMA(3,0,1) with non-zero mean : -11532\n",
      " ARIMA(4,0,2) with non-zero mean : -11540.01\n",
      " ARIMA(4,0,1) with non-zero mean : -11541.17\n",
      " ARIMA(4,0,0) with non-zero mean : -11542.91\n",
      " ARIMA(3,0,0) with non-zero mean : -11523.24\n",
      " ARIMA(5,0,0) with non-zero mean : -11548.94\n",
      " ARIMA(5,0,1) with non-zero mean : -11560.19\n",
      " ARIMA(5,0,2) with non-zero mean : -11558.2\n",
      " ARIMA(5,0,1) with zero mean     : -11562.08\n",
      " ARIMA(4,0,1) with zero mean     : -11543.1\n",
      " ARIMA(5,0,0) with zero mean     : -11550.92\n",
      " ARIMA(5,0,2) with zero mean     : -11560.09\n",
      " ARIMA(4,0,0) with zero mean     : -11544.85\n",
      " ARIMA(4,0,2) with zero mean     : -11541.94\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,1) with zero mean     : -11573.33\n",
      "\n",
      " Best model: ARIMA(5,0,1) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11485.88\n",
      " ARIMA(0,0,0) with non-zero mean : -7008.245\n",
      " ARIMA(1,0,0) with non-zero mean : -11447.22\n",
      " ARIMA(0,0,1) with non-zero mean : -8956.127\n",
      " ARIMA(0,0,0) with zero mean     : -7003.898\n",
      " ARIMA(1,0,2) with non-zero mean : -11483.16\n",
      " ARIMA(2,0,1) with non-zero mean : -11482.32\n",
      " ARIMA(3,0,2) with non-zero mean : -11506.05\n",
      " ARIMA(3,0,1) with non-zero mean : -11491.58\n",
      " ARIMA(4,0,2) with non-zero mean : -11505.48\n",
      " ARIMA(3,0,3) with non-zero mean : -11505.8\n",
      " ARIMA(2,0,3) with non-zero mean : -11498.3\n",
      " ARIMA(4,0,1) with non-zero mean : -11502.45\n",
      " ARIMA(4,0,3) with non-zero mean : -11520.2\n",
      " ARIMA(5,0,3) with non-zero mean : -11529.58\n",
      " ARIMA(5,0,2) with non-zero mean : -11525.97\n",
      " ARIMA(5,0,4) with non-zero mean : -11582.08\n",
      " ARIMA(4,0,4) with non-zero mean : -11531.68\n",
      " ARIMA(5,0,5) with non-zero mean : -11565.09\n",
      " ARIMA(4,0,5) with non-zero mean : -11538.66\n",
      " ARIMA(5,0,4) with zero mean     : -11583.66\n",
      " ARIMA(4,0,4) with zero mean     : -11533.24\n",
      " ARIMA(5,0,3) with zero mean     : -11531.52\n",
      " ARIMA(5,0,5) with zero mean     : -11566.72\n",
      " ARIMA(4,0,3) with zero mean     : -11521.86\n",
      " ARIMA(4,0,5) with zero mean     : -11540.44\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,5) with zero mean     : Inf\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with zero mean     : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11532.83\n",
      "\n",
      " Best model: ARIMA(5,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11484.53\n",
      " ARIMA(0,0,0) with non-zero mean : -7045.561\n",
      " ARIMA(1,0,0) with non-zero mean : -11444.21\n",
      " ARIMA(0,0,1) with non-zero mean : -8986.409\n",
      " ARIMA(0,0,0) with zero mean     : -7038.631\n",
      " ARIMA(1,0,2) with non-zero mean : -11482.13\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11504.12\n",
      " ARIMA(3,0,1) with non-zero mean : -11491.11\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11494.91\n",
      " ARIMA(4,0,1) with non-zero mean : -11499.35\n",
      " ARIMA(4,0,3) with non-zero mean : -11526.26\n",
      " ARIMA(5,0,3) with non-zero mean : -11517.71\n",
      " ARIMA(4,0,4) with non-zero mean : -11527.82\n",
      " ARIMA(3,0,4) with non-zero mean : -11575.39\n",
      " ARIMA(2,0,4) with non-zero mean : -11528.58\n",
      " ARIMA(3,0,5) with non-zero mean : -11562.18\n",
      " ARIMA(2,0,5) with non-zero mean : -11534.69\n",
      " ARIMA(4,0,5) with non-zero mean : -11524.81\n",
      " ARIMA(3,0,4) with zero mean     : -11577.89\n",
      " ARIMA(2,0,4) with zero mean     : -11530.23\n",
      " ARIMA(3,0,3) with zero mean     : -11566.83\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with zero mean     : -11564.21\n",
      " ARIMA(2,0,3) with zero mean     : -11496.61\n",
      " ARIMA(2,0,5) with zero mean     : -11536.4\n",
      " ARIMA(4,0,3) with zero mean     : -11527.89\n",
      " ARIMA(4,0,5) with zero mean     : -11526.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with zero mean     : -11533.26\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11512.55\n",
      " ARIMA(0,0,0) with non-zero mean : -7061.255\n",
      " ARIMA(1,0,0) with non-zero mean : -11465.68\n",
      " ARIMA(0,0,1) with non-zero mean : -9005.312\n",
      " ARIMA(0,0,0) with zero mean     : -7056.084\n",
      " ARIMA(1,0,2) with non-zero mean : -11505.82\n",
      " ARIMA(2,0,1) with non-zero mean : -11507.85\n",
      " ARIMA(3,0,2) with non-zero mean : -11529.8\n",
      " ARIMA(3,0,1) with non-zero mean : -11518.26\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -11528.69\n",
      " ARIMA(2,0,3) with non-zero mean : -11525.98\n",
      " ARIMA(4,0,1) with non-zero mean : -11526.77\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11531.71\n",
      " ARIMA(2,0,2) with zero mean     : -11514.51\n",
      " ARIMA(3,0,1) with zero mean     : -11520.21\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : -11530.61\n",
      " ARIMA(2,0,1) with zero mean     : -11509.79\n",
      " ARIMA(2,0,3) with zero mean     : -11527.91\n",
      " ARIMA(4,0,1) with zero mean     : -11528.68\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11531.16\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11482.71\n",
      " ARIMA(0,0,0) with non-zero mean : -7055.949\n",
      " ARIMA(1,0,0) with non-zero mean : -11440.36\n",
      " ARIMA(0,0,1) with non-zero mean : -8999.116\n",
      " ARIMA(0,0,0) with zero mean     : -7050.65\n",
      " ARIMA(1,0,2) with non-zero mean : -11479.36\n",
      " ARIMA(2,0,1) with non-zero mean : -11479.16\n",
      " ARIMA(3,0,2) with non-zero mean : -11504.84\n",
      " ARIMA(3,0,1) with non-zero mean : -11490.33\n",
      " ARIMA(4,0,2) with non-zero mean : -11502.25\n",
      " ARIMA(3,0,3) with non-zero mean : -11503.38\n",
      " ARIMA(2,0,3) with non-zero mean : -11497.76\n",
      " ARIMA(4,0,1) with non-zero mean : -11502.16\n",
      " ARIMA(4,0,3) with non-zero mean : -11506.83\n",
      " ARIMA(5,0,3) with non-zero mean : -11536.13\n",
      " ARIMA(5,0,2) with non-zero mean : -11529.28\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11522.49\n",
      " ARIMA(5,0,3) with zero mean     : -11537.82\n",
      " ARIMA(4,0,3) with zero mean     : -11507.84\n",
      " ARIMA(5,0,2) with zero mean     : -11530.86\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11503.86\n",
      " ARIMA(4,0,4) with zero mean     : -11523.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with zero mean     : -11537.58\n",
      "\n",
      " Best model: ARIMA(5,0,3) with zero mean     \n",
      "\n",
      "[1] \"60 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11490.37\n",
      " ARIMA(0,0,0) with non-zero mean : -7047.452\n",
      " ARIMA(1,0,0) with non-zero mean : -11444.65\n",
      " ARIMA(0,0,1) with non-zero mean : -8991.749\n",
      " ARIMA(0,0,0) with zero mean     : -7039.512\n",
      " ARIMA(1,0,2) with non-zero mean : -11484.88\n",
      " ARIMA(2,0,1) with non-zero mean : -11485.48\n",
      " ARIMA(3,0,2) with non-zero mean : -11509.2\n",
      " ARIMA(3,0,1) with non-zero mean : -11496.02\n",
      " ARIMA(4,0,2) with non-zero mean : -11507.8\n",
      " ARIMA(3,0,3) with non-zero mean : -11507.44\n",
      " ARIMA(2,0,3) with non-zero mean : -11503.08\n",
      " ARIMA(4,0,1) with non-zero mean : -11507.8\n",
      " ARIMA(4,0,3) with non-zero mean : -11548.82\n",
      " ARIMA(5,0,3) with non-zero mean : -11539.74\n",
      " ARIMA(4,0,4) with non-zero mean : -11525.75\n",
      " ARIMA(3,0,4) with non-zero mean : -11542.99\n",
      " ARIMA(5,0,2) with non-zero mean : -11530.54\n",
      " ARIMA(5,0,4) with non-zero mean : -11540.45\n",
      " ARIMA(4,0,3) with zero mean     : -11550.67\n",
      " ARIMA(3,0,3) with zero mean     : -11509.09\n",
      " ARIMA(4,0,2) with zero mean     : -11509.38\n",
      " ARIMA(5,0,3) with zero mean     : -11540.95\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11510.85\n",
      " ARIMA(3,0,4) with zero mean     : -11544.76\n",
      " ARIMA(5,0,2) with zero mean     : -11532.19\n",
      " ARIMA(5,0,4) with zero mean     : -11579.37\n",
      " ARIMA(5,0,5) with zero mean     : -11543.06\n",
      " ARIMA(4,0,5) with zero mean     : -11592.29\n",
      " ARIMA(3,0,5) with zero mean     : -11545.3\n",
      " ARIMA(4,0,5) with non-zero mean : -11590.86\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,5) with zero mean     : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with zero mean     : -11578.88\n",
      "\n",
      " Best model: ARIMA(5,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11508.12\n",
      " ARIMA(0,0,0) with non-zero mean : -7087.399\n",
      " ARIMA(1,0,0) with non-zero mean : -11462.71\n",
      " ARIMA(0,0,1) with non-zero mean : -9025.635\n",
      " ARIMA(0,0,0) with zero mean     : -7072.381\n",
      " ARIMA(1,0,2) with non-zero mean : -11504.23\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11528.6\n",
      " ARIMA(3,0,1) with non-zero mean : -11515.45\n",
      " ARIMA(4,0,2) with non-zero mean : -11526.53\n",
      " ARIMA(3,0,3) with non-zero mean : -11527.53\n",
      " ARIMA(2,0,3) with non-zero mean : -11520.4\n",
      " ARIMA(4,0,1) with non-zero mean : -11523.82\n",
      " ARIMA(4,0,3) with non-zero mean : -11542.11\n",
      " ARIMA(5,0,3) with non-zero mean : -11554.06\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : -11602.43\n",
      " ARIMA(4,0,4) with non-zero mean : -11549.88\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : -11557.33\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,4) with non-zero mean : -11602.48\n",
      "\n",
      " Best model: ARIMA(5,0,4) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11526.79\n",
      " ARIMA(0,0,0) with non-zero mean : -7092.398\n",
      " ARIMA(1,0,0) with non-zero mean : -11484.3\n",
      " ARIMA(0,0,1) with non-zero mean : -9043.673\n",
      " ARIMA(0,0,0) with zero mean     : -7075.856\n",
      " ARIMA(1,0,2) with non-zero mean : -11524.41\n",
      " ARIMA(2,0,1) with non-zero mean : -11524.82\n",
      " ARIMA(3,0,2) with non-zero mean : -11552.34\n",
      " ARIMA(3,0,1) with non-zero mean : -11541.36\n",
      " ARIMA(4,0,2) with non-zero mean : -11552.16\n",
      " ARIMA(3,0,3) with non-zero mean : -11552.84\n",
      " ARIMA(2,0,3) with non-zero mean : -11543.3\n",
      " ARIMA(4,0,3) with non-zero mean : -11554.74\n",
      " ARIMA(5,0,3) with non-zero mean : -11575.93\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -11577.43\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11553.65\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with zero mean     : -11571.37\n",
      "\n",
      " Best model: ARIMA(5,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11547.91\n",
      " ARIMA(0,0,0) with non-zero mean : -7107.758\n",
      " ARIMA(1,0,0) with non-zero mean : -11504.77\n",
      " ARIMA(0,0,1) with non-zero mean : -9060.209\n",
      " ARIMA(0,0,0) with zero mean     : -7094.49\n",
      " ARIMA(1,0,2) with non-zero mean : -11544.18\n",
      " ARIMA(2,0,1) with non-zero mean : -11542.64\n",
      " ARIMA(3,0,2) with non-zero mean : -11570.25\n",
      " ARIMA(3,0,1) with non-zero mean : -11554.96\n",
      " ARIMA(4,0,2) with non-zero mean : -11567.73\n",
      " ARIMA(3,0,3) with non-zero mean : -11568.73\n",
      " ARIMA(2,0,3) with non-zero mean : -11562.27\n",
      " ARIMA(4,0,1) with non-zero mean : -11563.92\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11571.9\n",
      " ARIMA(2,0,2) with zero mean     : -11549.64\n",
      " ARIMA(3,0,1) with zero mean     : -11556.68\n",
      " ARIMA(4,0,2) with zero mean     : -11569.38\n",
      " ARIMA(3,0,3) with zero mean     : -11570.38\n",
      " ARIMA(2,0,1) with zero mean     : -11544.33\n",
      " ARIMA(2,0,3) with zero mean     : -11563.9\n",
      " ARIMA(4,0,1) with zero mean     : -11565.55\n",
      " ARIMA(4,0,3) with zero mean     : -11629.13\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : -11626\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11570.11\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11556.06\n",
      " ARIMA(0,0,0) with non-zero mean : -7115.878\n",
      " ARIMA(1,0,0) with non-zero mean : -11512.93\n",
      " ARIMA(0,0,1) with non-zero mean : -9071.081\n",
      " ARIMA(0,0,0) with zero mean     : -7107.797\n",
      " ARIMA(1,0,2) with non-zero mean : -11552.01\n",
      " ARIMA(2,0,1) with non-zero mean : -11550.3\n",
      " ARIMA(3,0,2) with non-zero mean : -11577.24\n",
      " ARIMA(3,0,1) with non-zero mean : -11562.77\n",
      " ARIMA(4,0,2) with non-zero mean : -11575.26\n",
      " ARIMA(3,0,3) with non-zero mean : -11575.39\n",
      " ARIMA(2,0,3) with non-zero mean : -11569.65\n",
      " ARIMA(4,0,1) with non-zero mean : -11572.43\n",
      " ARIMA(4,0,3) with non-zero mean : -11632.57\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11572.78\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11634.31\n",
      " ARIMA(3,0,3) with zero mean     : -11577.2\n",
      " ARIMA(4,0,2) with zero mean     : -11577.1\n",
      " ARIMA(5,0,3) with zero mean     : -11596.63\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11579.07\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : -11574.61\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -11598.87\n",
      "\n",
      " Best model: ARIMA(5,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11550.76\n",
      " ARIMA(0,0,0) with non-zero mean : -7126.439\n",
      " ARIMA(1,0,0) with non-zero mean : -11509.95\n",
      " ARIMA(0,0,1) with non-zero mean : -9081.564\n",
      " ARIMA(0,0,0) with zero mean     : -7121.931\n",
      " ARIMA(1,0,2) with non-zero mean : -11547.26\n",
      " ARIMA(2,0,1) with non-zero mean : -11545.45\n",
      " ARIMA(3,0,2) with non-zero mean : -11615.83\n",
      " ARIMA(3,0,1) with non-zero mean : -11557.98\n",
      " ARIMA(4,0,2) with non-zero mean : -11570.85\n",
      " ARIMA(3,0,3) with non-zero mean : -11570.56\n",
      " ARIMA(2,0,3) with non-zero mean : -11564.49\n",
      " ARIMA(4,0,1) with non-zero mean : -11567.12\n",
      " ARIMA(4,0,3) with non-zero mean : -11624.41\n",
      " ARIMA(5,0,3) with non-zero mean : -11590.89\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -11596.23\n",
      " ARIMA(5,0,2) with non-zero mean : -11567.64\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11635.38\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11572.65\n",
      " ARIMA(5,0,3) with zero mean     : -11592.65\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11617.52\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with zero mean     : -11569.6\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with zero mean     : -11638.66\n",
      "\n",
      " Best model: ARIMA(4,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11545.12\n",
      " ARIMA(0,0,0) with non-zero mean : -7119.86\n",
      " ARIMA(1,0,0) with non-zero mean : -11506.09\n",
      " ARIMA(0,0,1) with non-zero mean : -9075.953\n",
      " ARIMA(0,0,0) with zero mean     : -7114.27\n",
      " ARIMA(1,0,2) with non-zero mean : -11541.95\n",
      " ARIMA(2,0,1) with non-zero mean : -11540.33\n",
      " ARIMA(3,0,2) with non-zero mean : -11606\n",
      " ARIMA(3,0,1) with non-zero mean : -11553.66\n",
      " ARIMA(4,0,2) with non-zero mean : -11563.55\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11558.54\n",
      " ARIMA(4,0,1) with non-zero mean : -11561.29\n",
      " ARIMA(4,0,3) with non-zero mean : -11618.61\n",
      " ARIMA(5,0,3) with non-zero mean : -11617\n",
      " ARIMA(4,0,4) with non-zero mean : -11627.13\n",
      " ARIMA(3,0,4) with non-zero mean : -11578.07\n",
      " ARIMA(5,0,4) with non-zero mean : -11649.58\n",
      " ARIMA(5,0,5) with non-zero mean : -11575.81\n",
      " ARIMA(4,0,5) with non-zero mean : -11587.7\n",
      " ARIMA(5,0,4) with zero mean     : -11623.15\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with zero mean     : -11631.44\n",
      "\n",
      " Best model: ARIMA(5,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11546.6\n",
      " ARIMA(0,0,0) with non-zero mean : -7114.313\n",
      " ARIMA(1,0,0) with non-zero mean : -11507.8\n",
      " ARIMA(0,0,1) with non-zero mean : -9072.376\n",
      " ARIMA(0,0,0) with zero mean     : -7106.949\n",
      " ARIMA(1,0,2) with non-zero mean : -11543.3\n",
      " ARIMA(2,0,1) with non-zero mean : -11541.55\n",
      " ARIMA(3,0,2) with non-zero mean : -11566.73\n",
      " ARIMA(3,0,1) with non-zero mean : -11554.22\n",
      " ARIMA(4,0,2) with non-zero mean : -11564.63\n",
      " ARIMA(3,0,3) with non-zero mean : -11565.27\n",
      " ARIMA(2,0,3) with non-zero mean : -11558.99\n",
      " ARIMA(4,0,1) with non-zero mean : -11562.35\n",
      " ARIMA(4,0,3) with non-zero mean : -11613.32\n",
      " ARIMA(5,0,3) with non-zero mean : -11628.52\n",
      " ARIMA(5,0,2) with non-zero mean : -11620.28\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11619.37\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : -11634.67\n",
      "\n",
      " Best model: ARIMA(5,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11551.54\n",
      " ARIMA(0,0,0) with non-zero mean : -7118.416\n",
      " ARIMA(1,0,0) with non-zero mean : -11511.29\n",
      " ARIMA(0,0,1) with non-zero mean : -9078.301\n",
      " ARIMA(0,0,0) with zero mean     : -7111.373\n",
      " ARIMA(1,0,2) with non-zero mean : -11547.03\n",
      " ARIMA(2,0,1) with non-zero mean : -11545.53\n",
      " ARIMA(3,0,2) with non-zero mean : -11615.2\n",
      " ARIMA(3,0,1) with non-zero mean : -11557.44\n",
      " ARIMA(4,0,2) with non-zero mean : -11568.29\n",
      " ARIMA(3,0,3) with non-zero mean : -11568.78\n",
      " ARIMA(2,0,3) with non-zero mean : -11563.36\n",
      " ARIMA(4,0,1) with non-zero mean : -11564.77\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11617.02\n",
      " ARIMA(2,0,2) with zero mean     : -11553.27\n",
      " ARIMA(3,0,1) with zero mean     : -11559.16\n",
      " ARIMA(4,0,2) with zero mean     : -11569.97\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -11547.24\n",
      " ARIMA(2,0,3) with zero mean     : -11565.04\n",
      " ARIMA(4,0,1) with zero mean     : -11566.45\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11620.7\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11554.01\n",
      " ARIMA(0,0,0) with non-zero mean : -7116.973\n",
      " ARIMA(1,0,0) with non-zero mean : -11514.16\n",
      " ARIMA(0,0,1) with non-zero mean : -9078.843\n",
      " ARIMA(0,0,0) with zero mean     : -7110.575\n",
      " ARIMA(1,0,2) with non-zero mean : -11549.31\n",
      " ARIMA(2,0,1) with non-zero mean : -11547.38\n",
      " ARIMA(3,0,2) with non-zero mean : -11617.37\n",
      " ARIMA(3,0,1) with non-zero mean : -11560.2\n",
      " ARIMA(4,0,2) with non-zero mean : -11570.91\n",
      " ARIMA(3,0,3) with non-zero mean : -11632.39\n",
      " ARIMA(2,0,3) with non-zero mean : -11565.17\n",
      " ARIMA(4,0,3) with non-zero mean : -11630.52\n",
      " ARIMA(3,0,4) with non-zero mean : -11585.25\n",
      " ARIMA(2,0,4) with non-zero mean : -11587.21\n",
      " ARIMA(4,0,4) with non-zero mean : -11628.73\n",
      " ARIMA(3,0,3) with zero mean     : -11634.27\n",
      " ARIMA(2,0,3) with zero mean     : -11566.99\n",
      " ARIMA(3,0,2) with zero mean     : -11619.19\n",
      " ARIMA(4,0,3) with zero mean     : -11632.5\n",
      " ARIMA(3,0,4) with zero mean     : -11625.88\n",
      " ARIMA(2,0,2) with zero mean     : -11555.88\n",
      " ARIMA(2,0,4) with zero mean     : -11588.91\n",
      " ARIMA(4,0,2) with zero mean     : -11572.75\n",
      " ARIMA(4,0,4) with zero mean     : -11630.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -11628.23\n",
      "\n",
      " Best model: ARIMA(3,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11551.34\n",
      " ARIMA(0,0,0) with non-zero mean : -7106.605\n",
      " ARIMA(1,0,0) with non-zero mean : -11513.4\n",
      " ARIMA(0,0,1) with non-zero mean : -9071.249\n",
      " ARIMA(0,0,0) with zero mean     : -7102.428\n",
      " ARIMA(1,0,2) with non-zero mean : -11547.63\n",
      " ARIMA(2,0,1) with non-zero mean : -11545.49\n",
      " ARIMA(3,0,2) with non-zero mean : -11617.89\n",
      " ARIMA(3,0,1) with non-zero mean : -11557.32\n",
      " ARIMA(4,0,2) with non-zero mean : -11568.4\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11562.84\n",
      " ARIMA(4,0,1) with non-zero mean : -11564.69\n",
      " ARIMA(4,0,3) with non-zero mean : -11630.55\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11636.38\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : -11589.82\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : -11638.05\n",
      " ARIMA(3,0,4) with zero mean     : -11633.51\n",
      " ARIMA(4,0,3) with zero mean     : -11632.3\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,5) with zero mean     : -11591.73\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,5) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,4) with zero mean     : -11590.88\n",
      "\n",
      " Best model: ARIMA(4,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11548.17\n",
      " ARIMA(0,0,0) with non-zero mean : -7106.547\n",
      " ARIMA(1,0,0) with non-zero mean : -11510.72\n",
      " ARIMA(0,0,1) with non-zero mean : -9069.574\n",
      " ARIMA(0,0,0) with zero mean     : -7102.552\n",
      " ARIMA(1,0,2) with non-zero mean : -11544.52\n",
      " ARIMA(2,0,1) with non-zero mean : -11542.44\n",
      " ARIMA(3,0,2) with non-zero mean : -11617.49\n",
      " ARIMA(3,0,1) with non-zero mean : -11553.85\n",
      " ARIMA(4,0,2) with non-zero mean : -11565.16\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11559.85\n",
      " ARIMA(4,0,1) with non-zero mean : -11561.4\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11619.37\n",
      " ARIMA(2,0,2) with zero mean     : -11550.07\n",
      " ARIMA(3,0,1) with zero mean     : -11555.75\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -11544.33\n",
      " ARIMA(2,0,3) with zero mean     : -11561.72\n",
      " ARIMA(4,0,1) with zero mean     : -11563.27\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11619.52\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11546.07\n",
      " ARIMA(0,0,0) with non-zero mean : -7112.958\n",
      " ARIMA(1,0,0) with non-zero mean : -11508.98\n",
      " ARIMA(0,0,1) with non-zero mean : -9075.459\n",
      " ARIMA(0,0,0) with zero mean     : -7109.358\n",
      " ARIMA(1,0,2) with non-zero mean : -11542.43\n",
      " ARIMA(2,0,1) with non-zero mean : -11540.32\n",
      " ARIMA(3,0,2) with non-zero mean : -11617.21\n",
      " ARIMA(3,0,1) with non-zero mean : -11551.7\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11557.75\n",
      " ARIMA(4,0,1) with non-zero mean : -11559.25\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11618.96\n",
      " ARIMA(2,0,2) with zero mean     : -11547.9\n",
      " ARIMA(3,0,1) with zero mean     : -11553.51\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -11542.14\n",
      " ARIMA(2,0,3) with zero mean     : -11559.55\n",
      " ARIMA(4,0,1) with zero mean     : -11561.06\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11619.15\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11546.69\n",
      " ARIMA(0,0,0) with non-zero mean : -7110.009\n",
      " ARIMA(1,0,0) with non-zero mean : -11509.7\n",
      " ARIMA(0,0,1) with non-zero mean : -9073.832\n",
      " ARIMA(0,0,0) with zero mean     : -7105.975\n",
      " ARIMA(1,0,2) with non-zero mean : -11542.96\n",
      " ARIMA(2,0,1) with non-zero mean : -11540.83\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11558.31\n",
      " ARIMA(1,0,3) with non-zero mean : -11560.89\n",
      " ARIMA(0,0,3) with non-zero mean : -10457.85\n",
      " ARIMA(1,0,4) with non-zero mean : -11559.83\n",
      " ARIMA(0,0,2) with non-zero mean : -9950.234\n",
      " ARIMA(0,0,4) with non-zero mean : -10869.46\n",
      " ARIMA(2,0,4) with non-zero mean : -11584.44\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11592.16\n",
      " ARIMA(1,0,5) with non-zero mean : -11564.19\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with zero mean     : -11594.02\n",
      " ARIMA(1,0,5) with zero mean     : -11566.03\n",
      " ARIMA(2,0,4) with zero mean     : -11586.28\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(1,0,4) with zero mean     : -11561.65\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,5) with zero mean     : -11593.87\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11547.96\n",
      " ARIMA(0,0,0) with non-zero mean : -7112.272\n",
      " ARIMA(1,0,0) with non-zero mean : -11510.05\n",
      " ARIMA(0,0,1) with non-zero mean : -9074.982\n",
      " ARIMA(0,0,0) with zero mean     : -7106.199\n",
      " ARIMA(1,0,2) with non-zero mean : -11544.13\n",
      " ARIMA(2,0,1) with non-zero mean : -11542.04\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11559.77\n",
      " ARIMA(1,0,3) with non-zero mean : -11562.34\n",
      " ARIMA(0,0,3) with non-zero mean : -10457.36\n",
      " ARIMA(1,0,4) with non-zero mean : -11561.29\n",
      " ARIMA(0,0,2) with non-zero mean : -9949.54\n",
      " ARIMA(0,0,4) with non-zero mean : -10868.67\n",
      " ARIMA(2,0,4) with non-zero mean : -11586.17\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11593.93\n",
      " ARIMA(1,0,5) with non-zero mean : -11565.7\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with zero mean     : -11595.61\n",
      " ARIMA(1,0,5) with zero mean     : -11567.42\n",
      " ARIMA(2,0,4) with zero mean     : -11587.81\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(1,0,4) with zero mean     : -11562.99\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,5) with zero mean     : -11595.61\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11551.98\n",
      " ARIMA(0,0,0) with non-zero mean : -7114.245\n",
      " ARIMA(1,0,0) with non-zero mean : -11513.27\n",
      " ARIMA(0,0,1) with non-zero mean : -9076.409\n",
      " ARIMA(0,0,0) with zero mean     : -7108.062\n",
      " ARIMA(1,0,2) with non-zero mean : -11548.07\n",
      " ARIMA(2,0,1) with non-zero mean : -11545.97\n",
      " ARIMA(3,0,2) with non-zero mean : -11621.92\n",
      " ARIMA(3,0,1) with non-zero mean : -11557.83\n",
      " ARIMA(4,0,2) with non-zero mean : -11569.14\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11563.49\n",
      " ARIMA(4,0,1) with non-zero mean : -11565.27\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : -11623.02\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11549.82\n",
      " ARIMA(0,0,0) with non-zero mean : -7108.307\n",
      " ARIMA(1,0,0) with non-zero mean : -11511.15\n",
      " ARIMA(0,0,1) with non-zero mean : -9070.413\n",
      " ARIMA(0,0,0) with zero mean     : -7098.131\n",
      " ARIMA(1,0,2) with non-zero mean : -11546.06\n",
      " ARIMA(2,0,1) with non-zero mean : -11543.98\n",
      " ARIMA(3,0,2) with non-zero mean : -11620.06\n",
      " ARIMA(3,0,1) with non-zero mean : -11555.65\n",
      " ARIMA(4,0,2) with non-zero mean : -11567.5\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11561.41\n",
      " ARIMA(4,0,1) with non-zero mean : -11563.26\n",
      " ARIMA(4,0,3) with non-zero mean : -11630.88\n",
      " ARIMA(5,0,3) with non-zero mean : -11623.84\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11631.65\n",
      " ARIMA(5,0,1) with non-zero mean : -11590.51\n",
      " ARIMA(5,0,2) with zero mean     : -11633.39\n",
      " ARIMA(4,0,2) with zero mean     : -11569.12\n",
      " ARIMA(5,0,1) with zero mean     : -11592.07\n",
      " ARIMA(5,0,3) with zero mean     : -11636.77\n",
      " ARIMA(4,0,3) with zero mean     : -11632.71\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with zero mean     : -11591.97\n",
      "\n",
      " Best model: ARIMA(5,0,3) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11546.59\n",
      " ARIMA(0,0,0) with non-zero mean : -7108.494\n",
      " ARIMA(1,0,0) with non-zero mean : -11507.88\n",
      " ARIMA(0,0,1) with non-zero mean : -9068.035\n",
      " ARIMA(0,0,0) with zero mean     : -7100.783\n",
      " ARIMA(1,0,2) with non-zero mean : -11542.94\n",
      " ARIMA(2,0,1) with non-zero mean : -11541.28\n",
      " ARIMA(3,0,2) with non-zero mean : -11614.15\n",
      " ARIMA(3,0,1) with non-zero mean : -11552.61\n",
      " ARIMA(4,0,2) with non-zero mean : -11630.6\n",
      " ARIMA(4,0,1) with non-zero mean : -11560.2\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,1) with non-zero mean : -11587.56\n",
      " ARIMA(5,0,3) with non-zero mean : -11634.25\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : -11635.68\n",
      "\n",
      " Best model: ARIMA(5,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11543.12\n",
      " ARIMA(0,0,0) with non-zero mean : -7104.029\n",
      " ARIMA(1,0,0) with non-zero mean : -11504.2\n",
      " ARIMA(0,0,1) with non-zero mean : -9062.16\n",
      " ARIMA(0,0,0) with zero mean     : -7093.004\n",
      " ARIMA(1,0,2) with non-zero mean : -11538.94\n",
      " ARIMA(2,0,1) with non-zero mean : -11537.27\n",
      " ARIMA(3,0,2) with non-zero mean : -11611.29\n",
      " ARIMA(3,0,1) with non-zero mean : -11548.77\n",
      " ARIMA(4,0,2) with non-zero mean : -11560.94\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11554.65\n",
      " ARIMA(4,0,1) with non-zero mean : -11556.15\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11612.56\n",
      " ARIMA(2,0,2) with zero mean     : -11544.66\n",
      " ARIMA(3,0,1) with zero mean     : -11550.31\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -11538.8\n",
      " ARIMA(2,0,3) with zero mean     : -11556.13\n",
      " ARIMA(4,0,1) with zero mean     : -11557.64\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11614.8\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11541.63\n",
      " ARIMA(0,0,0) with non-zero mean : -7104.001\n",
      " ARIMA(1,0,0) with non-zero mean : -11503.56\n",
      " ARIMA(0,0,1) with non-zero mean : -9064.192\n",
      " ARIMA(0,0,0) with zero mean     : -7092.129\n",
      " ARIMA(1,0,2) with non-zero mean : -11538.1\n",
      " ARIMA(2,0,1) with non-zero mean : -11536.04\n",
      " ARIMA(3,0,2) with non-zero mean : -11611.74\n",
      " ARIMA(3,0,1) with non-zero mean : -11547.4\n",
      " ARIMA(4,0,2) with non-zero mean : -11558.95\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11553.51\n",
      " ARIMA(4,0,1) with non-zero mean : -11555.88\n",
      " ARIMA(4,0,3) with non-zero mean : -11629.28\n",
      " ARIMA(5,0,3) with non-zero mean : -11628.64\n",
      " ARIMA(4,0,4) with non-zero mean : -11616.24\n",
      " ARIMA(3,0,4) with non-zero mean : -11583.02\n",
      " ARIMA(5,0,2) with non-zero mean : -11610.32\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -11619.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with non-zero mean : -11580.32\n",
      "\n",
      " Best model: ARIMA(4,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11542.31\n",
      " ARIMA(0,0,0) with non-zero mean : -7104.746\n",
      " ARIMA(1,0,0) with non-zero mean : -11503.98\n",
      " ARIMA(0,0,1) with non-zero mean : -9064.626\n",
      " ARIMA(0,0,0) with zero mean     : -7093.767\n",
      " ARIMA(1,0,2) with non-zero mean : -11538.59\n",
      " ARIMA(2,0,1) with non-zero mean : -11536.52\n",
      " ARIMA(3,0,2) with non-zero mean : -11610.53\n",
      " ARIMA(3,0,1) with non-zero mean : -11548.59\n",
      " ARIMA(4,0,2) with non-zero mean : -11560.71\n",
      " ARIMA(3,0,3) with non-zero mean : -11625.57\n",
      " ARIMA(2,0,3) with non-zero mean : -11554\n",
      " ARIMA(4,0,3) with non-zero mean : -11622.92\n",
      " ARIMA(3,0,4) with non-zero mean : -11580.38\n",
      " ARIMA(2,0,4) with non-zero mean : -11581.82\n",
      " ARIMA(4,0,4) with non-zero mean : -11621.31\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -11627.63\n",
      "\n",
      " Best model: ARIMA(4,0,3) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11539.47\n",
      " ARIMA(0,0,0) with non-zero mean : -7102.276\n",
      " ARIMA(1,0,0) with non-zero mean : -11501.5\n",
      " ARIMA(0,0,1) with non-zero mean : -9062.581\n",
      " ARIMA(0,0,0) with zero mean     : -7090.135\n",
      " ARIMA(1,0,2) with non-zero mean : -11535.92\n",
      " ARIMA(2,0,1) with non-zero mean : -11533.8\n",
      " ARIMA(3,0,2) with non-zero mean : -11606.73\n",
      " ARIMA(3,0,1) with non-zero mean : -11545.4\n",
      " ARIMA(4,0,2) with non-zero mean : -11558.05\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11551.07\n",
      " ARIMA(4,0,1) with non-zero mean : -11553.3\n",
      " ARIMA(4,0,3) with non-zero mean : -11619.69\n",
      " ARIMA(5,0,3) with non-zero mean : -11619.9\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11625.96\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : -11583\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(5,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with zero mean     : -11627.36\n",
      " ARIMA(3,0,4) with zero mean     : -11622.97\n",
      " ARIMA(4,0,3) with zero mean     : -11621.42\n",
      " ARIMA(5,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,5) with zero mean     : -11584.58\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -11621.32\n",
      " ARIMA(5,0,5) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -11626.69\n",
      "\n",
      " Best model: ARIMA(3,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11543\n",
      " ARIMA(0,0,0) with non-zero mean : -7109.443\n",
      " ARIMA(1,0,0) with non-zero mean : -11504.54\n",
      " ARIMA(0,0,1) with non-zero mean : -9066.509\n",
      " ARIMA(0,0,0) with zero mean     : -7097.631\n",
      " ARIMA(1,0,2) with non-zero mean : -11539.42\n",
      " ARIMA(2,0,1) with non-zero mean : -11537.33\n",
      " ARIMA(3,0,2) with non-zero mean : -11607.85\n",
      " ARIMA(3,0,1) with non-zero mean : -11549.09\n",
      " ARIMA(4,0,2) with non-zero mean : -11561.32\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11554.41\n",
      " ARIMA(4,0,1) with non-zero mean : -11556.82\n",
      " ARIMA(4,0,3) with non-zero mean : -11619.75\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11627.91\n",
      " ARIMA(3,0,4) with non-zero mean : -11576.49\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : -11586.89\n",
      " ARIMA(3,0,5) with non-zero mean : -11634.43\n",
      " ARIMA(2,0,5) with non-zero mean : -11590.8\n",
      " ARIMA(2,0,4) with non-zero mean : -11582.07\n",
      " ARIMA(3,0,5) with zero mean     : -11635\n",
      " ARIMA(2,0,5) with zero mean     : -11592.46\n",
      " ARIMA(3,0,4) with zero mean     : -11624.41\n",
      " ARIMA(4,0,5) with zero mean     : -11588.56\n",
      " ARIMA(2,0,4) with zero mean     : -11583.67\n",
      " ARIMA(4,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,5) with zero mean     : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -11629.23\n",
      "\n",
      " Best model: ARIMA(3,0,4) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11489.56\n",
      " ARIMA(0,1,0) with drift         : -11407.73\n",
      " ARIMA(1,1,0) with drift         : -11459.08\n",
      " ARIMA(0,1,1) with drift         : -11469.07\n",
      " ARIMA(0,1,0)                    : -11409.73\n",
      " ARIMA(1,1,2) with drift         : -11476.07\n",
      " ARIMA(2,1,1) with drift         : -11481.59\n",
      " ARIMA(3,1,2) with drift         : -11545.27\n",
      " ARIMA(3,1,1) with drift         : -11482.08\n",
      " ARIMA(4,1,2) with drift         : -11551.58\n",
      " ARIMA(4,1,1) with drift         : -11484.96\n",
      " ARIMA(5,1,2) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11548.26\n",
      " ARIMA(5,1,1) with drift         : -11492.25\n",
      " ARIMA(5,1,3) with drift         : -11514.51\n",
      " ARIMA(4,1,2)                    : -11553.38\n",
      " ARIMA(3,1,2)                    : -11547.18\n",
      " ARIMA(4,1,1)                    : -11486.97\n",
      " ARIMA(5,1,2)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(3,1,1)                    : -11484.09\n",
      " ARIMA(3,1,3)                    : -11550.27\n",
      " ARIMA(5,1,1)                    : -11494.27\n",
      " ARIMA(5,1,3)                    : -11516.53\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11568.56\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "[1] \"70 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11488.51\n",
      " ARIMA(0,1,0) with drift         : -11406.48\n",
      " ARIMA(1,1,0) with drift         : -11458.08\n",
      " ARIMA(0,1,1) with drift         : -11467.77\n",
      " ARIMA(0,1,0)                    : -11408.49\n",
      " ARIMA(1,1,2) with drift         : -11474.57\n",
      " ARIMA(2,1,1) with drift         : -11479.9\n",
      " ARIMA(3,1,2) with drift         : -11548.76\n",
      " ARIMA(3,1,1) with drift         : -11480.84\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11550.62\n",
      " ARIMA(2,1,3) with drift         : -11554.97\n",
      " ARIMA(1,1,3) with drift         : -11477.58\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11486.33\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11556.97\n",
      " ARIMA(1,1,3)                    : -11479.59\n",
      " ARIMA(2,1,2)                    : -11490.52\n",
      " ARIMA(3,1,3)                    : -11552.63\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11476.58\n",
      " ARIMA(1,1,4)                    : -11488.34\n",
      " ARIMA(3,1,2)                    : -11550.73\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11567.3\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11539.15\n",
      " ARIMA(0,0,0) with non-zero mean : -7107.673\n",
      " ARIMA(1,0,0) with non-zero mean : -11500.94\n",
      " ARIMA(0,0,1) with non-zero mean : -9065.001\n",
      " ARIMA(0,0,0) with zero mean     : -7096.296\n",
      " ARIMA(1,0,2) with non-zero mean : -11535.64\n",
      " ARIMA(2,0,1) with non-zero mean : -11533.93\n",
      " ARIMA(3,0,2) with non-zero mean : -11608.97\n",
      " ARIMA(3,0,1) with non-zero mean : -11545.34\n",
      " ARIMA(4,0,2) with non-zero mean : -11558.35\n",
      " ARIMA(3,0,3) with non-zero mean : -11559.27\n",
      " ARIMA(2,0,3) with non-zero mean : -11551.85\n",
      " ARIMA(4,0,1) with non-zero mean : -11553.66\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11610.6\n",
      " ARIMA(2,0,2) with zero mean     : -11540.78\n",
      " ARIMA(3,0,1) with zero mean     : -11546.94\n",
      " ARIMA(4,0,2) with zero mean     : -11559.91\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -11535.53\n",
      " ARIMA(2,0,3) with zero mean     : -11553.4\n",
      " ARIMA(4,0,1) with zero mean     : -11555.22\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11611.22\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11484.71\n",
      " ARIMA(0,1,0) with drift         : -11402.92\n",
      " ARIMA(1,1,0) with drift         : -11453.72\n",
      " ARIMA(0,1,1) with drift         : -11463.3\n",
      " ARIMA(0,1,0)                    : -11404.93\n",
      " ARIMA(1,1,2) with drift         : -11470.24\n",
      " ARIMA(2,1,1) with drift         : -11475.7\n",
      " ARIMA(3,1,2) with drift         : -11537.52\n",
      " ARIMA(3,1,1) with drift         : -11476.24\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11479.22\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2) with drift         : -11549.01\n",
      "\n",
      " Best model: ARIMA(3,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11541.88\n",
      " ARIMA(0,0,0) with non-zero mean : -7110.457\n",
      " ARIMA(1,0,0) with non-zero mean : -11504.25\n",
      " ARIMA(0,0,1) with non-zero mean : -9071.053\n",
      " ARIMA(0,0,0) with zero mean     : -7095.669\n",
      " ARIMA(1,0,2) with non-zero mean : -11537.67\n",
      " ARIMA(2,0,1) with non-zero mean : -11535.9\n",
      " ARIMA(3,0,2) with non-zero mean : -11610.43\n",
      " ARIMA(3,0,1) with non-zero mean : -11547.99\n",
      " ARIMA(4,0,2) with non-zero mean : -11561.34\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11554.77\n",
      " ARIMA(4,0,1) with non-zero mean : -11556.7\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11611.69\n",
      " ARIMA(2,0,2) with zero mean     : -11543.41\n",
      " ARIMA(3,0,1) with zero mean     : -11549.52\n",
      " ARIMA(4,0,2) with zero mean     : -11562.84\n",
      " ARIMA(3,0,3) with zero mean     : -11563.17\n",
      " ARIMA(2,0,1) with zero mean     : -11537.42\n",
      " ARIMA(2,0,3) with zero mean     : -11556.22\n",
      " ARIMA(4,0,1) with zero mean     : -11558.16\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with zero mean     : -11614.18\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11489.65\n",
      " ARIMA(0,1,0) with drift         : -11408.33\n",
      " ARIMA(1,1,0) with drift         : -11457.28\n",
      " ARIMA(0,1,1) with drift         : -11467.04\n",
      " ARIMA(0,1,0)                    : -11410.33\n",
      " ARIMA(1,1,2) with drift         : -11474.81\n",
      " ARIMA(2,1,1) with drift         : -11480.57\n",
      " ARIMA(3,1,2) with drift         : -11549.16\n",
      " ARIMA(3,1,1) with drift         : -11481.79\n",
      " ARIMA(4,1,2) with drift         : -11541.63\n",
      " ARIMA(3,1,3) with drift         : -11548.71\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11551.15\n",
      " ARIMA(2,1,2)                    : -11491.66\n",
      " ARIMA(3,1,1)                    : -11483.8\n",
      " ARIMA(4,1,2)                    : -11543.55\n",
      " ARIMA(3,1,3)                    : -11550.71\n",
      " ARIMA(2,1,1)                    : -11482.57\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11566.72\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11491.43\n",
      " ARIMA(0,1,0) with drift         : -11409.56\n",
      " ARIMA(1,1,0) with drift         : -11458.85\n",
      " ARIMA(0,1,1) with drift         : -11467.94\n",
      " ARIMA(0,1,0)                    : -11411.56\n",
      " ARIMA(1,1,2) with drift         : -11476.06\n",
      " ARIMA(2,1,1) with drift         : -11481.97\n",
      " ARIMA(3,1,2) with drift         : -11552.28\n",
      " ARIMA(3,1,1) with drift         : -11482.84\n",
      " ARIMA(4,1,2) with drift         : -11551.35\n",
      " ARIMA(3,1,3) with drift         : -11551.43\n",
      " ARIMA(2,1,3) with drift         : -11554.61\n",
      " ARIMA(1,1,3) with drift         : -11479.29\n",
      " ARIMA(2,1,4) with drift         : -11548.45\n",
      " ARIMA(1,1,4) with drift         : -11487.19\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11556.62\n",
      " ARIMA(1,1,3)                    : -11481.3\n",
      " ARIMA(2,1,2)                    : -11493.44\n",
      " ARIMA(3,1,3)                    : -11553.42\n",
      " ARIMA(2,1,4)                    : -11550.41\n",
      " ARIMA(1,1,2)                    : -11478.06\n",
      " ARIMA(1,1,4)                    : -11489.19\n",
      " ARIMA(3,1,2)                    : -11554.25\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : -11567.05\n",
      "\n",
      " Best model: ARIMA(2,1,3) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11488.75\n",
      " ARIMA(0,1,0) with drift         : -11408.4\n",
      " ARIMA(1,1,0) with drift         : -11457.15\n",
      " ARIMA(0,1,1) with drift         : -11466.65\n",
      " ARIMA(0,1,0)                    : -11410.4\n",
      " ARIMA(1,1,2) with drift         : -11474.23\n",
      " ARIMA(2,1,1) with drift         : -11479.83\n",
      " ARIMA(3,1,2) with drift         : -11552.95\n",
      " ARIMA(3,1,1) with drift         : -11480.15\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11553.93\n",
      " ARIMA(1,1,3) with drift         : -11477.19\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11485.58\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11555.94\n",
      " ARIMA(1,1,3)                    : -11479.19\n",
      " ARIMA(2,1,2)                    : -11490.76\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11476.23\n",
      " ARIMA(1,1,4)                    : -11487.59\n",
      " ARIMA(3,1,2)                    : -11554.95\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11566.29\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11487.92\n",
      " ARIMA(0,1,0) with drift         : -11407.66\n",
      " ARIMA(1,1,0) with drift         : -11456.44\n",
      " ARIMA(0,1,1) with drift         : -11466.09\n",
      " ARIMA(0,1,0)                    : -11409.66\n",
      " ARIMA(1,1,2) with drift         : -11473.69\n",
      " ARIMA(2,1,1) with drift         : -11479.01\n",
      " ARIMA(3,1,2) with drift         : -11553.48\n",
      " ARIMA(3,1,1) with drift         : -11479.31\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11482.74\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11555.47\n",
      " ARIMA(2,1,2)                    : -11489.93\n",
      " ARIMA(3,1,1)                    : -11481.31\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11481.01\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11565.76\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11488.54\n",
      " ARIMA(0,1,0) with drift         : -11407.27\n",
      " ARIMA(1,1,0) with drift         : -11456.51\n",
      " ARIMA(0,1,1) with drift         : -11465.84\n",
      " ARIMA(0,1,0)                    : -11409.28\n",
      " ARIMA(1,1,2) with drift         : -11473.84\n",
      " ARIMA(2,1,1) with drift         : -11479.38\n",
      " ARIMA(3,1,2) with drift         : -11550.57\n",
      " ARIMA(3,1,1) with drift         : -11479.9\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11549.41\n",
      " ARIMA(2,1,3) with drift         : -11551.1\n",
      " ARIMA(1,1,3) with drift         : -11476.99\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11484.53\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11553.11\n",
      " ARIMA(1,1,3)                    : -11478.99\n",
      " ARIMA(2,1,2)                    : -11490.55\n",
      " ARIMA(3,1,3)                    : -11551.39\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11475.85\n",
      " ARIMA(1,1,4)                    : -11486.54\n",
      " ARIMA(3,1,2)                    : -11552.52\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11565.82\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11483.48\n",
      " ARIMA(0,1,0) with drift         : -11402.7\n",
      " ARIMA(1,1,0) with drift         : -11451.73\n",
      " ARIMA(0,1,1) with drift         : -11461.1\n",
      " ARIMA(0,1,0)                    : -11404.7\n",
      " ARIMA(1,1,2) with drift         : -11468.25\n",
      " ARIMA(2,1,1) with drift         : -11474.04\n",
      " ARIMA(3,1,2) with drift         : -11536.83\n",
      " ARIMA(3,1,1) with drift         : -11474.56\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11549\n",
      " ARIMA(1,1,3) with drift         : -11471.67\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11480.23\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11550.98\n",
      " ARIMA(1,1,3)                    : -11473.67\n",
      " ARIMA(2,1,2)                    : -11485.48\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11470.26\n",
      " ARIMA(1,1,4)                    : -11482.24\n",
      " ARIMA(3,1,2)                    : -11548.92\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11561.42\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11482.57\n",
      " ARIMA(0,1,0) with drift         : -11400.37\n",
      " ARIMA(1,1,0) with drift         : -11450.16\n",
      " ARIMA(0,1,1) with drift         : -11458.84\n",
      " ARIMA(0,1,0)                    : -11402.37\n",
      " ARIMA(1,1,2) with drift         : -11465.69\n",
      " ARIMA(2,1,1) with drift         : -11472.97\n",
      " ARIMA(3,1,2) with drift         : -11540.16\n",
      " ARIMA(3,1,1) with drift         : -11473.79\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11539.88\n",
      " ARIMA(2,1,3) with drift         : -11537.05\n",
      " ARIMA(4,1,1) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11542.16\n",
      " ARIMA(2,1,2)                    : -11484.58\n",
      " ARIMA(3,1,1)                    : -11475.8\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11541.9\n",
      " ARIMA(2,1,1)                    : -11474.98\n",
      " ARIMA(2,1,3)                    : -11538.99\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11558.63\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11479.35\n",
      " ARIMA(0,1,0) with drift         : -11399.67\n",
      " ARIMA(1,1,0) with drift         : -11448.3\n",
      " ARIMA(0,1,1) with drift         : -11457.52\n",
      " ARIMA(0,1,0)                    : -11401.67\n",
      " ARIMA(1,1,2) with drift         : -11464.19\n",
      " ARIMA(2,1,1) with drift         : -11469.55\n",
      " ARIMA(3,1,2) with drift         : -11543.91\n",
      " ARIMA(3,1,1) with drift         : -11470.27\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11545.94\n",
      " ARIMA(2,1,2)                    : -11481.36\n",
      " ARIMA(3,1,1)                    : -11472.28\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11471.56\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11557.18\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11470.5\n",
      " ARIMA(0,1,0) with drift         : -11391.25\n",
      " ARIMA(1,1,0) with drift         : -11440.04\n",
      " ARIMA(0,1,1) with drift         : -11449.27\n",
      " ARIMA(0,1,0)                    : -11393.26\n",
      " ARIMA(1,1,2) with drift         : -11455.74\n",
      " ARIMA(2,1,1) with drift         : -11461.2\n",
      " ARIMA(3,1,2) with drift         : -11525.03\n",
      " ARIMA(3,1,1) with drift         : -11462.98\n",
      " ARIMA(4,1,2) with drift         : -11520.54\n",
      " ARIMA(3,1,3) with drift         : -11524.95\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11466.16\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11526.97\n",
      " ARIMA(2,1,2)                    : -11472.51\n",
      " ARIMA(3,1,1)                    : -11464.99\n",
      " ARIMA(4,1,2)                    : -11522.35\n",
      " ARIMA(3,1,3)                    : -11526.95\n",
      " ARIMA(2,1,1)                    : -11463.21\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : -11468.17\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11548.01\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11465.7\n",
      " ARIMA(0,1,0) with drift         : -11387.82\n",
      " ARIMA(1,1,0) with drift         : -11435.95\n",
      " ARIMA(0,1,1) with drift         : -11445.09\n",
      " ARIMA(0,1,0)                    : -11389.82\n",
      " ARIMA(1,1,2) with drift         : -11451.65\n",
      " ARIMA(2,1,1) with drift         : -11456.63\n",
      " ARIMA(3,1,2) with drift         : -11531.51\n",
      " ARIMA(3,1,1) with drift         : -11456.91\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11459.7\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11533.52\n",
      " ARIMA(2,1,2)                    : -11467.71\n",
      " ARIMA(3,1,1)                    : -11458.92\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11458.63\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11543.83\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11463.12\n",
      " ARIMA(0,1,0) with drift         : -11386.02\n",
      " ARIMA(1,1,0) with drift         : -11433.6\n",
      " ARIMA(0,1,1) with drift         : -11442.58\n",
      " ARIMA(0,1,0)                    : -11388.03\n",
      " ARIMA(1,1,2) with drift         : -11448.94\n",
      " ARIMA(2,1,1) with drift         : -11453.81\n",
      " ARIMA(3,1,2) with drift         : -11525.39\n",
      " ARIMA(3,1,1) with drift         : -11454.66\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11524.52\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11457.02\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11527.4\n",
      " ARIMA(2,1,2)                    : -11465.13\n",
      " ARIMA(3,1,1)                    : -11456.67\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11526.53\n",
      " ARIMA(2,1,1)                    : -11455.82\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : -11459.03\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11541.25\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11458.77\n",
      " ARIMA(0,1,0) with drift         : -11381.36\n",
      " ARIMA(1,1,0) with drift         : -11429.64\n",
      " ARIMA(0,1,1) with drift         : -11438.35\n",
      " ARIMA(0,1,0)                    : -11383.36\n",
      " ARIMA(1,1,2) with drift         : -11444.64\n",
      " ARIMA(2,1,1) with drift         : -11449.51\n",
      " ARIMA(3,1,2) with drift         : -11523.98\n",
      " ARIMA(3,1,1) with drift         : -11449.86\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11522.53\n",
      " ARIMA(2,1,3) with drift         : -11515.81\n",
      " ARIMA(4,1,1) with drift         : -11452.53\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11525.99\n",
      " ARIMA(2,1,2)                    : -11460.78\n",
      " ARIMA(3,1,1)                    : -11451.87\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11524.55\n",
      " ARIMA(2,1,1)                    : -11451.52\n",
      " ARIMA(2,1,3)                    : -11526.75\n",
      " ARIMA(1,1,3)                    : -11449.44\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11446.65\n",
      " ARIMA(1,1,4)                    : -11457.35\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : -11537.12\n",
      "\n",
      " Best model: ARIMA(2,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11461.71\n",
      " ARIMA(0,1,0) with drift         : -11383.29\n",
      " ARIMA(1,1,0) with drift         : -11431.95\n",
      " ARIMA(0,1,1) with drift         : -11440.93\n",
      " ARIMA(0,1,0)                    : -11385.29\n",
      " ARIMA(1,1,2) with drift         : -11446.83\n",
      " ARIMA(2,1,1) with drift         : -11452.16\n",
      " ARIMA(3,1,2) with drift         : -11524.45\n",
      " ARIMA(3,1,1) with drift         : -11453.21\n",
      " ARIMA(4,1,2) with drift         : -11516.21\n",
      " ARIMA(3,1,3) with drift         : -11523.63\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11456.45\n",
      " ARIMA(4,1,3) with drift         : -11557.15\n",
      " ARIMA(5,1,3) with drift         : -11485.61\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(5,1,2) with drift         : Inf\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(4,1,3)                    : -11558.96\n",
      " ARIMA(3,1,3)                    : -11525.63\n",
      " ARIMA(4,1,2)                    : -11518.15\n",
      " ARIMA(5,1,3)                    : -11487.74\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11526.44\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(5,1,2)                    : Inf\n",
      " ARIMA(5,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11539.94\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11464.63\n",
      " ARIMA(0,1,0) with drift         : -11385.89\n",
      " ARIMA(1,1,0) with drift         : -11435.55\n",
      " ARIMA(0,1,1) with drift         : -11444.16\n",
      " ARIMA(0,1,0)                    : -11387.89\n",
      " ARIMA(1,1,2) with drift         : -11450.41\n",
      " ARIMA(2,1,1) with drift         : -11455.3\n",
      " ARIMA(3,1,2) with drift         : -11527.35\n",
      " ARIMA(3,1,1) with drift         : -11455.78\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11529.4\n",
      " ARIMA(1,1,3) with drift         : -11453.12\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11460.64\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11531.41\n",
      " ARIMA(1,1,3)                    : -11455.13\n",
      " ARIMA(2,1,2)                    : -11466.63\n",
      " ARIMA(3,1,3)                    : -11528.15\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11452.43\n",
      " ARIMA(1,1,4)                    : -11462.65\n",
      " ARIMA(3,1,2)                    : -11529.33\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : -11541.1\n",
      "\n",
      " Best model: ARIMA(2,1,3) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11467.17\n",
      " ARIMA(0,1,0) with drift         : -11390.13\n",
      " ARIMA(1,1,0) with drift         : -11438.99\n",
      " ARIMA(0,1,1) with drift         : -11447.86\n",
      " ARIMA(0,1,0)                    : -11392.14\n",
      " ARIMA(1,1,2) with drift         : -11453.3\n",
      " ARIMA(2,1,1) with drift         : -11458.1\n",
      " ARIMA(3,1,2) with drift         : -11528.67\n",
      " ARIMA(3,1,1) with drift         : -11458.43\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11527.28\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11461.22\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11530.68\n",
      " ARIMA(2,1,2)                    : -11469.17\n",
      " ARIMA(3,1,1)                    : -11460.44\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11529.3\n",
      " ARIMA(2,1,1)                    : -11460.11\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : -11463.24\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11544.53\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11457.26\n",
      " ARIMA(0,1,0) with drift         : -11383.29\n",
      " ARIMA(1,1,0) with drift         : -11430.38\n",
      " ARIMA(0,1,1) with drift         : -11438.84\n",
      " ARIMA(0,1,0)                    : -11385.28\n",
      " ARIMA(1,1,2) with drift         : -11444.28\n",
      " ARIMA(2,1,1) with drift         : -11448.59\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11522.67\n",
      " ARIMA(1,1,3) with drift         : -11446.31\n",
      " ARIMA(3,1,3) with drift         : -11520.59\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11454.56\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11524.67\n",
      " ARIMA(1,1,3)                    : -11448.3\n",
      " ARIMA(2,1,2)                    : -11459.25\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11446.27\n",
      " ARIMA(1,1,4)                    : -11456.53\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : -11535.62\n",
      "\n",
      " Best model: ARIMA(2,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11426.76\n",
      " ARIMA(0,1,0) with drift         : -11358.01\n",
      " ARIMA(1,1,0) with drift         : -11402.29\n",
      " ARIMA(0,1,1) with drift         : -11410.68\n",
      " ARIMA(0,1,0)                    : -11360.01\n",
      " ARIMA(1,1,2) with drift         : -11416.65\n",
      " ARIMA(2,1,1) with drift         : -11420.05\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11411.29\n",
      " ARIMA(1,1,3) with drift         : -11417.46\n",
      " ARIMA(3,1,1) with drift         : -11419.14\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11428.77\n",
      " ARIMA(1,1,2)                    : -11418.66\n",
      " ARIMA(2,1,1)                    : -11422.06\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(1,1,1)                    : -11413.29\n",
      " ARIMA(1,1,3)                    : -11419.46\n",
      " ARIMA(3,1,1)                    : -11421.15\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11438.63\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11419.96\n",
      " ARIMA(0,1,0) with drift         : -11350.92\n",
      " ARIMA(1,1,0) with drift         : -11394.9\n",
      " ARIMA(0,1,1) with drift         : -11403.11\n",
      " ARIMA(0,1,0)                    : -11352.92\n",
      " ARIMA(1,1,2) with drift         : -11408.89\n",
      " ARIMA(2,1,1) with drift         : -11412.58\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11403.44\n",
      " ARIMA(1,1,3) with drift         : -11410.03\n",
      " ARIMA(3,1,1) with drift         : -11411.93\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11421.97\n",
      " ARIMA(1,1,2)                    : -11410.89\n",
      " ARIMA(2,1,1)                    : -11414.58\n",
      " ARIMA(3,1,2)                    : -11484.89\n",
      " ARIMA(3,1,1)                    : -11413.93\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : -11417.69\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11497.38\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11416.52\n",
      " ARIMA(0,1,0) with drift         : -11347.64\n",
      " ARIMA(1,1,0) with drift         : -11391.62\n",
      " ARIMA(0,1,1) with drift         : -11399.55\n",
      " ARIMA(0,1,0)                    : -11349.64\n",
      " ARIMA(1,1,2) with drift         : -11405.39\n",
      " ARIMA(2,1,1) with drift         : -11409.03\n",
      " ARIMA(3,1,2) with drift         : -11479.96\n",
      " ARIMA(3,1,1) with drift         : -11408.41\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11481.73\n",
      " ARIMA(1,1,3) with drift         : -11406.63\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11414.79\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11483.74\n",
      " ARIMA(1,1,3)                    : -11408.63\n",
      " ARIMA(2,1,2)                    : -11418.53\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11407.41\n",
      " ARIMA(1,1,4)                    : -11416.8\n",
      " ARIMA(3,1,2)                    : -11481.98\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : -11494.17\n",
      "\n",
      " Best model: ARIMA(2,1,3)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11407.96\n",
      " ARIMA(0,1,0) with drift         : -11338.46\n",
      " ARIMA(1,1,0) with drift         : -11382.61\n",
      " ARIMA(0,1,1) with drift         : -11390.38\n",
      " ARIMA(0,1,0)                    : -11340.46\n",
      " ARIMA(1,1,2) with drift         : -11396.61\n",
      " ARIMA(2,1,1) with drift         : -11400.55\n",
      " ARIMA(3,1,2) with drift         : -11471.9\n",
      " ARIMA(3,1,1) with drift         : -11399.74\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11470.53\n",
      " ARIMA(4,1,1) with drift         : -11403.38\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11473.9\n",
      " ARIMA(2,1,2)                    : -11409.97\n",
      " ARIMA(3,1,1)                    : -11401.75\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11402.56\n",
      " ARIMA(2,1,3)                    : -11472.5\n",
      " ARIMA(4,1,1)                    : -11405.4\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11484.35\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "[1] \"80 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11396.17\n",
      " ARIMA(0,1,0) with drift         : -11328.02\n",
      " ARIMA(1,1,0) with drift         : -11371.4\n",
      " ARIMA(0,1,1) with drift         : -11379.49\n",
      " ARIMA(0,1,0)                    : -11330.02\n",
      " ARIMA(1,1,2) with drift         : -11385.91\n",
      " ARIMA(2,1,1) with drift         : -11389.47\n",
      " ARIMA(3,1,2) with drift         : -11458.66\n",
      " ARIMA(3,1,1) with drift         : -11388.42\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11458.39\n",
      " ARIMA(4,1,1) with drift         : -11391.51\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11460.67\n",
      " ARIMA(2,1,2)                    : -11398.17\n",
      " ARIMA(3,1,1)                    : -11390.41\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11391.47\n",
      " ARIMA(2,1,3)                    : -11460.41\n",
      " ARIMA(4,1,1)                    : -11393.51\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11472.04\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11384.39\n",
      " ARIMA(0,1,0) with drift         : -11316.01\n",
      " ARIMA(1,1,0) with drift         : -11360.76\n",
      " ARIMA(0,1,1) with drift         : -11368.5\n",
      " ARIMA(0,1,0)                    : -11318.01\n",
      " ARIMA(1,1,2) with drift         : -11375.04\n",
      " ARIMA(2,1,1) with drift         : -11378.36\n",
      " ARIMA(3,1,2) with drift         : -11443.48\n",
      " ARIMA(3,1,1) with drift         : -11377.21\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11445.13\n",
      " ARIMA(2,1,3) with drift         : -11446.41\n",
      " ARIMA(1,1,3) with drift         : -11375.64\n",
      " ARIMA(2,1,4) with drift         : -11438.15\n",
      " ARIMA(1,1,4) with drift         : -11381.98\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11440.96\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3) with drift         : -11458.24\n",
      "\n",
      " Best model: ARIMA(2,1,3) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11382.84\n",
      " ARIMA(0,1,0) with drift         : -11314.2\n",
      " ARIMA(1,1,0) with drift         : -11359.08\n",
      " ARIMA(0,1,1) with drift         : -11366.52\n",
      " ARIMA(0,1,0)                    : -11316.21\n",
      " ARIMA(1,1,2) with drift         : -11373.79\n",
      " ARIMA(2,1,1) with drift         : -11377.02\n",
      " ARIMA(3,1,2) with drift         : -11443.18\n",
      " ARIMA(3,1,1) with drift         : -11375.83\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11441.2\n",
      " ARIMA(2,1,3) with drift         : -11440.68\n",
      " ARIMA(4,1,1) with drift         : -11378.62\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11445.18\n",
      " ARIMA(2,1,2)                    : -11384.85\n",
      " ARIMA(3,1,1)                    : -11377.84\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11443.21\n",
      " ARIMA(2,1,1)                    : -11379.03\n",
      " ARIMA(2,1,3)                    : -11442.69\n",
      " ARIMA(4,1,1)                    : -11380.64\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11457.01\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11385.06\n",
      " ARIMA(0,1,0) with drift         : -11317.34\n",
      " ARIMA(1,1,0) with drift         : -11361\n",
      " ARIMA(0,1,1) with drift         : -11369.29\n",
      " ARIMA(0,1,0)                    : -11319.34\n",
      " ARIMA(1,1,2) with drift         : -11375.57\n",
      " ARIMA(2,1,1) with drift         : -11378.89\n",
      " ARIMA(3,1,2) with drift         : -11447.76\n",
      " ARIMA(3,1,1) with drift         : -11377.8\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,1) with drift         : -11380.61\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11449.77\n",
      " ARIMA(2,1,2)                    : -11387.06\n",
      " ARIMA(3,1,1)                    : -11379.81\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,1)                    : -11380.9\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(4,1,1)                    : -11382.62\n",
      " ARIMA(4,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,2)                    : -11460.04\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11381.42\n",
      " ARIMA(0,1,0) with drift         : -11314.33\n",
      " ARIMA(1,1,0) with drift         : -11358.1\n",
      " ARIMA(0,1,1) with drift         : -11366.38\n",
      " ARIMA(0,1,0)                    : -11316.34\n",
      " ARIMA(1,1,2) with drift         : -11372.29\n",
      " ARIMA(2,1,1) with drift         : -11375.63\n",
      " ARIMA(3,1,2) with drift         : -11437\n",
      " ARIMA(3,1,1) with drift         : -11375\n",
      " ARIMA(4,1,2) with drift         : -11443.02\n",
      " ARIMA(4,1,1) with drift         : -11377.67\n",
      " ARIMA(5,1,2) with drift         : -11383.28\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(5,1,1) with drift         : -11384.28\n",
      " ARIMA(5,1,3) with drift         : -11460.66\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(5,1,3)                    : -11406.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : -11455.43\n",
      "\n",
      " Best model: ARIMA(3,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11376\n",
      " ARIMA(0,1,0) with drift         : -11310.81\n",
      " ARIMA(1,1,0) with drift         : -11353.5\n",
      " ARIMA(0,1,1) with drift         : -11361.68\n",
      " ARIMA(0,1,0)                    : -11312.81\n",
      " ARIMA(1,1,2) with drift         : -11367.66\n",
      " ARIMA(2,1,1) with drift         : -11370.74\n",
      " ARIMA(3,1,2) with drift         : -11435.23\n",
      " ARIMA(3,1,1) with drift         : -11369.84\n",
      " ARIMA(4,1,2) with drift         : -11435.36\n",
      " ARIMA(4,1,1) with drift         : -11372.57\n",
      " ARIMA(5,1,2) with drift         : -11379.67\n",
      " ARIMA(4,1,3) with drift         : -11462.93\n",
      " ARIMA(3,1,3) with drift         : -11437.7\n",
      " ARIMA(5,1,3) with drift         : -11450.93\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(5,1,4) with drift         : -11457.04\n",
      " ARIMA(4,1,3)                    : -11464.8\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(4,1,2)                    : -11437.24\n",
      " ARIMA(5,1,3)                    : -11452.91\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11437.19\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(5,1,2)                    : -11381.68\n",
      " ARIMA(5,1,4)                    : -11458.98\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(5,1,4)                    : Inf\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(5,1,3)                    : Inf\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(3,1,2)                    : -11451.79\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11377.46\n",
      " ARIMA(0,1,0) with drift         : -11311.79\n",
      " ARIMA(1,1,0) with drift         : -11353.83\n",
      " ARIMA(0,1,1) with drift         : -11361.84\n",
      " ARIMA(0,1,0)                    : -11313.79\n",
      " ARIMA(1,1,2) with drift         : -11367.56\n",
      " ARIMA(2,1,1) with drift         : -11372.91\n",
      " ARIMA(3,1,2) with drift         : -11421.85\n",
      " ARIMA(3,1,1) with drift         : -11371.51\n",
      " ARIMA(4,1,2) with drift         : -11441.18\n",
      " ARIMA(4,1,1) with drift         : -11374.72\n",
      " ARIMA(5,1,2) with drift         : -11382.23\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11422.45\n",
      " ARIMA(5,1,1) with drift         : -11383.49\n",
      " ARIMA(5,1,3) with drift         : -11452.79\n",
      " ARIMA(5,1,4) with drift         : -11453.95\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(5,1,5) with drift         : Inf\n",
      " ARIMA(4,1,5) with drift         : Inf\n",
      " ARIMA(5,1,4)                    : -11456\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(5,1,3)                    : -11454.45\n",
      " ARIMA(5,1,5)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(4,1,5)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,1,4)                    : Inf\n",
      " ARIMA(5,1,3)                    : Inf\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : -11449.4\n",
      "\n",
      " Best model: ARIMA(3,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11401.14\n",
      " ARIMA(0,1,0) with drift         : -11333.59\n",
      " ARIMA(1,1,0) with drift         : -11375.37\n",
      " ARIMA(0,1,1) with drift         : -11383.32\n",
      " ARIMA(0,1,0)                    : -11335.6\n",
      " ARIMA(1,1,2) with drift         : -11388.38\n",
      " ARIMA(2,1,1) with drift         : -11397.14\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11436.48\n",
      " ARIMA(1,1,3) with drift         : -11388.8\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11395.96\n",
      " ARIMA(3,1,4) with drift         : -11404.42\n",
      " ARIMA(2,1,3)                    : -11438.39\n",
      " ARIMA(1,1,3)                    : -11390.8\n",
      " ARIMA(2,1,2)                    : -11403.15\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11390.39\n",
      " ARIMA(1,1,4)                    : -11397.97\n",
      " ARIMA(3,1,2)                    : -11399.44\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11409.43\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11414.62\n",
      " ARIMA(0,1,0) with drift         : -11349.66\n",
      " ARIMA(1,1,0) with drift         : -11391.07\n",
      " ARIMA(0,1,1) with drift         : -11398.77\n",
      " ARIMA(0,1,0)                    : -11351.66\n",
      " ARIMA(1,1,2) with drift         : -11404.51\n",
      " ARIMA(2,1,1) with drift         : -11408.59\n",
      " ARIMA(3,1,2) with drift         : -11474.76\n",
      " ARIMA(3,1,1) with drift         : -11407.28\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11474.66\n",
      " ARIMA(2,1,3) with drift         : -11475\n",
      " ARIMA(1,1,3) with drift         : -11405.01\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11411.68\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11476.95\n",
      " ARIMA(1,1,3)                    : -11407\n",
      " ARIMA(2,1,2)                    : -11416.63\n",
      " ARIMA(3,1,3)                    : -11476.66\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11406.51\n",
      " ARIMA(1,1,4)                    : -11413.69\n",
      " ARIMA(3,1,2)                    : -11476.73\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : -11489.85\n",
      "\n",
      " Best model: ARIMA(3,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11417\n",
      " ARIMA(0,1,0) with drift         : -11350.81\n",
      " ARIMA(1,1,0) with drift         : -11393.43\n",
      " ARIMA(0,1,1) with drift         : -11401.37\n",
      " ARIMA(0,1,0)                    : -11352.81\n",
      " ARIMA(1,1,2) with drift         : -11408.15\n",
      " ARIMA(2,1,1) with drift         : -11411.62\n",
      " ARIMA(3,1,2) with drift         : -11478.61\n",
      " ARIMA(3,1,1) with drift         : -11410.14\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11477.88\n",
      " ARIMA(2,1,3) with drift         : -11480.64\n",
      " ARIMA(1,1,3) with drift         : -11408.04\n",
      " ARIMA(2,1,4) with drift         : -11470.54\n",
      " ARIMA(1,1,4) with drift         : -11413.2\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11482.64\n",
      " ARIMA(1,1,3)                    : -11410.05\n",
      " ARIMA(2,1,2)                    : -11419\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,4)                    : -11472.55\n",
      " ARIMA(1,1,2)                    : -11410.17\n",
      " ARIMA(1,1,4)                    : -11415.2\n",
      " ARIMA(3,1,2)                    : -11480.59\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : -11494.28\n",
      "\n",
      " Best model: ARIMA(3,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11428.15\n",
      " ARIMA(0,1,0) with drift         : -11363.82\n",
      " ARIMA(1,1,0) with drift         : -11405.04\n",
      " ARIMA(0,1,1) with drift         : -11413.13\n",
      " ARIMA(0,1,0)                    : -11365.82\n",
      " ARIMA(1,1,2) with drift         : -11419.24\n",
      " ARIMA(2,1,1) with drift         : -11423.1\n",
      " ARIMA(3,1,2) with drift         : -11485.43\n",
      " ARIMA(3,1,1) with drift         : -11421.44\n",
      " ARIMA(4,1,2) with drift         : -11470.37\n",
      " ARIMA(3,1,3) with drift         : -11484.77\n",
      " ARIMA(2,1,3) with drift         : -11487.17\n",
      " ARIMA(1,1,3) with drift         : -11419.2\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11425.26\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11489.13\n",
      " ARIMA(1,1,3)                    : -11421.2\n",
      " ARIMA(2,1,2)                    : -11430.16\n",
      " ARIMA(3,1,3)                    : -11486.74\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(1,1,2)                    : -11421.24\n",
      " ARIMA(1,1,4)                    : -11427.26\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11439.42\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11445.44\n",
      " ARIMA(0,1,0) with drift         : -11379.2\n",
      " ARIMA(1,1,0) with drift         : -11421.84\n",
      " ARIMA(0,1,1) with drift         : -11429.11\n",
      " ARIMA(0,1,0)                    : -11381.2\n",
      " ARIMA(1,1,2) with drift         : -11437.71\n",
      " ARIMA(2,1,1) with drift         : -11440.18\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11507.1\n",
      " ARIMA(1,1,3) with drift         : -11437.5\n",
      " ARIMA(3,1,3) with drift         : -11506.37\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11443.66\n",
      " ARIMA(3,1,4) with drift         : -11533.54\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(3,1,5) with drift         : -11472.61\n",
      " ARIMA(2,1,5) with drift         : -11477.81\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(4,1,5) with drift         : -11542.91\n",
      " ARIMA(5,1,5) with drift         : Inf\n",
      " ARIMA(5,1,4) with drift         : -11515.88\n",
      " ARIMA(4,1,5)                    : -11544.81\n",
      " ARIMA(3,1,5)                    : -11474.62\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(5,1,5)                    : Inf\n",
      " ARIMA(3,1,4)                    : -11533.75\n",
      " ARIMA(5,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,5)                    : Inf\n",
      " ARIMA(4,1,5) with drift         : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,5) with drift         : -11486.28\n",
      "\n",
      " Best model: ARIMA(2,1,5) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11460.12\n",
      " ARIMA(0,1,0) with drift         : -11392.48\n",
      " ARIMA(1,1,0) with drift         : -11436.18\n",
      " ARIMA(0,1,1) with drift         : -11443.02\n",
      " ARIMA(0,1,0)                    : -11394.47\n",
      " ARIMA(1,1,2) with drift         : -11452\n",
      " ARIMA(2,1,1) with drift         : -11454.69\n",
      " ARIMA(3,1,2) with drift         : -11512.45\n",
      " ARIMA(3,1,1) with drift         : -11453.12\n",
      " ARIMA(4,1,2) with drift         : -11538.32\n",
      " ARIMA(4,1,1) with drift         : -11454.98\n",
      " ARIMA(5,1,2) with drift         : -11480.96\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11519.43\n",
      " ARIMA(5,1,1) with drift         : -11465.65\n",
      " ARIMA(5,1,3) with drift         : -11541.25\n",
      " ARIMA(5,1,4) with drift         : -11546.31\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(5,1,5) with drift         : Inf\n",
      " ARIMA(4,1,5) with drift         : Inf\n",
      " ARIMA(5,1,4)                    : -11548.31\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(5,1,3)                    : -11543.22\n",
      " ARIMA(5,1,5)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(4,1,5)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,1,4)                    : Inf\n",
      " ARIMA(5,1,4) with drift         : Inf\n",
      " ARIMA(5,1,3)                    : Inf\n",
      " ARIMA(5,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : -11520.63\n",
      "\n",
      " Best model: ARIMA(3,1,2) with drift         \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11473.66\n",
      " ARIMA(0,1,0) with drift         : -11405.4\n",
      " ARIMA(1,1,0) with drift         : -11449.03\n",
      " ARIMA(0,1,1) with drift         : -11457.36\n",
      " ARIMA(0,1,0)                    : -11407.4\n",
      " ARIMA(1,1,2) with drift         : -11465.21\n",
      " ARIMA(2,1,1) with drift         : -11468.1\n",
      " ARIMA(3,1,2) with drift         : -11522.67\n",
      " ARIMA(3,1,1) with drift         : -11466.94\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,3) with drift         : -11523.94\n",
      " ARIMA(2,1,3) with drift         : -11530.31\n",
      " ARIMA(1,1,3) with drift         : -11464.92\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11469.99\n",
      " ARIMA(3,1,4) with drift         : -11553.79\n",
      " ARIMA(4,1,4) with drift         : Inf\n",
      " ARIMA(3,1,5) with drift         : -11506.29\n",
      " ARIMA(2,1,5) with drift         : Inf\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(4,1,5) with drift         : Inf\n",
      " ARIMA(3,1,4)                    : -11555.37\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(3,1,3)                    : -11525.89\n",
      " ARIMA(4,1,4)                    : Inf\n",
      " ARIMA(3,1,5)                    : -11508.29\n",
      " ARIMA(2,1,3)                    : -11532.31\n",
      " ARIMA(2,1,5)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(4,1,5)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(3,1,5)                    : -11517.89\n",
      "\n",
      " Best model: ARIMA(3,1,5)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11563.65\n",
      " ARIMA(0,0,0) with non-zero mean : -7092.942\n",
      " ARIMA(1,0,0) with non-zero mean : -11532.35\n",
      " ARIMA(0,0,1) with non-zero mean : -9062.662\n",
      " ARIMA(0,0,0) with zero mean     : -7069.286\n",
      " ARIMA(1,0,2) with non-zero mean : -11561.12\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11629.33\n",
      " ARIMA(3,0,1) with non-zero mean : -11567.62\n",
      " ARIMA(4,0,2) with non-zero mean : -11577.15\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11570.59\n",
      " ARIMA(4,0,1) with non-zero mean : -11573.86\n",
      " ARIMA(4,0,3) with non-zero mean : -11639.6\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : -11626.91\n",
      " ARIMA(5,0,4) with non-zero mean : -11629.53\n",
      " ARIMA(4,0,3) with zero mean     : -11641.48\n",
      " ARIMA(3,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with zero mean     : -11643.49\n",
      " ARIMA(3,0,2) with zero mean     : -11630.38\n",
      " ARIMA(4,0,1) with zero mean     : -11575.2\n",
      " ARIMA(5,0,2) with zero mean     : -11627.71\n",
      " ARIMA(3,0,1) with zero mean     : -11569\n",
      " ARIMA(5,0,1) with zero mean     : -11604.21\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -11634.59\n",
      "\n",
      " Best model: ARIMA(3,0,2) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11531.84\n",
      " ARIMA(0,1,0) with drift         : -11462.99\n",
      " ARIMA(1,1,0) with drift         : -11505.42\n",
      " ARIMA(0,1,1) with drift         : -11513.88\n",
      " ARIMA(0,1,0)                    : -11464.99\n",
      " ARIMA(1,1,2) with drift         : -11520.31\n",
      " ARIMA(2,1,1) with drift         : -11524.07\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11514.74\n",
      " ARIMA(1,1,3) with drift         : -11521.21\n",
      " ARIMA(3,1,1) with drift         : -11523.29\n",
      " ARIMA(3,1,3) with drift         : -11595.73\n",
      " ARIMA(4,1,3) with drift         : Inf\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(4,1,2) with drift         : -11603.16\n",
      " ARIMA(4,1,1) with drift         : -11525.22\n",
      " ARIMA(5,1,2) with drift         : -11560.26\n",
      " ARIMA(5,1,1) with drift         : -11535.35\n",
      " ARIMA(5,1,3) with drift         : -11560.94\n",
      " ARIMA(4,1,2)                    : -11605.05\n",
      " ARIMA(3,1,2)                    : -11599.29\n",
      " ARIMA(4,1,1)                    : -11527.23\n",
      " ARIMA(5,1,2)                    : -11562.29\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(3,1,1)                    : -11525.3\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(5,1,1)                    : -11537.37\n",
      " ARIMA(5,1,3)                    : -11562.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(4,1,2) with drift         : Inf\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(5,1,3)                    : Inf\n",
      " ARIMA(5,1,2)                    : -11574.41\n",
      "\n",
      " Best model: ARIMA(5,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11540.3\n",
      " ARIMA(0,1,0) with drift         : -11469.86\n",
      " ARIMA(1,1,0) with drift         : -11512.62\n",
      " ARIMA(0,1,1) with drift         : -11521.01\n",
      " ARIMA(0,1,0)                    : -11471.86\n",
      " ARIMA(1,1,2) with drift         : -11527.97\n",
      " ARIMA(2,1,1) with drift         : -11531.89\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(1,1,1) with drift         : -11522.06\n",
      " ARIMA(1,1,3) with drift         : -11529.09\n",
      " ARIMA(3,1,1) with drift         : -11531.68\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,2)                    : -11542.31\n",
      " ARIMA(1,1,2)                    : -11529.98\n",
      " ARIMA(2,1,1)                    : -11533.89\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(1,1,1)                    : -11524.06\n",
      " ARIMA(1,1,3)                    : -11531.09\n",
      " ARIMA(3,1,1)                    : -11533.69\n",
      " ARIMA(3,1,3)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,1,2)                    : -11551.54\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,1,2) with drift         : -11545.43\n",
      " ARIMA(0,1,0) with drift         : -11476.22\n",
      " ARIMA(1,1,0) with drift         : -11519.24\n",
      " ARIMA(0,1,1) with drift         : -11527.35\n",
      " ARIMA(0,1,0)                    : -11478.22\n",
      " ARIMA(1,1,2) with drift         : -11535.3\n",
      " ARIMA(2,1,1) with drift         : -11538.4\n",
      " ARIMA(3,1,2) with drift         : Inf\n",
      " ARIMA(2,1,3) with drift         : -11606.01\n",
      " ARIMA(1,1,3) with drift         : -11536.07\n",
      " ARIMA(3,1,3) with drift         : Inf\n",
      " ARIMA(2,1,4) with drift         : Inf\n",
      " ARIMA(1,1,4) with drift         : -11543.1\n",
      " ARIMA(3,1,4) with drift         : Inf\n",
      " ARIMA(2,1,3)                    : -11608.02\n",
      " ARIMA(1,1,3)                    : -11538.06\n",
      " ARIMA(2,1,2)                    : -11547.44\n",
      " ARIMA(3,1,3)                    : -11608.56\n",
      " ARIMA(3,1,2)                    : Inf\n",
      " ARIMA(4,1,3)                    : Inf\n",
      " ARIMA(3,1,4)                    : Inf\n",
      " ARIMA(2,1,4)                    : Inf\n",
      " ARIMA(4,1,2)                    : -11548.72\n",
      " ARIMA(4,1,4)                    : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,1,3)                    : Inf\n",
      " ARIMA(2,1,3)                    : Inf\n",
      " ARIMA(2,1,3) with drift         : Inf\n",
      " ARIMA(4,1,2)                    : Inf\n",
      " ARIMA(2,1,2)                    : -11557.99\n",
      "\n",
      " Best model: ARIMA(2,1,2)                    \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11626.41\n",
      " ARIMA(0,0,0) with non-zero mean : -7180.606\n",
      " ARIMA(1,0,0) with non-zero mean : -11595.23\n",
      " ARIMA(0,0,1) with non-zero mean : -9148.012\n",
      " ARIMA(0,0,0) with zero mean     : -7147.407\n",
      " ARIMA(1,0,2) with non-zero mean : -11622.24\n",
      " ARIMA(2,0,1) with non-zero mean : -11605.97\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11635.32\n",
      " ARIMA(1,0,3) with non-zero mean : -11637.31\n",
      " ARIMA(0,0,3) with non-zero mean : -10542.52\n",
      " ARIMA(1,0,4) with non-zero mean : -11636.59\n",
      " ARIMA(0,0,2) with non-zero mean : -10038.07\n",
      " ARIMA(0,0,4) with non-zero mean : -10971.87\n",
      " ARIMA(2,0,4) with non-zero mean : -11663.67\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11674.55\n",
      " ARIMA(1,0,5) with non-zero mean : -11642.38\n",
      " ARIMA(3,0,5) with non-zero mean : -11671.84\n",
      " ARIMA(2,0,5) with zero mean     : -11675.29\n",
      " ARIMA(1,0,5) with zero mean     : -11643.28\n",
      " ARIMA(2,0,4) with zero mean     : -11664.18\n",
      " ARIMA(3,0,5) with zero mean     : -11672.8\n",
      " ARIMA(1,0,4) with zero mean     : -11637.4\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,5) with zero mean     : -11676.74\n",
      "\n",
      " Best model: ARIMA(2,0,5) with zero mean     \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11637.1\n",
      " ARIMA(0,0,0) with non-zero mean : -7183.094\n",
      " ARIMA(1,0,0) with non-zero mean : -11607.12\n",
      " ARIMA(0,0,1) with non-zero mean : -9156.432\n",
      " ARIMA(0,0,0) with zero mean     : -7151.929\n",
      " ARIMA(1,0,2) with non-zero mean : -11633.92\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,3) with non-zero mean : -11646.52\n",
      " ARIMA(1,0,3) with non-zero mean : -11649.07\n",
      " ARIMA(0,0,3) with non-zero mean : -10551.96\n",
      " ARIMA(1,0,4) with non-zero mean : -11648.28\n",
      " ARIMA(0,0,2) with non-zero mean : -10047.3\n",
      " ARIMA(0,0,4) with non-zero mean : -10983.71\n",
      " ARIMA(2,0,4) with non-zero mean : -11680.57\n",
      " ARIMA(3,0,4) with non-zero mean : -11756.89\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11689.65\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(2,0,5) with non-zero mean : -11690\n",
      "\n",
      " Best model: ARIMA(2,0,5) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -11726.86\n",
      " ARIMA(0,0,0) with non-zero mean : -7219.871\n",
      " ARIMA(1,0,0) with non-zero mean : -11704.34\n",
      " ARIMA(0,0,1) with non-zero mean : -9202.304\n",
      " ARIMA(0,0,0) with zero mean     : -7181.348\n",
      " ARIMA(1,0,2) with non-zero mean : -11725.28\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -11821.89\n",
      " ARIMA(3,0,1) with non-zero mean : -11737.16\n",
      " ARIMA(4,0,2) with non-zero mean : -11746.45\n",
      " ARIMA(3,0,3) with non-zero mean : -11841.21\n",
      " ARIMA(2,0,3) with non-zero mean : -11736.78\n",
      " ARIMA(4,0,3) with non-zero mean : -11883.48\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -11882.26\n",
      " ARIMA(3,0,4) with non-zero mean : -11841.53\n",
      " ARIMA(5,0,2) with non-zero mean : -11819.23\n",
      " ARIMA(5,0,4) with non-zero mean : -11834.07\n",
      " ARIMA(4,0,3) with zero mean     : -11883.42\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,1) with non-zero mean : -11727.48\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12048.88\n",
      " ARIMA(0,0,0) with non-zero mean : -7798.523\n",
      " ARIMA(1,0,0) with non-zero mean : -12046.89\n",
      " ARIMA(0,0,1) with non-zero mean : -9695.57\n",
      " ARIMA(0,0,0) with zero mean     : -7706.469\n",
      " ARIMA(1,0,2) with non-zero mean : -12050.93\n",
      " ARIMA(0,0,2) with non-zero mean : -10590.18\n",
      " ARIMA(1,0,1) with non-zero mean : -12052.27\n",
      " ARIMA(2,0,1) with non-zero mean : Inf\n",
      " ARIMA(2,0,0) with non-zero mean : -12051.33\n",
      " ARIMA(1,0,1) with zero mean     : -12048.87\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,1) with non-zero mean : -12021.88\n",
      "\n",
      " Best model: ARIMA(1,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12434.36\n",
      " ARIMA(0,0,0) with non-zero mean : -7980.504\n",
      " ARIMA(1,0,0) with non-zero mean : -12372.67\n",
      " ARIMA(0,0,1) with non-zero mean : -9941.412\n",
      " ARIMA(0,0,0) with zero mean     : -7857.589\n",
      " ARIMA(1,0,2) with non-zero mean : -12376.41\n",
      " ARIMA(2,0,1) with non-zero mean : -12436.06\n",
      " ARIMA(1,0,1) with non-zero mean : -12377.95\n",
      " ARIMA(2,0,0) with non-zero mean : -12437.96\n",
      " ARIMA(3,0,0) with non-zero mean : -12435.15\n",
      " ARIMA(3,0,1) with non-zero mean : -12454.73\n",
      " ARIMA(4,0,1) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -12464.93\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -12537.98\n",
      " ARIMA(2,0,3) with non-zero mean : -12436.37\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -12558.88\n",
      " ARIMA(2,0,4) with non-zero mean : -12437.89\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : -12482.54\n",
      " ARIMA(2,0,5) with non-zero mean : -12443.38\n",
      " ARIMA(4,0,5) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : -12558.06\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,5) with non-zero mean : -12501.26\n",
      "\n",
      " Best model: ARIMA(3,0,5) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12731.55\n",
      " ARIMA(0,0,0) with non-zero mean : -8064.913\n",
      " ARIMA(1,0,0) with non-zero mean : -12677.97\n",
      " ARIMA(0,0,1) with non-zero mean : -10058.9\n",
      " ARIMA(0,0,0) with zero mean     : -7927.111\n",
      " ARIMA(1,0,2) with non-zero mean : -12680.87\n",
      " ARIMA(2,0,1) with non-zero mean : -12729.28\n",
      " ARIMA(3,0,2) with non-zero mean : -12759.62\n",
      " ARIMA(3,0,1) with non-zero mean : -12730.55\n",
      " ARIMA(4,0,2) with non-zero mean : -12811.44\n",
      " ARIMA(4,0,1) with non-zero mean : -12738.03\n",
      " ARIMA(5,0,2) with non-zero mean : -12780.21\n",
      " ARIMA(4,0,3) with non-zero mean : -12809.91\n",
      " ARIMA(3,0,3) with non-zero mean : -12761.06\n",
      " ARIMA(5,0,1) with non-zero mean : -12747.6\n",
      " ARIMA(5,0,3) with non-zero mean : -12832.04\n",
      " ARIMA(5,0,4) with non-zero mean : -12815.29\n",
      " ARIMA(4,0,4) with non-zero mean : -12808.46\n",
      " ARIMA(5,0,3) with zero mean     : -12788.39\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -12735.86\n",
      "\n",
      " Best model: ARIMA(5,0,3) with zero mean     \n",
      "\n",
      "[1] \"90 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12838.17\n",
      " ARIMA(0,0,0) with non-zero mean : -8091.392\n",
      " ARIMA(1,0,0) with non-zero mean : -12837.14\n",
      " ARIMA(0,0,1) with non-zero mean : -10097.45\n",
      " ARIMA(0,0,0) with zero mean     : -7938.12\n",
      " ARIMA(1,0,2) with non-zero mean : -12838.32\n",
      " ARIMA(0,0,2) with non-zero mean : -11279.5\n",
      " ARIMA(1,0,1) with non-zero mean : -12837.52\n",
      " ARIMA(1,0,3) with non-zero mean : -12836.31\n",
      " ARIMA(0,0,3) with non-zero mean : -11685.67\n",
      " ARIMA(2,0,1) with non-zero mean : -12838.94\n",
      " ARIMA(2,0,0) with non-zero mean : -12838.65\n",
      " ARIMA(3,0,1) with non-zero mean : -12842.45\n",
      " ARIMA(3,0,0) with non-zero mean : -12841.35\n",
      " ARIMA(4,0,1) with non-zero mean : -12840.34\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,0) with non-zero mean : -12838.9\n",
      " ARIMA(4,0,2) with non-zero mean : -12861.04\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -12898.44\n",
      " ARIMA(3,0,3) with non-zero mean : -12879.27\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : -12896.67\n",
      " ARIMA(3,0,4) with non-zero mean : -12878.13\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -12852.41\n",
      "\n",
      " Best model: ARIMA(4,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -12927.14\n",
      " ARIMA(0,0,0) with non-zero mean : -8198.192\n",
      " ARIMA(1,0,0) with non-zero mean : -12908.82\n",
      " ARIMA(0,0,1) with non-zero mean : -10141.79\n",
      " ARIMA(0,0,0) with zero mean     : -8024.557\n",
      " ARIMA(1,0,2) with non-zero mean : -12911.9\n",
      " ARIMA(2,0,1) with non-zero mean : -12929.13\n",
      " ARIMA(1,0,1) with non-zero mean : -12908.74\n",
      " ARIMA(2,0,0) with non-zero mean : -12908.7\n",
      " ARIMA(3,0,1) with non-zero mean : -12938.63\n",
      " ARIMA(3,0,0) with non-zero mean : -12936.86\n",
      " ARIMA(4,0,1) with non-zero mean : -12933.76\n",
      " ARIMA(3,0,2) with non-zero mean : -12952.1\n",
      " ARIMA(4,0,2) with non-zero mean : -12950.34\n",
      " ARIMA(3,0,3) with non-zero mean : -12953.03\n",
      " ARIMA(2,0,3) with non-zero mean : -12926.06\n",
      " ARIMA(4,0,3) with non-zero mean : -13011.78\n",
      " ARIMA(5,0,3) with non-zero mean : -12957.38\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -12955.51\n",
      " ARIMA(5,0,2) with non-zero mean : -12958.24\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with zero mean     : -12944\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -12921.65\n",
      "\n",
      " Best model: ARIMA(3,0,4) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13034.35\n",
      " ARIMA(0,0,0) with non-zero mean : -8419.008\n",
      " ARIMA(1,0,0) with non-zero mean : -13034.07\n",
      " ARIMA(0,0,1) with non-zero mean : -10368.77\n",
      " ARIMA(0,0,0) with zero mean     : -8212.474\n",
      " ARIMA(1,0,2) with non-zero mean : -13036.71\n",
      " ARIMA(0,0,2) with non-zero mean : -11525.41\n",
      " ARIMA(1,0,1) with non-zero mean : -13033.75\n",
      " ARIMA(1,0,3) with non-zero mean : -13035.61\n",
      " ARIMA(0,0,3) with non-zero mean : -11936.39\n",
      " ARIMA(2,0,1) with non-zero mean : -13032.6\n",
      " ARIMA(2,0,3) with non-zero mean : -13034.24\n",
      " ARIMA(1,0,2) with zero mean     : -13032.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(1,0,2) with non-zero mean : -13022.48\n",
      "\n",
      " Best model: ARIMA(1,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13141.92\n",
      " ARIMA(0,0,0) with non-zero mean : -8600.267\n",
      " ARIMA(1,0,0) with non-zero mean : -13132.96\n",
      " ARIMA(0,0,1) with non-zero mean : -10567.03\n",
      " ARIMA(0,0,0) with zero mean     : -8417.529\n",
      " ARIMA(1,0,2) with non-zero mean : -13135.69\n",
      " ARIMA(2,0,1) with non-zero mean : -13143.46\n",
      " ARIMA(1,0,1) with non-zero mean : -13131.3\n",
      " ARIMA(2,0,0) with non-zero mean : -13130.87\n",
      " ARIMA(3,0,1) with non-zero mean : -13141.06\n",
      " ARIMA(3,0,0) with non-zero mean : -13135.48\n",
      " ARIMA(3,0,2) with non-zero mean : -13139.83\n",
      " ARIMA(2,0,1) with zero mean     : -13139.77\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with non-zero mean : -13135.84\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13193.12\n",
      " ARIMA(0,0,0) with non-zero mean : -8651.976\n",
      " ARIMA(1,0,0) with non-zero mean : -13170.43\n",
      " ARIMA(0,0,1) with non-zero mean : -10600.05\n",
      " ARIMA(0,0,0) with zero mean     : -8478.609\n",
      " ARIMA(1,0,2) with non-zero mean : -13174.57\n",
      " ARIMA(2,0,1) with non-zero mean : -13191\n",
      " ARIMA(3,0,2) with non-zero mean : -13202.7\n",
      " ARIMA(3,0,1) with non-zero mean : -13192.86\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -13200.6\n",
      " ARIMA(2,0,3) with non-zero mean : -13191.28\n",
      " ARIMA(4,0,1) with non-zero mean : -13191.15\n",
      " ARIMA(4,0,3) with non-zero mean : -13218.39\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -13200.58\n",
      " ARIMA(5,0,2) with non-zero mean : -13252.64\n",
      " ARIMA(5,0,1) with non-zero mean : -13189.33\n",
      " ARIMA(5,0,2) with zero mean     : -13248.74\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -13185.97\n",
      "\n",
      " Best model: ARIMA(3,0,4) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13224.59\n",
      " ARIMA(0,0,0) with non-zero mean : -8659.661\n",
      " ARIMA(1,0,0) with non-zero mean : -13222\n",
      " ARIMA(0,0,1) with non-zero mean : -10646.41\n",
      " ARIMA(0,0,0) with zero mean     : -8488.456\n",
      " ARIMA(1,0,2) with non-zero mean : -13223.63\n",
      " ARIMA(2,0,1) with non-zero mean : -13221.42\n",
      " ARIMA(3,0,2) with non-zero mean : -13234.74\n",
      " ARIMA(3,0,1) with non-zero mean : -13224.58\n",
      " ARIMA(4,0,2) with non-zero mean : -13224.71\n",
      " ARIMA(3,0,3) with non-zero mean : -13233.34\n",
      " ARIMA(2,0,3) with non-zero mean : -13222.66\n",
      " ARIMA(4,0,1) with non-zero mean : -13223.65\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -13227.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : -13241.51\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13264.36\n",
      " ARIMA(0,0,0) with non-zero mean : -8704.311\n",
      " ARIMA(1,0,0) with non-zero mean : -13253.56\n",
      " ARIMA(0,0,1) with non-zero mean : -10687.09\n",
      " ARIMA(0,0,0) with zero mean     : -8526.564\n",
      " ARIMA(1,0,2) with non-zero mean : -13254.11\n",
      " ARIMA(2,0,1) with non-zero mean : -13262.34\n",
      " ARIMA(3,0,2) with non-zero mean : -13271.99\n",
      " ARIMA(3,0,1) with non-zero mean : -13272.92\n",
      " ARIMA(3,0,0) with non-zero mean : -13267.33\n",
      " ARIMA(4,0,1) with non-zero mean : -13266.58\n",
      " ARIMA(2,0,0) with non-zero mean : -13264.86\n",
      " ARIMA(4,0,0) with non-zero mean : -13267.59\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,1) with zero mean     : -13268.9\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -13257.04\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13286.09\n",
      " ARIMA(0,0,0) with non-zero mean : -8799.759\n",
      " ARIMA(1,0,0) with non-zero mean : -13281.32\n",
      " ARIMA(0,0,1) with non-zero mean : -10765\n",
      " ARIMA(0,0,0) with zero mean     : -8632.875\n",
      " ARIMA(1,0,2) with non-zero mean : -13281.08\n",
      " ARIMA(2,0,1) with non-zero mean : -13284.31\n",
      " ARIMA(3,0,2) with non-zero mean : -13294.12\n",
      " ARIMA(3,0,1) with non-zero mean : -13296\n",
      " ARIMA(3,0,0) with non-zero mean : -13287.48\n",
      " ARIMA(4,0,1) with non-zero mean : -13292.11\n",
      " ARIMA(2,0,0) with non-zero mean : -13286.29\n",
      " ARIMA(4,0,0) with non-zero mean : -13285.57\n",
      " ARIMA(4,0,2) with non-zero mean : -13307.77\n",
      " ARIMA(5,0,2) with non-zero mean : -13333.7\n",
      " ARIMA(5,0,1) with non-zero mean : -13288.79\n",
      " ARIMA(5,0,3) with non-zero mean : -13381.08\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -13370.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -13298.7\n",
      "\n",
      " Best model: ARIMA(4,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13315.22\n",
      " ARIMA(0,0,0) with non-zero mean : -8818.601\n",
      " ARIMA(1,0,0) with non-zero mean : -13308.47\n",
      " ARIMA(0,0,1) with non-zero mean : -10784.96\n",
      " ARIMA(0,0,0) with zero mean     : -8656.278\n",
      " ARIMA(1,0,2) with non-zero mean : -13308.69\n",
      " ARIMA(2,0,1) with non-zero mean : -13316.57\n",
      " ARIMA(1,0,1) with non-zero mean : -13306.78\n",
      " ARIMA(2,0,0) with non-zero mean : -13305.83\n",
      " ARIMA(3,0,1) with non-zero mean : -13313.95\n",
      " ARIMA(3,0,0) with non-zero mean : -13307.08\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -13312.98\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with non-zero mean : -13315.59\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13294.52\n",
      " ARIMA(0,0,0) with non-zero mean : -8751.451\n",
      " ARIMA(1,0,0) with non-zero mean : -13289.34\n",
      " ARIMA(0,0,1) with non-zero mean : -10730.44\n",
      " ARIMA(0,0,0) with zero mean     : -8614.585\n",
      " ARIMA(1,0,2) with non-zero mean : -13289.61\n",
      " ARIMA(2,0,1) with non-zero mean : -13295.78\n",
      " ARIMA(1,0,1) with non-zero mean : -13287.61\n",
      " ARIMA(2,0,0) with non-zero mean : -13286.67\n",
      " ARIMA(3,0,1) with non-zero mean : -13288.61\n",
      " ARIMA(3,0,0) with non-zero mean : -13288.71\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -13293.98\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with non-zero mean : -13296.56\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13281.55\n",
      " ARIMA(0,0,0) with non-zero mean : -8730.333\n",
      " ARIMA(1,0,0) with non-zero mean : -13273.79\n",
      " ARIMA(0,0,1) with non-zero mean : -10715.07\n",
      " ARIMA(0,0,0) with zero mean     : -8603.515\n",
      " ARIMA(1,0,2) with non-zero mean : -13273.78\n",
      " ARIMA(2,0,1) with non-zero mean : -13279.31\n",
      " ARIMA(3,0,2) with non-zero mean : -13289.56\n",
      " ARIMA(3,0,1) with non-zero mean : -13288.08\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -13288.21\n",
      " ARIMA(2,0,3) with non-zero mean : -13279.63\n",
      " ARIMA(4,0,1) with non-zero mean : -13289.48\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -13287.32\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : -13277.09\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13244.45\n",
      " ARIMA(0,0,0) with non-zero mean : -8638.893\n",
      " ARIMA(1,0,0) with non-zero mean : -13241.32\n",
      " ARIMA(0,0,1) with non-zero mean : -10627.38\n",
      " ARIMA(0,0,0) with zero mean     : -8538.471\n",
      " ARIMA(1,0,2) with non-zero mean : -13241.96\n",
      " ARIMA(2,0,1) with non-zero mean : -13242.56\n",
      " ARIMA(3,0,2) with non-zero mean : -13242.28\n",
      " ARIMA(2,0,3) with non-zero mean : -13242.54\n",
      " ARIMA(1,0,1) with non-zero mean : -13239.47\n",
      " ARIMA(1,0,3) with non-zero mean : -13239.97\n",
      " ARIMA(3,0,1) with non-zero mean : -13242.75\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(2,0,2) with zero mean     : -13243.81\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13247.7\n",
      "\n",
      " Best model: ARIMA(2,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13202.85\n",
      " ARIMA(0,0,0) with non-zero mean : -8591.905\n",
      " ARIMA(1,0,0) with non-zero mean : -13201\n",
      " ARIMA(0,0,1) with non-zero mean : -10586.47\n",
      " ARIMA(0,0,0) with zero mean     : -8489.949\n",
      " ARIMA(1,0,2) with non-zero mean : -13201.67\n",
      " ARIMA(2,0,1) with non-zero mean : -13200.09\n",
      " ARIMA(3,0,2) with non-zero mean : -13249.76\n",
      " ARIMA(3,0,1) with non-zero mean : -13215.09\n",
      " ARIMA(4,0,2) with non-zero mean : -13220.25\n",
      " ARIMA(3,0,3) with non-zero mean : -13213.48\n",
      " ARIMA(2,0,3) with non-zero mean : -13200.89\n",
      " ARIMA(4,0,1) with non-zero mean : -13210.99\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -13248.67\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -13219.49\n",
      "\n",
      " Best model: ARIMA(4,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13217.65\n",
      " ARIMA(0,0,0) with non-zero mean : -8600.973\n",
      " ARIMA(1,0,0) with non-zero mean : -13216.62\n",
      " ARIMA(0,0,1) with non-zero mean : -10599.03\n",
      " ARIMA(0,0,0) with zero mean     : -8478.971\n",
      " ARIMA(1,0,2) with non-zero mean : -13217.71\n",
      " ARIMA(0,0,2) with non-zero mean : -11739.39\n",
      " ARIMA(1,0,1) with non-zero mean : -13214.72\n",
      " ARIMA(1,0,3) with non-zero mean : -13215.7\n",
      " ARIMA(0,0,3) with non-zero mean : -12182.37\n",
      " ARIMA(2,0,1) with non-zero mean : -13218.8\n",
      " ARIMA(2,0,0) with non-zero mean : -13214.1\n",
      " ARIMA(3,0,1) with non-zero mean : -13230.16\n",
      " ARIMA(3,0,0) with non-zero mean : -13218.76\n",
      " ARIMA(4,0,1) with non-zero mean : -13222.52\n",
      " ARIMA(3,0,2) with non-zero mean : -13230.85\n",
      " ARIMA(4,0,2) with non-zero mean : -13234.85\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : -13233.84\n",
      " ARIMA(3,0,3) with non-zero mean : -13229.16\n",
      " ARIMA(5,0,1) with non-zero mean : -13223.37\n",
      " ARIMA(5,0,3) with non-zero mean : -13293.72\n",
      " ARIMA(5,0,4) with non-zero mean : -13262.21\n",
      " ARIMA(4,0,4) with non-zero mean : -13229.1\n",
      " ARIMA(5,0,3) with zero mean     : -13290.35\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -13234.4\n",
      "\n",
      " Best model: ARIMA(4,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13229.23\n",
      " ARIMA(0,0,0) with non-zero mean : -8638.204\n",
      " ARIMA(1,0,0) with non-zero mean : -13222.89\n",
      " ARIMA(0,0,1) with non-zero mean : -10628.86\n",
      " ARIMA(0,0,0) with zero mean     : -8523.826\n",
      " ARIMA(1,0,2) with non-zero mean : -13223.89\n",
      " ARIMA(2,0,1) with non-zero mean : -13230.19\n",
      " ARIMA(1,0,1) with non-zero mean : -13220.98\n",
      " ARIMA(2,0,0) with non-zero mean : -13220.28\n",
      " ARIMA(3,0,1) with non-zero mean : -13227.34\n",
      " ARIMA(3,0,0) with non-zero mean : -13222.97\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(2,0,1) with zero mean     : -13228.25\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(2,0,1) with non-zero mean : -13228.97\n",
      "\n",
      " Best model: ARIMA(2,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13225.78\n",
      " ARIMA(0,0,0) with non-zero mean : -8640.479\n",
      " ARIMA(1,0,0) with non-zero mean : -13222.35\n",
      " ARIMA(0,0,1) with non-zero mean : -10630.57\n",
      " ARIMA(0,0,0) with zero mean     : -8526.609\n",
      " ARIMA(1,0,2) with non-zero mean : -13223.83\n",
      " ARIMA(2,0,1) with non-zero mean : -13223.03\n",
      " ARIMA(3,0,2) with non-zero mean : -13251.14\n",
      " ARIMA(3,0,1) with non-zero mean : -13231.06\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -13249.33\n",
      " ARIMA(2,0,3) with non-zero mean : -13237.37\n",
      " ARIMA(4,0,1) with non-zero mean : -13228.66\n",
      " ARIMA(4,0,3) with non-zero mean : -13312.69\n",
      " ARIMA(5,0,3) with non-zero mean : -13240.06\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,4) with non-zero mean : -13225.83\n",
      " ARIMA(5,0,2) with non-zero mean : -13241.89\n",
      " ARIMA(5,0,4) with non-zero mean : -13272.13\n",
      " ARIMA(4,0,3) with zero mean     : -13226.4\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : -13240.64\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13273.5\n",
      " ARIMA(0,0,0) with non-zero mean : -8726.392\n",
      " ARIMA(1,0,0) with non-zero mean : -13268.27\n",
      " ARIMA(0,0,1) with non-zero mean : -10693.44\n",
      " ARIMA(0,0,0) with zero mean     : -8598.523\n",
      " ARIMA(1,0,2) with non-zero mean : -13269.54\n",
      " ARIMA(2,0,1) with non-zero mean : -13270.56\n",
      " ARIMA(3,0,2) with non-zero mean : -13290.67\n",
      " ARIMA(3,0,1) with non-zero mean : -13275.6\n",
      " ARIMA(4,0,2) with non-zero mean : -13337.17\n",
      " ARIMA(4,0,1) with non-zero mean : -13273.2\n",
      " ARIMA(5,0,2) with non-zero mean : -13320.19\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : -13322.75\n",
      " ARIMA(5,0,1) with non-zero mean : -13288.19\n",
      " ARIMA(5,0,3) with non-zero mean : -13339.1\n",
      " ARIMA(5,0,4) with non-zero mean : Inf\n",
      " ARIMA(4,0,4) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : -13330.91\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,3) with zero mean     : Inf\n",
      " ARIMA(3,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(5,0,1) with non-zero mean : -13260.9\n",
      "\n",
      " Best model: ARIMA(5,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13330.8\n",
      " ARIMA(0,0,0) with non-zero mean : -8763.678\n",
      " ARIMA(1,0,0) with non-zero mean : -13327.64\n",
      " ARIMA(0,0,1) with non-zero mean : -10748.55\n",
      " ARIMA(0,0,0) with zero mean     : -8614.882\n",
      " ARIMA(1,0,2) with non-zero mean : -13328.81\n",
      " ARIMA(2,0,1) with non-zero mean : -13325.66\n",
      " ARIMA(3,0,2) with non-zero mean : -13359.55\n",
      " ARIMA(3,0,1) with non-zero mean : -13338.61\n",
      " ARIMA(4,0,2) with non-zero mean : -13350.39\n",
      " ARIMA(3,0,3) with non-zero mean : -13339.44\n",
      " ARIMA(2,0,3) with non-zero mean : -13328.85\n",
      " ARIMA(4,0,1) with non-zero mean : -13346.18\n",
      " ARIMA(4,0,3) with non-zero mean : -13351.1\n",
      " ARIMA(3,0,2) with zero mean     : -13351.9\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : Inf\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(4,0,2) with non-zero mean : -13344.81\n",
      "\n",
      " Best model: ARIMA(4,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13380.83\n",
      " ARIMA(0,0,0) with non-zero mean : -8778.684\n",
      " ARIMA(1,0,0) with non-zero mean : -13373.4\n",
      " ARIMA(0,0,1) with non-zero mean : -10763.15\n",
      " ARIMA(0,0,0) with zero mean     : -8621.15\n",
      " ARIMA(1,0,2) with non-zero mean : -13374.03\n",
      " ARIMA(2,0,1) with non-zero mean : -13379.57\n",
      " ARIMA(3,0,2) with non-zero mean : -13384\n",
      " ARIMA(3,0,1) with non-zero mean : -13385.76\n",
      " ARIMA(3,0,0) with non-zero mean : -13372.9\n",
      " ARIMA(4,0,1) with non-zero mean : -13374.4\n",
      " ARIMA(2,0,0) with non-zero mean : -13370.69\n",
      " ARIMA(4,0,0) with non-zero mean : -13374.31\n",
      " ARIMA(4,0,2) with non-zero mean : -13396.01\n",
      " ARIMA(5,0,2) with non-zero mean : -13400.34\n",
      " ARIMA(5,0,1) with non-zero mean : -13377.97\n",
      " ARIMA(5,0,3) with non-zero mean : -13399.47\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(5,0,2) with zero mean     : -13397.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,2) with non-zero mean : -13433.95\n",
      "\n",
      " Best model: ARIMA(5,0,2) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13389.44\n",
      " ARIMA(0,0,0) with non-zero mean : -8785.203\n",
      " ARIMA(1,0,0) with non-zero mean : -13383.45\n",
      " ARIMA(0,0,1) with non-zero mean : -10766.55\n",
      " ARIMA(0,0,0) with zero mean     : -8638.774\n",
      " ARIMA(1,0,2) with non-zero mean : -13384.41\n",
      " ARIMA(2,0,1) with non-zero mean : -13386.49\n",
      " ARIMA(3,0,2) with non-zero mean : -13397.52\n",
      " ARIMA(3,0,1) with non-zero mean : -13398.73\n",
      " ARIMA(3,0,0) with non-zero mean : -13387.59\n",
      " ARIMA(4,0,1) with non-zero mean : -13394.72\n",
      " ARIMA(2,0,0) with non-zero mean : -13385.51\n",
      " ARIMA(4,0,0) with non-zero mean : -13385.26\n",
      " ARIMA(4,0,2) with non-zero mean : -13394.06\n",
      " ARIMA(3,0,1) with zero mean     : -13394.67\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -13389.26\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -8817.258\n",
      " ARIMA(1,0,0) with non-zero mean : -13394.02\n",
      " ARIMA(0,0,1) with non-zero mean : -10796.54\n",
      " ARIMA(0,0,0) with zero mean     : -8668.423\n",
      " ARIMA(2,0,0) with non-zero mean : -13393.41\n",
      " ARIMA(1,0,1) with non-zero mean : -13392.02\n",
      " ARIMA(2,0,1) with non-zero mean : -13394.62\n",
      " ARIMA(3,0,1) with non-zero mean : -13399.28\n",
      " ARIMA(3,0,0) with non-zero mean : -13396.73\n",
      " ARIMA(4,0,1) with non-zero mean : -13397.52\n",
      " ARIMA(3,0,2) with non-zero mean : Inf\n",
      " ARIMA(4,0,0) with non-zero mean : -13394.6\n",
      " ARIMA(4,0,2) with non-zero mean : Inf\n",
      " ARIMA(3,0,1) with zero mean     : -13396.56\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,1) with non-zero mean : -13399.41\n",
      "\n",
      " Best model: ARIMA(3,0,1) with non-zero mean \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : -13412.76\n",
      " ARIMA(0,0,0) with non-zero mean : -8835.11\n",
      " ARIMA(1,0,0) with non-zero mean : -13400.98\n",
      " ARIMA(0,0,1) with non-zero mean : -10816.87\n",
      " ARIMA(0,0,0) with zero mean     : -8697.246\n",
      " ARIMA(1,0,2) with non-zero mean : -13402.43\n",
      " ARIMA(2,0,1) with non-zero mean : -13412.29\n",
      " ARIMA(3,0,2) with non-zero mean : -13425.78\n",
      " ARIMA(3,0,1) with non-zero mean : -13408.73\n",
      " ARIMA(4,0,2) with non-zero mean : -13405.3\n",
      " ARIMA(3,0,3) with non-zero mean : -13423.77\n",
      " ARIMA(2,0,3) with non-zero mean : -13411.32\n",
      " ARIMA(4,0,1) with non-zero mean : -13407.09\n",
      " ARIMA(4,0,3) with non-zero mean : Inf\n",
      " ARIMA(3,0,2) with zero mean     : -13401.33\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(3,0,2) with non-zero mean : -13426.43\n",
      "\n",
      " Best model: ARIMA(3,0,2) with non-zero mean \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m03.1 <- my.tsCV.2(train, cv.forecast.2, h=hori, window=wind, step=peri, \n",
    "                          silent=T,\n",
    "                          sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4247b4e2-a191-4310-9df8-ee11224a71a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-01-24\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m03.1\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3603b7c1-1626-4d08-a2f0-35ea2db6d2db",
   "metadata": {},
   "source": [
    "## Regression with ARIMA errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad1a4e08-fca6-4a5b-b997-cf9d1e3cbe00",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14728.24\n",
      " Regression with ARIMA(0,1,0) errors : -14705.76\n",
      " Regression with ARIMA(1,1,0) errors : -14703.21\n",
      " Regression with ARIMA(0,1,1) errors : -14703.85\n",
      " Regression with ARIMA(0,1,0) errors : -14707.74\n",
      " Regression with ARIMA(1,1,2) errors : -14755.07\n",
      " Regression with ARIMA(0,1,2) errors : -14703.58\n",
      " Regression with ARIMA(1,1,1) errors : -14701.2\n",
      " Regression with ARIMA(1,1,3) errors : -14756.2\n",
      " Regression with ARIMA(0,1,3) errors : -14715.69\n",
      " Regression with ARIMA(2,1,3) errors : -14743.68\n",
      " Regression with ARIMA(1,1,4) errors : -14754.84\n",
      " Regression with ARIMA(0,1,4) errors : -14713.96\n",
      " Regression with ARIMA(2,1,4) errors : -14742.53\n",
      " Regression with ARIMA(1,1,3) errors : -14757.92\n",
      " Regression with ARIMA(0,1,3) errors : -14717.66\n",
      " Regression with ARIMA(1,1,2) errors : -14756.77\n",
      " Regression with ARIMA(2,1,3) errors : -14745.4\n",
      " Regression with ARIMA(1,1,4) errors : -14756.51\n",
      " Regression with ARIMA(0,1,2) errors : -14705.55\n",
      " Regression with ARIMA(0,1,4) errors : -14715.93\n",
      " Regression with ARIMA(2,1,2) errors : -14729.97\n",
      " Regression with ARIMA(2,1,4) errors : -14744.25\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14726.99\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14688.58\n",
      " Regression with ARIMA(1,1,0) errors : -14687.3\n",
      " Regression with ARIMA(0,1,1) errors : -14686.7\n",
      " Regression with ARIMA(0,1,0) errors : -14690.58\n",
      " Regression with ARIMA(1,1,1) errors : -14685.35\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14699.9\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14648.88\n",
      " Regression with ARIMA(1,1,0) errors : -14646.36\n",
      " Regression with ARIMA(0,1,1) errors : -14647.06\n",
      " Regression with ARIMA(0,1,0) errors : -14650.88\n",
      " Regression with ARIMA(1,1,1) errors : -14644.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14660.19\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14557.56\n",
      " Regression with ARIMA(1,1,0) errors : -14555.41\n",
      " Regression with ARIMA(0,1,1) errors : -14555.93\n",
      " Regression with ARIMA(0,1,0) errors : -14559.56\n",
      " Regression with ARIMA(1,1,1) errors : -14553.98\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14568.83\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14466.15\n",
      " Regression with ARIMA(1,1,0) errors : -14464.59\n",
      " Regression with ARIMA(0,1,1) errors : -14465.14\n",
      " Regression with ARIMA(0,1,0) errors : -14468.15\n",
      " Regression with ARIMA(1,1,1) errors : -14463.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14477.38\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14431.62\n",
      " Regression with ARIMA(1,1,0) errors : -14429.42\n",
      " Regression with ARIMA(0,1,1) errors : -14430.5\n",
      " Regression with ARIMA(0,1,0) errors : -14433.63\n",
      " Regression with ARIMA(1,1,1) errors : -14428.06\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14442.84\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14487.01\n",
      " Regression with ARIMA(0,1,0) errors : -14420.66\n",
      " Regression with ARIMA(1,1,0) errors : -14418.52\n",
      " Regression with ARIMA(0,1,1) errors : -14419.3\n",
      " Regression with ARIMA(0,1,0) errors : -14422.67\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14487.4\n",
      " Regression with ARIMA(1,1,1) errors : -14416.73\n",
      " Regression with ARIMA(2,1,0) errors : -14420.92\n",
      " Regression with ARIMA(3,1,1) errors : -14426\n",
      " Regression with ARIMA(3,1,0) errors : -14427.6\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14489.16\n",
      " Regression with ARIMA(1,1,1) errors : -14418.75\n",
      " Regression with ARIMA(2,1,0) errors : -14422.93\n",
      " Regression with ARIMA(3,1,1) errors : -14427.99\n",
      " Regression with ARIMA(2,1,2) errors : -14488.71\n",
      " Regression with ARIMA(1,1,0) errors : -14420.53\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -14429.61\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -14440.44\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14445.76\n",
      " Regression with ARIMA(0,1,0) errors : -14415.25\n",
      " Regression with ARIMA(1,1,0) errors : -14413.72\n",
      " Regression with ARIMA(0,1,1) errors : -14413.85\n",
      " Regression with ARIMA(0,1,0) errors : -14417.26\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14433.81\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14468.58\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14468.82\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14469.94\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14471.73\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14470.6\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14426.46\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14421.25\n",
      " Regression with ARIMA(1,1,0) errors : -14418.78\n",
      " Regression with ARIMA(0,1,1) errors : -14419.77\n",
      " Regression with ARIMA(0,1,0) errors : -14423.26\n",
      " Regression with ARIMA(1,1,1) errors : -14417.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14432.47\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14414.4\n",
      " Regression with ARIMA(1,1,0) errors : -14411.72\n",
      " Regression with ARIMA(0,1,1) errors : -14412.71\n",
      " Regression with ARIMA(0,1,0) errors : -14416.41\n",
      " Regression with ARIMA(1,1,1) errors : -14410.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14425.61\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14371.6\n",
      " Regression with ARIMA(1,1,0) errors : -14369.53\n",
      " Regression with ARIMA(0,1,1) errors : -14370.05\n",
      " Regression with ARIMA(0,1,0) errors : -14373.59\n",
      " Regression with ARIMA(1,1,1) errors : -14368.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14382.78\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14319.68\n",
      " Regression with ARIMA(0,1,0) errors : -14316.26\n",
      " Regression with ARIMA(1,1,0) errors : -14313.77\n",
      " Regression with ARIMA(0,1,1) errors : -14314.65\n",
      " Regression with ARIMA(0,1,0) errors : -14318.23\n",
      " Regression with ARIMA(1,1,2) errors : -14385.93\n",
      " Regression with ARIMA(0,1,2) errors : -14319.04\n",
      " Regression with ARIMA(1,1,1) errors : -14312.24\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14327.45\n",
      " Regression with ARIMA(2,1,1) errors : -14356.37\n",
      " Regression with ARIMA(2,1,3) errors : -14367.96\n",
      " Regression with ARIMA(1,1,2) errors : -14387.45\n",
      " Regression with ARIMA(0,1,2) errors : -14321.01\n",
      " Regression with ARIMA(1,1,1) errors : -14314.22\n",
      " Regression with ARIMA(2,1,2) errors : -14321.64\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(0,1,1) errors : -14316.62\n",
      " Regression with ARIMA(0,1,3) errors : -14329.42\n",
      " Regression with ARIMA(2,1,1) errors : -14358.04\n",
      " Regression with ARIMA(2,1,3) errors : -14369.57\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14338.56\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14254.7\n",
      " Regression with ARIMA(1,1,0) errors : -14252.25\n",
      " Regression with ARIMA(0,1,1) errors : -14252.87\n",
      " Regression with ARIMA(0,1,0) errors : -14256.7\n",
      " Regression with ARIMA(1,1,1) errors : -14250.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14265.84\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14249.15\n",
      " Regression with ARIMA(1,1,0) errors : -14246.58\n",
      " Regression with ARIMA(0,1,1) errors : -14247.46\n",
      " Regression with ARIMA(0,1,0) errors : -14251.14\n",
      " Regression with ARIMA(1,1,1) errors : -14245.11\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14260.28\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14341.48\n",
      " Regression with ARIMA(0,0,0) errors : -10840.14\n",
      " Regression with ARIMA(1,0,0) errors : -14339.73\n",
      " Regression with ARIMA(0,0,1) errors : -12569.99\n",
      " Regression with ARIMA(0,0,0) errors : -9528.814\n",
      " Regression with ARIMA(1,0,2) errors : -14343.89\n",
      " Regression with ARIMA(0,0,2) errors : -13424.35\n",
      " Regression with ARIMA(1,0,1) errors : -14345.89\n",
      " Regression with ARIMA(2,0,1) errors : -14342.88\n",
      " Regression with ARIMA(2,0,0) errors : -14344.83\n",
      " Regression with ARIMA(1,0,1) errors : -14199.07\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14344.44\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14131.23\n",
      " Regression with ARIMA(1,1,0) errors : -14129.6\n",
      " Regression with ARIMA(0,1,1) errors : -14129.22\n",
      " Regression with ARIMA(0,1,0) errors : -14133.21\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14142.29\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14104.7\n",
      " Regression with ARIMA(1,1,0) errors : -14102.15\n",
      " Regression with ARIMA(0,1,1) errors : -14102.72\n",
      " Regression with ARIMA(0,1,0) errors : -14106.71\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14115.78\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14094.76\n",
      " Regression with ARIMA(1,1,0) errors : -14092.35\n",
      " Regression with ARIMA(0,1,1) errors : -14092.76\n",
      " Regression with ARIMA(0,1,0) errors : -14096.76\n",
      " Regression with ARIMA(1,1,1) errors : -14091.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14105.82\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14158.82\n",
      " Regression with ARIMA(0,1,0) errors : -14086.53\n",
      " Regression with ARIMA(1,1,0) errors : -14083.63\n",
      " Regression with ARIMA(0,1,1) errors : -14084.57\n",
      " Regression with ARIMA(0,1,0) errors : -14088.54\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14155.6\n",
      " Regression with ARIMA(3,1,2) errors : -14153.06\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : -14177.73\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14178.44\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14179.86\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14181.4\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14179.99\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14166.32\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14097.6\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14074.57\n",
      " Regression with ARIMA(1,1,0) errors : -14071.57\n",
      " Regression with ARIMA(0,1,1) errors : -14072.57\n",
      " Regression with ARIMA(0,1,0) errors : -14076.57\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14085.63\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14156.68\n",
      " Regression with ARIMA(0,0,0) errors : -10543.02\n",
      " Regression with ARIMA(1,0,0) errors : -14157.58\n",
      " Regression with ARIMA(0,0,1) errors : -12288.52\n",
      " Regression with ARIMA(0,0,0) errors : -9161.948\n",
      " Regression with ARIMA(2,0,0) errors : -14160.85\n",
      " Regression with ARIMA(3,0,0) errors : -14159.41\n",
      " Regression with ARIMA(2,0,1) errors : -14158.76\n",
      " Regression with ARIMA(1,0,1) errors : -14161.58\n",
      " Regression with ARIMA(1,0,2) errors : -14159.57\n",
      " Regression with ARIMA(0,0,2) errors : -13166.06\n",
      " Regression with ARIMA(1,0,1) errors : -14036.84\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14160.49\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14097.59\n",
      " Regression with ARIMA(0,0,0) errors : -10474.05\n",
      " Regression with ARIMA(1,0,0) errors : -14096.1\n",
      " Regression with ARIMA(0,0,1) errors : -12234.47\n",
      " Regression with ARIMA(0,0,0) errors : -9152.683\n",
      " Regression with ARIMA(1,0,2) errors : -14099.35\n",
      " Regression with ARIMA(0,0,2) errors : -13115.29\n",
      " Regression with ARIMA(1,0,1) errors : -14101.37\n",
      " Regression with ARIMA(2,0,1) errors : -14098.29\n",
      " Regression with ARIMA(2,0,0) errors : -14100.36\n",
      " Regression with ARIMA(1,0,1) errors : -13962.68\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14100.49\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13956.34\n",
      " Regression with ARIMA(1,1,0) errors : -13954.24\n",
      " Regression with ARIMA(0,1,1) errors : -13954.58\n",
      " Regression with ARIMA(0,1,0) errors : -13958.35\n",
      " Regression with ARIMA(1,1,1) errors : -13952.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13967.35\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13942.25\n",
      " Regression with ARIMA(1,1,0) errors : -13939.51\n",
      " Regression with ARIMA(0,1,1) errors : -13940.54\n",
      " Regression with ARIMA(0,1,0) errors : -13944.26\n",
      " Regression with ARIMA(1,1,1) errors : -13938.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13953.25\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "[1] \"10 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14057.56\n",
      " Regression with ARIMA(0,0,0) errors : -10451.94\n",
      " Regression with ARIMA(1,0,0) errors : -14055.02\n",
      " Regression with ARIMA(0,0,1) errors : -12212.26\n",
      " Regression with ARIMA(0,0,0) errors : -9125.585\n",
      " Regression with ARIMA(1,0,2) errors : -14059.61\n",
      " Regression with ARIMA(0,0,2) errors : -13092.48\n",
      " Regression with ARIMA(1,0,1) errors : -14061.59\n",
      " Regression with ARIMA(2,0,1) errors : -14058.81\n",
      " Regression with ARIMA(2,0,0) errors : -14060.82\n",
      " Regression with ARIMA(1,0,1) errors : -13926.65\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14060.43\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14049.73\n",
      " Regression with ARIMA(0,0,0) errors : -10463.36\n",
      " Regression with ARIMA(1,0,0) errors : -14047.15\n",
      " Regression with ARIMA(0,0,1) errors : -12215.94\n",
      " Regression with ARIMA(0,0,0) errors : -9113.651\n",
      " Regression with ARIMA(1,0,2) errors : -14050.93\n",
      " Regression with ARIMA(0,0,2) errors : -13088.83\n",
      " Regression with ARIMA(1,0,1) errors : -14052.85\n",
      " Regression with ARIMA(2,0,1) errors : -14049.93\n",
      " Regression with ARIMA(2,0,0) errors : -14051.82\n",
      " Regression with ARIMA(1,0,1) errors : -13912.48\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14051.09\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13911.02\n",
      " Regression with ARIMA(1,1,0) errors : -13908.48\n",
      " Regression with ARIMA(0,1,1) errors : -13909.2\n",
      " Regression with ARIMA(0,1,0) errors : -13913.03\n",
      " Regression with ARIMA(1,1,1) errors : -13907.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13922.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13900.07\n",
      " Regression with ARIMA(1,1,0) errors : -13897.25\n",
      " Regression with ARIMA(0,1,1) errors : -13898.14\n",
      " Regression with ARIMA(0,1,0) errors : -13902.07\n",
      " Regression with ARIMA(1,1,1) errors : -13896.05\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13911.05\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13876.42\n",
      " Regression with ARIMA(0,1,0) errors : -13873.69\n",
      " Regression with ARIMA(1,1,0) errors : -13870.8\n",
      " Regression with ARIMA(0,1,1) errors : -13871.79\n",
      " Regression with ARIMA(0,1,0) errors : -13875.69\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -13951.7\n",
      " Regression with ARIMA(1,1,1) errors : -13869.75\n",
      " Regression with ARIMA(2,1,0) errors : -13877.74\n",
      " Regression with ARIMA(3,1,1) errors : -13879.69\n",
      " Regression with ARIMA(3,1,0) errors : -13878.26\n",
      " Regression with ARIMA(3,1,2) errors : -13880.96\n",
      " Regression with ARIMA(2,1,1) errors : -13953.47\n",
      " Regression with ARIMA(1,1,1) errors : -13871.73\n",
      " Regression with ARIMA(2,1,0) errors : -13879.75\n",
      " Regression with ARIMA(3,1,1) errors : -13881.7\n",
      " Regression with ARIMA(2,1,2) errors : -13878.44\n",
      " Regression with ARIMA(1,1,0) errors : -13872.8\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -13880.27\n",
      " Regression with ARIMA(3,1,2) errors : -13883\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -13906.38\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13861.23\n",
      " Regression with ARIMA(1,1,0) errors : -13858.29\n",
      " Regression with ARIMA(0,1,1) errors : -13859.25\n",
      " Regression with ARIMA(0,1,0) errors : -13863.23\n",
      " Regression with ARIMA(1,1,1) errors : -13857.3\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13872.19\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13896.9\n",
      " Regression with ARIMA(0,0,0) errors : -10196.26\n",
      " Regression with ARIMA(1,0,0) errors : -13893.1\n",
      " Regression with ARIMA(0,0,1) errors : -11966.99\n",
      " Regression with ARIMA(0,0,0) errors : -8742.913\n",
      " Regression with ARIMA(1,0,2) errors : -13897.42\n",
      " Regression with ARIMA(0,0,2) errors : -12878.36\n",
      " Regression with ARIMA(1,0,1) errors : -13899.18\n",
      " Regression with ARIMA(2,0,1) errors : -13896.32\n",
      " Regression with ARIMA(2,0,0) errors : -13897.97\n",
      " Regression with ARIMA(1,0,1) errors : -13775.62\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13898.36\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13779.66\n",
      " Regression with ARIMA(0,0,0) errors : -10097.98\n",
      " Regression with ARIMA(1,0,0) errors : -13771.91\n",
      " Regression with ARIMA(0,0,1) errors : -11865.72\n",
      " Regression with ARIMA(0,0,0) errors : -8710.896\n",
      " Regression with ARIMA(1,0,2) errors : -13777.93\n",
      " Regression with ARIMA(2,0,1) errors : -13777.15\n",
      " Regression with ARIMA(3,0,2) errors : -13783.79\n",
      " Regression with ARIMA(3,0,1) errors : -13778.18\n",
      " Regression with ARIMA(4,0,2) errors : -13782.79\n",
      " Regression with ARIMA(3,0,3) errors : -13790.74\n",
      " Regression with ARIMA(2,0,3) errors : -13778.27\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13781.06\n",
      " Regression with ARIMA(2,0,4) errors : -13781.18\n",
      " Regression with ARIMA(4,0,4) errors : -13783.64\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,3) errors : -13791.61\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13736.94\n",
      " Regression with ARIMA(0,0,0) errors : -10002.66\n",
      " Regression with ARIMA(1,0,0) errors : -13730.41\n",
      " Regression with ARIMA(0,0,1) errors : -11778.89\n",
      " Regression with ARIMA(0,0,0) errors : -8620.765\n",
      " Regression with ARIMA(1,0,2) errors : -13736.26\n",
      " Regression with ARIMA(2,0,1) errors : -13735.25\n",
      " Regression with ARIMA(3,0,2) errors : -13738.48\n",
      " Regression with ARIMA(3,0,1) errors : -13735.53\n",
      " Regression with ARIMA(4,0,2) errors : -13732.51\n",
      " Regression with ARIMA(3,0,3) errors : -13747.21\n",
      " Regression with ARIMA(2,0,3) errors : -13735.02\n",
      " Regression with ARIMA(4,0,3) errors : -13743.42\n",
      " Regression with ARIMA(3,0,4) errors : -13736.01\n",
      " Regression with ARIMA(2,0,4) errors : -13737.88\n",
      " Regression with ARIMA(4,0,4) errors : -13742.31\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,3) errors : -13748.29\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13671.5\n",
      " Regression with ARIMA(0,0,0) errors : -9894.943\n",
      " Regression with ARIMA(1,0,0) errors : -13665.86\n",
      " Regression with ARIMA(0,0,1) errors : -11694.71\n",
      " Regression with ARIMA(0,0,0) errors : -8560.227\n",
      " Regression with ARIMA(1,0,2) errors : -13672.38\n",
      " Regression with ARIMA(0,0,2) errors : -12612.9\n",
      " Regression with ARIMA(1,0,1) errors : -13674.2\n",
      " Regression with ARIMA(2,0,1) errors : -13671.58\n",
      " Regression with ARIMA(2,0,0) errors : -13673.48\n",
      " Regression with ARIMA(1,0,1) errors : -13559.42\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13673.28\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13629.1\n",
      " Regression with ARIMA(0,0,0) errors : -9878.792\n",
      " Regression with ARIMA(1,0,0) errors : -13624.85\n",
      " Regression with ARIMA(0,0,1) errors : -11666.73\n",
      " Regression with ARIMA(0,0,0) errors : -8556.701\n",
      " Regression with ARIMA(1,0,2) errors : -13629.96\n",
      " Regression with ARIMA(0,0,2) errors : -12579.75\n",
      " Regression with ARIMA(1,0,1) errors : -13631.19\n",
      " Regression with ARIMA(2,0,1) errors : -13629.28\n",
      " Regression with ARIMA(2,0,0) errors : -13630.88\n",
      " Regression with ARIMA(1,0,1) errors : -13512.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13630.37\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13611.31\n",
      " Regression with ARIMA(0,0,0) errors : -9870.771\n",
      " Regression with ARIMA(1,0,0) errors : -13607.01\n",
      " Regression with ARIMA(0,0,1) errors : -11652.28\n",
      " Regression with ARIMA(0,0,0) errors : -8549.922\n",
      " Regression with ARIMA(1,0,2) errors : -13611.78\n",
      " Regression with ARIMA(0,0,2) errors : -12567.48\n",
      " Regression with ARIMA(1,0,1) errors : -13612.86\n",
      " Regression with ARIMA(2,0,1) errors : -13620.17\n",
      " Regression with ARIMA(2,0,0) errors : -13612.21\n",
      " Regression with ARIMA(3,0,1) errors : -13610.14\n",
      " Regression with ARIMA(3,0,0) errors : -13609.99\n",
      " Regression with ARIMA(3,0,2) errors : -13609.53\n",
      " Regression with ARIMA(2,0,1) errors : -13511.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13612.06\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13585.71\n",
      " Regression with ARIMA(0,0,0) errors : -9844.615\n",
      " Regression with ARIMA(1,0,0) errors : -13581.02\n",
      " Regression with ARIMA(0,0,1) errors : -11622.06\n",
      " Regression with ARIMA(0,0,0) errors : -8510.432\n",
      " Regression with ARIMA(1,0,2) errors : -13586.32\n",
      " Regression with ARIMA(0,0,2) errors : -12543.41\n",
      " Regression with ARIMA(1,0,1) errors : -13587.02\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -13586.54\n",
      " Regression with ARIMA(1,0,1) errors : -13475.64\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13585.99\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13574.71\n",
      " Regression with ARIMA(0,0,0) errors : -9826.549\n",
      " Regression with ARIMA(1,0,0) errors : -13570.27\n",
      " Regression with ARIMA(0,0,1) errors : -11609.5\n",
      " Regression with ARIMA(0,0,0) errors : -8481.914\n",
      " Regression with ARIMA(1,0,2) errors : -13575.26\n",
      " Regression with ARIMA(0,0,2) errors : -12534.01\n",
      " Regression with ARIMA(1,0,1) errors : -13576.15\n",
      " Regression with ARIMA(2,0,1) errors : -13583.87\n",
      " Regression with ARIMA(2,0,0) errors : -13575.76\n",
      " Regression with ARIMA(3,0,1) errors : -13573.56\n",
      " Regression with ARIMA(3,0,0) errors : -13574.15\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13575.33\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13420.85\n",
      " Regression with ARIMA(1,1,0) errors : -13418.28\n",
      " Regression with ARIMA(0,1,1) errors : -13419.05\n",
      " Regression with ARIMA(0,1,0) errors : -13422.86\n",
      " Regression with ARIMA(1,1,1) errors : -13416.27\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13431.63\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13406.54\n",
      " Regression with ARIMA(1,1,0) errors : -13403.97\n",
      " Regression with ARIMA(0,1,1) errors : -13404.69\n",
      " Regression with ARIMA(0,1,0) errors : -13408.55\n",
      " Regression with ARIMA(1,1,1) errors : -13401.96\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13417.31\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13398.85\n",
      " Regression with ARIMA(1,1,0) errors : -13397.03\n",
      " Regression with ARIMA(0,1,1) errors : -13396.96\n",
      " Regression with ARIMA(0,1,0) errors : -13400.86\n",
      " Regression with ARIMA(1,1,1) errors : -13395.03\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13409.61\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13388.05\n",
      " Regression with ARIMA(1,1,0) errors : -13385.34\n",
      " Regression with ARIMA(0,1,1) errors : -13386.18\n",
      " Regression with ARIMA(0,1,0) errors : -13390.05\n",
      " Regression with ARIMA(1,1,1) errors : -13383.59\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13398.81\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13385.45\n",
      " Regression with ARIMA(1,1,0) errors : -13382.92\n",
      " Regression with ARIMA(0,1,1) errors : -13383.57\n",
      " Regression with ARIMA(0,1,0) errors : -13387.46\n",
      " Regression with ARIMA(1,1,1) errors : -13380.91\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13396.21\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13381.56\n",
      " Regression with ARIMA(1,1,0) errors : -13380.11\n",
      " Regression with ARIMA(0,1,1) errors : -13379.6\n",
      " Regression with ARIMA(0,1,0) errors : -13383.57\n",
      " Regression with ARIMA(1,1,1) errors : -13378.27\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13392.32\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13382.25\n",
      " Regression with ARIMA(1,1,0) errors : -13380.87\n",
      " Regression with ARIMA(0,1,1) errors : -13380.28\n",
      " Regression with ARIMA(0,1,0) errors : -13384.26\n",
      " Regression with ARIMA(1,1,1) errors : -13379.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13393.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13380.14\n",
      " Regression with ARIMA(1,1,0) errors : -13377.47\n",
      " Regression with ARIMA(0,1,1) errors : -13378.15\n",
      " Regression with ARIMA(0,1,0) errors : -13382.15\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.9\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13378.91\n",
      " Regression with ARIMA(1,1,0) errors : -13377.73\n",
      " Regression with ARIMA(0,1,1) errors : -13376.9\n",
      " Regression with ARIMA(0,1,0) errors : -13380.91\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13389.66\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13379.35\n",
      " Regression with ARIMA(1,1,0) errors : -13377.78\n",
      " Regression with ARIMA(0,1,1) errors : -13377.34\n",
      " Regression with ARIMA(0,1,0) errors : -13381.35\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.1\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "[1] \"20 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13379.9\n",
      " Regression with ARIMA(1,1,0) errors : -13377.2\n",
      " Regression with ARIMA(0,1,1) errors : -13377.89\n",
      " Regression with ARIMA(0,1,0) errors : -13381.91\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.66\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13381.25\n",
      " Regression with ARIMA(1,1,0) errors : -13378.41\n",
      " Regression with ARIMA(0,1,1) errors : -13379.25\n",
      " Regression with ARIMA(0,1,0) errors : -13383.26\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13392.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13376.01\n",
      " Regression with ARIMA(1,1,0) errors : -13373.65\n",
      " Regression with ARIMA(0,1,1) errors : -13374\n",
      " Regression with ARIMA(0,1,0) errors : -13378.02\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13386.77\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13369.58\n",
      " Regression with ARIMA(1,1,0) errors : -13366.83\n",
      " Regression with ARIMA(0,1,1) errors : -13367.57\n",
      " Regression with ARIMA(0,1,0) errors : -13371.59\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13380.33\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13497.89\n",
      " Regression with ARIMA(0,0,0) errors : -9950.123\n",
      " Regression with ARIMA(1,0,0) errors : -13493.27\n",
      " Regression with ARIMA(0,0,1) errors : -11642.05\n",
      " Regression with ARIMA(0,0,0) errors : -8458.864\n",
      " Regression with ARIMA(1,0,2) errors : -13494.53\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -13496.04\n",
      " Regression with ARIMA(1,0,1) errors : -13495.7\n",
      " Regression with ARIMA(1,0,3) errors : -13492.7\n",
      " Regression with ARIMA(3,0,1) errors : -13497.36\n",
      " Regression with ARIMA(3,0,3) errors : -13498.01\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13507.72\n",
      " Regression with ARIMA(2,0,4) errors : -13500.47\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13500.7\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13506.03\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13499.98\n",
      " Regression with ARIMA(0,0,0) errors : -9960.775\n",
      " Regression with ARIMA(1,0,0) errors : -13495.47\n",
      " Regression with ARIMA(0,0,1) errors : -11645.81\n",
      " Regression with ARIMA(0,0,0) errors : -8453.629\n",
      " Regression with ARIMA(1,0,2) errors : -13496.49\n",
      " Regression with ARIMA(2,0,1) errors : -13507.19\n",
      " Regression with ARIMA(1,0,1) errors : -13497.52\n",
      " Regression with ARIMA(2,0,0) errors : -13496.74\n",
      " Regression with ARIMA(3,0,1) errors : -13497.31\n",
      " Regression with ARIMA(3,0,0) errors : -13495.2\n",
      " Regression with ARIMA(3,0,2) errors : -13495.71\n",
      " Regression with ARIMA(2,0,1) errors : -13378.82\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13506.74\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13497.77\n",
      " Regression with ARIMA(0,0,0) errors : -9958.269\n",
      " Regression with ARIMA(1,0,0) errors : -13494.31\n",
      " Regression with ARIMA(0,0,1) errors : -11644.45\n",
      " Regression with ARIMA(0,0,0) errors : -8449.905\n",
      " Regression with ARIMA(1,0,2) errors : -13495.3\n",
      " Regression with ARIMA(2,0,1) errors : -13507.9\n",
      " Regression with ARIMA(1,0,1) errors : -13496.33\n",
      " Regression with ARIMA(2,0,0) errors : -13495.6\n",
      " Regression with ARIMA(3,0,1) errors : -13496.54\n",
      " Regression with ARIMA(3,0,0) errors : -13493.75\n",
      " Regression with ARIMA(3,0,2) errors : -13495.71\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13508.08\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13493.96\n",
      " Regression with ARIMA(0,0,0) errors : -9977.205\n",
      " Regression with ARIMA(1,0,0) errors : -13489.97\n",
      " Regression with ARIMA(0,0,1) errors : -11647.24\n",
      " Regression with ARIMA(0,0,0) errors : -8450.876\n",
      " Regression with ARIMA(1,0,2) errors : -13490.98\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13488.95\n",
      " Regression with ARIMA(2,0,3) errors : -13487.5\n",
      " Regression with ARIMA(1,0,1) errors : -13492.01\n",
      " Regression with ARIMA(1,0,3) errors : -13489.23\n",
      " Regression with ARIMA(3,0,1) errors : -13492.37\n",
      " Regression with ARIMA(3,0,3) errors : -13486.94\n",
      " Regression with ARIMA(2,0,2) errors : -13356.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.62\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.03\n",
      " Regression with ARIMA(0,0,0) errors : -10035.28\n",
      " Regression with ARIMA(1,0,0) errors : -13487.39\n",
      " Regression with ARIMA(0,0,1) errors : -11673.35\n",
      " Regression with ARIMA(0,0,0) errors : -8457.324\n",
      " Regression with ARIMA(1,0,2) errors : -13488\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13489.24\n",
      " Regression with ARIMA(2,0,3) errors : -13489.21\n",
      " Regression with ARIMA(1,0,1) errors : -13488.93\n",
      " Regression with ARIMA(1,0,3) errors : -13486.24\n",
      " Regression with ARIMA(3,0,1) errors : -13491.09\n",
      " Regression with ARIMA(3,0,0) errors : -13487.21\n",
      " Regression with ARIMA(4,0,1) errors : -13487.57\n",
      " Regression with ARIMA(2,0,0) errors : -13488.97\n",
      " Regression with ARIMA(4,0,0) errors : -13485.19\n",
      " Regression with ARIMA(4,0,2) errors : -13498.14\n",
      " Regression with ARIMA(5,0,2) errors : -13499.05\n",
      " Regression with ARIMA(5,0,1) errors : -13492.88\n",
      " Regression with ARIMA(5,0,3) errors : -13497.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13501.63\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.2\n",
      " Regression with ARIMA(0,0,0) errors : -10019.33\n",
      " Regression with ARIMA(1,0,0) errors : -13487.57\n",
      " Regression with ARIMA(0,0,1) errors : -11667.27\n",
      " Regression with ARIMA(0,0,0) errors : -8455.887\n",
      " Regression with ARIMA(1,0,2) errors : -13488.56\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13489.44\n",
      " Regression with ARIMA(2,0,3) errors : -13490.16\n",
      " Regression with ARIMA(1,0,1) errors : -13489.31\n",
      " Regression with ARIMA(1,0,3) errors : -13486.85\n",
      " Regression with ARIMA(3,0,1) errors : -13491.32\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13350.82\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.68\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13489.2\n",
      " Regression with ARIMA(0,0,0) errors : -10028.88\n",
      " Regression with ARIMA(1,0,0) errors : -13485\n",
      " Regression with ARIMA(0,0,1) errors : -11673.96\n",
      " Regression with ARIMA(0,0,0) errors : -8443.256\n",
      " Regression with ARIMA(1,0,2) errors : -13486.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -13487.2\n",
      " Regression with ARIMA(1,0,1) errors : -13487.01\n",
      " Regression with ARIMA(1,0,3) errors : -13484.63\n",
      " Regression with ARIMA(3,0,1) errors : -13491.48\n",
      " Regression with ARIMA(3,0,0) errors : -13487\n",
      " Regression with ARIMA(4,0,1) errors : -13489.1\n",
      " Regression with ARIMA(2,0,0) errors : -13486.23\n",
      " Regression with ARIMA(4,0,0) errors : -13484.88\n",
      " Regression with ARIMA(4,0,2) errors : -13500.18\n",
      " Regression with ARIMA(5,0,2) errors : -13502.09\n",
      " Regression with ARIMA(5,0,1) errors : -13494.32\n",
      " Regression with ARIMA(5,0,3) errors : -13500.12\n",
      " Regression with ARIMA(4,0,3) errors : -13500.55\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13500.88\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492\n",
      " Regression with ARIMA(0,0,0) errors : -10028.08\n",
      " Regression with ARIMA(1,0,0) errors : -13487.35\n",
      " Regression with ARIMA(0,0,1) errors : -11679.14\n",
      " Regression with ARIMA(0,0,0) errors : -8442.705\n",
      " Regression with ARIMA(1,0,2) errors : -13488.66\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13487.58\n",
      " Regression with ARIMA(2,0,3) errors : -13489.99\n",
      " Regression with ARIMA(1,0,1) errors : -13489.51\n",
      " Regression with ARIMA(1,0,3) errors : -13487.09\n",
      " Regression with ARIMA(3,0,1) errors : -13489.86\n",
      " Regression with ARIMA(3,0,3) errors : -13482.34\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.71\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13496.48\n",
      " Regression with ARIMA(0,0,0) errors : -10046.87\n",
      " Regression with ARIMA(1,0,0) errors : -13491.11\n",
      " Regression with ARIMA(0,0,1) errors : -11686.59\n",
      " Regression with ARIMA(0,0,0) errors : -8439.819\n",
      " Regression with ARIMA(1,0,2) errors : -13492.36\n",
      " Regression with ARIMA(2,0,1) errors : -13506.72\n",
      " Regression with ARIMA(1,0,1) errors : -13493.26\n",
      " Regression with ARIMA(2,0,0) errors : -13492.87\n",
      " Regression with ARIMA(3,0,1) errors : -13494.79\n",
      " Regression with ARIMA(3,0,0) errors : -13491.08\n",
      " Regression with ARIMA(3,0,2) errors : -13506.27\n",
      " Regression with ARIMA(2,0,1) errors : -13358.47\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13505.42\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.02\n",
      " Regression with ARIMA(0,0,0) errors : -10051.63\n",
      " Regression with ARIMA(1,0,0) errors : -13487.72\n",
      " Regression with ARIMA(0,0,1) errors : -11688.79\n",
      " Regression with ARIMA(0,0,0) errors : -8460.12\n",
      " Regression with ARIMA(1,0,2) errors : -13489\n",
      " Regression with ARIMA(2,0,1) errors : -13501\n",
      " Regression with ARIMA(1,0,1) errors : -13489.93\n",
      " Regression with ARIMA(2,0,0) errors : -13489.16\n",
      " Regression with ARIMA(3,0,1) errors : -13490.72\n",
      " Regression with ARIMA(3,0,0) errors : -13487.43\n",
      " Regression with ARIMA(3,0,2) errors : -13488.68\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13501.14\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13500.43\n",
      " Regression with ARIMA(0,0,0) errors : -10047.97\n",
      " Regression with ARIMA(1,0,0) errors : -13495.4\n",
      " Regression with ARIMA(0,0,1) errors : -11686.73\n",
      " Regression with ARIMA(0,0,0) errors : -8459.472\n",
      " Regression with ARIMA(1,0,2) errors : -13496.66\n",
      " Regression with ARIMA(2,0,1) errors : -13510.38\n",
      " Regression with ARIMA(1,0,1) errors : -13497.58\n",
      " Regression with ARIMA(2,0,0) errors : -13497.07\n",
      " Regression with ARIMA(3,0,1) errors : -13498.19\n",
      " Regression with ARIMA(3,0,0) errors : -13495.29\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13509.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10051.61\n",
      " Regression with ARIMA(1,0,0) errors : -13499.36\n",
      " Regression with ARIMA(0,0,1) errors : -11694.33\n",
      " Regression with ARIMA(0,0,0) errors : -8454.72\n",
      " Regression with ARIMA(2,0,0) errors : -13501.93\n",
      " Regression with ARIMA(3,0,0) errors : -13500.22\n",
      " Regression with ARIMA(2,0,1) errors : -13512.21\n",
      " Regression with ARIMA(1,0,1) errors : -13501.76\n",
      " Regression with ARIMA(3,0,1) errors : -13503.01\n",
      " Regression with ARIMA(1,0,2) errors : -13500.7\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13514.04\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13505.3\n",
      " Regression with ARIMA(0,0,0) errors : -10067.87\n",
      " Regression with ARIMA(1,0,0) errors : -13500.56\n",
      " Regression with ARIMA(0,0,1) errors : -11703.92\n",
      " Regression with ARIMA(0,0,0) errors : -8459.352\n",
      " Regression with ARIMA(1,0,2) errors : -13501.48\n",
      " Regression with ARIMA(2,0,1) errors : -13513.92\n",
      " Regression with ARIMA(1,0,1) errors : -13502.47\n",
      " Regression with ARIMA(2,0,0) errors : -13501.76\n",
      " Regression with ARIMA(3,0,1) errors : -13504.22\n",
      " Regression with ARIMA(3,0,0) errors : -13499.98\n",
      " Regression with ARIMA(3,0,2) errors : -13502.51\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13509.66\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13504.43\n",
      " Regression with ARIMA(0,0,0) errors : -10066.73\n",
      " Regression with ARIMA(1,0,0) errors : -13500.34\n",
      " Regression with ARIMA(0,0,1) errors : -11703.9\n",
      " Regression with ARIMA(0,0,0) errors : -8459.982\n",
      " Regression with ARIMA(1,0,2) errors : -13501.46\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13502.1\n",
      " Regression with ARIMA(2,0,3) errors : -13502.47\n",
      " Regression with ARIMA(1,0,1) errors : -13502.43\n",
      " Regression with ARIMA(1,0,3) errors : -13499.75\n",
      " Regression with ARIMA(3,0,1) errors : -13504.38\n",
      " Regression with ARIMA(3,0,3) errors : -13511.67\n",
      " Regression with ARIMA(4,0,3) errors : -13502.32\n",
      " Regression with ARIMA(3,0,4) errors : -13513.38\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -13510.29\n",
      " Regression with ARIMA(3,0,5) errors : -13505.27\n",
      " Regression with ARIMA(2,0,5) errors : -13506.32\n",
      " Regression with ARIMA(4,0,5) errors : -13507.77\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13512.15\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13504.84\n",
      " Regression with ARIMA(0,0,0) errors : -10082.23\n",
      " Regression with ARIMA(1,0,0) errors : -13499.69\n",
      " Regression with ARIMA(0,0,1) errors : -11711.37\n",
      " Regression with ARIMA(0,0,0) errors : -8482.428\n",
      " Regression with ARIMA(1,0,2) errors : -13500.44\n",
      " Regression with ARIMA(2,0,1) errors : -13506.21\n",
      " Regression with ARIMA(1,0,1) errors : -13501.67\n",
      " Regression with ARIMA(2,0,0) errors : -13507.48\n",
      " Regression with ARIMA(3,0,0) errors : -13505.43\n",
      " Regression with ARIMA(3,0,1) errors : -13508.06\n",
      " Regression with ARIMA(4,0,1) errors : -13504.51\n",
      " Regression with ARIMA(3,0,2) errors : -13507\n",
      " Regression with ARIMA(4,0,0) errors : -13503.26\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -13503.39\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13511.77\n",
      " Regression with ARIMA(0,0,0) errors : -10089.38\n",
      " Regression with ARIMA(1,0,0) errors : -13508.45\n",
      " Regression with ARIMA(0,0,1) errors : -11717.82\n",
      " Regression with ARIMA(0,0,0) errors : -8486.146\n",
      " Regression with ARIMA(1,0,2) errors : -13508.73\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13508.14\n",
      " Regression with ARIMA(2,0,3) errors : -13509.84\n",
      " Regression with ARIMA(1,0,1) errors : -13509.99\n",
      " Regression with ARIMA(1,0,3) errors : -13507.09\n",
      " Regression with ARIMA(3,0,1) errors : -13509.92\n",
      " Regression with ARIMA(3,0,3) errors : -13517.49\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13519.73\n",
      " Regression with ARIMA(2,0,4) errors : -13513.32\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13514.28\n",
      " Regression with ARIMA(4,0,5) errors : -13514.96\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13520.01\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13510.51\n",
      " Regression with ARIMA(0,0,0) errors : -10105.18\n",
      " Regression with ARIMA(1,0,0) errors : -13507.88\n",
      " Regression with ARIMA(0,0,1) errors : -11721.86\n",
      " Regression with ARIMA(0,0,0) errors : -8493.114\n",
      " Regression with ARIMA(1,0,2) errors : -13508.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13516.56\n",
      " Regression with ARIMA(3,0,1) errors : -13506.85\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13515.63\n",
      " Regression with ARIMA(2,0,3) errors : -13508.55\n",
      " Regression with ARIMA(4,0,1) errors : -13509.07\n",
      " Regression with ARIMA(4,0,3) errors : -13513.32\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13519.6\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13508.31\n",
      " Regression with ARIMA(0,0,0) errors : -10126.55\n",
      " Regression with ARIMA(1,0,0) errors : -13507.44\n",
      " Regression with ARIMA(0,0,1) errors : -11732.75\n",
      " Regression with ARIMA(0,0,0) errors : -8479.726\n",
      " Regression with ARIMA(1,0,2) errors : -13507.67\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13508.26\n",
      " Regression with ARIMA(2,0,3) errors : -13506.52\n",
      " Regression with ARIMA(1,0,1) errors : -13508.92\n",
      " Regression with ARIMA(0,0,2) errors : -12538.44\n",
      " Regression with ARIMA(2,0,0) errors : -13508.97\n",
      " Regression with ARIMA(3,0,0) errors : -13506.81\n",
      " Regression with ARIMA(3,0,1) errors : -13510.29\n",
      " Regression with ARIMA(4,0,1) errors : -13507.38\n",
      " Regression with ARIMA(4,0,0) errors : -13504.51\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -13510.44\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10215.23\n",
      " Regression with ARIMA(1,0,0) errors : -13503.24\n",
      " Regression with ARIMA(0,0,1) errors : -11765.85\n",
      " Regression with ARIMA(0,0,0) errors : -8496.584\n",
      " Regression with ARIMA(2,0,0) errors : -13503.84\n",
      " Regression with ARIMA(3,0,0) errors : -13502.9\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13504.35\n",
      " Regression with ARIMA(1,0,2) errors : -13503.03\n",
      " Regression with ARIMA(0,0,2) errors : -12548.3\n",
      " Regression with ARIMA(1,0,1) errors : -13380.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13503.51\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10218.34\n",
      " Regression with ARIMA(1,0,0) errors : -13503.41\n",
      " Regression with ARIMA(0,0,1) errors : -11768.16\n",
      " Regression with ARIMA(0,0,0) errors : -8499.03\n",
      " Regression with ARIMA(2,0,0) errors : -13503.77\n",
      " Regression with ARIMA(3,0,0) errors : -13502.7\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13504.25\n",
      " Regression with ARIMA(1,0,2) errors : -13502.87\n",
      " Regression with ARIMA(0,0,2) errors : -12542.4\n",
      " Regression with ARIMA(1,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13503.42\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "[1] \"30 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13509.32\n",
      " Regression with ARIMA(0,0,0) errors : -10219.25\n",
      " Regression with ARIMA(1,0,0) errors : -13507.76\n",
      " Regression with ARIMA(0,0,1) errors : -11765.04\n",
      " Regression with ARIMA(0,0,0) errors : -8502.109\n",
      " Regression with ARIMA(1,0,2) errors : -13506.99\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13502.83\n",
      " Regression with ARIMA(2,0,3) errors : -13507.36\n",
      " Regression with ARIMA(1,0,1) errors : -13508.29\n",
      " Regression with ARIMA(1,0,3) errors : -13505.45\n",
      " Regression with ARIMA(3,0,1) errors : -13506.88\n",
      " Regression with ARIMA(3,0,3) errors : -13513.93\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13514.85\n",
      " Regression with ARIMA(2,0,4) errors : -13509.02\n",
      " Regression with ARIMA(4,0,4) errors : -13512.96\n",
      " Regression with ARIMA(3,0,5) errors : -13508.01\n",
      " Regression with ARIMA(2,0,5) errors : -13510.83\n",
      " Regression with ARIMA(4,0,5) errors : -13505.08\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13517.28\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10222.58\n",
      " Regression with ARIMA(1,0,0) errors : -13506.49\n",
      " Regression with ARIMA(0,0,1) errors : -11761.77\n",
      " Regression with ARIMA(0,0,0) errors : -8501.931\n",
      " Regression with ARIMA(2,0,0) errors : -13505.83\n",
      " Regression with ARIMA(1,0,1) errors : -13506.71\n",
      " Regression with ARIMA(2,0,1) errors : -13516.88\n",
      " Regression with ARIMA(3,0,1) errors : -13512.26\n",
      " Regression with ARIMA(1,0,2) errors : -13505.56\n",
      " Regression with ARIMA(3,0,0) errors : -13505.02\n",
      " Regression with ARIMA(3,0,2) errors : -13499.27\n",
      " Regression with ARIMA(2,0,1) errors : -13367.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13503.41\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13512.51\n",
      " Regression with ARIMA(0,0,0) errors : -10227.27\n",
      " Regression with ARIMA(1,0,0) errors : -13513.98\n",
      " Regression with ARIMA(0,0,1) errors : -11762.97\n",
      " Regression with ARIMA(0,0,0) errors : -8502.27\n",
      " Regression with ARIMA(2,0,0) errors : -13514.25\n",
      " Regression with ARIMA(3,0,0) errors : -13513.04\n",
      " Regression with ARIMA(2,0,1) errors : -13512.24\n",
      " Regression with ARIMA(1,0,1) errors : -13514.02\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -13380.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,0) errors : -13511.98\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13526.34\n",
      " Regression with ARIMA(0,0,0) errors : -10223.66\n",
      " Regression with ARIMA(1,0,0) errors : -13526.45\n",
      " Regression with ARIMA(0,0,1) errors : -11757.01\n",
      " Regression with ARIMA(0,0,0) errors : -8519.276\n",
      " Regression with ARIMA(2,0,0) errors : -13525.32\n",
      " Regression with ARIMA(1,0,1) errors : -13526.23\n",
      " Regression with ARIMA(2,0,1) errors : -13535.26\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13525.01\n",
      " Regression with ARIMA(3,0,0) errors : -13523.41\n",
      " Regression with ARIMA(3,0,2) errors : -13520.69\n",
      " Regression with ARIMA(2,0,1) errors : -13408.03\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13521.31\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10227.11\n",
      " Regression with ARIMA(1,0,0) errors : -13535.83\n",
      " Regression with ARIMA(0,0,1) errors : -11776.31\n",
      " Regression with ARIMA(0,0,0) errors : -8558.409\n",
      " Regression with ARIMA(2,0,0) errors : -13535.04\n",
      " Regression with ARIMA(1,0,1) errors : -13535.63\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13535.07\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10239.17\n",
      " Regression with ARIMA(1,0,0) errors : -13532.83\n",
      " Regression with ARIMA(0,0,1) errors : -11782.72\n",
      " Regression with ARIMA(0,0,0) errors : -8566.374\n",
      " Regression with ARIMA(2,0,0) errors : -13533.02\n",
      " Regression with ARIMA(3,0,0) errors : -13531.58\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13532.77\n",
      " Regression with ARIMA(3,0,1) errors : -13532.73\n",
      " Regression with ARIMA(2,0,0) errors : -13415.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,0) errors : -13531.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13539.55\n",
      " Regression with ARIMA(0,0,0) errors : -10238.93\n",
      " Regression with ARIMA(1,0,0) errors : -13540.07\n",
      " Regression with ARIMA(0,0,1) errors : -11784.97\n",
      " Regression with ARIMA(0,0,0) errors : -8571.174\n",
      " Regression with ARIMA(2,0,0) errors : -13539.5\n",
      " Regression with ARIMA(1,0,1) errors : -13540.16\n",
      " Regression with ARIMA(2,0,1) errors : -13549.2\n",
      " Regression with ARIMA(3,0,1) errors : -13539.61\n",
      " Regression with ARIMA(1,0,2) errors : -13539.06\n",
      " Regression with ARIMA(3,0,0) errors : -13537.64\n",
      " Regression with ARIMA(3,0,2) errors : -13537.96\n",
      " Regression with ARIMA(2,0,1) errors : -13400.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13550.1\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13537.09\n",
      " Regression with ARIMA(0,0,0) errors : -10239.99\n",
      " Regression with ARIMA(1,0,0) errors : -13540.98\n",
      " Regression with ARIMA(0,0,1) errors : -11788.21\n",
      " Regression with ARIMA(0,0,0) errors : -8584.355\n",
      " Regression with ARIMA(2,0,0) errors : -13540.68\n",
      " Regression with ARIMA(1,0,1) errors : -13540.96\n",
      " Regression with ARIMA(2,0,1) errors : -13550.79\n",
      " Regression with ARIMA(3,0,1) errors : -13544.63\n",
      " Regression with ARIMA(1,0,2) errors : -13539.89\n",
      " Regression with ARIMA(3,0,0) errors : -13538.95\n",
      " Regression with ARIMA(3,0,2) errors : -13543.48\n",
      " Regression with ARIMA(2,0,1) errors : -13423.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : -13541.93\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13563.2\n",
      " Regression with ARIMA(0,0,0) errors : -10221.42\n",
      " Regression with ARIMA(1,0,0) errors : -13558.89\n",
      " Regression with ARIMA(0,0,1) errors : -11783.59\n",
      " Regression with ARIMA(0,0,0) errors : -8587.344\n",
      " Regression with ARIMA(1,0,2) errors : -13557.75\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13560.36\n",
      " Regression with ARIMA(2,0,3) errors : -13561.2\n",
      " Regression with ARIMA(1,0,1) errors : -13558.83\n",
      " Regression with ARIMA(1,0,3) errors : -13556.36\n",
      " Regression with ARIMA(3,0,1) errors : -13562.66\n",
      " Regression with ARIMA(3,0,3) errors : -13569.83\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13571.17\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -13563.95\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13566.38\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13567.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13570.4\n",
      " Regression with ARIMA(0,0,0) errors : -10190.39\n",
      " Regression with ARIMA(1,0,0) errors : -13568.75\n",
      " Regression with ARIMA(0,0,1) errors : -11771.15\n",
      " Regression with ARIMA(0,0,0) errors : -8593.643\n",
      " Regression with ARIMA(1,0,2) errors : -13567.8\n",
      " Regression with ARIMA(2,0,1) errors : -13578.25\n",
      " Regression with ARIMA(1,0,1) errors : -13568.87\n",
      " Regression with ARIMA(2,0,0) errors : -13567.98\n",
      " Regression with ARIMA(3,0,1) errors : -13566.18\n",
      " Regression with ARIMA(3,0,0) errors : -13566.18\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : -13449.02\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13568.25\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13634.9\n",
      " Regression with ARIMA(0,0,0) errors : -10190.23\n",
      " Regression with ARIMA(1,0,0) errors : -13630.94\n",
      " Regression with ARIMA(0,0,1) errors : -11790.6\n",
      " Regression with ARIMA(0,0,0) errors : -8611.59\n",
      " Regression with ARIMA(1,0,2) errors : -13631.17\n",
      " Regression with ARIMA(2,0,1) errors : -13641.72\n",
      " Regression with ARIMA(1,0,1) errors : -13631.97\n",
      " Regression with ARIMA(2,0,0) errors : -13632.33\n",
      " Regression with ARIMA(3,0,1) errors : -13630.61\n",
      " Regression with ARIMA(3,0,0) errors : -13630.85\n",
      " Regression with ARIMA(3,0,2) errors : -13642.1\n",
      " Regression with ARIMA(4,0,2) errors : -13636.63\n",
      " Regression with ARIMA(3,0,3) errors : -13640.47\n",
      " Regression with ARIMA(2,0,3) errors : -13632.93\n",
      " Regression with ARIMA(4,0,1) errors : -13631.33\n",
      " Regression with ARIMA(4,0,3) errors : -13636.07\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13640.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13645.23\n",
      " Regression with ARIMA(0,0,0) errors : -10202.47\n",
      " Regression with ARIMA(1,0,0) errors : -13645.74\n",
      " Regression with ARIMA(0,0,1) errors : -11804.3\n",
      " Regression with ARIMA(0,0,0) errors : -8622.517\n",
      " Regression with ARIMA(2,0,0) errors : -13646.54\n",
      " Regression with ARIMA(3,0,0) errors : -13646.95\n",
      " Regression with ARIMA(4,0,0) errors : -13644.57\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -13646.54\n",
      " Regression with ARIMA(3,0,0) errors : -13536.11\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,0) errors : -13645.14\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13662.78\n",
      " Regression with ARIMA(0,0,0) errors : -10203.12\n",
      " Regression with ARIMA(1,0,0) errors : -13661.7\n",
      " Regression with ARIMA(0,0,1) errors : -11801.53\n",
      " Regression with ARIMA(0,0,0) errors : -8623.09\n",
      " Regression with ARIMA(1,0,2) errors : -13661.65\n",
      " Regression with ARIMA(2,0,1) errors : -13670.27\n",
      " Regression with ARIMA(1,0,1) errors : -13662.54\n",
      " Regression with ARIMA(2,0,0) errors : -13662.03\n",
      " Regression with ARIMA(3,0,1) errors : -13660.85\n",
      " Regression with ARIMA(3,0,0) errors : -13660.75\n",
      " Regression with ARIMA(3,0,2) errors : -13668.59\n",
      " Regression with ARIMA(2,0,1) errors : -13554.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13669.89\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13665.71\n",
      " Regression with ARIMA(0,0,0) errors : -10188.87\n",
      " Regression with ARIMA(1,0,0) errors : -13663.7\n",
      " Regression with ARIMA(0,0,1) errors : -11795.42\n",
      " Regression with ARIMA(0,0,0) errors : -8643.892\n",
      " Regression with ARIMA(1,0,2) errors : -13663.8\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13660.35\n",
      " Regression with ARIMA(2,0,3) errors : -13663.69\n",
      " Regression with ARIMA(1,0,1) errors : -13664.64\n",
      " Regression with ARIMA(1,0,3) errors : -13662.17\n",
      " Regression with ARIMA(3,0,1) errors : -13664.67\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13565.22\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13665.83\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13656.64\n",
      " Regression with ARIMA(0,0,0) errors : -10191.97\n",
      " Regression with ARIMA(1,0,0) errors : -13653.06\n",
      " Regression with ARIMA(0,0,1) errors : -11788.05\n",
      " Regression with ARIMA(0,0,0) errors : -8651.602\n",
      " Regression with ARIMA(1,0,2) errors : -13653.54\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13653.21\n",
      " Regression with ARIMA(2,0,3) errors : -13654.62\n",
      " Regression with ARIMA(1,0,1) errors : -13654.33\n",
      " Regression with ARIMA(1,0,3) errors : -13651.95\n",
      " Regression with ARIMA(3,0,1) errors : -13655.42\n",
      " Regression with ARIMA(3,0,3) errors : -13661.07\n",
      " Regression with ARIMA(4,0,3) errors : -13648.86\n",
      " Regression with ARIMA(3,0,4) errors : -13662.96\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13661.06\n",
      " Regression with ARIMA(4,0,5) errors : -13659.57\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13659.73\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13649.41\n",
      " Regression with ARIMA(0,0,0) errors : -10167.99\n",
      " Regression with ARIMA(1,0,0) errors : -13648.99\n",
      " Regression with ARIMA(0,0,1) errors : -11774.26\n",
      " Regression with ARIMA(0,0,0) errors : -8653.868\n",
      " Regression with ARIMA(1,0,2) errors : -13649.56\n",
      " Regression with ARIMA(0,0,2) errors : -12612.9\n",
      " Regression with ARIMA(1,0,1) errors : -13650.24\n",
      " Regression with ARIMA(2,0,1) errors : -13660.4\n",
      " Regression with ARIMA(2,0,0) errors : -13649.71\n",
      " Regression with ARIMA(3,0,1) errors : -13651.41\n",
      " Regression with ARIMA(3,0,0) errors : -13648.4\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13661.18\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13655.63\n",
      " Regression with ARIMA(0,0,0) errors : -10165.57\n",
      " Regression with ARIMA(1,0,0) errors : -13654.18\n",
      " Regression with ARIMA(0,0,1) errors : -11773.14\n",
      " Regression with ARIMA(0,0,0) errors : -8656.522\n",
      " Regression with ARIMA(1,0,2) errors : -13654.42\n",
      " Regression with ARIMA(2,0,1) errors : -13665.49\n",
      " Regression with ARIMA(1,0,1) errors : -13655.18\n",
      " Regression with ARIMA(2,0,0) errors : -13654.5\n",
      " Regression with ARIMA(3,0,1) errors : -13655.23\n",
      " Regression with ARIMA(3,0,0) errors : -13653.04\n",
      " Regression with ARIMA(3,0,2) errors : -13653.31\n",
      " Regression with ARIMA(2,0,1) errors : -13554.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13666.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13657.3\n",
      " Regression with ARIMA(0,0,0) errors : -10165.83\n",
      " Regression with ARIMA(1,0,0) errors : -13655.15\n",
      " Regression with ARIMA(0,0,1) errors : -11771.76\n",
      " Regression with ARIMA(0,0,0) errors : -8655.923\n",
      " Regression with ARIMA(1,0,2) errors : -13655.23\n",
      " Regression with ARIMA(2,0,1) errors : -13667.08\n",
      " Regression with ARIMA(1,0,1) errors : -13656.02\n",
      " Regression with ARIMA(2,0,0) errors : -13655.19\n",
      " Regression with ARIMA(3,0,1) errors : -13655.86\n",
      " Regression with ARIMA(3,0,0) errors : -13658.04\n",
      " Regression with ARIMA(3,0,2) errors : -13655.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13666.52\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13655.6\n",
      " Regression with ARIMA(0,0,0) errors : -10159.47\n",
      " Regression with ARIMA(1,0,0) errors : -13654.74\n",
      " Regression with ARIMA(0,0,1) errors : -11765.48\n",
      " Regression with ARIMA(0,0,0) errors : -8662.39\n",
      " Regression with ARIMA(1,0,2) errors : -13655.14\n",
      " Regression with ARIMA(2,0,1) errors : -13671.56\n",
      " Regression with ARIMA(1,0,1) errors : -13655.72\n",
      " Regression with ARIMA(2,0,0) errors : -13656.86\n",
      " Regression with ARIMA(3,0,1) errors : -13656.12\n",
      " Regression with ARIMA(3,0,0) errors : -13655.95\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13665.81\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13656.79\n",
      " Regression with ARIMA(0,0,0) errors : -10173.96\n",
      " Regression with ARIMA(1,0,0) errors : -13652.05\n",
      " Regression with ARIMA(0,0,1) errors : -11777.5\n",
      " Regression with ARIMA(0,0,0) errors : -8700.468\n",
      " Regression with ARIMA(1,0,2) errors : -13652.23\n",
      " Regression with ARIMA(2,0,1) errors : -13668.02\n",
      " Regression with ARIMA(1,0,1) errors : -13652.1\n",
      " Regression with ARIMA(2,0,0) errors : -13652.19\n",
      " Regression with ARIMA(3,0,1) errors : -13656.11\n",
      " Regression with ARIMA(3,0,0) errors : -13652.01\n",
      " Regression with ARIMA(3,0,2) errors : -13662.39\n",
      " Regression with ARIMA(2,0,1) errors : -13548.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13662.69\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13625.68\n",
      " Regression with ARIMA(0,1,0) errors : -13621.46\n",
      " Regression with ARIMA(1,1,0) errors : -13624.34\n",
      " Regression with ARIMA(0,1,1) errors : -13619.6\n",
      " Regression with ARIMA(0,1,0) errors : -13623.47\n",
      " Regression with ARIMA(1,1,2) errors : -13629.17\n",
      " Regression with ARIMA(0,1,2) errors : -13617.77\n",
      " Regression with ARIMA(1,1,1) errors : -13628.01\n",
      " Regression with ARIMA(1,1,3) errors : -13633.78\n",
      " Regression with ARIMA(0,1,3) errors : -13616.46\n",
      " Regression with ARIMA(2,1,3) errors : -13627.37\n",
      " Regression with ARIMA(1,1,4) errors : -13638.05\n",
      " Regression with ARIMA(0,1,4) errors : -13614.88\n",
      " Regression with ARIMA(2,1,4) errors : -13627.68\n",
      " Regression with ARIMA(1,1,5) errors : -13657.04\n",
      " Regression with ARIMA(0,1,5) errors : -13617.4\n",
      " Regression with ARIMA(2,1,5) errors : -13647.25\n",
      " Regression with ARIMA(1,1,5) errors : -13658.92\n",
      " Regression with ARIMA(0,1,5) errors : -13619.42\n",
      " Regression with ARIMA(1,1,4) errors : -13639.93\n",
      " Regression with ARIMA(2,1,5) errors : -13649.14\n",
      " Regression with ARIMA(0,1,4) errors : -13616.89\n",
      " Regression with ARIMA(2,1,4) errors : -13629.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,0) errors : -13628.45\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13669.46\n",
      " Regression with ARIMA(0,1,0) errors : -13667.96\n",
      " Regression with ARIMA(1,1,0) errors : -13665.88\n",
      " Regression with ARIMA(0,1,1) errors : -13666.47\n",
      " Regression with ARIMA(0,1,0) errors : -13669.95\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13678.82\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10272.74\n",
      " Regression with ARIMA(1,0,0) errors : -13772.01\n",
      " Regression with ARIMA(0,0,1) errors : -11891.74\n",
      " Regression with ARIMA(0,0,0) errors : -8843.671\n",
      " Regression with ARIMA(2,0,0) errors : -13770.9\n",
      " Regression with ARIMA(1,0,1) errors : -13771.44\n",
      " Regression with ARIMA(2,0,1) errors : -13785.75\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13772.19\n",
      " Regression with ARIMA(3,0,0) errors : -13772.31\n",
      " Regression with ARIMA(3,0,2) errors : -13785.11\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13783.28\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13764.52\n",
      " Regression with ARIMA(0,0,0) errors : -10268.04\n",
      " Regression with ARIMA(1,0,0) errors : -13761.23\n",
      " Regression with ARIMA(0,0,1) errors : -11885.1\n",
      " Regression with ARIMA(0,0,0) errors : -8858.715\n",
      " Regression with ARIMA(1,0,2) errors : -13761.55\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13782.76\n",
      " Regression with ARIMA(3,0,1) errors : -13780.45\n",
      " Regression with ARIMA(4,0,2) errors : -13778.02\n",
      " Regression with ARIMA(3,0,3) errors : -13780.93\n",
      " Regression with ARIMA(2,0,3) errors : -13762.9\n",
      " Regression with ARIMA(4,0,1) errors : -13774.34\n",
      " Regression with ARIMA(4,0,3) errors : -13775.95\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13775.78\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "[1] \"40 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13769.81\n",
      " Regression with ARIMA(0,0,0) errors : -10265.3\n",
      " Regression with ARIMA(1,0,0) errors : -13762.85\n",
      " Regression with ARIMA(0,0,1) errors : -11881.84\n",
      " Regression with ARIMA(0,0,0) errors : -8821.143\n",
      " Regression with ARIMA(1,0,2) errors : -13762.57\n",
      " Regression with ARIMA(2,0,1) errors : -13768.3\n",
      " Regression with ARIMA(3,0,2) errors : -13783.22\n",
      " Regression with ARIMA(3,0,1) errors : -13768.49\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13781.28\n",
      " Regression with ARIMA(2,0,3) errors : -13768.18\n",
      " Regression with ARIMA(4,0,1) errors : -13769.2\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13777.69\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13769.38\n",
      " Regression with ARIMA(0,0,0) errors : -10260.46\n",
      " Regression with ARIMA(1,0,0) errors : -13763.75\n",
      " Regression with ARIMA(0,0,1) errors : -11877.06\n",
      " Regression with ARIMA(0,0,0) errors : -8820.979\n",
      " Regression with ARIMA(1,0,2) errors : -13763.9\n",
      " Regression with ARIMA(2,0,1) errors : -13767.21\n",
      " Regression with ARIMA(3,0,2) errors : -13781.12\n",
      " Regression with ARIMA(3,0,1) errors : -13768.51\n",
      " Regression with ARIMA(4,0,2) errors : -13781.64\n",
      " Regression with ARIMA(4,0,1) errors : -13767.06\n",
      " Regression with ARIMA(5,0,2) errors : -13779.5\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13781.37\n",
      " Regression with ARIMA(5,0,1) errors : -13775.92\n",
      " Regression with ARIMA(5,0,3) errors : -13777.89\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,2) errors : -13774.84\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13730.6\n",
      " Regression with ARIMA(0,0,0) errors : -10252.14\n",
      " Regression with ARIMA(1,0,0) errors : -13734.15\n",
      " Regression with ARIMA(0,0,1) errors : -11865.14\n",
      " Regression with ARIMA(0,0,0) errors : -8811.741\n",
      " Regression with ARIMA(2,0,0) errors : -13732.86\n",
      " Regression with ARIMA(1,0,1) errors : -13733.55\n",
      " Regression with ARIMA(2,0,1) errors : -13745.03\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13733.84\n",
      " Regression with ARIMA(3,0,0) errors : -13732.77\n",
      " Regression with ARIMA(3,0,2) errors : -13730.31\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13733.34\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10248.64\n",
      " Regression with ARIMA(1,0,0) errors : -13726.11\n",
      " Regression with ARIMA(0,0,1) errors : -11859.38\n",
      " Regression with ARIMA(0,0,0) errors : -8814.75\n",
      " Regression with ARIMA(2,0,0) errors : -13726.2\n",
      " Regression with ARIMA(3,0,0) errors : -13726.52\n",
      " Regression with ARIMA(4,0,0) errors : -13725.54\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : -13736.42\n",
      " Regression with ARIMA(1,0,1) errors : -13725.25\n",
      " Regression with ARIMA(1,0,2) errors : -13725.96\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,0) errors : -13725.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10253.6\n",
      " Regression with ARIMA(1,0,0) errors : -13735.62\n",
      " Regression with ARIMA(0,0,1) errors : -11865.12\n",
      " Regression with ARIMA(0,0,0) errors : -8816.856\n",
      " Regression with ARIMA(2,0,0) errors : -13733.87\n",
      " Regression with ARIMA(1,0,1) errors : -13734.66\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13733.14\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13750.01\n",
      " Regression with ARIMA(0,0,0) errors : -10257.06\n",
      " Regression with ARIMA(1,0,0) errors : -13738.28\n",
      " Regression with ARIMA(0,0,1) errors : -11865.9\n",
      " Regression with ARIMA(0,0,0) errors : -8780.029\n",
      " Regression with ARIMA(1,0,2) errors : -13737.34\n",
      " Regression with ARIMA(2,0,1) errors : -13751.1\n",
      " Regression with ARIMA(1,0,1) errors : -13737.18\n",
      " Regression with ARIMA(2,0,0) errors : -13736.6\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,0) errors : -13736.27\n",
      " Regression with ARIMA(3,0,2) errors : -13732.63\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13735.84\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10256.83\n",
      " Regression with ARIMA(1,0,0) errors : -13730.95\n",
      " Regression with ARIMA(0,0,1) errors : -11861.77\n",
      " Regression with ARIMA(0,0,0) errors : -8779.258\n",
      " Regression with ARIMA(2,0,0) errors : -13729.15\n",
      " Regression with ARIMA(1,0,1) errors : -13729.46\n",
      " Regression with ARIMA(2,0,1) errors : -13743.66\n",
      " Regression with ARIMA(3,0,1) errors : -13740.11\n",
      " Regression with ARIMA(1,0,2) errors : -13729.66\n",
      " Regression with ARIMA(3,0,0) errors : -13731.65\n",
      " Regression with ARIMA(3,0,2) errors : -13742.18\n",
      " Regression with ARIMA(2,0,1) errors : -13618.71\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13744.27\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13704.92\n",
      " Regression with ARIMA(0,0,0) errors : -10273.67\n",
      " Regression with ARIMA(1,0,0) errors : -13706.69\n",
      " Regression with ARIMA(0,0,1) errors : -11878.39\n",
      " Regression with ARIMA(0,0,0) errors : -8797.955\n",
      " Regression with ARIMA(2,0,0) errors : -13704.19\n",
      " Regression with ARIMA(1,0,1) errors : -13704.98\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13577.35\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13704.77\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13513.55\n",
      " Regression with ARIMA(0,0,0) errors : -10068.34\n",
      " Regression with ARIMA(1,0,0) errors : -13520.38\n",
      " Regression with ARIMA(0,0,1) errors : -11654.6\n",
      " Regression with ARIMA(0,0,0) errors : -8614.487\n",
      " Regression with ARIMA(2,0,0) errors : -13517.43\n",
      " Regression with ARIMA(1,0,1) errors : -13518.38\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13517.53\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12970.83\n",
      " Regression with ARIMA(0,1,0) errors : -12930.49\n",
      " Regression with ARIMA(1,1,0) errors : -12945.11\n",
      " Regression with ARIMA(0,1,1) errors : -12947.22\n",
      " Regression with ARIMA(0,1,0) errors : -12932.5\n",
      " Regression with ARIMA(1,1,2) errors : -12962.91\n",
      " Regression with ARIMA(2,1,1) errors : -12971.71\n",
      " Regression with ARIMA(1,1,1) errors : -12955.51\n",
      " Regression with ARIMA(2,1,0) errors : -12969.84\n",
      " Regression with ARIMA(3,1,1) errors : -12974.24\n",
      " Regression with ARIMA(3,1,0) errors : -12974.64\n",
      " Regression with ARIMA(4,1,0) errors : -12978.76\n",
      " Regression with ARIMA(5,1,0) errors : -12976.29\n",
      " Regression with ARIMA(4,1,1) errors : -12976.71\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,0) errors : -12980.76\n",
      " Regression with ARIMA(3,1,0) errors : -12976.65\n",
      " Regression with ARIMA(5,1,0) errors : -12978.28\n",
      " Regression with ARIMA(4,1,1) errors : -12978.77\n",
      " Regression with ARIMA(3,1,1) errors : -12976.24\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,1,0) errors : -12980.2\n",
      "\n",
      " Best model: Regression with ARIMA(4,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12722.08\n",
      " Regression with ARIMA(0,1,0) errors : -12682.87\n",
      " Regression with ARIMA(1,1,0) errors : -12702.85\n",
      " Regression with ARIMA(0,1,1) errors : -12708.6\n",
      " Regression with ARIMA(0,1,0) errors : -12684.84\n",
      " Regression with ARIMA(1,1,2) errors : -12720.75\n",
      " Regression with ARIMA(2,1,1) errors : -12722.99\n",
      " Regression with ARIMA(1,1,1) errors : -12711.35\n",
      " Regression with ARIMA(2,1,0) errors : -12720.41\n",
      " Regression with ARIMA(3,1,1) errors : -12722.13\n",
      " Regression with ARIMA(3,1,0) errors : -12724.07\n",
      " Regression with ARIMA(4,1,0) errors : -12721.18\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -12726.05\n",
      " Regression with ARIMA(2,1,0) errors : -12722.38\n",
      " Regression with ARIMA(4,1,0) errors : -12723.17\n",
      " Regression with ARIMA(3,1,1) errors : -12724.11\n",
      " Regression with ARIMA(2,1,1) errors : -12724.96\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,0) errors : -12736.42\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12560.78\n",
      " Regression with ARIMA(0,1,0) errors : -12505.96\n",
      " Regression with ARIMA(1,1,0) errors : -12527.34\n",
      " Regression with ARIMA(0,1,1) errors : -12533.58\n",
      " Regression with ARIMA(0,1,0) errors : -12507.97\n",
      " Regression with ARIMA(1,1,2) errors : -12551.89\n",
      " Regression with ARIMA(2,1,1) errors : -12557.49\n",
      " Regression with ARIMA(3,1,2) errors : -12557.93\n",
      " Regression with ARIMA(2,1,3) errors : -12558.92\n",
      " Regression with ARIMA(1,1,1) errors : -12537.48\n",
      " Regression with ARIMA(1,1,3) errors : -12554.56\n",
      " Regression with ARIMA(3,1,1) errors : -12557.55\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12562.8\n",
      " Regression with ARIMA(1,1,2) errors : -12553.91\n",
      " Regression with ARIMA(2,1,1) errors : -12559.5\n",
      " Regression with ARIMA(3,1,2) errors : -12559.9\n",
      " Regression with ARIMA(2,1,3) errors : -12560.93\n",
      " Regression with ARIMA(1,1,1) errors : -12539.48\n",
      " Regression with ARIMA(1,1,3) errors : -12556.58\n",
      " Regression with ARIMA(3,1,1) errors : -12559.56\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12572.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12525.75\n",
      " Regression with ARIMA(0,1,0) errors : -12472.26\n",
      " Regression with ARIMA(1,1,0) errors : -12494.36\n",
      " Regression with ARIMA(0,1,1) errors : -12499.92\n",
      " Regression with ARIMA(0,1,0) errors : -12474.27\n",
      " Regression with ARIMA(1,1,2) errors : -12516.93\n",
      " Regression with ARIMA(2,1,1) errors : -12522.47\n",
      " Regression with ARIMA(3,1,2) errors : -12522.7\n",
      " Regression with ARIMA(2,1,3) errors : -12523.75\n",
      " Regression with ARIMA(1,1,1) errors : -12502.95\n",
      " Regression with ARIMA(1,1,3) errors : -12520.19\n",
      " Regression with ARIMA(3,1,1) errors : -12522.74\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12527.77\n",
      " Regression with ARIMA(1,1,2) errors : -12518.94\n",
      " Regression with ARIMA(2,1,1) errors : -12524.48\n",
      " Regression with ARIMA(3,1,2) errors : -12524.7\n",
      " Regression with ARIMA(2,1,3) errors : -12525.77\n",
      " Regression with ARIMA(1,1,1) errors : -12504.95\n",
      " Regression with ARIMA(1,1,3) errors : -12522.21\n",
      " Regression with ARIMA(3,1,1) errors : -12524.75\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12537.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12470.37\n",
      " Regression with ARIMA(0,1,0) errors : -12414.35\n",
      " Regression with ARIMA(1,1,0) errors : -12436.58\n",
      " Regression with ARIMA(0,1,1) errors : -12443.12\n",
      " Regression with ARIMA(0,1,0) errors : -12416.35\n",
      " Regression with ARIMA(1,1,2) errors : -12461.95\n",
      " Regression with ARIMA(2,1,1) errors : -12468.01\n",
      " Regression with ARIMA(3,1,2) errors : -12467.45\n",
      " Regression with ARIMA(2,1,3) errors : -12468.34\n",
      " Regression with ARIMA(1,1,1) errors : -12445.63\n",
      " Regression with ARIMA(1,1,3) errors : -12464.82\n",
      " Regression with ARIMA(3,1,1) errors : -12468.7\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12472.37\n",
      " Regression with ARIMA(1,1,2) errors : -12463.95\n",
      " Regression with ARIMA(2,1,1) errors : -12470\n",
      " Regression with ARIMA(3,1,2) errors : -12469.45\n",
      " Regression with ARIMA(2,1,3) errors : -12470.36\n",
      " Regression with ARIMA(1,1,1) errors : -12447.62\n",
      " Regression with ARIMA(1,1,3) errors : -12466.82\n",
      " Regression with ARIMA(3,1,1) errors : -12470.69\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12481.51\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12415.46\n",
      " Regression with ARIMA(0,1,0) errors : -12357.7\n",
      " Regression with ARIMA(1,1,0) errors : -12377.73\n",
      " Regression with ARIMA(0,1,1) errors : -12382.8\n",
      " Regression with ARIMA(0,1,0) errors : -12359.71\n",
      " Regression with ARIMA(1,1,2) errors : -12397.26\n",
      " Regression with ARIMA(2,1,1) errors : -12405.48\n",
      " Regression with ARIMA(3,1,2) errors : -12413.51\n",
      " Regression with ARIMA(2,1,3) errors : -12414.64\n",
      " Regression with ARIMA(1,1,1) errors : -12383.72\n",
      " Regression with ARIMA(1,1,3) errors : -12404.76\n",
      " Regression with ARIMA(3,1,1) errors : -12410.9\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12417.47\n",
      " Regression with ARIMA(1,1,2) errors : -12399.27\n",
      " Regression with ARIMA(2,1,1) errors : -12407.49\n",
      " Regression with ARIMA(3,1,2) errors : -12415.52\n",
      " Regression with ARIMA(2,1,3) errors : -12416.65\n",
      " Regression with ARIMA(1,1,1) errors : -12385.73\n",
      " Regression with ARIMA(1,1,3) errors : -12406.78\n",
      " Regression with ARIMA(3,1,1) errors : -12412.92\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12422.35\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12392.88\n",
      " Regression with ARIMA(0,1,0) errors : -12334.96\n",
      " Regression with ARIMA(1,1,0) errors : -12358.48\n",
      " Regression with ARIMA(0,1,1) errors : -12364.77\n",
      " Regression with ARIMA(0,1,0) errors : -12336.95\n",
      " Regression with ARIMA(1,1,2) errors : -12380.24\n",
      " Regression with ARIMA(2,1,1) errors : -12390.33\n",
      " Regression with ARIMA(3,1,2) errors : -12392.56\n",
      " Regression with ARIMA(2,1,3) errors : -12390.88\n",
      " Regression with ARIMA(1,1,1) errors : -12366.94\n",
      " Regression with ARIMA(1,1,3) errors : -12386.73\n",
      " Regression with ARIMA(3,1,1) errors : -12394.33\n",
      " Regression with ARIMA(3,1,0) errors : -12396.28\n",
      " Regression with ARIMA(2,1,0) errors : -12381.04\n",
      " Regression with ARIMA(4,1,0) errors : -12409.24\n",
      " Regression with ARIMA(5,1,0) errors : -12418.87\n",
      " Regression with ARIMA(5,1,1) errors : -12429.22\n",
      " Regression with ARIMA(4,1,1) errors : -12408.98\n",
      " Regression with ARIMA(5,1,2) errors : -12419\n",
      " Regression with ARIMA(4,1,2) errors : -12415.77\n",
      " Regression with ARIMA(5,1,1) errors : -12431.1\n",
      " Regression with ARIMA(4,1,1) errors : -12410.99\n",
      " Regression with ARIMA(5,1,0) errors : -12420.89\n",
      " Regression with ARIMA(5,1,2) errors : -12421.01\n",
      " Regression with ARIMA(4,1,0) errors : -12411.25\n",
      " Regression with ARIMA(4,1,2) errors : -12417.78\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,0) errors : -12408.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12405.22\n",
      " Regression with ARIMA(0,1,0) errors : -12342.22\n",
      " Regression with ARIMA(1,1,0) errors : -12369.17\n",
      " Regression with ARIMA(0,1,1) errors : -12375.11\n",
      " Regression with ARIMA(0,1,0) errors : -12344.23\n",
      " Regression with ARIMA(1,1,2) errors : -12390.01\n",
      " Regression with ARIMA(2,1,1) errors : -12397.17\n",
      " Regression with ARIMA(3,1,2) errors : -12404.33\n",
      " Regression with ARIMA(2,1,3) errors : -12403.26\n",
      " Regression with ARIMA(1,1,1) errors : -12376.7\n",
      " Regression with ARIMA(1,1,3) errors : -12397.27\n",
      " Regression with ARIMA(3,1,1) errors : -12402.52\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12407.23\n",
      " Regression with ARIMA(1,1,2) errors : -12392.02\n",
      " Regression with ARIMA(2,1,1) errors : -12399.19\n",
      " Regression with ARIMA(3,1,2) errors : -12406.34\n",
      " Regression with ARIMA(2,1,3) errors : -12405.28\n",
      " Regression with ARIMA(1,1,1) errors : -12378.71\n",
      " Regression with ARIMA(1,1,3) errors : -12399.28\n",
      " Regression with ARIMA(3,1,1) errors : -12404.53\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12418.09\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12479.1\n",
      " Regression with ARIMA(0,0,0) errors : -8904.547\n",
      " Regression with ARIMA(1,0,0) errors : -12457.86\n",
      " Regression with ARIMA(0,0,1) errors : -10586.67\n",
      " Regression with ARIMA(0,0,0) errors : -7757.971\n",
      " Regression with ARIMA(1,0,2) errors : -12470.62\n",
      " Regression with ARIMA(2,0,1) errors : -12467.78\n",
      " Regression with ARIMA(3,0,2) errors : -12535.04\n",
      " Regression with ARIMA(3,0,1) errors : -12486.22\n",
      " Regression with ARIMA(4,0,2) errors : -12504.23\n",
      " Regression with ARIMA(3,0,3) errors : -12504.59\n",
      " Regression with ARIMA(2,0,3) errors : -12501.85\n",
      " Regression with ARIMA(4,0,1) errors : -12505.69\n",
      " Regression with ARIMA(4,0,3) errors : -12533.86\n",
      " Regression with ARIMA(3,0,2) errors : -12438.48\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12506.31\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12465.71\n",
      " Regression with ARIMA(0,0,0) errors : -8892.805\n",
      " Regression with ARIMA(1,0,0) errors : -12446.23\n",
      " Regression with ARIMA(0,0,1) errors : -10571.36\n",
      " Regression with ARIMA(0,0,0) errors : -7709.597\n",
      " Regression with ARIMA(1,0,2) errors : -12458.34\n",
      " Regression with ARIMA(2,0,1) errors : -12455.94\n",
      " Regression with ARIMA(3,0,2) errors : -12524.46\n",
      " Regression with ARIMA(3,0,1) errors : -12471.77\n",
      " Regression with ARIMA(4,0,2) errors : -12490.22\n",
      " Regression with ARIMA(3,0,3) errors : -12489.3\n",
      " Regression with ARIMA(2,0,3) errors : -12488.4\n",
      " Regression with ARIMA(4,0,1) errors : -12491.45\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12529.33\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12465.29\n",
      " Regression with ARIMA(0,0,0) errors : -8894.651\n",
      " Regression with ARIMA(1,0,0) errors : -12445.35\n",
      " Regression with ARIMA(0,0,1) errors : -10573.51\n",
      " Regression with ARIMA(0,0,0) errors : -7703.577\n",
      " Regression with ARIMA(1,0,2) errors : -12457.79\n",
      " Regression with ARIMA(2,0,1) errors : -12455.34\n",
      " Regression with ARIMA(3,0,2) errors : -12521.44\n",
      " Regression with ARIMA(3,0,1) errors : -12471.75\n",
      " Regression with ARIMA(4,0,2) errors : -12489.95\n",
      " Regression with ARIMA(3,0,3) errors : -12489.87\n",
      " Regression with ARIMA(2,0,3) errors : -12487.74\n",
      " Regression with ARIMA(4,0,1) errors : -12490.93\n",
      " Regression with ARIMA(4,0,3) errors : -12517.07\n",
      " Regression with ARIMA(3,0,2) errors : -12443.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12527.75\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12457.74\n",
      " Regression with ARIMA(0,0,0) errors : -8888.053\n",
      " Regression with ARIMA(1,0,0) errors : -12438.77\n",
      " Regression with ARIMA(0,0,1) errors : -10568.72\n",
      " Regression with ARIMA(0,0,0) errors : -7699.325\n",
      " Regression with ARIMA(1,0,2) errors : -12450.59\n",
      " Regression with ARIMA(2,0,1) errors : -12447.71\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12479.45\n",
      " Regression with ARIMA(1,0,3) errors : -12482.41\n",
      " Regression with ARIMA(0,0,3) errors : -11655.39\n",
      " Regression with ARIMA(1,0,4) errors : -12480.42\n",
      " Regression with ARIMA(0,0,2) errors : -11226.37\n",
      " Regression with ARIMA(0,0,4) errors : -11987.9\n",
      " Regression with ARIMA(2,0,4) errors : -12508.61\n",
      " Regression with ARIMA(3,0,4) errors : -12510.98\n",
      " Regression with ARIMA(3,0,3) errors : -12480.89\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12508.89\n",
      " Regression with ARIMA(2,0,5) errors : -12511.16\n",
      " Regression with ARIMA(1,0,5) errors : -12481.3\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12511.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12454.54\n",
      " Regression with ARIMA(0,0,0) errors : -8881.322\n",
      " Regression with ARIMA(1,0,0) errors : -12434.91\n",
      " Regression with ARIMA(0,0,1) errors : -10562.75\n",
      " Regression with ARIMA(0,0,0) errors : -7707.396\n",
      " Regression with ARIMA(1,0,2) errors : -12446.19\n",
      " Regression with ARIMA(2,0,1) errors : -12444.84\n",
      " Regression with ARIMA(3,0,2) errors : -12469.19\n",
      " Regression with ARIMA(3,0,1) errors : -12458.01\n",
      " Regression with ARIMA(4,0,2) errors : -12484.21\n",
      " Regression with ARIMA(4,0,1) errors : -12483.69\n",
      " Regression with ARIMA(5,0,2) errors : -12502.19\n",
      " Regression with ARIMA(5,0,1) errors : -12498.17\n",
      " Regression with ARIMA(5,0,3) errors : -12504.05\n",
      " Regression with ARIMA(4,0,3) errors : -12482.32\n",
      " Regression with ARIMA(5,0,4) errors : -12490.42\n",
      " Regression with ARIMA(4,0,4) errors : -12481.71\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : -12506.66\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12464.6\n",
      " Regression with ARIMA(0,0,0) errors : -8887.118\n",
      " Regression with ARIMA(1,0,0) errors : -12445.24\n",
      " Regression with ARIMA(0,0,1) errors : -10561.18\n",
      " Regression with ARIMA(0,0,0) errors : -7708.215\n",
      " Regression with ARIMA(1,0,2) errors : -12456.91\n",
      " Regression with ARIMA(2,0,1) errors : -12455.73\n",
      " Regression with ARIMA(3,0,2) errors : -12528.24\n",
      " Regression with ARIMA(3,0,1) errors : -12470.67\n",
      " Regression with ARIMA(4,0,2) errors : -12491.02\n",
      " Regression with ARIMA(3,0,3) errors : -12487.94\n",
      " Regression with ARIMA(2,0,3) errors : -12488.17\n",
      " Regression with ARIMA(4,0,1) errors : -12491.62\n",
      " Regression with ARIMA(4,0,3) errors : -12490.61\n",
      " Regression with ARIMA(3,0,2) errors : -12436.46\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12488.78\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12482.33\n",
      " Regression with ARIMA(0,0,0) errors : -8891.815\n",
      " Regression with ARIMA(1,0,0) errors : -12463.17\n",
      " Regression with ARIMA(0,0,1) errors : -10569.71\n",
      " Regression with ARIMA(0,0,0) errors : -7717.256\n",
      " Regression with ARIMA(1,0,2) errors : -12475.08\n",
      " Regression with ARIMA(2,0,1) errors : -12474.77\n",
      " Regression with ARIMA(3,0,2) errors : -12536.91\n",
      " Regression with ARIMA(3,0,1) errors : -12489.05\n",
      " Regression with ARIMA(4,0,2) errors : -12507.21\n",
      " Regression with ARIMA(3,0,3) errors : -12507.02\n",
      " Regression with ARIMA(2,0,3) errors : -12506.61\n",
      " Regression with ARIMA(4,0,1) errors : -12508.71\n",
      " Regression with ARIMA(4,0,3) errors : -12506.62\n",
      " Regression with ARIMA(3,0,2) errors : -12453.39\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12508.55\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "[1] \"50 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12503.57\n",
      " Regression with ARIMA(0,0,0) errors : -8896.241\n",
      " Regression with ARIMA(1,0,0) errors : -12485.86\n",
      " Regression with ARIMA(0,0,1) errors : -10569.77\n",
      " Regression with ARIMA(0,0,0) errors : -7714.817\n",
      " Regression with ARIMA(1,0,2) errors : -12497.82\n",
      " Regression with ARIMA(2,0,1) errors : -12496.35\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12527.94\n",
      " Regression with ARIMA(1,0,3) errors : -12530.81\n",
      " Regression with ARIMA(0,0,3) errors : -11677.03\n",
      " Regression with ARIMA(1,0,4) errors : -12528.79\n",
      " Regression with ARIMA(0,0,2) errors : -11229.55\n",
      " Regression with ARIMA(0,0,4) errors : -12012.79\n",
      " Regression with ARIMA(2,0,4) errors : -12555.48\n",
      " Regression with ARIMA(3,0,4) errors : -12559.17\n",
      " Regression with ARIMA(3,0,3) errors : -12529.19\n",
      " Regression with ARIMA(4,0,4) errors : -12555.94\n",
      " Regression with ARIMA(3,0,5) errors : -12539.67\n",
      " Regression with ARIMA(2,0,5) errors : -12558.37\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -12560.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12499.29\n",
      " Regression with ARIMA(0,0,0) errors : -8896.211\n",
      " Regression with ARIMA(1,0,0) errors : -12479.6\n",
      " Regression with ARIMA(0,0,1) errors : -10569.06\n",
      " Regression with ARIMA(0,0,0) errors : -7726.249\n",
      " Regression with ARIMA(1,0,2) errors : -12491.43\n",
      " Regression with ARIMA(2,0,1) errors : -12490.08\n",
      " Regression with ARIMA(3,0,2) errors : -12549.65\n",
      " Regression with ARIMA(3,0,1) errors : -12505.95\n",
      " Regression with ARIMA(4,0,2) errors : -12523.02\n",
      " Regression with ARIMA(3,0,3) errors : -12522.73\n",
      " Regression with ARIMA(2,0,3) errors : -12520.84\n",
      " Regression with ARIMA(4,0,1) errors : -12524.79\n",
      " Regression with ARIMA(4,0,3) errors : -12548.68\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12521.78\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12522.71\n",
      " Regression with ARIMA(0,0,0) errors : -8912.717\n",
      " Regression with ARIMA(1,0,0) errors : -12499.7\n",
      " Regression with ARIMA(0,0,1) errors : -10598.43\n",
      " Regression with ARIMA(0,0,0) errors : -7791.064\n",
      " Regression with ARIMA(1,0,2) errors : -12511.99\n",
      " Regression with ARIMA(2,0,1) errors : -12511.69\n",
      " Regression with ARIMA(3,0,2) errors : -12565.33\n",
      " Regression with ARIMA(3,0,1) errors : -12529.16\n",
      " Regression with ARIMA(4,0,2) errors : -12545.66\n",
      " Regression with ARIMA(3,0,3) errors : -12545.28\n",
      " Regression with ARIMA(2,0,3) errors : -12543.96\n",
      " Regression with ARIMA(4,0,1) errors : -12547.58\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12526.08\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.95\n",
      " Regression with ARIMA(0,0,0) errors : -8942.089\n",
      " Regression with ARIMA(1,0,0) errors : -12527.3\n",
      " Regression with ARIMA(0,0,1) errors : -10625.79\n",
      " Regression with ARIMA(0,0,0) errors : -7815.365\n",
      " Regression with ARIMA(1,0,2) errors : -12539.1\n",
      " Regression with ARIMA(2,0,1) errors : -12537.44\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12568.26\n",
      " Regression with ARIMA(1,0,3) errors : -12570.63\n",
      " Regression with ARIMA(0,0,3) errors : -11727.96\n",
      " Regression with ARIMA(1,0,4) errors : -12568.62\n",
      " Regression with ARIMA(0,0,2) errors : -11285.05\n",
      " Regression with ARIMA(0,0,4) errors : -12063.02\n",
      " Regression with ARIMA(2,0,4) errors : -12594.01\n",
      " Regression with ARIMA(3,0,4) errors : -12602.32\n",
      " Regression with ARIMA(3,0,3) errors : -12568.74\n",
      " Regression with ARIMA(4,0,4) errors : -12567.01\n",
      " Regression with ARIMA(3,0,5) errors : -12578.76\n",
      " Regression with ARIMA(2,0,5) errors : -12598.99\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12467.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -12600.43\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12532.16\n",
      " Regression with ARIMA(0,0,0) errors : -8934.83\n",
      " Regression with ARIMA(1,0,0) errors : -12512.55\n",
      " Regression with ARIMA(0,0,1) errors : -10617.82\n",
      " Regression with ARIMA(0,0,0) errors : -7779.834\n",
      " Regression with ARIMA(1,0,2) errors : -12525.18\n",
      " Regression with ARIMA(2,0,1) errors : -12523.58\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12554.76\n",
      " Regression with ARIMA(1,0,3) errors : -12557.17\n",
      " Regression with ARIMA(0,0,3) errors : -11723.56\n",
      " Regression with ARIMA(1,0,4) errors : -12555.2\n",
      " Regression with ARIMA(0,0,2) errors : -11272.84\n",
      " Regression with ARIMA(0,0,4) errors : -12053.22\n",
      " Regression with ARIMA(2,0,4) errors : -12583\n",
      " Regression with ARIMA(3,0,4) errors : -12586.36\n",
      " Regression with ARIMA(3,0,3) errors : -12555.78\n",
      " Regression with ARIMA(4,0,4) errors : -12586.4\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12572.16\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12559.34\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,5) errors : -12569.81\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : -12587.09\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12509.71\n",
      " Regression with ARIMA(0,0,0) errors : -8923.006\n",
      " Regression with ARIMA(1,0,0) errors : -12490.06\n",
      " Regression with ARIMA(0,0,1) errors : -10606.06\n",
      " Regression with ARIMA(0,0,0) errors : -7778.001\n",
      " Regression with ARIMA(1,0,2) errors : -12503.3\n",
      " Regression with ARIMA(2,0,1) errors : -12501.4\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12532.82\n",
      " Regression with ARIMA(1,0,3) errors : -12535.75\n",
      " Regression with ARIMA(0,0,3) errors : -11707.59\n",
      " Regression with ARIMA(1,0,4) errors : -12533.75\n",
      " Regression with ARIMA(0,0,2) errors : -11261.54\n",
      " Regression with ARIMA(0,0,4) errors : -12037.84\n",
      " Regression with ARIMA(2,0,4) errors : -12562.35\n",
      " Regression with ARIMA(3,0,4) errors : -12563.64\n",
      " Regression with ARIMA(3,0,3) errors : -12534.12\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12540.3\n",
      " Regression with ARIMA(2,0,5) errors : -12565.8\n",
      " Regression with ARIMA(1,0,5) errors : -12534.53\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12565.48\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12497.83\n",
      " Regression with ARIMA(0,0,0) errors : -8905.257\n",
      " Regression with ARIMA(1,0,0) errors : -12479.66\n",
      " Regression with ARIMA(0,0,1) errors : -10592.39\n",
      " Regression with ARIMA(0,0,0) errors : -7770.197\n",
      " Regression with ARIMA(1,0,2) errors : -12491.59\n",
      " Regression with ARIMA(2,0,1) errors : -12491.59\n",
      " Regression with ARIMA(3,0,2) errors : -12541.44\n",
      " Regression with ARIMA(3,0,1) errors : -12505.67\n",
      " Regression with ARIMA(4,0,2) errors : -12524.33\n",
      " Regression with ARIMA(3,0,3) errors : -12524.65\n",
      " Regression with ARIMA(2,0,3) errors : -12523.33\n",
      " Regression with ARIMA(4,0,1) errors : -12525.8\n",
      " Regression with ARIMA(4,0,3) errors : -12554.64\n",
      " Regression with ARIMA(5,0,3) errors : -12551.24\n",
      " Regression with ARIMA(4,0,4) errors : -12549.94\n",
      " Regression with ARIMA(3,0,4) errors : -12553.02\n",
      " Regression with ARIMA(5,0,2) errors : -12548.7\n",
      " Regression with ARIMA(5,0,4) errors : -12528.29\n",
      " Regression with ARIMA(4,0,3) errors : -12482.77\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12554.1\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12497.83\n",
      " Regression with ARIMA(0,0,0) errors : -8898.064\n",
      " Regression with ARIMA(1,0,0) errors : -12477.67\n",
      " Regression with ARIMA(0,0,1) errors : -10586.17\n",
      " Regression with ARIMA(0,0,0) errors : -7763.444\n",
      " Regression with ARIMA(1,0,2) errors : -12489.24\n",
      " Regression with ARIMA(2,0,1) errors : -12490.62\n",
      " Regression with ARIMA(3,0,2) errors : -12555.3\n",
      " Regression with ARIMA(3,0,1) errors : -12503.83\n",
      " Regression with ARIMA(4,0,2) errors : -12522.97\n",
      " Regression with ARIMA(3,0,3) errors : -12522.77\n",
      " Regression with ARIMA(2,0,3) errors : -12522.46\n",
      " Regression with ARIMA(4,0,1) errors : -12524.5\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12474.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12523.61\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12513.83\n",
      " Regression with ARIMA(0,0,0) errors : -8943.164\n",
      " Regression with ARIMA(1,0,0) errors : -12488.42\n",
      " Regression with ARIMA(0,0,1) errors : -10621.1\n",
      " Regression with ARIMA(0,0,0) errors : -7868.129\n",
      " Regression with ARIMA(1,0,2) errors : -12499.53\n",
      " Regression with ARIMA(2,0,1) errors : -12510\n",
      " Regression with ARIMA(3,0,2) errors : -12538.21\n",
      " Regression with ARIMA(3,0,1) errors : -12522.06\n",
      " Regression with ARIMA(4,0,2) errors : -12545.22\n",
      " Regression with ARIMA(4,0,1) errors : -12546.86\n",
      " Regression with ARIMA(4,0,0) errors : -12546.27\n",
      " Regression with ARIMA(5,0,1) errors : -12549.63\n",
      " Regression with ARIMA(5,0,0) errors : -12550.19\n",
      " Regression with ARIMA(5,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,0) errors : -12530.49\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12537.41\n",
      " Regression with ARIMA(0,0,0) errors : -8980.404\n",
      " Regression with ARIMA(1,0,0) errors : -12515.87\n",
      " Regression with ARIMA(0,0,1) errors : -10652.29\n",
      " Regression with ARIMA(0,0,0) errors : -7878.327\n",
      " Regression with ARIMA(1,0,2) errors : -12530.48\n",
      " Regression with ARIMA(2,0,1) errors : -12528.68\n",
      " Regression with ARIMA(3,0,2) errors : -12554.48\n",
      " Regression with ARIMA(3,0,1) errors : -12543.44\n",
      " Regression with ARIMA(4,0,2) errors : -12559.77\n",
      " Regression with ARIMA(4,0,1) errors : -12561.17\n",
      " Regression with ARIMA(4,0,0) errors : -12562.64\n",
      " Regression with ARIMA(3,0,0) errors : -12534.45\n",
      " Regression with ARIMA(5,0,0) errors : -12560.32\n",
      " Regression with ARIMA(5,0,1) errors : -12583.89\n",
      " Regression with ARIMA(5,0,2) errors : -12582.7\n",
      " Regression with ARIMA(5,0,1) errors : -12494.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12584.44\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.24\n",
      " Regression with ARIMA(0,0,0) errors : -8985.481\n",
      " Regression with ARIMA(1,0,0) errors : -12523.97\n",
      " Regression with ARIMA(0,0,1) errors : -10655.97\n",
      " Regression with ARIMA(0,0,0) errors : -7884.878\n",
      " Regression with ARIMA(1,0,2) errors : -12538.88\n",
      " Regression with ARIMA(2,0,1) errors : -12537.23\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12566.95\n",
      " Regression with ARIMA(1,0,3) errors : -12569.82\n",
      " Regression with ARIMA(0,0,3) errors : -11754.84\n",
      " Regression with ARIMA(1,0,4) errors : -12567.97\n",
      " Regression with ARIMA(0,0,2) errors : -11299.19\n",
      " Regression with ARIMA(0,0,4) errors : -12073.38\n",
      " Regression with ARIMA(2,0,4) errors : -12592.97\n",
      " Regression with ARIMA(3,0,4) errors : -12597.31\n",
      " Regression with ARIMA(3,0,3) errors : -12567.29\n",
      " Regression with ARIMA(4,0,4) errors : -12596.6\n",
      " Regression with ARIMA(3,0,5) errors : -12570.58\n",
      " Regression with ARIMA(2,0,5) errors : -12597.68\n",
      " Regression with ARIMA(1,0,5) errors : -12568.02\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12597.69\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12546.78\n",
      " Regression with ARIMA(0,0,0) errors : -8970.223\n",
      " Regression with ARIMA(1,0,0) errors : -12525.95\n",
      " Regression with ARIMA(0,0,1) errors : -10649.53\n",
      " Regression with ARIMA(0,0,0) errors : -7878.626\n",
      " Regression with ARIMA(1,0,2) errors : -12540.83\n",
      " Regression with ARIMA(2,0,1) errors : -12539.25\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12568.27\n",
      " Regression with ARIMA(1,0,3) errors : -12571.19\n",
      " Regression with ARIMA(0,0,3) errors : -11751.13\n",
      " Regression with ARIMA(1,0,4) errors : -12569.31\n",
      " Regression with ARIMA(0,0,2) errors : -11296.38\n",
      " Regression with ARIMA(0,0,4) errors : -12067\n",
      " Regression with ARIMA(2,0,4) errors : -12594.34\n",
      " Regression with ARIMA(3,0,4) errors : -12595.54\n",
      " Regression with ARIMA(3,0,3) errors : -12568.5\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12574.84\n",
      " Regression with ARIMA(2,0,5) errors : -12598.8\n",
      " Regression with ARIMA(1,0,5) errors : -12569.08\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12597.59\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.79\n",
      " Regression with ARIMA(0,0,0) errors : -8964.909\n",
      " Regression with ARIMA(1,0,0) errors : -12525.68\n",
      " Regression with ARIMA(0,0,1) errors : -10646.25\n",
      " Regression with ARIMA(0,0,0) errors : -7885.222\n",
      " Regression with ARIMA(1,0,2) errors : -12540.83\n",
      " Regression with ARIMA(2,0,1) errors : -12539.59\n",
      " Regression with ARIMA(3,0,2) errors : -12603.07\n",
      " Regression with ARIMA(3,0,1) errors : -12554.12\n",
      " Regression with ARIMA(4,0,2) errors : -12569.57\n",
      " Regression with ARIMA(3,0,3) errors : -12569.71\n",
      " Regression with ARIMA(2,0,3) errors : -12568.45\n",
      " Regression with ARIMA(4,0,1) errors : -12570.93\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12494.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12570.9\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12548.69\n",
      " Regression with ARIMA(0,0,0) errors : -8959.862\n",
      " Regression with ARIMA(1,0,0) errors : -12529.05\n",
      " Regression with ARIMA(0,0,1) errors : -10643.71\n",
      " Regression with ARIMA(0,0,0) errors : -7886.635\n",
      " Regression with ARIMA(1,0,2) errors : -12544.11\n",
      " Regression with ARIMA(2,0,1) errors : -12544.13\n",
      " Regression with ARIMA(3,0,2) errors : -12571.06\n",
      " Regression with ARIMA(3,0,1) errors : -12561.51\n",
      " Regression with ARIMA(4,0,2) errors : -12576.07\n",
      " Regression with ARIMA(4,0,1) errors : -12578.07\n",
      " Regression with ARIMA(4,0,0) errors : -12579.62\n",
      " Regression with ARIMA(3,0,0) errors : -12551.25\n",
      " Regression with ARIMA(5,0,0) errors : -12579.64\n",
      " Regression with ARIMA(5,0,1) errors : Inf\n",
      " Regression with ARIMA(5,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,0) errors : -12575.23\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12551.97\n",
      " Regression with ARIMA(0,0,0) errors : -8967.683\n",
      " Regression with ARIMA(1,0,0) errors : -12529.69\n",
      " Regression with ARIMA(0,0,1) errors : -10653.67\n",
      " Regression with ARIMA(0,0,0) errors : -7896.484\n",
      " Regression with ARIMA(1,0,2) errors : -12544.97\n",
      " Regression with ARIMA(2,0,1) errors : -12543.7\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12573.37\n",
      " Regression with ARIMA(1,0,3) errors : -12575.68\n",
      " Regression with ARIMA(0,0,3) errors : -11753.95\n",
      " Regression with ARIMA(1,0,4) errors : -12573.8\n",
      " Regression with ARIMA(0,0,2) errors : -11300.67\n",
      " Regression with ARIMA(0,0,4) errors : -12074.69\n",
      " Regression with ARIMA(2,0,4) errors : -12591.45\n",
      " Regression with ARIMA(3,0,4) errors : -12595.99\n",
      " Regression with ARIMA(3,0,3) errors : -12573.8\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12580.86\n",
      " Regression with ARIMA(2,0,5) errors : -12597\n",
      " Regression with ARIMA(1,0,5) errors : -12573.86\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12603.04\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12556.25\n",
      " Regression with ARIMA(0,0,0) errors : -8962.755\n",
      " Regression with ARIMA(1,0,0) errors : -12535.8\n",
      " Regression with ARIMA(0,0,1) errors : -10648.64\n",
      " Regression with ARIMA(0,0,0) errors : -7898.839\n",
      " Regression with ARIMA(1,0,2) errors : -12550.14\n",
      " Regression with ARIMA(2,0,1) errors : -12548.54\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12578.72\n",
      " Regression with ARIMA(1,0,3) errors : -12581.63\n",
      " Regression with ARIMA(0,0,3) errors : -11752.88\n",
      " Regression with ARIMA(1,0,4) errors : -12579.7\n",
      " Regression with ARIMA(0,0,2) errors : -11299.22\n",
      " Regression with ARIMA(0,0,4) errors : -12072.91\n",
      " Regression with ARIMA(2,0,4) errors : -12605.06\n",
      " Regression with ARIMA(3,0,4) errors : -12603.2\n",
      " Regression with ARIMA(2,0,5) errors : -12609.26\n",
      " Regression with ARIMA(1,0,5) errors : -12579.72\n",
      " Regression with ARIMA(3,0,5) errors : -12582.04\n",
      " Regression with ARIMA(2,0,5) errors : -12540.55\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12607.82\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12570.6\n",
      " Regression with ARIMA(0,0,0) errors : -8967.56\n",
      " Regression with ARIMA(1,0,0) errors : -12549.25\n",
      " Regression with ARIMA(0,0,1) errors : -10654.34\n",
      " Regression with ARIMA(0,0,0) errors : -7906.854\n",
      " Regression with ARIMA(1,0,2) errors : -12564.03\n",
      " Regression with ARIMA(2,0,1) errors : -12563.91\n",
      " Regression with ARIMA(3,0,2) errors : -12627.87\n",
      " Regression with ARIMA(3,0,1) errors : -12577.27\n",
      " Regression with ARIMA(4,0,2) errors : -12593.34\n",
      " Regression with ARIMA(3,0,3) errors : -12593.82\n",
      " Regression with ARIMA(2,0,3) errors : -12593.22\n",
      " Regression with ARIMA(4,0,1) errors : -12594.72\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12522.09\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12594.39\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12576.56\n",
      " Regression with ARIMA(0,0,0) errors : -8968.532\n",
      " Regression with ARIMA(1,0,0) errors : -12555.14\n",
      " Regression with ARIMA(0,0,1) errors : -10657.19\n",
      " Regression with ARIMA(0,0,0) errors : -7936.331\n",
      " Regression with ARIMA(1,0,2) errors : -12569.91\n",
      " Regression with ARIMA(2,0,1) errors : -12570.88\n",
      " Regression with ARIMA(3,0,2) errors : -12594.83\n",
      " Regression with ARIMA(3,0,1) errors : -12583.62\n",
      " Regression with ARIMA(4,0,2) errors : -12601.21\n",
      " Regression with ARIMA(4,0,1) errors : -12602.62\n",
      " Regression with ARIMA(4,0,0) errors : -12603.98\n",
      " Regression with ARIMA(3,0,0) errors : -12574.44\n",
      " Regression with ARIMA(5,0,0) errors : -12601.82\n",
      " Regression with ARIMA(5,0,1) errors : -12626.33\n",
      " Regression with ARIMA(5,0,2) errors : -12625.22\n",
      " Regression with ARIMA(5,0,1) errors : -12547.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12620.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12601.85\n",
      " Regression with ARIMA(0,0,0) errors : -9048.224\n",
      " Regression with ARIMA(1,0,0) errors : -12582.93\n",
      " Regression with ARIMA(0,0,1) errors : -10732.82\n",
      " Regression with ARIMA(0,0,0) errors : -8067.123\n",
      " Regression with ARIMA(1,0,2) errors : -12598.44\n",
      " Regression with ARIMA(2,0,1) errors : -12601.12\n",
      " Regression with ARIMA(3,0,2) errors : -12619.05\n",
      " Regression with ARIMA(3,0,1) errors : -12618.74\n",
      " Regression with ARIMA(4,0,2) errors : -12650.56\n",
      " Regression with ARIMA(4,0,1) errors : -12652.27\n",
      " Regression with ARIMA(4,0,0) errors : -12652.06\n",
      " Regression with ARIMA(5,0,1) errors : -12662.55\n",
      " Regression with ARIMA(5,0,0) errors : -12658.45\n",
      " Regression with ARIMA(5,0,2) errors : -12663.08\n",
      " Regression with ARIMA(5,0,3) errors : -12661.14\n",
      " Regression with ARIMA(4,0,3) errors : -12649.44\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -12652.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12607.62\n",
      " Regression with ARIMA(0,0,0) errors : -9029.222\n",
      " Regression with ARIMA(1,0,0) errors : -12581.78\n",
      " Regression with ARIMA(0,0,1) errors : -10679.8\n",
      " Regression with ARIMA(0,0,0) errors : -7988.616\n",
      " Regression with ARIMA(1,0,2) errors : -12606.76\n",
      " Regression with ARIMA(2,0,1) errors : -12606.03\n",
      " Regression with ARIMA(3,0,2) errors : -12633.3\n",
      " Regression with ARIMA(3,0,1) errors : -12616.63\n",
      " Regression with ARIMA(4,0,2) errors : -12637.18\n",
      " Regression with ARIMA(4,0,1) errors : -12639.14\n",
      " Regression with ARIMA(4,0,0) errors : -12638.63\n",
      " Regression with ARIMA(5,0,1) errors : -12657.77\n",
      " Regression with ARIMA(5,0,0) errors : -12639.34\n",
      " Regression with ARIMA(5,0,2) errors : -12656.11\n",
      " Regression with ARIMA(5,0,1) errors : -12576.93\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12665.38\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12515.14\n",
      " Regression with ARIMA(0,1,0) errors : -12443.47\n",
      " Regression with ARIMA(1,1,0) errors : -12487.68\n",
      " Regression with ARIMA(0,1,1) errors : -12495.53\n",
      " Regression with ARIMA(0,1,0) errors : -12445.47\n",
      " Regression with ARIMA(1,1,2) errors : -12499.79\n",
      " Regression with ARIMA(2,1,1) errors : -12505.72\n",
      " Regression with ARIMA(3,1,2) errors : -12545.83\n",
      " Regression with ARIMA(3,1,1) errors : -12512.71\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -12547.75\n",
      " Regression with ARIMA(2,1,2) errors : -12517.15\n",
      " Regression with ARIMA(3,1,1) errors : -12514.72\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -12507.73\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12527.28\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12606.67\n",
      " Regression with ARIMA(0,0,0) errors : -9078.123\n",
      " Regression with ARIMA(1,0,0) errors : -12575.25\n",
      " Regression with ARIMA(0,0,1) errors : -10725.64\n",
      " Regression with ARIMA(0,0,0) errors : -8063.193\n",
      " Regression with ARIMA(1,0,2) errors : -12597.15\n",
      " Regression with ARIMA(2,0,1) errors : -12601.19\n",
      " Regression with ARIMA(3,0,2) errors : -12625.54\n",
      " Regression with ARIMA(3,0,1) errors : -12611.94\n",
      " Regression with ARIMA(4,0,2) errors : -12627.49\n",
      " Regression with ARIMA(4,0,1) errors : -12627.75\n",
      " Regression with ARIMA(4,0,0) errors : -12627.47\n",
      " Regression with ARIMA(5,0,1) errors : -12646.75\n",
      " Regression with ARIMA(5,0,0) errors : -12630.02\n",
      " Regression with ARIMA(5,0,2) errors : -12645.2\n",
      " Regression with ARIMA(5,0,1) errors : -12548.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12650.4\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12592.63\n",
      " Regression with ARIMA(0,0,0) errors : -9082.048\n",
      " Regression with ARIMA(1,0,0) errors : -12566.66\n",
      " Regression with ARIMA(0,0,1) errors : -10726.09\n",
      " Regression with ARIMA(0,0,0) errors : -8059.077\n",
      " Regression with ARIMA(1,0,2) errors : -12588.96\n",
      " Regression with ARIMA(2,0,1) errors : -12589.11\n",
      " Regression with ARIMA(3,0,2) errors : -12638.23\n",
      " Regression with ARIMA(3,0,1) errors : -12600.16\n",
      " Regression with ARIMA(4,0,2) errors : -12617.62\n",
      " Regression with ARIMA(3,0,3) errors : -12618.48\n",
      " Regression with ARIMA(2,0,3) errors : -12614.14\n",
      " Regression with ARIMA(4,0,1) errors : -12616.7\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12548.15\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12652.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12584\n",
      " Regression with ARIMA(0,0,0) errors : -9072.623\n",
      " Regression with ARIMA(1,0,0) errors : -12558.92\n",
      " Regression with ARIMA(0,0,1) errors : -10724.45\n",
      " Regression with ARIMA(0,0,0) errors : -8059.797\n",
      " Regression with ARIMA(1,0,2) errors : -12579.62\n",
      " Regression with ARIMA(2,0,1) errors : -12579.45\n",
      " Regression with ARIMA(3,0,2) errors : -12637.15\n",
      " Regression with ARIMA(3,0,1) errors : -12590.09\n",
      " Regression with ARIMA(4,0,2) errors : -12609.14\n",
      " Regression with ARIMA(3,0,3) errors : -12608.81\n",
      " Regression with ARIMA(2,0,3) errors : -12605.33\n",
      " Regression with ARIMA(4,0,1) errors : -12609.45\n",
      " Regression with ARIMA(4,0,3) errors : -12638.04\n",
      " Regression with ARIMA(5,0,3) errors : -12624.89\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12633.6\n",
      " Regression with ARIMA(5,0,2) errors : -12623.44\n",
      " Regression with ARIMA(5,0,4) errors : -12618.15\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12645.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "[1] \"60 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12597.56\n",
      " Regression with ARIMA(0,0,0) errors : -9087.133\n",
      " Regression with ARIMA(1,0,0) errors : -12572.15\n",
      " Regression with ARIMA(0,0,1) errors : -10736.93\n",
      " Regression with ARIMA(0,0,0) errors : -8079.117\n",
      " Regression with ARIMA(1,0,2) errors : -12594.14\n",
      " Regression with ARIMA(2,0,1) errors : -12593.03\n",
      " Regression with ARIMA(3,0,2) errors : -12658.36\n",
      " Regression with ARIMA(3,0,1) errors : -12603.77\n",
      " Regression with ARIMA(4,0,2) errors : -12622.07\n",
      " Regression with ARIMA(3,0,3) errors : -12622.59\n",
      " Regression with ARIMA(2,0,3) errors : -12619.12\n",
      " Regression with ARIMA(4,0,1) errors : -12620.82\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12548.61\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12655.81\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12610.85\n",
      " Regression with ARIMA(0,0,0) errors : -9095.509\n",
      " Regression with ARIMA(1,0,0) errors : -12584.86\n",
      " Regression with ARIMA(0,0,1) errors : -10749.33\n",
      " Regression with ARIMA(0,0,0) errors : -8097.852\n",
      " Regression with ARIMA(1,0,2) errors : -12606.97\n",
      " Regression with ARIMA(2,0,1) errors : -12608.39\n",
      " Regression with ARIMA(3,0,2) errors : -12658.34\n",
      " Regression with ARIMA(3,0,1) errors : -12619.38\n",
      " Regression with ARIMA(4,0,2) errors : -12636.67\n",
      " Regression with ARIMA(3,0,3) errors : -12637.2\n",
      " Regression with ARIMA(2,0,3) errors : -12634.49\n",
      " Regression with ARIMA(4,0,1) errors : -12636.79\n",
      " Regression with ARIMA(4,0,3) errors : -12679.01\n",
      " Regression with ARIMA(5,0,3) errors : -12665.31\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12669.72\n",
      " Regression with ARIMA(5,0,2) errors : -12665.96\n",
      " Regression with ARIMA(5,0,4) errors : -12644.1\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12661.83\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.42\n",
      " Regression with ARIMA(0,0,0) errors : -9117.955\n",
      " Regression with ARIMA(1,0,0) errors : -12604.61\n",
      " Regression with ARIMA(0,0,1) errors : -10769.78\n",
      " Regression with ARIMA(0,0,0) errors : -8106.906\n",
      " Regression with ARIMA(1,0,2) errors : -12626.91\n",
      " Regression with ARIMA(2,0,1) errors : -12625.67\n",
      " Regression with ARIMA(3,0,2) errors : -12690.09\n",
      " Regression with ARIMA(3,0,1) errors : -12637.43\n",
      " Regression with ARIMA(4,0,2) errors : -12655.81\n",
      " Regression with ARIMA(3,0,3) errors : -12655.49\n",
      " Regression with ARIMA(2,0,3) errors : -12652.79\n",
      " Regression with ARIMA(4,0,1) errors : -12654.8\n",
      " Regression with ARIMA(4,0,3) errors : -12693.24\n",
      " Regression with ARIMA(5,0,3) errors : -12662.02\n",
      " Regression with ARIMA(4,0,4) errors : -12671.03\n",
      " Regression with ARIMA(3,0,4) errors : -12677.48\n",
      " Regression with ARIMA(5,0,2) errors : -12662.99\n",
      " Regression with ARIMA(5,0,4) errors : -12675.56\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12692.59\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12641.13\n",
      " Regression with ARIMA(0,0,0) errors : -9120.512\n",
      " Regression with ARIMA(1,0,0) errors : -12614.69\n",
      " Regression with ARIMA(0,0,1) errors : -10777.29\n",
      " Regression with ARIMA(0,0,0) errors : -8113.97\n",
      " Regression with ARIMA(1,0,2) errors : -12636.3\n",
      " Regression with ARIMA(2,0,1) errors : -12634.97\n",
      " Regression with ARIMA(3,0,2) errors : -12703.57\n",
      " Regression with ARIMA(3,0,1) errors : -12648.05\n",
      " Regression with ARIMA(4,0,2) errors : -12667.51\n",
      " Regression with ARIMA(3,0,3) errors : -12666.81\n",
      " Regression with ARIMA(2,0,3) errors : -12663.2\n",
      " Regression with ARIMA(4,0,1) errors : -12665.98\n",
      " Regression with ARIMA(4,0,3) errors : -12703.17\n",
      " Regression with ARIMA(3,0,2) errors : -12608.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.93\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12643.6\n",
      " Regression with ARIMA(0,0,0) errors : -9119.216\n",
      " Regression with ARIMA(1,0,0) errors : -12616.26\n",
      " Regression with ARIMA(0,0,1) errors : -10777.52\n",
      " Regression with ARIMA(0,0,0) errors : -8101.041\n",
      " Regression with ARIMA(1,0,2) errors : -12637.47\n",
      " Regression with ARIMA(2,0,1) errors : -12640.52\n",
      " Regression with ARIMA(3,0,2) errors : -12680.71\n",
      " Regression with ARIMA(3,0,1) errors : -12652.57\n",
      " Regression with ARIMA(4,0,2) errors : -12672.29\n",
      " Regression with ARIMA(3,0,3) errors : -12671.04\n",
      " Regression with ARIMA(2,0,3) errors : -12668.46\n",
      " Regression with ARIMA(4,0,1) errors : -12671.99\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12605.13\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12704.4\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12641.82\n",
      " Regression with ARIMA(0,0,0) errors : -9125.129\n",
      " Regression with ARIMA(1,0,0) errors : -12617.13\n",
      " Regression with ARIMA(0,0,1) errors : -10783.88\n",
      " Regression with ARIMA(0,0,0) errors : -8122.685\n",
      " Regression with ARIMA(1,0,2) errors : -12638.09\n",
      " Regression with ARIMA(2,0,1) errors : -12636.93\n",
      " Regression with ARIMA(3,0,2) errors : -12695.39\n",
      " Regression with ARIMA(3,0,1) errors : -12649.51\n",
      " Regression with ARIMA(4,0,2) errors : -12667.03\n",
      " Regression with ARIMA(3,0,3) errors : -12667.49\n",
      " Regression with ARIMA(2,0,3) errors : -12664.06\n",
      " Regression with ARIMA(4,0,1) errors : -12666.82\n",
      " Regression with ARIMA(4,0,3) errors : -12707.83\n",
      " Regression with ARIMA(5,0,3) errors : -12686.77\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12686.56\n",
      " Regression with ARIMA(5,0,2) errors : -12685.94\n",
      " Regression with ARIMA(5,0,4) errors : -12670.08\n",
      " Regression with ARIMA(4,0,3) errors : -12637.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12704.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12640.83\n",
      " Regression with ARIMA(0,0,0) errors : -9124.201\n",
      " Regression with ARIMA(1,0,0) errors : -12614.79\n",
      " Regression with ARIMA(0,0,1) errors : -10783.44\n",
      " Regression with ARIMA(0,0,0) errors : -8122.209\n",
      " Regression with ARIMA(1,0,2) errors : -12635.64\n",
      " Regression with ARIMA(2,0,1) errors : -12634.86\n",
      " Regression with ARIMA(3,0,2) errors : -12695.41\n",
      " Regression with ARIMA(3,0,1) errors : -12647.57\n",
      " Regression with ARIMA(4,0,2) errors : -12665.91\n",
      " Regression with ARIMA(3,0,3) errors : -12665.62\n",
      " Regression with ARIMA(2,0,3) errors : -12662.3\n",
      " Regression with ARIMA(4,0,1) errors : -12664.73\n",
      " Regression with ARIMA(4,0,3) errors : -12708.36\n",
      " Regression with ARIMA(5,0,3) errors : -12683.74\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12676.17\n",
      " Regression with ARIMA(4,0,3) errors : -12636.53\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12702.9\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.35\n",
      " Regression with ARIMA(0,0,0) errors : -9121.854\n",
      " Regression with ARIMA(1,0,0) errors : -12613.51\n",
      " Regression with ARIMA(0,0,1) errors : -10782.18\n",
      " Regression with ARIMA(0,0,0) errors : -8117.61\n",
      " Regression with ARIMA(1,0,2) errors : -12633.27\n",
      " Regression with ARIMA(2,0,1) errors : -12632.06\n",
      " Regression with ARIMA(3,0,2) errors : -12698.45\n",
      " Regression with ARIMA(3,0,1) errors : -12643.7\n",
      " Regression with ARIMA(4,0,2) errors : -12660.83\n",
      " Regression with ARIMA(3,0,3) errors : -12661.66\n",
      " Regression with ARIMA(2,0,3) errors : -12658.11\n",
      " Regression with ARIMA(4,0,1) errors : -12659.62\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12597.25\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12700.82\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.09\n",
      " Regression with ARIMA(0,0,0) errors : -9116.676\n",
      " Regression with ARIMA(1,0,0) errors : -12611.67\n",
      " Regression with ARIMA(0,0,1) errors : -10780.74\n",
      " Regression with ARIMA(0,0,0) errors : -8116.581\n",
      " Regression with ARIMA(1,0,2) errors : -12630.99\n",
      " Regression with ARIMA(2,0,1) errors : -12629.63\n",
      " Regression with ARIMA(3,0,2) errors : -12699.18\n",
      " Regression with ARIMA(3,0,1) errors : -12641.18\n",
      " Regression with ARIMA(4,0,2) errors : -12658.75\n",
      " Regression with ARIMA(3,0,3) errors : -12659.44\n",
      " Regression with ARIMA(2,0,3) errors : -12655.65\n",
      " Regression with ARIMA(4,0,1) errors : -12657.53\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12615.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12699.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12639.03\n",
      " Regression with ARIMA(0,0,0) errors : -9117.537\n",
      " Regression with ARIMA(1,0,0) errors : -12615.18\n",
      " Regression with ARIMA(0,0,1) errors : -10783.7\n",
      " Regression with ARIMA(0,0,0) errors : -8118.136\n",
      " Regression with ARIMA(1,0,2) errors : -12634.65\n",
      " Regression with ARIMA(2,0,1) errors : -12633.24\n",
      " Regression with ARIMA(3,0,2) errors : -12699.98\n",
      " Regression with ARIMA(3,0,1) errors : -12645.33\n",
      " Regression with ARIMA(4,0,2) errors : -12662.46\n",
      " Regression with ARIMA(3,0,3) errors : -12663.29\n",
      " Regression with ARIMA(2,0,3) errors : -12659.28\n",
      " Regression with ARIMA(4,0,1) errors : -12661.46\n",
      " Regression with ARIMA(4,0,3) errors : -12704.33\n",
      " Regression with ARIMA(5,0,3) errors : -12680.72\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12676.03\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12672.54\n",
      " Regression with ARIMA(4,0,3) errors : -12599.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12703.36\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.78\n",
      " Regression with ARIMA(0,0,0) errors : -9113.603\n",
      " Regression with ARIMA(1,0,0) errors : -12610.36\n",
      " Regression with ARIMA(0,0,1) errors : -10781.97\n",
      " Regression with ARIMA(0,0,0) errors : -8111.354\n",
      " Regression with ARIMA(1,0,2) errors : -12629.21\n",
      " Regression with ARIMA(2,0,1) errors : -12627.93\n",
      " Regression with ARIMA(3,0,2) errors : -12693.18\n",
      " Regression with ARIMA(3,0,1) errors : -12639.63\n",
      " Regression with ARIMA(4,0,2) errors : -12657.34\n",
      " Regression with ARIMA(3,0,3) errors : -12657.78\n",
      " Regression with ARIMA(2,0,3) errors : -12654.23\n",
      " Regression with ARIMA(4,0,1) errors : -12656.4\n",
      " Regression with ARIMA(4,0,3) errors : -12699.31\n",
      " Regression with ARIMA(5,0,3) errors : -12674.55\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12675.54\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12667.95\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.07\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.46\n",
      " Regression with ARIMA(0,0,0) errors : -9119.245\n",
      " Regression with ARIMA(1,0,0) errors : -12613.96\n",
      " Regression with ARIMA(0,0,1) errors : -10785.81\n",
      " Regression with ARIMA(0,0,0) errors : -8116.382\n",
      " Regression with ARIMA(1,0,2) errors : -12632.76\n",
      " Regression with ARIMA(2,0,1) errors : -12631.28\n",
      " Regression with ARIMA(3,0,2) errors : -12700.56\n",
      " Regression with ARIMA(3,0,1) errors : -12643.51\n",
      " Regression with ARIMA(4,0,2) errors : -12660.35\n",
      " Regression with ARIMA(3,0,3) errors : -12660.75\n",
      " Regression with ARIMA(2,0,3) errors : -12657.34\n",
      " Regression with ARIMA(4,0,1) errors : -12659.28\n",
      " Regression with ARIMA(4,0,3) errors : -12705.25\n",
      " Regression with ARIMA(5,0,3) errors : -12677.25\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12659.26\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12674.2\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12701.28\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.91\n",
      " Regression with ARIMA(0,0,0) errors : -9115.346\n",
      " Regression with ARIMA(1,0,0) errors : -12609.25\n",
      " Regression with ARIMA(0,0,1) errors : -10783.59\n",
      " Regression with ARIMA(0,0,0) errors : -8119.022\n",
      " Regression with ARIMA(1,0,2) errors : -12628.07\n",
      " Regression with ARIMA(2,0,1) errors : -12626.55\n",
      " Regression with ARIMA(3,0,2) errors : -12695.08\n",
      " Regression with ARIMA(3,0,1) errors : -12639.09\n",
      " Regression with ARIMA(4,0,2) errors : -12655.57\n",
      " Regression with ARIMA(3,0,3) errors : -12655.97\n",
      " Regression with ARIMA(2,0,3) errors : -12652.64\n",
      " Regression with ARIMA(4,0,1) errors : -12654.48\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12608.86\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12697.61\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12634.77\n",
      " Regression with ARIMA(0,0,0) errors : -9112.722\n",
      " Regression with ARIMA(1,0,0) errors : -12611.67\n",
      " Regression with ARIMA(0,0,1) errors : -10782.69\n",
      " Regression with ARIMA(0,0,0) errors : -8118.407\n",
      " Regression with ARIMA(1,0,2) errors : -12630.3\n",
      " Regression with ARIMA(2,0,1) errors : -12628.79\n",
      " Regression with ARIMA(3,0,2) errors : -12698.97\n",
      " Regression with ARIMA(3,0,1) errors : -12640.78\n",
      " Regression with ARIMA(4,0,2) errors : -12656.92\n",
      " Regression with ARIMA(3,0,3) errors : -12657.7\n",
      " Regression with ARIMA(2,0,3) errors : -12654.48\n",
      " Regression with ARIMA(4,0,1) errors : -12655.94\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12604.1\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12699.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.36\n",
      " Regression with ARIMA(0,0,0) errors : -9119.25\n",
      " Regression with ARIMA(1,0,0) errors : -12613.66\n",
      " Regression with ARIMA(0,0,1) errors : -10784.04\n",
      " Regression with ARIMA(0,0,0) errors : -8121.82\n",
      " Regression with ARIMA(1,0,2) errors : -12632.84\n",
      " Regression with ARIMA(2,0,1) errors : -12631.38\n",
      " Regression with ARIMA(3,0,2) errors : -12686.69\n",
      " Regression with ARIMA(3,0,1) errors : -12643.65\n",
      " Regression with ARIMA(4,0,2) errors : -12661.74\n",
      " Regression with ARIMA(3,0,3) errors : -12661.05\n",
      " Regression with ARIMA(2,0,3) errors : -12657.15\n",
      " Regression with ARIMA(4,0,1) errors : -12661.45\n",
      " Regression with ARIMA(4,0,3) errors : -12661.55\n",
      " Regression with ARIMA(3,0,2) errors : -12592.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.86\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.03\n",
      " Regression with ARIMA(0,0,0) errors : -9124.803\n",
      " Regression with ARIMA(1,0,0) errors : -12611.58\n",
      " Regression with ARIMA(0,0,1) errors : -10785.79\n",
      " Regression with ARIMA(0,0,0) errors : -8120.735\n",
      " Regression with ARIMA(1,0,2) errors : -12631.26\n",
      " Regression with ARIMA(2,0,1) errors : -12629.83\n",
      " Regression with ARIMA(3,0,2) errors : -12695.7\n",
      " Regression with ARIMA(3,0,1) errors : -12642.68\n",
      " Regression with ARIMA(4,0,2) errors : -12659.94\n",
      " Regression with ARIMA(3,0,3) errors : -12660.68\n",
      " Regression with ARIMA(2,0,3) errors : -12655.54\n",
      " Regression with ARIMA(4,0,1) errors : -12658.46\n",
      " Regression with ARIMA(4,0,3) errors : -12702.36\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12659.16\n",
      " Regression with ARIMA(5,0,2) errors : -12657.49\n",
      " Regression with ARIMA(5,0,4) errors : -12659.7\n",
      " Regression with ARIMA(4,0,3) errors : -12584.34\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.35\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12639.64\n",
      " Regression with ARIMA(0,0,0) errors : -9126.097\n",
      " Regression with ARIMA(1,0,0) errors : -12614.91\n",
      " Regression with ARIMA(0,0,1) errors : -10785.02\n",
      " Regression with ARIMA(0,0,0) errors : -8116.995\n",
      " Regression with ARIMA(1,0,2) errors : -12635.07\n",
      " Regression with ARIMA(2,0,1) errors : -12633.58\n",
      " Regression with ARIMA(3,0,2) errors : -12700.58\n",
      " Regression with ARIMA(3,0,1) errors : -12646.01\n",
      " Regression with ARIMA(4,0,2) errors : -12662.46\n",
      " Regression with ARIMA(3,0,3) errors : -12663.22\n",
      " Regression with ARIMA(2,0,3) errors : -12659.45\n",
      " Regression with ARIMA(4,0,1) errors : -12661.32\n",
      " Regression with ARIMA(4,0,3) errors : -12707.82\n",
      " Regression with ARIMA(5,0,3) errors : -12680.87\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.94\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12674.86\n",
      " Regression with ARIMA(4,0,3) errors : -12602.62\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12703.26\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.76\n",
      " Regression with ARIMA(0,0,0) errors : -9126.664\n",
      " Regression with ARIMA(1,0,0) errors : -12610.17\n",
      " Regression with ARIMA(0,0,1) errors : -10784.22\n",
      " Regression with ARIMA(0,0,0) errors : -8120.924\n",
      " Regression with ARIMA(1,0,2) errors : -12630.62\n",
      " Regression with ARIMA(2,0,1) errors : -12629.52\n",
      " Regression with ARIMA(3,0,2) errors : -12694.59\n",
      " Regression with ARIMA(3,0,1) errors : -12642.09\n",
      " Regression with ARIMA(4,0,2) errors : -12658.44\n",
      " Regression with ARIMA(3,0,3) errors : -12658.75\n",
      " Regression with ARIMA(2,0,3) errors : -12655.04\n",
      " Regression with ARIMA(4,0,1) errors : -12657.14\n",
      " Regression with ARIMA(4,0,3) errors : -12704.19\n",
      " Regression with ARIMA(5,0,3) errors : -12674.9\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.25\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12664.74\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.55\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.01\n",
      " Regression with ARIMA(0,0,0) errors : -9129.67\n",
      " Regression with ARIMA(1,0,0) errors : -12606.43\n",
      " Regression with ARIMA(0,0,1) errors : -10786.26\n",
      " Regression with ARIMA(0,0,0) errors : -8109.689\n",
      " Regression with ARIMA(1,0,2) errors : -12626.33\n",
      " Regression with ARIMA(2,0,1) errors : -12625.7\n",
      " Regression with ARIMA(3,0,2) errors : -12685.15\n",
      " Regression with ARIMA(3,0,1) errors : -12638.15\n",
      " Regression with ARIMA(4,0,2) errors : -12654.36\n",
      " Regression with ARIMA(3,0,3) errors : -12654.53\n",
      " Regression with ARIMA(2,0,3) errors : -12651.32\n",
      " Regression with ARIMA(4,0,1) errors : -12653.1\n",
      " Regression with ARIMA(4,0,3) errors : -12701.37\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12653.24\n",
      " Regression with ARIMA(3,0,4) errors : -12676.54\n",
      " Regression with ARIMA(5,0,2) errors : -12652.64\n",
      " Regression with ARIMA(5,0,4) errors : -12668.09\n",
      " Regression with ARIMA(4,0,3) errors : -12590.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.56\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.77\n",
      " Regression with ARIMA(0,0,0) errors : -9125.562\n",
      " Regression with ARIMA(1,0,0) errors : -12610.64\n",
      " Regression with ARIMA(0,0,1) errors : -10785.7\n",
      " Regression with ARIMA(0,0,0) errors : -8108.179\n",
      " Regression with ARIMA(1,0,2) errors : -12630.51\n",
      " Regression with ARIMA(2,0,1) errors : -12629.36\n",
      " Regression with ARIMA(3,0,2) errors : -12694.15\n",
      " Regression with ARIMA(3,0,1) errors : -12642.13\n",
      " Regression with ARIMA(4,0,2) errors : -12658.37\n",
      " Regression with ARIMA(3,0,3) errors : -12658.83\n",
      " Regression with ARIMA(2,0,3) errors : -12655.24\n",
      " Regression with ARIMA(4,0,1) errors : -12657.12\n",
      " Regression with ARIMA(4,0,3) errors : -12704.42\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12679.15\n",
      " Regression with ARIMA(3,0,4) errors : -12677.56\n",
      " Regression with ARIMA(5,0,2) errors : -12656.96\n",
      " Regression with ARIMA(5,0,4) errors : -12670.89\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12699.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.76\n",
      " Regression with ARIMA(0,0,0) errors : -9119.29\n",
      " Regression with ARIMA(1,0,0) errors : -12609.83\n",
      " Regression with ARIMA(0,0,1) errors : -10782.32\n",
      " Regression with ARIMA(0,0,0) errors : -8104.093\n",
      " Regression with ARIMA(1,0,2) errors : -12629.02\n",
      " Regression with ARIMA(2,0,1) errors : -12627.65\n",
      " Regression with ARIMA(3,0,2) errors : -12693.41\n",
      " Regression with ARIMA(3,0,1) errors : -12640.24\n",
      " Regression with ARIMA(4,0,2) errors : -12657.4\n",
      " Regression with ARIMA(3,0,3) errors : -12657.65\n",
      " Regression with ARIMA(2,0,3) errors : -12654\n",
      " Regression with ARIMA(4,0,1) errors : -12655.98\n",
      " Regression with ARIMA(4,0,3) errors : -12700.63\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12678.52\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12666.19\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.72\n",
      " Regression with ARIMA(0,0,0) errors : -9127.533\n",
      " Regression with ARIMA(1,0,0) errors : -12608.51\n",
      " Regression with ARIMA(0,0,1) errors : -10784.58\n",
      " Regression with ARIMA(0,0,0) errors : -8099.693\n",
      " Regression with ARIMA(1,0,2) errors : -12627.71\n",
      " Regression with ARIMA(2,0,1) errors : -12626.53\n",
      " Regression with ARIMA(3,0,2) errors : -12687.4\n",
      " Regression with ARIMA(3,0,1) errors : -12638.82\n",
      " Regression with ARIMA(4,0,2) errors : -12655.24\n",
      " Regression with ARIMA(3,0,3) errors : -12655.99\n",
      " Regression with ARIMA(2,0,3) errors : -12651.92\n",
      " Regression with ARIMA(4,0,1) errors : -12654.76\n",
      " Regression with ARIMA(4,0,3) errors : -12698.43\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12654.62\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -12611.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12696.67\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.19\n",
      " Regression with ARIMA(0,0,0) errors : -9131.072\n",
      " Regression with ARIMA(1,0,0) errors : -12612.33\n",
      " Regression with ARIMA(0,0,1) errors : -10786.34\n",
      " Regression with ARIMA(0,0,0) errors : -8111.89\n",
      " Regression with ARIMA(1,0,2) errors : -12632.14\n",
      " Regression with ARIMA(2,0,1) errors : -12630.94\n",
      " Regression with ARIMA(3,0,2) errors : -12697.09\n",
      " Regression with ARIMA(3,0,1) errors : -12642.55\n",
      " Regression with ARIMA(4,0,2) errors : -12659.42\n",
      " Regression with ARIMA(3,0,3) errors : -12660.03\n",
      " Regression with ARIMA(2,0,3) errors : -12656.53\n",
      " Regression with ARIMA(4,0,1) errors : -12658.14\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12614.5\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12700.42\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.26\n",
      " Regression with ARIMA(0,0,0) errors : -9126.592\n",
      " Regression with ARIMA(1,0,0) errors : -12609.67\n",
      " Regression with ARIMA(0,0,1) errors : -10781.77\n",
      " Regression with ARIMA(0,0,0) errors : -8113.176\n",
      " Regression with ARIMA(1,0,2) errors : -12629.18\n",
      " Regression with ARIMA(2,0,1) errors : -12627.73\n",
      " Regression with ARIMA(3,0,2) errors : -12692.71\n",
      " Regression with ARIMA(3,0,1) errors : -12639.26\n",
      " Regression with ARIMA(4,0,2) errors : -12656.27\n",
      " Regression with ARIMA(3,0,3) errors : -12657.03\n",
      " Regression with ARIMA(2,0,3) errors : -12652.75\n",
      " Regression with ARIMA(4,0,1) errors : -12654.72\n",
      " Regression with ARIMA(4,0,3) errors : -12699.6\n",
      " Regression with ARIMA(5,0,3) errors : -12672.77\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12668.99\n",
      " Regression with ARIMA(4,0,3) errors : -12626.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12697.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "[1] \"70 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.51\n",
      " Regression with ARIMA(0,0,0) errors : -9120.766\n",
      " Regression with ARIMA(1,0,0) errors : -12607\n",
      " Regression with ARIMA(0,0,1) errors : -10776.09\n",
      " Regression with ARIMA(0,0,0) errors : -8111.103\n",
      " Regression with ARIMA(1,0,2) errors : -12626.77\n",
      " Regression with ARIMA(2,0,1) errors : -12625.53\n",
      " Regression with ARIMA(3,0,2) errors : -12685.73\n",
      " Regression with ARIMA(3,0,1) errors : -12637.75\n",
      " Regression with ARIMA(4,0,2) errors : -12654.14\n",
      " Regression with ARIMA(3,0,3) errors : -12654.51\n",
      " Regression with ARIMA(2,0,3) errors : -12650.91\n",
      " Regression with ARIMA(4,0,1) errors : -12654.37\n",
      " Regression with ARIMA(4,0,3) errors : -12686.13\n",
      " Regression with ARIMA(5,0,3) errors : -12700.25\n",
      " Regression with ARIMA(5,0,2) errors : -12654.47\n",
      " Regression with ARIMA(5,0,4) errors : -12662.71\n",
      " Regression with ARIMA(4,0,4) errors : -12698.47\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : -12673.47\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12629.83\n",
      " Regression with ARIMA(0,0,0) errors : -9123.342\n",
      " Regression with ARIMA(1,0,0) errors : -12606.52\n",
      " Regression with ARIMA(0,0,1) errors : -10778\n",
      " Regression with ARIMA(0,0,0) errors : -8105.722\n",
      " Regression with ARIMA(1,0,2) errors : -12626.01\n",
      " Regression with ARIMA(2,0,1) errors : -12624.6\n",
      " Regression with ARIMA(3,0,2) errors : -12689.93\n",
      " Regression with ARIMA(3,0,1) errors : -12636.27\n",
      " Regression with ARIMA(4,0,2) errors : -12652.8\n",
      " Regression with ARIMA(3,0,3) errors : -12653.27\n",
      " Regression with ARIMA(2,0,3) errors : -12649.98\n",
      " Regression with ARIMA(4,0,1) errors : -12652.27\n",
      " Regression with ARIMA(4,0,3) errors : -12694.07\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12670.15\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12654.04\n",
      " Regression with ARIMA(4,0,3) errors : -12618.5\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.06\n",
      " Regression with ARIMA(0,0,0) errors : -9131.681\n",
      " Regression with ARIMA(1,0,0) errors : -12608.01\n",
      " Regression with ARIMA(0,0,1) errors : -10782.66\n",
      " Regression with ARIMA(0,0,0) errors : -8107.119\n",
      " Regression with ARIMA(1,0,2) errors : -12628.11\n",
      " Regression with ARIMA(2,0,1) errors : -12626.67\n",
      " Regression with ARIMA(3,0,2) errors : -12693.49\n",
      " Regression with ARIMA(3,0,1) errors : -12638.11\n",
      " Regression with ARIMA(4,0,2) errors : -12655.3\n",
      " Regression with ARIMA(3,0,3) errors : -12655.92\n",
      " Regression with ARIMA(2,0,3) errors : -12652.11\n",
      " Regression with ARIMA(4,0,1) errors : -12653.8\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12610.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12696.06\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.24\n",
      " Regression with ARIMA(0,0,0) errors : -9131.239\n",
      " Regression with ARIMA(1,0,0) errors : -12606.95\n",
      " Regression with ARIMA(0,0,1) errors : -10780.44\n",
      " Regression with ARIMA(0,0,0) errors : -8112.5\n",
      " Regression with ARIMA(1,0,2) errors : -12627\n",
      " Regression with ARIMA(2,0,1) errors : -12625.5\n",
      " Regression with ARIMA(3,0,2) errors : -12689.64\n",
      " Regression with ARIMA(3,0,1) errors : -12638.39\n",
      " Regression with ARIMA(4,0,2) errors : -12654.7\n",
      " Regression with ARIMA(3,0,3) errors : -12654.57\n",
      " Regression with ARIMA(2,0,3) errors : -12650.34\n",
      " Regression with ARIMA(4,0,1) errors : -12654\n",
      " Regression with ARIMA(4,0,3) errors : -12691.8\n",
      " Regression with ARIMA(5,0,3) errors : -12674.84\n",
      " Regression with ARIMA(4,0,4) errors : -12670.68\n",
      " Regression with ARIMA(3,0,4) errors : -12676.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12662.77\n",
      " Regression with ARIMA(4,0,3) errors : -12620.21\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.43\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.92\n",
      " Regression with ARIMA(0,0,0) errors : -9128.861\n",
      " Regression with ARIMA(1,0,0) errors : -12610.07\n",
      " Regression with ARIMA(0,0,1) errors : -10783.53\n",
      " Regression with ARIMA(0,0,0) errors : -8110.608\n",
      " Regression with ARIMA(1,0,2) errors : -12629.79\n",
      " Regression with ARIMA(2,0,1) errors : -12628.8\n",
      " Regression with ARIMA(3,0,2) errors : -12690.81\n",
      " Regression with ARIMA(3,0,1) errors : -12640.88\n",
      " Regression with ARIMA(4,0,2) errors : -12657.06\n",
      " Regression with ARIMA(3,0,3) errors : -12657.59\n",
      " Regression with ARIMA(2,0,3) errors : -12654.11\n",
      " Regression with ARIMA(4,0,1) errors : -12656.04\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12597.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12697.96\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12634.62\n",
      " Regression with ARIMA(0,0,0) errors : -9126.781\n",
      " Regression with ARIMA(1,0,0) errors : -12610.65\n",
      " Regression with ARIMA(0,0,1) errors : -10781.97\n",
      " Regression with ARIMA(0,0,0) errors : -8113.142\n",
      " Regression with ARIMA(1,0,2) errors : -12630.54\n",
      " Regression with ARIMA(2,0,1) errors : -12629.23\n",
      " Regression with ARIMA(3,0,2) errors : -12696.42\n",
      " Regression with ARIMA(3,0,1) errors : -12641.18\n",
      " Regression with ARIMA(4,0,2) errors : -12657.47\n",
      " Regression with ARIMA(3,0,3) errors : -12658.27\n",
      " Regression with ARIMA(2,0,3) errors : -12654.69\n",
      " Regression with ARIMA(4,0,1) errors : -12656.72\n",
      " Regression with ARIMA(4,0,3) errors : -12703.68\n",
      " Regression with ARIMA(5,0,3) errors : -12677.09\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12669.72\n",
      " Regression with ARIMA(4,0,3) errors : -12577.74\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.4\n",
      " Regression with ARIMA(0,0,0) errors : -9125.689\n",
      " Regression with ARIMA(1,0,0) errors : -12612.41\n",
      " Regression with ARIMA(0,0,1) errors : -10783.44\n",
      " Regression with ARIMA(0,0,0) errors : -8112.957\n",
      " Regression with ARIMA(1,0,2) errors : -12632.37\n",
      " Regression with ARIMA(2,0,1) errors : -12631.02\n",
      " Regression with ARIMA(3,0,2) errors : -12698.98\n",
      " Regression with ARIMA(3,0,1) errors : -12642.99\n",
      " Regression with ARIMA(4,0,2) errors : -12659.39\n",
      " Regression with ARIMA(3,0,3) errors : -12660.05\n",
      " Regression with ARIMA(2,0,3) errors : -12656.41\n",
      " Regression with ARIMA(4,0,1) errors : -12658.4\n",
      " Regression with ARIMA(4,0,3) errors : -12705.73\n",
      " Regression with ARIMA(5,0,3) errors : -12677.06\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12682.47\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12672.68\n",
      " Regression with ARIMA(4,0,3) errors : -12592.32\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.68\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.3\n",
      " Regression with ARIMA(0,0,0) errors : -9115.868\n",
      " Regression with ARIMA(1,0,0) errors : -12611.51\n",
      " Regression with ARIMA(0,0,1) errors : -10777.8\n",
      " Regression with ARIMA(0,0,0) errors : -8111.841\n",
      " Regression with ARIMA(1,0,2) errors : -12631.09\n",
      " Regression with ARIMA(2,0,1) errors : -12629.64\n",
      " Regression with ARIMA(3,0,2) errors : -12698.43\n",
      " Regression with ARIMA(3,0,1) errors : -12641.39\n",
      " Regression with ARIMA(4,0,2) errors : -12658.34\n",
      " Regression with ARIMA(3,0,3) errors : -12658.92\n",
      " Regression with ARIMA(2,0,3) errors : -12655.53\n",
      " Regression with ARIMA(4,0,1) errors : -12657.54\n",
      " Regression with ARIMA(4,0,3) errors : -12704.55\n",
      " Regression with ARIMA(5,0,3) errors : -12677.45\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12671.36\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.66\n",
      " Regression with ARIMA(0,0,0) errors : -9124.945\n",
      " Regression with ARIMA(1,0,0) errors : -12612.72\n",
      " Regression with ARIMA(0,0,1) errors : -10780.08\n",
      " Regression with ARIMA(0,0,0) errors : -8108.834\n",
      " Regression with ARIMA(1,0,2) errors : -12632.51\n",
      " Regression with ARIMA(2,0,1) errors : -12631.82\n",
      " Regression with ARIMA(3,0,2) errors : -12694.27\n",
      " Regression with ARIMA(3,0,1) errors : -12643.59\n",
      " Regression with ARIMA(4,0,2) errors : -12660.23\n",
      " Regression with ARIMA(3,0,3) errors : -12660.57\n",
      " Regression with ARIMA(2,0,3) errors : -12657.73\n",
      " Regression with ARIMA(4,0,1) errors : -12659.39\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12588.55\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.13\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12627.74\n",
      " Regression with ARIMA(0,0,0) errors : -9117.039\n",
      " Regression with ARIMA(1,0,0) errors : -12604.36\n",
      " Regression with ARIMA(0,0,1) errors : -10772.74\n",
      " Regression with ARIMA(0,0,0) errors : -8100.168\n",
      " Regression with ARIMA(1,0,2) errors : -12624.03\n",
      " Regression with ARIMA(2,0,1) errors : -12622.73\n",
      " Regression with ARIMA(3,0,2) errors : -12688.87\n",
      " Regression with ARIMA(3,0,1) errors : -12635.29\n",
      " Regression with ARIMA(4,0,2) errors : -12652.41\n",
      " Regression with ARIMA(3,0,3) errors : -12652.42\n",
      " Regression with ARIMA(2,0,3) errors : -12648.98\n",
      " Regression with ARIMA(4,0,1) errors : -12651.73\n",
      " Regression with ARIMA(4,0,3) errors : -12695.02\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12668.42\n",
      " Regression with ARIMA(3,0,4) errors : -12666.86\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12662.55\n",
      " Regression with ARIMA(4,0,3) errors : -12583.67\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12692.62\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12629.95\n",
      " Regression with ARIMA(0,0,0) errors : -9111.839\n",
      " Regression with ARIMA(1,0,0) errors : -12606.59\n",
      " Regression with ARIMA(0,0,1) errors : -10768.97\n",
      " Regression with ARIMA(0,0,0) errors : -8094.359\n",
      " Regression with ARIMA(1,0,2) errors : -12626.11\n",
      " Regression with ARIMA(2,0,1) errors : -12624.99\n",
      " Regression with ARIMA(3,0,2) errors : -12691.49\n",
      " Regression with ARIMA(3,0,1) errors : -12636.29\n",
      " Regression with ARIMA(4,0,2) errors : -12654.61\n",
      " Regression with ARIMA(3,0,3) errors : -12655.25\n",
      " Regression with ARIMA(2,0,3) errors : -12651.79\n",
      " Regression with ARIMA(4,0,1) errors : -12653.54\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12606.28\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12694.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12625.86\n",
      " Regression with ARIMA(0,0,0) errors : -9104.057\n",
      " Regression with ARIMA(1,0,0) errors : -12602.52\n",
      " Regression with ARIMA(0,0,1) errors : -10763.32\n",
      " Regression with ARIMA(0,0,0) errors : -8093.859\n",
      " Regression with ARIMA(1,0,2) errors : -12621.83\n",
      " Regression with ARIMA(2,0,1) errors : -12620.75\n",
      " Regression with ARIMA(3,0,2) errors : -12688.22\n",
      " Regression with ARIMA(3,0,1) errors : -12631.52\n",
      " Regression with ARIMA(4,0,2) errors : -12652.06\n",
      " Regression with ARIMA(3,0,3) errors : -12650.46\n",
      " Regression with ARIMA(2,0,3) errors : -12647.56\n",
      " Regression with ARIMA(4,0,1) errors : -12651.23\n",
      " Regression with ARIMA(4,0,3) errors : -12681.28\n",
      " Regression with ARIMA(3,0,2) errors : -12603.68\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12690.63\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12618.91\n",
      " Regression with ARIMA(0,0,0) errors : -9103.363\n",
      " Regression with ARIMA(1,0,0) errors : -12597.31\n",
      " Regression with ARIMA(0,0,1) errors : -10765.68\n",
      " Regression with ARIMA(0,0,0) errors : -8091.292\n",
      " Regression with ARIMA(1,0,2) errors : -12615.19\n",
      " Regression with ARIMA(2,0,1) errors : -12613.85\n",
      " Regression with ARIMA(3,0,2) errors : -12682.31\n",
      " Regression with ARIMA(3,0,1) errors : -12625.35\n",
      " Regression with ARIMA(4,0,2) errors : -12644.79\n",
      " Regression with ARIMA(3,0,3) errors : -12644.37\n",
      " Regression with ARIMA(2,0,3) errors : -12640.45\n",
      " Regression with ARIMA(4,0,1) errors : -12643.65\n",
      " Regression with ARIMA(4,0,3) errors : -12682.08\n",
      " Regression with ARIMA(3,0,2) errors : -12580.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12684.69\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12615.06\n",
      " Regression with ARIMA(0,0,0) errors : -9099.58\n",
      " Regression with ARIMA(1,0,0) errors : -12592.84\n",
      " Regression with ARIMA(0,0,1) errors : -10762.48\n",
      " Regression with ARIMA(0,0,0) errors : -8087.004\n",
      " Regression with ARIMA(1,0,2) errors : -12610.83\n",
      " Regression with ARIMA(2,0,1) errors : -12609.67\n",
      " Regression with ARIMA(3,0,2) errors : -12677.21\n",
      " Regression with ARIMA(3,0,1) errors : -12621.08\n",
      " Regression with ARIMA(4,0,2) errors : -12640.17\n",
      " Regression with ARIMA(3,0,3) errors : -12640.85\n",
      " Regression with ARIMA(2,0,3) errors : -12636.93\n",
      " Regression with ARIMA(4,0,1) errors : -12638.83\n",
      " Regression with ARIMA(4,0,3) errors : -12684.27\n",
      " Regression with ARIMA(5,0,3) errors : -12658.04\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12639.53\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12654.82\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12680.01\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12613.46\n",
      " Regression with ARIMA(0,0,0) errors : -9099.695\n",
      " Regression with ARIMA(1,0,0) errors : -12591.66\n",
      " Regression with ARIMA(0,0,1) errors : -10763.22\n",
      " Regression with ARIMA(0,0,0) errors : -8089.962\n",
      " Regression with ARIMA(1,0,2) errors : -12609.68\n",
      " Regression with ARIMA(2,0,1) errors : -12608.39\n",
      " Regression with ARIMA(3,0,2) errors : -12677.01\n",
      " Regression with ARIMA(3,0,1) errors : -12619.63\n",
      " Regression with ARIMA(4,0,2) errors : -12638.73\n",
      " Regression with ARIMA(3,0,3) errors : -12639.14\n",
      " Regression with ARIMA(2,0,3) errors : -12635.44\n",
      " Regression with ARIMA(4,0,1) errors : -12637.36\n",
      " Regression with ARIMA(4,0,3) errors : -12681.2\n",
      " Regression with ARIMA(5,0,3) errors : -12656.69\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12660.48\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12652.18\n",
      " Regression with ARIMA(4,0,3) errors : -12597.54\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12678.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12615.16\n",
      " Regression with ARIMA(0,0,0) errors : -9100.818\n",
      " Regression with ARIMA(1,0,0) errors : -12593.22\n",
      " Regression with ARIMA(0,0,1) errors : -10765.31\n",
      " Regression with ARIMA(0,0,0) errors : -8091.06\n",
      " Regression with ARIMA(1,0,2) errors : -12611.24\n",
      " Regression with ARIMA(2,0,1) errors : -12609.93\n",
      " Regression with ARIMA(3,0,2) errors : -12679.3\n",
      " Regression with ARIMA(3,0,1) errors : -12621.06\n",
      " Regression with ARIMA(4,0,2) errors : -12639.78\n",
      " Regression with ARIMA(3,0,3) errors : -12640.43\n",
      " Regression with ARIMA(2,0,3) errors : -12636.97\n",
      " Regression with ARIMA(4,0,1) errors : -12638.66\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12594.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12679.67\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12617.12\n",
      " Regression with ARIMA(0,0,0) errors : -9109.583\n",
      " Regression with ARIMA(1,0,0) errors : -12595.07\n",
      " Regression with ARIMA(0,0,1) errors : -10771.08\n",
      " Regression with ARIMA(0,0,0) errors : -8093.37\n",
      " Regression with ARIMA(1,0,2) errors : -12613.21\n",
      " Regression with ARIMA(2,0,1) errors : -12611.88\n",
      " Regression with ARIMA(3,0,2) errors : -12678.72\n",
      " Regression with ARIMA(3,0,1) errors : -12623\n",
      " Regression with ARIMA(4,0,2) errors : -12641.23\n",
      " Regression with ARIMA(3,0,3) errors : -12641.89\n",
      " Regression with ARIMA(2,0,3) errors : -12638.42\n",
      " Regression with ARIMA(4,0,1) errors : -12640.06\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12592.8\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12681.68\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12619.74\n",
      " Regression with ARIMA(0,0,0) errors : -9112.072\n",
      " Regression with ARIMA(1,0,0) errors : -12597.43\n",
      " Regression with ARIMA(0,0,1) errors : -10771.67\n",
      " Regression with ARIMA(0,0,0) errors : -8099.27\n",
      " Regression with ARIMA(1,0,2) errors : -12615.95\n",
      " Regression with ARIMA(2,0,1) errors : -12614.81\n",
      " Regression with ARIMA(3,0,2) errors : -12684.97\n",
      " Regression with ARIMA(3,0,1) errors : -12626.06\n",
      " Regression with ARIMA(4,0,2) errors : -12644.83\n",
      " Regression with ARIMA(3,0,3) errors : -12645.37\n",
      " Regression with ARIMA(2,0,3) errors : -12641.62\n",
      " Regression with ARIMA(4,0,1) errors : -12643.67\n",
      " Regression with ARIMA(4,0,3) errors : -12690.35\n",
      " Regression with ARIMA(5,0,3) errors : -12663.66\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12668.79\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12658.85\n",
      " Regression with ARIMA(4,0,3) errors : -12609.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12685.05\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12619.78\n",
      " Regression with ARIMA(0,0,0) errors : -9111.436\n",
      " Regression with ARIMA(1,0,0) errors : -12596.51\n",
      " Regression with ARIMA(0,0,1) errors : -10769.82\n",
      " Regression with ARIMA(0,0,0) errors : -8099.19\n",
      " Regression with ARIMA(1,0,2) errors : -12615.12\n",
      " Regression with ARIMA(2,0,1) errors : -12615.29\n",
      " Regression with ARIMA(3,0,2) errors : -12677.01\n",
      " Regression with ARIMA(3,0,1) errors : -12626.47\n",
      " Regression with ARIMA(4,0,2) errors : -12646.5\n",
      " Regression with ARIMA(3,0,3) errors : -12647.04\n",
      " Regression with ARIMA(2,0,3) errors : -12642.14\n",
      " Regression with ARIMA(4,0,1) errors : -12644.59\n",
      " Regression with ARIMA(4,0,3) errors : -12686.33\n",
      " Regression with ARIMA(5,0,3) errors : -12661.66\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12668.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12657.53\n",
      " Regression with ARIMA(4,0,3) errors : -12608.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12683.18\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12616.6\n",
      " Regression with ARIMA(0,0,0) errors : -9093.993\n",
      " Regression with ARIMA(1,0,0) errors : -12593.32\n",
      " Regression with ARIMA(0,0,1) errors : -10754.58\n",
      " Regression with ARIMA(0,0,0) errors : -8057.969\n",
      " Regression with ARIMA(1,0,2) errors : -12612.81\n",
      " Regression with ARIMA(2,0,1) errors : -12611.61\n",
      " Regression with ARIMA(3,0,2) errors : -12678.85\n",
      " Regression with ARIMA(3,0,1) errors : -12622.82\n",
      " Regression with ARIMA(4,0,2) errors : -12641.44\n",
      " Regression with ARIMA(3,0,3) errors : -12642.14\n",
      " Regression with ARIMA(2,0,3) errors : -12638.25\n",
      " Regression with ARIMA(4,0,1) errors : -12639.95\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12583.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12680.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12583.96\n",
      " Regression with ARIMA(0,0,0) errors : -9092.613\n",
      " Regression with ARIMA(1,0,0) errors : -12563.7\n",
      " Regression with ARIMA(0,0,1) errors : -10747.78\n",
      " Regression with ARIMA(0,0,0) errors : -8051.218\n",
      " Regression with ARIMA(1,0,2) errors : -12580.28\n",
      " Regression with ARIMA(2,0,1) errors : -12579.03\n",
      " Regression with ARIMA(3,0,2) errors : -12646.7\n",
      " Regression with ARIMA(3,0,1) errors : -12589.65\n",
      " Regression with ARIMA(4,0,2) errors : -12606.27\n",
      " Regression with ARIMA(3,0,3) errors : -12606.89\n",
      " Regression with ARIMA(2,0,3) errors : -12603.05\n",
      " Regression with ARIMA(4,0,1) errors : -12604.75\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12556.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12648.35\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12577.66\n",
      " Regression with ARIMA(0,0,0) errors : -9095.204\n",
      " Regression with ARIMA(1,0,0) errors : -12557.4\n",
      " Regression with ARIMA(0,0,1) errors : -10745.91\n",
      " Regression with ARIMA(0,0,0) errors : -8037.239\n",
      " Regression with ARIMA(1,0,2) errors : -12573.72\n",
      " Regression with ARIMA(2,0,1) errors : -12572.35\n",
      " Regression with ARIMA(3,0,2) errors : -12641.2\n",
      " Regression with ARIMA(3,0,1) errors : -12583.1\n",
      " Regression with ARIMA(4,0,2) errors : -12600.41\n",
      " Regression with ARIMA(3,0,3) errors : -12601.11\n",
      " Regression with ARIMA(2,0,3) errors : -12597.21\n",
      " Regression with ARIMA(4,0,1) errors : -12599.03\n",
      " Regression with ARIMA(4,0,3) errors : -12644.07\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12622.13\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12612.01\n",
      " Regression with ARIMA(4,0,3) errors : -12563.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12642.54\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12575.52\n",
      " Regression with ARIMA(0,0,0) errors : -9101.37\n",
      " Regression with ARIMA(1,0,0) errors : -12554.94\n",
      " Regression with ARIMA(0,0,1) errors : -10747.52\n",
      " Regression with ARIMA(0,0,0) errors : -8033.351\n",
      " Regression with ARIMA(1,0,2) errors : -12571.38\n",
      " Regression with ARIMA(2,0,1) errors : -12570.05\n",
      " Regression with ARIMA(3,0,2) errors : -12638.35\n",
      " Regression with ARIMA(3,0,1) errors : -12581.07\n",
      " Regression with ARIMA(4,0,2) errors : -12598.59\n",
      " Regression with ARIMA(3,0,3) errors : -12599.01\n",
      " Regression with ARIMA(2,0,3) errors : -12595.34\n",
      " Regression with ARIMA(4,0,1) errors : -12597.11\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12519.88\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12639.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12565.83\n",
      " Regression with ARIMA(0,0,0) errors : -9101.364\n",
      " Regression with ARIMA(1,0,0) errors : -12545.42\n",
      " Regression with ARIMA(0,0,1) errors : -10744.99\n",
      " Regression with ARIMA(0,0,0) errors : -8028.435\n",
      " Regression with ARIMA(1,0,2) errors : -12561.69\n",
      " Regression with ARIMA(2,0,1) errors : -12560.33\n",
      " Regression with ARIMA(3,0,2) errors : -12625.38\n",
      " Regression with ARIMA(3,0,1) errors : -12571.55\n",
      " Regression with ARIMA(4,0,2) errors : -12589.48\n",
      " Regression with ARIMA(3,0,3) errors : -12589.91\n",
      " Regression with ARIMA(2,0,3) errors : -12585.25\n",
      " Regression with ARIMA(4,0,1) errors : -12587.54\n",
      " Regression with ARIMA(4,0,3) errors : -12629.39\n",
      " Regression with ARIMA(5,0,3) errors : -12606.27\n",
      " Regression with ARIMA(4,0,4) errors : -12632.75\n",
      " Regression with ARIMA(3,0,4) errors : -12604.33\n",
      " Regression with ARIMA(5,0,4) errors : -12602.45\n",
      " Regression with ARIMA(4,0,5) errors : -12606.94\n",
      " Regression with ARIMA(3,0,5) errors : -12601.51\n",
      " Regression with ARIMA(5,0,5) errors : -12608.1\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12629.36\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "[1] \"80 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12550.88\n",
      " Regression with ARIMA(0,0,0) errors : -9082.974\n",
      " Regression with ARIMA(1,0,0) errors : -12530.87\n",
      " Regression with ARIMA(0,0,1) errors : -10726.19\n",
      " Regression with ARIMA(0,0,0) errors : -7990.949\n",
      " Regression with ARIMA(1,0,2) errors : -12547.22\n",
      " Regression with ARIMA(2,0,1) errors : -12546.03\n",
      " Regression with ARIMA(3,0,2) errors : -12611.03\n",
      " Regression with ARIMA(3,0,1) errors : -12556.14\n",
      " Regression with ARIMA(4,0,2) errors : -12573.38\n",
      " Regression with ARIMA(3,0,3) errors : -12573.93\n",
      " Regression with ARIMA(2,0,3) errors : -12570.37\n",
      " Regression with ARIMA(4,0,1) errors : -12572.13\n",
      " Regression with ARIMA(4,0,3) errors : -12616.54\n",
      " Regression with ARIMA(5,0,3) errors : -12590.07\n",
      " Regression with ARIMA(4,0,4) errors : -12620.02\n",
      " Regression with ARIMA(3,0,4) errors : -12593.33\n",
      " Regression with ARIMA(5,0,4) errors : -12585.19\n",
      " Regression with ARIMA(4,0,5) errors : -12590.96\n",
      " Regression with ARIMA(3,0,5) errors : -12586.08\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12613.46\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12541.98\n",
      " Regression with ARIMA(0,0,0) errors : -9085.693\n",
      " Regression with ARIMA(1,0,0) errors : -12521.52\n",
      " Regression with ARIMA(0,0,1) errors : -10727.61\n",
      " Regression with ARIMA(0,0,0) errors : -7984.545\n",
      " Regression with ARIMA(1,0,2) errors : -12537.92\n",
      " Regression with ARIMA(2,0,1) errors : -12537.24\n",
      " Regression with ARIMA(3,0,2) errors : -12601.89\n",
      " Regression with ARIMA(3,0,1) errors : -12547.19\n",
      " Regression with ARIMA(4,0,2) errors : -12564.24\n",
      " Regression with ARIMA(3,0,3) errors : -12564.26\n",
      " Regression with ARIMA(2,0,3) errors : -12561.62\n",
      " Regression with ARIMA(4,0,1) errors : -12563.37\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12499.3\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12602.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.96\n",
      " Regression with ARIMA(0,0,0) errors : -9090.727\n",
      " Regression with ARIMA(1,0,0) errors : -12524.23\n",
      " Regression with ARIMA(0,0,1) errors : -10729.14\n",
      " Regression with ARIMA(0,0,0) errors : -7988.192\n",
      " Regression with ARIMA(1,0,2) errors : -12541.23\n",
      " Regression with ARIMA(2,0,1) errors : -12541.2\n",
      " Regression with ARIMA(3,0,2) errors : -12596.53\n",
      " Regression with ARIMA(3,0,1) errors : -12551.61\n",
      " Regression with ARIMA(4,0,2) errors : -12568.27\n",
      " Regression with ARIMA(3,0,3) errors : -12568.72\n",
      " Regression with ARIMA(2,0,3) errors : -12565.53\n",
      " Regression with ARIMA(4,0,1) errors : -12567.05\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12496.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12605.49\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12548.88\n",
      " Regression with ARIMA(0,0,0) errors : -9100.305\n",
      " Regression with ARIMA(1,0,0) errors : -12527.5\n",
      " Regression with ARIMA(0,0,1) errors : -10736.35\n",
      " Regression with ARIMA(0,0,0) errors : -7988.759\n",
      " Regression with ARIMA(1,0,2) errors : -12544.66\n",
      " Regression with ARIMA(2,0,1) errors : -12543.65\n",
      " Regression with ARIMA(3,0,2) errors : -12605.4\n",
      " Regression with ARIMA(3,0,1) errors : -12554.44\n",
      " Regression with ARIMA(4,0,2) errors : -12571.11\n",
      " Regression with ARIMA(3,0,3) errors : -12571.91\n",
      " Regression with ARIMA(2,0,3) errors : -12568.5\n",
      " Regression with ARIMA(4,0,1) errors : -12570.06\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12504.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12608.79\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.27\n",
      " Regression with ARIMA(0,0,0) errors : -9095.28\n",
      " Regression with ARIMA(1,0,0) errors : -12526.27\n",
      " Regression with ARIMA(0,0,1) errors : -10733.95\n",
      " Regression with ARIMA(0,0,0) errors : -7985.631\n",
      " Regression with ARIMA(1,0,2) errors : -12543.29\n",
      " Regression with ARIMA(2,0,1) errors : -12541.96\n",
      " Regression with ARIMA(3,0,2) errors : -12605.92\n",
      " Regression with ARIMA(3,0,1) errors : -12552.76\n",
      " Regression with ARIMA(4,0,2) errors : -12569.38\n",
      " Regression with ARIMA(3,0,3) errors : -12569.97\n",
      " Regression with ARIMA(2,0,3) errors : -12566.62\n",
      " Regression with ARIMA(4,0,1) errors : -12568.51\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12514.77\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12607.57\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12551.72\n",
      " Regression with ARIMA(0,0,0) errors : -9094.616\n",
      " Regression with ARIMA(1,0,0) errors : -12527.72\n",
      " Regression with ARIMA(0,0,1) errors : -10731.91\n",
      " Regression with ARIMA(0,0,0) errors : -7984.814\n",
      " Regression with ARIMA(1,0,2) errors : -12544.83\n",
      " Regression with ARIMA(2,0,1) errors : -12545.69\n",
      " Regression with ARIMA(3,0,2) errors : -12599.12\n",
      " Regression with ARIMA(3,0,1) errors : -12556.69\n",
      " Regression with ARIMA(4,0,2) errors : -12574.58\n",
      " Regression with ARIMA(3,0,3) errors : -12572.21\n",
      " Regression with ARIMA(2,0,3) errors : -12570.48\n",
      " Regression with ARIMA(4,0,1) errors : -12574.57\n",
      " Regression with ARIMA(4,0,3) errors : -12602.14\n",
      " Regression with ARIMA(5,0,3) errors : -12593.97\n",
      " Regression with ARIMA(4,0,4) errors : -12614.31\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12592.12\n",
      " Regression with ARIMA(4,0,5) errors : -12613.12\n",
      " Regression with ARIMA(3,0,5) errors : -12593.98\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -12615.97\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.25\n",
      " Regression with ARIMA(0,0,0) errors : -9103.285\n",
      " Regression with ARIMA(1,0,0) errors : -12525.6\n",
      " Regression with ARIMA(0,0,1) errors : -10740.02\n",
      " Regression with ARIMA(0,0,0) errors : -7987.126\n",
      " Regression with ARIMA(1,0,2) errors : -12542.63\n",
      " Regression with ARIMA(2,0,1) errors : -12541.09\n",
      " Regression with ARIMA(3,0,2) errors : -12595.27\n",
      " Regression with ARIMA(3,0,1) errors : -12553.61\n",
      " Regression with ARIMA(4,0,2) errors : -12567.35\n",
      " Regression with ARIMA(3,0,3) errors : -12568.1\n",
      " Regression with ARIMA(2,0,3) errors : -12564.84\n",
      " Regression with ARIMA(4,0,1) errors : -12567.61\n",
      " Regression with ARIMA(4,0,3) errors : -12599.93\n",
      " Regression with ARIMA(5,0,3) errors : -12585.25\n",
      " Regression with ARIMA(4,0,4) errors : -12587.13\n",
      " Regression with ARIMA(3,0,4) errors : -12586.59\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12587.56\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12603.94\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12563.76\n",
      " Regression with ARIMA(0,0,0) errors : -9114.748\n",
      " Regression with ARIMA(1,0,0) errors : -12542.44\n",
      " Regression with ARIMA(0,0,1) errors : -10750.26\n",
      " Regression with ARIMA(0,0,0) errors : -7996.79\n",
      " Regression with ARIMA(1,0,2) errors : -12559.52\n",
      " Regression with ARIMA(2,0,1) errors : -12557.88\n",
      " Regression with ARIMA(3,0,2) errors : -12623.24\n",
      " Regression with ARIMA(3,0,1) errors : -12569.07\n",
      " Regression with ARIMA(4,0,2) errors : -12584.06\n",
      " Regression with ARIMA(3,0,3) errors : -12584.83\n",
      " Regression with ARIMA(2,0,3) errors : -12581.2\n",
      " Regression with ARIMA(4,0,1) errors : -12583.59\n",
      " Regression with ARIMA(4,0,3) errors : -12622.16\n",
      " Regression with ARIMA(3,0,2) errors : -12529.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12623.55\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12571.66\n",
      " Regression with ARIMA(0,0,0) errors : -9119.255\n",
      " Regression with ARIMA(1,0,0) errors : -12550.63\n",
      " Regression with ARIMA(0,0,1) errors : -10754.38\n",
      " Regression with ARIMA(0,0,0) errors : -7999.828\n",
      " Regression with ARIMA(1,0,2) errors : -12567.56\n",
      " Regression with ARIMA(2,0,1) errors : -12565.97\n",
      " Regression with ARIMA(3,0,2) errors : -12623.38\n",
      " Regression with ARIMA(3,0,1) errors : -12577.61\n",
      " Regression with ARIMA(4,0,2) errors : -12592.71\n",
      " Regression with ARIMA(3,0,3) errors : -12593.33\n",
      " Regression with ARIMA(2,0,3) errors : -12589.24\n",
      " Regression with ARIMA(4,0,1) errors : -12591.99\n",
      " Regression with ARIMA(4,0,3) errors : -12628.14\n",
      " Regression with ARIMA(5,0,3) errors : -12611.42\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12608.22\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12601.46\n",
      " Regression with ARIMA(4,0,3) errors : -12518.46\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12632.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12570.69\n",
      " Regression with ARIMA(0,0,0) errors : -9115.278\n",
      " Regression with ARIMA(1,0,0) errors : -12549.82\n",
      " Regression with ARIMA(0,0,1) errors : -10753.47\n",
      " Regression with ARIMA(0,0,0) errors : -8003.712\n",
      " Regression with ARIMA(1,0,2) errors : -12566.64\n",
      " Regression with ARIMA(2,0,1) errors : -12564.99\n",
      " Regression with ARIMA(3,0,2) errors : -12627.12\n",
      " Regression with ARIMA(3,0,1) errors : -12576.67\n",
      " Regression with ARIMA(4,0,2) errors : -12592.86\n",
      " Regression with ARIMA(3,0,3) errors : -12593.53\n",
      " Regression with ARIMA(2,0,3) errors : -12588.09\n",
      " Regression with ARIMA(4,0,1) errors : -12591.37\n",
      " Regression with ARIMA(4,0,3) errors : -12631.06\n",
      " Regression with ARIMA(5,0,3) errors : -12608.52\n",
      " Regression with ARIMA(4,0,4) errors : -12636.78\n",
      " Regression with ARIMA(3,0,4) errors : -12595.05\n",
      " Regression with ARIMA(5,0,4) errors : -12606.13\n",
      " Regression with ARIMA(4,0,5) errors : -12611.46\n",
      " Regression with ARIMA(3,0,5) errors : -12589.1\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12631.52\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12578.38\n",
      " Regression with ARIMA(0,0,0) errors : -9111.17\n",
      " Regression with ARIMA(1,0,0) errors : -12558.92\n",
      " Regression with ARIMA(0,0,1) errors : -10753.78\n",
      " Regression with ARIMA(0,0,0) errors : -8020.573\n",
      " Regression with ARIMA(1,0,2) errors : -12574.68\n",
      " Regression with ARIMA(2,0,1) errors : -12573.05\n",
      " Regression with ARIMA(3,0,2) errors : -12623.18\n",
      " Regression with ARIMA(3,0,1) errors : -12586.14\n",
      " Regression with ARIMA(4,0,2) errors : -12599.85\n",
      " Regression with ARIMA(3,0,3) errors : -12600.52\n",
      " Regression with ARIMA(2,0,3) errors : -12595.7\n",
      " Regression with ARIMA(4,0,1) errors : -12599.55\n",
      " Regression with ARIMA(4,0,3) errors : -12630.95\n",
      " Regression with ARIMA(5,0,3) errors : -12614.41\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12610.87\n",
      " Regression with ARIMA(5,0,2) errors : -12611.96\n",
      " Regression with ARIMA(5,0,4) errors : -12609.33\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12639.79\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12589.89\n",
      " Regression with ARIMA(0,0,0) errors : -9118.887\n",
      " Regression with ARIMA(1,0,0) errors : -12570.44\n",
      " Regression with ARIMA(0,0,1) errors : -10762.54\n",
      " Regression with ARIMA(0,0,0) errors : -8023.134\n",
      " Regression with ARIMA(1,0,2) errors : -12586.06\n",
      " Regression with ARIMA(2,0,1) errors : -12584.58\n",
      " Regression with ARIMA(3,0,2) errors : -12650.24\n",
      " Regression with ARIMA(3,0,1) errors : -12595.09\n",
      " Regression with ARIMA(4,0,2) errors : -12610.13\n",
      " Regression with ARIMA(3,0,3) errors : -12611.25\n",
      " Regression with ARIMA(2,0,3) errors : -12607.47\n",
      " Regression with ARIMA(4,0,1) errors : -12610.04\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12562.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12652.57\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12605.76\n",
      " Regression with ARIMA(0,0,0) errors : -9124.298\n",
      " Regression with ARIMA(1,0,0) errors : -12585.84\n",
      " Regression with ARIMA(0,0,1) errors : -10776.69\n",
      " Regression with ARIMA(0,0,0) errors : -8072.897\n",
      " Regression with ARIMA(1,0,2) errors : -12601.79\n",
      " Regression with ARIMA(2,0,1) errors : -12600.13\n",
      " Regression with ARIMA(3,0,2) errors : -12662.69\n",
      " Regression with ARIMA(3,0,1) errors : -12612.34\n",
      " Regression with ARIMA(4,0,2) errors : -12629.9\n",
      " Regression with ARIMA(3,0,3) errors : -12629.01\n",
      " Regression with ARIMA(2,0,3) errors : -12623.63\n",
      " Regression with ARIMA(4,0,1) errors : -12627.83\n",
      " Regression with ARIMA(4,0,3) errors : -12662.1\n",
      " Regression with ARIMA(3,0,2) errors : -12538.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12668.81\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12617.98\n",
      " Regression with ARIMA(0,0,0) errors : -9103.826\n",
      " Regression with ARIMA(1,0,0) errors : -12597.39\n",
      " Regression with ARIMA(0,0,1) errors : -10769.07\n",
      " Regression with ARIMA(0,0,0) errors : -8071.78\n",
      " Regression with ARIMA(1,0,2) errors : -12613.58\n",
      " Regression with ARIMA(2,0,1) errors : -12612.03\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12634.81\n",
      " Regression with ARIMA(1,0,3) errors : -12637.74\n",
      " Regression with ARIMA(0,0,3) errors : -11857.74\n",
      " Regression with ARIMA(1,0,4) errors : -12635.79\n",
      " Regression with ARIMA(0,0,2) errors : -11425.89\n",
      " Regression with ARIMA(0,0,4) errors : -12183.34\n",
      " Regression with ARIMA(2,0,4) errors : -12660.74\n",
      " Regression with ARIMA(3,0,4) errors : -12661.91\n",
      " Regression with ARIMA(3,0,3) errors : -12639.57\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12664.79\n",
      " Regression with ARIMA(1,0,5) errors : -12637.48\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12662.8\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12648.96\n",
      " Regression with ARIMA(0,0,0) errors : -9121.032\n",
      " Regression with ARIMA(1,0,0) errors : -12628.13\n",
      " Regression with ARIMA(0,0,1) errors : -10785.99\n",
      " Regression with ARIMA(0,0,0) errors : -8086.924\n",
      " Regression with ARIMA(1,0,2) errors : -12643.58\n",
      " Regression with ARIMA(2,0,1) errors : -12645.29\n",
      " Regression with ARIMA(3,0,2) errors : -12693.39\n",
      " Regression with ARIMA(3,0,1) errors : -12657.07\n",
      " Regression with ARIMA(4,0,2) errors : -12674.99\n",
      " Regression with ARIMA(3,0,3) errors : -12674.05\n",
      " Regression with ARIMA(2,0,3) errors : -12670.13\n",
      " Regression with ARIMA(4,0,1) errors : -12673.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12586.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12712.63\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12660.79\n",
      " Regression with ARIMA(0,0,0) errors : -9128.864\n",
      " Regression with ARIMA(1,0,0) errors : -12639.5\n",
      " Regression with ARIMA(0,0,1) errors : -10794.45\n",
      " Regression with ARIMA(0,0,0) errors : -8086.79\n",
      " Regression with ARIMA(1,0,2) errors : -12656.36\n",
      " Regression with ARIMA(2,0,1) errors : -12654.67\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12681.02\n",
      " Regression with ARIMA(1,0,3) errors : -12683.93\n",
      " Regression with ARIMA(0,0,3) errors : -11882.7\n",
      " Regression with ARIMA(1,0,4) errors : -12681.93\n",
      " Regression with ARIMA(0,0,2) errors : -11451.05\n",
      " Regression with ARIMA(0,0,4) errors : -12222.24\n",
      " Regression with ARIMA(2,0,4) errors : -12708.43\n",
      " Regression with ARIMA(3,0,4) errors : -12700.64\n",
      " Regression with ARIMA(2,0,5) errors : -12711.77\n",
      " Regression with ARIMA(1,0,5) errors : -12684.46\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12635.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12712.16\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12663.87\n",
      " Regression with ARIMA(0,0,0) errors : -9125.032\n",
      " Regression with ARIMA(1,0,0) errors : -12642.83\n",
      " Regression with ARIMA(0,0,1) errors : -10795.06\n",
      " Regression with ARIMA(0,0,0) errors : -8088.558\n",
      " Regression with ARIMA(1,0,2) errors : -12659.49\n",
      " Regression with ARIMA(2,0,1) errors : -12657.96\n",
      " Regression with ARIMA(3,0,2) errors : -12717.9\n",
      " Regression with ARIMA(3,0,1) errors : -12671.05\n",
      " Regression with ARIMA(4,0,2) errors : -12688.31\n",
      " Regression with ARIMA(3,0,3) errors : -12688.66\n",
      " Regression with ARIMA(2,0,3) errors : -12684.8\n",
      " Regression with ARIMA(4,0,1) errors : -12687.93\n",
      " Regression with ARIMA(4,0,3) errors : -12724.73\n",
      " Regression with ARIMA(5,0,3) errors : -12705.98\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12706.33\n",
      " Regression with ARIMA(5,0,2) errors : -12704.8\n",
      " Regression with ARIMA(5,0,4) errors : -12707.76\n",
      " Regression with ARIMA(4,0,3) errors : -12626.28\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12711.43\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12675.17\n",
      " Regression with ARIMA(0,0,0) errors : -9127.822\n",
      " Regression with ARIMA(1,0,0) errors : -12652.69\n",
      " Regression with ARIMA(0,0,1) errors : -10797.32\n",
      " Regression with ARIMA(0,0,0) errors : -8122.42\n",
      " Regression with ARIMA(1,0,2) errors : -12669.49\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12695.32\n",
      " Regression with ARIMA(1,0,3) errors : -12697.68\n",
      " Regression with ARIMA(0,0,3) errors : -11885.17\n",
      " Regression with ARIMA(1,0,4) errors : -12695.67\n",
      " Regression with ARIMA(0,0,2) errors : -11454.21\n",
      " Regression with ARIMA(0,0,4) errors : -12223.07\n",
      " Regression with ARIMA(2,0,4) errors : -12724.02\n",
      " Regression with ARIMA(3,0,4) errors : -12727\n",
      " Regression with ARIMA(3,0,3) errors : -12699.87\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12728.15\n",
      " Regression with ARIMA(1,0,5) errors : -12698.24\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12723.48\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12683.94\n",
      " Regression with ARIMA(0,0,0) errors : -9138.188\n",
      " Regression with ARIMA(1,0,0) errors : -12661.92\n",
      " Regression with ARIMA(0,0,1) errors : -10809.04\n",
      " Regression with ARIMA(0,0,0) errors : -8146.342\n",
      " Regression with ARIMA(1,0,2) errors : -12678.66\n",
      " Regression with ARIMA(2,0,1) errors : -12676.73\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12704.85\n",
      " Regression with ARIMA(1,0,3) errors : -12707.91\n",
      " Regression with ARIMA(0,0,3) errors : -11899.86\n",
      " Regression with ARIMA(1,0,4) errors : -12705.92\n",
      " Regression with ARIMA(0,0,2) errors : -11462.84\n",
      " Regression with ARIMA(0,0,4) errors : -12239.61\n",
      " Regression with ARIMA(2,0,4) errors : -12733.61\n",
      " Regression with ARIMA(3,0,4) errors : -12727.8\n",
      " Regression with ARIMA(2,0,5) errors : -12736.88\n",
      " Regression with ARIMA(1,0,5) errors : -12708.11\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12658.61\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12738.19\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12707.9\n",
      " Regression with ARIMA(0,0,0) errors : -9146.696\n",
      " Regression with ARIMA(1,0,0) errors : -12685.85\n",
      " Regression with ARIMA(0,0,1) errors : -10816.31\n",
      " Regression with ARIMA(0,0,0) errors : -8145.991\n",
      " Regression with ARIMA(1,0,2) errors : -12701.98\n",
      " Regression with ARIMA(2,0,1) errors : -12702.83\n",
      " Regression with ARIMA(3,0,2) errors : -12752.59\n",
      " Regression with ARIMA(3,0,1) errors : -12716.78\n",
      " Regression with ARIMA(4,0,2) errors : -12776.93\n",
      " Regression with ARIMA(4,0,1) errors : -12738.81\n",
      " Regression with ARIMA(5,0,2) errors : -12750.69\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -12740.15\n",
      " Regression with ARIMA(5,0,1) errors : -12807.17\n",
      " Regression with ARIMA(5,0,0) errors : -12741.34\n",
      " Regression with ARIMA(4,0,0) errors : -12738.7\n",
      " Regression with ARIMA(5,0,1) errors : -12728.9\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12760.88\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12912.84\n",
      " Regression with ARIMA(0,0,0) errors : -9287.558\n",
      " Regression with ARIMA(1,0,0) errors : -12838.23\n",
      " Regression with ARIMA(0,0,1) errors : -10970.44\n",
      " Regression with ARIMA(0,0,0) errors : -8334.607\n",
      " Regression with ARIMA(1,0,2) errors : -12850.07\n",
      " Regression with ARIMA(2,0,1) errors : -12896.83\n",
      " Regression with ARIMA(3,0,2) errors : -12886.59\n",
      " Regression with ARIMA(2,0,3) errors : -12920.49\n",
      " Regression with ARIMA(1,0,3) errors : -12869.31\n",
      " Regression with ARIMA(3,0,3) errors : -12922.93\n",
      " Regression with ARIMA(4,0,3) errors : -12951.22\n",
      " Regression with ARIMA(4,0,2) errors : -12979.64\n",
      " Regression with ARIMA(4,0,1) errors : -12919.17\n",
      " Regression with ARIMA(5,0,2) errors : -13016.01\n",
      " Regression with ARIMA(5,0,1) errors : -12918.05\n",
      " Regression with ARIMA(5,0,3) errors : -13009.45\n",
      " Regression with ARIMA(5,0,2) errors : -12924.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -12851.52\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13340.53\n",
      " Regression with ARIMA(0,0,0) errors : -9896.247\n",
      " Regression with ARIMA(1,0,0) errors : -13321.04\n",
      " Regression with ARIMA(0,0,1) errors : -11543.52\n",
      " Regression with ARIMA(0,0,0) errors : -8940.049\n",
      " Regression with ARIMA(1,0,2) errors : -13322.44\n",
      " Regression with ARIMA(2,0,1) errors : -13321.63\n",
      " Regression with ARIMA(3,0,2) errors : -13355.77\n",
      " Regression with ARIMA(3,0,1) errors : -13337\n",
      " Regression with ARIMA(4,0,2) errors : -13354.79\n",
      " Regression with ARIMA(3,0,3) errors : -13380.32\n",
      " Regression with ARIMA(2,0,3) errors : -13333.79\n",
      " Regression with ARIMA(4,0,3) errors : -13412.84\n",
      " Regression with ARIMA(5,0,3) errors : -13428.89\n",
      " Regression with ARIMA(5,0,2) errors : -13429.21\n",
      " Regression with ARIMA(5,0,1) errors : -13348.63\n",
      " Regression with ARIMA(4,0,1) errors : -13348.07\n",
      " Regression with ARIMA(5,0,2) errors : -13296.63\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13383.36\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13638.8\n",
      " Regression with ARIMA(0,1,0) errors : -13557.1\n",
      " Regression with ARIMA(1,1,0) errors : -13569.73\n",
      " Regression with ARIMA(0,1,1) errors : -13568.98\n",
      " Regression with ARIMA(0,1,0) errors : -13559.1\n",
      " Regression with ARIMA(1,1,2) errors : -13569.88\n",
      " Regression with ARIMA(2,1,1) errors : -13572.21\n",
      " Regression with ARIMA(3,1,2) errors : -13655.74\n",
      " Regression with ARIMA(3,1,1) errors : -13608.61\n",
      " Regression with ARIMA(4,1,2) errors : -13690.96\n",
      " Regression with ARIMA(4,1,1) errors : -13635.24\n",
      " Regression with ARIMA(5,1,2) errors : -13685.37\n",
      " Regression with ARIMA(4,1,3) errors : -13668.95\n",
      " Regression with ARIMA(3,1,3) errors : -13656.78\n",
      " Regression with ARIMA(5,1,1) errors : -13674.36\n",
      " Regression with ARIMA(5,1,3) errors : -13699.07\n",
      " Regression with ARIMA(5,1,4) errors : -13798\n",
      " Regression with ARIMA(4,1,4) errors : -13766.7\n",
      " Regression with ARIMA(5,1,5) errors : -13796.13\n",
      " Regression with ARIMA(4,1,5) errors : -13791.29\n",
      " Regression with ARIMA(5,1,4) errors : -13800.01\n",
      " Regression with ARIMA(4,1,4) errors : -13768.68\n",
      " Regression with ARIMA(5,1,3) errors : -13701.1\n",
      " Regression with ARIMA(5,1,5) errors : -13798.15\n",
      " Regression with ARIMA(4,1,3) errors : -13669.36\n",
      " Regression with ARIMA(4,1,5) errors : -13793.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,4) errors : -13627.14\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13856.97\n",
      " Regression with ARIMA(0,1,0) errors : -13830.28\n",
      " Regression with ARIMA(1,1,0) errors : -13844.83\n",
      " Regression with ARIMA(0,1,1) errors : -13841.77\n",
      " Regression with ARIMA(0,1,0) errors : -13832.29\n",
      " Regression with ARIMA(1,1,2) errors : -13852.88\n",
      " Regression with ARIMA(2,1,1) errors : -13857.98\n",
      " Regression with ARIMA(1,1,1) errors : -13853.24\n",
      " Regression with ARIMA(2,1,0) errors : -13857.59\n",
      " Regression with ARIMA(3,1,1) errors : -13856.45\n",
      " Regression with ARIMA(3,1,0) errors : -13855.79\n",
      " Regression with ARIMA(3,1,2) errors : -13853.87\n",
      " Regression with ARIMA(2,1,1) errors : -13859.99\n",
      " Regression with ARIMA(1,1,1) errors : -13855.24\n",
      " Regression with ARIMA(2,1,0) errors : -13859.61\n",
      " Regression with ARIMA(3,1,1) errors : -13858.47\n",
      " Regression with ARIMA(2,1,2) errors : -13858.99\n",
      " Regression with ARIMA(1,1,0) errors : -13846.84\n",
      " Regression with ARIMA(1,1,2) errors : -13854.88\n",
      " Regression with ARIMA(3,1,0) errors : -13857.8\n",
      " Regression with ARIMA(3,1,2) errors : -13855.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : -13852.22\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,1) errors \n",
      "\n",
      "[1] \"90 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13947.36\n",
      " Regression with ARIMA(0,1,0) errors : -13900.86\n",
      " Regression with ARIMA(1,1,0) errors : -13932.84\n",
      " Regression with ARIMA(0,1,1) errors : -13911.73\n",
      " Regression with ARIMA(0,1,0) errors : -13902.87\n",
      " Regression with ARIMA(1,1,2) errors : -13939.01\n",
      " Regression with ARIMA(2,1,1) errors : -13943.65\n",
      " Regression with ARIMA(3,1,2) errors : -13959.09\n",
      " Regression with ARIMA(3,1,1) errors : -13956.45\n",
      " Regression with ARIMA(4,1,2) errors : -14000.17\n",
      " Regression with ARIMA(4,1,1) errors : -13952.05\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : -14004.61\n",
      " Regression with ARIMA(3,1,3) errors : -13984.19\n",
      " Regression with ARIMA(5,1,3) errors : -14058.98\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : -14034.52\n",
      " Regression with ARIMA(5,1,3) errors : -14060.9\n",
      " Regression with ARIMA(4,1,3) errors : -14006.63\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : -14002.15\n",
      " Regression with ARIMA(4,1,4) errors : -14036.43\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : -13974.19\n",
      "\n",
      " Best model: Regression with ARIMA(4,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14051.09\n",
      " Regression with ARIMA(0,1,0) errors : -14017.53\n",
      " Regression with ARIMA(1,1,0) errors : -14026.02\n",
      " Regression with ARIMA(0,1,1) errors : -14026.4\n",
      " Regression with ARIMA(0,1,0) errors : -14019.51\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14049.92\n",
      " Regression with ARIMA(3,1,2) errors : -14072.45\n",
      " Regression with ARIMA(3,1,1) errors : -14060.26\n",
      " Regression with ARIMA(4,1,2) errors : -14078.94\n",
      " Regression with ARIMA(4,1,1) errors : -14061.76\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : -14126.2\n",
      " Regression with ARIMA(2,1,3) errors : -14050.56\n",
      " Regression with ARIMA(3,1,4) errors : -14077.3\n",
      " Regression with ARIMA(2,1,4) errors : -14048.58\n",
      " Regression with ARIMA(4,1,4) errors : -14193.59\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14215.31\n",
      " Regression with ARIMA(2,1,5) errors : -14059.26\n",
      " Regression with ARIMA(3,1,5) errors : -14216.42\n",
      " Regression with ARIMA(2,1,5) errors : -14061.28\n",
      " Regression with ARIMA(3,1,4) errors : -14177.43\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14050.61\n",
      " Regression with ARIMA(4,1,4) errors : -14194.71\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -14036.04\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14232.72\n",
      " Regression with ARIMA(0,1,0) errors : -14162.77\n",
      " Regression with ARIMA(1,1,0) errors : -14185.38\n",
      " Regression with ARIMA(0,1,1) errors : -14173.07\n",
      " Regression with ARIMA(0,1,0) errors : -14164.75\n",
      " Regression with ARIMA(1,1,2) errors : -14207.81\n",
      " Regression with ARIMA(2,1,1) errors : -14224.23\n",
      " Regression with ARIMA(3,1,2) errors : -14248.4\n",
      " Regression with ARIMA(3,1,1) errors : -14225.86\n",
      " Regression with ARIMA(4,1,2) errors : -14270.04\n",
      " Regression with ARIMA(4,1,1) errors : -14226.79\n",
      " Regression with ARIMA(5,1,2) errors : -14276.69\n",
      " Regression with ARIMA(5,1,1) errors : -14239.31\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : -14278.66\n",
      " Regression with ARIMA(4,1,2) errors : -14272.05\n",
      " Regression with ARIMA(5,1,1) errors : -14241.32\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : -14228.77\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,1) errors : -14188.43\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14269.51\n",
      " Regression with ARIMA(1,1,0) errors : -14280.67\n",
      " Regression with ARIMA(0,1,1) errors : -14275.99\n",
      " Regression with ARIMA(0,1,0) errors : -14271.49\n",
      " Regression with ARIMA(2,1,0) errors : -14280.26\n",
      " Regression with ARIMA(1,1,1) errors : -14283.64\n",
      " Regression with ARIMA(2,1,1) errors : -14282.63\n",
      " Regression with ARIMA(1,1,2) errors : -14281.81\n",
      " Regression with ARIMA(0,1,2) errors : -14276.35\n",
      " Regression with ARIMA(1,1,1) errors : -14285.62\n",
      " Regression with ARIMA(0,1,1) errors : -14277.97\n",
      " Regression with ARIMA(1,1,0) errors : -14282.66\n",
      " Regression with ARIMA(2,1,1) errors : -14284.63\n",
      " Regression with ARIMA(1,1,2) errors : -14283.8\n",
      " Regression with ARIMA(0,1,2) errors : -14278.33\n",
      " Regression with ARIMA(2,1,0) errors : -14282.25\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14292.77\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14392.52\n",
      " Regression with ARIMA(0,1,0) errors : -14319.87\n",
      " Regression with ARIMA(1,1,0) errors : -14323.95\n",
      " Regression with ARIMA(0,1,1) errors : -14324.28\n",
      " Regression with ARIMA(0,1,0) errors : -14321.88\n",
      " Regression with ARIMA(1,1,2) errors : -14328.67\n",
      " Regression with ARIMA(2,1,1) errors : -14322.2\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14396.05\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14397.58\n",
      " Regression with ARIMA(1,1,4) errors : -14325.55\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14409.11\n",
      " Regression with ARIMA(0,1,5) errors : -14329.22\n",
      " Regression with ARIMA(0,1,4) errors : -14322.36\n",
      " Regression with ARIMA(1,1,5) errors : -14410.56\n",
      " Regression with ARIMA(0,1,5) errors : -14331.23\n",
      " Regression with ARIMA(1,1,4) errors : -14327.56\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(0,1,4) errors : -14324.37\n",
      " Regression with ARIMA(2,1,4) errors : -14399.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,5) errors : -14340.4\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14414.39\n",
      " Regression with ARIMA(0,1,0) errors : -14347.05\n",
      " Regression with ARIMA(1,1,0) errors : -14351.5\n",
      " Regression with ARIMA(0,1,1) errors : -14351.98\n",
      " Regression with ARIMA(0,1,0) errors : -14349.06\n",
      " Regression with ARIMA(1,1,2) errors : -14355.74\n",
      " Regression with ARIMA(2,1,1) errors : -14357.14\n",
      " Regression with ARIMA(3,1,2) errors : -14356.58\n",
      " Regression with ARIMA(2,1,3) errors : -14416.78\n",
      " Regression with ARIMA(1,1,3) errors : -14352.44\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14426.08\n",
      " Regression with ARIMA(1,1,4) errors : -14352.46\n",
      " Regression with ARIMA(3,1,4) errors : -14359.23\n",
      " Regression with ARIMA(2,1,5) errors : -14433.08\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14448.43\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14449.79\n",
      " Regression with ARIMA(2,1,5) errors : -14434.5\n",
      " Regression with ARIMA(3,1,4) errors : -14361.25\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14427.62\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14373.05\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14467.17\n",
      " Regression with ARIMA(0,1,0) errors : -14387.79\n",
      " Regression with ARIMA(1,1,0) errors : -14392.42\n",
      " Regression with ARIMA(0,1,1) errors : -14393.12\n",
      " Regression with ARIMA(0,1,0) errors : -14389.79\n",
      " Regression with ARIMA(1,1,2) errors : -14393.52\n",
      " Regression with ARIMA(2,1,1) errors : -14392.46\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14467.02\n",
      " Regression with ARIMA(1,1,1) errors : -14394.63\n",
      " Regression with ARIMA(1,1,3) errors : -14391.52\n",
      " Regression with ARIMA(3,1,1) errors : -14450.2\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -14468.77\n",
      " Regression with ARIMA(1,1,2) errors : -14395.53\n",
      " Regression with ARIMA(2,1,1) errors : -14394.46\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14468.52\n",
      " Regression with ARIMA(1,1,1) errors : -14396.63\n",
      " Regression with ARIMA(1,1,3) errors : -14393.52\n",
      " Regression with ARIMA(3,1,1) errors : -14452.03\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : -14406.82\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11132.19\n",
      " Regression with ARIMA(1,0,0) errors : -14540.36\n",
      " Regression with ARIMA(0,0,1) errors : -12745.99\n",
      " Regression with ARIMA(0,0,0) errors : -9972.371\n",
      " Regression with ARIMA(2,0,0) errors : -14537.54\n",
      " Regression with ARIMA(1,0,1) errors : -14538.45\n",
      " Regression with ARIMA(2,0,1) errors : -14542.87\n",
      " Regression with ARIMA(3,0,1) errors : -14558.56\n",
      " Regression with ARIMA(3,0,0) errors : -14548.35\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -14559.21\n",
      " Regression with ARIMA(4,0,2) errors : -14555.78\n",
      " Regression with ARIMA(3,0,3) errors : -14558.89\n",
      " Regression with ARIMA(2,0,3) errors : -14545.56\n",
      " Regression with ARIMA(4,0,3) errors : -14553.54\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14560.17\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11151.48\n",
      " Regression with ARIMA(1,0,0) errors : -14551.11\n",
      " Regression with ARIMA(0,0,1) errors : -12768.97\n",
      " Regression with ARIMA(0,0,0) errors : -9991.611\n",
      " Regression with ARIMA(2,0,0) errors : -14548.25\n",
      " Regression with ARIMA(1,0,1) errors : -14549.23\n",
      " Regression with ARIMA(2,0,1) errors : -14552.94\n",
      " Regression with ARIMA(3,0,1) errors : -14567.66\n",
      " Regression with ARIMA(3,0,0) errors : -14558.46\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,0) errors : -14557.43\n",
      " Regression with ARIMA(4,0,2) errors : -14572.3\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -14567.45\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,1) errors : -14571.65\n",
      " Regression with ARIMA(5,0,3) errors : -14591.07\n",
      " Regression with ARIMA(5,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -14588.65\n",
      " Regression with ARIMA(5,0,3) errors : -14466.83\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -14592.39\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14560.15\n",
      " Regression with ARIMA(0,0,0) errors : -11132.88\n",
      " Regression with ARIMA(1,0,0) errors : -14543.96\n",
      " Regression with ARIMA(0,0,1) errors : -12748.49\n",
      " Regression with ARIMA(0,0,0) errors : -9916.669\n",
      " Regression with ARIMA(1,0,2) errors : -14552.05\n",
      " Regression with ARIMA(2,0,1) errors : -14544.14\n",
      " Regression with ARIMA(3,0,2) errors : -14551.85\n",
      " Regression with ARIMA(2,0,3) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -14542.09\n",
      " Regression with ARIMA(1,0,3) errors : -14551.93\n",
      " Regression with ARIMA(3,0,1) errors : -14569.13\n",
      " Regression with ARIMA(3,0,0) errors : -14553.2\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -14542.46\n",
      " Regression with ARIMA(4,0,0) errors : -14553.19\n",
      " Regression with ARIMA(4,0,2) errors : -14568.72\n",
      " Regression with ARIMA(3,0,1) errors : -14400.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -14566.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11155.69\n",
      " Regression with ARIMA(1,0,0) errors : -14548.92\n",
      " Regression with ARIMA(0,0,1) errors : -12768.48\n",
      " Regression with ARIMA(0,0,0) errors : -9907.063\n",
      " Regression with ARIMA(2,0,0) errors : -14546.07\n",
      " Regression with ARIMA(1,0,1) errors : -14546.93\n",
      " Regression with ARIMA(2,0,1) errors : -14550.78\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -14554.96\n",
      " Regression with ARIMA(0,0,2) errors : -13588.57\n",
      " Regression with ARIMA(1,0,3) errors : -14555.05\n",
      " Regression with ARIMA(0,0,3) errors : -13929.67\n",
      " Regression with ARIMA(2,0,3) errors : -14552.73\n",
      " Regression with ARIMA(1,0,4) errors : -14561.38\n",
      " Regression with ARIMA(0,0,4) errors : -14217.43\n",
      " Regression with ARIMA(2,0,4) errors : -14559.98\n",
      " Regression with ARIMA(1,0,5) errors : -14560.36\n",
      " Regression with ARIMA(0,0,5) errors : -14327\n",
      " Regression with ARIMA(2,0,5) errors : -14558.11\n",
      " Regression with ARIMA(1,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,4) errors : -14560.62\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14379.34\n",
      " Regression with ARIMA(1,1,0) errors : -14383.72\n",
      " Regression with ARIMA(0,1,1) errors : -14382.54\n",
      " Regression with ARIMA(0,1,0) errors : -14381.35\n",
      " Regression with ARIMA(2,1,0) errors : -14382.72\n",
      " Regression with ARIMA(1,1,1) errors : -14384.5\n",
      " Regression with ARIMA(2,1,1) errors : -14382.23\n",
      " Regression with ARIMA(1,1,2) errors : -14382.66\n",
      " Regression with ARIMA(0,1,2) errors : -14382.21\n",
      " Regression with ARIMA(1,1,1) errors : -14386.51\n",
      " Regression with ARIMA(0,1,1) errors : -14384.55\n",
      " Regression with ARIMA(1,1,0) errors : -14385.73\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : -14384.54\n",
      " Regression with ARIMA(0,1,2) errors : -14384.22\n",
      " Regression with ARIMA(2,1,0) errors : -14384.73\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14397.22\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14483.22\n",
      " Regression with ARIMA(0,0,0) errors : -11017.35\n",
      " Regression with ARIMA(1,0,0) errors : -14460.22\n",
      " Regression with ARIMA(0,0,1) errors : -12640.36\n",
      " Regression with ARIMA(0,0,0) errors : -9780.733\n",
      " Regression with ARIMA(1,0,2) errors : -14467.99\n",
      " Regression with ARIMA(2,0,1) errors : -14461.13\n",
      " Regression with ARIMA(3,0,2) errors : -14483.56\n",
      " Regression with ARIMA(3,0,1) errors : -14483.17\n",
      " Regression with ARIMA(4,0,2) errors : -14480.81\n",
      " Regression with ARIMA(3,0,3) errors : -14482.96\n",
      " Regression with ARIMA(2,0,3) errors : -14464.37\n",
      " Regression with ARIMA(4,0,1) errors : -14477.63\n",
      " Regression with ARIMA(4,0,3) errors : -14478.99\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14477.22\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14498.8\n",
      " Regression with ARIMA(0,0,0) errors : -11029\n",
      " Regression with ARIMA(1,0,0) errors : -14478.15\n",
      " Regression with ARIMA(0,0,1) errors : -12661.86\n",
      " Regression with ARIMA(0,0,0) errors : -9798.577\n",
      " Regression with ARIMA(1,0,2) errors : -14485.32\n",
      " Regression with ARIMA(2,0,1) errors : -14479.56\n",
      " Regression with ARIMA(3,0,2) errors : -14498.67\n",
      " Regression with ARIMA(2,0,3) errors : -14482.25\n",
      " Regression with ARIMA(1,0,1) errors : -14476.18\n",
      " Regression with ARIMA(1,0,3) errors : -14486.49\n",
      " Regression with ARIMA(3,0,1) errors : -14499.33\n",
      " Regression with ARIMA(3,0,0) errors : -14485.04\n",
      " Regression with ARIMA(4,0,1) errors : -14493.81\n",
      " Regression with ARIMA(2,0,0) errors : -14475.19\n",
      " Regression with ARIMA(4,0,0) errors : -14489\n",
      " Regression with ARIMA(4,0,2) errors : -14497.35\n",
      " Regression with ARIMA(3,0,1) errors : -14328.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -14499.04\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14499.82\n",
      " Regression with ARIMA(0,0,0) errors : -11030.92\n",
      " Regression with ARIMA(1,0,0) errors : -14479.83\n",
      " Regression with ARIMA(0,0,1) errors : -12666.18\n",
      " Regression with ARIMA(0,0,0) errors : -9815.953\n",
      " Regression with ARIMA(1,0,2) errors : -14487.24\n",
      " Regression with ARIMA(2,0,1) errors : -14480.13\n",
      " Regression with ARIMA(3,0,2) errors : -14499.16\n",
      " Regression with ARIMA(2,0,3) errors : -14482.98\n",
      " Regression with ARIMA(1,0,1) errors : -14477.85\n",
      " Regression with ARIMA(1,0,3) errors : -14488.5\n",
      " Regression with ARIMA(3,0,1) errors : -14497.61\n",
      " Regression with ARIMA(3,0,3) errors : -14499.03\n",
      " Regression with ARIMA(2,0,2) errors : -14337.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14481.43\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14520.82\n",
      " Regression with ARIMA(0,0,0) errors : -11039.14\n",
      " Regression with ARIMA(1,0,0) errors : -14493.69\n",
      " Regression with ARIMA(0,0,1) errors : -12672\n",
      " Regression with ARIMA(0,0,0) errors : -9822.197\n",
      " Regression with ARIMA(1,0,2) errors : -14500.76\n",
      " Regression with ARIMA(2,0,1) errors : -14497.56\n",
      " Regression with ARIMA(3,0,2) errors : -14524.84\n",
      " Regression with ARIMA(3,0,1) errors : -14518.61\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -14524.22\n",
      " Regression with ARIMA(2,0,3) errors : -14520.02\n",
      " Regression with ARIMA(4,0,1) errors : -14521.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14510.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14421.28\n",
      " Regression with ARIMA(1,1,0) errors : -14438.68\n",
      " Regression with ARIMA(0,1,1) errors : -14424.25\n",
      " Regression with ARIMA(0,1,0) errors : -14423.29\n",
      " Regression with ARIMA(2,1,0) errors : -14439.8\n",
      " Regression with ARIMA(3,1,0) errors : -14439.79\n",
      " Regression with ARIMA(2,1,1) errors : -14444.89\n",
      " Regression with ARIMA(1,1,1) errors : -14446.77\n",
      " Regression with ARIMA(1,1,2) errors : -14444.79\n",
      " Regression with ARIMA(0,1,2) errors : -14423.33\n",
      " Regression with ARIMA(1,1,1) errors : -14448.78\n",
      " Regression with ARIMA(0,1,1) errors : -14426.26\n",
      " Regression with ARIMA(1,1,0) errors : -14440.69\n",
      " Regression with ARIMA(2,1,1) errors : -14446.9\n",
      " Regression with ARIMA(1,1,2) errors : -14446.8\n",
      " Regression with ARIMA(0,1,2) errors : -14425.34\n",
      " Regression with ARIMA(2,1,0) errors : -14441.81\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14440.01\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14553.28\n",
      " Regression with ARIMA(0,1,0) errors : -14483.96\n",
      " Regression with ARIMA(1,1,0) errors : -14484.77\n",
      " Regression with ARIMA(0,1,1) errors : -14485.54\n",
      " Regression with ARIMA(0,1,0) errors : -14485.96\n",
      " Regression with ARIMA(1,1,2) errors : -14488.25\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14562.68\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14567.68\n",
      " Regression with ARIMA(1,1,4) errors : -14484.21\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14585.28\n",
      " Regression with ARIMA(1,1,5) errors : -14492.24\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14586.81\n",
      " Regression with ARIMA(1,1,5) errors : -14494.25\n",
      " Regression with ARIMA(2,1,4) errors : -14569.27\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : -14485.81\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14504.5\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14595.43\n",
      " Regression with ARIMA(0,1,0) errors : -14527.09\n",
      " Regression with ARIMA(1,1,0) errors : -14529.37\n",
      " Regression with ARIMA(0,1,1) errors : -14529.7\n",
      " Regression with ARIMA(0,1,0) errors : -14529.09\n",
      " Regression with ARIMA(1,1,2) errors : -14533.99\n",
      " Regression with ARIMA(2,1,1) errors : -14543.6\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14601.94\n",
      " Regression with ARIMA(1,1,3) errors : -14532.49\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14605.78\n",
      " Regression with ARIMA(1,1,4) errors : -14530.67\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14537.39\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14607.58\n",
      " Regression with ARIMA(1,1,4) errors : -14532.67\n",
      " Regression with ARIMA(2,1,3) errors : -14603.75\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : -14534.49\n",
      " Regression with ARIMA(1,1,5) errors : -14539.39\n",
      " Regression with ARIMA(3,1,3) errors : -14598.8\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14549.06\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14516.87\n",
      " Regression with ARIMA(1,1,0) errors : -14525.36\n",
      " Regression with ARIMA(0,1,1) errors : -14520.46\n",
      " Regression with ARIMA(0,1,0) errors : -14518.88\n",
      " Regression with ARIMA(2,1,0) errors : -14523.87\n",
      " Regression with ARIMA(1,1,1) errors : -14523.58\n",
      " Regression with ARIMA(2,1,1) errors : -14528.44\n",
      " Regression with ARIMA(3,1,1) errors : -14605.73\n",
      " Regression with ARIMA(3,1,0) errors : -14522.73\n",
      " Regression with ARIMA(4,1,1) errors : -14552.02\n",
      " Regression with ARIMA(3,1,2) errors : -14601.37\n",
      " Regression with ARIMA(4,1,0) errors : -14523.8\n",
      " Regression with ARIMA(4,1,2) errors : -14570.42\n",
      " Regression with ARIMA(3,1,1) errors : -14607.28\n",
      " Regression with ARIMA(2,1,1) errors : -14530.46\n",
      " Regression with ARIMA(3,1,0) errors : -14524.74\n",
      " Regression with ARIMA(4,1,1) errors : -14553.78\n",
      " Regression with ARIMA(3,1,2) errors : -14602.92\n",
      " Regression with ARIMA(2,1,0) errors : -14525.88\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,0) errors : -14525.81\n",
      " Regression with ARIMA(4,1,2) errors : -14572.1\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14535.51\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11250.18\n",
      " Regression with ARIMA(1,0,0) errors : -14656.36\n",
      " Regression with ARIMA(0,0,1) errors : -12862.56\n",
      " Regression with ARIMA(0,0,0) errors : -10027.92\n",
      " Regression with ARIMA(2,0,0) errors : -14654.03\n",
      " Regression with ARIMA(1,0,1) errors : -14654.36\n",
      " Regression with ARIMA(2,0,1) errors : -14660.84\n",
      " Regression with ARIMA(3,0,1) errors : -14661.21\n",
      " Regression with ARIMA(3,0,0) errors : -14664.08\n",
      " Regression with ARIMA(4,0,0) errors : -14664.12\n",
      " Regression with ARIMA(5,0,0) errors : -14670.91\n",
      " Regression with ARIMA(5,0,1) errors : -14674.19\n",
      " Regression with ARIMA(4,0,1) errors : -14674.78\n",
      " Regression with ARIMA(4,0,2) errors : -14678.29\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : -14693.27\n",
      " Regression with ARIMA(5,0,3) errors : -14691.32\n",
      " Regression with ARIMA(4,0,3) errors : -14661.91\n",
      " Regression with ARIMA(5,0,2) errors : -14579.72\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -14701.58\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11249.56\n",
      " Regression with ARIMA(1,0,0) errors : -14656.24\n",
      " Regression with ARIMA(0,0,1) errors : -12864.81\n",
      " Regression with ARIMA(0,0,0) errors : -10027.74\n",
      " Regression with ARIMA(2,0,0) errors : -14657.78\n",
      " Regression with ARIMA(3,0,0) errors : -14666.92\n",
      " Regression with ARIMA(4,0,0) errors : -14666.09\n",
      " Regression with ARIMA(3,0,1) errors : -14664.16\n",
      " Regression with ARIMA(2,0,1) errors : -14658.57\n",
      " Regression with ARIMA(4,0,1) errors : -14666.46\n",
      " Regression with ARIMA(3,0,0) errors : -14546.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,0) errors : -14662.78\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m03.2 <- my.tsCV.2(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                      silent=F,\n",
    "                      xreg=trainx[,2:4],\n",
    "                      sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4fa7c88-54f4-4a91-954c-62b4b79f5327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-01-24\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m03.2\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435ab53e-426a-4b91-9d3a-d037e4dd9995",
   "metadata": {},
   "source": [
    "## Regressor mean of smaller period for forecast \n",
    "- Regressor mean for forecast is calculated from the number of latest 'horizon' period\n",
    "- the 1st model used the number of latest 'window' period for the calc of regressor mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "035d6b87-06c6-4440-88ae-98eaf1e6ca7b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14728.24\n",
      " Regression with ARIMA(0,1,0) errors : -14705.76\n",
      " Regression with ARIMA(1,1,0) errors : -14703.21\n",
      " Regression with ARIMA(0,1,1) errors : -14703.85\n",
      " Regression with ARIMA(0,1,0) errors : -14707.74\n",
      " Regression with ARIMA(1,1,2) errors : -14755.07\n",
      " Regression with ARIMA(0,1,2) errors : -14703.58\n",
      " Regression with ARIMA(1,1,1) errors : -14701.2\n",
      " Regression with ARIMA(1,1,3) errors : -14756.2\n",
      " Regression with ARIMA(0,1,3) errors : -14715.69\n",
      " Regression with ARIMA(2,1,3) errors : -14743.68\n",
      " Regression with ARIMA(1,1,4) errors : -14754.84\n",
      " Regression with ARIMA(0,1,4) errors : -14713.96\n",
      " Regression with ARIMA(2,1,4) errors : -14742.53\n",
      " Regression with ARIMA(1,1,3) errors : -14757.92\n",
      " Regression with ARIMA(0,1,3) errors : -14717.66\n",
      " Regression with ARIMA(1,1,2) errors : -14756.77\n",
      " Regression with ARIMA(2,1,3) errors : -14745.4\n",
      " Regression with ARIMA(1,1,4) errors : -14756.51\n",
      " Regression with ARIMA(0,1,2) errors : -14705.55\n",
      " Regression with ARIMA(0,1,4) errors : -14715.93\n",
      " Regression with ARIMA(2,1,2) errors : -14729.97\n",
      " Regression with ARIMA(2,1,4) errors : -14744.25\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14726.99\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14688.58\n",
      " Regression with ARIMA(1,1,0) errors : -14687.3\n",
      " Regression with ARIMA(0,1,1) errors : -14686.7\n",
      " Regression with ARIMA(0,1,0) errors : -14690.58\n",
      " Regression with ARIMA(1,1,1) errors : -14685.35\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14699.9\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14648.88\n",
      " Regression with ARIMA(1,1,0) errors : -14646.36\n",
      " Regression with ARIMA(0,1,1) errors : -14647.06\n",
      " Regression with ARIMA(0,1,0) errors : -14650.88\n",
      " Regression with ARIMA(1,1,1) errors : -14644.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14660.19\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14557.56\n",
      " Regression with ARIMA(1,1,0) errors : -14555.41\n",
      " Regression with ARIMA(0,1,1) errors : -14555.93\n",
      " Regression with ARIMA(0,1,0) errors : -14559.56\n",
      " Regression with ARIMA(1,1,1) errors : -14553.98\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14568.83\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14466.15\n",
      " Regression with ARIMA(1,1,0) errors : -14464.59\n",
      " Regression with ARIMA(0,1,1) errors : -14465.14\n",
      " Regression with ARIMA(0,1,0) errors : -14468.15\n",
      " Regression with ARIMA(1,1,1) errors : -14463.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14477.38\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14431.62\n",
      " Regression with ARIMA(1,1,0) errors : -14429.42\n",
      " Regression with ARIMA(0,1,1) errors : -14430.5\n",
      " Regression with ARIMA(0,1,0) errors : -14433.63\n",
      " Regression with ARIMA(1,1,1) errors : -14428.06\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14442.84\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14487.01\n",
      " Regression with ARIMA(0,1,0) errors : -14420.66\n",
      " Regression with ARIMA(1,1,0) errors : -14418.52\n",
      " Regression with ARIMA(0,1,1) errors : -14419.3\n",
      " Regression with ARIMA(0,1,0) errors : -14422.67\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14487.4\n",
      " Regression with ARIMA(1,1,1) errors : -14416.73\n",
      " Regression with ARIMA(2,1,0) errors : -14420.92\n",
      " Regression with ARIMA(3,1,1) errors : -14426\n",
      " Regression with ARIMA(3,1,0) errors : -14427.6\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14489.16\n",
      " Regression with ARIMA(1,1,1) errors : -14418.75\n",
      " Regression with ARIMA(2,1,0) errors : -14422.93\n",
      " Regression with ARIMA(3,1,1) errors : -14427.99\n",
      " Regression with ARIMA(2,1,2) errors : -14488.71\n",
      " Regression with ARIMA(1,1,0) errors : -14420.53\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -14429.61\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -14440.44\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14445.76\n",
      " Regression with ARIMA(0,1,0) errors : -14415.25\n",
      " Regression with ARIMA(1,1,0) errors : -14413.72\n",
      " Regression with ARIMA(0,1,1) errors : -14413.85\n",
      " Regression with ARIMA(0,1,0) errors : -14417.26\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14433.81\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14468.58\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14468.82\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14469.94\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14471.73\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14470.6\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14426.46\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14421.25\n",
      " Regression with ARIMA(1,1,0) errors : -14418.78\n",
      " Regression with ARIMA(0,1,1) errors : -14419.77\n",
      " Regression with ARIMA(0,1,0) errors : -14423.26\n",
      " Regression with ARIMA(1,1,1) errors : -14417.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14432.47\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14414.4\n",
      " Regression with ARIMA(1,1,0) errors : -14411.72\n",
      " Regression with ARIMA(0,1,1) errors : -14412.71\n",
      " Regression with ARIMA(0,1,0) errors : -14416.41\n",
      " Regression with ARIMA(1,1,1) errors : -14410.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14425.61\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14371.6\n",
      " Regression with ARIMA(1,1,0) errors : -14369.53\n",
      " Regression with ARIMA(0,1,1) errors : -14370.05\n",
      " Regression with ARIMA(0,1,0) errors : -14373.59\n",
      " Regression with ARIMA(1,1,1) errors : -14368.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14382.78\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14319.68\n",
      " Regression with ARIMA(0,1,0) errors : -14316.26\n",
      " Regression with ARIMA(1,1,0) errors : -14313.77\n",
      " Regression with ARIMA(0,1,1) errors : -14314.65\n",
      " Regression with ARIMA(0,1,0) errors : -14318.23\n",
      " Regression with ARIMA(1,1,2) errors : -14385.93\n",
      " Regression with ARIMA(0,1,2) errors : -14319.04\n",
      " Regression with ARIMA(1,1,1) errors : -14312.24\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14327.45\n",
      " Regression with ARIMA(2,1,1) errors : -14356.37\n",
      " Regression with ARIMA(2,1,3) errors : -14367.96\n",
      " Regression with ARIMA(1,1,2) errors : -14387.45\n",
      " Regression with ARIMA(0,1,2) errors : -14321.01\n",
      " Regression with ARIMA(1,1,1) errors : -14314.22\n",
      " Regression with ARIMA(2,1,2) errors : -14321.64\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(0,1,1) errors : -14316.62\n",
      " Regression with ARIMA(0,1,3) errors : -14329.42\n",
      " Regression with ARIMA(2,1,1) errors : -14358.04\n",
      " Regression with ARIMA(2,1,3) errors : -14369.57\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(0,1,3) errors : -14338.56\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14254.7\n",
      " Regression with ARIMA(1,1,0) errors : -14252.25\n",
      " Regression with ARIMA(0,1,1) errors : -14252.87\n",
      " Regression with ARIMA(0,1,0) errors : -14256.7\n",
      " Regression with ARIMA(1,1,1) errors : -14250.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14265.84\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14249.15\n",
      " Regression with ARIMA(1,1,0) errors : -14246.58\n",
      " Regression with ARIMA(0,1,1) errors : -14247.46\n",
      " Regression with ARIMA(0,1,0) errors : -14251.14\n",
      " Regression with ARIMA(1,1,1) errors : -14245.11\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14260.28\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14341.48\n",
      " Regression with ARIMA(0,0,0) errors : -10840.14\n",
      " Regression with ARIMA(1,0,0) errors : -14339.73\n",
      " Regression with ARIMA(0,0,1) errors : -12569.99\n",
      " Regression with ARIMA(0,0,0) errors : -9528.814\n",
      " Regression with ARIMA(1,0,2) errors : -14343.89\n",
      " Regression with ARIMA(0,0,2) errors : -13424.35\n",
      " Regression with ARIMA(1,0,1) errors : -14345.89\n",
      " Regression with ARIMA(2,0,1) errors : -14342.88\n",
      " Regression with ARIMA(2,0,0) errors : -14344.83\n",
      " Regression with ARIMA(1,0,1) errors : -14199.07\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14344.44\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14131.23\n",
      " Regression with ARIMA(1,1,0) errors : -14129.6\n",
      " Regression with ARIMA(0,1,1) errors : -14129.22\n",
      " Regression with ARIMA(0,1,0) errors : -14133.21\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14142.29\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14104.7\n",
      " Regression with ARIMA(1,1,0) errors : -14102.15\n",
      " Regression with ARIMA(0,1,1) errors : -14102.72\n",
      " Regression with ARIMA(0,1,0) errors : -14106.71\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14115.78\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14094.76\n",
      " Regression with ARIMA(1,1,0) errors : -14092.35\n",
      " Regression with ARIMA(0,1,1) errors : -14092.76\n",
      " Regression with ARIMA(0,1,0) errors : -14096.76\n",
      " Regression with ARIMA(1,1,1) errors : -14091.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14105.82\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14158.82\n",
      " Regression with ARIMA(0,1,0) errors : -14086.53\n",
      " Regression with ARIMA(1,1,0) errors : -14083.63\n",
      " Regression with ARIMA(0,1,1) errors : -14084.57\n",
      " Regression with ARIMA(0,1,0) errors : -14088.54\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14155.6\n",
      " Regression with ARIMA(3,1,2) errors : -14153.06\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : -14177.73\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14178.44\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14179.86\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14181.4\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14179.99\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14166.32\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14097.6\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14074.57\n",
      " Regression with ARIMA(1,1,0) errors : -14071.57\n",
      " Regression with ARIMA(0,1,1) errors : -14072.57\n",
      " Regression with ARIMA(0,1,0) errors : -14076.57\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -14085.63\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14156.68\n",
      " Regression with ARIMA(0,0,0) errors : -10543.02\n",
      " Regression with ARIMA(1,0,0) errors : -14157.58\n",
      " Regression with ARIMA(0,0,1) errors : -12288.52\n",
      " Regression with ARIMA(0,0,0) errors : -9161.948\n",
      " Regression with ARIMA(2,0,0) errors : -14160.85\n",
      " Regression with ARIMA(3,0,0) errors : -14159.41\n",
      " Regression with ARIMA(2,0,1) errors : -14158.76\n",
      " Regression with ARIMA(1,0,1) errors : -14161.58\n",
      " Regression with ARIMA(1,0,2) errors : -14159.57\n",
      " Regression with ARIMA(0,0,2) errors : -13166.06\n",
      " Regression with ARIMA(1,0,1) errors : -14036.84\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14160.49\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14097.59\n",
      " Regression with ARIMA(0,0,0) errors : -10474.05\n",
      " Regression with ARIMA(1,0,0) errors : -14096.1\n",
      " Regression with ARIMA(0,0,1) errors : -12234.47\n",
      " Regression with ARIMA(0,0,0) errors : -9152.683\n",
      " Regression with ARIMA(1,0,2) errors : -14099.35\n",
      " Regression with ARIMA(0,0,2) errors : -13115.29\n",
      " Regression with ARIMA(1,0,1) errors : -14101.37\n",
      " Regression with ARIMA(2,0,1) errors : -14098.29\n",
      " Regression with ARIMA(2,0,0) errors : -14100.36\n",
      " Regression with ARIMA(1,0,1) errors : -13962.68\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14100.49\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13956.34\n",
      " Regression with ARIMA(1,1,0) errors : -13954.24\n",
      " Regression with ARIMA(0,1,1) errors : -13954.58\n",
      " Regression with ARIMA(0,1,0) errors : -13958.35\n",
      " Regression with ARIMA(1,1,1) errors : -13952.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13967.35\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13942.25\n",
      " Regression with ARIMA(1,1,0) errors : -13939.51\n",
      " Regression with ARIMA(0,1,1) errors : -13940.54\n",
      " Regression with ARIMA(0,1,0) errors : -13944.26\n",
      " Regression with ARIMA(1,1,1) errors : -13938.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13953.25\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "[1] \"10 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14057.56\n",
      " Regression with ARIMA(0,0,0) errors : -10451.94\n",
      " Regression with ARIMA(1,0,0) errors : -14055.02\n",
      " Regression with ARIMA(0,0,1) errors : -12212.26\n",
      " Regression with ARIMA(0,0,0) errors : -9125.585\n",
      " Regression with ARIMA(1,0,2) errors : -14059.61\n",
      " Regression with ARIMA(0,0,2) errors : -13092.48\n",
      " Regression with ARIMA(1,0,1) errors : -14061.59\n",
      " Regression with ARIMA(2,0,1) errors : -14058.81\n",
      " Regression with ARIMA(2,0,0) errors : -14060.82\n",
      " Regression with ARIMA(1,0,1) errors : -13926.65\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14060.43\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14049.73\n",
      " Regression with ARIMA(0,0,0) errors : -10463.36\n",
      " Regression with ARIMA(1,0,0) errors : -14047.15\n",
      " Regression with ARIMA(0,0,1) errors : -12215.94\n",
      " Regression with ARIMA(0,0,0) errors : -9113.651\n",
      " Regression with ARIMA(1,0,2) errors : -14050.93\n",
      " Regression with ARIMA(0,0,2) errors : -13088.83\n",
      " Regression with ARIMA(1,0,1) errors : -14052.85\n",
      " Regression with ARIMA(2,0,1) errors : -14049.93\n",
      " Regression with ARIMA(2,0,0) errors : -14051.82\n",
      " Regression with ARIMA(1,0,1) errors : -13912.48\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -14051.09\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13911.02\n",
      " Regression with ARIMA(1,1,0) errors : -13908.48\n",
      " Regression with ARIMA(0,1,1) errors : -13909.2\n",
      " Regression with ARIMA(0,1,0) errors : -13913.03\n",
      " Regression with ARIMA(1,1,1) errors : -13907.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13922.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13900.07\n",
      " Regression with ARIMA(1,1,0) errors : -13897.25\n",
      " Regression with ARIMA(0,1,1) errors : -13898.14\n",
      " Regression with ARIMA(0,1,0) errors : -13902.07\n",
      " Regression with ARIMA(1,1,1) errors : -13896.05\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13911.05\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13876.42\n",
      " Regression with ARIMA(0,1,0) errors : -13873.69\n",
      " Regression with ARIMA(1,1,0) errors : -13870.8\n",
      " Regression with ARIMA(0,1,1) errors : -13871.79\n",
      " Regression with ARIMA(0,1,0) errors : -13875.69\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -13951.7\n",
      " Regression with ARIMA(1,1,1) errors : -13869.75\n",
      " Regression with ARIMA(2,1,0) errors : -13877.74\n",
      " Regression with ARIMA(3,1,1) errors : -13879.69\n",
      " Regression with ARIMA(3,1,0) errors : -13878.26\n",
      " Regression with ARIMA(3,1,2) errors : -13880.96\n",
      " Regression with ARIMA(2,1,1) errors : -13953.47\n",
      " Regression with ARIMA(1,1,1) errors : -13871.73\n",
      " Regression with ARIMA(2,1,0) errors : -13879.75\n",
      " Regression with ARIMA(3,1,1) errors : -13881.7\n",
      " Regression with ARIMA(2,1,2) errors : -13878.44\n",
      " Regression with ARIMA(1,1,0) errors : -13872.8\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -13880.27\n",
      " Regression with ARIMA(3,1,2) errors : -13883\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -13906.38\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13861.23\n",
      " Regression with ARIMA(1,1,0) errors : -13858.29\n",
      " Regression with ARIMA(0,1,1) errors : -13859.25\n",
      " Regression with ARIMA(0,1,0) errors : -13863.23\n",
      " Regression with ARIMA(1,1,1) errors : -13857.3\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13872.19\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13896.9\n",
      " Regression with ARIMA(0,0,0) errors : -10196.26\n",
      " Regression with ARIMA(1,0,0) errors : -13893.1\n",
      " Regression with ARIMA(0,0,1) errors : -11966.99\n",
      " Regression with ARIMA(0,0,0) errors : -8742.913\n",
      " Regression with ARIMA(1,0,2) errors : -13897.42\n",
      " Regression with ARIMA(0,0,2) errors : -12878.36\n",
      " Regression with ARIMA(1,0,1) errors : -13899.18\n",
      " Regression with ARIMA(2,0,1) errors : -13896.32\n",
      " Regression with ARIMA(2,0,0) errors : -13897.97\n",
      " Regression with ARIMA(1,0,1) errors : -13775.62\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13898.36\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13779.66\n",
      " Regression with ARIMA(0,0,0) errors : -10097.98\n",
      " Regression with ARIMA(1,0,0) errors : -13771.91\n",
      " Regression with ARIMA(0,0,1) errors : -11865.72\n",
      " Regression with ARIMA(0,0,0) errors : -8710.896\n",
      " Regression with ARIMA(1,0,2) errors : -13777.93\n",
      " Regression with ARIMA(2,0,1) errors : -13777.15\n",
      " Regression with ARIMA(3,0,2) errors : -13783.79\n",
      " Regression with ARIMA(3,0,1) errors : -13778.18\n",
      " Regression with ARIMA(4,0,2) errors : -13782.79\n",
      " Regression with ARIMA(3,0,3) errors : -13790.74\n",
      " Regression with ARIMA(2,0,3) errors : -13778.27\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13781.06\n",
      " Regression with ARIMA(2,0,4) errors : -13781.18\n",
      " Regression with ARIMA(4,0,4) errors : -13783.64\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,3) errors : -13791.61\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13736.94\n",
      " Regression with ARIMA(0,0,0) errors : -10002.66\n",
      " Regression with ARIMA(1,0,0) errors : -13730.41\n",
      " Regression with ARIMA(0,0,1) errors : -11778.89\n",
      " Regression with ARIMA(0,0,0) errors : -8620.765\n",
      " Regression with ARIMA(1,0,2) errors : -13736.26\n",
      " Regression with ARIMA(2,0,1) errors : -13735.25\n",
      " Regression with ARIMA(3,0,2) errors : -13738.48\n",
      " Regression with ARIMA(3,0,1) errors : -13735.53\n",
      " Regression with ARIMA(4,0,2) errors : -13732.51\n",
      " Regression with ARIMA(3,0,3) errors : -13747.21\n",
      " Regression with ARIMA(2,0,3) errors : -13735.02\n",
      " Regression with ARIMA(4,0,3) errors : -13743.42\n",
      " Regression with ARIMA(3,0,4) errors : -13736.01\n",
      " Regression with ARIMA(2,0,4) errors : -13737.88\n",
      " Regression with ARIMA(4,0,4) errors : -13742.31\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,3) errors : -13748.29\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13671.5\n",
      " Regression with ARIMA(0,0,0) errors : -9894.943\n",
      " Regression with ARIMA(1,0,0) errors : -13665.86\n",
      " Regression with ARIMA(0,0,1) errors : -11694.71\n",
      " Regression with ARIMA(0,0,0) errors : -8560.227\n",
      " Regression with ARIMA(1,0,2) errors : -13672.38\n",
      " Regression with ARIMA(0,0,2) errors : -12612.9\n",
      " Regression with ARIMA(1,0,1) errors : -13674.2\n",
      " Regression with ARIMA(2,0,1) errors : -13671.58\n",
      " Regression with ARIMA(2,0,0) errors : -13673.48\n",
      " Regression with ARIMA(1,0,1) errors : -13559.42\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13673.28\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13629.1\n",
      " Regression with ARIMA(0,0,0) errors : -9878.792\n",
      " Regression with ARIMA(1,0,0) errors : -13624.85\n",
      " Regression with ARIMA(0,0,1) errors : -11666.73\n",
      " Regression with ARIMA(0,0,0) errors : -8556.701\n",
      " Regression with ARIMA(1,0,2) errors : -13629.96\n",
      " Regression with ARIMA(0,0,2) errors : -12579.75\n",
      " Regression with ARIMA(1,0,1) errors : -13631.19\n",
      " Regression with ARIMA(2,0,1) errors : -13629.28\n",
      " Regression with ARIMA(2,0,0) errors : -13630.88\n",
      " Regression with ARIMA(1,0,1) errors : -13512.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13630.37\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13611.31\n",
      " Regression with ARIMA(0,0,0) errors : -9870.771\n",
      " Regression with ARIMA(1,0,0) errors : -13607.01\n",
      " Regression with ARIMA(0,0,1) errors : -11652.28\n",
      " Regression with ARIMA(0,0,0) errors : -8549.922\n",
      " Regression with ARIMA(1,0,2) errors : -13611.78\n",
      " Regression with ARIMA(0,0,2) errors : -12567.48\n",
      " Regression with ARIMA(1,0,1) errors : -13612.86\n",
      " Regression with ARIMA(2,0,1) errors : -13620.17\n",
      " Regression with ARIMA(2,0,0) errors : -13612.21\n",
      " Regression with ARIMA(3,0,1) errors : -13610.14\n",
      " Regression with ARIMA(3,0,0) errors : -13609.99\n",
      " Regression with ARIMA(3,0,2) errors : -13609.53\n",
      " Regression with ARIMA(2,0,1) errors : -13511.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13612.06\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13585.71\n",
      " Regression with ARIMA(0,0,0) errors : -9844.615\n",
      " Regression with ARIMA(1,0,0) errors : -13581.02\n",
      " Regression with ARIMA(0,0,1) errors : -11622.06\n",
      " Regression with ARIMA(0,0,0) errors : -8510.432\n",
      " Regression with ARIMA(1,0,2) errors : -13586.32\n",
      " Regression with ARIMA(0,0,2) errors : -12543.41\n",
      " Regression with ARIMA(1,0,1) errors : -13587.02\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -13586.54\n",
      " Regression with ARIMA(1,0,1) errors : -13475.64\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13585.99\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13574.71\n",
      " Regression with ARIMA(0,0,0) errors : -9826.549\n",
      " Regression with ARIMA(1,0,0) errors : -13570.27\n",
      " Regression with ARIMA(0,0,1) errors : -11609.5\n",
      " Regression with ARIMA(0,0,0) errors : -8481.914\n",
      " Regression with ARIMA(1,0,2) errors : -13575.26\n",
      " Regression with ARIMA(0,0,2) errors : -12534.01\n",
      " Regression with ARIMA(1,0,1) errors : -13576.15\n",
      " Regression with ARIMA(2,0,1) errors : -13583.87\n",
      " Regression with ARIMA(2,0,0) errors : -13575.76\n",
      " Regression with ARIMA(3,0,1) errors : -13573.56\n",
      " Regression with ARIMA(3,0,0) errors : -13574.15\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13575.33\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13420.85\n",
      " Regression with ARIMA(1,1,0) errors : -13418.28\n",
      " Regression with ARIMA(0,1,1) errors : -13419.05\n",
      " Regression with ARIMA(0,1,0) errors : -13422.86\n",
      " Regression with ARIMA(1,1,1) errors : -13416.27\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13431.63\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13406.54\n",
      " Regression with ARIMA(1,1,0) errors : -13403.97\n",
      " Regression with ARIMA(0,1,1) errors : -13404.69\n",
      " Regression with ARIMA(0,1,0) errors : -13408.55\n",
      " Regression with ARIMA(1,1,1) errors : -13401.96\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13417.31\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13398.85\n",
      " Regression with ARIMA(1,1,0) errors : -13397.03\n",
      " Regression with ARIMA(0,1,1) errors : -13396.96\n",
      " Regression with ARIMA(0,1,0) errors : -13400.86\n",
      " Regression with ARIMA(1,1,1) errors : -13395.03\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13409.61\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13388.05\n",
      " Regression with ARIMA(1,1,0) errors : -13385.34\n",
      " Regression with ARIMA(0,1,1) errors : -13386.18\n",
      " Regression with ARIMA(0,1,0) errors : -13390.05\n",
      " Regression with ARIMA(1,1,1) errors : -13383.59\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13398.81\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13385.45\n",
      " Regression with ARIMA(1,1,0) errors : -13382.92\n",
      " Regression with ARIMA(0,1,1) errors : -13383.57\n",
      " Regression with ARIMA(0,1,0) errors : -13387.46\n",
      " Regression with ARIMA(1,1,1) errors : -13380.91\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13396.21\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13381.56\n",
      " Regression with ARIMA(1,1,0) errors : -13380.11\n",
      " Regression with ARIMA(0,1,1) errors : -13379.6\n",
      " Regression with ARIMA(0,1,0) errors : -13383.57\n",
      " Regression with ARIMA(1,1,1) errors : -13378.27\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13392.32\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13382.25\n",
      " Regression with ARIMA(1,1,0) errors : -13380.87\n",
      " Regression with ARIMA(0,1,1) errors : -13380.28\n",
      " Regression with ARIMA(0,1,0) errors : -13384.26\n",
      " Regression with ARIMA(1,1,1) errors : -13379.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13393.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13380.14\n",
      " Regression with ARIMA(1,1,0) errors : -13377.47\n",
      " Regression with ARIMA(0,1,1) errors : -13378.15\n",
      " Regression with ARIMA(0,1,0) errors : -13382.15\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.9\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13378.91\n",
      " Regression with ARIMA(1,1,0) errors : -13377.73\n",
      " Regression with ARIMA(0,1,1) errors : -13376.9\n",
      " Regression with ARIMA(0,1,0) errors : -13380.91\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13389.66\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13379.35\n",
      " Regression with ARIMA(1,1,0) errors : -13377.78\n",
      " Regression with ARIMA(0,1,1) errors : -13377.34\n",
      " Regression with ARIMA(0,1,0) errors : -13381.35\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.1\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "[1] \"20 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13379.9\n",
      " Regression with ARIMA(1,1,0) errors : -13377.2\n",
      " Regression with ARIMA(0,1,1) errors : -13377.89\n",
      " Regression with ARIMA(0,1,0) errors : -13381.91\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13390.66\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13381.25\n",
      " Regression with ARIMA(1,1,0) errors : -13378.41\n",
      " Regression with ARIMA(0,1,1) errors : -13379.25\n",
      " Regression with ARIMA(0,1,0) errors : -13383.26\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13392.01\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13376.01\n",
      " Regression with ARIMA(1,1,0) errors : -13373.65\n",
      " Regression with ARIMA(0,1,1) errors : -13374\n",
      " Regression with ARIMA(0,1,0) errors : -13378.02\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13386.77\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -13369.58\n",
      " Regression with ARIMA(1,1,0) errors : -13366.83\n",
      " Regression with ARIMA(0,1,1) errors : -13367.57\n",
      " Regression with ARIMA(0,1,0) errors : -13371.59\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13380.33\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13497.89\n",
      " Regression with ARIMA(0,0,0) errors : -9950.123\n",
      " Regression with ARIMA(1,0,0) errors : -13493.27\n",
      " Regression with ARIMA(0,0,1) errors : -11642.05\n",
      " Regression with ARIMA(0,0,0) errors : -8458.864\n",
      " Regression with ARIMA(1,0,2) errors : -13494.53\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -13496.04\n",
      " Regression with ARIMA(1,0,1) errors : -13495.7\n",
      " Regression with ARIMA(1,0,3) errors : -13492.7\n",
      " Regression with ARIMA(3,0,1) errors : -13497.36\n",
      " Regression with ARIMA(3,0,3) errors : -13498.01\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13507.72\n",
      " Regression with ARIMA(2,0,4) errors : -13500.47\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13500.7\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13506.03\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13499.98\n",
      " Regression with ARIMA(0,0,0) errors : -9960.775\n",
      " Regression with ARIMA(1,0,0) errors : -13495.47\n",
      " Regression with ARIMA(0,0,1) errors : -11645.81\n",
      " Regression with ARIMA(0,0,0) errors : -8453.629\n",
      " Regression with ARIMA(1,0,2) errors : -13496.49\n",
      " Regression with ARIMA(2,0,1) errors : -13507.19\n",
      " Regression with ARIMA(1,0,1) errors : -13497.52\n",
      " Regression with ARIMA(2,0,0) errors : -13496.74\n",
      " Regression with ARIMA(3,0,1) errors : -13497.31\n",
      " Regression with ARIMA(3,0,0) errors : -13495.2\n",
      " Regression with ARIMA(3,0,2) errors : -13495.71\n",
      " Regression with ARIMA(2,0,1) errors : -13378.82\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13506.74\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13497.77\n",
      " Regression with ARIMA(0,0,0) errors : -9958.269\n",
      " Regression with ARIMA(1,0,0) errors : -13494.31\n",
      " Regression with ARIMA(0,0,1) errors : -11644.45\n",
      " Regression with ARIMA(0,0,0) errors : -8449.905\n",
      " Regression with ARIMA(1,0,2) errors : -13495.3\n",
      " Regression with ARIMA(2,0,1) errors : -13507.9\n",
      " Regression with ARIMA(1,0,1) errors : -13496.33\n",
      " Regression with ARIMA(2,0,0) errors : -13495.6\n",
      " Regression with ARIMA(3,0,1) errors : -13496.54\n",
      " Regression with ARIMA(3,0,0) errors : -13493.75\n",
      " Regression with ARIMA(3,0,2) errors : -13495.71\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13508.08\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13493.96\n",
      " Regression with ARIMA(0,0,0) errors : -9977.205\n",
      " Regression with ARIMA(1,0,0) errors : -13489.97\n",
      " Regression with ARIMA(0,0,1) errors : -11647.24\n",
      " Regression with ARIMA(0,0,0) errors : -8450.876\n",
      " Regression with ARIMA(1,0,2) errors : -13490.98\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13488.95\n",
      " Regression with ARIMA(2,0,3) errors : -13487.5\n",
      " Regression with ARIMA(1,0,1) errors : -13492.01\n",
      " Regression with ARIMA(1,0,3) errors : -13489.23\n",
      " Regression with ARIMA(3,0,1) errors : -13492.37\n",
      " Regression with ARIMA(3,0,3) errors : -13486.94\n",
      " Regression with ARIMA(2,0,2) errors : -13356.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.62\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.03\n",
      " Regression with ARIMA(0,0,0) errors : -10035.28\n",
      " Regression with ARIMA(1,0,0) errors : -13487.39\n",
      " Regression with ARIMA(0,0,1) errors : -11673.35\n",
      " Regression with ARIMA(0,0,0) errors : -8457.324\n",
      " Regression with ARIMA(1,0,2) errors : -13488\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13489.24\n",
      " Regression with ARIMA(2,0,3) errors : -13489.21\n",
      " Regression with ARIMA(1,0,1) errors : -13488.93\n",
      " Regression with ARIMA(1,0,3) errors : -13486.24\n",
      " Regression with ARIMA(3,0,1) errors : -13491.09\n",
      " Regression with ARIMA(3,0,0) errors : -13487.21\n",
      " Regression with ARIMA(4,0,1) errors : -13487.57\n",
      " Regression with ARIMA(2,0,0) errors : -13488.97\n",
      " Regression with ARIMA(4,0,0) errors : -13485.19\n",
      " Regression with ARIMA(4,0,2) errors : -13498.14\n",
      " Regression with ARIMA(5,0,2) errors : -13499.05\n",
      " Regression with ARIMA(5,0,1) errors : -13492.88\n",
      " Regression with ARIMA(5,0,3) errors : -13497.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13501.63\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.2\n",
      " Regression with ARIMA(0,0,0) errors : -10019.33\n",
      " Regression with ARIMA(1,0,0) errors : -13487.57\n",
      " Regression with ARIMA(0,0,1) errors : -11667.27\n",
      " Regression with ARIMA(0,0,0) errors : -8455.887\n",
      " Regression with ARIMA(1,0,2) errors : -13488.56\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13489.44\n",
      " Regression with ARIMA(2,0,3) errors : -13490.16\n",
      " Regression with ARIMA(1,0,1) errors : -13489.31\n",
      " Regression with ARIMA(1,0,3) errors : -13486.85\n",
      " Regression with ARIMA(3,0,1) errors : -13491.32\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13350.82\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.68\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13489.2\n",
      " Regression with ARIMA(0,0,0) errors : -10028.88\n",
      " Regression with ARIMA(1,0,0) errors : -13485\n",
      " Regression with ARIMA(0,0,1) errors : -11673.96\n",
      " Regression with ARIMA(0,0,0) errors : -8443.256\n",
      " Regression with ARIMA(1,0,2) errors : -13486.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -13487.2\n",
      " Regression with ARIMA(1,0,1) errors : -13487.01\n",
      " Regression with ARIMA(1,0,3) errors : -13484.63\n",
      " Regression with ARIMA(3,0,1) errors : -13491.48\n",
      " Regression with ARIMA(3,0,0) errors : -13487\n",
      " Regression with ARIMA(4,0,1) errors : -13489.1\n",
      " Regression with ARIMA(2,0,0) errors : -13486.23\n",
      " Regression with ARIMA(4,0,0) errors : -13484.88\n",
      " Regression with ARIMA(4,0,2) errors : -13500.18\n",
      " Regression with ARIMA(5,0,2) errors : -13502.09\n",
      " Regression with ARIMA(5,0,1) errors : -13494.32\n",
      " Regression with ARIMA(5,0,3) errors : -13500.12\n",
      " Regression with ARIMA(4,0,3) errors : -13500.55\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13500.88\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492\n",
      " Regression with ARIMA(0,0,0) errors : -10028.08\n",
      " Regression with ARIMA(1,0,0) errors : -13487.35\n",
      " Regression with ARIMA(0,0,1) errors : -11679.14\n",
      " Regression with ARIMA(0,0,0) errors : -8442.705\n",
      " Regression with ARIMA(1,0,2) errors : -13488.66\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13487.58\n",
      " Regression with ARIMA(2,0,3) errors : -13489.99\n",
      " Regression with ARIMA(1,0,1) errors : -13489.51\n",
      " Regression with ARIMA(1,0,3) errors : -13487.09\n",
      " Regression with ARIMA(3,0,1) errors : -13489.86\n",
      " Regression with ARIMA(3,0,3) errors : -13482.34\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13491.71\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13496.48\n",
      " Regression with ARIMA(0,0,0) errors : -10046.87\n",
      " Regression with ARIMA(1,0,0) errors : -13491.11\n",
      " Regression with ARIMA(0,0,1) errors : -11686.59\n",
      " Regression with ARIMA(0,0,0) errors : -8439.819\n",
      " Regression with ARIMA(1,0,2) errors : -13492.36\n",
      " Regression with ARIMA(2,0,1) errors : -13506.72\n",
      " Regression with ARIMA(1,0,1) errors : -13493.26\n",
      " Regression with ARIMA(2,0,0) errors : -13492.87\n",
      " Regression with ARIMA(3,0,1) errors : -13494.79\n",
      " Regression with ARIMA(3,0,0) errors : -13491.08\n",
      " Regression with ARIMA(3,0,2) errors : -13506.27\n",
      " Regression with ARIMA(2,0,1) errors : -13358.47\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13505.42\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13492.02\n",
      " Regression with ARIMA(0,0,0) errors : -10051.63\n",
      " Regression with ARIMA(1,0,0) errors : -13487.72\n",
      " Regression with ARIMA(0,0,1) errors : -11688.79\n",
      " Regression with ARIMA(0,0,0) errors : -8460.12\n",
      " Regression with ARIMA(1,0,2) errors : -13489\n",
      " Regression with ARIMA(2,0,1) errors : -13501\n",
      " Regression with ARIMA(1,0,1) errors : -13489.93\n",
      " Regression with ARIMA(2,0,0) errors : -13489.16\n",
      " Regression with ARIMA(3,0,1) errors : -13490.72\n",
      " Regression with ARIMA(3,0,0) errors : -13487.43\n",
      " Regression with ARIMA(3,0,2) errors : -13488.68\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13501.14\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13500.43\n",
      " Regression with ARIMA(0,0,0) errors : -10047.97\n",
      " Regression with ARIMA(1,0,0) errors : -13495.4\n",
      " Regression with ARIMA(0,0,1) errors : -11686.73\n",
      " Regression with ARIMA(0,0,0) errors : -8459.472\n",
      " Regression with ARIMA(1,0,2) errors : -13496.66\n",
      " Regression with ARIMA(2,0,1) errors : -13510.38\n",
      " Regression with ARIMA(1,0,1) errors : -13497.58\n",
      " Regression with ARIMA(2,0,0) errors : -13497.07\n",
      " Regression with ARIMA(3,0,1) errors : -13498.19\n",
      " Regression with ARIMA(3,0,0) errors : -13495.29\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13509.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10051.61\n",
      " Regression with ARIMA(1,0,0) errors : -13499.36\n",
      " Regression with ARIMA(0,0,1) errors : -11694.33\n",
      " Regression with ARIMA(0,0,0) errors : -8454.72\n",
      " Regression with ARIMA(2,0,0) errors : -13501.93\n",
      " Regression with ARIMA(3,0,0) errors : -13500.22\n",
      " Regression with ARIMA(2,0,1) errors : -13512.21\n",
      " Regression with ARIMA(1,0,1) errors : -13501.76\n",
      " Regression with ARIMA(3,0,1) errors : -13503.01\n",
      " Regression with ARIMA(1,0,2) errors : -13500.7\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13514.04\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13505.3\n",
      " Regression with ARIMA(0,0,0) errors : -10067.87\n",
      " Regression with ARIMA(1,0,0) errors : -13500.56\n",
      " Regression with ARIMA(0,0,1) errors : -11703.92\n",
      " Regression with ARIMA(0,0,0) errors : -8459.352\n",
      " Regression with ARIMA(1,0,2) errors : -13501.48\n",
      " Regression with ARIMA(2,0,1) errors : -13513.92\n",
      " Regression with ARIMA(1,0,1) errors : -13502.47\n",
      " Regression with ARIMA(2,0,0) errors : -13501.76\n",
      " Regression with ARIMA(3,0,1) errors : -13504.22\n",
      " Regression with ARIMA(3,0,0) errors : -13499.98\n",
      " Regression with ARIMA(3,0,2) errors : -13502.51\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13509.66\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13504.43\n",
      " Regression with ARIMA(0,0,0) errors : -10066.73\n",
      " Regression with ARIMA(1,0,0) errors : -13500.34\n",
      " Regression with ARIMA(0,0,1) errors : -11703.9\n",
      " Regression with ARIMA(0,0,0) errors : -8459.982\n",
      " Regression with ARIMA(1,0,2) errors : -13501.46\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13502.1\n",
      " Regression with ARIMA(2,0,3) errors : -13502.47\n",
      " Regression with ARIMA(1,0,1) errors : -13502.43\n",
      " Regression with ARIMA(1,0,3) errors : -13499.75\n",
      " Regression with ARIMA(3,0,1) errors : -13504.38\n",
      " Regression with ARIMA(3,0,3) errors : -13511.67\n",
      " Regression with ARIMA(4,0,3) errors : -13502.32\n",
      " Regression with ARIMA(3,0,4) errors : -13513.38\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -13510.29\n",
      " Regression with ARIMA(3,0,5) errors : -13505.27\n",
      " Regression with ARIMA(2,0,5) errors : -13506.32\n",
      " Regression with ARIMA(4,0,5) errors : -13507.77\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13512.15\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13504.84\n",
      " Regression with ARIMA(0,0,0) errors : -10082.23\n",
      " Regression with ARIMA(1,0,0) errors : -13499.69\n",
      " Regression with ARIMA(0,0,1) errors : -11711.37\n",
      " Regression with ARIMA(0,0,0) errors : -8482.428\n",
      " Regression with ARIMA(1,0,2) errors : -13500.44\n",
      " Regression with ARIMA(2,0,1) errors : -13506.21\n",
      " Regression with ARIMA(1,0,1) errors : -13501.67\n",
      " Regression with ARIMA(2,0,0) errors : -13507.48\n",
      " Regression with ARIMA(3,0,0) errors : -13505.43\n",
      " Regression with ARIMA(3,0,1) errors : -13508.06\n",
      " Regression with ARIMA(4,0,1) errors : -13504.51\n",
      " Regression with ARIMA(3,0,2) errors : -13507\n",
      " Regression with ARIMA(4,0,0) errors : -13503.26\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -13503.39\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13511.77\n",
      " Regression with ARIMA(0,0,0) errors : -10089.38\n",
      " Regression with ARIMA(1,0,0) errors : -13508.45\n",
      " Regression with ARIMA(0,0,1) errors : -11717.82\n",
      " Regression with ARIMA(0,0,0) errors : -8486.146\n",
      " Regression with ARIMA(1,0,2) errors : -13508.73\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13508.14\n",
      " Regression with ARIMA(2,0,3) errors : -13509.84\n",
      " Regression with ARIMA(1,0,1) errors : -13509.99\n",
      " Regression with ARIMA(1,0,3) errors : -13507.09\n",
      " Regression with ARIMA(3,0,1) errors : -13509.92\n",
      " Regression with ARIMA(3,0,3) errors : -13517.49\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13519.73\n",
      " Regression with ARIMA(2,0,4) errors : -13513.32\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13514.28\n",
      " Regression with ARIMA(4,0,5) errors : -13514.96\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13520.01\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13510.51\n",
      " Regression with ARIMA(0,0,0) errors : -10105.18\n",
      " Regression with ARIMA(1,0,0) errors : -13507.88\n",
      " Regression with ARIMA(0,0,1) errors : -11721.86\n",
      " Regression with ARIMA(0,0,0) errors : -8493.114\n",
      " Regression with ARIMA(1,0,2) errors : -13508.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13516.56\n",
      " Regression with ARIMA(3,0,1) errors : -13506.85\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13515.63\n",
      " Regression with ARIMA(2,0,3) errors : -13508.55\n",
      " Regression with ARIMA(4,0,1) errors : -13509.07\n",
      " Regression with ARIMA(4,0,3) errors : -13513.32\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13519.6\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13508.31\n",
      " Regression with ARIMA(0,0,0) errors : -10126.55\n",
      " Regression with ARIMA(1,0,0) errors : -13507.44\n",
      " Regression with ARIMA(0,0,1) errors : -11732.75\n",
      " Regression with ARIMA(0,0,0) errors : -8479.726\n",
      " Regression with ARIMA(1,0,2) errors : -13507.67\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13508.26\n",
      " Regression with ARIMA(2,0,3) errors : -13506.52\n",
      " Regression with ARIMA(1,0,1) errors : -13508.92\n",
      " Regression with ARIMA(0,0,2) errors : -12538.44\n",
      " Regression with ARIMA(2,0,0) errors : -13508.97\n",
      " Regression with ARIMA(3,0,0) errors : -13506.81\n",
      " Regression with ARIMA(3,0,1) errors : -13510.29\n",
      " Regression with ARIMA(4,0,1) errors : -13507.38\n",
      " Regression with ARIMA(4,0,0) errors : -13504.51\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -13510.44\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10215.23\n",
      " Regression with ARIMA(1,0,0) errors : -13503.24\n",
      " Regression with ARIMA(0,0,1) errors : -11765.85\n",
      " Regression with ARIMA(0,0,0) errors : -8496.584\n",
      " Regression with ARIMA(2,0,0) errors : -13503.84\n",
      " Regression with ARIMA(3,0,0) errors : -13502.9\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13504.35\n",
      " Regression with ARIMA(1,0,2) errors : -13503.03\n",
      " Regression with ARIMA(0,0,2) errors : -12548.3\n",
      " Regression with ARIMA(1,0,1) errors : -13380.69\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13503.51\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10218.34\n",
      " Regression with ARIMA(1,0,0) errors : -13503.41\n",
      " Regression with ARIMA(0,0,1) errors : -11768.16\n",
      " Regression with ARIMA(0,0,0) errors : -8499.03\n",
      " Regression with ARIMA(2,0,0) errors : -13503.77\n",
      " Regression with ARIMA(3,0,0) errors : -13502.7\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13504.25\n",
      " Regression with ARIMA(1,0,2) errors : -13502.87\n",
      " Regression with ARIMA(0,0,2) errors : -12542.4\n",
      " Regression with ARIMA(1,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,1) errors : -13503.42\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,1) errors \n",
      "\n",
      "[1] \"30 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13509.32\n",
      " Regression with ARIMA(0,0,0) errors : -10219.25\n",
      " Regression with ARIMA(1,0,0) errors : -13507.76\n",
      " Regression with ARIMA(0,0,1) errors : -11765.04\n",
      " Regression with ARIMA(0,0,0) errors : -8502.109\n",
      " Regression with ARIMA(1,0,2) errors : -13506.99\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13502.83\n",
      " Regression with ARIMA(2,0,3) errors : -13507.36\n",
      " Regression with ARIMA(1,0,1) errors : -13508.29\n",
      " Regression with ARIMA(1,0,3) errors : -13505.45\n",
      " Regression with ARIMA(3,0,1) errors : -13506.88\n",
      " Regression with ARIMA(3,0,3) errors : -13513.93\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13514.85\n",
      " Regression with ARIMA(2,0,4) errors : -13509.02\n",
      " Regression with ARIMA(4,0,4) errors : -13512.96\n",
      " Regression with ARIMA(3,0,5) errors : -13508.01\n",
      " Regression with ARIMA(2,0,5) errors : -13510.83\n",
      " Regression with ARIMA(4,0,5) errors : -13505.08\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13517.28\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10222.58\n",
      " Regression with ARIMA(1,0,0) errors : -13506.49\n",
      " Regression with ARIMA(0,0,1) errors : -11761.77\n",
      " Regression with ARIMA(0,0,0) errors : -8501.931\n",
      " Regression with ARIMA(2,0,0) errors : -13505.83\n",
      " Regression with ARIMA(1,0,1) errors : -13506.71\n",
      " Regression with ARIMA(2,0,1) errors : -13516.88\n",
      " Regression with ARIMA(3,0,1) errors : -13512.26\n",
      " Regression with ARIMA(1,0,2) errors : -13505.56\n",
      " Regression with ARIMA(3,0,0) errors : -13505.02\n",
      " Regression with ARIMA(3,0,2) errors : -13499.27\n",
      " Regression with ARIMA(2,0,1) errors : -13367.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13503.41\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13512.51\n",
      " Regression with ARIMA(0,0,0) errors : -10227.27\n",
      " Regression with ARIMA(1,0,0) errors : -13513.98\n",
      " Regression with ARIMA(0,0,1) errors : -11762.97\n",
      " Regression with ARIMA(0,0,0) errors : -8502.27\n",
      " Regression with ARIMA(2,0,0) errors : -13514.25\n",
      " Regression with ARIMA(3,0,0) errors : -13513.04\n",
      " Regression with ARIMA(2,0,1) errors : -13512.24\n",
      " Regression with ARIMA(1,0,1) errors : -13514.02\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -13380.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,0) errors : -13511.98\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13526.34\n",
      " Regression with ARIMA(0,0,0) errors : -10223.66\n",
      " Regression with ARIMA(1,0,0) errors : -13526.45\n",
      " Regression with ARIMA(0,0,1) errors : -11757.01\n",
      " Regression with ARIMA(0,0,0) errors : -8519.276\n",
      " Regression with ARIMA(2,0,0) errors : -13525.32\n",
      " Regression with ARIMA(1,0,1) errors : -13526.23\n",
      " Regression with ARIMA(2,0,1) errors : -13535.26\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13525.01\n",
      " Regression with ARIMA(3,0,0) errors : -13523.41\n",
      " Regression with ARIMA(3,0,2) errors : -13520.69\n",
      " Regression with ARIMA(2,0,1) errors : -13408.03\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13521.31\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10227.11\n",
      " Regression with ARIMA(1,0,0) errors : -13535.83\n",
      " Regression with ARIMA(0,0,1) errors : -11776.31\n",
      " Regression with ARIMA(0,0,0) errors : -8558.409\n",
      " Regression with ARIMA(2,0,0) errors : -13535.04\n",
      " Regression with ARIMA(1,0,1) errors : -13535.63\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13535.07\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10239.17\n",
      " Regression with ARIMA(1,0,0) errors : -13532.83\n",
      " Regression with ARIMA(0,0,1) errors : -11782.72\n",
      " Regression with ARIMA(0,0,0) errors : -8566.374\n",
      " Regression with ARIMA(2,0,0) errors : -13533.02\n",
      " Regression with ARIMA(3,0,0) errors : -13531.58\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -13532.77\n",
      " Regression with ARIMA(3,0,1) errors : -13532.73\n",
      " Regression with ARIMA(2,0,0) errors : -13415.66\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,0) errors : -13531.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13539.55\n",
      " Regression with ARIMA(0,0,0) errors : -10238.93\n",
      " Regression with ARIMA(1,0,0) errors : -13540.07\n",
      " Regression with ARIMA(0,0,1) errors : -11784.97\n",
      " Regression with ARIMA(0,0,0) errors : -8571.174\n",
      " Regression with ARIMA(2,0,0) errors : -13539.5\n",
      " Regression with ARIMA(1,0,1) errors : -13540.16\n",
      " Regression with ARIMA(2,0,1) errors : -13549.2\n",
      " Regression with ARIMA(3,0,1) errors : -13539.61\n",
      " Regression with ARIMA(1,0,2) errors : -13539.06\n",
      " Regression with ARIMA(3,0,0) errors : -13537.64\n",
      " Regression with ARIMA(3,0,2) errors : -13537.96\n",
      " Regression with ARIMA(2,0,1) errors : -13400.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13550.1\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13537.09\n",
      " Regression with ARIMA(0,0,0) errors : -10239.99\n",
      " Regression with ARIMA(1,0,0) errors : -13540.98\n",
      " Regression with ARIMA(0,0,1) errors : -11788.21\n",
      " Regression with ARIMA(0,0,0) errors : -8584.355\n",
      " Regression with ARIMA(2,0,0) errors : -13540.68\n",
      " Regression with ARIMA(1,0,1) errors : -13540.96\n",
      " Regression with ARIMA(2,0,1) errors : -13550.79\n",
      " Regression with ARIMA(3,0,1) errors : -13544.63\n",
      " Regression with ARIMA(1,0,2) errors : -13539.89\n",
      " Regression with ARIMA(3,0,0) errors : -13538.95\n",
      " Regression with ARIMA(3,0,2) errors : -13543.48\n",
      " Regression with ARIMA(2,0,1) errors : -13423.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,1) errors : -13541.93\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13563.2\n",
      " Regression with ARIMA(0,0,0) errors : -10221.42\n",
      " Regression with ARIMA(1,0,0) errors : -13558.89\n",
      " Regression with ARIMA(0,0,1) errors : -11783.59\n",
      " Regression with ARIMA(0,0,0) errors : -8587.344\n",
      " Regression with ARIMA(1,0,2) errors : -13557.75\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13560.36\n",
      " Regression with ARIMA(2,0,3) errors : -13561.2\n",
      " Regression with ARIMA(1,0,1) errors : -13558.83\n",
      " Regression with ARIMA(1,0,3) errors : -13556.36\n",
      " Regression with ARIMA(3,0,1) errors : -13562.66\n",
      " Regression with ARIMA(3,0,3) errors : -13569.83\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -13571.17\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -13563.95\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13566.38\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -13567.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13570.4\n",
      " Regression with ARIMA(0,0,0) errors : -10190.39\n",
      " Regression with ARIMA(1,0,0) errors : -13568.75\n",
      " Regression with ARIMA(0,0,1) errors : -11771.15\n",
      " Regression with ARIMA(0,0,0) errors : -8593.643\n",
      " Regression with ARIMA(1,0,2) errors : -13567.8\n",
      " Regression with ARIMA(2,0,1) errors : -13578.25\n",
      " Regression with ARIMA(1,0,1) errors : -13568.87\n",
      " Regression with ARIMA(2,0,0) errors : -13567.98\n",
      " Regression with ARIMA(3,0,1) errors : -13566.18\n",
      " Regression with ARIMA(3,0,0) errors : -13566.18\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : -13449.02\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13568.25\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13634.9\n",
      " Regression with ARIMA(0,0,0) errors : -10190.23\n",
      " Regression with ARIMA(1,0,0) errors : -13630.94\n",
      " Regression with ARIMA(0,0,1) errors : -11790.6\n",
      " Regression with ARIMA(0,0,0) errors : -8611.59\n",
      " Regression with ARIMA(1,0,2) errors : -13631.17\n",
      " Regression with ARIMA(2,0,1) errors : -13641.72\n",
      " Regression with ARIMA(1,0,1) errors : -13631.97\n",
      " Regression with ARIMA(2,0,0) errors : -13632.33\n",
      " Regression with ARIMA(3,0,1) errors : -13630.61\n",
      " Regression with ARIMA(3,0,0) errors : -13630.85\n",
      " Regression with ARIMA(3,0,2) errors : -13642.1\n",
      " Regression with ARIMA(4,0,2) errors : -13636.63\n",
      " Regression with ARIMA(3,0,3) errors : -13640.47\n",
      " Regression with ARIMA(2,0,3) errors : -13632.93\n",
      " Regression with ARIMA(4,0,1) errors : -13631.33\n",
      " Regression with ARIMA(4,0,3) errors : -13636.07\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13640.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13645.23\n",
      " Regression with ARIMA(0,0,0) errors : -10202.47\n",
      " Regression with ARIMA(1,0,0) errors : -13645.74\n",
      " Regression with ARIMA(0,0,1) errors : -11804.3\n",
      " Regression with ARIMA(0,0,0) errors : -8622.517\n",
      " Regression with ARIMA(2,0,0) errors : -13646.54\n",
      " Regression with ARIMA(3,0,0) errors : -13646.95\n",
      " Regression with ARIMA(4,0,0) errors : -13644.57\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -13646.54\n",
      " Regression with ARIMA(3,0,0) errors : -13536.11\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,0) errors : -13645.14\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13662.78\n",
      " Regression with ARIMA(0,0,0) errors : -10203.12\n",
      " Regression with ARIMA(1,0,0) errors : -13661.7\n",
      " Regression with ARIMA(0,0,1) errors : -11801.53\n",
      " Regression with ARIMA(0,0,0) errors : -8623.09\n",
      " Regression with ARIMA(1,0,2) errors : -13661.65\n",
      " Regression with ARIMA(2,0,1) errors : -13670.27\n",
      " Regression with ARIMA(1,0,1) errors : -13662.54\n",
      " Regression with ARIMA(2,0,0) errors : -13662.03\n",
      " Regression with ARIMA(3,0,1) errors : -13660.85\n",
      " Regression with ARIMA(3,0,0) errors : -13660.75\n",
      " Regression with ARIMA(3,0,2) errors : -13668.59\n",
      " Regression with ARIMA(2,0,1) errors : -13554.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13669.89\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13665.71\n",
      " Regression with ARIMA(0,0,0) errors : -10188.87\n",
      " Regression with ARIMA(1,0,0) errors : -13663.7\n",
      " Regression with ARIMA(0,0,1) errors : -11795.42\n",
      " Regression with ARIMA(0,0,0) errors : -8643.892\n",
      " Regression with ARIMA(1,0,2) errors : -13663.8\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13660.35\n",
      " Regression with ARIMA(2,0,3) errors : -13663.69\n",
      " Regression with ARIMA(1,0,1) errors : -13664.64\n",
      " Regression with ARIMA(1,0,3) errors : -13662.17\n",
      " Regression with ARIMA(3,0,1) errors : -13664.67\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : -13565.22\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13665.83\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13656.64\n",
      " Regression with ARIMA(0,0,0) errors : -10191.97\n",
      " Regression with ARIMA(1,0,0) errors : -13653.06\n",
      " Regression with ARIMA(0,0,1) errors : -11788.05\n",
      " Regression with ARIMA(0,0,0) errors : -8651.602\n",
      " Regression with ARIMA(1,0,2) errors : -13653.54\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13653.21\n",
      " Regression with ARIMA(2,0,3) errors : -13654.62\n",
      " Regression with ARIMA(1,0,1) errors : -13654.33\n",
      " Regression with ARIMA(1,0,3) errors : -13651.95\n",
      " Regression with ARIMA(3,0,1) errors : -13655.42\n",
      " Regression with ARIMA(3,0,3) errors : -13661.07\n",
      " Regression with ARIMA(4,0,3) errors : -13648.86\n",
      " Regression with ARIMA(3,0,4) errors : -13662.96\n",
      " Regression with ARIMA(2,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13661.06\n",
      " Regression with ARIMA(4,0,5) errors : -13659.57\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -13659.73\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13649.41\n",
      " Regression with ARIMA(0,0,0) errors : -10167.99\n",
      " Regression with ARIMA(1,0,0) errors : -13648.99\n",
      " Regression with ARIMA(0,0,1) errors : -11774.26\n",
      " Regression with ARIMA(0,0,0) errors : -8653.868\n",
      " Regression with ARIMA(1,0,2) errors : -13649.56\n",
      " Regression with ARIMA(0,0,2) errors : -12612.9\n",
      " Regression with ARIMA(1,0,1) errors : -13650.24\n",
      " Regression with ARIMA(2,0,1) errors : -13660.4\n",
      " Regression with ARIMA(2,0,0) errors : -13649.71\n",
      " Regression with ARIMA(3,0,1) errors : -13651.41\n",
      " Regression with ARIMA(3,0,0) errors : -13648.4\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13661.18\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13655.63\n",
      " Regression with ARIMA(0,0,0) errors : -10165.57\n",
      " Regression with ARIMA(1,0,0) errors : -13654.18\n",
      " Regression with ARIMA(0,0,1) errors : -11773.14\n",
      " Regression with ARIMA(0,0,0) errors : -8656.522\n",
      " Regression with ARIMA(1,0,2) errors : -13654.42\n",
      " Regression with ARIMA(2,0,1) errors : -13665.49\n",
      " Regression with ARIMA(1,0,1) errors : -13655.18\n",
      " Regression with ARIMA(2,0,0) errors : -13654.5\n",
      " Regression with ARIMA(3,0,1) errors : -13655.23\n",
      " Regression with ARIMA(3,0,0) errors : -13653.04\n",
      " Regression with ARIMA(3,0,2) errors : -13653.31\n",
      " Regression with ARIMA(2,0,1) errors : -13554.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13666.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13657.3\n",
      " Regression with ARIMA(0,0,0) errors : -10165.83\n",
      " Regression with ARIMA(1,0,0) errors : -13655.15\n",
      " Regression with ARIMA(0,0,1) errors : -11771.76\n",
      " Regression with ARIMA(0,0,0) errors : -8655.923\n",
      " Regression with ARIMA(1,0,2) errors : -13655.23\n",
      " Regression with ARIMA(2,0,1) errors : -13667.08\n",
      " Regression with ARIMA(1,0,1) errors : -13656.02\n",
      " Regression with ARIMA(2,0,0) errors : -13655.19\n",
      " Regression with ARIMA(3,0,1) errors : -13655.86\n",
      " Regression with ARIMA(3,0,0) errors : -13658.04\n",
      " Regression with ARIMA(3,0,2) errors : -13655.29\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13666.52\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13655.6\n",
      " Regression with ARIMA(0,0,0) errors : -10159.47\n",
      " Regression with ARIMA(1,0,0) errors : -13654.74\n",
      " Regression with ARIMA(0,0,1) errors : -11765.48\n",
      " Regression with ARIMA(0,0,0) errors : -8662.39\n",
      " Regression with ARIMA(1,0,2) errors : -13655.14\n",
      " Regression with ARIMA(2,0,1) errors : -13671.56\n",
      " Regression with ARIMA(1,0,1) errors : -13655.72\n",
      " Regression with ARIMA(2,0,0) errors : -13656.86\n",
      " Regression with ARIMA(3,0,1) errors : -13656.12\n",
      " Regression with ARIMA(3,0,0) errors : -13655.95\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13665.81\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13656.79\n",
      " Regression with ARIMA(0,0,0) errors : -10173.96\n",
      " Regression with ARIMA(1,0,0) errors : -13652.05\n",
      " Regression with ARIMA(0,0,1) errors : -11777.5\n",
      " Regression with ARIMA(0,0,0) errors : -8700.468\n",
      " Regression with ARIMA(1,0,2) errors : -13652.23\n",
      " Regression with ARIMA(2,0,1) errors : -13668.02\n",
      " Regression with ARIMA(1,0,1) errors : -13652.1\n",
      " Regression with ARIMA(2,0,0) errors : -13652.19\n",
      " Regression with ARIMA(3,0,1) errors : -13656.11\n",
      " Regression with ARIMA(3,0,0) errors : -13652.01\n",
      " Regression with ARIMA(3,0,2) errors : -13662.39\n",
      " Regression with ARIMA(2,0,1) errors : -13548.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13662.69\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13625.68\n",
      " Regression with ARIMA(0,1,0) errors : -13621.46\n",
      " Regression with ARIMA(1,1,0) errors : -13624.34\n",
      " Regression with ARIMA(0,1,1) errors : -13619.6\n",
      " Regression with ARIMA(0,1,0) errors : -13623.47\n",
      " Regression with ARIMA(1,1,2) errors : -13629.17\n",
      " Regression with ARIMA(0,1,2) errors : -13617.77\n",
      " Regression with ARIMA(1,1,1) errors : -13628.01\n",
      " Regression with ARIMA(1,1,3) errors : -13633.78\n",
      " Regression with ARIMA(0,1,3) errors : -13616.46\n",
      " Regression with ARIMA(2,1,3) errors : -13627.37\n",
      " Regression with ARIMA(1,1,4) errors : -13638.05\n",
      " Regression with ARIMA(0,1,4) errors : -13614.88\n",
      " Regression with ARIMA(2,1,4) errors : -13627.68\n",
      " Regression with ARIMA(1,1,5) errors : -13657.04\n",
      " Regression with ARIMA(0,1,5) errors : -13617.4\n",
      " Regression with ARIMA(2,1,5) errors : -13647.25\n",
      " Regression with ARIMA(1,1,5) errors : -13658.92\n",
      " Regression with ARIMA(0,1,5) errors : -13619.42\n",
      " Regression with ARIMA(1,1,4) errors : -13639.93\n",
      " Regression with ARIMA(2,1,5) errors : -13649.14\n",
      " Regression with ARIMA(0,1,4) errors : -13616.89\n",
      " Regression with ARIMA(2,1,4) errors : -13629.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,0) errors : -13628.45\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13669.46\n",
      " Regression with ARIMA(0,1,0) errors : -13667.96\n",
      " Regression with ARIMA(1,1,0) errors : -13665.88\n",
      " Regression with ARIMA(0,1,1) errors : -13666.47\n",
      " Regression with ARIMA(0,1,0) errors : -13669.95\n",
      " Regression with ARIMA(1,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(0,1,0) errors : -13678.82\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10272.74\n",
      " Regression with ARIMA(1,0,0) errors : -13772.01\n",
      " Regression with ARIMA(0,0,1) errors : -11891.74\n",
      " Regression with ARIMA(0,0,0) errors : -8843.671\n",
      " Regression with ARIMA(2,0,0) errors : -13770.9\n",
      " Regression with ARIMA(1,0,1) errors : -13771.44\n",
      " Regression with ARIMA(2,0,1) errors : -13785.75\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13772.19\n",
      " Regression with ARIMA(3,0,0) errors : -13772.31\n",
      " Regression with ARIMA(3,0,2) errors : -13785.11\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : -13783.28\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13764.52\n",
      " Regression with ARIMA(0,0,0) errors : -10268.04\n",
      " Regression with ARIMA(1,0,0) errors : -13761.23\n",
      " Regression with ARIMA(0,0,1) errors : -11885.1\n",
      " Regression with ARIMA(0,0,0) errors : -8858.715\n",
      " Regression with ARIMA(1,0,2) errors : -13761.55\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13782.76\n",
      " Regression with ARIMA(3,0,1) errors : -13780.45\n",
      " Regression with ARIMA(4,0,2) errors : -13778.02\n",
      " Regression with ARIMA(3,0,3) errors : -13780.93\n",
      " Regression with ARIMA(2,0,3) errors : -13762.9\n",
      " Regression with ARIMA(4,0,1) errors : -13774.34\n",
      " Regression with ARIMA(4,0,3) errors : -13775.95\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13775.78\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "[1] \"40 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13769.81\n",
      " Regression with ARIMA(0,0,0) errors : -10265.3\n",
      " Regression with ARIMA(1,0,0) errors : -13762.85\n",
      " Regression with ARIMA(0,0,1) errors : -11881.84\n",
      " Regression with ARIMA(0,0,0) errors : -8821.143\n",
      " Regression with ARIMA(1,0,2) errors : -13762.57\n",
      " Regression with ARIMA(2,0,1) errors : -13768.3\n",
      " Regression with ARIMA(3,0,2) errors : -13783.22\n",
      " Regression with ARIMA(3,0,1) errors : -13768.49\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13781.28\n",
      " Regression with ARIMA(2,0,3) errors : -13768.18\n",
      " Regression with ARIMA(4,0,1) errors : -13769.2\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -13777.69\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13769.38\n",
      " Regression with ARIMA(0,0,0) errors : -10260.46\n",
      " Regression with ARIMA(1,0,0) errors : -13763.75\n",
      " Regression with ARIMA(0,0,1) errors : -11877.06\n",
      " Regression with ARIMA(0,0,0) errors : -8820.979\n",
      " Regression with ARIMA(1,0,2) errors : -13763.9\n",
      " Regression with ARIMA(2,0,1) errors : -13767.21\n",
      " Regression with ARIMA(3,0,2) errors : -13781.12\n",
      " Regression with ARIMA(3,0,1) errors : -13768.51\n",
      " Regression with ARIMA(4,0,2) errors : -13781.64\n",
      " Regression with ARIMA(4,0,1) errors : -13767.06\n",
      " Regression with ARIMA(5,0,2) errors : -13779.5\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -13781.37\n",
      " Regression with ARIMA(5,0,1) errors : -13775.92\n",
      " Regression with ARIMA(5,0,3) errors : -13777.89\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,2) errors : -13774.84\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13730.6\n",
      " Regression with ARIMA(0,0,0) errors : -10252.14\n",
      " Regression with ARIMA(1,0,0) errors : -13734.15\n",
      " Regression with ARIMA(0,0,1) errors : -11865.14\n",
      " Regression with ARIMA(0,0,0) errors : -8811.741\n",
      " Regression with ARIMA(2,0,0) errors : -13732.86\n",
      " Regression with ARIMA(1,0,1) errors : -13733.55\n",
      " Regression with ARIMA(2,0,1) errors : -13745.03\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -13733.84\n",
      " Regression with ARIMA(3,0,0) errors : -13732.77\n",
      " Regression with ARIMA(3,0,2) errors : -13730.31\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13733.34\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10248.64\n",
      " Regression with ARIMA(1,0,0) errors : -13726.11\n",
      " Regression with ARIMA(0,0,1) errors : -11859.38\n",
      " Regression with ARIMA(0,0,0) errors : -8814.75\n",
      " Regression with ARIMA(2,0,0) errors : -13726.2\n",
      " Regression with ARIMA(3,0,0) errors : -13726.52\n",
      " Regression with ARIMA(4,0,0) errors : -13725.54\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : -13736.42\n",
      " Regression with ARIMA(1,0,1) errors : -13725.25\n",
      " Regression with ARIMA(1,0,2) errors : -13725.96\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,0) errors : -13725.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10253.6\n",
      " Regression with ARIMA(1,0,0) errors : -13735.62\n",
      " Regression with ARIMA(0,0,1) errors : -11865.12\n",
      " Regression with ARIMA(0,0,0) errors : -8816.856\n",
      " Regression with ARIMA(2,0,0) errors : -13733.87\n",
      " Regression with ARIMA(1,0,1) errors : -13734.66\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13733.14\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13750.01\n",
      " Regression with ARIMA(0,0,0) errors : -10257.06\n",
      " Regression with ARIMA(1,0,0) errors : -13738.28\n",
      " Regression with ARIMA(0,0,1) errors : -11865.9\n",
      " Regression with ARIMA(0,0,0) errors : -8780.029\n",
      " Regression with ARIMA(1,0,2) errors : -13737.34\n",
      " Regression with ARIMA(2,0,1) errors : -13751.1\n",
      " Regression with ARIMA(1,0,1) errors : -13737.18\n",
      " Regression with ARIMA(2,0,0) errors : -13736.6\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,0) errors : -13736.27\n",
      " Regression with ARIMA(3,0,2) errors : -13732.63\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13735.84\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -10256.83\n",
      " Regression with ARIMA(1,0,0) errors : -13730.95\n",
      " Regression with ARIMA(0,0,1) errors : -11861.77\n",
      " Regression with ARIMA(0,0,0) errors : -8779.258\n",
      " Regression with ARIMA(2,0,0) errors : -13729.15\n",
      " Regression with ARIMA(1,0,1) errors : -13729.46\n",
      " Regression with ARIMA(2,0,1) errors : -13743.66\n",
      " Regression with ARIMA(3,0,1) errors : -13740.11\n",
      " Regression with ARIMA(1,0,2) errors : -13729.66\n",
      " Regression with ARIMA(3,0,0) errors : -13731.65\n",
      " Regression with ARIMA(3,0,2) errors : -13742.18\n",
      " Regression with ARIMA(2,0,1) errors : -13618.71\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -13744.27\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13704.92\n",
      " Regression with ARIMA(0,0,0) errors : -10273.67\n",
      " Regression with ARIMA(1,0,0) errors : -13706.69\n",
      " Regression with ARIMA(0,0,1) errors : -11878.39\n",
      " Regression with ARIMA(0,0,0) errors : -8797.955\n",
      " Regression with ARIMA(2,0,0) errors : -13704.19\n",
      " Regression with ARIMA(1,0,1) errors : -13704.98\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : -13577.35\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13704.77\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13513.55\n",
      " Regression with ARIMA(0,0,0) errors : -10068.34\n",
      " Regression with ARIMA(1,0,0) errors : -13520.38\n",
      " Regression with ARIMA(0,0,1) errors : -11654.6\n",
      " Regression with ARIMA(0,0,0) errors : -8614.487\n",
      " Regression with ARIMA(2,0,0) errors : -13517.43\n",
      " Regression with ARIMA(1,0,1) errors : -13518.38\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,0) errors : -13517.53\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12970.83\n",
      " Regression with ARIMA(0,1,0) errors : -12930.49\n",
      " Regression with ARIMA(1,1,0) errors : -12945.11\n",
      " Regression with ARIMA(0,1,1) errors : -12947.22\n",
      " Regression with ARIMA(0,1,0) errors : -12932.5\n",
      " Regression with ARIMA(1,1,2) errors : -12962.91\n",
      " Regression with ARIMA(2,1,1) errors : -12971.71\n",
      " Regression with ARIMA(1,1,1) errors : -12955.51\n",
      " Regression with ARIMA(2,1,0) errors : -12969.84\n",
      " Regression with ARIMA(3,1,1) errors : -12974.24\n",
      " Regression with ARIMA(3,1,0) errors : -12974.64\n",
      " Regression with ARIMA(4,1,0) errors : -12978.76\n",
      " Regression with ARIMA(5,1,0) errors : -12976.29\n",
      " Regression with ARIMA(4,1,1) errors : -12976.71\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,0) errors : -12980.76\n",
      " Regression with ARIMA(3,1,0) errors : -12976.65\n",
      " Regression with ARIMA(5,1,0) errors : -12978.28\n",
      " Regression with ARIMA(4,1,1) errors : -12978.77\n",
      " Regression with ARIMA(3,1,1) errors : -12976.24\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,1,0) errors : -12980.2\n",
      "\n",
      " Best model: Regression with ARIMA(4,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12722.08\n",
      " Regression with ARIMA(0,1,0) errors : -12682.87\n",
      " Regression with ARIMA(1,1,0) errors : -12702.85\n",
      " Regression with ARIMA(0,1,1) errors : -12708.6\n",
      " Regression with ARIMA(0,1,0) errors : -12684.84\n",
      " Regression with ARIMA(1,1,2) errors : -12720.75\n",
      " Regression with ARIMA(2,1,1) errors : -12722.99\n",
      " Regression with ARIMA(1,1,1) errors : -12711.35\n",
      " Regression with ARIMA(2,1,0) errors : -12720.41\n",
      " Regression with ARIMA(3,1,1) errors : -12722.13\n",
      " Regression with ARIMA(3,1,0) errors : -12724.07\n",
      " Regression with ARIMA(4,1,0) errors : -12721.18\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,0) errors : -12726.05\n",
      " Regression with ARIMA(2,1,0) errors : -12722.38\n",
      " Regression with ARIMA(4,1,0) errors : -12723.17\n",
      " Regression with ARIMA(3,1,1) errors : -12724.11\n",
      " Regression with ARIMA(2,1,1) errors : -12724.96\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,0) errors : -12736.42\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12560.78\n",
      " Regression with ARIMA(0,1,0) errors : -12505.96\n",
      " Regression with ARIMA(1,1,0) errors : -12527.34\n",
      " Regression with ARIMA(0,1,1) errors : -12533.58\n",
      " Regression with ARIMA(0,1,0) errors : -12507.97\n",
      " Regression with ARIMA(1,1,2) errors : -12551.89\n",
      " Regression with ARIMA(2,1,1) errors : -12557.49\n",
      " Regression with ARIMA(3,1,2) errors : -12557.93\n",
      " Regression with ARIMA(2,1,3) errors : -12558.92\n",
      " Regression with ARIMA(1,1,1) errors : -12537.48\n",
      " Regression with ARIMA(1,1,3) errors : -12554.56\n",
      " Regression with ARIMA(3,1,1) errors : -12557.55\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12562.8\n",
      " Regression with ARIMA(1,1,2) errors : -12553.91\n",
      " Regression with ARIMA(2,1,1) errors : -12559.5\n",
      " Regression with ARIMA(3,1,2) errors : -12559.9\n",
      " Regression with ARIMA(2,1,3) errors : -12560.93\n",
      " Regression with ARIMA(1,1,1) errors : -12539.48\n",
      " Regression with ARIMA(1,1,3) errors : -12556.58\n",
      " Regression with ARIMA(3,1,1) errors : -12559.56\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12572.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12525.75\n",
      " Regression with ARIMA(0,1,0) errors : -12472.26\n",
      " Regression with ARIMA(1,1,0) errors : -12494.36\n",
      " Regression with ARIMA(0,1,1) errors : -12499.92\n",
      " Regression with ARIMA(0,1,0) errors : -12474.27\n",
      " Regression with ARIMA(1,1,2) errors : -12516.93\n",
      " Regression with ARIMA(2,1,1) errors : -12522.47\n",
      " Regression with ARIMA(3,1,2) errors : -12522.7\n",
      " Regression with ARIMA(2,1,3) errors : -12523.75\n",
      " Regression with ARIMA(1,1,1) errors : -12502.95\n",
      " Regression with ARIMA(1,1,3) errors : -12520.19\n",
      " Regression with ARIMA(3,1,1) errors : -12522.74\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12527.77\n",
      " Regression with ARIMA(1,1,2) errors : -12518.94\n",
      " Regression with ARIMA(2,1,1) errors : -12524.48\n",
      " Regression with ARIMA(3,1,2) errors : -12524.7\n",
      " Regression with ARIMA(2,1,3) errors : -12525.77\n",
      " Regression with ARIMA(1,1,1) errors : -12504.95\n",
      " Regression with ARIMA(1,1,3) errors : -12522.21\n",
      " Regression with ARIMA(3,1,1) errors : -12524.75\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12537.2\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12470.37\n",
      " Regression with ARIMA(0,1,0) errors : -12414.35\n",
      " Regression with ARIMA(1,1,0) errors : -12436.58\n",
      " Regression with ARIMA(0,1,1) errors : -12443.12\n",
      " Regression with ARIMA(0,1,0) errors : -12416.35\n",
      " Regression with ARIMA(1,1,2) errors : -12461.95\n",
      " Regression with ARIMA(2,1,1) errors : -12468.01\n",
      " Regression with ARIMA(3,1,2) errors : -12467.45\n",
      " Regression with ARIMA(2,1,3) errors : -12468.34\n",
      " Regression with ARIMA(1,1,1) errors : -12445.63\n",
      " Regression with ARIMA(1,1,3) errors : -12464.82\n",
      " Regression with ARIMA(3,1,1) errors : -12468.7\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12472.37\n",
      " Regression with ARIMA(1,1,2) errors : -12463.95\n",
      " Regression with ARIMA(2,1,1) errors : -12470\n",
      " Regression with ARIMA(3,1,2) errors : -12469.45\n",
      " Regression with ARIMA(2,1,3) errors : -12470.36\n",
      " Regression with ARIMA(1,1,1) errors : -12447.62\n",
      " Regression with ARIMA(1,1,3) errors : -12466.82\n",
      " Regression with ARIMA(3,1,1) errors : -12470.69\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12481.51\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12415.46\n",
      " Regression with ARIMA(0,1,0) errors : -12357.7\n",
      " Regression with ARIMA(1,1,0) errors : -12377.73\n",
      " Regression with ARIMA(0,1,1) errors : -12382.8\n",
      " Regression with ARIMA(0,1,0) errors : -12359.71\n",
      " Regression with ARIMA(1,1,2) errors : -12397.26\n",
      " Regression with ARIMA(2,1,1) errors : -12405.48\n",
      " Regression with ARIMA(3,1,2) errors : -12413.51\n",
      " Regression with ARIMA(2,1,3) errors : -12414.64\n",
      " Regression with ARIMA(1,1,1) errors : -12383.72\n",
      " Regression with ARIMA(1,1,3) errors : -12404.76\n",
      " Regression with ARIMA(3,1,1) errors : -12410.9\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12417.47\n",
      " Regression with ARIMA(1,1,2) errors : -12399.27\n",
      " Regression with ARIMA(2,1,1) errors : -12407.49\n",
      " Regression with ARIMA(3,1,2) errors : -12415.52\n",
      " Regression with ARIMA(2,1,3) errors : -12416.65\n",
      " Regression with ARIMA(1,1,1) errors : -12385.73\n",
      " Regression with ARIMA(1,1,3) errors : -12406.78\n",
      " Regression with ARIMA(3,1,1) errors : -12412.92\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12422.35\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12392.88\n",
      " Regression with ARIMA(0,1,0) errors : -12334.96\n",
      " Regression with ARIMA(1,1,0) errors : -12358.48\n",
      " Regression with ARIMA(0,1,1) errors : -12364.77\n",
      " Regression with ARIMA(0,1,0) errors : -12336.95\n",
      " Regression with ARIMA(1,1,2) errors : -12380.24\n",
      " Regression with ARIMA(2,1,1) errors : -12390.33\n",
      " Regression with ARIMA(3,1,2) errors : -12392.56\n",
      " Regression with ARIMA(2,1,3) errors : -12390.88\n",
      " Regression with ARIMA(1,1,1) errors : -12366.94\n",
      " Regression with ARIMA(1,1,3) errors : -12386.73\n",
      " Regression with ARIMA(3,1,1) errors : -12394.33\n",
      " Regression with ARIMA(3,1,0) errors : -12396.28\n",
      " Regression with ARIMA(2,1,0) errors : -12381.04\n",
      " Regression with ARIMA(4,1,0) errors : -12409.24\n",
      " Regression with ARIMA(5,1,0) errors : -12418.87\n",
      " Regression with ARIMA(5,1,1) errors : -12429.22\n",
      " Regression with ARIMA(4,1,1) errors : -12408.98\n",
      " Regression with ARIMA(5,1,2) errors : -12419\n",
      " Regression with ARIMA(4,1,2) errors : -12415.77\n",
      " Regression with ARIMA(5,1,1) errors : -12431.1\n",
      " Regression with ARIMA(4,1,1) errors : -12410.99\n",
      " Regression with ARIMA(5,1,0) errors : -12420.89\n",
      " Regression with ARIMA(5,1,2) errors : -12421.01\n",
      " Regression with ARIMA(4,1,0) errors : -12411.25\n",
      " Regression with ARIMA(4,1,2) errors : -12417.78\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(5,1,1) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,0) errors : -12408.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12405.22\n",
      " Regression with ARIMA(0,1,0) errors : -12342.22\n",
      " Regression with ARIMA(1,1,0) errors : -12369.17\n",
      " Regression with ARIMA(0,1,1) errors : -12375.11\n",
      " Regression with ARIMA(0,1,0) errors : -12344.23\n",
      " Regression with ARIMA(1,1,2) errors : -12390.01\n",
      " Regression with ARIMA(2,1,1) errors : -12397.17\n",
      " Regression with ARIMA(3,1,2) errors : -12404.33\n",
      " Regression with ARIMA(2,1,3) errors : -12403.26\n",
      " Regression with ARIMA(1,1,1) errors : -12376.7\n",
      " Regression with ARIMA(1,1,3) errors : -12397.27\n",
      " Regression with ARIMA(3,1,1) errors : -12402.52\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12407.23\n",
      " Regression with ARIMA(1,1,2) errors : -12392.02\n",
      " Regression with ARIMA(2,1,1) errors : -12399.19\n",
      " Regression with ARIMA(3,1,2) errors : -12406.34\n",
      " Regression with ARIMA(2,1,3) errors : -12405.28\n",
      " Regression with ARIMA(1,1,1) errors : -12378.71\n",
      " Regression with ARIMA(1,1,3) errors : -12399.28\n",
      " Regression with ARIMA(3,1,1) errors : -12404.53\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12418.09\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12479.1\n",
      " Regression with ARIMA(0,0,0) errors : -8904.547\n",
      " Regression with ARIMA(1,0,0) errors : -12457.86\n",
      " Regression with ARIMA(0,0,1) errors : -10586.67\n",
      " Regression with ARIMA(0,0,0) errors : -7757.971\n",
      " Regression with ARIMA(1,0,2) errors : -12470.62\n",
      " Regression with ARIMA(2,0,1) errors : -12467.78\n",
      " Regression with ARIMA(3,0,2) errors : -12535.04\n",
      " Regression with ARIMA(3,0,1) errors : -12486.22\n",
      " Regression with ARIMA(4,0,2) errors : -12504.23\n",
      " Regression with ARIMA(3,0,3) errors : -12504.59\n",
      " Regression with ARIMA(2,0,3) errors : -12501.85\n",
      " Regression with ARIMA(4,0,1) errors : -12505.69\n",
      " Regression with ARIMA(4,0,3) errors : -12533.86\n",
      " Regression with ARIMA(3,0,2) errors : -12438.48\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12506.31\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12465.71\n",
      " Regression with ARIMA(0,0,0) errors : -8892.805\n",
      " Regression with ARIMA(1,0,0) errors : -12446.23\n",
      " Regression with ARIMA(0,0,1) errors : -10571.36\n",
      " Regression with ARIMA(0,0,0) errors : -7709.597\n",
      " Regression with ARIMA(1,0,2) errors : -12458.34\n",
      " Regression with ARIMA(2,0,1) errors : -12455.94\n",
      " Regression with ARIMA(3,0,2) errors : -12524.46\n",
      " Regression with ARIMA(3,0,1) errors : -12471.77\n",
      " Regression with ARIMA(4,0,2) errors : -12490.22\n",
      " Regression with ARIMA(3,0,3) errors : -12489.3\n",
      " Regression with ARIMA(2,0,3) errors : -12488.4\n",
      " Regression with ARIMA(4,0,1) errors : -12491.45\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12529.33\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12465.29\n",
      " Regression with ARIMA(0,0,0) errors : -8894.651\n",
      " Regression with ARIMA(1,0,0) errors : -12445.35\n",
      " Regression with ARIMA(0,0,1) errors : -10573.51\n",
      " Regression with ARIMA(0,0,0) errors : -7703.577\n",
      " Regression with ARIMA(1,0,2) errors : -12457.79\n",
      " Regression with ARIMA(2,0,1) errors : -12455.34\n",
      " Regression with ARIMA(3,0,2) errors : -12521.44\n",
      " Regression with ARIMA(3,0,1) errors : -12471.75\n",
      " Regression with ARIMA(4,0,2) errors : -12489.95\n",
      " Regression with ARIMA(3,0,3) errors : -12489.87\n",
      " Regression with ARIMA(2,0,3) errors : -12487.74\n",
      " Regression with ARIMA(4,0,1) errors : -12490.93\n",
      " Regression with ARIMA(4,0,3) errors : -12517.07\n",
      " Regression with ARIMA(3,0,2) errors : -12443.7\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12527.75\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12457.74\n",
      " Regression with ARIMA(0,0,0) errors : -8888.053\n",
      " Regression with ARIMA(1,0,0) errors : -12438.77\n",
      " Regression with ARIMA(0,0,1) errors : -10568.72\n",
      " Regression with ARIMA(0,0,0) errors : -7699.325\n",
      " Regression with ARIMA(1,0,2) errors : -12450.59\n",
      " Regression with ARIMA(2,0,1) errors : -12447.71\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12479.45\n",
      " Regression with ARIMA(1,0,3) errors : -12482.41\n",
      " Regression with ARIMA(0,0,3) errors : -11655.39\n",
      " Regression with ARIMA(1,0,4) errors : -12480.42\n",
      " Regression with ARIMA(0,0,2) errors : -11226.37\n",
      " Regression with ARIMA(0,0,4) errors : -11987.9\n",
      " Regression with ARIMA(2,0,4) errors : -12508.61\n",
      " Regression with ARIMA(3,0,4) errors : -12510.98\n",
      " Regression with ARIMA(3,0,3) errors : -12480.89\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12508.89\n",
      " Regression with ARIMA(2,0,5) errors : -12511.16\n",
      " Regression with ARIMA(1,0,5) errors : -12481.3\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12511.4\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12454.54\n",
      " Regression with ARIMA(0,0,0) errors : -8881.322\n",
      " Regression with ARIMA(1,0,0) errors : -12434.91\n",
      " Regression with ARIMA(0,0,1) errors : -10562.75\n",
      " Regression with ARIMA(0,0,0) errors : -7707.396\n",
      " Regression with ARIMA(1,0,2) errors : -12446.19\n",
      " Regression with ARIMA(2,0,1) errors : -12444.84\n",
      " Regression with ARIMA(3,0,2) errors : -12469.19\n",
      " Regression with ARIMA(3,0,1) errors : -12458.01\n",
      " Regression with ARIMA(4,0,2) errors : -12484.21\n",
      " Regression with ARIMA(4,0,1) errors : -12483.69\n",
      " Regression with ARIMA(5,0,2) errors : -12502.19\n",
      " Regression with ARIMA(5,0,1) errors : -12498.17\n",
      " Regression with ARIMA(5,0,3) errors : -12504.05\n",
      " Regression with ARIMA(4,0,3) errors : -12482.32\n",
      " Regression with ARIMA(5,0,4) errors : -12490.42\n",
      " Regression with ARIMA(4,0,4) errors : -12481.71\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : -12506.66\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12464.6\n",
      " Regression with ARIMA(0,0,0) errors : -8887.118\n",
      " Regression with ARIMA(1,0,0) errors : -12445.24\n",
      " Regression with ARIMA(0,0,1) errors : -10561.18\n",
      " Regression with ARIMA(0,0,0) errors : -7708.215\n",
      " Regression with ARIMA(1,0,2) errors : -12456.91\n",
      " Regression with ARIMA(2,0,1) errors : -12455.73\n",
      " Regression with ARIMA(3,0,2) errors : -12528.24\n",
      " Regression with ARIMA(3,0,1) errors : -12470.67\n",
      " Regression with ARIMA(4,0,2) errors : -12491.02\n",
      " Regression with ARIMA(3,0,3) errors : -12487.94\n",
      " Regression with ARIMA(2,0,3) errors : -12488.17\n",
      " Regression with ARIMA(4,0,1) errors : -12491.62\n",
      " Regression with ARIMA(4,0,3) errors : -12490.61\n",
      " Regression with ARIMA(3,0,2) errors : -12436.46\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12488.78\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12482.33\n",
      " Regression with ARIMA(0,0,0) errors : -8891.815\n",
      " Regression with ARIMA(1,0,0) errors : -12463.17\n",
      " Regression with ARIMA(0,0,1) errors : -10569.71\n",
      " Regression with ARIMA(0,0,0) errors : -7717.256\n",
      " Regression with ARIMA(1,0,2) errors : -12475.08\n",
      " Regression with ARIMA(2,0,1) errors : -12474.77\n",
      " Regression with ARIMA(3,0,2) errors : -12536.91\n",
      " Regression with ARIMA(3,0,1) errors : -12489.05\n",
      " Regression with ARIMA(4,0,2) errors : -12507.21\n",
      " Regression with ARIMA(3,0,3) errors : -12507.02\n",
      " Regression with ARIMA(2,0,3) errors : -12506.61\n",
      " Regression with ARIMA(4,0,1) errors : -12508.71\n",
      " Regression with ARIMA(4,0,3) errors : -12506.62\n",
      " Regression with ARIMA(3,0,2) errors : -12453.39\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12508.55\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "[1] \"50 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12503.57\n",
      " Regression with ARIMA(0,0,0) errors : -8896.241\n",
      " Regression with ARIMA(1,0,0) errors : -12485.86\n",
      " Regression with ARIMA(0,0,1) errors : -10569.77\n",
      " Regression with ARIMA(0,0,0) errors : -7714.817\n",
      " Regression with ARIMA(1,0,2) errors : -12497.82\n",
      " Regression with ARIMA(2,0,1) errors : -12496.35\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12527.94\n",
      " Regression with ARIMA(1,0,3) errors : -12530.81\n",
      " Regression with ARIMA(0,0,3) errors : -11677.03\n",
      " Regression with ARIMA(1,0,4) errors : -12528.79\n",
      " Regression with ARIMA(0,0,2) errors : -11229.55\n",
      " Regression with ARIMA(0,0,4) errors : -12012.79\n",
      " Regression with ARIMA(2,0,4) errors : -12555.48\n",
      " Regression with ARIMA(3,0,4) errors : -12559.17\n",
      " Regression with ARIMA(3,0,3) errors : -12529.19\n",
      " Regression with ARIMA(4,0,4) errors : -12555.94\n",
      " Regression with ARIMA(3,0,5) errors : -12539.67\n",
      " Regression with ARIMA(2,0,5) errors : -12558.37\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -12560.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12499.29\n",
      " Regression with ARIMA(0,0,0) errors : -8896.211\n",
      " Regression with ARIMA(1,0,0) errors : -12479.6\n",
      " Regression with ARIMA(0,0,1) errors : -10569.06\n",
      " Regression with ARIMA(0,0,0) errors : -7726.249\n",
      " Regression with ARIMA(1,0,2) errors : -12491.43\n",
      " Regression with ARIMA(2,0,1) errors : -12490.08\n",
      " Regression with ARIMA(3,0,2) errors : -12549.65\n",
      " Regression with ARIMA(3,0,1) errors : -12505.95\n",
      " Regression with ARIMA(4,0,2) errors : -12523.02\n",
      " Regression with ARIMA(3,0,3) errors : -12522.73\n",
      " Regression with ARIMA(2,0,3) errors : -12520.84\n",
      " Regression with ARIMA(4,0,1) errors : -12524.79\n",
      " Regression with ARIMA(4,0,3) errors : -12548.68\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12521.78\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12522.71\n",
      " Regression with ARIMA(0,0,0) errors : -8912.717\n",
      " Regression with ARIMA(1,0,0) errors : -12499.7\n",
      " Regression with ARIMA(0,0,1) errors : -10598.43\n",
      " Regression with ARIMA(0,0,0) errors : -7791.064\n",
      " Regression with ARIMA(1,0,2) errors : -12511.99\n",
      " Regression with ARIMA(2,0,1) errors : -12511.69\n",
      " Regression with ARIMA(3,0,2) errors : -12565.33\n",
      " Regression with ARIMA(3,0,1) errors : -12529.16\n",
      " Regression with ARIMA(4,0,2) errors : -12545.66\n",
      " Regression with ARIMA(3,0,3) errors : -12545.28\n",
      " Regression with ARIMA(2,0,3) errors : -12543.96\n",
      " Regression with ARIMA(4,0,1) errors : -12547.58\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12526.08\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.95\n",
      " Regression with ARIMA(0,0,0) errors : -8942.089\n",
      " Regression with ARIMA(1,0,0) errors : -12527.3\n",
      " Regression with ARIMA(0,0,1) errors : -10625.79\n",
      " Regression with ARIMA(0,0,0) errors : -7815.365\n",
      " Regression with ARIMA(1,0,2) errors : -12539.1\n",
      " Regression with ARIMA(2,0,1) errors : -12537.44\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12568.26\n",
      " Regression with ARIMA(1,0,3) errors : -12570.63\n",
      " Regression with ARIMA(0,0,3) errors : -11727.96\n",
      " Regression with ARIMA(1,0,4) errors : -12568.62\n",
      " Regression with ARIMA(0,0,2) errors : -11285.05\n",
      " Regression with ARIMA(0,0,4) errors : -12063.02\n",
      " Regression with ARIMA(2,0,4) errors : -12594.01\n",
      " Regression with ARIMA(3,0,4) errors : -12602.32\n",
      " Regression with ARIMA(3,0,3) errors : -12568.74\n",
      " Regression with ARIMA(4,0,4) errors : -12567.01\n",
      " Regression with ARIMA(3,0,5) errors : -12578.76\n",
      " Regression with ARIMA(2,0,5) errors : -12598.99\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12467.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,4) errors : -12600.43\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12532.16\n",
      " Regression with ARIMA(0,0,0) errors : -8934.83\n",
      " Regression with ARIMA(1,0,0) errors : -12512.55\n",
      " Regression with ARIMA(0,0,1) errors : -10617.82\n",
      " Regression with ARIMA(0,0,0) errors : -7779.834\n",
      " Regression with ARIMA(1,0,2) errors : -12525.18\n",
      " Regression with ARIMA(2,0,1) errors : -12523.58\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12554.76\n",
      " Regression with ARIMA(1,0,3) errors : -12557.17\n",
      " Regression with ARIMA(0,0,3) errors : -11723.56\n",
      " Regression with ARIMA(1,0,4) errors : -12555.2\n",
      " Regression with ARIMA(0,0,2) errors : -11272.84\n",
      " Regression with ARIMA(0,0,4) errors : -12053.22\n",
      " Regression with ARIMA(2,0,4) errors : -12583\n",
      " Regression with ARIMA(3,0,4) errors : -12586.36\n",
      " Regression with ARIMA(3,0,3) errors : -12555.78\n",
      " Regression with ARIMA(4,0,4) errors : -12586.4\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12572.16\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12559.34\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,5) errors : -12569.81\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : -12587.09\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12509.71\n",
      " Regression with ARIMA(0,0,0) errors : -8923.006\n",
      " Regression with ARIMA(1,0,0) errors : -12490.06\n",
      " Regression with ARIMA(0,0,1) errors : -10606.06\n",
      " Regression with ARIMA(0,0,0) errors : -7778.001\n",
      " Regression with ARIMA(1,0,2) errors : -12503.3\n",
      " Regression with ARIMA(2,0,1) errors : -12501.4\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12532.82\n",
      " Regression with ARIMA(1,0,3) errors : -12535.75\n",
      " Regression with ARIMA(0,0,3) errors : -11707.59\n",
      " Regression with ARIMA(1,0,4) errors : -12533.75\n",
      " Regression with ARIMA(0,0,2) errors : -11261.54\n",
      " Regression with ARIMA(0,0,4) errors : -12037.84\n",
      " Regression with ARIMA(2,0,4) errors : -12562.35\n",
      " Regression with ARIMA(3,0,4) errors : -12563.64\n",
      " Regression with ARIMA(3,0,3) errors : -12534.12\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12540.3\n",
      " Regression with ARIMA(2,0,5) errors : -12565.8\n",
      " Regression with ARIMA(1,0,5) errors : -12534.53\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12565.48\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12497.83\n",
      " Regression with ARIMA(0,0,0) errors : -8905.257\n",
      " Regression with ARIMA(1,0,0) errors : -12479.66\n",
      " Regression with ARIMA(0,0,1) errors : -10592.39\n",
      " Regression with ARIMA(0,0,0) errors : -7770.197\n",
      " Regression with ARIMA(1,0,2) errors : -12491.59\n",
      " Regression with ARIMA(2,0,1) errors : -12491.59\n",
      " Regression with ARIMA(3,0,2) errors : -12541.44\n",
      " Regression with ARIMA(3,0,1) errors : -12505.67\n",
      " Regression with ARIMA(4,0,2) errors : -12524.33\n",
      " Regression with ARIMA(3,0,3) errors : -12524.65\n",
      " Regression with ARIMA(2,0,3) errors : -12523.33\n",
      " Regression with ARIMA(4,0,1) errors : -12525.8\n",
      " Regression with ARIMA(4,0,3) errors : -12554.64\n",
      " Regression with ARIMA(5,0,3) errors : -12551.24\n",
      " Regression with ARIMA(4,0,4) errors : -12549.94\n",
      " Regression with ARIMA(3,0,4) errors : -12553.02\n",
      " Regression with ARIMA(5,0,2) errors : -12548.7\n",
      " Regression with ARIMA(5,0,4) errors : -12528.29\n",
      " Regression with ARIMA(4,0,3) errors : -12482.77\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12554.1\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12497.83\n",
      " Regression with ARIMA(0,0,0) errors : -8898.064\n",
      " Regression with ARIMA(1,0,0) errors : -12477.67\n",
      " Regression with ARIMA(0,0,1) errors : -10586.17\n",
      " Regression with ARIMA(0,0,0) errors : -7763.444\n",
      " Regression with ARIMA(1,0,2) errors : -12489.24\n",
      " Regression with ARIMA(2,0,1) errors : -12490.62\n",
      " Regression with ARIMA(3,0,2) errors : -12555.3\n",
      " Regression with ARIMA(3,0,1) errors : -12503.83\n",
      " Regression with ARIMA(4,0,2) errors : -12522.97\n",
      " Regression with ARIMA(3,0,3) errors : -12522.77\n",
      " Regression with ARIMA(2,0,3) errors : -12522.46\n",
      " Regression with ARIMA(4,0,1) errors : -12524.5\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12474.85\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12523.61\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12513.83\n",
      " Regression with ARIMA(0,0,0) errors : -8943.164\n",
      " Regression with ARIMA(1,0,0) errors : -12488.42\n",
      " Regression with ARIMA(0,0,1) errors : -10621.1\n",
      " Regression with ARIMA(0,0,0) errors : -7868.129\n",
      " Regression with ARIMA(1,0,2) errors : -12499.53\n",
      " Regression with ARIMA(2,0,1) errors : -12510\n",
      " Regression with ARIMA(3,0,2) errors : -12538.21\n",
      " Regression with ARIMA(3,0,1) errors : -12522.06\n",
      " Regression with ARIMA(4,0,2) errors : -12545.22\n",
      " Regression with ARIMA(4,0,1) errors : -12546.86\n",
      " Regression with ARIMA(4,0,0) errors : -12546.27\n",
      " Regression with ARIMA(5,0,1) errors : -12549.63\n",
      " Regression with ARIMA(5,0,0) errors : -12550.19\n",
      " Regression with ARIMA(5,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,0) errors : -12530.49\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12537.41\n",
      " Regression with ARIMA(0,0,0) errors : -8980.404\n",
      " Regression with ARIMA(1,0,0) errors : -12515.87\n",
      " Regression with ARIMA(0,0,1) errors : -10652.29\n",
      " Regression with ARIMA(0,0,0) errors : -7878.327\n",
      " Regression with ARIMA(1,0,2) errors : -12530.48\n",
      " Regression with ARIMA(2,0,1) errors : -12528.68\n",
      " Regression with ARIMA(3,0,2) errors : -12554.48\n",
      " Regression with ARIMA(3,0,1) errors : -12543.44\n",
      " Regression with ARIMA(4,0,2) errors : -12559.77\n",
      " Regression with ARIMA(4,0,1) errors : -12561.17\n",
      " Regression with ARIMA(4,0,0) errors : -12562.64\n",
      " Regression with ARIMA(3,0,0) errors : -12534.45\n",
      " Regression with ARIMA(5,0,0) errors : -12560.32\n",
      " Regression with ARIMA(5,0,1) errors : -12583.89\n",
      " Regression with ARIMA(5,0,2) errors : -12582.7\n",
      " Regression with ARIMA(5,0,1) errors : -12494.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12584.44\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.24\n",
      " Regression with ARIMA(0,0,0) errors : -8985.481\n",
      " Regression with ARIMA(1,0,0) errors : -12523.97\n",
      " Regression with ARIMA(0,0,1) errors : -10655.97\n",
      " Regression with ARIMA(0,0,0) errors : -7884.878\n",
      " Regression with ARIMA(1,0,2) errors : -12538.88\n",
      " Regression with ARIMA(2,0,1) errors : -12537.23\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12566.95\n",
      " Regression with ARIMA(1,0,3) errors : -12569.82\n",
      " Regression with ARIMA(0,0,3) errors : -11754.84\n",
      " Regression with ARIMA(1,0,4) errors : -12567.97\n",
      " Regression with ARIMA(0,0,2) errors : -11299.19\n",
      " Regression with ARIMA(0,0,4) errors : -12073.38\n",
      " Regression with ARIMA(2,0,4) errors : -12592.97\n",
      " Regression with ARIMA(3,0,4) errors : -12597.31\n",
      " Regression with ARIMA(3,0,3) errors : -12567.29\n",
      " Regression with ARIMA(4,0,4) errors : -12596.6\n",
      " Regression with ARIMA(3,0,5) errors : -12570.58\n",
      " Regression with ARIMA(2,0,5) errors : -12597.68\n",
      " Regression with ARIMA(1,0,5) errors : -12568.02\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12597.69\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12546.78\n",
      " Regression with ARIMA(0,0,0) errors : -8970.223\n",
      " Regression with ARIMA(1,0,0) errors : -12525.95\n",
      " Regression with ARIMA(0,0,1) errors : -10649.53\n",
      " Regression with ARIMA(0,0,0) errors : -7878.626\n",
      " Regression with ARIMA(1,0,2) errors : -12540.83\n",
      " Regression with ARIMA(2,0,1) errors : -12539.25\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12568.27\n",
      " Regression with ARIMA(1,0,3) errors : -12571.19\n",
      " Regression with ARIMA(0,0,3) errors : -11751.13\n",
      " Regression with ARIMA(1,0,4) errors : -12569.31\n",
      " Regression with ARIMA(0,0,2) errors : -11296.38\n",
      " Regression with ARIMA(0,0,4) errors : -12067\n",
      " Regression with ARIMA(2,0,4) errors : -12594.34\n",
      " Regression with ARIMA(3,0,4) errors : -12595.54\n",
      " Regression with ARIMA(3,0,3) errors : -12568.5\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12574.84\n",
      " Regression with ARIMA(2,0,5) errors : -12598.8\n",
      " Regression with ARIMA(1,0,5) errors : -12569.08\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12597.59\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.79\n",
      " Regression with ARIMA(0,0,0) errors : -8964.909\n",
      " Regression with ARIMA(1,0,0) errors : -12525.68\n",
      " Regression with ARIMA(0,0,1) errors : -10646.25\n",
      " Regression with ARIMA(0,0,0) errors : -7885.222\n",
      " Regression with ARIMA(1,0,2) errors : -12540.83\n",
      " Regression with ARIMA(2,0,1) errors : -12539.59\n",
      " Regression with ARIMA(3,0,2) errors : -12603.07\n",
      " Regression with ARIMA(3,0,1) errors : -12554.12\n",
      " Regression with ARIMA(4,0,2) errors : -12569.57\n",
      " Regression with ARIMA(3,0,3) errors : -12569.71\n",
      " Regression with ARIMA(2,0,3) errors : -12568.45\n",
      " Regression with ARIMA(4,0,1) errors : -12570.93\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12494.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12570.9\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12548.69\n",
      " Regression with ARIMA(0,0,0) errors : -8959.862\n",
      " Regression with ARIMA(1,0,0) errors : -12529.05\n",
      " Regression with ARIMA(0,0,1) errors : -10643.71\n",
      " Regression with ARIMA(0,0,0) errors : -7886.635\n",
      " Regression with ARIMA(1,0,2) errors : -12544.11\n",
      " Regression with ARIMA(2,0,1) errors : -12544.13\n",
      " Regression with ARIMA(3,0,2) errors : -12571.06\n",
      " Regression with ARIMA(3,0,1) errors : -12561.51\n",
      " Regression with ARIMA(4,0,2) errors : -12576.07\n",
      " Regression with ARIMA(4,0,1) errors : -12578.07\n",
      " Regression with ARIMA(4,0,0) errors : -12579.62\n",
      " Regression with ARIMA(3,0,0) errors : -12551.25\n",
      " Regression with ARIMA(5,0,0) errors : -12579.64\n",
      " Regression with ARIMA(5,0,1) errors : Inf\n",
      " Regression with ARIMA(5,0,0) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,0) errors : -12575.23\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,0) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12551.97\n",
      " Regression with ARIMA(0,0,0) errors : -8967.683\n",
      " Regression with ARIMA(1,0,0) errors : -12529.69\n",
      " Regression with ARIMA(0,0,1) errors : -10653.67\n",
      " Regression with ARIMA(0,0,0) errors : -7896.484\n",
      " Regression with ARIMA(1,0,2) errors : -12544.97\n",
      " Regression with ARIMA(2,0,1) errors : -12543.7\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12573.37\n",
      " Regression with ARIMA(1,0,3) errors : -12575.68\n",
      " Regression with ARIMA(0,0,3) errors : -11753.95\n",
      " Regression with ARIMA(1,0,4) errors : -12573.8\n",
      " Regression with ARIMA(0,0,2) errors : -11300.67\n",
      " Regression with ARIMA(0,0,4) errors : -12074.69\n",
      " Regression with ARIMA(2,0,4) errors : -12591.45\n",
      " Regression with ARIMA(3,0,4) errors : -12595.99\n",
      " Regression with ARIMA(3,0,3) errors : -12573.8\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : -12580.86\n",
      " Regression with ARIMA(2,0,5) errors : -12597\n",
      " Regression with ARIMA(1,0,5) errors : -12573.86\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12603.04\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12556.25\n",
      " Regression with ARIMA(0,0,0) errors : -8962.755\n",
      " Regression with ARIMA(1,0,0) errors : -12535.8\n",
      " Regression with ARIMA(0,0,1) errors : -10648.64\n",
      " Regression with ARIMA(0,0,0) errors : -7898.839\n",
      " Regression with ARIMA(1,0,2) errors : -12550.14\n",
      " Regression with ARIMA(2,0,1) errors : -12548.54\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12578.72\n",
      " Regression with ARIMA(1,0,3) errors : -12581.63\n",
      " Regression with ARIMA(0,0,3) errors : -11752.88\n",
      " Regression with ARIMA(1,0,4) errors : -12579.7\n",
      " Regression with ARIMA(0,0,2) errors : -11299.22\n",
      " Regression with ARIMA(0,0,4) errors : -12072.91\n",
      " Regression with ARIMA(2,0,4) errors : -12605.06\n",
      " Regression with ARIMA(3,0,4) errors : -12603.2\n",
      " Regression with ARIMA(2,0,5) errors : -12609.26\n",
      " Regression with ARIMA(1,0,5) errors : -12579.72\n",
      " Regression with ARIMA(3,0,5) errors : -12582.04\n",
      " Regression with ARIMA(2,0,5) errors : -12540.55\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12607.82\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12570.6\n",
      " Regression with ARIMA(0,0,0) errors : -8967.56\n",
      " Regression with ARIMA(1,0,0) errors : -12549.25\n",
      " Regression with ARIMA(0,0,1) errors : -10654.34\n",
      " Regression with ARIMA(0,0,0) errors : -7906.854\n",
      " Regression with ARIMA(1,0,2) errors : -12564.03\n",
      " Regression with ARIMA(2,0,1) errors : -12563.91\n",
      " Regression with ARIMA(3,0,2) errors : -12627.87\n",
      " Regression with ARIMA(3,0,1) errors : -12577.27\n",
      " Regression with ARIMA(4,0,2) errors : -12593.34\n",
      " Regression with ARIMA(3,0,3) errors : -12593.82\n",
      " Regression with ARIMA(2,0,3) errors : -12593.22\n",
      " Regression with ARIMA(4,0,1) errors : -12594.72\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12522.09\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,1) errors : -12594.39\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12576.56\n",
      " Regression with ARIMA(0,0,0) errors : -8968.532\n",
      " Regression with ARIMA(1,0,0) errors : -12555.14\n",
      " Regression with ARIMA(0,0,1) errors : -10657.19\n",
      " Regression with ARIMA(0,0,0) errors : -7936.331\n",
      " Regression with ARIMA(1,0,2) errors : -12569.91\n",
      " Regression with ARIMA(2,0,1) errors : -12570.88\n",
      " Regression with ARIMA(3,0,2) errors : -12594.83\n",
      " Regression with ARIMA(3,0,1) errors : -12583.62\n",
      " Regression with ARIMA(4,0,2) errors : -12601.21\n",
      " Regression with ARIMA(4,0,1) errors : -12602.62\n",
      " Regression with ARIMA(4,0,0) errors : -12603.98\n",
      " Regression with ARIMA(3,0,0) errors : -12574.44\n",
      " Regression with ARIMA(5,0,0) errors : -12601.82\n",
      " Regression with ARIMA(5,0,1) errors : -12626.33\n",
      " Regression with ARIMA(5,0,2) errors : -12625.22\n",
      " Regression with ARIMA(5,0,1) errors : -12547.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12620.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12601.85\n",
      " Regression with ARIMA(0,0,0) errors : -9048.224\n",
      " Regression with ARIMA(1,0,0) errors : -12582.93\n",
      " Regression with ARIMA(0,0,1) errors : -10732.82\n",
      " Regression with ARIMA(0,0,0) errors : -8067.123\n",
      " Regression with ARIMA(1,0,2) errors : -12598.44\n",
      " Regression with ARIMA(2,0,1) errors : -12601.12\n",
      " Regression with ARIMA(3,0,2) errors : -12619.05\n",
      " Regression with ARIMA(3,0,1) errors : -12618.74\n",
      " Regression with ARIMA(4,0,2) errors : -12650.56\n",
      " Regression with ARIMA(4,0,1) errors : -12652.27\n",
      " Regression with ARIMA(4,0,0) errors : -12652.06\n",
      " Regression with ARIMA(5,0,1) errors : -12662.55\n",
      " Regression with ARIMA(5,0,0) errors : -12658.45\n",
      " Regression with ARIMA(5,0,2) errors : -12663.08\n",
      " Regression with ARIMA(5,0,3) errors : -12661.14\n",
      " Regression with ARIMA(4,0,3) errors : -12649.44\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -12652.97\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12607.62\n",
      " Regression with ARIMA(0,0,0) errors : -9029.222\n",
      " Regression with ARIMA(1,0,0) errors : -12581.78\n",
      " Regression with ARIMA(0,0,1) errors : -10679.8\n",
      " Regression with ARIMA(0,0,0) errors : -7988.616\n",
      " Regression with ARIMA(1,0,2) errors : -12606.76\n",
      " Regression with ARIMA(2,0,1) errors : -12606.03\n",
      " Regression with ARIMA(3,0,2) errors : -12633.3\n",
      " Regression with ARIMA(3,0,1) errors : -12616.63\n",
      " Regression with ARIMA(4,0,2) errors : -12637.18\n",
      " Regression with ARIMA(4,0,1) errors : -12639.14\n",
      " Regression with ARIMA(4,0,0) errors : -12638.63\n",
      " Regression with ARIMA(5,0,1) errors : -12657.77\n",
      " Regression with ARIMA(5,0,0) errors : -12639.34\n",
      " Regression with ARIMA(5,0,2) errors : -12656.11\n",
      " Regression with ARIMA(5,0,1) errors : -12576.93\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12665.38\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -12515.14\n",
      " Regression with ARIMA(0,1,0) errors : -12443.47\n",
      " Regression with ARIMA(1,1,0) errors : -12487.68\n",
      " Regression with ARIMA(0,1,1) errors : -12495.53\n",
      " Regression with ARIMA(0,1,0) errors : -12445.47\n",
      " Regression with ARIMA(1,1,2) errors : -12499.79\n",
      " Regression with ARIMA(2,1,1) errors : -12505.72\n",
      " Regression with ARIMA(3,1,2) errors : -12545.83\n",
      " Regression with ARIMA(3,1,1) errors : -12512.71\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -12547.75\n",
      " Regression with ARIMA(2,1,2) errors : -12517.15\n",
      " Regression with ARIMA(3,1,1) errors : -12514.72\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -12507.73\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -12527.28\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12606.67\n",
      " Regression with ARIMA(0,0,0) errors : -9078.123\n",
      " Regression with ARIMA(1,0,0) errors : -12575.25\n",
      " Regression with ARIMA(0,0,1) errors : -10725.64\n",
      " Regression with ARIMA(0,0,0) errors : -8063.193\n",
      " Regression with ARIMA(1,0,2) errors : -12597.15\n",
      " Regression with ARIMA(2,0,1) errors : -12601.19\n",
      " Regression with ARIMA(3,0,2) errors : -12625.54\n",
      " Regression with ARIMA(3,0,1) errors : -12611.94\n",
      " Regression with ARIMA(4,0,2) errors : -12627.49\n",
      " Regression with ARIMA(4,0,1) errors : -12627.75\n",
      " Regression with ARIMA(4,0,0) errors : -12627.47\n",
      " Regression with ARIMA(5,0,1) errors : -12646.75\n",
      " Regression with ARIMA(5,0,0) errors : -12630.02\n",
      " Regression with ARIMA(5,0,2) errors : -12645.2\n",
      " Regression with ARIMA(5,0,1) errors : -12548.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12650.4\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12592.63\n",
      " Regression with ARIMA(0,0,0) errors : -9082.048\n",
      " Regression with ARIMA(1,0,0) errors : -12566.66\n",
      " Regression with ARIMA(0,0,1) errors : -10726.09\n",
      " Regression with ARIMA(0,0,0) errors : -8059.077\n",
      " Regression with ARIMA(1,0,2) errors : -12588.96\n",
      " Regression with ARIMA(2,0,1) errors : -12589.11\n",
      " Regression with ARIMA(3,0,2) errors : -12638.23\n",
      " Regression with ARIMA(3,0,1) errors : -12600.16\n",
      " Regression with ARIMA(4,0,2) errors : -12617.62\n",
      " Regression with ARIMA(3,0,3) errors : -12618.48\n",
      " Regression with ARIMA(2,0,3) errors : -12614.14\n",
      " Regression with ARIMA(4,0,1) errors : -12616.7\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12548.15\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12652.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12584\n",
      " Regression with ARIMA(0,0,0) errors : -9072.623\n",
      " Regression with ARIMA(1,0,0) errors : -12558.92\n",
      " Regression with ARIMA(0,0,1) errors : -10724.45\n",
      " Regression with ARIMA(0,0,0) errors : -8059.797\n",
      " Regression with ARIMA(1,0,2) errors : -12579.62\n",
      " Regression with ARIMA(2,0,1) errors : -12579.45\n",
      " Regression with ARIMA(3,0,2) errors : -12637.15\n",
      " Regression with ARIMA(3,0,1) errors : -12590.09\n",
      " Regression with ARIMA(4,0,2) errors : -12609.14\n",
      " Regression with ARIMA(3,0,3) errors : -12608.81\n",
      " Regression with ARIMA(2,0,3) errors : -12605.33\n",
      " Regression with ARIMA(4,0,1) errors : -12609.45\n",
      " Regression with ARIMA(4,0,3) errors : -12638.04\n",
      " Regression with ARIMA(5,0,3) errors : -12624.89\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12633.6\n",
      " Regression with ARIMA(5,0,2) errors : -12623.44\n",
      " Regression with ARIMA(5,0,4) errors : -12618.15\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12645.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "[1] \"60 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12597.56\n",
      " Regression with ARIMA(0,0,0) errors : -9087.133\n",
      " Regression with ARIMA(1,0,0) errors : -12572.15\n",
      " Regression with ARIMA(0,0,1) errors : -10736.93\n",
      " Regression with ARIMA(0,0,0) errors : -8079.117\n",
      " Regression with ARIMA(1,0,2) errors : -12594.14\n",
      " Regression with ARIMA(2,0,1) errors : -12593.03\n",
      " Regression with ARIMA(3,0,2) errors : -12658.36\n",
      " Regression with ARIMA(3,0,1) errors : -12603.77\n",
      " Regression with ARIMA(4,0,2) errors : -12622.07\n",
      " Regression with ARIMA(3,0,3) errors : -12622.59\n",
      " Regression with ARIMA(2,0,3) errors : -12619.12\n",
      " Regression with ARIMA(4,0,1) errors : -12620.82\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12548.61\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12655.81\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12610.85\n",
      " Regression with ARIMA(0,0,0) errors : -9095.509\n",
      " Regression with ARIMA(1,0,0) errors : -12584.86\n",
      " Regression with ARIMA(0,0,1) errors : -10749.33\n",
      " Regression with ARIMA(0,0,0) errors : -8097.852\n",
      " Regression with ARIMA(1,0,2) errors : -12606.97\n",
      " Regression with ARIMA(2,0,1) errors : -12608.39\n",
      " Regression with ARIMA(3,0,2) errors : -12658.34\n",
      " Regression with ARIMA(3,0,1) errors : -12619.38\n",
      " Regression with ARIMA(4,0,2) errors : -12636.67\n",
      " Regression with ARIMA(3,0,3) errors : -12637.2\n",
      " Regression with ARIMA(2,0,3) errors : -12634.49\n",
      " Regression with ARIMA(4,0,1) errors : -12636.79\n",
      " Regression with ARIMA(4,0,3) errors : -12679.01\n",
      " Regression with ARIMA(5,0,3) errors : -12665.31\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12669.72\n",
      " Regression with ARIMA(5,0,2) errors : -12665.96\n",
      " Regression with ARIMA(5,0,4) errors : -12644.1\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12661.83\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.42\n",
      " Regression with ARIMA(0,0,0) errors : -9117.955\n",
      " Regression with ARIMA(1,0,0) errors : -12604.61\n",
      " Regression with ARIMA(0,0,1) errors : -10769.78\n",
      " Regression with ARIMA(0,0,0) errors : -8106.906\n",
      " Regression with ARIMA(1,0,2) errors : -12626.91\n",
      " Regression with ARIMA(2,0,1) errors : -12625.67\n",
      " Regression with ARIMA(3,0,2) errors : -12690.09\n",
      " Regression with ARIMA(3,0,1) errors : -12637.43\n",
      " Regression with ARIMA(4,0,2) errors : -12655.81\n",
      " Regression with ARIMA(3,0,3) errors : -12655.49\n",
      " Regression with ARIMA(2,0,3) errors : -12652.79\n",
      " Regression with ARIMA(4,0,1) errors : -12654.8\n",
      " Regression with ARIMA(4,0,3) errors : -12693.24\n",
      " Regression with ARIMA(5,0,3) errors : -12662.02\n",
      " Regression with ARIMA(4,0,4) errors : -12671.03\n",
      " Regression with ARIMA(3,0,4) errors : -12677.48\n",
      " Regression with ARIMA(5,0,2) errors : -12662.99\n",
      " Regression with ARIMA(5,0,4) errors : -12675.56\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12692.59\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12641.13\n",
      " Regression with ARIMA(0,0,0) errors : -9120.512\n",
      " Regression with ARIMA(1,0,0) errors : -12614.69\n",
      " Regression with ARIMA(0,0,1) errors : -10777.29\n",
      " Regression with ARIMA(0,0,0) errors : -8113.97\n",
      " Regression with ARIMA(1,0,2) errors : -12636.3\n",
      " Regression with ARIMA(2,0,1) errors : -12634.97\n",
      " Regression with ARIMA(3,0,2) errors : -12703.57\n",
      " Regression with ARIMA(3,0,1) errors : -12648.05\n",
      " Regression with ARIMA(4,0,2) errors : -12667.51\n",
      " Regression with ARIMA(3,0,3) errors : -12666.81\n",
      " Regression with ARIMA(2,0,3) errors : -12663.2\n",
      " Regression with ARIMA(4,0,1) errors : -12665.98\n",
      " Regression with ARIMA(4,0,3) errors : -12703.17\n",
      " Regression with ARIMA(3,0,2) errors : -12608.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.93\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12643.6\n",
      " Regression with ARIMA(0,0,0) errors : -9119.216\n",
      " Regression with ARIMA(1,0,0) errors : -12616.26\n",
      " Regression with ARIMA(0,0,1) errors : -10777.52\n",
      " Regression with ARIMA(0,0,0) errors : -8101.041\n",
      " Regression with ARIMA(1,0,2) errors : -12637.47\n",
      " Regression with ARIMA(2,0,1) errors : -12640.52\n",
      " Regression with ARIMA(3,0,2) errors : -12680.71\n",
      " Regression with ARIMA(3,0,1) errors : -12652.57\n",
      " Regression with ARIMA(4,0,2) errors : -12672.29\n",
      " Regression with ARIMA(3,0,3) errors : -12671.04\n",
      " Regression with ARIMA(2,0,3) errors : -12668.46\n",
      " Regression with ARIMA(4,0,1) errors : -12671.99\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12605.13\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12704.4\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12641.82\n",
      " Regression with ARIMA(0,0,0) errors : -9125.129\n",
      " Regression with ARIMA(1,0,0) errors : -12617.13\n",
      " Regression with ARIMA(0,0,1) errors : -10783.88\n",
      " Regression with ARIMA(0,0,0) errors : -8122.685\n",
      " Regression with ARIMA(1,0,2) errors : -12638.09\n",
      " Regression with ARIMA(2,0,1) errors : -12636.93\n",
      " Regression with ARIMA(3,0,2) errors : -12695.39\n",
      " Regression with ARIMA(3,0,1) errors : -12649.51\n",
      " Regression with ARIMA(4,0,2) errors : -12667.03\n",
      " Regression with ARIMA(3,0,3) errors : -12667.49\n",
      " Regression with ARIMA(2,0,3) errors : -12664.06\n",
      " Regression with ARIMA(4,0,1) errors : -12666.82\n",
      " Regression with ARIMA(4,0,3) errors : -12707.83\n",
      " Regression with ARIMA(5,0,3) errors : -12686.77\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12686.56\n",
      " Regression with ARIMA(5,0,2) errors : -12685.94\n",
      " Regression with ARIMA(5,0,4) errors : -12670.08\n",
      " Regression with ARIMA(4,0,3) errors : -12637.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12704.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12640.83\n",
      " Regression with ARIMA(0,0,0) errors : -9124.201\n",
      " Regression with ARIMA(1,0,0) errors : -12614.79\n",
      " Regression with ARIMA(0,0,1) errors : -10783.44\n",
      " Regression with ARIMA(0,0,0) errors : -8122.209\n",
      " Regression with ARIMA(1,0,2) errors : -12635.64\n",
      " Regression with ARIMA(2,0,1) errors : -12634.86\n",
      " Regression with ARIMA(3,0,2) errors : -12695.41\n",
      " Regression with ARIMA(3,0,1) errors : -12647.57\n",
      " Regression with ARIMA(4,0,2) errors : -12665.91\n",
      " Regression with ARIMA(3,0,3) errors : -12665.62\n",
      " Regression with ARIMA(2,0,3) errors : -12662.3\n",
      " Regression with ARIMA(4,0,1) errors : -12664.73\n",
      " Regression with ARIMA(4,0,3) errors : -12708.36\n",
      " Regression with ARIMA(5,0,3) errors : -12683.74\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12676.17\n",
      " Regression with ARIMA(4,0,3) errors : -12636.53\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12702.9\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.35\n",
      " Regression with ARIMA(0,0,0) errors : -9121.854\n",
      " Regression with ARIMA(1,0,0) errors : -12613.51\n",
      " Regression with ARIMA(0,0,1) errors : -10782.18\n",
      " Regression with ARIMA(0,0,0) errors : -8117.61\n",
      " Regression with ARIMA(1,0,2) errors : -12633.27\n",
      " Regression with ARIMA(2,0,1) errors : -12632.06\n",
      " Regression with ARIMA(3,0,2) errors : -12698.45\n",
      " Regression with ARIMA(3,0,1) errors : -12643.7\n",
      " Regression with ARIMA(4,0,2) errors : -12660.83\n",
      " Regression with ARIMA(3,0,3) errors : -12661.66\n",
      " Regression with ARIMA(2,0,3) errors : -12658.11\n",
      " Regression with ARIMA(4,0,1) errors : -12659.62\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12597.25\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12700.82\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.09\n",
      " Regression with ARIMA(0,0,0) errors : -9116.676\n",
      " Regression with ARIMA(1,0,0) errors : -12611.67\n",
      " Regression with ARIMA(0,0,1) errors : -10780.74\n",
      " Regression with ARIMA(0,0,0) errors : -8116.581\n",
      " Regression with ARIMA(1,0,2) errors : -12630.99\n",
      " Regression with ARIMA(2,0,1) errors : -12629.63\n",
      " Regression with ARIMA(3,0,2) errors : -12699.18\n",
      " Regression with ARIMA(3,0,1) errors : -12641.18\n",
      " Regression with ARIMA(4,0,2) errors : -12658.75\n",
      " Regression with ARIMA(3,0,3) errors : -12659.44\n",
      " Regression with ARIMA(2,0,3) errors : -12655.65\n",
      " Regression with ARIMA(4,0,1) errors : -12657.53\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12615.6\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12699.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12639.03\n",
      " Regression with ARIMA(0,0,0) errors : -9117.537\n",
      " Regression with ARIMA(1,0,0) errors : -12615.18\n",
      " Regression with ARIMA(0,0,1) errors : -10783.7\n",
      " Regression with ARIMA(0,0,0) errors : -8118.136\n",
      " Regression with ARIMA(1,0,2) errors : -12634.65\n",
      " Regression with ARIMA(2,0,1) errors : -12633.24\n",
      " Regression with ARIMA(3,0,2) errors : -12699.98\n",
      " Regression with ARIMA(3,0,1) errors : -12645.33\n",
      " Regression with ARIMA(4,0,2) errors : -12662.46\n",
      " Regression with ARIMA(3,0,3) errors : -12663.29\n",
      " Regression with ARIMA(2,0,3) errors : -12659.28\n",
      " Regression with ARIMA(4,0,1) errors : -12661.46\n",
      " Regression with ARIMA(4,0,3) errors : -12704.33\n",
      " Regression with ARIMA(5,0,3) errors : -12680.72\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12676.03\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12672.54\n",
      " Regression with ARIMA(4,0,3) errors : -12599.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12703.36\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.78\n",
      " Regression with ARIMA(0,0,0) errors : -9113.603\n",
      " Regression with ARIMA(1,0,0) errors : -12610.36\n",
      " Regression with ARIMA(0,0,1) errors : -10781.97\n",
      " Regression with ARIMA(0,0,0) errors : -8111.354\n",
      " Regression with ARIMA(1,0,2) errors : -12629.21\n",
      " Regression with ARIMA(2,0,1) errors : -12627.93\n",
      " Regression with ARIMA(3,0,2) errors : -12693.18\n",
      " Regression with ARIMA(3,0,1) errors : -12639.63\n",
      " Regression with ARIMA(4,0,2) errors : -12657.34\n",
      " Regression with ARIMA(3,0,3) errors : -12657.78\n",
      " Regression with ARIMA(2,0,3) errors : -12654.23\n",
      " Regression with ARIMA(4,0,1) errors : -12656.4\n",
      " Regression with ARIMA(4,0,3) errors : -12699.31\n",
      " Regression with ARIMA(5,0,3) errors : -12674.55\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12675.54\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12667.95\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.07\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.46\n",
      " Regression with ARIMA(0,0,0) errors : -9119.245\n",
      " Regression with ARIMA(1,0,0) errors : -12613.96\n",
      " Regression with ARIMA(0,0,1) errors : -10785.81\n",
      " Regression with ARIMA(0,0,0) errors : -8116.382\n",
      " Regression with ARIMA(1,0,2) errors : -12632.76\n",
      " Regression with ARIMA(2,0,1) errors : -12631.28\n",
      " Regression with ARIMA(3,0,2) errors : -12700.56\n",
      " Regression with ARIMA(3,0,1) errors : -12643.51\n",
      " Regression with ARIMA(4,0,2) errors : -12660.35\n",
      " Regression with ARIMA(3,0,3) errors : -12660.75\n",
      " Regression with ARIMA(2,0,3) errors : -12657.34\n",
      " Regression with ARIMA(4,0,1) errors : -12659.28\n",
      " Regression with ARIMA(4,0,3) errors : -12705.25\n",
      " Regression with ARIMA(5,0,3) errors : -12677.25\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12659.26\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12674.2\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12701.28\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.91\n",
      " Regression with ARIMA(0,0,0) errors : -9115.346\n",
      " Regression with ARIMA(1,0,0) errors : -12609.25\n",
      " Regression with ARIMA(0,0,1) errors : -10783.59\n",
      " Regression with ARIMA(0,0,0) errors : -8119.022\n",
      " Regression with ARIMA(1,0,2) errors : -12628.07\n",
      " Regression with ARIMA(2,0,1) errors : -12626.55\n",
      " Regression with ARIMA(3,0,2) errors : -12695.08\n",
      " Regression with ARIMA(3,0,1) errors : -12639.09\n",
      " Regression with ARIMA(4,0,2) errors : -12655.57\n",
      " Regression with ARIMA(3,0,3) errors : -12655.97\n",
      " Regression with ARIMA(2,0,3) errors : -12652.64\n",
      " Regression with ARIMA(4,0,1) errors : -12654.48\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12608.86\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12697.61\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12634.77\n",
      " Regression with ARIMA(0,0,0) errors : -9112.722\n",
      " Regression with ARIMA(1,0,0) errors : -12611.67\n",
      " Regression with ARIMA(0,0,1) errors : -10782.69\n",
      " Regression with ARIMA(0,0,0) errors : -8118.407\n",
      " Regression with ARIMA(1,0,2) errors : -12630.3\n",
      " Regression with ARIMA(2,0,1) errors : -12628.79\n",
      " Regression with ARIMA(3,0,2) errors : -12698.97\n",
      " Regression with ARIMA(3,0,1) errors : -12640.78\n",
      " Regression with ARIMA(4,0,2) errors : -12656.92\n",
      " Regression with ARIMA(3,0,3) errors : -12657.7\n",
      " Regression with ARIMA(2,0,3) errors : -12654.48\n",
      " Regression with ARIMA(4,0,1) errors : -12655.94\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12604.1\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12699.84\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.36\n",
      " Regression with ARIMA(0,0,0) errors : -9119.25\n",
      " Regression with ARIMA(1,0,0) errors : -12613.66\n",
      " Regression with ARIMA(0,0,1) errors : -10784.04\n",
      " Regression with ARIMA(0,0,0) errors : -8121.82\n",
      " Regression with ARIMA(1,0,2) errors : -12632.84\n",
      " Regression with ARIMA(2,0,1) errors : -12631.38\n",
      " Regression with ARIMA(3,0,2) errors : -12686.69\n",
      " Regression with ARIMA(3,0,1) errors : -12643.65\n",
      " Regression with ARIMA(4,0,2) errors : -12661.74\n",
      " Regression with ARIMA(3,0,3) errors : -12661.05\n",
      " Regression with ARIMA(2,0,3) errors : -12657.15\n",
      " Regression with ARIMA(4,0,1) errors : -12661.45\n",
      " Regression with ARIMA(4,0,3) errors : -12661.55\n",
      " Regression with ARIMA(3,0,2) errors : -12592.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.86\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.03\n",
      " Regression with ARIMA(0,0,0) errors : -9124.803\n",
      " Regression with ARIMA(1,0,0) errors : -12611.58\n",
      " Regression with ARIMA(0,0,1) errors : -10785.79\n",
      " Regression with ARIMA(0,0,0) errors : -8120.735\n",
      " Regression with ARIMA(1,0,2) errors : -12631.26\n",
      " Regression with ARIMA(2,0,1) errors : -12629.83\n",
      " Regression with ARIMA(3,0,2) errors : -12695.7\n",
      " Regression with ARIMA(3,0,1) errors : -12642.68\n",
      " Regression with ARIMA(4,0,2) errors : -12659.94\n",
      " Regression with ARIMA(3,0,3) errors : -12660.68\n",
      " Regression with ARIMA(2,0,3) errors : -12655.54\n",
      " Regression with ARIMA(4,0,1) errors : -12658.46\n",
      " Regression with ARIMA(4,0,3) errors : -12702.36\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12659.16\n",
      " Regression with ARIMA(5,0,2) errors : -12657.49\n",
      " Regression with ARIMA(5,0,4) errors : -12659.7\n",
      " Regression with ARIMA(4,0,3) errors : -12584.34\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.35\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12639.64\n",
      " Regression with ARIMA(0,0,0) errors : -9126.097\n",
      " Regression with ARIMA(1,0,0) errors : -12614.91\n",
      " Regression with ARIMA(0,0,1) errors : -10785.02\n",
      " Regression with ARIMA(0,0,0) errors : -8116.995\n",
      " Regression with ARIMA(1,0,2) errors : -12635.07\n",
      " Regression with ARIMA(2,0,1) errors : -12633.58\n",
      " Regression with ARIMA(3,0,2) errors : -12700.58\n",
      " Regression with ARIMA(3,0,1) errors : -12646.01\n",
      " Regression with ARIMA(4,0,2) errors : -12662.46\n",
      " Regression with ARIMA(3,0,3) errors : -12663.22\n",
      " Regression with ARIMA(2,0,3) errors : -12659.45\n",
      " Regression with ARIMA(4,0,1) errors : -12661.32\n",
      " Regression with ARIMA(4,0,3) errors : -12707.82\n",
      " Regression with ARIMA(5,0,3) errors : -12680.87\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.94\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12674.86\n",
      " Regression with ARIMA(4,0,3) errors : -12602.62\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12703.26\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.76\n",
      " Regression with ARIMA(0,0,0) errors : -9126.664\n",
      " Regression with ARIMA(1,0,0) errors : -12610.17\n",
      " Regression with ARIMA(0,0,1) errors : -10784.22\n",
      " Regression with ARIMA(0,0,0) errors : -8120.924\n",
      " Regression with ARIMA(1,0,2) errors : -12630.62\n",
      " Regression with ARIMA(2,0,1) errors : -12629.52\n",
      " Regression with ARIMA(3,0,2) errors : -12694.59\n",
      " Regression with ARIMA(3,0,1) errors : -12642.09\n",
      " Regression with ARIMA(4,0,2) errors : -12658.44\n",
      " Regression with ARIMA(3,0,3) errors : -12658.75\n",
      " Regression with ARIMA(2,0,3) errors : -12655.04\n",
      " Regression with ARIMA(4,0,1) errors : -12657.14\n",
      " Regression with ARIMA(4,0,3) errors : -12704.19\n",
      " Regression with ARIMA(5,0,3) errors : -12674.9\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.25\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12664.74\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.55\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.01\n",
      " Regression with ARIMA(0,0,0) errors : -9129.67\n",
      " Regression with ARIMA(1,0,0) errors : -12606.43\n",
      " Regression with ARIMA(0,0,1) errors : -10786.26\n",
      " Regression with ARIMA(0,0,0) errors : -8109.689\n",
      " Regression with ARIMA(1,0,2) errors : -12626.33\n",
      " Regression with ARIMA(2,0,1) errors : -12625.7\n",
      " Regression with ARIMA(3,0,2) errors : -12685.15\n",
      " Regression with ARIMA(3,0,1) errors : -12638.15\n",
      " Regression with ARIMA(4,0,2) errors : -12654.36\n",
      " Regression with ARIMA(3,0,3) errors : -12654.53\n",
      " Regression with ARIMA(2,0,3) errors : -12651.32\n",
      " Regression with ARIMA(4,0,1) errors : -12653.1\n",
      " Regression with ARIMA(4,0,3) errors : -12701.37\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12653.24\n",
      " Regression with ARIMA(3,0,4) errors : -12676.54\n",
      " Regression with ARIMA(5,0,2) errors : -12652.64\n",
      " Regression with ARIMA(5,0,4) errors : -12668.09\n",
      " Regression with ARIMA(4,0,3) errors : -12590.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.56\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.77\n",
      " Regression with ARIMA(0,0,0) errors : -9125.562\n",
      " Regression with ARIMA(1,0,0) errors : -12610.64\n",
      " Regression with ARIMA(0,0,1) errors : -10785.7\n",
      " Regression with ARIMA(0,0,0) errors : -8108.179\n",
      " Regression with ARIMA(1,0,2) errors : -12630.51\n",
      " Regression with ARIMA(2,0,1) errors : -12629.36\n",
      " Regression with ARIMA(3,0,2) errors : -12694.15\n",
      " Regression with ARIMA(3,0,1) errors : -12642.13\n",
      " Regression with ARIMA(4,0,2) errors : -12658.37\n",
      " Regression with ARIMA(3,0,3) errors : -12658.83\n",
      " Regression with ARIMA(2,0,3) errors : -12655.24\n",
      " Regression with ARIMA(4,0,1) errors : -12657.12\n",
      " Regression with ARIMA(4,0,3) errors : -12704.42\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12679.15\n",
      " Regression with ARIMA(3,0,4) errors : -12677.56\n",
      " Regression with ARIMA(5,0,2) errors : -12656.96\n",
      " Regression with ARIMA(5,0,4) errors : -12670.89\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12699.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.76\n",
      " Regression with ARIMA(0,0,0) errors : -9119.29\n",
      " Regression with ARIMA(1,0,0) errors : -12609.83\n",
      " Regression with ARIMA(0,0,1) errors : -10782.32\n",
      " Regression with ARIMA(0,0,0) errors : -8104.093\n",
      " Regression with ARIMA(1,0,2) errors : -12629.02\n",
      " Regression with ARIMA(2,0,1) errors : -12627.65\n",
      " Regression with ARIMA(3,0,2) errors : -12693.41\n",
      " Regression with ARIMA(3,0,1) errors : -12640.24\n",
      " Regression with ARIMA(4,0,2) errors : -12657.4\n",
      " Regression with ARIMA(3,0,3) errors : -12657.65\n",
      " Regression with ARIMA(2,0,3) errors : -12654\n",
      " Regression with ARIMA(4,0,1) errors : -12655.98\n",
      " Regression with ARIMA(4,0,3) errors : -12700.63\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12678.52\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12666.19\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.72\n",
      " Regression with ARIMA(0,0,0) errors : -9127.533\n",
      " Regression with ARIMA(1,0,0) errors : -12608.51\n",
      " Regression with ARIMA(0,0,1) errors : -10784.58\n",
      " Regression with ARIMA(0,0,0) errors : -8099.693\n",
      " Regression with ARIMA(1,0,2) errors : -12627.71\n",
      " Regression with ARIMA(2,0,1) errors : -12626.53\n",
      " Regression with ARIMA(3,0,2) errors : -12687.4\n",
      " Regression with ARIMA(3,0,1) errors : -12638.82\n",
      " Regression with ARIMA(4,0,2) errors : -12655.24\n",
      " Regression with ARIMA(3,0,3) errors : -12655.99\n",
      " Regression with ARIMA(2,0,3) errors : -12651.92\n",
      " Regression with ARIMA(4,0,1) errors : -12654.76\n",
      " Regression with ARIMA(4,0,3) errors : -12698.43\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12654.62\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -12611.23\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12696.67\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.19\n",
      " Regression with ARIMA(0,0,0) errors : -9131.072\n",
      " Regression with ARIMA(1,0,0) errors : -12612.33\n",
      " Regression with ARIMA(0,0,1) errors : -10786.34\n",
      " Regression with ARIMA(0,0,0) errors : -8111.89\n",
      " Regression with ARIMA(1,0,2) errors : -12632.14\n",
      " Regression with ARIMA(2,0,1) errors : -12630.94\n",
      " Regression with ARIMA(3,0,2) errors : -12697.09\n",
      " Regression with ARIMA(3,0,1) errors : -12642.55\n",
      " Regression with ARIMA(4,0,2) errors : -12659.42\n",
      " Regression with ARIMA(3,0,3) errors : -12660.03\n",
      " Regression with ARIMA(2,0,3) errors : -12656.53\n",
      " Regression with ARIMA(4,0,1) errors : -12658.14\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12614.5\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12700.42\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.26\n",
      " Regression with ARIMA(0,0,0) errors : -9126.592\n",
      " Regression with ARIMA(1,0,0) errors : -12609.67\n",
      " Regression with ARIMA(0,0,1) errors : -10781.77\n",
      " Regression with ARIMA(0,0,0) errors : -8113.176\n",
      " Regression with ARIMA(1,0,2) errors : -12629.18\n",
      " Regression with ARIMA(2,0,1) errors : -12627.73\n",
      " Regression with ARIMA(3,0,2) errors : -12692.71\n",
      " Regression with ARIMA(3,0,1) errors : -12639.26\n",
      " Regression with ARIMA(4,0,2) errors : -12656.27\n",
      " Regression with ARIMA(3,0,3) errors : -12657.03\n",
      " Regression with ARIMA(2,0,3) errors : -12652.75\n",
      " Regression with ARIMA(4,0,1) errors : -12654.72\n",
      " Regression with ARIMA(4,0,3) errors : -12699.6\n",
      " Regression with ARIMA(5,0,3) errors : -12672.77\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12668.99\n",
      " Regression with ARIMA(4,0,3) errors : -12626.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12697.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "[1] \"70 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.51\n",
      " Regression with ARIMA(0,0,0) errors : -9120.766\n",
      " Regression with ARIMA(1,0,0) errors : -12607\n",
      " Regression with ARIMA(0,0,1) errors : -10776.09\n",
      " Regression with ARIMA(0,0,0) errors : -8111.103\n",
      " Regression with ARIMA(1,0,2) errors : -12626.77\n",
      " Regression with ARIMA(2,0,1) errors : -12625.53\n",
      " Regression with ARIMA(3,0,2) errors : -12685.73\n",
      " Regression with ARIMA(3,0,1) errors : -12637.75\n",
      " Regression with ARIMA(4,0,2) errors : -12654.14\n",
      " Regression with ARIMA(3,0,3) errors : -12654.51\n",
      " Regression with ARIMA(2,0,3) errors : -12650.91\n",
      " Regression with ARIMA(4,0,1) errors : -12654.37\n",
      " Regression with ARIMA(4,0,3) errors : -12686.13\n",
      " Regression with ARIMA(5,0,3) errors : -12700.25\n",
      " Regression with ARIMA(5,0,2) errors : -12654.47\n",
      " Regression with ARIMA(5,0,4) errors : -12662.71\n",
      " Regression with ARIMA(4,0,4) errors : -12698.47\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : -12673.47\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12629.83\n",
      " Regression with ARIMA(0,0,0) errors : -9123.342\n",
      " Regression with ARIMA(1,0,0) errors : -12606.52\n",
      " Regression with ARIMA(0,0,1) errors : -10778\n",
      " Regression with ARIMA(0,0,0) errors : -8105.722\n",
      " Regression with ARIMA(1,0,2) errors : -12626.01\n",
      " Regression with ARIMA(2,0,1) errors : -12624.6\n",
      " Regression with ARIMA(3,0,2) errors : -12689.93\n",
      " Regression with ARIMA(3,0,1) errors : -12636.27\n",
      " Regression with ARIMA(4,0,2) errors : -12652.8\n",
      " Regression with ARIMA(3,0,3) errors : -12653.27\n",
      " Regression with ARIMA(2,0,3) errors : -12649.98\n",
      " Regression with ARIMA(4,0,1) errors : -12652.27\n",
      " Regression with ARIMA(4,0,3) errors : -12694.07\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12670.15\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12654.04\n",
      " Regression with ARIMA(4,0,3) errors : -12618.5\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.32\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12632.06\n",
      " Regression with ARIMA(0,0,0) errors : -9131.681\n",
      " Regression with ARIMA(1,0,0) errors : -12608.01\n",
      " Regression with ARIMA(0,0,1) errors : -10782.66\n",
      " Regression with ARIMA(0,0,0) errors : -8107.119\n",
      " Regression with ARIMA(1,0,2) errors : -12628.11\n",
      " Regression with ARIMA(2,0,1) errors : -12626.67\n",
      " Regression with ARIMA(3,0,2) errors : -12693.49\n",
      " Regression with ARIMA(3,0,1) errors : -12638.11\n",
      " Regression with ARIMA(4,0,2) errors : -12655.3\n",
      " Regression with ARIMA(3,0,3) errors : -12655.92\n",
      " Regression with ARIMA(2,0,3) errors : -12652.11\n",
      " Regression with ARIMA(4,0,1) errors : -12653.8\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12610.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12696.06\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12631.24\n",
      " Regression with ARIMA(0,0,0) errors : -9131.239\n",
      " Regression with ARIMA(1,0,0) errors : -12606.95\n",
      " Regression with ARIMA(0,0,1) errors : -10780.44\n",
      " Regression with ARIMA(0,0,0) errors : -8112.5\n",
      " Regression with ARIMA(1,0,2) errors : -12627\n",
      " Regression with ARIMA(2,0,1) errors : -12625.5\n",
      " Regression with ARIMA(3,0,2) errors : -12689.64\n",
      " Regression with ARIMA(3,0,1) errors : -12638.39\n",
      " Regression with ARIMA(4,0,2) errors : -12654.7\n",
      " Regression with ARIMA(3,0,3) errors : -12654.57\n",
      " Regression with ARIMA(2,0,3) errors : -12650.34\n",
      " Regression with ARIMA(4,0,1) errors : -12654\n",
      " Regression with ARIMA(4,0,3) errors : -12691.8\n",
      " Regression with ARIMA(5,0,3) errors : -12674.84\n",
      " Regression with ARIMA(4,0,4) errors : -12670.68\n",
      " Regression with ARIMA(3,0,4) errors : -12676.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12662.77\n",
      " Regression with ARIMA(4,0,3) errors : -12620.21\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12694.43\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12633.92\n",
      " Regression with ARIMA(0,0,0) errors : -9128.861\n",
      " Regression with ARIMA(1,0,0) errors : -12610.07\n",
      " Regression with ARIMA(0,0,1) errors : -10783.53\n",
      " Regression with ARIMA(0,0,0) errors : -8110.608\n",
      " Regression with ARIMA(1,0,2) errors : -12629.79\n",
      " Regression with ARIMA(2,0,1) errors : -12628.8\n",
      " Regression with ARIMA(3,0,2) errors : -12690.81\n",
      " Regression with ARIMA(3,0,1) errors : -12640.88\n",
      " Regression with ARIMA(4,0,2) errors : -12657.06\n",
      " Regression with ARIMA(3,0,3) errors : -12657.59\n",
      " Regression with ARIMA(2,0,3) errors : -12654.11\n",
      " Regression with ARIMA(4,0,1) errors : -12656.04\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12597.97\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12697.96\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12634.62\n",
      " Regression with ARIMA(0,0,0) errors : -9126.781\n",
      " Regression with ARIMA(1,0,0) errors : -12610.65\n",
      " Regression with ARIMA(0,0,1) errors : -10781.97\n",
      " Regression with ARIMA(0,0,0) errors : -8113.142\n",
      " Regression with ARIMA(1,0,2) errors : -12630.54\n",
      " Regression with ARIMA(2,0,1) errors : -12629.23\n",
      " Regression with ARIMA(3,0,2) errors : -12696.42\n",
      " Regression with ARIMA(3,0,1) errors : -12641.18\n",
      " Regression with ARIMA(4,0,2) errors : -12657.47\n",
      " Regression with ARIMA(3,0,3) errors : -12658.27\n",
      " Regression with ARIMA(2,0,3) errors : -12654.69\n",
      " Regression with ARIMA(4,0,1) errors : -12656.72\n",
      " Regression with ARIMA(4,0,3) errors : -12703.68\n",
      " Regression with ARIMA(5,0,3) errors : -12677.09\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12669.72\n",
      " Regression with ARIMA(4,0,3) errors : -12577.74\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12698.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12636.4\n",
      " Regression with ARIMA(0,0,0) errors : -9125.689\n",
      " Regression with ARIMA(1,0,0) errors : -12612.41\n",
      " Regression with ARIMA(0,0,1) errors : -10783.44\n",
      " Regression with ARIMA(0,0,0) errors : -8112.957\n",
      " Regression with ARIMA(1,0,2) errors : -12632.37\n",
      " Regression with ARIMA(2,0,1) errors : -12631.02\n",
      " Regression with ARIMA(3,0,2) errors : -12698.98\n",
      " Regression with ARIMA(3,0,1) errors : -12642.99\n",
      " Regression with ARIMA(4,0,2) errors : -12659.39\n",
      " Regression with ARIMA(3,0,3) errors : -12660.05\n",
      " Regression with ARIMA(2,0,3) errors : -12656.41\n",
      " Regression with ARIMA(4,0,1) errors : -12658.4\n",
      " Regression with ARIMA(4,0,3) errors : -12705.73\n",
      " Regression with ARIMA(5,0,3) errors : -12677.06\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12682.47\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12672.68\n",
      " Regression with ARIMA(4,0,3) errors : -12592.32\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.68\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12635.3\n",
      " Regression with ARIMA(0,0,0) errors : -9115.868\n",
      " Regression with ARIMA(1,0,0) errors : -12611.51\n",
      " Regression with ARIMA(0,0,1) errors : -10777.8\n",
      " Regression with ARIMA(0,0,0) errors : -8111.841\n",
      " Regression with ARIMA(1,0,2) errors : -12631.09\n",
      " Regression with ARIMA(2,0,1) errors : -12629.64\n",
      " Regression with ARIMA(3,0,2) errors : -12698.43\n",
      " Regression with ARIMA(3,0,1) errors : -12641.39\n",
      " Regression with ARIMA(4,0,2) errors : -12658.34\n",
      " Regression with ARIMA(3,0,3) errors : -12658.92\n",
      " Regression with ARIMA(2,0,3) errors : -12655.53\n",
      " Regression with ARIMA(4,0,1) errors : -12657.54\n",
      " Regression with ARIMA(4,0,3) errors : -12704.55\n",
      " Regression with ARIMA(5,0,3) errors : -12677.45\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12680.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12671.36\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12700.02\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12637.66\n",
      " Regression with ARIMA(0,0,0) errors : -9124.945\n",
      " Regression with ARIMA(1,0,0) errors : -12612.72\n",
      " Regression with ARIMA(0,0,1) errors : -10780.08\n",
      " Regression with ARIMA(0,0,0) errors : -8108.834\n",
      " Regression with ARIMA(1,0,2) errors : -12632.51\n",
      " Regression with ARIMA(2,0,1) errors : -12631.82\n",
      " Regression with ARIMA(3,0,2) errors : -12694.27\n",
      " Regression with ARIMA(3,0,1) errors : -12643.59\n",
      " Regression with ARIMA(4,0,2) errors : -12660.23\n",
      " Regression with ARIMA(3,0,3) errors : -12660.57\n",
      " Regression with ARIMA(2,0,3) errors : -12657.73\n",
      " Regression with ARIMA(4,0,1) errors : -12659.39\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12588.55\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12701.13\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12627.74\n",
      " Regression with ARIMA(0,0,0) errors : -9117.039\n",
      " Regression with ARIMA(1,0,0) errors : -12604.36\n",
      " Regression with ARIMA(0,0,1) errors : -10772.74\n",
      " Regression with ARIMA(0,0,0) errors : -8100.168\n",
      " Regression with ARIMA(1,0,2) errors : -12624.03\n",
      " Regression with ARIMA(2,0,1) errors : -12622.73\n",
      " Regression with ARIMA(3,0,2) errors : -12688.87\n",
      " Regression with ARIMA(3,0,1) errors : -12635.29\n",
      " Regression with ARIMA(4,0,2) errors : -12652.41\n",
      " Regression with ARIMA(3,0,3) errors : -12652.42\n",
      " Regression with ARIMA(2,0,3) errors : -12648.98\n",
      " Regression with ARIMA(4,0,1) errors : -12651.73\n",
      " Regression with ARIMA(4,0,3) errors : -12695.02\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -12668.42\n",
      " Regression with ARIMA(3,0,4) errors : -12666.86\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12662.55\n",
      " Regression with ARIMA(4,0,3) errors : -12583.67\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12692.62\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12629.95\n",
      " Regression with ARIMA(0,0,0) errors : -9111.839\n",
      " Regression with ARIMA(1,0,0) errors : -12606.59\n",
      " Regression with ARIMA(0,0,1) errors : -10768.97\n",
      " Regression with ARIMA(0,0,0) errors : -8094.359\n",
      " Regression with ARIMA(1,0,2) errors : -12626.11\n",
      " Regression with ARIMA(2,0,1) errors : -12624.99\n",
      " Regression with ARIMA(3,0,2) errors : -12691.49\n",
      " Regression with ARIMA(3,0,1) errors : -12636.29\n",
      " Regression with ARIMA(4,0,2) errors : -12654.61\n",
      " Regression with ARIMA(3,0,3) errors : -12655.25\n",
      " Regression with ARIMA(2,0,3) errors : -12651.79\n",
      " Regression with ARIMA(4,0,1) errors : -12653.54\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12606.28\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12694.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12625.86\n",
      " Regression with ARIMA(0,0,0) errors : -9104.057\n",
      " Regression with ARIMA(1,0,0) errors : -12602.52\n",
      " Regression with ARIMA(0,0,1) errors : -10763.32\n",
      " Regression with ARIMA(0,0,0) errors : -8093.859\n",
      " Regression with ARIMA(1,0,2) errors : -12621.83\n",
      " Regression with ARIMA(2,0,1) errors : -12620.75\n",
      " Regression with ARIMA(3,0,2) errors : -12688.22\n",
      " Regression with ARIMA(3,0,1) errors : -12631.52\n",
      " Regression with ARIMA(4,0,2) errors : -12652.06\n",
      " Regression with ARIMA(3,0,3) errors : -12650.46\n",
      " Regression with ARIMA(2,0,3) errors : -12647.56\n",
      " Regression with ARIMA(4,0,1) errors : -12651.23\n",
      " Regression with ARIMA(4,0,3) errors : -12681.28\n",
      " Regression with ARIMA(3,0,2) errors : -12603.68\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12690.63\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12618.91\n",
      " Regression with ARIMA(0,0,0) errors : -9103.363\n",
      " Regression with ARIMA(1,0,0) errors : -12597.31\n",
      " Regression with ARIMA(0,0,1) errors : -10765.68\n",
      " Regression with ARIMA(0,0,0) errors : -8091.292\n",
      " Regression with ARIMA(1,0,2) errors : -12615.19\n",
      " Regression with ARIMA(2,0,1) errors : -12613.85\n",
      " Regression with ARIMA(3,0,2) errors : -12682.31\n",
      " Regression with ARIMA(3,0,1) errors : -12625.35\n",
      " Regression with ARIMA(4,0,2) errors : -12644.79\n",
      " Regression with ARIMA(3,0,3) errors : -12644.37\n",
      " Regression with ARIMA(2,0,3) errors : -12640.45\n",
      " Regression with ARIMA(4,0,1) errors : -12643.65\n",
      " Regression with ARIMA(4,0,3) errors : -12682.08\n",
      " Regression with ARIMA(3,0,2) errors : -12580.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12684.69\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12615.06\n",
      " Regression with ARIMA(0,0,0) errors : -9099.58\n",
      " Regression with ARIMA(1,0,0) errors : -12592.84\n",
      " Regression with ARIMA(0,0,1) errors : -10762.48\n",
      " Regression with ARIMA(0,0,0) errors : -8087.004\n",
      " Regression with ARIMA(1,0,2) errors : -12610.83\n",
      " Regression with ARIMA(2,0,1) errors : -12609.67\n",
      " Regression with ARIMA(3,0,2) errors : -12677.21\n",
      " Regression with ARIMA(3,0,1) errors : -12621.08\n",
      " Regression with ARIMA(4,0,2) errors : -12640.17\n",
      " Regression with ARIMA(3,0,3) errors : -12640.85\n",
      " Regression with ARIMA(2,0,3) errors : -12636.93\n",
      " Regression with ARIMA(4,0,1) errors : -12638.83\n",
      " Regression with ARIMA(4,0,3) errors : -12684.27\n",
      " Regression with ARIMA(5,0,3) errors : -12658.04\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12639.53\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12654.82\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12680.01\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12613.46\n",
      " Regression with ARIMA(0,0,0) errors : -9099.695\n",
      " Regression with ARIMA(1,0,0) errors : -12591.66\n",
      " Regression with ARIMA(0,0,1) errors : -10763.22\n",
      " Regression with ARIMA(0,0,0) errors : -8089.962\n",
      " Regression with ARIMA(1,0,2) errors : -12609.68\n",
      " Regression with ARIMA(2,0,1) errors : -12608.39\n",
      " Regression with ARIMA(3,0,2) errors : -12677.01\n",
      " Regression with ARIMA(3,0,1) errors : -12619.63\n",
      " Regression with ARIMA(4,0,2) errors : -12638.73\n",
      " Regression with ARIMA(3,0,3) errors : -12639.14\n",
      " Regression with ARIMA(2,0,3) errors : -12635.44\n",
      " Regression with ARIMA(4,0,1) errors : -12637.36\n",
      " Regression with ARIMA(4,0,3) errors : -12681.2\n",
      " Regression with ARIMA(5,0,3) errors : -12656.69\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12660.48\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12652.18\n",
      " Regression with ARIMA(4,0,3) errors : -12597.54\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12678.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12615.16\n",
      " Regression with ARIMA(0,0,0) errors : -9100.818\n",
      " Regression with ARIMA(1,0,0) errors : -12593.22\n",
      " Regression with ARIMA(0,0,1) errors : -10765.31\n",
      " Regression with ARIMA(0,0,0) errors : -8091.06\n",
      " Regression with ARIMA(1,0,2) errors : -12611.24\n",
      " Regression with ARIMA(2,0,1) errors : -12609.93\n",
      " Regression with ARIMA(3,0,2) errors : -12679.3\n",
      " Regression with ARIMA(3,0,1) errors : -12621.06\n",
      " Regression with ARIMA(4,0,2) errors : -12639.78\n",
      " Regression with ARIMA(3,0,3) errors : -12640.43\n",
      " Regression with ARIMA(2,0,3) errors : -12636.97\n",
      " Regression with ARIMA(4,0,1) errors : -12638.66\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12594.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12679.67\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12617.12\n",
      " Regression with ARIMA(0,0,0) errors : -9109.583\n",
      " Regression with ARIMA(1,0,0) errors : -12595.07\n",
      " Regression with ARIMA(0,0,1) errors : -10771.08\n",
      " Regression with ARIMA(0,0,0) errors : -8093.37\n",
      " Regression with ARIMA(1,0,2) errors : -12613.21\n",
      " Regression with ARIMA(2,0,1) errors : -12611.88\n",
      " Regression with ARIMA(3,0,2) errors : -12678.72\n",
      " Regression with ARIMA(3,0,1) errors : -12623\n",
      " Regression with ARIMA(4,0,2) errors : -12641.23\n",
      " Regression with ARIMA(3,0,3) errors : -12641.89\n",
      " Regression with ARIMA(2,0,3) errors : -12638.42\n",
      " Regression with ARIMA(4,0,1) errors : -12640.06\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12592.8\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12681.68\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12619.74\n",
      " Regression with ARIMA(0,0,0) errors : -9112.072\n",
      " Regression with ARIMA(1,0,0) errors : -12597.43\n",
      " Regression with ARIMA(0,0,1) errors : -10771.67\n",
      " Regression with ARIMA(0,0,0) errors : -8099.27\n",
      " Regression with ARIMA(1,0,2) errors : -12615.95\n",
      " Regression with ARIMA(2,0,1) errors : -12614.81\n",
      " Regression with ARIMA(3,0,2) errors : -12684.97\n",
      " Regression with ARIMA(3,0,1) errors : -12626.06\n",
      " Regression with ARIMA(4,0,2) errors : -12644.83\n",
      " Regression with ARIMA(3,0,3) errors : -12645.37\n",
      " Regression with ARIMA(2,0,3) errors : -12641.62\n",
      " Regression with ARIMA(4,0,1) errors : -12643.67\n",
      " Regression with ARIMA(4,0,3) errors : -12690.35\n",
      " Regression with ARIMA(5,0,3) errors : -12663.66\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12668.79\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12658.85\n",
      " Regression with ARIMA(4,0,3) errors : -12609.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12685.05\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12619.78\n",
      " Regression with ARIMA(0,0,0) errors : -9111.436\n",
      " Regression with ARIMA(1,0,0) errors : -12596.51\n",
      " Regression with ARIMA(0,0,1) errors : -10769.82\n",
      " Regression with ARIMA(0,0,0) errors : -8099.19\n",
      " Regression with ARIMA(1,0,2) errors : -12615.12\n",
      " Regression with ARIMA(2,0,1) errors : -12615.29\n",
      " Regression with ARIMA(3,0,2) errors : -12677.01\n",
      " Regression with ARIMA(3,0,1) errors : -12626.47\n",
      " Regression with ARIMA(4,0,2) errors : -12646.5\n",
      " Regression with ARIMA(3,0,3) errors : -12647.04\n",
      " Regression with ARIMA(2,0,3) errors : -12642.14\n",
      " Regression with ARIMA(4,0,1) errors : -12644.59\n",
      " Regression with ARIMA(4,0,3) errors : -12686.33\n",
      " Regression with ARIMA(5,0,3) errors : -12661.66\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12668.72\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12657.53\n",
      " Regression with ARIMA(4,0,3) errors : -12608.24\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12683.18\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12616.6\n",
      " Regression with ARIMA(0,0,0) errors : -9093.993\n",
      " Regression with ARIMA(1,0,0) errors : -12593.32\n",
      " Regression with ARIMA(0,0,1) errors : -10754.58\n",
      " Regression with ARIMA(0,0,0) errors : -8057.969\n",
      " Regression with ARIMA(1,0,2) errors : -12612.81\n",
      " Regression with ARIMA(2,0,1) errors : -12611.61\n",
      " Regression with ARIMA(3,0,2) errors : -12678.85\n",
      " Regression with ARIMA(3,0,1) errors : -12622.82\n",
      " Regression with ARIMA(4,0,2) errors : -12641.44\n",
      " Regression with ARIMA(3,0,3) errors : -12642.14\n",
      " Regression with ARIMA(2,0,3) errors : -12638.25\n",
      " Regression with ARIMA(4,0,1) errors : -12639.95\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12583.17\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12680.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12583.96\n",
      " Regression with ARIMA(0,0,0) errors : -9092.613\n",
      " Regression with ARIMA(1,0,0) errors : -12563.7\n",
      " Regression with ARIMA(0,0,1) errors : -10747.78\n",
      " Regression with ARIMA(0,0,0) errors : -8051.218\n",
      " Regression with ARIMA(1,0,2) errors : -12580.28\n",
      " Regression with ARIMA(2,0,1) errors : -12579.03\n",
      " Regression with ARIMA(3,0,2) errors : -12646.7\n",
      " Regression with ARIMA(3,0,1) errors : -12589.65\n",
      " Regression with ARIMA(4,0,2) errors : -12606.27\n",
      " Regression with ARIMA(3,0,3) errors : -12606.89\n",
      " Regression with ARIMA(2,0,3) errors : -12603.05\n",
      " Regression with ARIMA(4,0,1) errors : -12604.75\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12556.01\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12648.35\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12577.66\n",
      " Regression with ARIMA(0,0,0) errors : -9095.204\n",
      " Regression with ARIMA(1,0,0) errors : -12557.4\n",
      " Regression with ARIMA(0,0,1) errors : -10745.91\n",
      " Regression with ARIMA(0,0,0) errors : -8037.239\n",
      " Regression with ARIMA(1,0,2) errors : -12573.72\n",
      " Regression with ARIMA(2,0,1) errors : -12572.35\n",
      " Regression with ARIMA(3,0,2) errors : -12641.2\n",
      " Regression with ARIMA(3,0,1) errors : -12583.1\n",
      " Regression with ARIMA(4,0,2) errors : -12600.41\n",
      " Regression with ARIMA(3,0,3) errors : -12601.11\n",
      " Regression with ARIMA(2,0,3) errors : -12597.21\n",
      " Regression with ARIMA(4,0,1) errors : -12599.03\n",
      " Regression with ARIMA(4,0,3) errors : -12644.07\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12622.13\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12612.01\n",
      " Regression with ARIMA(4,0,3) errors : -12563.58\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12642.54\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12575.52\n",
      " Regression with ARIMA(0,0,0) errors : -9101.37\n",
      " Regression with ARIMA(1,0,0) errors : -12554.94\n",
      " Regression with ARIMA(0,0,1) errors : -10747.52\n",
      " Regression with ARIMA(0,0,0) errors : -8033.351\n",
      " Regression with ARIMA(1,0,2) errors : -12571.38\n",
      " Regression with ARIMA(2,0,1) errors : -12570.05\n",
      " Regression with ARIMA(3,0,2) errors : -12638.35\n",
      " Regression with ARIMA(3,0,1) errors : -12581.07\n",
      " Regression with ARIMA(4,0,2) errors : -12598.59\n",
      " Regression with ARIMA(3,0,3) errors : -12599.01\n",
      " Regression with ARIMA(2,0,3) errors : -12595.34\n",
      " Regression with ARIMA(4,0,1) errors : -12597.11\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12519.88\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12639.65\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12565.83\n",
      " Regression with ARIMA(0,0,0) errors : -9101.364\n",
      " Regression with ARIMA(1,0,0) errors : -12545.42\n",
      " Regression with ARIMA(0,0,1) errors : -10744.99\n",
      " Regression with ARIMA(0,0,0) errors : -8028.435\n",
      " Regression with ARIMA(1,0,2) errors : -12561.69\n",
      " Regression with ARIMA(2,0,1) errors : -12560.33\n",
      " Regression with ARIMA(3,0,2) errors : -12625.38\n",
      " Regression with ARIMA(3,0,1) errors : -12571.55\n",
      " Regression with ARIMA(4,0,2) errors : -12589.48\n",
      " Regression with ARIMA(3,0,3) errors : -12589.91\n",
      " Regression with ARIMA(2,0,3) errors : -12585.25\n",
      " Regression with ARIMA(4,0,1) errors : -12587.54\n",
      " Regression with ARIMA(4,0,3) errors : -12629.39\n",
      " Regression with ARIMA(5,0,3) errors : -12606.27\n",
      " Regression with ARIMA(4,0,4) errors : -12632.75\n",
      " Regression with ARIMA(3,0,4) errors : -12604.33\n",
      " Regression with ARIMA(5,0,4) errors : -12602.45\n",
      " Regression with ARIMA(4,0,5) errors : -12606.94\n",
      " Regression with ARIMA(3,0,5) errors : -12601.51\n",
      " Regression with ARIMA(5,0,5) errors : -12608.1\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12629.36\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "[1] \"80 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12550.88\n",
      " Regression with ARIMA(0,0,0) errors : -9082.974\n",
      " Regression with ARIMA(1,0,0) errors : -12530.87\n",
      " Regression with ARIMA(0,0,1) errors : -10726.19\n",
      " Regression with ARIMA(0,0,0) errors : -7990.949\n",
      " Regression with ARIMA(1,0,2) errors : -12547.22\n",
      " Regression with ARIMA(2,0,1) errors : -12546.03\n",
      " Regression with ARIMA(3,0,2) errors : -12611.03\n",
      " Regression with ARIMA(3,0,1) errors : -12556.14\n",
      " Regression with ARIMA(4,0,2) errors : -12573.38\n",
      " Regression with ARIMA(3,0,3) errors : -12573.93\n",
      " Regression with ARIMA(2,0,3) errors : -12570.37\n",
      " Regression with ARIMA(4,0,1) errors : -12572.13\n",
      " Regression with ARIMA(4,0,3) errors : -12616.54\n",
      " Regression with ARIMA(5,0,3) errors : -12590.07\n",
      " Regression with ARIMA(4,0,4) errors : -12620.02\n",
      " Regression with ARIMA(3,0,4) errors : -12593.33\n",
      " Regression with ARIMA(5,0,4) errors : -12585.19\n",
      " Regression with ARIMA(4,0,5) errors : -12590.96\n",
      " Regression with ARIMA(3,0,5) errors : -12586.08\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12613.46\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12541.98\n",
      " Regression with ARIMA(0,0,0) errors : -9085.693\n",
      " Regression with ARIMA(1,0,0) errors : -12521.52\n",
      " Regression with ARIMA(0,0,1) errors : -10727.61\n",
      " Regression with ARIMA(0,0,0) errors : -7984.545\n",
      " Regression with ARIMA(1,0,2) errors : -12537.92\n",
      " Regression with ARIMA(2,0,1) errors : -12537.24\n",
      " Regression with ARIMA(3,0,2) errors : -12601.89\n",
      " Regression with ARIMA(3,0,1) errors : -12547.19\n",
      " Regression with ARIMA(4,0,2) errors : -12564.24\n",
      " Regression with ARIMA(3,0,3) errors : -12564.26\n",
      " Regression with ARIMA(2,0,3) errors : -12561.62\n",
      " Regression with ARIMA(4,0,1) errors : -12563.37\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12499.3\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12602.92\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12545.96\n",
      " Regression with ARIMA(0,0,0) errors : -9090.727\n",
      " Regression with ARIMA(1,0,0) errors : -12524.23\n",
      " Regression with ARIMA(0,0,1) errors : -10729.14\n",
      " Regression with ARIMA(0,0,0) errors : -7988.192\n",
      " Regression with ARIMA(1,0,2) errors : -12541.23\n",
      " Regression with ARIMA(2,0,1) errors : -12541.2\n",
      " Regression with ARIMA(3,0,2) errors : -12596.53\n",
      " Regression with ARIMA(3,0,1) errors : -12551.61\n",
      " Regression with ARIMA(4,0,2) errors : -12568.27\n",
      " Regression with ARIMA(3,0,3) errors : -12568.72\n",
      " Regression with ARIMA(2,0,3) errors : -12565.53\n",
      " Regression with ARIMA(4,0,1) errors : -12567.05\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12496.37\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12605.49\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12548.88\n",
      " Regression with ARIMA(0,0,0) errors : -9100.305\n",
      " Regression with ARIMA(1,0,0) errors : -12527.5\n",
      " Regression with ARIMA(0,0,1) errors : -10736.35\n",
      " Regression with ARIMA(0,0,0) errors : -7988.759\n",
      " Regression with ARIMA(1,0,2) errors : -12544.66\n",
      " Regression with ARIMA(2,0,1) errors : -12543.65\n",
      " Regression with ARIMA(3,0,2) errors : -12605.4\n",
      " Regression with ARIMA(3,0,1) errors : -12554.44\n",
      " Regression with ARIMA(4,0,2) errors : -12571.11\n",
      " Regression with ARIMA(3,0,3) errors : -12571.91\n",
      " Regression with ARIMA(2,0,3) errors : -12568.5\n",
      " Regression with ARIMA(4,0,1) errors : -12570.06\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12504.19\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12608.79\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.27\n",
      " Regression with ARIMA(0,0,0) errors : -9095.28\n",
      " Regression with ARIMA(1,0,0) errors : -12526.27\n",
      " Regression with ARIMA(0,0,1) errors : -10733.95\n",
      " Regression with ARIMA(0,0,0) errors : -7985.631\n",
      " Regression with ARIMA(1,0,2) errors : -12543.29\n",
      " Regression with ARIMA(2,0,1) errors : -12541.96\n",
      " Regression with ARIMA(3,0,2) errors : -12605.92\n",
      " Regression with ARIMA(3,0,1) errors : -12552.76\n",
      " Regression with ARIMA(4,0,2) errors : -12569.38\n",
      " Regression with ARIMA(3,0,3) errors : -12569.97\n",
      " Regression with ARIMA(2,0,3) errors : -12566.62\n",
      " Regression with ARIMA(4,0,1) errors : -12568.51\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12514.77\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12607.57\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12551.72\n",
      " Regression with ARIMA(0,0,0) errors : -9094.616\n",
      " Regression with ARIMA(1,0,0) errors : -12527.72\n",
      " Regression with ARIMA(0,0,1) errors : -10731.91\n",
      " Regression with ARIMA(0,0,0) errors : -7984.814\n",
      " Regression with ARIMA(1,0,2) errors : -12544.83\n",
      " Regression with ARIMA(2,0,1) errors : -12545.69\n",
      " Regression with ARIMA(3,0,2) errors : -12599.12\n",
      " Regression with ARIMA(3,0,1) errors : -12556.69\n",
      " Regression with ARIMA(4,0,2) errors : -12574.58\n",
      " Regression with ARIMA(3,0,3) errors : -12572.21\n",
      " Regression with ARIMA(2,0,3) errors : -12570.48\n",
      " Regression with ARIMA(4,0,1) errors : -12574.57\n",
      " Regression with ARIMA(4,0,3) errors : -12602.14\n",
      " Regression with ARIMA(5,0,3) errors : -12593.97\n",
      " Regression with ARIMA(4,0,4) errors : -12614.31\n",
      " Regression with ARIMA(3,0,4) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12592.12\n",
      " Regression with ARIMA(4,0,5) errors : -12613.12\n",
      " Regression with ARIMA(3,0,5) errors : -12593.98\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -12615.97\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12547.25\n",
      " Regression with ARIMA(0,0,0) errors : -9103.285\n",
      " Regression with ARIMA(1,0,0) errors : -12525.6\n",
      " Regression with ARIMA(0,0,1) errors : -10740.02\n",
      " Regression with ARIMA(0,0,0) errors : -7987.126\n",
      " Regression with ARIMA(1,0,2) errors : -12542.63\n",
      " Regression with ARIMA(2,0,1) errors : -12541.09\n",
      " Regression with ARIMA(3,0,2) errors : -12595.27\n",
      " Regression with ARIMA(3,0,1) errors : -12553.61\n",
      " Regression with ARIMA(4,0,2) errors : -12567.35\n",
      " Regression with ARIMA(3,0,3) errors : -12568.1\n",
      " Regression with ARIMA(2,0,3) errors : -12564.84\n",
      " Regression with ARIMA(4,0,1) errors : -12567.61\n",
      " Regression with ARIMA(4,0,3) errors : -12599.93\n",
      " Regression with ARIMA(5,0,3) errors : -12585.25\n",
      " Regression with ARIMA(4,0,4) errors : -12587.13\n",
      " Regression with ARIMA(3,0,4) errors : -12586.59\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12587.56\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12603.94\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12563.76\n",
      " Regression with ARIMA(0,0,0) errors : -9114.748\n",
      " Regression with ARIMA(1,0,0) errors : -12542.44\n",
      " Regression with ARIMA(0,0,1) errors : -10750.26\n",
      " Regression with ARIMA(0,0,0) errors : -7996.79\n",
      " Regression with ARIMA(1,0,2) errors : -12559.52\n",
      " Regression with ARIMA(2,0,1) errors : -12557.88\n",
      " Regression with ARIMA(3,0,2) errors : -12623.24\n",
      " Regression with ARIMA(3,0,1) errors : -12569.07\n",
      " Regression with ARIMA(4,0,2) errors : -12584.06\n",
      " Regression with ARIMA(3,0,3) errors : -12584.83\n",
      " Regression with ARIMA(2,0,3) errors : -12581.2\n",
      " Regression with ARIMA(4,0,1) errors : -12583.59\n",
      " Regression with ARIMA(4,0,3) errors : -12622.16\n",
      " Regression with ARIMA(3,0,2) errors : -12529.16\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12623.55\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12571.66\n",
      " Regression with ARIMA(0,0,0) errors : -9119.255\n",
      " Regression with ARIMA(1,0,0) errors : -12550.63\n",
      " Regression with ARIMA(0,0,1) errors : -10754.38\n",
      " Regression with ARIMA(0,0,0) errors : -7999.828\n",
      " Regression with ARIMA(1,0,2) errors : -12567.56\n",
      " Regression with ARIMA(2,0,1) errors : -12565.97\n",
      " Regression with ARIMA(3,0,2) errors : -12623.38\n",
      " Regression with ARIMA(3,0,1) errors : -12577.61\n",
      " Regression with ARIMA(4,0,2) errors : -12592.71\n",
      " Regression with ARIMA(3,0,3) errors : -12593.33\n",
      " Regression with ARIMA(2,0,3) errors : -12589.24\n",
      " Regression with ARIMA(4,0,1) errors : -12591.99\n",
      " Regression with ARIMA(4,0,3) errors : -12628.14\n",
      " Regression with ARIMA(5,0,3) errors : -12611.42\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12608.22\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12601.46\n",
      " Regression with ARIMA(4,0,3) errors : -12518.46\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12632.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12570.69\n",
      " Regression with ARIMA(0,0,0) errors : -9115.278\n",
      " Regression with ARIMA(1,0,0) errors : -12549.82\n",
      " Regression with ARIMA(0,0,1) errors : -10753.47\n",
      " Regression with ARIMA(0,0,0) errors : -8003.712\n",
      " Regression with ARIMA(1,0,2) errors : -12566.64\n",
      " Regression with ARIMA(2,0,1) errors : -12564.99\n",
      " Regression with ARIMA(3,0,2) errors : -12627.12\n",
      " Regression with ARIMA(3,0,1) errors : -12576.67\n",
      " Regression with ARIMA(4,0,2) errors : -12592.86\n",
      " Regression with ARIMA(3,0,3) errors : -12593.53\n",
      " Regression with ARIMA(2,0,3) errors : -12588.09\n",
      " Regression with ARIMA(4,0,1) errors : -12591.37\n",
      " Regression with ARIMA(4,0,3) errors : -12631.06\n",
      " Regression with ARIMA(5,0,3) errors : -12608.52\n",
      " Regression with ARIMA(4,0,4) errors : -12636.78\n",
      " Regression with ARIMA(3,0,4) errors : -12595.05\n",
      " Regression with ARIMA(5,0,4) errors : -12606.13\n",
      " Regression with ARIMA(4,0,5) errors : -12611.46\n",
      " Regression with ARIMA(3,0,5) errors : -12589.1\n",
      " Regression with ARIMA(5,0,5) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12631.52\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12578.38\n",
      " Regression with ARIMA(0,0,0) errors : -9111.17\n",
      " Regression with ARIMA(1,0,0) errors : -12558.92\n",
      " Regression with ARIMA(0,0,1) errors : -10753.78\n",
      " Regression with ARIMA(0,0,0) errors : -8020.573\n",
      " Regression with ARIMA(1,0,2) errors : -12574.68\n",
      " Regression with ARIMA(2,0,1) errors : -12573.05\n",
      " Regression with ARIMA(3,0,2) errors : -12623.18\n",
      " Regression with ARIMA(3,0,1) errors : -12586.14\n",
      " Regression with ARIMA(4,0,2) errors : -12599.85\n",
      " Regression with ARIMA(3,0,3) errors : -12600.52\n",
      " Regression with ARIMA(2,0,3) errors : -12595.7\n",
      " Regression with ARIMA(4,0,1) errors : -12599.55\n",
      " Regression with ARIMA(4,0,3) errors : -12630.95\n",
      " Regression with ARIMA(5,0,3) errors : -12614.41\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12610.87\n",
      " Regression with ARIMA(5,0,2) errors : -12611.96\n",
      " Regression with ARIMA(5,0,4) errors : -12609.33\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12639.79\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12589.89\n",
      " Regression with ARIMA(0,0,0) errors : -9118.887\n",
      " Regression with ARIMA(1,0,0) errors : -12570.44\n",
      " Regression with ARIMA(0,0,1) errors : -10762.54\n",
      " Regression with ARIMA(0,0,0) errors : -8023.134\n",
      " Regression with ARIMA(1,0,2) errors : -12586.06\n",
      " Regression with ARIMA(2,0,1) errors : -12584.58\n",
      " Regression with ARIMA(3,0,2) errors : -12650.24\n",
      " Regression with ARIMA(3,0,1) errors : -12595.09\n",
      " Regression with ARIMA(4,0,2) errors : -12610.13\n",
      " Regression with ARIMA(3,0,3) errors : -12611.25\n",
      " Regression with ARIMA(2,0,3) errors : -12607.47\n",
      " Regression with ARIMA(4,0,1) errors : -12610.04\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12562.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12652.57\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12605.76\n",
      " Regression with ARIMA(0,0,0) errors : -9124.298\n",
      " Regression with ARIMA(1,0,0) errors : -12585.84\n",
      " Regression with ARIMA(0,0,1) errors : -10776.69\n",
      " Regression with ARIMA(0,0,0) errors : -8072.897\n",
      " Regression with ARIMA(1,0,2) errors : -12601.79\n",
      " Regression with ARIMA(2,0,1) errors : -12600.13\n",
      " Regression with ARIMA(3,0,2) errors : -12662.69\n",
      " Regression with ARIMA(3,0,1) errors : -12612.34\n",
      " Regression with ARIMA(4,0,2) errors : -12629.9\n",
      " Regression with ARIMA(3,0,3) errors : -12629.01\n",
      " Regression with ARIMA(2,0,3) errors : -12623.63\n",
      " Regression with ARIMA(4,0,1) errors : -12627.83\n",
      " Regression with ARIMA(4,0,3) errors : -12662.1\n",
      " Regression with ARIMA(3,0,2) errors : -12538.49\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12668.81\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12617.98\n",
      " Regression with ARIMA(0,0,0) errors : -9103.826\n",
      " Regression with ARIMA(1,0,0) errors : -12597.39\n",
      " Regression with ARIMA(0,0,1) errors : -10769.07\n",
      " Regression with ARIMA(0,0,0) errors : -8071.78\n",
      " Regression with ARIMA(1,0,2) errors : -12613.58\n",
      " Regression with ARIMA(2,0,1) errors : -12612.03\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12634.81\n",
      " Regression with ARIMA(1,0,3) errors : -12637.74\n",
      " Regression with ARIMA(0,0,3) errors : -11857.74\n",
      " Regression with ARIMA(1,0,4) errors : -12635.79\n",
      " Regression with ARIMA(0,0,2) errors : -11425.89\n",
      " Regression with ARIMA(0,0,4) errors : -12183.34\n",
      " Regression with ARIMA(2,0,4) errors : -12660.74\n",
      " Regression with ARIMA(3,0,4) errors : -12661.91\n",
      " Regression with ARIMA(3,0,3) errors : -12639.57\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12664.79\n",
      " Regression with ARIMA(1,0,5) errors : -12637.48\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12662.8\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12648.96\n",
      " Regression with ARIMA(0,0,0) errors : -9121.032\n",
      " Regression with ARIMA(1,0,0) errors : -12628.13\n",
      " Regression with ARIMA(0,0,1) errors : -10785.99\n",
      " Regression with ARIMA(0,0,0) errors : -8086.924\n",
      " Regression with ARIMA(1,0,2) errors : -12643.58\n",
      " Regression with ARIMA(2,0,1) errors : -12645.29\n",
      " Regression with ARIMA(3,0,2) errors : -12693.39\n",
      " Regression with ARIMA(3,0,1) errors : -12657.07\n",
      " Regression with ARIMA(4,0,2) errors : -12674.99\n",
      " Regression with ARIMA(3,0,3) errors : -12674.05\n",
      " Regression with ARIMA(2,0,3) errors : -12670.13\n",
      " Regression with ARIMA(4,0,1) errors : -12673.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -12586.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -12712.63\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12660.79\n",
      " Regression with ARIMA(0,0,0) errors : -9128.864\n",
      " Regression with ARIMA(1,0,0) errors : -12639.5\n",
      " Regression with ARIMA(0,0,1) errors : -10794.45\n",
      " Regression with ARIMA(0,0,0) errors : -8086.79\n",
      " Regression with ARIMA(1,0,2) errors : -12656.36\n",
      " Regression with ARIMA(2,0,1) errors : -12654.67\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12681.02\n",
      " Regression with ARIMA(1,0,3) errors : -12683.93\n",
      " Regression with ARIMA(0,0,3) errors : -11882.7\n",
      " Regression with ARIMA(1,0,4) errors : -12681.93\n",
      " Regression with ARIMA(0,0,2) errors : -11451.05\n",
      " Regression with ARIMA(0,0,4) errors : -12222.24\n",
      " Regression with ARIMA(2,0,4) errors : -12708.43\n",
      " Regression with ARIMA(3,0,4) errors : -12700.64\n",
      " Regression with ARIMA(2,0,5) errors : -12711.77\n",
      " Regression with ARIMA(1,0,5) errors : -12684.46\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12635.99\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12712.16\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12663.87\n",
      " Regression with ARIMA(0,0,0) errors : -9125.032\n",
      " Regression with ARIMA(1,0,0) errors : -12642.83\n",
      " Regression with ARIMA(0,0,1) errors : -10795.06\n",
      " Regression with ARIMA(0,0,0) errors : -8088.558\n",
      " Regression with ARIMA(1,0,2) errors : -12659.49\n",
      " Regression with ARIMA(2,0,1) errors : -12657.96\n",
      " Regression with ARIMA(3,0,2) errors : -12717.9\n",
      " Regression with ARIMA(3,0,1) errors : -12671.05\n",
      " Regression with ARIMA(4,0,2) errors : -12688.31\n",
      " Regression with ARIMA(3,0,3) errors : -12688.66\n",
      " Regression with ARIMA(2,0,3) errors : -12684.8\n",
      " Regression with ARIMA(4,0,1) errors : -12687.93\n",
      " Regression with ARIMA(4,0,3) errors : -12724.73\n",
      " Regression with ARIMA(5,0,3) errors : -12705.98\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,4) errors : -12706.33\n",
      " Regression with ARIMA(5,0,2) errors : -12704.8\n",
      " Regression with ARIMA(5,0,4) errors : -12707.76\n",
      " Regression with ARIMA(4,0,3) errors : -12626.28\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,4) errors : -12711.43\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12675.17\n",
      " Regression with ARIMA(0,0,0) errors : -9127.822\n",
      " Regression with ARIMA(1,0,0) errors : -12652.69\n",
      " Regression with ARIMA(0,0,1) errors : -10797.32\n",
      " Regression with ARIMA(0,0,0) errors : -8122.42\n",
      " Regression with ARIMA(1,0,2) errors : -12669.49\n",
      " Regression with ARIMA(2,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12695.32\n",
      " Regression with ARIMA(1,0,3) errors : -12697.68\n",
      " Regression with ARIMA(0,0,3) errors : -11885.17\n",
      " Regression with ARIMA(1,0,4) errors : -12695.67\n",
      " Regression with ARIMA(0,0,2) errors : -11454.21\n",
      " Regression with ARIMA(0,0,4) errors : -12223.07\n",
      " Regression with ARIMA(2,0,4) errors : -12724.02\n",
      " Regression with ARIMA(3,0,4) errors : -12727\n",
      " Regression with ARIMA(3,0,3) errors : -12699.87\n",
      " Regression with ARIMA(4,0,4) errors : Inf\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12728.15\n",
      " Regression with ARIMA(1,0,5) errors : -12698.24\n",
      " Regression with ARIMA(2,0,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12723.48\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12683.94\n",
      " Regression with ARIMA(0,0,0) errors : -9138.188\n",
      " Regression with ARIMA(1,0,0) errors : -12661.92\n",
      " Regression with ARIMA(0,0,1) errors : -10809.04\n",
      " Regression with ARIMA(0,0,0) errors : -8146.342\n",
      " Regression with ARIMA(1,0,2) errors : -12678.66\n",
      " Regression with ARIMA(2,0,1) errors : -12676.73\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(2,0,3) errors : -12704.85\n",
      " Regression with ARIMA(1,0,3) errors : -12707.91\n",
      " Regression with ARIMA(0,0,3) errors : -11899.86\n",
      " Regression with ARIMA(1,0,4) errors : -12705.92\n",
      " Regression with ARIMA(0,0,2) errors : -11462.84\n",
      " Regression with ARIMA(0,0,4) errors : -12239.61\n",
      " Regression with ARIMA(2,0,4) errors : -12733.61\n",
      " Regression with ARIMA(3,0,4) errors : -12727.8\n",
      " Regression with ARIMA(2,0,5) errors : -12736.88\n",
      " Regression with ARIMA(1,0,5) errors : -12708.11\n",
      " Regression with ARIMA(3,0,5) errors : Inf\n",
      " Regression with ARIMA(2,0,5) errors : -12658.61\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,5) errors : -12738.19\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12707.9\n",
      " Regression with ARIMA(0,0,0) errors : -9146.696\n",
      " Regression with ARIMA(1,0,0) errors : -12685.85\n",
      " Regression with ARIMA(0,0,1) errors : -10816.31\n",
      " Regression with ARIMA(0,0,0) errors : -8145.991\n",
      " Regression with ARIMA(1,0,2) errors : -12701.98\n",
      " Regression with ARIMA(2,0,1) errors : -12702.83\n",
      " Regression with ARIMA(3,0,2) errors : -12752.59\n",
      " Regression with ARIMA(3,0,1) errors : -12716.78\n",
      " Regression with ARIMA(4,0,2) errors : -12776.93\n",
      " Regression with ARIMA(4,0,1) errors : -12738.81\n",
      " Regression with ARIMA(5,0,2) errors : -12750.69\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -12740.15\n",
      " Regression with ARIMA(5,0,1) errors : -12807.17\n",
      " Regression with ARIMA(5,0,0) errors : -12741.34\n",
      " Regression with ARIMA(4,0,0) errors : -12738.7\n",
      " Regression with ARIMA(5,0,1) errors : -12728.9\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,1) errors : -12760.88\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -12912.84\n",
      " Regression with ARIMA(0,0,0) errors : -9287.558\n",
      " Regression with ARIMA(1,0,0) errors : -12838.23\n",
      " Regression with ARIMA(0,0,1) errors : -10970.44\n",
      " Regression with ARIMA(0,0,0) errors : -8334.607\n",
      " Regression with ARIMA(1,0,2) errors : -12850.07\n",
      " Regression with ARIMA(2,0,1) errors : -12896.83\n",
      " Regression with ARIMA(3,0,2) errors : -12886.59\n",
      " Regression with ARIMA(2,0,3) errors : -12920.49\n",
      " Regression with ARIMA(1,0,3) errors : -12869.31\n",
      " Regression with ARIMA(3,0,3) errors : -12922.93\n",
      " Regression with ARIMA(4,0,3) errors : -12951.22\n",
      " Regression with ARIMA(4,0,2) errors : -12979.64\n",
      " Regression with ARIMA(4,0,1) errors : -12919.17\n",
      " Regression with ARIMA(5,0,2) errors : -13016.01\n",
      " Regression with ARIMA(5,0,1) errors : -12918.05\n",
      " Regression with ARIMA(5,0,3) errors : -13009.45\n",
      " Regression with ARIMA(5,0,2) errors : -12924.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -12851.52\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -13340.53\n",
      " Regression with ARIMA(0,0,0) errors : -9896.247\n",
      " Regression with ARIMA(1,0,0) errors : -13321.04\n",
      " Regression with ARIMA(0,0,1) errors : -11543.52\n",
      " Regression with ARIMA(0,0,0) errors : -8940.049\n",
      " Regression with ARIMA(1,0,2) errors : -13322.44\n",
      " Regression with ARIMA(2,0,1) errors : -13321.63\n",
      " Regression with ARIMA(3,0,2) errors : -13355.77\n",
      " Regression with ARIMA(3,0,1) errors : -13337\n",
      " Regression with ARIMA(4,0,2) errors : -13354.79\n",
      " Regression with ARIMA(3,0,3) errors : -13380.32\n",
      " Regression with ARIMA(2,0,3) errors : -13333.79\n",
      " Regression with ARIMA(4,0,3) errors : -13412.84\n",
      " Regression with ARIMA(5,0,3) errors : -13428.89\n",
      " Regression with ARIMA(5,0,2) errors : -13429.21\n",
      " Regression with ARIMA(5,0,1) errors : -13348.63\n",
      " Regression with ARIMA(4,0,1) errors : -13348.07\n",
      " Regression with ARIMA(5,0,2) errors : -13296.63\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -13383.36\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13638.8\n",
      " Regression with ARIMA(0,1,0) errors : -13557.1\n",
      " Regression with ARIMA(1,1,0) errors : -13569.73\n",
      " Regression with ARIMA(0,1,1) errors : -13568.98\n",
      " Regression with ARIMA(0,1,0) errors : -13559.1\n",
      " Regression with ARIMA(1,1,2) errors : -13569.88\n",
      " Regression with ARIMA(2,1,1) errors : -13572.21\n",
      " Regression with ARIMA(3,1,2) errors : -13655.74\n",
      " Regression with ARIMA(3,1,1) errors : -13608.61\n",
      " Regression with ARIMA(4,1,2) errors : -13690.96\n",
      " Regression with ARIMA(4,1,1) errors : -13635.24\n",
      " Regression with ARIMA(5,1,2) errors : -13685.37\n",
      " Regression with ARIMA(4,1,3) errors : -13668.95\n",
      " Regression with ARIMA(3,1,3) errors : -13656.78\n",
      " Regression with ARIMA(5,1,1) errors : -13674.36\n",
      " Regression with ARIMA(5,1,3) errors : -13699.07\n",
      " Regression with ARIMA(5,1,4) errors : -13798\n",
      " Regression with ARIMA(4,1,4) errors : -13766.7\n",
      " Regression with ARIMA(5,1,5) errors : -13796.13\n",
      " Regression with ARIMA(4,1,5) errors : -13791.29\n",
      " Regression with ARIMA(5,1,4) errors : -13800.01\n",
      " Regression with ARIMA(4,1,4) errors : -13768.68\n",
      " Regression with ARIMA(5,1,3) errors : -13701.1\n",
      " Regression with ARIMA(5,1,5) errors : -13798.15\n",
      " Regression with ARIMA(4,1,3) errors : -13669.36\n",
      " Regression with ARIMA(4,1,5) errors : -13793.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,4) errors : -13627.14\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13856.97\n",
      " Regression with ARIMA(0,1,0) errors : -13830.28\n",
      " Regression with ARIMA(1,1,0) errors : -13844.83\n",
      " Regression with ARIMA(0,1,1) errors : -13841.77\n",
      " Regression with ARIMA(0,1,0) errors : -13832.29\n",
      " Regression with ARIMA(1,1,2) errors : -13852.88\n",
      " Regression with ARIMA(2,1,1) errors : -13857.98\n",
      " Regression with ARIMA(1,1,1) errors : -13853.24\n",
      " Regression with ARIMA(2,1,0) errors : -13857.59\n",
      " Regression with ARIMA(3,1,1) errors : -13856.45\n",
      " Regression with ARIMA(3,1,0) errors : -13855.79\n",
      " Regression with ARIMA(3,1,2) errors : -13853.87\n",
      " Regression with ARIMA(2,1,1) errors : -13859.99\n",
      " Regression with ARIMA(1,1,1) errors : -13855.24\n",
      " Regression with ARIMA(2,1,0) errors : -13859.61\n",
      " Regression with ARIMA(3,1,1) errors : -13858.47\n",
      " Regression with ARIMA(2,1,2) errors : -13858.99\n",
      " Regression with ARIMA(1,1,0) errors : -13846.84\n",
      " Regression with ARIMA(1,1,2) errors : -13854.88\n",
      " Regression with ARIMA(3,1,0) errors : -13857.8\n",
      " Regression with ARIMA(3,1,2) errors : -13855.89\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,1) errors : -13852.22\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,1) errors \n",
      "\n",
      "[1] \"90 % done.\"\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -13947.36\n",
      " Regression with ARIMA(0,1,0) errors : -13900.86\n",
      " Regression with ARIMA(1,1,0) errors : -13932.84\n",
      " Regression with ARIMA(0,1,1) errors : -13911.73\n",
      " Regression with ARIMA(0,1,0) errors : -13902.87\n",
      " Regression with ARIMA(1,1,2) errors : -13939.01\n",
      " Regression with ARIMA(2,1,1) errors : -13943.65\n",
      " Regression with ARIMA(3,1,2) errors : -13959.09\n",
      " Regression with ARIMA(3,1,1) errors : -13956.45\n",
      " Regression with ARIMA(4,1,2) errors : -14000.17\n",
      " Regression with ARIMA(4,1,1) errors : -13952.05\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : -14004.61\n",
      " Regression with ARIMA(3,1,3) errors : -13984.19\n",
      " Regression with ARIMA(5,1,3) errors : -14058.98\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : -14034.52\n",
      " Regression with ARIMA(5,1,3) errors : -14060.9\n",
      " Regression with ARIMA(4,1,3) errors : -14006.63\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : -14002.15\n",
      " Regression with ARIMA(4,1,4) errors : -14036.43\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : -13974.19\n",
      "\n",
      " Best model: Regression with ARIMA(4,1,3) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14051.09\n",
      " Regression with ARIMA(0,1,0) errors : -14017.53\n",
      " Regression with ARIMA(1,1,0) errors : -14026.02\n",
      " Regression with ARIMA(0,1,1) errors : -14026.4\n",
      " Regression with ARIMA(0,1,0) errors : -14019.51\n",
      " Regression with ARIMA(1,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14049.92\n",
      " Regression with ARIMA(3,1,2) errors : -14072.45\n",
      " Regression with ARIMA(3,1,1) errors : -14060.26\n",
      " Regression with ARIMA(4,1,2) errors : -14078.94\n",
      " Regression with ARIMA(4,1,1) errors : -14061.76\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : -14126.2\n",
      " Regression with ARIMA(2,1,3) errors : -14050.56\n",
      " Regression with ARIMA(3,1,4) errors : -14077.3\n",
      " Regression with ARIMA(2,1,4) errors : -14048.58\n",
      " Regression with ARIMA(4,1,4) errors : -14193.59\n",
      " Regression with ARIMA(5,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14215.31\n",
      " Regression with ARIMA(2,1,5) errors : -14059.26\n",
      " Regression with ARIMA(3,1,5) errors : -14216.42\n",
      " Regression with ARIMA(2,1,5) errors : -14061.28\n",
      " Regression with ARIMA(3,1,4) errors : -14177.43\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14050.61\n",
      " Regression with ARIMA(4,1,4) errors : -14194.71\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : -14036.04\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14232.72\n",
      " Regression with ARIMA(0,1,0) errors : -14162.77\n",
      " Regression with ARIMA(1,1,0) errors : -14185.38\n",
      " Regression with ARIMA(0,1,1) errors : -14173.07\n",
      " Regression with ARIMA(0,1,0) errors : -14164.75\n",
      " Regression with ARIMA(1,1,2) errors : -14207.81\n",
      " Regression with ARIMA(2,1,1) errors : -14224.23\n",
      " Regression with ARIMA(3,1,2) errors : -14248.4\n",
      " Regression with ARIMA(3,1,1) errors : -14225.86\n",
      " Regression with ARIMA(4,1,2) errors : -14270.04\n",
      " Regression with ARIMA(4,1,1) errors : -14226.79\n",
      " Regression with ARIMA(5,1,2) errors : -14276.69\n",
      " Regression with ARIMA(5,1,1) errors : -14239.31\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : -14278.66\n",
      " Regression with ARIMA(4,1,2) errors : -14272.05\n",
      " Regression with ARIMA(5,1,1) errors : -14241.32\n",
      " Regression with ARIMA(5,1,3) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : -14228.77\n",
      " Regression with ARIMA(4,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(5,1,1) errors : -14188.43\n",
      "\n",
      " Best model: Regression with ARIMA(5,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14269.51\n",
      " Regression with ARIMA(1,1,0) errors : -14280.67\n",
      " Regression with ARIMA(0,1,1) errors : -14275.99\n",
      " Regression with ARIMA(0,1,0) errors : -14271.49\n",
      " Regression with ARIMA(2,1,0) errors : -14280.26\n",
      " Regression with ARIMA(1,1,1) errors : -14283.64\n",
      " Regression with ARIMA(2,1,1) errors : -14282.63\n",
      " Regression with ARIMA(1,1,2) errors : -14281.81\n",
      " Regression with ARIMA(0,1,2) errors : -14276.35\n",
      " Regression with ARIMA(1,1,1) errors : -14285.62\n",
      " Regression with ARIMA(0,1,1) errors : -14277.97\n",
      " Regression with ARIMA(1,1,0) errors : -14282.66\n",
      " Regression with ARIMA(2,1,1) errors : -14284.63\n",
      " Regression with ARIMA(1,1,2) errors : -14283.8\n",
      " Regression with ARIMA(0,1,2) errors : -14278.33\n",
      " Regression with ARIMA(2,1,0) errors : -14282.25\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14292.77\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14392.52\n",
      " Regression with ARIMA(0,1,0) errors : -14319.87\n",
      " Regression with ARIMA(1,1,0) errors : -14323.95\n",
      " Regression with ARIMA(0,1,1) errors : -14324.28\n",
      " Regression with ARIMA(0,1,0) errors : -14321.88\n",
      " Regression with ARIMA(1,1,2) errors : -14328.67\n",
      " Regression with ARIMA(2,1,1) errors : -14322.2\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14396.05\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14397.58\n",
      " Regression with ARIMA(1,1,4) errors : -14325.55\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14409.11\n",
      " Regression with ARIMA(0,1,5) errors : -14329.22\n",
      " Regression with ARIMA(0,1,4) errors : -14322.36\n",
      " Regression with ARIMA(1,1,5) errors : -14410.56\n",
      " Regression with ARIMA(0,1,5) errors : -14331.23\n",
      " Regression with ARIMA(1,1,4) errors : -14327.56\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(0,1,4) errors : -14324.37\n",
      " Regression with ARIMA(2,1,4) errors : -14399.04\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,5) errors : -14340.4\n",
      "\n",
      " Best model: Regression with ARIMA(0,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14414.39\n",
      " Regression with ARIMA(0,1,0) errors : -14347.05\n",
      " Regression with ARIMA(1,1,0) errors : -14351.5\n",
      " Regression with ARIMA(0,1,1) errors : -14351.98\n",
      " Regression with ARIMA(0,1,0) errors : -14349.06\n",
      " Regression with ARIMA(1,1,2) errors : -14355.74\n",
      " Regression with ARIMA(2,1,1) errors : -14357.14\n",
      " Regression with ARIMA(3,1,2) errors : -14356.58\n",
      " Regression with ARIMA(2,1,3) errors : -14416.78\n",
      " Regression with ARIMA(1,1,3) errors : -14352.44\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14426.08\n",
      " Regression with ARIMA(1,1,4) errors : -14352.46\n",
      " Regression with ARIMA(3,1,4) errors : -14359.23\n",
      " Regression with ARIMA(2,1,5) errors : -14433.08\n",
      " Regression with ARIMA(1,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14448.43\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : -14449.79\n",
      " Regression with ARIMA(2,1,5) errors : -14434.5\n",
      " Regression with ARIMA(3,1,4) errors : -14361.25\n",
      " Regression with ARIMA(4,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14427.62\n",
      " Regression with ARIMA(4,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,4) errors : -14373.05\n",
      "\n",
      " Best model: Regression with ARIMA(3,1,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14467.17\n",
      " Regression with ARIMA(0,1,0) errors : -14387.79\n",
      " Regression with ARIMA(1,1,0) errors : -14392.42\n",
      " Regression with ARIMA(0,1,1) errors : -14393.12\n",
      " Regression with ARIMA(0,1,0) errors : -14389.79\n",
      " Regression with ARIMA(1,1,2) errors : -14393.52\n",
      " Regression with ARIMA(2,1,1) errors : -14392.46\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14467.02\n",
      " Regression with ARIMA(1,1,1) errors : -14394.63\n",
      " Regression with ARIMA(1,1,3) errors : -14391.52\n",
      " Regression with ARIMA(3,1,1) errors : -14450.2\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : -14468.77\n",
      " Regression with ARIMA(1,1,2) errors : -14395.53\n",
      " Regression with ARIMA(2,1,1) errors : -14394.46\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14468.52\n",
      " Regression with ARIMA(1,1,1) errors : -14396.63\n",
      " Regression with ARIMA(1,1,3) errors : -14393.52\n",
      " Regression with ARIMA(3,1,1) errors : -14452.03\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,1) errors : -14406.82\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11132.19\n",
      " Regression with ARIMA(1,0,0) errors : -14540.36\n",
      " Regression with ARIMA(0,0,1) errors : -12745.99\n",
      " Regression with ARIMA(0,0,0) errors : -9972.371\n",
      " Regression with ARIMA(2,0,0) errors : -14537.54\n",
      " Regression with ARIMA(1,0,1) errors : -14538.45\n",
      " Regression with ARIMA(2,0,1) errors : -14542.87\n",
      " Regression with ARIMA(3,0,1) errors : -14558.56\n",
      " Regression with ARIMA(3,0,0) errors : -14548.35\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : -14559.21\n",
      " Regression with ARIMA(4,0,2) errors : -14555.78\n",
      " Regression with ARIMA(3,0,3) errors : -14558.89\n",
      " Regression with ARIMA(2,0,3) errors : -14545.56\n",
      " Regression with ARIMA(4,0,3) errors : -14553.54\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14560.17\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11151.48\n",
      " Regression with ARIMA(1,0,0) errors : -14551.11\n",
      " Regression with ARIMA(0,0,1) errors : -12768.97\n",
      " Regression with ARIMA(0,0,0) errors : -9991.611\n",
      " Regression with ARIMA(2,0,0) errors : -14548.25\n",
      " Regression with ARIMA(1,0,1) errors : -14549.23\n",
      " Regression with ARIMA(2,0,1) errors : -14552.94\n",
      " Regression with ARIMA(3,0,1) errors : -14567.66\n",
      " Regression with ARIMA(3,0,0) errors : -14558.46\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,0) errors : -14557.43\n",
      " Regression with ARIMA(4,0,2) errors : -14572.3\n",
      " Regression with ARIMA(5,0,2) errors : Inf\n",
      " Regression with ARIMA(4,0,3) errors : -14567.45\n",
      " Regression with ARIMA(3,0,3) errors : Inf\n",
      " Regression with ARIMA(5,0,1) errors : -14571.65\n",
      " Regression with ARIMA(5,0,3) errors : -14591.07\n",
      " Regression with ARIMA(5,0,4) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -14588.65\n",
      " Regression with ARIMA(5,0,3) errors : -14466.83\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,3) errors : Inf\n",
      " Regression with ARIMA(4,0,4) errors : -14592.39\n",
      "\n",
      " Best model: Regression with ARIMA(4,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14560.15\n",
      " Regression with ARIMA(0,0,0) errors : -11132.88\n",
      " Regression with ARIMA(1,0,0) errors : -14543.96\n",
      " Regression with ARIMA(0,0,1) errors : -12748.49\n",
      " Regression with ARIMA(0,0,0) errors : -9916.669\n",
      " Regression with ARIMA(1,0,2) errors : -14552.05\n",
      " Regression with ARIMA(2,0,1) errors : -14544.14\n",
      " Regression with ARIMA(3,0,2) errors : -14551.85\n",
      " Regression with ARIMA(2,0,3) errors : Inf\n",
      " Regression with ARIMA(1,0,1) errors : -14542.09\n",
      " Regression with ARIMA(1,0,3) errors : -14551.93\n",
      " Regression with ARIMA(3,0,1) errors : -14569.13\n",
      " Regression with ARIMA(3,0,0) errors : -14553.2\n",
      " Regression with ARIMA(4,0,1) errors : Inf\n",
      " Regression with ARIMA(2,0,0) errors : -14542.46\n",
      " Regression with ARIMA(4,0,0) errors : -14553.19\n",
      " Regression with ARIMA(4,0,2) errors : -14568.72\n",
      " Regression with ARIMA(3,0,1) errors : -14400.14\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -14566.71\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11155.69\n",
      " Regression with ARIMA(1,0,0) errors : -14548.92\n",
      " Regression with ARIMA(0,0,1) errors : -12768.48\n",
      " Regression with ARIMA(0,0,0) errors : -9907.063\n",
      " Regression with ARIMA(2,0,0) errors : -14546.07\n",
      " Regression with ARIMA(1,0,1) errors : -14546.93\n",
      " Regression with ARIMA(2,0,1) errors : -14550.78\n",
      " Regression with ARIMA(3,0,1) errors : Inf\n",
      " Regression with ARIMA(1,0,2) errors : -14554.96\n",
      " Regression with ARIMA(0,0,2) errors : -13588.57\n",
      " Regression with ARIMA(1,0,3) errors : -14555.05\n",
      " Regression with ARIMA(0,0,3) errors : -13929.67\n",
      " Regression with ARIMA(2,0,3) errors : -14552.73\n",
      " Regression with ARIMA(1,0,4) errors : -14561.38\n",
      " Regression with ARIMA(0,0,4) errors : -14217.43\n",
      " Regression with ARIMA(2,0,4) errors : -14559.98\n",
      " Regression with ARIMA(1,0,5) errors : -14560.36\n",
      " Regression with ARIMA(0,0,5) errors : -14327\n",
      " Regression with ARIMA(2,0,5) errors : -14558.11\n",
      " Regression with ARIMA(1,0,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,0,4) errors : -14560.62\n",
      "\n",
      " Best model: Regression with ARIMA(1,0,4) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14379.34\n",
      " Regression with ARIMA(1,1,0) errors : -14383.72\n",
      " Regression with ARIMA(0,1,1) errors : -14382.54\n",
      " Regression with ARIMA(0,1,0) errors : -14381.35\n",
      " Regression with ARIMA(2,1,0) errors : -14382.72\n",
      " Regression with ARIMA(1,1,1) errors : -14384.5\n",
      " Regression with ARIMA(2,1,1) errors : -14382.23\n",
      " Regression with ARIMA(1,1,2) errors : -14382.66\n",
      " Regression with ARIMA(0,1,2) errors : -14382.21\n",
      " Regression with ARIMA(1,1,1) errors : -14386.51\n",
      " Regression with ARIMA(0,1,1) errors : -14384.55\n",
      " Regression with ARIMA(1,1,0) errors : -14385.73\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,2) errors : -14384.54\n",
      " Regression with ARIMA(0,1,2) errors : -14384.22\n",
      " Regression with ARIMA(2,1,0) errors : -14384.73\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14397.22\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14483.22\n",
      " Regression with ARIMA(0,0,0) errors : -11017.35\n",
      " Regression with ARIMA(1,0,0) errors : -14460.22\n",
      " Regression with ARIMA(0,0,1) errors : -12640.36\n",
      " Regression with ARIMA(0,0,0) errors : -9780.733\n",
      " Regression with ARIMA(1,0,2) errors : -14467.99\n",
      " Regression with ARIMA(2,0,1) errors : -14461.13\n",
      " Regression with ARIMA(3,0,2) errors : -14483.56\n",
      " Regression with ARIMA(3,0,1) errors : -14483.17\n",
      " Regression with ARIMA(4,0,2) errors : -14480.81\n",
      " Regression with ARIMA(3,0,3) errors : -14482.96\n",
      " Regression with ARIMA(2,0,3) errors : -14464.37\n",
      " Regression with ARIMA(4,0,1) errors : -14477.63\n",
      " Regression with ARIMA(4,0,3) errors : -14478.99\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14477.22\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14498.8\n",
      " Regression with ARIMA(0,0,0) errors : -11029\n",
      " Regression with ARIMA(1,0,0) errors : -14478.15\n",
      " Regression with ARIMA(0,0,1) errors : -12661.86\n",
      " Regression with ARIMA(0,0,0) errors : -9798.577\n",
      " Regression with ARIMA(1,0,2) errors : -14485.32\n",
      " Regression with ARIMA(2,0,1) errors : -14479.56\n",
      " Regression with ARIMA(3,0,2) errors : -14498.67\n",
      " Regression with ARIMA(2,0,3) errors : -14482.25\n",
      " Regression with ARIMA(1,0,1) errors : -14476.18\n",
      " Regression with ARIMA(1,0,3) errors : -14486.49\n",
      " Regression with ARIMA(3,0,1) errors : -14499.33\n",
      " Regression with ARIMA(3,0,0) errors : -14485.04\n",
      " Regression with ARIMA(4,0,1) errors : -14493.81\n",
      " Regression with ARIMA(2,0,0) errors : -14475.19\n",
      " Regression with ARIMA(4,0,0) errors : -14489\n",
      " Regression with ARIMA(4,0,2) errors : -14497.35\n",
      " Regression with ARIMA(3,0,1) errors : -14328.38\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,1) errors : -14499.04\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14499.82\n",
      " Regression with ARIMA(0,0,0) errors : -11030.92\n",
      " Regression with ARIMA(1,0,0) errors : -14479.83\n",
      " Regression with ARIMA(0,0,1) errors : -12666.18\n",
      " Regression with ARIMA(0,0,0) errors : -9815.953\n",
      " Regression with ARIMA(1,0,2) errors : -14487.24\n",
      " Regression with ARIMA(2,0,1) errors : -14480.13\n",
      " Regression with ARIMA(3,0,2) errors : -14499.16\n",
      " Regression with ARIMA(2,0,3) errors : -14482.98\n",
      " Regression with ARIMA(1,0,1) errors : -14477.85\n",
      " Regression with ARIMA(1,0,3) errors : -14488.5\n",
      " Regression with ARIMA(3,0,1) errors : -14497.61\n",
      " Regression with ARIMA(3,0,3) errors : -14499.03\n",
      " Regression with ARIMA(2,0,2) errors : -14337.18\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14481.43\n",
      "\n",
      " Best model: Regression with ARIMA(2,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : -14520.82\n",
      " Regression with ARIMA(0,0,0) errors : -11039.14\n",
      " Regression with ARIMA(1,0,0) errors : -14493.69\n",
      " Regression with ARIMA(0,0,1) errors : -12672\n",
      " Regression with ARIMA(0,0,0) errors : -9822.197\n",
      " Regression with ARIMA(1,0,2) errors : -14500.76\n",
      " Regression with ARIMA(2,0,1) errors : -14497.56\n",
      " Regression with ARIMA(3,0,2) errors : -14524.84\n",
      " Regression with ARIMA(3,0,1) errors : -14518.61\n",
      " Regression with ARIMA(4,0,2) errors : Inf\n",
      " Regression with ARIMA(3,0,3) errors : -14524.22\n",
      " Regression with ARIMA(2,0,3) errors : -14520.02\n",
      " Regression with ARIMA(4,0,1) errors : -14521.07\n",
      " Regression with ARIMA(4,0,3) errors : Inf\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,2) errors : -14510.48\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14421.28\n",
      " Regression with ARIMA(1,1,0) errors : -14438.68\n",
      " Regression with ARIMA(0,1,1) errors : -14424.25\n",
      " Regression with ARIMA(0,1,0) errors : -14423.29\n",
      " Regression with ARIMA(2,1,0) errors : -14439.8\n",
      " Regression with ARIMA(3,1,0) errors : -14439.79\n",
      " Regression with ARIMA(2,1,1) errors : -14444.89\n",
      " Regression with ARIMA(1,1,1) errors : -14446.77\n",
      " Regression with ARIMA(1,1,2) errors : -14444.79\n",
      " Regression with ARIMA(0,1,2) errors : -14423.33\n",
      " Regression with ARIMA(1,1,1) errors : -14448.78\n",
      " Regression with ARIMA(0,1,1) errors : -14426.26\n",
      " Regression with ARIMA(1,1,0) errors : -14440.69\n",
      " Regression with ARIMA(2,1,1) errors : -14446.9\n",
      " Regression with ARIMA(1,1,2) errors : -14446.8\n",
      " Regression with ARIMA(0,1,2) errors : -14425.34\n",
      " Regression with ARIMA(2,1,0) errors : -14441.81\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(1,1,1) errors : -14440.01\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14553.28\n",
      " Regression with ARIMA(0,1,0) errors : -14483.96\n",
      " Regression with ARIMA(1,1,0) errors : -14484.77\n",
      " Regression with ARIMA(0,1,1) errors : -14485.54\n",
      " Regression with ARIMA(0,1,0) errors : -14485.96\n",
      " Regression with ARIMA(1,1,2) errors : -14488.25\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14562.68\n",
      " Regression with ARIMA(1,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14567.68\n",
      " Regression with ARIMA(1,1,4) errors : -14484.21\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14585.28\n",
      " Regression with ARIMA(1,1,5) errors : -14492.24\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : -14586.81\n",
      " Regression with ARIMA(1,1,5) errors : -14494.25\n",
      " Regression with ARIMA(2,1,4) errors : -14569.27\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,4) errors : -14485.81\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14504.5\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : -14595.43\n",
      " Regression with ARIMA(0,1,0) errors : -14527.09\n",
      " Regression with ARIMA(1,1,0) errors : -14529.37\n",
      " Regression with ARIMA(0,1,1) errors : -14529.7\n",
      " Regression with ARIMA(0,1,0) errors : -14529.09\n",
      " Regression with ARIMA(1,1,2) errors : -14533.99\n",
      " Regression with ARIMA(2,1,1) errors : -14543.6\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : -14601.94\n",
      " Regression with ARIMA(1,1,3) errors : -14532.49\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14605.78\n",
      " Regression with ARIMA(1,1,4) errors : -14530.67\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14537.39\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : -14607.58\n",
      " Regression with ARIMA(1,1,4) errors : -14532.67\n",
      " Regression with ARIMA(2,1,3) errors : -14603.75\n",
      " Regression with ARIMA(3,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,5) errors : Inf\n",
      " Regression with ARIMA(1,1,3) errors : -14534.49\n",
      " Regression with ARIMA(1,1,5) errors : -14539.39\n",
      " Regression with ARIMA(3,1,3) errors : -14598.8\n",
      " Regression with ARIMA(3,1,5) errors : Inf\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,4) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,3) errors : Inf\n",
      " Regression with ARIMA(3,1,3) errors : Inf\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : Inf\n",
      " Regression with ARIMA(1,1,5) errors : -14549.06\n",
      "\n",
      " Best model: Regression with ARIMA(1,1,5) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(0,1,0) errors : -14516.87\n",
      " Regression with ARIMA(1,1,0) errors : -14525.36\n",
      " Regression with ARIMA(0,1,1) errors : -14520.46\n",
      " Regression with ARIMA(0,1,0) errors : -14518.88\n",
      " Regression with ARIMA(2,1,0) errors : -14523.87\n",
      " Regression with ARIMA(1,1,1) errors : -14523.58\n",
      " Regression with ARIMA(2,1,1) errors : -14528.44\n",
      " Regression with ARIMA(3,1,1) errors : -14605.73\n",
      " Regression with ARIMA(3,1,0) errors : -14522.73\n",
      " Regression with ARIMA(4,1,1) errors : -14552.02\n",
      " Regression with ARIMA(3,1,2) errors : -14601.37\n",
      " Regression with ARIMA(4,1,0) errors : -14523.8\n",
      " Regression with ARIMA(4,1,2) errors : -14570.42\n",
      " Regression with ARIMA(3,1,1) errors : -14607.28\n",
      " Regression with ARIMA(2,1,1) errors : -14530.46\n",
      " Regression with ARIMA(3,1,0) errors : -14524.74\n",
      " Regression with ARIMA(4,1,1) errors : -14553.78\n",
      " Regression with ARIMA(3,1,2) errors : -14602.92\n",
      " Regression with ARIMA(2,1,0) errors : -14525.88\n",
      " Regression with ARIMA(2,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,0) errors : -14525.81\n",
      " Regression with ARIMA(4,1,2) errors : -14572.1\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,1) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(3,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,2) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(4,1,1) errors : Inf\n",
      " Regression with ARIMA(2,1,1) errors : -14535.51\n",
      "\n",
      " Best model: Regression with ARIMA(2,1,1) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11250.18\n",
      " Regression with ARIMA(1,0,0) errors : -14656.36\n",
      " Regression with ARIMA(0,0,1) errors : -12862.56\n",
      " Regression with ARIMA(0,0,0) errors : -10027.92\n",
      " Regression with ARIMA(2,0,0) errors : -14654.03\n",
      " Regression with ARIMA(1,0,1) errors : -14654.36\n",
      " Regression with ARIMA(2,0,1) errors : -14660.84\n",
      " Regression with ARIMA(3,0,1) errors : -14661.21\n",
      " Regression with ARIMA(3,0,0) errors : -14664.08\n",
      " Regression with ARIMA(4,0,0) errors : -14664.12\n",
      " Regression with ARIMA(5,0,0) errors : -14670.91\n",
      " Regression with ARIMA(5,0,1) errors : -14674.19\n",
      " Regression with ARIMA(4,0,1) errors : -14674.78\n",
      " Regression with ARIMA(4,0,2) errors : -14678.29\n",
      " Regression with ARIMA(3,0,2) errors : Inf\n",
      " Regression with ARIMA(5,0,2) errors : -14693.27\n",
      " Regression with ARIMA(5,0,3) errors : -14691.32\n",
      " Regression with ARIMA(4,0,3) errors : -14661.91\n",
      " Regression with ARIMA(5,0,2) errors : -14579.72\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(5,0,2) errors : -14701.58\n",
      "\n",
      " Best model: Regression with ARIMA(5,0,2) errors \n",
      "\n",
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " Regression with ARIMA(2,0,2) errors : Inf\n",
      " Regression with ARIMA(0,0,0) errors : -11249.56\n",
      " Regression with ARIMA(1,0,0) errors : -14656.24\n",
      " Regression with ARIMA(0,0,1) errors : -12864.81\n",
      " Regression with ARIMA(0,0,0) errors : -10027.74\n",
      " Regression with ARIMA(2,0,0) errors : -14657.78\n",
      " Regression with ARIMA(3,0,0) errors : -14666.92\n",
      " Regression with ARIMA(4,0,0) errors : -14666.09\n",
      " Regression with ARIMA(3,0,1) errors : -14664.16\n",
      " Regression with ARIMA(2,0,1) errors : -14658.57\n",
      " Regression with ARIMA(4,0,1) errors : -14666.46\n",
      " Regression with ARIMA(3,0,0) errors : -14546.26\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " Regression with ARIMA(3,0,0) errors : -14662.78\n",
      "\n",
      " Best model: Regression with ARIMA(3,0,0) errors \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.m03.3 <- my.tsCV.2(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                      xreg.msize=hori,\n",
    "                      xreg=trainx[,2:4],\n",
    "                      sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfd95132-f6b6-449a-80b4-b9750616bde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-01-24\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m03.3\n",
    "from <- na.omit(x[,1])[1]\n",
    "from <- index(train[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53f2b51-a9df-4dbd-bdd6-d77af2fe524f",
   "metadata": {},
   "source": [
    "## Compare Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed9c467c-feac-4461-816b-ac6a0abcae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "my.figsize(10,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e499e5ce-1237-49e0-a787-a1be8de29cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94\nAAAgAElEQVR4nOzdeWBM5/7H8e8sWWSVXSJBRMTSiqW1FCUlllCUa22utVxFW/21ilsatXRB\na7laYl9Le1XVvlyt4paqpdRWO1lIRGRfJzO/P8YdkRCDTAbn/fprznOec873DCGfec48j8pg\nMAgAAAAAQHnU1i4AAAAAAGAdBEIAAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAACkUgBAAA\nAACFIhACAAAAgEIRCAEAAABAobTWLsCy0tPTdTqdtavAbRqNxsnJKS8vLzs729q1AEWpVCoX\nFxedTpeZmWntWoB7cHFx0ev1GRkZ1i4Ed7i5uVm7BAB4XM94INTr9QUFBdauAneo1WoR4Q8F\nTyCVSsXfTzzJ+PsJALAEHhkFAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQ\nKAIhAAAAACgUgRAAAAAAFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAA\noFAEQgAAAABQKAIhAAAAACgUgRAAAAAAFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEIAQAA\nAEChCIQAAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAAFIpACAAAAAAKpbV2AQBgfQaD4bff\nfrtw4YKjo2PdunUrV65s7YqAO/Ly8jZu3HjhwgWNRlO7du02bdqo1XyeCwAoHSqDwWDtGiwo\nNTU1Pz/f2lXgNo1G4+bmlpOTk5GRYe1agDtyc3OHDx8eGxtr3FSr1V27dn3jjTesWxVglJ2d\nPXLkyCtXrpha6tWrN2XKFDLhk8DT09PaJQDA4+K/EwBKN2XKFFMaFBG9Xr927dpDhw5ZsSTA\nZNmyZYXToIgcPXp0w4YN1qoHAPCMIRACULp7Zr9Vq1aVfSVAcb///ruZjQAAPAICIQBF0+v1\ner2+eHtycnLZFwMUp9PpijcWFBSUfSUAgGcSgRCAoqnV6nt+F8vd3b3siwGKq1mzZvHGGjVq\nlH0lAIBnEoEQgNI1bNiweOPf//73sq8EKG7gwIHOzs6FW3x9fXv27GmtegAAzxhmGUXZYZZR\nPJlyc3MHDx6cmJho3FSpVB07dhw+fLh1qwJMrl+/vnz58jNnzmi12tDQ0MjISFdXV2sXBRFm\nGQXwTGAdQgBKd/78eVMaFBGDwXD8+PG8vDxbW1srVgWYVKhQ4YMPPvDw8NDr9bdu3bJ2OQCA\nZwqPjAJQuujo6CItV65c2bRpk1WKAe4nPj6+8CcXAACUCgIhAEUzGAwXLlwo3n7PRsCKevfu\n/c4771i7CgDAs4ZACEDRVCrVPdtTUlLKuBIAAICyRyAEoHT3zIT3XIsCAADgGcNvPAAUzWAw\n3HOyZRcXl7IvBgAAoIwRCAEomkqlql69evH2kJCQsi8GAACgjBEIASjdm2++aWNjU7glKCio\nffv21qoHAACgzBAIAShd9erVp0+f3qBBAxcXF19f306dOn322WdFIiIAAMAziYXpAUBCQkI+\n+eQTDw+PvLy8tLQ0a5cDAABQRhghBAAAAACFIhACAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIA\nAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAACkUgBAAAAACFIhACAAAAgEIRCAEAAABAoQiE\nAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAACkUgBAAAAACFIhACAAAAgEIR\nCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAACkUgBAAAAACF\nIhACAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAA\nCkUgBAAAAACFIhACAAAAgEIRCAEAAABAoQiEAAAAAKBQBEIAEBHJyckZM2bMsmXLrF0IAABA\n2SEQAoCIiE6n+89//nPs2DFrFwIAAFB2CIQAAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAA\nFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAA\nACgUgRAAAAAAFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAA\nAABQKAIhAAAAACgUgRAAAAAAFIpACAAAAAAKRSAEAAAAAIXSWrsAKMWlS5eio6NjYmJcXFxa\ntWrVtWtXtZrPIwAAAABrIhCiLBw6dOijjz7S6/UicvPmzYULFx44cGD69OnWrgsAAABQNIZo\nUBY++eQTYxo0OXHixK5du6xVDwAAAAAhEKIMJCYmZmVlFW/fuXNn2RcDAAAAwIRACIu7ZxoU\nkby8vDKuBAAAAEBhz/h3CB0dHTUajbWrULry5ctrNJqCgoIi7S+++KKHh4dVSgKKs7W1FRG1\nWs1fSzyxVCoVfz8BAKXrGQ+EmZmZ+fn51q4C0qlTpx9++KFwi5OTU9euXW/evGmtkoAiMjMz\nRUSv1/PXEk8sg8HA388niqenp7VLAIDHxSOjKAtDhgzp1q2babS2SpUqs2fPtrOzs25VAAAA\ngMI94yOEeEKoVKrBgwe/8cYbWVlZDg4OKpXK2hUBAAAAYIQQZUir1VauXNnZ2dnahQAAAAAQ\nIRACAAAAgGIRCAEAAABAoQiEAAAAAKBQBEIAAAAAUCgCIQAAAAAoFIEQAAAAABSKQAgAAAAA\nCkUgBAAAAACFIhACAAAAgEIRCAEAAABAoQiEAAAAAKBQWmsXAAW5cuXKoUOHHBwcAgMDbW1t\nrV0OAAAAoHQEQpSFvLy8qVOn7tu3z7jp7e09atSo559/3rpVAQAAAArHI6MoCwsXLjSlQRFJ\nTEycPHlySkqKFUsCAAAAQCCExeXn52/durVIY2pq6u7du61RDgAAAIDbCISwuNTU1Pz8/OLt\nN2/eLPtiAAAAAJgQCGFxrq6udnZ2xdu9vb3LvhgAAAAAJgRCWJyNjc1rr71WpNHLy6tly5bW\nKAcAAADAbQRClIXIyMiOHTuaNqtUqRIVFeXs7GzFkgAAAACw7ATKglarHTFiRN++fW/evOng\n4ODl5aVW82EEAAAAYGUEQpQdNze3qlWr5uTkZGRkWLsWAAAAADwyCgAAAABKRSAEAAAAAIUi\nEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAAFIpACAAAAAAK\nRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAA\nFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAA\nACgUgRAAAAAAFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAA\nAABQKAIhAAAAACgUgRAAAAAAFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQA\nAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAAFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEI\nAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAAFIpACAAAAAAKRSAEAAAAAIUi\nEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAAFIpACAAAAAAK\nRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAAACgUgRAAAAAA\nFIpACAAAAAAKRSAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKAIhAAAA\nACgUgRAAAAAAFEpr7QIAPFnS09MzMzOtXYUVZGVliUhubu7169etXYt1eHh42NjYWLsKAABQ\npgiEKDtxcXH9+/cPCwuLjIy0di24t+zs7L59+2ZnZ1u7EKs5evRo//79rV2FdbRo0WLs2LHW\nrgIAAJQpAiHKTn5+flxcXGpqqrULwX1lZmZmZ2fnuUhmZZ4nVxKDwe2E4ebNm9auAwAAlDUC\nIYCiMiupLvbRWLsKlB1VgbiNy7d2FQAAwAoYBAAAAAAAhSIQAgAAAIBCEQgBAAAAQKEIhAAA\nAACgUJadVCYjI2P+/Pm///67Tqd77rnn3nzzTW9vbzP7xMTELFmy5MyZM3q9PjAwsF+/fjVq\n1DDznAAAAACAB7LsCOHMmTOvXr06adKkGTNmaDSaiRMn6vV6c/rk5+ePGzfO2dl52rRpM2bM\n8PHxmTBhgnFtNHPOCQAAAAB4IAsGwqSkpIMHD7799tvVqlXz9/cfOXJkXFzcsWPHzOmTlZXV\npUuXoUOHVqxY0dfXt3v37llZWdevXzfnnAAAAAAAc1gwEJ47d87W1jYwMNC46eTkFBAQcO7c\nOXP6uLq6vvbaa+XKlROR9PT0DRs2+Pv7+/v7m3NOAAAAAIA5LPgdwrS0NGdnZ5VKZWpxdXVN\nTU01v49er//b3/6m0+lq1649efJkGxubB57z4sWLmzdvNm1GRET4+fmV+q3h0djb24uISqVy\ndHS0di24t6ysLGuXAKvRaDT8bD7h+PcTAFDqLDupTOHkJiIGg+Gh+qjV6lmzZqWkpGzYsOHD\nDz+cPn36A8955cqVZcuWmTYbNWoUFBT0GHeA0mRraysiarXaOPaLJ5AxtEOZnoqfzatXr16/\nft3aVViHXq/Pzs7+888/rV2IdVSuXNnHx8faVQDAM8iCgbB8+fJpaWkGg8EU4VJTU93c3B6q\nT0BAQEBAQK1atfr27bt7925PT8+S+4eGhn799deFDy8yJgkrMo4+6fV6/lCeWOnp6dYuAVaj\n0+me/J/Nvn37ZmRkWLsKq4mPjx82bJi1q7COoKCg+fPnW7uKolxdXa1dAgA8LgsGwurVq+fn\n558/fz44OFhEUlNTY2JijEtHPLDPsWPHvvrqq9mzZxvHK9RqtUqlMhgMDzynu7t7w4YNTZup\nqan5+fmWu0c8FJ1OJyIGg4E/lCcWfzRK9lT8bGZlZdk4+Xg+18PahaBMJR5elJGR8eT//QSA\np5EFA6Gbm1vTpk3/9a9/vf3223Z2dgsXLqxWrVrt2rVFZOfOnTk5Oa+++ur9+mRlZeXm5s6a\nNatPnz42NjYbN27MycmpX79+CecEACiBjYOnV71+1q4CZerGsVXWLgEAnlmW/Q7hiBEjFixY\nMG7cOL1eX69evZEjRxof9fzjjz/S0tJeffXV+/VxdHScOHHismXLxowZU1BQULly5Y8++sg4\nPcz9zgkAAAAAeCiWDYQODg7vvPPOO++8U6R91KhRD+xjDIHmnxMAAAAA8FAsuA4hAAAAAOBJ\nRiAEAAAAAIUiEAIAAACAQhEIAQAAAEChCIQAAAAAoFAEQgAAAABQKMsuOwEAFncpSxbHyMl0\nyddLFQfpXVFecnvEzuczZVmsnMuQbL342UsHb4nwFvX/VjrVGWRNnOy4ITfzxctWIrylu5+Y\nlkH9I01Wx8nFTNEZxL+cdKkgr3gKi6QCAIAnGyOEAJ5mcTnyfyclNlsGBMjIquKokY//kl+T\nH6XzqXR556RczZK/+ck/Kkt5rcy+JIuu3jn8s/OyMk6au8v7VaWOiyy8Kitjb+86cEtGn5J0\nnUT6y8BKYqOSz8/LN3GWvHMAAIBSwAghgKfZilgpMMgXtcXdRkQkzEOG/SnRV6SJ+z1G50ru\nvCRG7NQy8zlxsxERae8tw/+UDQkysJJoVHIoRfbclDeryGsVRETCPCVTJ8fSJFJEJbI4RirY\nyYzaYqe+feyQ47I2XvpUZJAQAAA8yRghBPDU0htk/y1p5HY74ImIWiVtvORarlzMfOjOrTxl\nRJXbaVBEVCI1nSRXLxk6EZGdSeKokY7ed044vrpMryUqEYNIe28ZWuV2GhQRrUpqOUlmgeTq\nLXHfAAAApYURQgBPreu5kl0gVR3uaqzmKCJyMUuCHB+ucztvKSIuR1y14mIjInIqXWo6i41a\nRMQgd437qeT2sKGJQeRylnjZij0fugEAgCcagRDAUys5X0TujOkZlbcREbmZ/1idRWTPTTmS\nKoMq3R4DTMyVF8rLlkT5Ll6u5YijVlp4yJBKUk5z55B8vdzKl6Q82ZAgF7NkbPBj3R0AAIDl\nEQgBPLXy9CIi2rtH4YyDePnFntV8qM6/pci0C9LITXr4iYjkFIhB5HCKnM+UAQHirJXDKfL9\ndYnPkc9r3jnqz3QZc1pExMdOoqpLo/tPdgoAAPBkIBACeGrZ3ivOGYOfbbFnNc3vvCFBvr4s\nzdxlTLXbj4ZqVSIi2QUyr444aERE6rtKgci6a3ImQ2o43T4wyFEmhkhqvhxOlY/+kp4VZWDA\nY94iAACARREIATy1jNPD3Lr7gc/kPBERT9tH7Dzviqy7Jr38ZEClO18UtFGLg0aqONxOg0YN\nXGXdNbmUdScQumqlsZuISFtv8baTNXHS1E1CnAQAAOBJxYQHAJ5avvbipJWzd08o+leGiEiw\n46N0XhIjP1yTkVVlYKWiy0VUcyz6VUOdQUTERi0p+bIp4fapTJ5zFhG5lPWQtwQAAFCmCIQA\nnloqkebu8nuKJOTebsnTy7YbUtVBKpV76M5HUmV1nLxZRSKKTTcqIi08JDZbDqfeafnlpohI\nTSexUcvXl2X+VTEU6n80VUTE2+7x7xIAAMByeGQUwNMs0l9+TZb3T8lrFcReI1sTJSFXPvvf\nRC/7b8nHZ2VoZelS4QGdCwwy55K4asVOLVsT77pEfVfxsZP23rItUSb8Jd18xddeDqXILzel\nrZdUtBcR6VVRVsbKeyeluYfYqOTPdNmdJLWcpZ5rWb4ZeALdiv3z8Lp/JpzfV6DLda/4fJ0O\n/6xUt/Ojdb555cjRH6OSrhzS5WY6ewWFtPhHyMuDVWpNkZOkJZ5fP6GO1tahz8wkU+O1Mz8d\n2/zJrZhj+oJ8F5/qtVq/HdTodVEVGQcHACgRgRDA08zLVmbUlgVXZXmsFBgk2FE+qymhLrf3\nGgyiN4je8ODOGQUSmyMiMuNi0UtMqC4+dqJVyec1ZUmMbEuUNJ1420n/AOnpd7tPX3+paC8b\nE2RlrOgM4mMn/QLktQpFnzuFwqQlnNvyeXN7F+8Gr02xKedy/tflu756rdWwdZXqdXnYzokX\n9m+bFubgVvG5tu/b2DtfOfz9/pVvpt+48GL3aXedxWD477LBBXnZWts7S27GHNu4a04X90p1\n63aKUqk1F39bvWfh39OTLtXtON7CbwAA4ClAIATwlPMvJx+H3HvXS+6yo7FZnV21RXsW56SV\ntwLlrcB7723lKa08H1gsFOWPjR/r9br2H/zi4OorIlUb9t4wqcHB796rVLdz8dG5kjsfXvdP\njW25DmN/LefiIyLVm7+xcfKLZ37+ukG3T9XqO/+V/7V3wY2LB/xqtb559aip8fC6fzp5Vukw\nep/Gtpzx2PVRz5/c/kXdDuMYJAQA8B1CAABKn0FfcPWPDQF1OhgDnoio1JpqL/VPv3ExOfbY\nw3YOahzZ5PWvjGlQRFQqtVfVxrq8rLzMW6aTZKXEH/r3B3U6/NPJo/KdMxv01Zu/0bDnDGMa\nFBG1xsY7qEledqouj0mPAAAEQgAALCA96VJ+Trq7f2jhRo9K9UQkOaZoIHxg5+rNB1Vt1Kfw\n3rSEc/ZOnnZOHqaW/SuHOboH1Gk/pnA3lUpdq/U7lep2utNkMNyKO+HoHqC1KzYZLwBAeXhk\nFACA0pedek1E7P83pmdk7+ItIlmp1x6ns4hcPvTv+FM7X+j2mUp1+4PdS79/F3NsY4d/7ldr\nbO5ZT4EuNyctIfNW3Jmfv0qOPd5i8DePdl8AgGcMgRAAgNJXkJ8jIhqtbeFGjdbOtOuRO8cc\n37x3cf+AOh2fazfK2JKbmXzgm7dqtX7bK7Dh/epJOLt3+5fhIuLkUfmVYd8H1On4SLcFAHjW\n8MgoAAClT2NjLyIFutzCjcZ0p7Upuk6m+Z1P//zVrjmd/et0eGXY96bhwYPfvqu1c6jfZXIJ\n9bhXqtv6rQ3N+i/yCmqy61+dD6/756PdFwDgGcMIIQAApc+hvJ+IZKdeL9xofDTUwa3io3U+\n+O27J3fOrNN+TIOun5gmCI07ueP8/hWthq83iCE/N0NE9AU6EcnPzVCrtcaoKSL2Tp4Boa+K\nSHCzgYfcKx3f8mnl+q95VnmxFG8ZAPA0IhACAFD6nDwDbR3ckq4cLtx449JBEfGo3OAROh/+\n4cNT/5n9Ut/okJeHFO4W88cGMRh2zSm63v3K4c4BdTo0G7D48uF1HpXrF36a1Ce42Z/bpibH\nHCcQAgAIhAAAlD6VSl2lQbcL+1dkJF128qwiIgX5OWf3LnLzr1Pet+bDdo4/tfP45k8a955d\nJA2KSO02/xfYsFfhlj+3fp5wbm/rtzfZObqrtXa/rX7bO6hJu1E/mx4xjT+9S0QKr04BAFAs\nAiEAABZR99WPrh5dv3V6WK1W79jYOZ7duzDz5pU2/7fDuPfqHxt++rprw55f1mr1dsmd9Xrd\n/lUj7J08Nbblzu5dWPgSfrXCnb2qOntVLdx4/telKo3WJ7iZcbNOxNg/Nk7cOrVFlQZ/U2vt\nEs7uufj7Gu+gJr41XymLdwEA8GQjEAIAYBGO7gERY/YdWvvB0Q1RhgKdR+X6bf5vh2+NsNu7\nDXqDvsCg1z+wc15WSlrCWRH577LBRS7RavgPDxzoq9f5Yxef4DM/f/3Hxol6XZ6TZ5X6nSfW\nCh9pGjAEACgZgRAAAEtxrRDSasSP99xVqV6XAQsN5nS2d/Is0rNkTfstbNrvroHEoMaRQY0j\nzT8DAEA5+HQQAAAAABSKQAgAAAAACkUgBAAAAACFIhACAAAAgEIRCAEAAABAoQiEAAAAAKBQ\nBEIAAAAAUCiz1iHMyMjYunXr9u3bjx49euPGjZSUlPLly3t5edWtW7ddu3bt27d3cnKydKEA\nAAAAgNL1gBHCnJycadOmBQYG9ujRY8WKFfn5+cHBweHh4cHBwfn5+StXruzRo0dgYOD06dNz\ncnLKpmIAAAAAQKkoaYTw0qVLXbt2PX78ePfu3fv169eiRQsHB4fCHTIzM3/55Zdly5aNHj36\nm2+++f777wMDAy1cMACLK3fdUHFbgbWrQBnSW7sAAABgJSUFwgYNGtStW/fEiRM1a9a8ZwdH\nR8eIiIiIiIjTp08PHz68QYMGycnJlqkTQNmxT5IKvxARAAAAnn0lPTI6fPjwnTt33i8NFlaz\nZs2dO3cOGzas9AoDAAAAAFhWSSOEkyZNKryZnZ19+PDhuLi4Vq1aeXp66nQ6rfbO4RqNZvLk\nyZYqEwAAAABQ2syaZVREpk2bNnny5LS0NBHZv3+/p6dnVFTUtWvXFixYoNFoLFkhgLJ26znV\nxdfN/ccBzwBVgdQfl2/tKgAAgBWYtQ7hwoULP/jgg5YtW86bN8/UGBISsmLFimnTplmsNgAA\nAACABZkVCOfMmTN06NAff/yxX79+psa+ffuOGjVqxYoVFqsNAAAAAGBBZgXCM2fOdOvWrXh7\nixYtLl26VNolAQAAAADKglmB0MbGJjs7u3h7QkKCjY1NaZcEAAAAACgLZgXChg0bzpw5Mzc3\nt3BjSkrKtGnTGjdubJnCAAAAAACWZdZEglFRUa1atapVq1bbtm1FZP78+fPmzVu/fn1WVlbh\naWYAALAog8GQmxpzZccYaxeCMlWQlyHiZu0qys6ECRM+/vhjLy+vuLi44o9iDR48eOHChU2b\nNt23b98jnLxXr16bNm3KyMh4YM9mzZolJSWdOXPmEa4C4CliViB8+eWXt2/fPmrUqLlz54rI\nkiVLRKRhw4ZTp05t2rSpZQsEAOB/VCpVQW5a6oX/WLsQwLLUanVycvLWrVs7depUuD0nJ+ff\n//63ra2ttQoD8Owxd6mxV1555fDhw0lJSTExMSqVqnLlym5uCvqsDgAAoMyo1epGjRotXbq0\nSCDcsGFDZmbmCy+8YK3CADx7Hm7taU9PT09PTwuVAgDAA6nUGrWNo7WrQJnS5z34+cZnjE6n\n69Kly4cffnjz5k0PDw9T+/Lly8PCwnJzcwsKCkyNW7du/fTTT48eParT6YKCggYOHPjuu++q\nVCoRMRgMkyZNWrBgwY0bN4KDg6OiooztJv/9738nTJjw22+/5efn16hR46233ho4cGDxeq5d\nu/bRRx/t2LEjISGhfPnyTZs2nTJlSo0aNSz2BgAoOyUFQjN/znm4HABQZsp51qjWbZm1q0CZ\nOrW0jbVLsILXXntt9OjRq1evHjFihLElMTFx+/bt0dHRCxYs0Gg0xsb169d37dq1WbNmS5cu\ndXZ2Xrt27XvvvRcfHz99+nQRmTZtWlRUVO/evQcMGHDz5s2oqKjCSXL37t1t2rR56aWXVq5c\nWa5cuXXr1g0aNCg5Ofn9998vUkzXrl0vX748efLkwMDA+Pj4zz//3Lj2mIODQ5m8GQAsqKRA\nyGAgAACAVVSsWPGVV15ZunSpKRCuXr3axsame/fu8+fPN3UbO3asv7//zp077ezsRKRNmzZJ\nSUmzZ88eO3asu7v7rFmzateuvWrVKuPA4Msvv1ylShXTVxDff/99f3//7du3G48NDw+Pj4+f\nPHny8OHDy5UrZ7pEWlragQMHRo8ePWjQIGNL06ZN16xZk5KSQiAEngElBcIHzl6VmZkZHx9f\nqvUAAABARKR///6RkZEnT56sXbu2iCxfvrxLly7Ozs6mDvHx8WfOnBkyZIgx0Rl16NDhhx9+\nOHDgwPPPPx8fH9+tWzfTY6J+fn4vvPDC8ePHRSQpKenw4cNvvvmmwWDIyckxdoiIiNiwYcPh\nw4ebNWtmOqGDg4Onp+eaNWvCw8PDwsLUanVgYODYsWPL4B0AUAbMWofwfg4cOHH1Z+YAACAA\nSURBVNCyZctSqgQAAAB3vPbaa87OzkuXLhWRU6dOHTlypG/fvoU7xMXFiYi/v3/hRj8/PxG5\ndu3a9evXRcTb27v4XhGJiYkRkblz55YrZOjQoabTmmi12i1btqhUqtatW3t5efXs2XP16tWF\nHz0F8FQzd1KZzZs3r169+urVq3q93thSUFBw8uTJwp9IAQAAoLQ4ODh079595cqVn3322fLl\ny319fcPDwwt3MA795eXlFW40GAzGXcYXRZiCnPHYAQMGDBkypEifatWqFWl58cUXz58/v2fP\nnm3btm3duvW7776bM2fOTz/9xO+BwDPArEC4Zs2a3r17a7XaChUqxMbG+vn5paamZmZmhoWF\nvffee5YuEQAAQJn69eu3ePHiffv2rVmzpk+fPqa5ZIwCAgLkf2N9JrGxsSLi7+/v5eUlIgkJ\nCYX3Xr582fiiUqVKIqLX6xs3bmxOJRqNJiwsLCws7PPPP4+Ojh46dOi3335bZMQSwNPIrEdG\np0+fHhERkZycHBMTY2dnt2vXrpSUlLlz52q12hYtWli6RAAAAGVq3rx51apVp02bduXKleLp\ny8fH5/nnn9+0aVN2drapcf369Q4ODk2aNKlSpYqnp+euXbtMj3edOXPG+AVCEXF3d2/YsOH6\n9etTUlJMxy5fvnzcuHE6na7wVQ4dOtSrV6/ExERTi3GgsnALgKeXWYHw7Nmzw4YNK/wlZq1W\nO3To0NDQ0NGjR1usNgAAAEVTqVR9+/bdvHlzaGhonTp1inf49NNPb926FR4e/v3332/cuLFP\nnz5bt24dP368i4uLWq1+8803T58+3bVr17Vr13799dft2rVr0KCB6dipU6dmZWU1b958xYoV\nO3bsGD9+/BtvvBEfH6/V3vUEWcWKFbdt2xYeHr548eKdO3euXr06MjLSzs7u1Vdftfj9A7A8\nsx4ZVavVpvmpbG1t09PTja87derUo0ePr776ylLVAUDZOJ8py2LlXIZk68XPXjp4S4S3qP+3\nfPMfabI6Ti5mis4g/uWkSwV5xVNMazv/clPWX5er2aIzSAU7CfeSzj5i81hTdgGASd++fT/+\n+OP7PZzZoUOHLVu2TJkypV+/fjqdrlatWosXLx4wYIBxb1RUVH5+/tKlS7du3RoSEjJz5szd\nu3f/8ccfxr0tWrT46aefJk6cOHz48Pz8/MDAwIkTJ44aNarIJXx9fffs2TNx4sQPP/wwOTnZ\nw8OjYcOGe/bsCQkJsdxdAygzZgXCGjVqLFmyJDw83MbGxs/Pb/fu3S+++KKI3Lx50xQOAeBp\ndSpdRp0WTxv5m584aGTvTZl9Sa7lyODKIiIHbknUXxLkKJH+olbJz0ny+Xm5niuvVxQR+f6a\nRF+RVzwl0l+0KjmaKguuyOl0GV/duvcE4Ok1YcKECRMmmDYDAwNNz3waHThwoPBm27Zt27Zt\ne89TaTSaTz/99NNPPzW1dOnSZebMmabNZs2a7dix457HFl5+rE6dOmvXrn2IewDw9DArEL7z\nzjt9+vRJT0/ftm1b27Ztx48fHxsb6+HhER0dHRoaaukSAcCylsSInVpmPiduNiIi7b1l+J+y\nIUEGVhKNShbHSAU7mVFb7NS39w45LmvjpU9FUYlsThRfOxld7faAYaiLXM6WvcmSoRMnc6dx\nBgAAsBazfl/p3bu3Wq2+evWqiEyYMOH06dOzZ88WkYCAgFmzZlm2QAB4oFGnJN8g71aVuZfl\nVLrYqSXUVYZVEXcbMYik6e59lEZuZ7ZWntJefTsNiohKpKaTnM+UDJ242Eh7b6lgdzsNiohW\nJbWcZMcNydWLvVpsVVKgvvP4qIiUU4taxSOjAADgqWDuB9g9e/Y0vnBzc9uxY0d8fHxaWlpQ\nUJCNjU3JBwKAxWlVEp8j0y9IpL+8HySnM+TTc5Knl4khcitfeh2+91H+5WRxqIhIO++iu+Jy\nxFUrLjaiEnmtwl27DCKXs8TLVuzVIiJ/85Op5+WbOGnvLbZqOZoq+5Klk8+dAAkAAPAEMzcQ\nXrt2be3atW+99ZZx08bG5rvvvhs8eLCvr6/FagMA86hUciNPPqgmoS4iIs3dZWd5OZoqBhEX\nrXxW895H2d8ns+25KUdSZVClu8b98vVyK1+S8mRDglzMkrHBt9tbe4qNSr68KEtjRERUIr0r\nSr+A0rozAAAAizIrEP71118tW7ZMTk42BcKsrKyoqKh58+bt2bOnWrVqlqwQAMxgo5Y6Lnc2\nPW0lVy95erFTS33XhzjPbyky7YI0cpMefne1/5kuY06LiPjYSVR1aeT2v/Y0+fKi1HGRDt5i\nq5aDKbImXmzV0qfiY94QAABAGTDroaYxY8Y4OTkVnmyqcuXKp06dcnR0HDNmjMVqAwCzuWrv\nGtAz/tumNzzcSTYkSNRf0shNoqrfdTYRCXKUiSHyXlWp6SQf/SWLY0REDCLTL0hFe5kYIo3d\npL6rDK0snXxkWYzE5TzO3QAAAJQNs0YI9+7dO23aNONSEyY1a9YcNWrUuHHjLFMYAJQGcyaV\nMZp3RdZdk15+MqBS0TQoIq5aaewmItLWW7ztZE2cNHUTFxu5liu9PO/qX89V1l+XU+lS0b40\nbwQAAMACzAqEmZmZdnZ29zhYq83MzCztkgCg9JgzqYyILImRH67JyKoScfcEMyn5si9Zgh0l\nxOlO43PO8p3IpSyp6SwiortrfTDJ14uI6B5ycBIAAMAazAqE9erVW7ZsWa9evdTqO4+YZmZm\nzps3r27duharDQAemzmTyhxJldVxMqxK0TQoIjZq+fqy1HSW6bXuDAMeTRUR8baTivbiqJFD\nqTJY7uw9kioidwVIAACAJ5VZgXD8+PEdO3asVatWeHi4j49PTk5ObGzsxo0bU1JSNm/ebOkS\nAeDRaVUPmFSmwCBzLomrVuzUsjXxrl31XcXHTnpVlJWx8t5Jae4hNir5M112J0ktZ6nnKiqR\nfgHy9WX58Iy09xY7tRxOkW03pIWHVHWw6G0BeFalp6db4rTOzs6WOC2AZ4BZgbB9+/YbN24c\nO3bsnDlzTI2hoaErVqxo166dxWoDAMvLKJDYHBGRGReL7ppQXXzspK+/VLSXjQmyMlZ0BvGx\nk34B8lqF20OCXSqIm438cF2mnpcCg/jaSz9/6e5X9FQAAABPJHPXIYyIiIiIiLhx40ZsbKyI\nBAQEeHp6WrIwADDbJzWKtowIlBGBZh3rqpUdjR/Qp5WntLr/v3gtPKSFh1nXAoBScu7cuVOn\nTnXu3NnahQB46pkbCLOyslJTU319fb28vHJycr799tsbN2506tSpevXqFq0PAAAARaxcuXLP\nnj0tW7Z0dX2YpVYBoBiz1iE8c+ZMYGDgsmXLRESn073yyiv9+/cfNWpUaGjo4cP3mb4PAAAA\nlqHX60WkoKDA2oUAeOqZFQg//PDDChUq9OzZU0S+/fbb/fv3z58//8KFC/Xq1ZsyZYqFKwQA\nAAAAWIRZj4zu27dvxowZgYGBIvLjjz/WqVNn8ODBIjJixIgPPvjAsgUCAKBsN68cOfpjVNKV\nQ7rcTGevoJAW/wh5ebBKrTHuvXbmp2ObP7kVc0xfkO/iU71W67eDGr0uqtsLoVz6/btTu2an\nXjut1+U5eQVWe6lfzVdGaLT3WFsYTxS9Xn/x4kXjMOA9ZWRkiMiFCxeSkpLu18fHx4cHSgE8\nkFmBMCUlxdfXV0T0ev2uXbveeOMNY7uXl1cJ/wwBAIDHlHhh/7ZpYQ5uFZ9r+76NvfOVw9/v\nX/lm+o0LL3afJiIxxzbumtPFvVLdup2iVGrNxd9W71n49/SkS3U7jheRkzu+PPjde0GNX6/7\n6kcarW386V2//3vUjQv7w95ca+3bwgNs3Lhx5syZD+xW8ufyQUFBCxcuLL2iADybzAqEPj4+\nFy9eDAsL+/nnn5OTk9u3b29sj4mJ8fBgbj0AACzl8Lp/amzLdRj7azkXHxGp3vyNjZNfPPPz\n1w26fapWaw+v+6eTZ5UOo/dpbMsZ966Pev7k9i/qdhgnKtVfe+Y7e1V9edAK44BhhZCWt+JO\nXD78fV7WLVsHNyvfGEqUmpoqImHeHhXL2T/aGdbFXk9LSyvVogA8m8wKhG3atBk3bty5c+fW\nrFlTpUqV5s2bi0hiYuKsWbOaNm1q4QoBAHiKbZ0WptflNe03/7c1IxMv7NfalKtQI6xx79nl\nXCuIwZCTefOeR6nVWluH8iIS1Dgy5OXBxjQoIiqV2qtq45tXjuRl3rJz8qje/A0nz0BjGhQR\ntcbGO6jJuf8u1eVlae0cNTb2KrXG9PioiNjYOanUGjWPjD4lIny9X/J8xOi+4/oNQ+lWA+AZ\nZVYgnDRp0smTJz///HMvL6+tW7dqNBoRefvtt69evbpq1SoLVwgAwFNMo7VNv3Fh7+IBdTtF\nNRuw5MbF335Z0KcgP6f1Wxuy0xLWvOd7z6NcK4R0nXxGRKo3H1RkV1rCOXsnTzsnD5VKXav1\nO3ftMxhuxZ1wdA/Q2jmKyHNt3tuzqO+xTZOrvzxYY2N/7fSuy0e+rxk2XGvrYJFbxdPsr7/+\n6tev36FDh3Q6nTn9ExMTAwICvL29L1++bPzN0OiFF14oPAW9u7t7vXr1Jk+e3Ljx7RVfIyMj\nk5KStm3bZup85MiRevXqmQ7R6XT+/v4JCQn5+flarbbkywF4fGYFQl9f3/3796elpTk4OJh+\nMt9///2ZM2dWqFDBkuUBAPC0U2UmxzQfuMy3RpiIODbwP/9r2/jT/xGDwc7Rve3/7bznMcZE\nV9zlQ/+OP7XzhW6fqVR35gkv0OXmpCVk3oo78/NXybHHWwz+xtge1OTvaq3df5cOOrJ+vIio\nVOo6Hf5Zv/PEUr4/PP2+/fbbd999Nzw8/NChQ2YesnDhwmbNmp04cWLTpk2dO3cuvKt///6T\nJk0yvk5ISPjiiy/Cw8OPHz9unJ6wCG9v70WLFs2ZM8fUsmXLluKz6ZRwOQCPydyF6UXExcWl\n8OYLL7xQ2sUAAPAM0mjtfENamjYd3SoW5GXr8rO1tg5+tVqbf56Y45v3Lu4fUKfjc+1GFW5P\nOLt3+5fhIuLkUfmVYd8H1OlobL9+ds9/l71RIaRlSIshGptysX9uOb7lU43WLrTjuFK4KzxD\ncnNzDxw4cOTIETOf/NLr9fPnz//oo4+OHTsWHR1dJKE5Ojr6+/sbX/v7+y9fvtzNzW3z5s0j\nRowofqqIiIhVq1ZNnz7d3v72tyUXL17cunXr1atXm3k5AI/JrHUIAQDAI7Nz9iz8RT6VSiMi\nBsN9VxS4p9M/f7VrTmf/Oh1eGfZ94eFBEXGvVLf1Wxua9V/kFdRk1786H173T+P59y0Z4OIT\n3OqtHwNCX/Wr1bphzy9rhA07+mNUWsK50rgtPDv69u1bqVIl8/tv2bIlKSmpR48eAwYM2L59\n++XLl0vorNFoNBrN/Z5EbdCggYeHx7p164ybiYmJ27Zt69at2yNfDsDDeogRQgAAUJrMmFTG\n6OC3757cObNO+zENun5SOFsa2Tt5BoS+KiLBzQYecq90fMunleu/ZufokX7jYp2IsYXTo1/N\n1qd3/Svxwn4Xn2AL3A9KjTHzjDp2+nFOYpuaWjrVFPP111/36NHDycmpbt26oaGhCxYsmDJl\nyj17ZmRkfPzxx1lZWR07drzf2QYOHLho0aI+ffqIyIoVK8LCwipWrPholwPwCAiEAABYhzmT\nyojI4R8+PPWf2S/1jQ55eUjhPjnpiZcPr/OoXN8rsKGp0Se42Z/bpibHHPcOaiIiel1e4UP0\nulwR0Rfc1YgnkJOTk4gEOzm62jzir2rHUtJM8z6UrkuXLm3fvn3Pnj3GzYEDB06ePHnChAk2\nNjbGlvnz5y9dutT4OjMzs3bt2uvXr69Wrdr9Tti/f/8JEyZcvHixatWqS5YsiYqKeqjLAXhM\nBEIAAKzDnEll4k/tPL75k8a9ZxdJgyKi1tr9tvpt76Am7Ub9bBoGjD+9S0ScPCq7+ATblnON\nO7n9BcPUO3tP/UdEPKu8aInbQSny9PQUkSFBlR552YnX9h0yON57aqLHFB0drdfrO3ToYNws\nKCjIyMhYv3599+7djS09e/Y0hrq0tLTWrVsPGzYsIiKihBP6+fm1bdt28eLFnTt3vn79eufO\nnY8cOWL+5QA8JgIhAADWodbaljypjF6v279qhL2Tp8a23Nm9Cwvv8qsV7uRRuU7E2D82Ttw6\ntUWVBn9Ta+0Szu65+Psa76AmvjVfUanU9bpM/G31OztnRlR/+Q2trUPcyR1n9y0KfLGne0Co\nhe8Mz6y8vLzFixdHRUX179/f1Dhq1Kjo6GhTQnN1dTWNB86ePXvIkCEtW7asVatWCacdNGjQ\n6NGjMzIyXn/9dVtb24e6HIDHZFYgtLGxsbO79yK2KpXKxcWlbt2677//flhYWKnWBgCAouVl\npaQlnBWR/y4bXGRXq+E/OHlUrtf5Yxef4DM/f/3Hxol6XZ6TZ5X6nSfWCh9pHBKs1ertci4V\nTv1n5t5F/fR6nbNn1fqdJxaZoRQQkevXr+t0ups3b4pIbGysiJQvX97JyWnRokUZGRnvvHNn\nucu1a9empqaOGDHCOIZp9NZbb7Vs2fLcuXPBwUW/mxoZGfnDDz/07t374MGD9/tlUkQ6duw4\ndOjQlStX7tq1q3D7w14OwCMwKxC++eabv/3228GDB2vVqhUSEqJSqc6ePXvixIlmzZpVqlQp\nMTFx375927Zt27x5c7t27SxdMQAAT5E2724r0tL49TmNX59zz85F2Dt5DlhoKLlPUOPIoMaR\n99sb+GKPwBd7mHMtKFnjxo2vXLlifB0QECAiM2bMGDly5M6dO5OSkgoHwrlz53bt2rVwPBOR\nl19+OSQkJDo6evr06cVPPm/evOeee2706NEzZ868XwFarbZv3767du0KDb1r+PoRLgfgYZkV\nCF999dUNGzb8+uuvTZo0MTXu37+/X79+M2fObNCgQWpqaps2baZMmUIgBJ4B9jekwi8PNyE+\nnm76B0QOAM+2+y3ksGbNmiIte/fuvWfP06dvT4hafGl7Ly+vhIQE0+bKlStNrwt3njp1qul1\n48aNDQaDOZcD8PjMCoSjR4+ePHly4TQoIk2aNBkzZsx77723e/duV1fXkSNHDh5c9IEWAE8X\nOzs7tVpdLkFfcVuBtWtBWTOtCg3gCTHr3KVFl2Ie7dhb+bryD+4FAOYFwpMnT/r4+BRv9/Pz\n+/33342vHRwcVMVWRrI6BwcHtVr94H4oE7du3RIRjUbj5vaIc6bB0tzc3ObPn5+YmGjtQqwg\nOzt70qRJISEh/fr1s3Yt1vH888/zs4knltL+7wgODnZxcUk1GFLvM36fnZ2t0+mcnJzu99uX\nvaNjyfO4AICRWYHQy8tr4cKFrVu3LvKPzurVqx0dHUVEp9NFR0fXqFHDIjU+hqysrPz8fGtX\ngdsyMjJEpKCgwJgM8WTy9/f39/e3dhVWkJmZKSJubm7169e3di1Ww88mnlhP5v8dRb7bVoqa\nNGny448/ltBh/Pjx+/btW7Zsmbu7u4VqAKAQZgXCQYMGTZw48dSpU+Hh4b6+viqV6saNG7t3\n7z548OBbb70lIj169Ni6devq1astXC0AAAAAoNSYFQijoqK0Wu2cOXNmzJhhanR1dX333Xc/\n++wzEWnRokX37t179eplqTIBAAAAAKXNrECoVqvHjx8/bty4K1euJCYmGgwGDw+PwMBAjUZj\n7FB4PmIAAABYlIODg1arZS4oAI/PrEBolJycfOLEiWvXrqnVan9/fx8fH2dnZ8tVBgAAgHsa\nMWJEr169HBwcrF0IgKeeWYFQr9e/9957X331VeEJWhwdHaOiokaNGmWx2gAAAHAPzs7OfC4P\noFSYFQi//PLLmTNndu3aNSIiws/Pz2AwxMbGrlu37oMPPvDx8enbt6+lqwQAAAAAlDqzAuGS\nJUv+8Y9/zJs3r3DjkCFDevXqNWvWLAIhAAAAADyNzFq0/cKFC926dSve3qdPn9OnT5d2SQAA\nACjJnj17pk2bptfrrV0IgKeeWYFQq9Wmp6cXb8/LyzNNNAoAAICysXPnzi1btqSmplq7EABP\nPbMCYb169WbNmpWXl1e4MTs7e+bMmfXr17dMYQAAACiJwWCwdgkAnnpmfYdw7NixHTt2DA4O\nbteunb+/f15eXkxMzKZNm1JSUrZt22bpEgEAAAAAlmBWIIyIiFi3bt3YsWPnz59vaqxTp86K\nFStat25tsdoAAACUKDMz85dffikoKLhfh+vXr4vIjh07HB0d79enevXqISEhFqkPwDPE3IXp\nu3Tp0qVLl/j4+Li4OJVKFRAQ4OPjY9HKAAAAlGnjxo3R0dEP7FZyH19f32+++ab0igLwbDI3\nEBr5+fn5+flZqBQAAACIiHHihsQm6uwKqkc7g/82vU6nK9WiADybSgqENWrUMOcUZ86cKaVi\nAAAAcFtadXVqjUcMhL4/3fdxUwAorKRZRj3NU2a1AgAAoNTFx8e//vrr3t7erq6uLVq0OHjw\n4AMPSUxMtLOzCwgIKPJFxxdeeEFViIeHR+vWrQ8cOGDqEBkZ2a5du8Kdjx49WvgMOp2uQoUK\nKpWq8Ajn/S53v+saVatWzfw34fE9wtsIPAlKGiHct29fmdUBAAAAq+jcubODg8OOHTucnJzG\njx/fsWPHS5culTBdjYgsXLiwWbNmJ06c2LRpU+fOnQvv6t+//6RJk4yvExISvvjii/Dw8OPH\njwcGBhY/j7e396JFi+bMmWNq2bJli16vN/9yJpGRkVFRUYVbbG1ti/TJz8+3sbG53+b9mNnt\nEd5G4ElQ0gjhwIEDs7OzzTxRdnb2oEGDSqMkAAAAlJHk5OQqVarMnz+/bt261apV+/zzz2/c\nuHHixIkSDtHr9fPnz3/99dd79epVfGIbR0dH//9p0KDB8uXLRWTz5s33PFVERMSqVatycnJM\nLYsXLy4yiX3JlzNxdXWtdrdKlSqJSH5+vkqlWrJkSWBg4MCBA4tsikhCQkLv3r39/Pw8PDxa\ntWp1/Pjx4keJyNKlS2vWrFmuXLkKFSoMGzascM2P9jYCT4iSRgh/+umnRo0azZ49u2XLliWf\nZe/evSNGjEhNTS3N0gAAABTJuOK83U2DQ9wjnkFVIMXH2e7J3d393//+t2kzLi5OrVZXrFix\nhEO2bNmSlJTUo0eP+vXrN2jQ4PLly1WqVLlfZ41Go9Fo7jfDTYMGDfbu3btu3bo+ffqISGJi\n4rZt21atWrV69epHu1xxNjY2KpVq7ty5P/zwQ9WqVYtsikjnzp09PDyOHj3q6OgYFRXVokWL\n8+fPe3h4FO528eLFgQMH7ty5s2XLlnFxcd26dZsxY8bYsWNNV3mEtxF4QpQUCA8fPty7d++w\nsLAWLVr069cvPDzc39+/cIe4uLhdu3YtW7bsp59+Cg8P/+mnnyxcLQAAwLPv7NmzIhKw6bEm\nhknNeehP6pOTkwcNGvT2228X+ZWviK+//rpHjx5OTk5169YNDQ1dsGDBlClT7tkzIyPj448/\nzsrK6tix4/3ONnDgwEWLFhkD4YoVK8LCworkKDMvN3/+/KVLlxZumTp16rBhw0RErVZ36tSp\nbt26xvbCm0ePHv3tt99OnDhhXFBt0qRJc+fO3bBhw4ABAwp3O3XqlMFgcHNz02g0lSpVOnDg\ngEajud8dmfk2Ak+IkgKhh4fHtm3bvvnmm48//tg4Vu7l5WX8pmxqauqNGzcSExNFJDg4eOXK\nlb1791arS3oAFQAAAOYwBolbz6lzPR7xDF4H9C52Dg91yJkzZ1599dXWrVt/8cUXJXS7dOnS\n9u3b9+zZY9wcOHDg5MmTJ0yYYPqWXeFglpmZWbt27fXr15cwv0v//v0nTJhw8eLFqlWrLlmy\npMj3AB94OZOePXsWOdbLy8v0Ojg4uPAu0+aFCxdUKlVISIhx08HBoWLFihcuXCjSrVGjRsOH\nD2/UqFHDhg1bt27du3fv+83Gb+bbCDw5HrAOoVqtjoyM7N2796+//rp9+/Zjx47duHEjOTm5\nfPnyVatWDQ0Nbdu2bZMmTUr4jAQAgFKUn5V04+gya1eBMmXQ5Yg8eEqPZ4lxJpKbDR592Qn3\nP/R2tnbm99+1a1fPnj0nTJgwYsSIkntGR0fr9foOHToYNwsKCjIyMtavX9+9e3djiymYpaWl\ntW7detiwYRERESWc0M/Pr23btosXL+7cufP169c7d+585MgR8y9nYvwO4f2uYmdnV8Km8Rld\n02uVSlWkm0qlmjNnzujRozdv3rxp06ZPP/105cqVPXr0KHIV899G4Mlh1sL0Go2mefPmzZs3\nt3Q1AACUwN7ePisj4dqBf1m7EJS1cuW8rV3Cs2zfvn09evRYtWqVaUGI+8nLy1u8eHFUVFT/\n/v1NjaNGjYqOjjYltMLBbPbs2UOGDGnZsmWtWrVKOO2gQYNGjx6dkZHx+uuvF54a1JzLPabg\n4GCDwXDmzJnnn39eRDIyMuLi4ooMJ4qITqe7detWQEDA0KFDhw4dOnLkSOODrIX7mP82Ak8U\nswIhAABPgi+//DImJsbaVVjH9OnTy5cv/8Ybb1i7ECtQqVTFf0FHacnOzu7Xr9/IkSOfe+65\n2NhYY6Obm5ujo+OiRYsyMjLeeecdU+e1a9empqaOGDGi8ErUb731VsuWLc+dO1f8jykyMvKH\nH37o3bv3wYMHiwzKFdaxY8ehQ4euXLly165dhdsf6nKpqannz58vcubKlSuXvGJEaGjoSy+9\nNGbMmKVLl9rZ2Y0dO9bFxaVLly5Fui1btmzChAnr16+vV6+ecfrQoKCgwh1KeBtLuDrwJCAQ\nAgCeGlWqVHmo2QWfJTNmzHB0dORpHZS6X3/99eLFix999NFHH31kavzXv/41YsSInTt3JiUl\nFQ6Ec+fO7dq1a+F4JiIvv/xySEhIdHT09OnTi59/3v+zd5/xUVR9/8fPS23CxQAAIABJREFU\n7qb3EBJKEiAx9N4D0psivYNwE6qCgopSpRcVASkKRmmheQPCpUhHBLkAJdIJAkFCCARICIEU\nQtpmd/8P5nb/62Z3syGEjczn/fJBZuacmd+cHUO+O+2bb2rVqjVlypTly5ebq8HOzm7o0KFH\njhypW7eu4fxCbW7Lli1btmwxWvO1a9fM3eynt23btvHjxwcHBzs6OjZt2vTEiRMeHh5GbUaM\nGHHv3r2+ffsmJCR4eXl17tzZ6BZBC8NoeeuAzREIAQAA5Kt9+/aGd9AZ2rZtm9GcEydOmGx5\n7do16YezZ88aLfL19X3w4IF+0jCzGTZetGiR/ufQ0FCppAI3Z3JV+Rm99MJoMjAwcNeuXZZ7\nKRQKo7BnxMIwAiUcgRAAAKBkkR5qErLR9Lv7rOVbcBMAIBACAACULE2aNImKirJwxunmzZup\nqal16tSxcIOc9JQUALCMQAgAAFCyVK1adfHixRYazJw58+TJk7Nnzy5VqtQLqwrAS4lXyQMA\nAACATBEIAQAAAECmCIQAAAD/MmXLlvXw8OAddwCKjkAIAADwL/POO+/s2LHDwqveAcBKhQiE\nWVlZJ0+e3L59e3Jyssj3ChcAAAC8GAqFwsHBwdZVAHgZWBsIFy9eXLZs2ZYtWw4cODAmJkYI\nMXv27BEjRmg0muIsDwAAAABQXKwKhGvXrp08eXKbNm2++eYb/cyqVatu3rzZ8jORAQAAAAAl\nllWBcOXKlWPGjPnpp5/CwsL0M4cOHTpp0qTNmzcXW20AAAAwYdu2baNHj1ar1bYuBMC/nlWB\nMDo6uk+fPvnnt27d+tatW8+7JAAAAFhy5cqVmJiYJ0+e2LoQAP96VgVCe3v7rKys/PMfPHhg\nb2//vEsCAAAAALwIVgXCJk2aLF++PCcnx3Bmamrq4sWLQ0NDi6cwAAAAAEDxsrOm0ezZs9u3\nb1+jRo3XXntNCLF69epvvvlm165dmZmZho+ZAQAAQNHdv3//+++/12q15hpIj3z/9ttvLbyK\nsFatWp06dSqW+gC8RKwKhK1atTp06NCkSZPCw8OFEBEREUKIJk2aLFq06NVXXy3eAl86Go1m\nx44dmZmZti7EBtLT04UQ165dW79+va1rsY02bdoEBwfbugoAQEl39OjRn376qcBmP//8s4Wl\nf/zxB4EQQIGsCoRCiHbt2p07dy45OTk+Pl6hUFSsWNHb27tYK3tZxcbGbtiwwdZV2FJMTIz0\nvaYMPXr0aNKkSbauAgBQ0knnBgPazHTzb/Rsa7j540idTvdci0LBcnJymjdvPmzYsPHjx589\ne3bAgAEJCQm3b9/29fW1dWkokuL+NOPi4oKCgi5fvlyrVq0irmrSpEnR0dG7d+9WKBRWdrE2\nEGZmZqalpZUrV6506dLZ2dnbt29/+PBh9+7dq1Sp8qzVypRGoxFCdChTelCF8rauBS9Ocq56\nyqVrFi7+AQDAiJ2Lj4OH/zN2VqqEsPYfnatXr06ePPn333/XaDT16tX77LPPmjdvbrlLUlJS\nYGCgn59fXFycSqXSz2/UqNG5c+f0k6VKlapfv/6CBQv0T50YMmRIcnLywYMH9Y3Pnz9fv359\nfZe8vLyAgIAHDx6o1Wo7OzvLmzO3Xckrr7zygr+DnjJlSpkyZcaPHy+EWLlyZbly5c6ePevp\n6Wmu/dGjRz08PBo1esbYjxfG3Kd5//79SZMmHT58OCcnp169eosXL27SpIm06Pr162FhYWfP\nns3Ly3uRpX766aeNGzdevnz5hAkTrOxiVSCMjo5u3br1hAkTpk6dmpeX165du1OnTgkhZs6c\nefLkyYYNGz57yXJVysG+moebravAi3M/K9vWJQAAYEJOTk6HDh06dOhw6tQplUo1f/78zp07\n3717193d3UKvtWvXtmjR4s8//9y7d2+PHj0MFw0bNmz+/PnSzw8ePPjiiy86duwYFRUVFBSU\nfz1+fn7r1q1buXKlfs7+/fvzf39qYXN6Q4YMmT17tuEcBwcHozZqtdrwCflGk+ZY2SwuLi48\nPDwyMlKafPToUa1atSxfUrd06dKuXbtaGQitLKOIXZ5j9xK4oWdm7tPs0aOHi4vLzz//7Obm\nNnPmzK5du966dcvV1XX79u0TJkzo2LHj2bNnX3Cp9vb2c+bMGTly5KhRoyz/X6xn1VNGp0+f\nXrZs2QEDBgghtm/ffurUqdWrV9+8ebN+/fqffPJJkUoGAACA7aSnp3/44YerVq2qWrVqSEjI\n9OnT09PTY2NjLXTRarWrV68ePHjwwIEDv/32W6Olrq6uAX9r2LDhpk2bhBD79u0zuao33njj\nu+++y87+/1+brl+/vkOHDtZvTs/T0zPknypUqCCEUKvVCoUiIiIiKChoxIgRRpNCiAcPHgwa\nNKh8+fI+Pj7t27ePiorK30sIsWHDhurVqzs7O5ctW/add94xrFnyzTffNG7cWDrb2apVqwMH\nDqxbt87NzS02NlahUBw7dkxqFhMTo1AoYmJi2rVrt3///g8++KBhw4YZGRkm25isdsCAAV5e\nXj4+Pp06dbpy5YpRGdZ3uXDhQmhoqJubW8OGDY8ePapQKC5cuGB9d5MDYnKmlSOsp9PpFArF\nli1bWrVqVa5cudq1a1++fPnDDz+sVq1amTJlPv/8c6mZucKuXr3aqVMnb29vLy+v1157TTpL\nLK3z+++/79SpU0hISMWKFaUj04jJUg0/zaSkJH3jx48fV6pUafXq1fXq1QsJCfn8888fPnz4\n559/CiFycnIiIyN79epl7nAVQly8eLFp06aurq516tTRf49grv7mzZuPHTtW3yYyMlKpVMbF\nxZkccCmmfvfddxa2bsiqQHjy5MkpU6ZI3+v89NNPderUGT16dHBw8Lhx406fPm3llgAAAFDS\n+Pr6Tpw4UTqT8Pjx4+XLl1erVq1atWoWuuzfvz85Obl///7Dhw8/dOhQXFychcYqlUqlUpm7\naq5hw4Y+Pj4//PCDNJmUlHTw4ME+ffo88+bys7e3VygU4eHhP/7446pVq4wmhRA9evRIT0+/\ncOHC7du369Wr17p160ePHhk1i42NHTFixMqVKzMyMk6fPn3mzJlly5YZbejnn3/u2LGj9PPx\n48dff/31kSNHZmRk+Pn5mSzs6NGjFSpUWL58ef6LXc0VL4QYPHiwECI2Nvbu3btNmjTp0KGD\n0aMKreySk5PTuXPn6tWrJyYmbt26derUqVJfK7ubHBBzo2TNCBvugkKhUKlU4eHhe/bsiY+P\n9/T0bNu2bePGjaOjo9euXTt9+nQplZkbin79+pUtW/bOnTt37txxc3MLCwvTr3PhwoUREREx\nMTGTJ08eO3bs06dPjQbcZKnmPs1SpUrt2LGjatWq0uS9e/eUSqW/v78QYujQodL3EeZotdpe\nvXpVq1btwYMHe/bskZ7cKTFZ/6hRo7Zt26b/GmL79u1t2rTRarUmB1yhULRv3/7w4cMWCjBk\nVSBMTU0tV66cVPqRI0def/11ab6vr29ycrKVWwIAAIA1cnNzhRBP7vz+6OoPz/afVp1ZqDuX\nNBqNo6Ojj4/PlStXjhw5YuFtFkKIr7/+un///m5ubvXq1atbt+6aNWvMtczIyJg8eXJmZmbX\nrl3NtRkxYsS6deuknzdv3ty2bVvpT+rCbm716tVu//T1119Li5RKZffu3evVq+fh4WE0eeHC\nhT/++GPRokVlypRxc3ObP39+Tk7O7t27jZolJSXpdDpvb2+VSlWhQoXIyMhp06YZFXDlypXa\ntWtbGLdnY1iG9Ol8+eWXpUqVcnZ2njdvXnZ29t69e5+hy6lTpx48eDB79mw3N7cqVapI9z1a\n393kgJicaeUI59/xIUOGeHp62tnZtWjRwsnJadCgQUKItm3bajSaW7duWRiK48ePh4eHu7u7\ne3h4vPnmm2fOnNE/YGno0KHS0dW1a9fMzEyjLxcslFqgx48fjxw58r333gsICLCmfWRkZFxc\n3KxZs9zc3CpWrGh4v5/J+gcMGKDRaH788UchhE6n27Fjx/Dhwy0clnXq1JHOVVrDqnsIy5Qp\nExsb27Zt219//fXx48edO3eW5sfHx/v4+Fi5JQAAAFjj5s2bQohHf35flJWk55l4+Io5KpXq\n4sWLiYmJK1asaNu27R9//OHl5WWy5a1btw4dOnT8+HFpcsSIEQsWLJgzZ47+HrDVq1frH6j+\n9OnTmjVr7tq1KyQkxNymhw0bNmfOnNjY2ODg4IiICKP7AAvcnN6AAQOM+ho+DbJy5cqGi/ST\nN2/eVCgU+pM8Li4u/v7+0vgbNmvatOm7777btGlT6UzUoEGDjE6ipqen5+bmli5d2txuFoW+\njBs3bgghypYta7jU5PW9BXbJzs5WqVQVK1aU5jRt2rRQ3fv165d/QEyOkpUjnJ8+WTk5Oem/\nI3BychJCZGVlJSQkmBuKCxcuLFy4MDY2VqvVZmVlqdVqjUYjPaBIv7/SVx5ZWVmG3S2XakF0\ndHS3bt06dOjwxRdfFNhYIr24oVKlStKk4XM6Tdbv6uo6aNCgiIiIQYMGnTx5Mj09vU+fPs7O\nzuYOSx8fH+vP21kVCDt16jRjxowbN25s27atUqVKLVu2FEIkJSWtWLGC9xACAAA8X5UrV46M\njPStP8zF19KlmxbcPf6Zp0shAqEQonr16tWrV2/ZsmXZsmW3bNkybtw4k82+/fZbrVbbpUsX\naVKj0WRkZOzatatfv37SHH0wS09P79ChwzvvvPPGG29Y2G758uVfe+219evX9+jRIzExsUeP\nHufPn7d+c3rSPYTmtmJ0ztNo0vAVHdLNZkbNFArFypUrp0yZsm/fvr1793722Wdbtmzp37+/\n0VasedC/NY8cN2pjWIYQIjMz09nZ2fIaCuyyceNGw2qNKrdmiyYHJP9MpVIprBjh/CyUZ6Gw\n27dvd+3adfbs2fv373dwcNi9e7fhU4is+YDMlWrOkSNHBgwYMGfOHHP/y5iUk5NjOKk/n2+h\n/lGjRoWGht6/f3/79u0DBgxwcXERZj4FK/dUz6pLRufPn1+pUqXPP/88MzNz586d0tN+33vv\nvTt37syaNcv6jQEAAKBA0tkM13L1PF/p8Gz/Ke2cTL6eIb8jR46EhITob6ZSqVQKhcLcOwxz\nc3PXr18/e/bsi3+7fPly3759DZ/1on+4S4MGDb788suJEydevXrVcg0jR47csWPHd999N3jw\nYMNHg1qzuSKqXLmyTqeLjo6WJjMyMu7du5f/tFVeXt7Dhw8DAwPHjBmzd+/ed955R389qsTD\nw8PBweHhw4f5N+Ho6KhQKKTLgIUQJu+BtKaN+Pt82sWLF/VzLD/+x0KX8uXL5+Xl3bt3T5pp\n7rEg5rqbHBCTM60c4cIyV9iZM2c0Gs3UqVOlA6lQD/l8hlJPnjzZv39/C1+gmBMQEKDT6e7c\nuSNN6p+IY6H+xo0b165de+vWrTt27Bg2bJiweFgmJydb/75EqwJhuXLlTp06lZaWdv/+ff1L\nJiZOnHjt2rWivzwRAAAAttKwYcOnT58OGzbs6tWrsbGxEyZMyMjIkB4YsW7duhUrVhg23rlz\nZ1pa2rhx4yoZGD9+/NGjR6VrC40MGTKkc+fOgwYNMjofYqRr165paWlbtmwxetpkoTaXlpYW\nk49arba8+3Xr1m3evPnUqVMfPnyYnp4+ZcoUDw+Pnj17GjXbuHFjgwYNzp07p9VqHzx48Oef\nf77yyitGbWrWrHn58uX8m7C3tw8JCZFevZiRkWH4jg0XF5eYmBjpCSvm2hiqUaNGu3btJk6c\nGB8fr1arw8PDa9eunZiYaGEHzXVp3ry5p6fnp59+mpmZ+ddffxk+1MSa7iYHxORMK0e4sMwV\nFhAQkJeXd+LECa1Wu3Xr1qNHjwoh7t+/b806C1tqVlZWWFjYBx98UKtWrbt/k75bSUxMvHv3\n7qNHj4QQ0vyMjAzDvs2aNfPx8Zk7d25KSsq1a9f0n7jl+keOHLlgwQJPT0/pIk0Lh2VUVFTN\nmjWtHEyrAqHE1dU1MzMz9W8hISFOTk6pqanWrwEAAAAlipeX1+HDh7Oyslq2bFm/fv2zZ8/u\n27dPOity+PDhPXv2GDYODw/v3bu30Z1yrVq1qlq1qrmzdt98801iYuKUKVMs1GBnZzd06NCK\nFSvWrVv3mTe3ZcuWyvlYcwPYtm3b7O3tg4ODg4OD4+LiTpw4kf8ZJyNGjBg9enTfvn1dXFzq\n1q0bGBiY/26xTp06mXuuY3h4+P79+4OCgjp06CA9vkW6RPDtt98ODw+XXmVuro2R7777LiAg\noHbt2t7e3ps3bz5w4IDRfXRWdnF1dd21a9eJEyd8fX1HjBghXeUrXd5pTXeTA2JulKwZ4Wdg\nsrDQ0NBJkyb17NnTz8/v6NGje/bsqV+/fqNGjax8OG2hSv39999jY2NnzZoVaCAiIkIIERoa\nGhgYOGrUKI1GI81fu3atYV9nZ+d9+/Zdvny5fPnyAwYMmDFjhhBCrVZbrn/IkCGZmZnDhw+X\nVmJuwHU63ZEjR1577TUrR9LsJQGGbty4MWrUqFOnTpn8lsWaNdhKWlpagd8MvWDR0dEffPBB\n/8By71cx8XpWvKzuZ2X3+/1827ZtLf+LCBt6+vRpnz59QkND58yZY+taABN69+5dtmxZo6vU\nYFvF8QSRJ0+eCCE2bdoUERFR6Y3lHhVbPNt6rm3u4uWs/f77/3ssjZXvp0ZRxMXFVa1aNTIy\nUnoVYcmXl5en1WqlSxMjIyObNWuWlpb2XKIaiklUVFSTJk1u375dpkwZC8127do1atSoW7du\nWfk/vlUPlXn77bcvXLjQt2/f8uXLSxe1AwAAoFjlpsVnPbz2bH11GrUQhXuoDIqoUqVKY8eO\nnT59+v79+21dS8F0Ol3NmjWbN2++bNmyrKysuXPntmnThjRYYuXk5MTHxw8fPnzMmDGW06Ba\nrZ47d+6MGTOs/xrIqnR3+vTpHTt26N82AQAAgOIjPQ/m/m/WPsLeJIW76feho/h8/vnnzZs3\n//LLL9977z1b11IAhUKxc+dO6b15zs7Obdq0MbqmESXK4sWLFyxY0KtXr88++8xyy+nTp/v7\n+7///vvWr9yqQOjm5pb/xlkAAAAUh44dO2ZlZVl4P8GJEyfu3r3bq1cv6bVsJhm9KA8vgKOj\n47lz52xdhbVq167966+/2roKWGXGjBnSfYYFWrRoUWFXblUgDAsLi4iIKDCPAgAAoOj8/PxG\njRploUF8fPzdu3eHDBlSqlSpF1YVgJeSVYHwk08+6dOnT7NmzVq0aOHj42O0dOrUqcVQGAAA\nAACgeFkVCJcvX757924hRGRkZP6lBEIAAAAA+DeyKhAuW7asc+fOU6dO5SmjAAAANtegQYMn\nT57wTEgARWdVunv06NEXX3xRvXr14q4GAAAABerVq1evXr1sXQWAl4HSmka1a9d+9OhRcZcC\nAAAAAHiRrDpDuHLlyilTpnzxxRcNGzYs7oIAAABky/p3SQPAc2FVIJw4ceKdO3caNWrk5uaW\n/ymjcXFxz78uAAAAAEAxsyoQKpXKkJCQypUrF3c1AAAAAIAXxqpA+N///re46wAAAAAAvGAF\nP1QmNze3cePGe/fufQHVAAAAAABemIIDoYODw/3792NiYl5ANQAAAACAF8aq1058++23a9eu\n/fHHH/Py8oq7IAAAAADAi2HVPYSLFy9WqVS9e/e2s7Pz9fV1cHAwXMpTRgEAAADg38iqQJiX\nl+ft7d2+ffvirgYl1p8PH806/vvvdxNyNJpavj6TQxt1qxz8zI1vPE4dtvfQucSknwf2blXB\n35pFC377Y8Fvp4021LZi4IEBPZ/H/gEAAAByZFUg/O2334q7DpRkMSmp7f93p6+Ly9xWzTwc\nHLZcudb/x33be3XpbioTFth4zcU/p/x6opSTU/6+Fhal5eQqFYpVr7U1nFneze157B8AAAAg\nU1YFQsjcJ7+dztPqfhnUu6ybqxCif40qzTZum/LryW6VgxWFbPzH/cRJR48vbNPC1cF+9P5f\nDDtaWCSESMvJcXewH16nZvHtJgAAACA3Vj1UBnKm0en2xtzq/EolKeAJIVQKxf/Uqn4rNS0q\n6WFhG5d2dj7xP/3HNKiTf0MWFgkh0nNy3f958yoAAACAIiIQogBxqelPcnNr+5U2nFmvjK8Q\n4nJScmEbv+LtWdu3tDDFwiIhRFpOrofj/wXCLJ52CwAAADwPXDKKAiQ+fSqEKOPiYjjT18VZ\nCJGQkVmUxoWSnpOTo9EM3/fz/phbaTm5pZydBtWoOq9VM1d7+6KsFgAAAJAzAiEKkJ2nEUI4\nqP5xMtlRpRJC5GiMz9QVqnGhpObkxKaktQjwX/laOzul8qe/Yladu3Q1+TFPGQUAAACeGYEQ\nBXCyk+KcxnBmtkYjhHCyMz5+CtW4UH4e2NtOqSzj+n/nHntVecVBpdp0+dp/79xtXSGgKGsG\nAAAAZIt7CFGAcm6uQojEp/+44DMx46kQwj/fWx8K1bhQ/N3d9GlQ0rdaZSFEVL77GAEAAABY\niUCIAlTy9PB2cryQmGQ480zCAyFE/bK+RWlcKOm5uem5uYZznqrzhBAu9pzlBgAAAJ4RgRAF\nUCoUPauEHIq9fTstXZqTnafZEHW1tm/paj6litLYeg+eZpZbsXrYnkOGMzddvqoQokWA/zOv\nFgAAAJA5zq6gYNNfbbL7RmynbT+Oa1jX1d4+IurKnfQn+/r3kJbujbk14Md9i9q1fLdh3QIb\nn7qXEP3osfSDEOJAbNzN1FQhRJsKAYlPM80tCvLyfLt+na/PX+q246eeVV7J1Wh//Cvm+J17\n7zSoW9XH2wYjAgAAALwUCIQoWIC726+D+3x87Lf5J//I02nrlfHb17+H/lEuWp1Oo9NpdTpr\nGn93JXrtxT/1a152+rz0w6Zurx2Pv2duUZCX55L2LauU8tpw+eq0X39Ta7XVS5da9VrbkXVr\nFfe+AwAAAC8xAiGsUqWU987eXU0u6l45OHvyeCsbr+zUdmWntiYX9a9exdwiIYRSoRjToM6Y\nBnWsLhkAAABAAbiHEAAAAABkikAIAAAAADJFIAQAAAAAmSIQAgAAAIBMEQgBAAAAQKYIhAAA\nAAAgUwRCAAAAAJApAiEAAAAAyBSBEAAAAABkikAIAAAAADJlV6xrz8jIWL169ZkzZ/Ly8mrV\nqjV27Fg/Pz/r29y7d2/ZsmUxMTG7du0q1DoBAAAAAAUq3jOEy5cvv3Pnzvz585ctW6ZSqebN\nm6fVaq1sc+LEiY8//jggIOAZ1gkAAAAAKFAxBsLk5OTTp0+/9957ISEhAQEBH3zwwb179y5d\numRlG7VavWTJktDQ0MKuEwAAAABgjWK8ZPTGjRsODg5BQUHSpJubW2Bg4I0bN+rXr29Nm3bt\n2gkhbt68Wah1Pn78OCYmRt8+MDDQxcWl2HbxWdjZFe9luijJlEqlvb29rauAadJHo1Ao+IxQ\nknF8AgCer2IMJ+np6e7u7gqFQj/H09MzLS2tsG0K1f7SpUuTJk3ST3799ddNmjQp4o48X25u\nbrYuATZjb2/v6elp6ypgmlKpFEIoFAo+I5RYHJ8AgOeueM9WGSY3IYROp3u2Nta3f+WVV8aP\nH6+f9PX1ffr0qZXVvhhZWVm2LgE2k5eXV9IOSOhJ/2/qdDo+I5RkHJ8liqurq61LAICiKsZA\n6OXllZ6ertPp9BEuLS3N29u7sG0K1b5ChQphYWH6ybS0tJIWwHJycmxdAmxGo9GUtAMSevpA\nyGeEEovjs6QhEAJ4CRTjQ2WqVKmiVqv1d/SlpaXFx8dXq1atsG2K0h4AAAAAYE4xBkJvb+9X\nX331q6++iomJiY+PX7p0aUhISM2aNYUQhw8f3rNnj+U2KSkpycnJT548EUIkJycnJydnZ2db\naA8AAAAAKJTivYdw3Lhxa9asmTFjhlarrV+//gcffCBd6nnx4sX09PRu3bpZaDNp0qSkpCRp\nPSNGjBBCjBo1qnv37ubaAwAAAAAKpXgDoYuLy/vvv//+++8bzTd8EKi5NmvXri3UOgEAAAAA\nhVKMl4wCAAAAAEoyAiEAAAAAyBSBEAAAAABkikAIAAAAADJVvA+VgTmnHqUkX861dRV4cbI0\nWluXAAAAABgjENpGfGZ2fGa2rasAAAAAIGtcMgoAAAAAMsUZQttwUCqdVKRxGdHqREZenq2r\nAAAAAP6BQGgbPf3LvF8lyNZV4MW5n5Xd7/fztq4CAAAA+AdOUgEAAACATBEIAQAAAECmCIQA\nAAAAIFMEQgAAAACQKQIhAAAAAMgUgRAAAAAAZIpACAAAAAAyRSAEAAAAAJkiEAIAAACATBEI\nAQAAAECmCIQAAAAAIFMEQgAAAACQKQIhAAAAAMgUgRAAAAAAZIpACAAAAAAyRSAEAAAAAJki\nEAIAAACATNnZugDIxYUHD+efjDyXmJSpzgv28hxVr9aIujVVCoW09Njtu59Hno1KSs7TaiqX\n8n63Qd2BNasq/u67M/rGqnOXrj9KydVqKnl6DKlVfWyDOo4qla32BQAAAHg5EAjxIvxxP7HT\n1h/Ku7tNaNLA3cH+x+s3x//8a2xq2mdtXhVC7Iu51e/HfXX9Ss94tYlKodh+7a/h+36+lZb+\ncfPGQogVZy5M+fXkoBpVp7/axEGp+vV2/LRfT/5xL2FrzzdsvVt4qbi4uGzevNnBwcHWhQAA\nALw4BEK8CDOP/+5sZ/ffwX39XF2EEMPr1Hx10/ZvL0TNb9XMTqmcdfxURU+Po4P7OtvZCSGG\n163ZcP3/rjhzflrzxgoh1l26EuTlub5rJ+mEYasK/leSH/34182U7BxvJ0eb7hZeKkqlsnr1\n6rm5uenp6bauBQAA4AUhEMIqnbb9kKvRfv1au4lHjv9xP9HJzq5NBf+lHVqXcXXRCfE4K8tk\nL5VS6eXoKIR4s0a1EXXspDQohFAqFE3Kl73w4GFqdk4pZ6fhdWsN4G6rAAAgAElEQVRW8vSQ\n0qAQwl6pbFq+7OY/r2Wq1a729k52KpVGoTBYrauDvUqh4JJRAAAAoIgIhLCKg1IVm5L21oFf\npjdvssav9OmEB2F7DmVrNP/p3TXpaWbFVetM9qpSyjtq1BAhxLA6NYwWxaSk+jg7l3J2UioU\n4xrWNVykE+Jq8qMAdzdXe3shxAeN64/Yd/izU2dG1qnpaGf36+34XddvjmlQx8WeoxcAAAAo\nEv6khlUUCnH3Sca6Lh1bVwgQQvRyd9sSVOFoXLxOCG8nx/0DeprsJSW6/P5zPeZIXPyC1s2V\nBmf+cjSapKeZ9zOefnM+6vLDRxu7vSbNf7NmNQeVaszBI3NPRAohlArFlNBGs1qGPuc9BAAA\nAOSHQAhrOapUrSoE6CfLu7lm5eVlqfNc7O3aVQy0fj0HbsaN3n/4jVcqfdikgeH83+7ef2P7\nLiFEBQ/3bT3feOOVStL8k/H3xh482irQf2TdWs72dgdvxi2KPOtgp5rWrPFz2CsAAABAxgiE\nsJaPs7PhjXwqpVIIodXpCrWSb85HfXTkeM8qr0R07aT8x42Boq5f6f/07pqclXUkLr7vD3sn\nNm04r1UzrU43+sCREG/Pnb27Su3bVQzM0+rmn/yjX7XKId5eRd8vAAAAQLYIhCgqax4qI5l0\n9MRXZy9OCm04r1VzRb7GPs7OXUKChBBhtWsEergtijzbvXKwj7PTrdS0yaGNDNNju0qBX5+/\n9Mf9RAIhAAAAUBQEQhSVNQ+VEULMPn5q1blLq15rO7JuLcM2DzOzdv11s14Z38blyuhnNvcv\n/4U4/+fDR039ywohcjUawy45Gk3+mQAAAAAKi0CIorLmoTJH4uI/jzy7tEMrozQohHBQqT78\n5b9N/cv9PLCX/jTgr7fjhRAVPN1DvL08HR0O37rzaRudfunRuHghRMOyZQQAAACAIiAQoqgc\nVCrLD5XJ02o/+OWYj7Ozs51dRNQVw0XtK1Wo4OE+ObTRJ7+f7rD1h95VQxxVqpPx976/9lfT\n8mXbVAhQKhSzWoR+dOR4j527h9ep6WJv98utOxuirvSrVrmOX+li3jMAAADgJUcgRLFLy8m5\n8ThVCDH24FGjRd/36lLBw31mi6Yh3l7fXIj69LfTuVpNRQ+PWS1DxzesJ50SfLdh3TKuLl+d\nvThq/+E8rS7Iy2NWy1CjJ5QCAAAAeAYEQlhlT78eRnOWd2i9vENra/r6ODtnTx5vuc2gmlUH\n1axqbmnfapX7VqtszbYAAAAAWE9p6wIAAAAAALZBIAQAAAAAmSIQAgAAAIBMEQgBAAAAQKYI\nhAAAAAAgUwRCAAAAAJApAiEAAAAAyBSBEAAAAABkikAIAMC/gJubm6urq62rAAC8bOxsXQAA\nACjYvn37tFptSkqKrQsBALxUOEMIAAAAADJFIAQAAAAAmSIQAgAAAIBMEQgBAAAAQKYIhAAA\nAAAgUwRCAAAAAJApAiEAAAAAyBTvIbSNww+So9Ke2LoKvDi5Gq2tSwAAAACMEQhftDJlynh5\neaWkpqbkqm1dC14oe3v7kJAQW1cBAAAA/H8EwhfN29t727Zttq7CNuLj40ePHt2tW7d3333X\n1rUAAAAA4B5CAAAAAJArAiEAAAAAyBSBEAAAAABkikAIAAAAADJFIAQAAAAAmSIQAgAAAIBM\nEQgBAAAAQKYIhAAAAAAgUwRCAAAAAJApAiEAAAAAyBSBEAAAAABkikAIAAAAADJFIAQAAAAA\nmSIQAgAAAIBMEQgBAAAAQKYIhAAAAAAgUwRCAAAAAJApAiEAAAAAyBSBEAAAAABkikAIAAAA\nADJFIAQAAAAAmSIQAgAAAIBMEQgBAAAAQKYIhAAAAAAgUwRCAAAAAJApAiEAAAAAyBSBEAAA\nAABkikAIAAAAADJFIAQAAAAAmSIQAgAAAIBMEQgBAAAAQKYIhAAAAAAgUwRCAAAAAJApAiEA\nAAAAyBSBEAAAAABkikAIAAAAADJFIAQAAAAAmSIQAgAAAIBMEQgBAAAAQKYIhAAAAAAgUwRC\nAAAAAJApAiEAAAAAyBSBEAAAAABkikAIAAAAADJlZ+sCipeLi4tSSegtKVJSUoQQKpXK29vb\n1rUAptnb23N8omRSKBRKpZLjEwDwfL3kgTAzM1OtVtu6CvyfjIwMIYRGo5GSIVCiKBQKHx8f\ntVqdnp5u61oAE3x8fLRaLb8/S5TSpUvbugQAKCrOngEAAACATBEIAQAAAECmCIQAAAAAIFME\nQgAAAACQKQIhAAAAAMgUgRAAAAAAZIpACAAAAAAyRSAEAAAAAJkiEAIAAACATBEIAQAAAECm\nCIQAAAAAIFMEQgAAAACQKQIhAAAAAMgUgRAAAAAAZIpACAAAAAAyRSAEAAAAAJkiEAIAAACA\nTBEIAQAAAECmCIQAAAAAIFMEQgAAAACQKQIhAAAAAMgUgRAAAAAAZIpACAAAAAAyRSAEAAAA\nAJkiEAIAAACATBEIAQAAAECmCIQAAAAAIFMEQgAAAACQKQIhAAAAAMgUgRAAAAAAZIpACAAA\nAAAyRSAEAAAAAJkiEAIAAACATBEIAQAAAECmCIQAAAAAIFMEQgAAAACQKQIhAAAAAMgUgRAA\nAAAAZIpACAAAAAAyRSAEAAAAAJkiEAIAAACATBEIAQAAAECmCIQAAAAAIFMEQgAAAACQKQIh\nAAAAAMgUgRAAAAAAZIpACAAAAAAyRSAEAAAAAJkiEAIAAACATBEIAQAAAECmCIQAAAAAIFME\nQgAAAACQKQIhAAAAAMgUgRAAAAAAZIpACAAAAAAyRSAEAAAAAJkiEAIAAACATBEIAQAAAECm\nCIQAAAAAIFMEQgAAAACQKQIhAAAAAMgUgRAAAAAAZIpACAAAAAAyRSAEAAAAAJkiEAIAAACA\nTBEIAQAAAECmCIQAAAAAIFMEQgAAAACQKQIhAAAAAMgUgRAAAAAAZIpACAAAAAAyRSAEAAAA\nAJkiEAIAAACATBEIAQAAAECmCIQAAAAAIFMEQgAAAACQKQIhAAAAAMgUgRAAAAAAZIpACAAA\nAAAyRSAEAAAAAJkiEAIAAACATBEIAQAAAECmCIQAAAAAIFMEQgAAAACQKQIhAAAAAMgUgRAA\nAAAAZIpACAAAAAAyRSAEAAAAAJkiEAIAAACATBEIAQAAAECmCIQAAAAAIFMEQgAAAACQKQIh\nAAAAAMgUgRAAAAAAZMrO1gVARry9vcePH1+xYkVbFwIAAABACAIhXiRPT8+wsLDs7OyMjAxb\n1wIAAACAS0YBAAAAQK4IhAAAAAAgUwRCAAAAAJApAiEAAAAAyBSBEAAAAABkikAIAAAAADJF\nIAQAAAAAmSIQAgAAAIBMFe+L6TMyMlavXn3mzJm8vLxatWqNHTvWz8/Pyjbm5sfHx0dERERH\nR2u12qCgoLCwsGrVqhXrXgAAAADAS6l4zxAuX778zp078+fPX7ZsmUqlmjdvnlartbKNyflq\ntXrGjBnu7u6LFy9etmxZmTJl5syZk5WVVax7AQAAAAAvpWIMhMnJyadPn37vvfdCQkICAgI+\n+OCDe/fuXbp0yZo25uZnZmb27NlzzJgx/v7+5cqV69evX2ZmZmJiYvHtBQAAAAC8rIoxEN64\nccPBwSEoKEiadHNzCwwMvHHjhjVtzM339PTs1auXs7OzEOLJkye7d+8OCAgICAgovr0AAAAA\ngJdVMd5DmJ6e7u7urlAo9HM8PT3T0tKsaePp6Wmhr1ar7du3b15eXs2aNRcsWGBvb69vduXK\nlc2bN+snhw0bpk+VsDnpA7W3t3d3d7d1LYBpdnZ2HJ8omRQKhVKp5PgEADxfxftQGcNEJ4TQ\n6XTWt7HQV6lUrlixIjU1dffu3dOnT1+yZImrq6u0KCkp6ZdfftG37N27t6OjY9F2As+ZSqVS\nqVS2rgIwTalU8ksDJZZCoeD4BAA8X8UYCL28vNLT03U6nT7apaWleXt7W9OmwL6BgYGBgYE1\natQYOnTosWPHunTpIs0PDQ396aef9M0cHR1TUlKKbx9RKCqVysPDIycnJzMz09a1AMYUCoWX\nl5darc7IyLB1LYAJXl5eWq02PT3d1oXg/zP6qwYA/o2KMRBWqVJFrVbHxMRUrlxZCJGWlhYf\nH2/0ighzbfz9/U3Ov3Tp0qpVq7788ksnJychhFKpVCgUhicPnZ2d/f399ZNpaWlqtbr49hHP\nQKfTaTQaW1cBGJO+fuL4RAnH8QkAeL6K8aEy3t7er7766ldffRUTExMfH7906dKQkJCaNWsK\nIQ4fPrxnzx4LbczNDwkJycnJWbFiRXx8fGJi4tq1a7Ozsxs0aFB8ewEAAAAALyuFyfv6npfM\nzMw1a9acOnVKq9XWr19/zJgx0sUVixcvTk9Pnz9/voU25ubfvn1748aN169f12g0FStWHDx4\ncJ06dcwVwBnCEkWlUnl7e2dnZ3NJHkoghULh4+OTm5vLJXkomXx8fLRaLfdBlCilS5e2dQkA\nUFTFGwhtjkBYohAIUZIRCFHCEQhLIAIhgJdAMV4yCgAAAAAoyQiEAAAAACBTBEIAAAAAkCkC\nIQAAAADIFIEQAAAAAGSKQAgAAAAAMkUgBAAAAACZIhACAAAAgEwRCAEAAABAphQ6nc7WNUAu\nHj58uGbNmnr16r3xxhu2rgUwlp2dvXTp0uDg4IEDB9q6FsCExYsXe3p6vvXWW7YuBADwUuEM\nIV6c9PT0H3744fz587YuBDBBrVb/8MMPv//+u60LAUzbs2fPkSNHbF0FAOBlQyAEAAAAAJki\nEAIAAACATBEIAQAAAECmeKgMAAAAAMgUZwgBAAAAQKYIhAAAAAAgUwRCAACEWq2eMGHC3r17\nhRAxMTFvvfVW375909LSbF0Xiqq4P82kpKTu3bvfvn276KuKiIiYP38+9/IAeMHsbF0ASq57\n9+4tW7YsJiZm165d1rRPS0sbPny4l5fX2rVrlcr//13Dhx9+GBMTo590d3cPDg4eMmRI1apV\npTlLly5NT0+fM2eOvvHy5cuDg4P1XTQazfDhw1NTU3/88UeVSmV5cyhpHj9+HBERcfHiRbVa\nHRQUNHz48CpVqljuUtKOJaPtSsqWLbt69Wrrx6GIzA1jfHx8REREdHS0VqsNCgoKCwurVq2a\n5VUxvCZt2LDBy8ura9euQoi9e/d6e3svXbrU1dXVXPuoqCgXF5eQkJAXWCOehblP08KvpsL+\n8/e8DB069MMPP9y9e3ePHj1e5HYByByBEKadOHFi7dq19evXz/+Hmjk///xzjRo1bt++febM\nmaZNmxouat++/eDBg6WfU1NTd+3aNXPmzK+++qpMmTL51+Pp6Xn48OG3335bP+fcuXP5vzG1\nsDmUKAsWLHB0dJw7d66zs/OWLVvmz5+/Zs0aJycnC11K4LHUpk2bQYMGGc6xszP+/anRaPQp\nKP+kOVY2MzmMKpVqxowZ9erVW7x4sVKp3L59+5w5cyIiIpydnS2siuHNLykp6cCBA0uWLJEm\nnzx5UrFiRTc3Nwtddu3a1bhxYysDoZVlFLHLc+xeAjf0zMx9muZ+NT3DP3/Pi0qlGjRo0Fdf\nfdWpUyfL/xcDwHPEeRWYplarlyxZEhoaamV7nU536NChNm3atGrV6uDBg0ZLnZycSv8tJCRk\nwoQJQoizZ8+aXFWjRo2OHTuWm5urn3P48OG6detavzmUHE+ePClTpsy4ceOCg4PLlSs3bNiw\ntLS0O3fuWOhSMo8lV1fXcv/k6+srhNBoNN27d//ll19GjRq1YsUKo0khRGpq6uLFi8PCwgYP\nHjxjxoy4uLj8vYQQR44ceeedd/r27Tt06NDw8HDDmi0MY2ZmZs+ePceMGePv71+uXLl+/fpl\nZmYmJiYyvIUaXiHEgQMHKleuLJ3tnDZt2rlz5w4fPty/f//ExMTu3btfvnxZapaQkNC9e/eE\nhITp06efO3du7dq1EyZMyM7ONtnGZLWLFi0aOHDg4MGDZ82alf9/BOu7xMbGTpw4sX///hMm\nTIiKiurevXtsbKz13U0OiMmZVo6w4SfevXv3Y8eOTZs2LSwsbPz48bdv3163bt3YsWP/53/+\n5z//+Y/UzFxh8fHxs2bNGjRo0MCBA2fPnp2QkKBf58mTJ2fNmvXWW2+NHDny6NGj+Y8ik6Ua\nfpqGl4xa+NVkzT9/0vj369dv/Pjx169f1883Wf/kyZPDw8P1ba5fv96jR4+kpCSTA960aVNH\nR8djx45Z2DoAPF8EQpjWrl076Q8yK509ezY9Pb1Fixbt27c/f/58UlKShcZKpVKpVGo0GpNL\nQ0JC3N3dT506JU2mpaWdP3++efPmz7w52JC7u/uUKVP8/f2lyUePHikUilKlSlno8u86llQq\nlUKhOHDgwMcffzxmzBijSSHEggULsrKyVqxYsW7duuDg4GnTpj158sSoWWJi4pdffvn2229/\n//33X3zxxY0bN3bv3m24FXPD6Onp2atXL+lMwpMnT3bv3h0QEBAQEGChYIY3//AKIS5cuFCv\nXj3p588++6xBgwYdO3b8/vvvvby8TBb2ySef+Pr6jho1atmyZVYWL4T44osvhBBr1qyJiIio\nUqXKzJkzc3JynqGLWq2eM2dOYGDgpk2bJk6cuHHjRqmvld1NDoi5UbJmhA13QaFQKJXK/fv3\nz5w5c/369S4uLh9//HHlypXDw8PHjx+/efNmKZWZG4qFCxd6e3uvX79+/fr1Tk5O0vBK69y5\nc+f777+/evXq3r17h4eHZ2dnGw24yVINP01PT099Ywu/mgr850+n03366acBAQGbN2+eOXPm\n/v379YtM1t+pU6fjx4/rv4Y4ceJErVq1tFqtyQFXKBR16tS5ePGihQIA4PkiEOL52L9/f4sW\nLZycnIKDg4OCgg4dOmSuZXZ29oYNG3Jycho3bmyuTceOHQ8fPiz9/Ouvv9auXdvHx+fZNoeS\n48mTJ1999VW3bt1Kly5toVnJPJYOHjzY/5/0fwUqFIomTZoEBwe7uLgYTcbGxv7111/Dhg3z\n8vJycnIaPHiwWq3+448/jJqlpaXpdDo3NzelUunr67tkyZK+ffua26P8w6jVanv37j148OA7\nd+4sWLDA3t7eXF/r91fIbHjv3LlTqVIlC+P2bAzLuHPnzqVLl9566y13d3cHB4fBgwfn5uae\nOXPmGbpER0enpqYOGjTIycnJ399fuu/R+u4mB8TkTCtHOP+Ot23b1sXFRaVS1ahRw8HBoVWr\nVkKIOnXqaLXaBw8eWBiKhQsXjh071tnZ2cXFpXXr1jdu3NBfhNyuXTvp6GrcuHFOTo7RlwsW\nSi2Qlb+a9K5fv56UlDRw4EAnJyc/Pz/D+/1M1t+iRQutVhsZGSmE0Ol0v/32W4cOHSwclpUq\nVbJ8GQUAPF/cQ4jn4MGDB+fPn1+4cKE02bFjx+3bt7/55pv6G0sOHjx45MgR6efs7OwKFSpM\nnz69XLly5lbYvn37//3f/01MTCxbtuwvv/xidHNRgZtDCXT37t358+fXq1dv5MiRFpqV2GOp\nZcuWRn0NzzaUL1/ecJF+MiEhQaFQ6M9CODo6+vj46C/p1DerUqVKly5dJk6cWLly5Xr16rVq\n1crcWT6Tw6hUKlesWJGamrp79+7p06cvWbLE3KNQGF6Tw5uZmZmXl+fh4WFuN4tCX8b9+/eF\nEEOHDjVcavL63gK75ObmSilCmmP0lKYCu7/66qv5B8TkKFk5wvnpvxdwcHDQ/yx9VZGTk/P4\n8WNzQxEbG7tz587ExESdTpeTk6PRaLRarXTA6PdXWo/Rdb+WS7XAyl9Nhh4+fKhQKPz8/KRJ\n/UbN1e/k5NSqVatffvmlVatWV69ezczMbN68uYODg7nD0sPDIz093cpiAKDoCIR4Dg4ePKjT\n6ebOnStNarXa7OzsyMjIV199VZqj/2svMzNz5syZb7zxRqNGjSyssFSpUg0aNPjll1+aNm2a\nkpLStGnTmzdvWr85lDSXLl1atGjRm2++2aVLF8stS+yxJN3kZm4rRiflLJyj0+l0CoXCqJlC\noXj77bf79Olz5syZM2fO7Nix46OPPmrRooVRXwvDGBgYGBgYWKNGjaFDhx47dszcODO8FobX\nGlqttrBtDMsQQuzcudPBwcHyGgrscvToUf1u6psVaosmByT/TKM1CzMjnF/+jvmX5i8sKSlp\n3rx5gwYNmj17tp2d3enTpxcsWGDlOvMzLNUc6381GVKr1YaT+muqLdTfqVOniRMnPn78+OTJ\nky1btnR0dBRmPoVC7CEAPCcEQhRVXl6edGagffv2+pkREREHDx7U/9ln+NfeW2+9tXLlytq1\nawcGBlpYbceOHTdu3JiVldWmTRvD5w1aszmUKFevXl20aNFHH33UoEEDyy1fvmOpfPnyOp3u\n7t27FStWFEJkZ2c/fvw4f/LRaDQZGRmlS5fu3Llz586d16xZI11padjG5DBeunRp1apVX375\npfTUVqVSqVAozL3EjOE1N7wuLi52dnYmz8nY29srFIq8vDxp0uQ9kNa0EX+fT4uNjdW/F0Q6\ns2p5B012KVWqlEajefTokXSJ419//VWo7iYHpFmzZvlnjh492poRLixzhd24cUOr1fbp00cK\ncjdu3CjUOgtbqvW/moyULl1ap9M9fPhQevqu/vJOC/VXrly5UqVKx48fP3ny5McffywsHpbp\n6enFdL4aAEziHkKYlpKSkpyc/OTJEyFEcnJycnKydAf/4cOH9+zZY9jyt99+e/r0aZcuXfwM\ndO3aNSoqSrpgyUibNm0aNmy4ePFioy9ZjTRu3Pjp06fHjh3r0KFDUTYH28rNzV2+fHn37t0r\nVKiQ/Ld/47H09OnThHzMPW1FLygoqFq1ahs3bkxLS8vMzNywYYOzs3P+pxcePXp0woQJMTEx\nOp0uNTX1zp07RjnB3DCGhITk5OSsWLEiPj4+MTFx7dq12dnZ0l+3DK/1wyuEqFChgvRQSiMq\nlapcuXLnz58XQmRnZ+/bt0+/yNHRMSEhQXrCirk2hgIDA+vUqbN+/frk5GSNRnPgwIHx48en\npKRY2EFzXapVq+bi4rJjx46cnJx79+4dOHCgUN1NDojJmVaOcGGZK6x06dIajebq1as6ne74\n8eNRUVFCCOn60gIVtlQLv5rM/fOnV61aNXd3961bt2ZkZMTHx+/du1eab7l+6ZJpV1fX6tWr\nC4uHZVxcXIUKFQo5qADw7DhDCNMmTZqk/557xIgRQohRo0Z179794sWL6enp3bp107c8cOBA\ns2bNjL7OrFmzpr+//8GDB6W+Rt55551x48Zt2LBh9OjR5gpQqVTt2rW7dOlSUFCQ4fxn2Bxs\n6Nq1a4mJid999913332nn/n222936dLl33UsHTt2LP+D4L/++mvLj/QUQkyePPnbb78dPXq0\nvb191apVFy5cmP8hHB06dHj06NHChQtTUlJcXV0bNmxodDuThWGcN2/exo0bp06dqtFoKlas\nOGvWLOn0C8OrV+DwCiHq169/8eJFo/sYJWPHjv3mm29OnTrl5eU1ZMiQ06dPS0n19ddf37Rp\nU2Rk5OrVq821MfLRRx+tWbNm3LhxWq22UqVKc+bM8fb2tryD5rpMnz599erVQ4YMCQ4OHjRo\n0KxZs5RKE9/wmuxuckBcXFxMjpI1I/wMTBbm7e3du3fvTz75RKFQNGvWbObMmTNmzPjwww+l\nR5IWqFClWvh/ytw/f/pmDg4Os2fPDg8PHzZsmPTKirlz52o0mqpVq5qr38/Pr02bNuvXr9d/\nb2LusNTpdFFRUQMGDCj8oALAMzJ7cREAADKRlJQ0ZsyYJUuWSK8iLPk0Go1Op5Ou0b1+/fqk\nSZO2bdv2XKIaiklcXNxHH320bt06c+8ykURGRn711Vdr167lxfQAXhguGQUAyJ2fn1/nzp03\nb95s60KsotPpxo0bt2rVqqdPn6akpGzdurV27dqkwRJLrVYnJCSsWLHi9ddft5wGNRrNtm3b\nBgwYQBoE8CIRCAEAEMOGDUtNTTW68bJkUigUU6dOTUpKGj58+Pjx452dnT/88ENbFwWzfvjh\nh3HjxpUvXz4sLMxyy82bN5cqVcrwSm8AeAG4ZBQAAAAAZIozhAAAAAAgUwRCAAAAAJApAiEA\nAAAAyBSBEAAAAABkikAI4N9qzpw5CoXCz89PrVbnXzp69GiFQtGiRYtnW/nAgQPd3Nysadmi\nRYtq1ao921YAAABsi0AI4F9MqVQ+fvz4wIEDRvOzs7N37Njh4OBgk6oAAAD+LQiEAP7FlEpl\naGjohg0bjObv3r376dOnDRo0sEVRAAAA/xoEQgD/Ynl5eT179ty3b9+jR48M52/atKlt27ZG\nZwgPHDjQqlUrd3d3Z2fnWrVqLV26VP8iVp1ON2/evMDAQCcnp9q1a+/cuVOhUBj2/e233zp2\n7Ojh4eHs7Fy/fv3169ebrCchIWH06NEVK1Z0cnIqW7Zsnz59oqOjn+seAwAAPE8EQgD/br16\n9crLy9u6dat+TlJS0qFDhwYOHJibm6ufuWvXri5dugghNmzY8NNPPzVv3vyjjz6aNGmStHTx\n4sWzZ89u2bLlnj17pk+fPnv27AsXLuj7Hjt2rG3btmq1esuWLbt37w4NDR05cuSSJUvyF9O7\nd++9e/fOmjVr//79S5Ys+euvv1q3bp2ZmVlcOw8AAFA0Cv0X5ADw7zJnzpy5c+dmZWV169Yt\nJSXl7Nmz0vwVK1ZMmzbtwYMHHTt2tLOzO3nypBCievXqT58+vXHjhqOjo9RMCm8JCQmlSpUK\nCAjw9va+fPmydGLw/v37lSpVcnBwyMjIEEI0atTo8ePH165d0/ft0aPHf//734SEBGdn5xYt\nWiQnJ0dHR6enp3t6ek6ZMmXhwoVSs1u3bm3bti0sLKx8+fIveHAAAACswRlCAP96w4YNO3fu\n3JUrV6TJTZs29ezZ093dXd/g/v370dHRnTt31ic6IUSXLsHACXQAAAOCSURBVF3UanVkZGR8\nfPz9+/fbtWunv0y0fPnyjRo1kn5OTk4+d+7c66+/rtPpsv/2xhtvpKWlnTt3zrAMFxeX0qVL\nb9u27ciRI1qtVggRFBQ0bdo00iAAACixCIQA/vV69erl7u4uPVrm6tWr58+fHzp0qGGDe/fu\nCSECAgIMZ0o5LSEhITExUQjh5+eXf6kQIj4+XggRHh7ubGDMmDH61erZ2dnt379foVB06NDB\n19d3wIABW7du1Wg0z3lvAQAAnh87WxcAAEXl4uLSr1+/LVu2LFy4cNOmTeXKlevYsaNhA+nU\nn+EthUII6YJ5hcL0lfP6ICf1HT58+FtvvWXUJiQkxGhO48aNY2Jijh8/fvDgwQMHDnz//fcr\nV648evSo4ZlJAACAkoNACOBlEBYWtn79+pMnT27btu3NN99UqVSGSwMDA8Xf5/r07t69K4QI\nCAjw9fUVQjx48MBwaVxcnPRDhQoVhBBarTY0NNSaSlQqVdu2bdu2bfv5559/++23Y8aM2b59\nu9EZSwAAgBKCS0YBvAxatmwZHBy8ePHi27dv509fZcqUqV279t69e7OysvQzd+3a5eLi0qxZ\ns0qVKpUuXVp/458QIjo6OioqSvq5VKlSTZo02bVrV2pqqr7vpk2bZsyYkZeXZ7iVs2fPDhw4\nMCkpST9HOlFpOAcAAKBEIRACeBkoFIqhQ4fu27evbt26derUyd/gs88+S0lJ6dix43/+8589\ne/a8+eabBw4cmDlzpoeHh1KpHDt27LVr13r37r1z586vv/769ddfb9iwob7vokWLMjMzW7Zs\nuXnz5p9//nnmzJmjRo26f/++nd0/LrLw9/c/ePBgx44d169ff/jw4a1btw4ZMsTR0bFbt27F\nvv8AAADPhEtGAbwkhg4dOnfuXHMXZ3bp0mX//v2ffPJJWFhYXl5ejRo11q9fP3z4cGnp7Nmz\n1Wr1hg0bDhw4ULVq1eXLlx87duzixYvS0tatWx89enTevHnvvvuuWq0OCgqaN2+e/h2GeuXK\nlTt+/Pi8efOmT5/++PFjHx+fJk2aHD9+vGrVqsW31wAAAEXBewgBAAAAQKa4ZBQAAAAAZIpA\nCAAAAAAyRSAEAAAAAJkiEAIAgP/Xfh0IAAAAAAjytx7ksgiAKSEEAACYEkIAAIApIQQAAJgS\nQgAAgCkhBAAAmBJCAACAKSEEAACYCgs5jTZ7aestAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- new.get_result(result.m03.1, '1. ARIMA')\n",
    "errors.2 <- new.get_result(result.m03.2, '2. ARIMA Errors 2')\n",
    "n <- paste('3. ARIMA Errors (future regressor mean of', hori ,'days)', sep=' ')\n",
    "errors.3 <- new.get_result(result.m03.3, n)\n",
    "\n",
    "x <- rbind(errors.1, errors.2)\n",
    "x <- rbind(x, errors.3)\n",
    "\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b58831-3950-4988-b3bf-3f5313d409f9",
   "metadata": {},
   "source": [
    "### save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab39eccc-4453-4c0e-b430-b46b51c21e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- result.m03.1\n",
    "write.csv(x, file = \"arima_result_m0301.csv\")\n",
    "x <- result.m03.2\n",
    "write.csv(x, file = \"arima_result_m0302.csv\")\n",
    "x <- result.m03.3\n",
    "write.csv(x, file = \"arima_result_m0303.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c35829-53d8-47e0-b381-71b6dfd0d856",
   "metadata": {},
   "source": [
    "### load result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c522e476-b850-4a80-8d6f-4d52ec6b5ae5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.m03.1 <- read.csv(file = 'arima_result_m0301.csv')\n",
    "result.m03.2 <- read.csv(file = 'arima_result_m0302.csv')\n",
    "result.m03.3 <- read.csv(file = 'arima_result_m0303.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f0a8df7-b56a-46aa-9af5-d6702ae1057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m03 <- result.m03.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88acae2-994b-4716-b170-6ce34970d63e",
   "metadata": {},
   "source": [
    "# ARIMA+GARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748e4290-f9bd-441f-a136-17269a33122d",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f191fab1-f27c-4776-857e-0122f16923dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast <- function(x, h, \n",
    "                        mxreg=NULL, mxreg.msize=NULL, \n",
    "                        vxreg=NULL, vxreg.msize=NULL,\n",
    "                        order=NULL) {\n",
    "    forc <- ag2.forecast(x, h, \n",
    "                         mxreg=mxreg, mxreg.msize=mxreg.msize, \n",
    "                         vxreg=vxreg, vxreg.msize=vxreg.msize, \n",
    "                         out.sample=0, order=order)\n",
    "    if (!is.na(forc)) {\n",
    "        fc <- list(method = \"ARIMA+GARCH Forecasting\", mean=forc@forecast$seriesFor[,1],\n",
    "                   arima.order=forc@users$arima.order)\n",
    "        attr(fc$mean, \"names\") <- NULL\n",
    "        return(fc)\n",
    "    }\n",
    "}\n",
    "\n",
    "agarch.forecast <- cv.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab8d0cf9-7d7d-4ee6-bc28-10f3982ef4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.forecast.2 <- function(x, h, \n",
    "                          mxreg=NULL, mxreg.msize=NULL, \n",
    "                          vxreg=NULL, vxreg.msize=NULL, \n",
    "                          sample.n=0) \n",
    "{\n",
    "    result.rmse <- c()\n",
    "    result.mape <- c()\n",
    "    train.len <- length(x) - h\n",
    "    my.subset <- function(x, s, e) {\n",
    "        if (!is.null(x)) {\n",
    "            x <- subset(ts(x), start=s, end=e)\n",
    "        }\n",
    "        return(x)\n",
    "    }\n",
    "    idx <- 0:(h-1)\n",
    "    if ((sample.n>0) & (sample.n<h)) {\n",
    "        idx <- sort(sample(idx, sample.n))\n",
    "    }\n",
    "    \n",
    "    order <- NULL\n",
    "    for (i in seq_along(idx)) {\n",
    "        trlen <- train.len+idx[i]\n",
    "        x.train <- my.subset(x, 1, trlen)\n",
    "        mxreg.train <- my.subset(mxreg, 1, trlen)\n",
    "        vxreg.train <- my.subset(vxreg, 1, trlen)\n",
    "        \n",
    "        fc <- cv.forecast(x.train, 1, \n",
    "                          mxreg=mxreg.train, mxreg.msize=mxreg.msize, \n",
    "                          vxreg=vxreg.train, vxreg.msize=vxreg.msize, \n",
    "                          order=order)\n",
    "        if (i==1) { # reuse param for the rest of periods\n",
    "            order <- fc$arima.order\n",
    "        }\n",
    "        \n",
    "        result.rmse[i] <- sqrt(mean((fc$mean - x[trlen+1])^2))\n",
    "        result.mape[i] <- mean(abs(1 - fc$mean / x[trlen+1]))\n",
    "    }\n",
    "    e <- list(rmse.mean=mean(result.rmse), rmse.sigma=sd(result.rmse), \n",
    "              mape.mean=mean(result.mape), mape.sigma=sd(result.mape))\n",
    "    return(e)\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8dd1a8-1213-4b11-be11-ed86fa7e0ac2",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fc5c70c-df6f-49dd-b5a3-d09dcd858c0e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"10 % done.\"\n",
      "[1] \"20 % done.\"\n",
      "[1] \"30 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"40 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"50 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"60 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"70 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"80 % done.\"\n",
      "[1] \"90 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n"
     ]
    }
   ],
   "source": [
    "result.m04.1 <- my.tsCV.2(train, cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          silent=F,\n",
    "                          sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4916d16-6a26-4c9c-bb1b-30988b39aa2a",
   "metadata": {},
   "source": [
    "## Regressors for mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce4d19cd-012a-426c-bd7f-9d312c363316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"10 % done.\"\n",
      "[1] \"20 % done.\"\n",
      "[1] \"30 % done.\"\n",
      "[1] \"40 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"50 % done.\"\n",
      "[1] \"60 % done.\"\n",
      "[1] \"70 % done.\"\n",
      "[1] \"80 % done.\"\n",
      "[1] \"90 % done.\"\n"
     ]
    }
   ],
   "source": [
    "result.m04.2 <- my.tsCV.2(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          mxreg=trainx[,2:4], silent=F,\n",
    "                          sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b54ebef-c351-4357-8f97-9c524bd47711",
   "metadata": {},
   "source": [
    "## Regressors for variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "665586fb-e4bf-4356-86fb-2be0133969fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"10 % done.\"\n",
      "[1] \"20 % done.\"\n",
      "[1] \"30 % done.\"\n",
      "[1] \"40 % done.\"\n",
      "[1] \"50 % done.\"\n",
      "[1] \"60 % done.\"\n",
      "[1] \"70 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"80 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"90 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"GARCH model does not converge\"\n"
     ]
    }
   ],
   "source": [
    "result.m04.3 <- my.tsCV.2(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          vxreg=trainx[,2:4], silent=F,\n",
    "                          sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26215cf2-deb9-45fa-be1f-ea72448a97b7",
   "metadata": {},
   "source": [
    "## Regressors for both of mean & variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "048f72f1-594f-416e-8dc4-a12ecb877efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"10 % done.\"\n",
      "[1] \"GARCH model does not converge\"\n",
      "[1] \"20 % done.\"\n",
      "[1] \"30 % done.\"\n",
      "[1] \"40 % done.\"\n",
      "[1] \"50 % done.\"\n",
      "[1] \"60 % done.\"\n",
      "[1] \"70 % done.\"\n",
      "[1] \"80 % done.\"\n",
      "[1] \"90 % done.\"\n"
     ]
    }
   ],
   "source": [
    "result.m04.4 <- my.tsCV.2(trainx[,1], cv.forecast.2, h=hori, window=wind, step=peri,\n",
    "                          mxreg=trainx[,2:4], vxreg=trainx[,2:4], \n",
    "                          silent=F,\n",
    "                          sample.n=round(hori*sample.r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4805d3a-1bc0-47e4-95f8-d358940ab858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"cv starts from 2000-02-09\"\n"
     ]
    }
   ],
   "source": [
    "x <- result.m04.4\n",
    "from <- x[!is.na(x[,'forecast_start']),][,1][1]\n",
    "from <- index(trainx[from])\n",
    "print(paste('cv starts from', from, sep=' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8c970c-798b-4d41-9930-01e336c80952",
   "metadata": {},
   "source": [
    "## Compare Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "624fa65b-7533-4f86-86de-0c335271b0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAALQCAIAAAAPZx74AAAACXBIWXMAABJ0AAASdAHeZh94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\n",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.1 <- new.get_result(result.m04.1, '1.AG')\n",
    "errors.2 <- new.get_result(result.m04.2, '2.AG with mxreg')\n",
    "errors.3 <- new.get_result(result.m04.3, '3.AG with vxreg')\n",
    "errors.4 <- new.get_result(result.m04.4, '4.AG with m&v xreg')\n",
    "\n",
    "x <- rbind(errors.1, errors.2)\n",
    "x <- rbind(x, errors.3)\n",
    "x <- rbind(x, errors.4)\n",
    "\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec0491-dff8-4c4b-8965-bcbfbecf1375",
   "metadata": {},
   "source": [
    "### save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4121890e-a78d-4c57-a282-e65c742ce8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- result.m04.1\n",
    "write.csv(x, file = \"agarch_result_m0401.csv\")\n",
    "x <- result.m04.2\n",
    "write.csv(x, file = \"agarch_result_m0402.csv\")\n",
    "x <- result.m04.3\n",
    "write.csv(x, file = \"agarch_result_m0403.csv\")\n",
    "x <- result.m04.4\n",
    "write.csv(x, file = \"agarch_result_m0404.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ddbbe0-2e37-4bbc-b30e-eb93048e1f1a",
   "metadata": {},
   "source": [
    "### load result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "199edcd6-5769-43b7-84e5-7169ce2ca863",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.m04.1 <- read.csv(file = 'agarch_result_m0401.csv')\n",
    "result.m04.2 <- read.csv(file = 'agarch_result_m0402.csv')\n",
    "result.m04.3 <- read.csv(file = 'agarch_result_m0403.csv')\n",
    "result.m04.4 <- read.csv(file = 'agarch_result_m0404.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ab8b4ec-19dc-42d8-bdcf-2c6d98936fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.m04 <- result.m04.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb209ef-30c2-4407-b353-1a388b17d202",
   "metadata": {},
   "source": [
    "# Model Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9a63c6f-09de-4820-a6e8-a454f4973d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.1 <- new.get_result(result.m01, '1. Prophet')\n",
    "errors.2 <- new.get_result(result.m02, '2. BSTS')\n",
    "errors.3 <- new.get_result(result.m03, '3. ARIMA')\n",
    "errors.4 <- new.get_result(result.m04, '4. ARIMA+GARCH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27d10fd6-6a42-4cc0-8441-08220c600b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAAJYCAIAAAD9hIhNAAAACXBIWXMAABJ0AAASdAHeZh94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\nSCkEhAAAAAAAAFLq/wB3rWDX9x2ldAAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 300,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors.list <- list(errors.1, errors.2, errors.3, errors.4)\n",
    "x <- errors.list[[1]]\n",
    "for (e in errors.list[2:length(errors.list)]) {\n",
    "    x <- rbind(x, e)\n",
    "}\n",
    "\n",
    "my.figsize(10, 5)\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd06f2b6-2391-499a-ae18-3310b7dc6dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "write.csv(x, file = \"result_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "569362d7-a89d-41b8-8268-76f63cc84ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAAJYCAIAAAD9hIhNAAAACXBIWXMAABJ0AAASdAHeZh94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\nRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 300,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x <- read.csv(file = 'result_comparison.csv')\n",
    "my.figsize(10, 5)\n",
    "new.plot_errors(x, ylog=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e916cdb4-5e18-454f-89d1-c8097ed32fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1185"
      ],
      "text/latex": [
       "1185"
      ],
      "text/markdown": [
       "1185"
      ],
      "text/plain": [
       "[1] 1185"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "948"
      ],
      "text/latex": [
       "948"
      ],
      "text/markdown": [
       "948"
      ],
      "text/plain": [
       "[1] 948"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrow(x)\n",
    "#head(x)\n",
    "x2 <- x[x[,'Models']!='5. Gradient Boosting',]\n",
    "nrow(x2)\n",
    "write.csv(x2, file = \"result_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6adf8ad-567c-461e-a306-052d9af2451b",
   "metadata": {},
   "source": [
    "## Forecast with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "cd4c644f-b363-4718-a2d5-84dc96697626",
   "metadata": {},
   "outputs": [],
   "source": [
    "h <- 21\n",
    "x.train <- train[1:wind]\n",
    "x.test <- train[(wind+1):(wind+h)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "468d812f-067c-41e8-b4cc-fa28cc823c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "my.figsize(10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "31da8a77-3e6b-405a-afa2-1c2113fd74c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fitting models using approximations to speed things up...\n",
      "\n",
      " ARIMA(2,0,2) with non-zero mean : Inf\n",
      " ARIMA(0,0,0) with non-zero mean : -8729.901\n",
      " ARIMA(1,0,0) with non-zero mean : -13486.9\n",
      " ARIMA(0,0,1) with non-zero mean : -10820.55\n",
      " ARIMA(0,0,0) with zero mean     : -8407.697\n",
      " ARIMA(2,0,0) with non-zero mean : -13491.63\n",
      " ARIMA(3,0,0) with non-zero mean : -13491.75\n",
      " ARIMA(4,0,0) with non-zero mean : -13496.44\n",
      " ARIMA(5,0,0) with non-zero mean : -13502.01\n",
      " ARIMA(5,0,1) with non-zero mean : -13509.96\n",
      " ARIMA(4,0,1) with non-zero mean : -13504.29\n",
      " ARIMA(5,0,2) with non-zero mean : -13507.99\n",
      " ARIMA(4,0,2) with non-zero mean : -13508.66\n",
      " ARIMA(5,0,1) with zero mean     : -13497.02\n",
      "\n",
      " Now re-fitting the best model(s) without approximations...\n",
      "\n",
      " ARIMA(5,0,1) with non-zero mean : -13497.21\n",
      "\n",
      " Best model: ARIMA(5,0,1) with non-zero mean \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAAJYCAIAAAD9hIhNAAAACXBIWXMAABJ0AAASdAHeZh94\nAAAgAElEQVR4nOzdeVxU9f4/8PeZGYZh2AZQUGSRAAUUEUFQNG+baWaZ7atLmlZaWl2vZV1v\nZaXftLKb2lUztay8alq5lNdyN1RABVFUEFnUGRZB9mWGOb8/Ptf5zWUZZgbmHJh5PR/+4Zw5\n58x7VuY1n43jeZ4AAAAAAADA8UjELgAAAAAAAADEgUAIAAAAAADgoBAIAQAAAAAAHBQCIQAA\nAAAAgINCIAQAAAAAAHBQCIQAAAAAAAAOCoEQAAAAAADAQSEQwn+dOnVqxIgRrq6ubm5u+fn5\nYpdjty5duuTl5ZWUlNTY2Ch2Lf/jo48+4jhu1apVnX7mN998k+O4f/3rX23tsGTJEo7jli1b\n1uk3DQAAAACm2W0gPHPmDGfS3Llzxa6x03z77be//PJLB08yefLkP//8c9iwYS+88IJSqeyU\nwjpFTU2Np6cnx3F33nlnqzu09Vwrlcp+/fq9+OKL2dnZzQ5RKBQcx5WWljY7w4QJE9oqY+fO\nnWyfd955x4oimfr6+ocffpiItm7dKpfLU1JS2np9Ll++3PTDsnnz5lGjRqlUKqVSGR0dvXjx\nYjMTZkpKSlRUFMdxH3zwgfH2BQsWjB07ds6cOSkpKeacx3xeXl7BwcHu7u6GLZ3yigUAAACA\njpOJXYBtubq63nPPPa1eFR0dLXAxtvO3v/3t/vvvf/DBB60+Q0NDw7lz59zd3ffu3SuTda1X\nxXfffVdZWRkaGnrw4MGLFy/279+/1d3c3Nzuv/9+w0We54uLizMyMlavXv3NN9/s3Lnz7rvv\nNn1DHMft2bNHo9H06tWr5bXr16/nOI7n+Y4U+f777587d27t2rV9+vQhops3bxJRWFhYXFxc\nsz3bOgMzf/78jz/+2N3dffTo0a6urocOHVqwYMGBAwf27Nlj4unTarWLFi1avHgxx3Gt7rB2\n7dr+/ftPnjw5IyOjE18G8+fPnz9/vvGWjr9iAQAAAKBz8Hbq9OnTRBQaGtrpZ66uru70c3bE\n5cuXiWjatGkdOUl5eTkRBQcHt7WDiPd68ODBbm5uu3fvJqK5c+e23MHEc11TU/Piiy8SUUBA\ngE6nM2x3dnYmopKSEuMzDB48mIiWLFnS8jzFxcVOTk6DBg0iorffftuKInmeLygocHZ2joyM\nNFTy73//m4jmz5/f3mPwP1gLXnBw8NWrV9mWurq6sWPHEtGqVatMHPiXv/yF47jXXnvt3Xff\nJaJFixa13OfNN99s9zwd1PIVu3jxYiJaunSp7W60u+hqHy8AAABg9+y2y6j5tFrt559/PnTo\nUHd3d4VCERYW9sorr1y/ft2wwzvvvMNx3M6dO1euXNm7d+8ePXqw7TzPf/XVV0lJSR4eHgqF\nIiIiYsGCBZWVlc1O/umnnw4ePFipVPr6+o4ePXr//v3GO1RXVy9ZsiQ2Ntbb29vZ2Tk8PHze\nvHnNTrJt27a77rrL29tbLpf7+/vfd999v/76K7vq0UcfDQ0NJaJ169ZxHDdy5Mh2D2npoYce\n8vLyIqL8/HzWXzEnJ6ete93uw/Xuu+9yHPfLL7/89ttvCQkJSqWyR48eTz75ZGlpqU6ne/fd\nd2+77TYXF5fIyMh//vOffBsNbgbJyclnzpx56KGHxo4d6+/vv3Hjxvr6etOHGFMqlStWrPDw\n8Lh69WpmZqbpnePi4vz8/NatW9fyqk2bNmm12rZam80s8osvvmhoaHj11VelUinbwloI2YNv\nvtWrVxPR+++/z5oZiUihULAupl9++aWJA+vr6/ft2/fpp5+yPNyqV155RSaTffrpp209NX36\n9HFxcTHunmro+Hrt2jXDxpKSEolEMnToUPrfMYRtvWKJSCqVnj9/fsKECT4+Pp6enomJibt2\n7TJxdwyvtJMnT44ZM8bLy0uhUMTExPzwww/Gu5n/ijV9npbuuOOOVrv7Pvroo4Z92v2UsPqN\nZuIBsfStZ85HWbufVFY/jAAAACCurtU5UHh6vX7ChAm//vprv379Zs+e7erq+ueff65YsWL7\n9u3JyclBQUFEpFAoiOjo0aMrV6584IEHDOPrJk2atGnTpqCgoClTpri7u+/fv3/x4sW7du06\nduwYGy7F8/wjjzyyc+fO/v37T506taKi4ueff7777rs3bNgwefJkItJqtePHjz906NDgwYMn\nT57M8/zevXuXLVt26NCh5ORkFhvWrl07Y8aMnj17Pv74476+vtevX9+xY8f999+/cePG5557\nburUqe7u7hs2bBg2bNgTTzzBEoLpQ1o+CNOmTUtMTFywYIGXl9fChQuJqGfPnq3ea3MeLhY2\n9uzZ89tvv82dO9fHx2fDhg3//ve/q6urfXx8rl27tnDhwrq6usWLF8+ZM8fDw2PKlCkmniCW\ncKZMmSKRSJ599tmPP/54y5YtkyZNMv8plkqlvr6+lZWVDQ0N7b4YHn300ZUrVx4+fHjUqFHG\nV61fv97X13f48OEdKXLbtm0cx7ExhAxrmPX29jb/7hAR+01h3Lhxxhv79+8fGhp69uzZoqIi\nPz+/Vg88cOCAi4uL6ZP7+/sPHz78yJEj6enprMm0mdGjR2/cuPHkyZOGLHfgwAG5XN7Y2Hjo\n0KGnn36abTx48CDP82PGjGl2eKuvWObq1asjRoxISEiYOnVqXl7e9u3bH3jggf3797c1LJO9\n0v7444/vvvtu1qxZ06dPz8vL+/DDD59++ulevXqxo8x/xZo+T6uee+4540BLROvXr79+/bpx\nl+N2PyWsfqO19YBY8dZrt0hzPqmsfhgBAABAZOI0TNqemV1G16xZQ0RJSUn19fWGjX//+9+J\n6PHHH2cXP/roIyLy9PQ8dOiQYR/W2W/w4MHl5eVsi16vnz17NhHNmzePbdm4cSMRjRkzRqvV\nsi0XLlxQKpVKpbKqqorn+Z9++omIEhMTm5qa2A4NDQ0RERFE9Msvv7AtbKxjTk6O4aYLCws9\nPDyGDRvGLm7dupX+twNeu4e01LLLaKv32pyHi3X/c3Z2vnLlCttSU1Pj6upKRMOHDzf0lvzt\nt9+I6L777murJJ7nS0tLFQpF37599Xo9e/TYSZrtZvq5vnTpkkQikUqlN2/eNGxstcvo5MmT\nT548SUSTJk0yPgProvn666+zh7pZl1Ezi2QT20RHRxtvZCPrPvzww+eeey4kJMTZ2TkgIGD6\n9On5+fltPSb19fUSicTHx6flVSwisiRmGnuOWu0yyvM861D68ccft3rtpk2bWM2GLWPGjElK\nSgoJCZkxY4Zh48svv0xEhw8fNtzNL7/8kl3V8hXL6pHL5d9++61h4z/+8Y+Wz0XLeyGRSFJT\nUw0bv/jiC/ZUsovmv2JNn8ccP/74IxEFBQUZPhPM+ZSw+o3W1gNi6VvPnCLN+aTqrIcRAAAA\nBOboXUZZZvv73/9u3Ilu3rx5crl8x44ddXV1RMRm4IiIiDBuNWLf2D788EOVSsW2cBy3aNEi\nJyenDRs2sC3sPwsWLDDMz9G/f/8PP/zwpZdeKi4uJqKYmJjt27evXLlSIvnvEyGXy9lElxkZ\nGWzLzZs3OY5zc3Mz3HRAQEBJSUlycnJbd8qKQ1pq9V6b83AxEyZM6Nu3L/u/Uqlk3x1ffvll\nQ29JNo3KlStXTNTw9ddf19fXT506lRXTv3//pKSk5ORkw4NjWklJyY4dO8aNG6fX62fOnOnp\n6dnuIUOHDo2Ojt62bVtFRYVh4/r164no+eef70iRhw8fJqJmDY+sy+jbb7+9f//+mJiY8ePH\n8zz/1VdfxcbGttXBtaysTK/XGzoWGmMbDVOnWu0vf/kLER06dKjVa++55x6O49jdISKtVnv0\n6NGkpKSEhATjQw4ePOju7t5Wm2qrkpKSnn32WcPF++67j4hycnJMHzV+/HjjKXmSkpKIyDCv\nrPmvWNPnaVdhYeH06dOlUul3331n+Eww51Oig2+0lix965lTpDmfVEwHH0YAAAAQnp0HwsuX\nL7c1rf+uXbt4nk9LSyOiZl9b3d3d+/fvr9Vqz507Z9g4bNgw431OnDjR8kCVSjVw4MCSkpK8\nvDwiYi1LzSaQnDt37rJly2677TYi6tu378SJE+Pi4nier6qqKi0tLS0tZUHO8J1v3LhxPM+P\nGjVq/fr1Go2GbZTL5SbutRWHtMX4Xlv0cPXr1894H3anjDeyLSYGBPI8v3r1aolEYtynlKUy\nNoiumZbPta+v78MPP5yTkzN58mTz17ibNm1abW2tYeBTQ0PDDz/8kJCQMGDAgI4UyUZ/BQQE\nGG8MDQ29//77Fy9enJeXt2PHjm3btmVnZz/11FNlZWVTp05ttTz2iLX6bLLwYDotmIN142xr\nuJqfn9+gQYP+/PPPpqYmIjp58mRNTc2oUaNGjhx58eLFoqIiIiopKcnKyrr77rstmqo0MTHR\n+CIbWllbW2v6qIEDBxpfZF0c2VEWvWJNnKddTU1NzzzzTHl5+d///nfjTqTmfEowVr/RWrL0\nrWdOkeZ8UjEdeRgBAABAFHY+hlCpVN5+++2tXuXr61tdXV1fX+/s7Nyy7ahnz570v40tvr6+\nhv/X1dVVV1dT26O/1Gq1n59fdXW1s7Mz67LVls2bN69YsSItLa2taPTZZ581NjZ+8803LGYM\nGDDg/vvvnzFjBpuZo7MOaYvxvbbo4Wq1Oc7Dw6PZFr7tSWX27t17+fLle++913jE1BNPPDFn\nzpxNmzZ9/PHHzR7YZstOXLt27ejRo5GRkXv27DE0mJjj2WefnT9//rp169j0pDt27CgvL28r\nnplfJHtwmrXszZs3b968ecZbXFxcVq9evWfPntTU1Ozs7PDw8Ga3yAYBtrrkIBsk2fE1JFmR\nJSUlbe0wevToZcuWnT59Oj4+/sCBA2xuGPYIHDp06PHHH29rAKE5t2vAGqNMvEKYZlPysAY3\ndpRFr1gT52lqamq2ZsnChQvvuusuw8UPP/zwyJEjI0eONF6j0pxPCcMr0+o3WksWvfXML7Ld\nTyrGxMMIAAAAXZOdB8LevXuzATOtqqqqoja+rLCNxsu1GbfJsO0cx7EpWFoyzCph+pvQypUr\nZ8+erVKpXn/99SFDhnh4eHAct337duO5Il1cXL7++usPPvhg586de/fuPXDgwMcff7x8+fLv\nvvvOeDJDY1Yc0paWLVFmPlwdxx6E//znP62e9vvvv3/hhReMt/j5+W3evNlwsa6ubuDAgVlZ\nWRcuXLAoEPr4+EyYMGHLli3p6ekxMTHr1693cXF56qmnOlgk64Nq6JVngru7e3R09NGjRy9f\nvtwyEHp7e0ul0lbTGmudY5mhI1iRrDtrq1ggPHz4cHx8/P79+wcNGuTl5eXp6ckGwrFASET3\n3ntvByvpFB1/xfI836wDLevyzfz555/vv/++SqX67rvvDN0yyZJPCRLvjWZmkeZ8UgEAAEA3\nZeeB0DQ3NzelUllbW1teXt7sh232ha+t79YKhcLT07OiouLll182/mm/GXd396qqqpYnN/jw\nww+JaPfu3WykDXP8+PGWe/r7+8+cOXPmzJmNjY3r16+fNWvWjBkzJkyY4OTk1NatW3GIaVY/\nXFYoLCzcvXu3SqVi45SM1dTUbNu2bfXq1c0CYTMuLi4rV6687777Zs6cmZmZybqumWnatGlb\ntmzZuHHjG2+88fvvvz/11FOttrpYVCQ7g/HQRBNYF7tWF4eQy+VhYWGsc2az2UTPnTvHcVyr\nXVst0m52HTVqlEKhOHz48KxZs5KTk2fOnElEEokkKSmJBaeDBw+Gh4ezftEi6qxXrEwma+uX\nnYqKiqeffrqpqWnNmjXNJv8081PCdmWbw8wizf+kAgAAgG7HzscQmsZxHFsn7dixY8bby8vL\nL1686OLiYuK7NRvvdOTIkWbby8rKDP+Pj49vuc/ixYvvueee5OTkuro6tVqtVCqNv2MRUbMF\nA/Pz89VqteGiXC6fOXPmnXfeWV5e3tZ8G1YcYo6OPFyWWr16dVNT09SpUze0sHXr1oiIiLS0\ntNTUVNMnGTt27GOPPVZQUMBmuTTfPffcExQU9PPPP2/btk2v17c1nYxFRbbs7KfVah988MG4\nuDjWUm3ABuBxHMdmi22Jtbzt3LnTeGNaWtrVq1cTEhIsXcSiJdb8aCJ1KBSKkSNHHj169M8/\n/6yvr2eT0BDR7bfffv78+aysrPPnz1vaX9QWBHjFzpgxIz8/f/r06Y899ljLa835lBClbIuK\nNPOTCgAAALophw6ERMTGhn3wwQfGi9S99957Op3umWeeMbF+97Rp09iebAQOc+TIET8/vyef\nfJJdZBONvPfee4Y5FfLy8pYuXXrs2LGoqCgXFxcfH5/a2tqCggLDGT744IPc3Fy61WHv9OnT\nffv2ffbZZ43HjFVXV1+8eJEtr0e31jG7ceMGu9acQ6xm9cNlEa1Wy1aHnz59eqs7sAefLXRu\n2vLlyz08PP71r38ZZsU0h0QimTp1am5u7qpVq0JCQlpdQs3SIv39/Yno6tWrhh1YU+2pU6fm\nzJmj0+nYxurq6hdeeKGuru6hhx4yjKnbuHHjV199ZVgE/KWXXpJKpe+++67hlVNdXf3qq68S\n0dy5cw3nb3aU+dj68qzgtowePfrGjRtscXnD9Ji33347z/NLly4lIhOBsNkr1qZs+opdt27d\nli1bIiIiPv/881Z3MOdTQviyLS3SnE8qAAAA6L4cussoEU2aNOnHH3/cuXPn4MGDH330UScn\np/379x86dKhfv35LliwxceDjjz/+008//fDDDwMGDHj00Ufd3d0zMzN/+eUXpVL52muvsX2e\ne+65rVu37tq1KzIycty4cTU1NT/99FNVVdWGDRtYB8LJkyd/+umn99xzz+TJk5uamvbs2VNR\nUfHtt9+OHj168+bNAQEBzzzzzDPPPPPdd99FRkbed999Pj4+N27c2LVrV2Fh4RtvvOHj40NE\nkZGRHMft3r172rRpcrn8yy+/bPcQ4R8ui+zYsUOj0YwcOTIqKqrVHSZPnvz2229v3rz5k08+\nMb2YhL+//6JFi+bMmTNt2rSMjIx2l2U3mDp16qJFiy5duvTee++1OmTL0iJZamrWDrNixYrT\np0+vX7/+jz/+GDFiRH19fXJyskajCQ8PNx6dNWvWrJqamjvuuINNDRIZGfnhhx+++eabAwYM\nGDt2rEKh+P333zUazVNPPfXEE0+0ddTx48cNU61evHiRiDZv3nzmzBm25Z///KchAba6QkYz\n99577/z587du3Tpw4EDDi2ro0KHOzs7fffedXC6/44472jq25SvWxA11kO1esTdv3pwzZw4R\nRUZGsrUEDdzd3VmjtDmfEgKX3ZI5RZrzSdW5VQEAAIBwhFjsUAxmLkzP87xWq/3888+HDBmi\nVCqdnZ0jIiLeeustwxrN/K0Fl5cuXdrswKamprVr1w4fPtzd3V2hUISEhLzwwgsXL1403qex\nsXHZsmWDBg1SKBRsytOff/7ZcG1dXd3bb78dGhrq7OwcGBg4a9assrIynueff/55V1fXXr16\nZWRkNDU1rVq1KikpydfXVy6XBwQEjB49eseOHca3smTJkh49eigUivj4eFZYu4c003Jh+rbu\ntXUPF+tVmJWVZXzfm92iAcsSGzduNFEw66H3xRdf8O09101NTWzljzfeeMOwsa2F6Y0PHD16\ntEQiMV4j3nhhekuL5Hk+JCSE47jS0lLjfYqKihYsWDBw4EB3d3cXF5fo6OiFCxdWVFQY78Om\nKr18+bLxxh07dowaNcrd3V2pVA4ePHjFihWGRcNbPYoV3xbjp4ZFwdOnT5u4a3q9nrU2z549\n23g7m9T3jjvuMN7YbGF6vsUrttXXDFu8LiYmpq0azDzKuldsu7deWFjY1oPp5+dn2K3dTwmr\n32hmPiDmvPXaLdKcTyrrHkYAAAAQHcdjQnAAQcybN2/ZsmVr1qwxPR1OS9evX+/Tp09xcbFF\ns4lYd5RGowkKCgoKCsrOzu7caWMBAAAAoAty9DGEAIJ55ZVXnJ2dP//8c71eb9GBJ0+e7N27\nt6VzS1p31IoVK7Ra7RtvvIE0CAAAAOAIEAgBBBIUFDR37txz586tX7/eogOXLVvW1tQ1nXvU\n9evXly9fHhkZaWkbJgAAAAB0U+gyCiCc+vr6uLg4tVqdmZlpehpPUYwfP37v3r3Hjh1LSEgQ\nuxYAAAAAEAJaCAGEo1Aotm/fzvP8Y489ZrwuSFewZMmS3bt3f/7550iDAAAAAI4DLYQAAAAA\nAAAOCi2EAAAAAAAADgqBEAAAAAAAwEEhEAIAAAAAADgoBEIAAAAAAAAHhUAIAAAAAADgoBAI\nAQAAAAAAHBQCIQAAAAAAgINCIAQAAAAAAHBQMrELsImamhqdTid2FWLiOE6pVDY1NdXX14td\nC3SUXC7X6/UO/pK2D0qlkohqa2vFLgQ6SiaTSSSSxsZGsQuBjlIoFFKptLa2lud5sWuBDpFI\nJHK5HF97RCeTyVxdXcWuAixjn4FQp9NptVqxqxATx3EymUyv1zv442AfWCDEU2kHpFIpEeGp\ntAMSiUQikeCptAMuLi4ymUyn0+n1erFrgQ6RSqUKhQLvSgAroMsoAAAAAACAg0IgBAAAAAAA\ncFAIhAAAAAAAAA4KgRAAAAAAAMBBIRACAAAAAAA4KARCAAAAAAAAB4VACAAAAAAA4KAQCAEA\nAAAAABwUAiEAAAAAAICDQiAEAAAAAABwUAiEAAAAAAAADgqBEAAAAAAAwEEhEAIAAAAAADgo\nBEIAAAAAAAAHhUAIAAAAAADgoBAIAQAAAAAAHBQCIQAAAAAAgINCIAQAAAAAAHBQCIQAAAAA\nAAAOiuN5XuwaOl99fb3YJYiM4zhnZ2e9Xt/Y2Ch2LdBRMpmM5/mmpiaxC4GOcnZ2JqKGhgax\nC4GOkkqlHMfpdDqxC4GOcnJykkqlDQ0Ndvl1yKFwHOfk5ISvPV2BQqEQuwSwjEzsAmxCp9M5\n+LdnQyDEV087wHFcU1OTVqsVuxDoKLlcznEc3pVd3P79+/39/SMiIkzsY0gRglUFNiKVShEI\n7YNEIsG7siuQSqVilwAWs89AiG/PHMcRkV6vd/DHwT7I5XK8pO0Gz/N4KruyioqKxx57LDY2\n9tdffzWxm0Qi4TgOT6UdYDlQp9Pp9Xqxa4EOkUql+IAFsA7GEAIAAPzXqVOnmpqa0tPT6+rq\nxK4FAABACAiEAAAA/5WWlkZEWq02PT1d7FoAAACEgEAIAADwXywQEtHJkyfFrQQAAEAYCIQA\nAABERDzPnzp1ytXVlYhSUlLELgcAAEAICIQAAABERFeuXCkrK7v77rt79+598uRJTDsJAACO\nAIEQAACAiCg1NZWI4uLi4uLiysrKcnNzxa4IAADA5hAIAQAAiIhOnTpFRHFxcUOHDiX0GgUA\nAMeAQAgAAEBElJqa6uTkNGjQIARCAABwHAiEAAAAVF9fn5WVFRUV5eLiEhMTo1AoEAgBAMAR\nIBACAABQenp6Y2NjfHw8Ecnl8piYmAsXLty8eVPsugAAAGwLgRAAAOC/M8oMGTKEXUxISGCr\nUIhaFAAAgM0hEAIAAPx3SXrWQmj4D5anBwAAu4dACAAAQKdOnfLy8goJCWEXExISCPPKAACA\nA0AgBAAAR6fRaK5duxYXF8dxHNvSo0ePkJCQ1NRUnU4nbm0AAAA2hUAIAACOzrAkvfHGhISE\n2trarKwskYoCAAAQAgIhAAA4OsOS9MYb2WqEGEYIAAD2DYEQAAAcXWpqKsdxsbGxxhvZMELW\neAgAAGCvEAgBAMChNTU1paenh4eHq1Qq4+39+/f38PBACyEAANg3BEIAAHBo58+fr62tNaxA\naCCRSOLi4goKCtRqtSiFAQAACACBEAAAHFqrM8owbBgheo0CAIAdQyAEAACHxmaUMSxJb4wF\nQqxGCAAAdgyBEAAAHFpqaqqLi0tERETLq+Lj46VSKQIhAADYMQRCAABwXBUVFbm5ubGxsTKZ\nrOW1bm5uERER6enp9fX1wtcGAAAgAARCAABwXGlpaXq9vtX+okxCQoJWq01PTxeyKgAAAMEg\nEAIAgONKS0sjopZTjBpgeXoAALBvCIQAAOC42g2EbHl6DCMEAAB7hUAIAAAOiuf506dP9+nT\np3fv3m3tExwc7Ofnd/LkSZ7nhawNAABAGAiEAADgoAoLC8vKymJjY03vNnTo0Bs3bly+fFmY\nqgAAAISEQAgAAA6qsLCQiG677TbTuyUmJhLRiRMnhKgJAABAWAiEAADgoDQaDRH16tXL9G4I\nhAAAYMcQCAEAwEGZGQijo6NdXV0RCAEAwC4hEAIAgIMyMxDKZLIhQ4bk5uYWFxcLUhcAAIBw\nEAgBAMBBmRkI6VavUaxGCAAA9geBEAAAHJRareY4zs/Pr9092WqECIQAAGB/EAgBAMBBaTQa\nb29vuVze7p7x8fFSqRTDCAEAwP4gEAIAgIMqKioyp78oEbm7u0dFRZ09e7aurs7WVQEAAAgJ\ngRAAABxReXl5fX29mYGQiBITE7VabVpamk2rAgAAEBgCIQAAOCI2o0zv3r3N3B/DCAEAwC4h\nEAIAgCMyf4pRZtiwYYTl6QEAwO4gEAIAgCOyNBD27t07MDAwJSWlqanJlnUBAAAICoEQAAAc\nkaWBkIgSExOrqqqysrJsVhQAAIDQEAgBAMARWREI2TBC9BoFAAB7gkAIAACOyNJJZejWMELM\nKwMAAPYEgRAAAByRWq2WyWQ+Pj7mHxIREeHl5ZWcnGy7qgAAAASGQAgAAI5Io9H4+vpKpVLz\nD+E4Li4uTq1WFxYW2q4wAAAAISEQAgCAw9Hr9SUlJRYNIGQSExOJ6Pjx4zYoCgAAQAQIhAAA\n4HBKS0t1Op2fn5+lB7YVCI8dO7Zs2TK9Xt859QEAAAhFJnYBAAAAQrNiRhkmNjZWLpc3G0a4\nefPm119/XavVjhs3LioqqtOqBAAAsD1BA2F1dfWaNWtSUlJ0Ot3AgQNfeuklX2IWZZEAACAA\nSURBVF/flrtdu3bts88+y8nJ+emnnyw9FgAAoF1qtZosXHOCUSgUMTExaWlpFRUVMpmMiJYu\nXbp06VKe54koIyMDgRAAALoXQbuMLl++vKCgYNGiRZ999plUKn3//fdb9q45cuTIggULAgIC\nrDgWAADAHCwQWtFCSESJiYl6vf7EiRM6ne6vf/3rxx9/7Ofn98EHHxDR2bNnO7lQAAAAGxMu\nEJaWlp48efLVV18NCwsLCAiYO3futWvX0tPTm+2m1WqXLVvG1nqy9FgAAABzFBUVEZEVYwjp\n1vL0e/fuffrppzdu3DhgwIB9+/Y9+eSTHMdlZmZ2cqEAAAA2JlyX0ezsbLlcHhISwi66ubkF\nBgZmZ2fHxsYa73bXXXcR0eXLly069vr168ZD/OPj4729vW13X7o+juOISCqVKhQKsWuBjpLJ\nZBzHsecUujX2JOJd2RWUlJQQUVBQkBVPx6hRoziO+/LLL4no7rvv3rRpk5ubGztbZmams7Oz\n+e/WvLy8Bx988JNPPhk9erSlZUCnkEgkROTs7Mw6/UL3JZFIJBIJPmBFh68r3ZFwgbCystLd\n3d34VeLp6VlRUdEpx168ePGjjz4yXFy1alVQUFBnVN29SaVS9jUFujsnJyexS4BOg3dlV1Bc\nXExE4eHhVjwdbm5u/fv3v3DhwtSpU1evXm14e8bFxW3fvr2kpOS2224z81QpKSlXrlz58ccf\nJ06caGkZ0IlcXV3FLgE6Bz5gRafT6cQuASwm6KQyzX4zsOjXONPH9u/ff8GCBYaLvXr1qq6u\ntqpGO8FxnKura1NTU11dndi1QEc5Ozs3NTXhE9YOsC+dNTU1YhcCdPXqVYVC4eTkZN0fi+XL\nl+fl5T399NMNDQ0NDQ1sY1RU1Pbt25OTk82f84yNOTx8+LCD/80SkUKhkMlkNTU1aCHs7iQS\nibOzM772iI7jODbhFnQjwj1hKpWqsrKS53lDtKuoqPDy8uqUY/39/R9++GHDxYqKivr6+s6r\nvfsxBEIHfxzsg1Qq1el0hi+d0H0plUoiwruyK7h27VqvXr2sflslJSWNGjWqWbaPjIwkolOn\nTo0ZM8bM81y4cIGICgsLc3JyWs6mBgKQy+VE1NDQgJnqujupVOrk5IQPWNGhT1N3JNykMv36\n9dNqtTk5OexiRUVFYWFhRESErY8FAAAw1tjYWF5ebsWaE6ZFR0eThRONZmdns/+cOHGic4sB\nAAAwk3CB0MvLa8SIEV988UVOTk5hYeGnn34aFhY2YMAAItq3b9/OnTvZbuXl5aWlpVVVVURU\nWlpaWlpaX19v4lgAAACLFBUV8Txv3RSjJvTu3dvHx8f8QNjY2Jifn8/mwDCeFw0AAEBIgvbx\nnT179tq1a9955x29Xh8bGzt37lzWBfTMmTOVlZUPPPAAEc2bN4+N9Sei559/noimT5/+4IMP\ntnUsAACARdgihP7+/p1+5ujo6IMHD5aUlPTs2bPdna9cuaLVaseNG/fbb78hEAIAgFgEDYRK\npXLOnDlz5sxptn3evHmG/3/11VcWHQsAAGARjUZDRJ3eZZRuBcLMzMw777yz3Z1Zf9EBAwYU\nFxcfP368rKzMwRdMAgAAUQjXZRQAAKArsGkgJLOHEbKB8eHh4YmJiTzPp6SkdHo9AAAA7UIg\nBAAAx2K7QDhw4ECyMBCGhYUNHz6cMIwQAABEgnVCAADAsdguEIaGhrq6upoZCLOzs6VS6W23\n3danTx+pVIpACAAAokALIQAAOBbbBUKJRBIVFXXlypVmSxS26vLly8HBwXK53N3dPSoqKj09\nHWtqAwCA8BAIAQDAsajVak9PT6VSaYuTR0dH6/X68+fPm95No9FUVFSEh4ezi4mJiVqtNi0t\nzRYlAQAAmIBACAAAjkWj0diieZBhwwgzMjJM78amGDUEQjaMEMvTAwCA8BAIAQDAgdTU1FRX\nV9suEJo50SgLhGFhYezisGHDCPPKAACAGBAIAQDAgbBV6Xv37m2j80dFRTk5OWVmZprezbDm\nBLvo6+sbEhKSkpKi0+lsVBgAAECrEAgBAMCBsEBouxZCuVweFhaWlZWl1WpN7GZYc8KwJTEx\nsaampt0kCQAA0LkQCAEAwIGwKUb9/PxsdxODBg1qbGxknULbkp2d7ePj4+3tbdiCYYQAACAK\nBEIAAHAgtltzwqDdeWXq6uquX79u6C/KYBghAACIAoEQAAAciACBkM0rY6LzZ3Z2tl6vbxYI\nb7vtNj8/v+TkZJ7nbVcbAABAMwiEAADgQIRpIeQ4zsREo82mGDUYOnTojRs3Ll++bLvaAAAA\nmkEgBAAAB6JWqyUSia+vr+1uwtPTMzAw8OzZs2219TWbYtQAwwgBAEB4CIQAAOBANBqNj4+P\nXC636a1ER0dXVVUVFBS0em2zVekNMIwQAACEh0AIAACOguf54uJim/YXZUwvT5+dnS2XywMD\nA5ttHzBggIeHR3Jysq3LAwAAMEAgBAAAR1FeXt7Q0CBuINTr9bm5uaGhoVKptNlVUqk0Li4u\nPz//+vXrtq4QAACAQSAEAABHwWaU6d27t61viK080WogLCwsrK+vb9lflGG9RlNSUmxaHgAA\ngAECIQAAOAoBVqVn/P39fXx8Wl15gs0o03KKUYYFQswrAwAAgkEgBAAAR6FWq0mQFkIiio6O\nVqvVJSUlzbZfunSJWptRhunbty/dCq4AAAACQCAEAABHUVRURIK0EBJRbGwsEf3666/Ntre1\n5gSjUqmI6ObNmzauDgAA4L8QCAEAwFEI2UI4adIkuVy+dOnS+vp64+3Z2dkcx7XVZVSpVMrl\ncgRCAAAQDAIhAAA4CsEmlSGigICAKVOmaDSaDRs2GG/Pzs729/d3dXVt60CVSoVACAAAgkEg\nBAAAR6FWq52cnLy9vYW5uddff93Nze2zzz6rrq5mW8rLy0tLS9vqL8p4eXkhEAIAgGAQCAEA\nwFFoNBo/Pz+JRKC/fT4+Pi+88EJZWdmaNWvYFtNTjDKenp7V1dU6nU6IEgEAwOEhEAIAgENo\namoqLS0VYFV6Y7Nnz/by8lq5cmV5eTkRZWdnU3uB0MvLi+f5iooKgUoEAADHhkAIAAAOobi4\nuKmpSeBA6OHh8fLLL1dWVq5cuZLam2KUwUSjAAAgJARCAABwCGyKUYEDIRHNmDHD19d39erV\narWatRCaEwhZiyIAAICtIRACAIBDYK1zgYGBAt+uUql87bXX6uvrP//88+zsbDc3N9OhlAVC\ndBkFAABhIBACAIBDOHnyJBHFx8cLf9OTJk0KDAz89ttv8/Pzw8PDOY4zsTNaCAEAQEgIhAAA\n4BBOnDghl8sHDx4s/E3L5fK//vWvjY2NOp3OdH9RwhhCAAAQFgIhAADYv4qKikuXLg0ePFgu\nl4tSwBNPPMGioOkpRgmBEAAAhIVACAAA9i81NVWv1yckJIhVgFQqXbhwoYuLy4gRI0zviUAI\nAABCkoldAAAAgM0dP36ciBITE0WsYezYsQUFBe3uhkllAABASGghBAAA+5eSksJx3NChQ8Uu\npH1eXl6ESWUAAEAoCIQAAGDntFrtqVOnQkNDfXx8xK6lfZ6enhzHIRACAIAwEAgBAMDOZWZm\n1tXViTiA0CIymczV1RVdRgEAQBgIhAAAYOfYCoTiDiC0iJeXF1oIAQBAGAiEAABg506cOEFE\n3aWFkIg8PT0xyygAAAgDgRAAAOxcamqqt7d3aGio2IWYy8vLq7Gxsa6uTuxCAADA/iEQAgCA\nPSsoKFCr1UOHDuU4TuxazMVWnkCvUQAAEAACIQAA2LNu11+UsBQhAAAICIEQAADsWbebUYaw\nFCEAAAgIgRAAAOzZyZMn5XJ5TEyM2IVYwNPTk4gwrwwAAAhAJnYBAAAAtlJVVXXx4sUhQ4Yo\nFAqxa7EA6zKKQAgA7bpwwdXw/4iIGhErge4LgRAAAOxWampqU1NT9xpASLe6jCIQAkAzxvEP\noLMgEAIAgN3qjjPKELqMAsAtSIAgAPsMhFKpVOwSRMZmV5dIJE5OTmLXAh0lkUikUimeSvvA\ncRyeSiGlpKQQ0bBhwzr3YZdKpTb9gO3ZsycRVVZW4tVia+zPpUwm43le7FqgQyQSid18wJ49\nK7fuwK5w9/ElvDuyz0Aok8lkMvu8a2YyBEJnZ2exa4GOYl89JRJMAdXtsTcm3pWC0el0p06d\nCg0NDQoK6twzS6VSjuNs91T6+voSUWVlJV4ttsY+Wp2dnREIuzuO47r1157U1E54BXbfuw/i\nss/U1NDQoNVqxa5CTOybik6nq66uFrsW6ChXV1edTtfQ0CB2IdBRcrmciPCuFEx6enp1dfX4\n8eM7/TF3dnaWyWQ1Nbaav4G9VEpLS/FqsTUPDw+pVFpTU6PX68WuBTpEKpW6ubl1r7dMp3cH\n7Qp338nJqXtN4gVkr4EQAACArUDY7QYQEpGbm5tMJsM6hAD2B2MCoQtCIAQAAPvUfQMhx3Ee\nHh6YVAbAbiAHQleGQAgAAPYpJSVFpVKFh4eLXYg1vLy8bty4IXYVANAhyIHQLSAQAgCAHbp6\n9eq1a9dGjx7dTSdkUqlUV65c0ev13bR+AEeGHAjdCwIhAADYodTUVOqe/UUZlUql1+srKytV\nKpXYtQCAWZADoZtCIAQAADuUl5dHRP379xe7ECt5eXkR0c2bNxEIAbo45EDo7hAIAQDADhUV\nFRFRr169xC7ESiwHYl4ZgK4MURDsAwIhAADYIbVaTUS9e/cWuxArsUCIlScAuiDkQLAzCIQA\nAGCH1Gq1VCrt2bOn2IVYiQXCiooKsQsBgP8PURDsEgIhAADYIY1G4+vrK5VKxS7ESp6enoQW\nQoAuA1EQ7BgCIQAA2Bu9Xl9cXBwdHS12IdZjk8qghRBAdIiCYPcQCAEAwN6UlJTodLruO4CQ\nMKkMQBeAKAgOAoEQAADsjUajoe48xShhUhkAUSEKgkNBIAQAAHvT3acYJUwqAyASREFwQBKx\nCwAAAOhkLBB26xZCNoYQLYQAQkIaBMeEFkIAALA3dtBlVC6Xu7i4YAwhgDAQBcGRIRACAIC9\nsYNASEQqlQqBEMDWEAUB0GUUAADsjR2MISQilUqFLqMANoU0CEBoIQQAAPuj0WgUCgVb2737\nUqlUdXV1jY2Ncrlc7FoA7A2iIIABWggBAMDeaDSa7t48SLfmlUGvUYBOhzQIYAyBEAAA7EpD\nQ8PNmzftIBCyFk70GgXoRBcuuCINAjSDQAgAAHZFrVbzPG8HgZC1EGIpQoDOgigI0CoEQgAA\nsCv2McUo3VqbHi2EAJ0CaRCgLZhUBgAA7IodrErPsECIMYQAHYQoCGAaWggBAMCusBZCO+gy\nikAI0HFIgwDtQiAEAAC7Yh+LEBICIUCHIQ0CmAOBEAAA7IqdjSFEIASwDtIggJkwhhAAAOyK\nWq3mOM7Pz0/sQjoK6xACWAdREMAiaCEEAADLVFVV/f777zzPi11I64qKiry8vJydncUupKPY\nOoQIhAAWQRoEsBQCIQAAWIDn+ZkzZz711FO7du0Su5bWaTQaO+gvSkQeHh4SiQSBEMB8SIMA\nVkAgBAAAC6xbt27fvn1EtGbNGrFracXNmzfr6ursIxBKpVIPDw8EQgAznTihE7sEgG4JgRAA\nAMyVlZX17rvvqlSqmJiY48ePZ2Zmil1Rc3YzxSjj6emJhekBzHHunELsEgC6KwRCAAAwS2Nj\n44svvtjQ0PDxxx+//vrrRLR27Vqxi2rObhYhZLy8vCoqKrrscE2ALgI9RQE6AoEQAADM8o9/\n/OP8+fPPPPPMxIkTx4wZExQUtG3bttLSUrHr+h+shdA+uowSkUql0ul01dXVYhcC0HUhDQJ0\nEAIhAAC0b//+/evWrQsJCfnggw+ISCqVTpkypbGx8fvvvxe7tP9hZy2EWIoQwDSkQYCOQyAE\nAIB2lJaWvvLKKzKZ7Msvv3Rzc2Mbn3vuOaVSuX79ep2uC03kYGdjCBEIAUxAGgToFAiEAABg\nCs/zr776anFx8VtvvRUXF2fYrlKpHn744atXr/72228iltcMayG0py6jhEAI0BqkQYDOgkAI\nAACmfPPNN/v27Rs1atSsWbOaXTV9+nQi+uqrr8Soq3UajcbJycnHx0fsQjoHAiFAq5AGAToR\nAiEAAJhy5MgRIlq8eLFE0vxPxoABA5KSko4dO5aVlSVGaa3QaDS+vr4tS+2mvLy8qPMCYWZm\n5muvvVZTU9MpZwMQC9IgQOeykz+ZAABgI5WVldT2qDzWSNhF1p/Q6XQlJSV201+UiDw9Panz\nAuGXX365adOmAwcOdMrZAESBNAjQ6RAIAQDAlJs3b0qlUsNcMs2MGzcuMDBw69atZWVlAhfW\nUnFxcVNTk93MKEOd3UKYnJxMRKmpqZ1yNgAAsA8IhAAAYEplZaWHhwfHca1eK5VKJ02aVF9f\n/8MPPwhcWEt2NsUodeoYwuvXrxcWFhICIXRnaB4EsAUEQgAAMKWiosLDw8PEDpMmTVIoFOvW\nrWtqahKsqlbZ2RSjdCsQlpeXd/xUrHmQiM6cOdPY2NjxEwIIDGkQwEYQCAEAwBTWQmhiB29v\n74kTJxYWFoo+OI0FQj8/P3HL6EQsEFZUVHT8VCdOnCCifv36NTQ0nDt3ruMnBBAS0iCA7SAQ\nAgBAmxoaGhobG9nUJiaMGTOGiDIzMwUpqk0sENpTl1GlUimXyzulhfD48ePOzs7PP/88odco\ndDdIgwA2hUAIAABtYm1TplsIiahv375ElJeXZ/uKTLG/LqNEpFKpOj6GsLy8/MKFC7GxsSNG\njCAEwg6rqan55JNPrl69KnYhDgFpEMDWZGIXAAAAXZeZgTAoKIiICgoKhKipbfbXQkhEKpWK\nTZbTESdOnOB5ftiwYf369fPw8EAg7KA9e/YsWbJky5Ytu3fv7tGjh9jlgCP6z38aWm6MiBC+\nELAHCIQAANAm1jbFRrKZ4O7u7uXllZ+fL0hRbbp+/bqbm5u7u7u4ZXQulUqVnZ2t0+lkMuv/\nZB8/fpyIkpKSJBJJXFzcgQMHiouLfX19O69Mx5Kenk5Eubm5jzzyyC+//NJun2qwGpoHmVbj\nH0BnETQQVldXr1mzJiUlRafTDRw48KWXXmr516itfV599VXjzkgKhWLLli1CFg8A4ICqq6uJ\nyJyIFRwcnJmZ2cHc0kFFRUV21l+UiFQqFc/zFRUVPj4+Vp/kxIkTUqk0Pj6eiOLj4w8cOJCa\nmjpu3LjOK9OxZGRkcBw3fvz4nTt3Tpky5d///rdcLhe7KDvkyGkQCRCEJOif7eXLl5eWli5a\ntEihUGzYsOH999//5z//KZFIzNmnurp6xowZw4YNY7s1OwoAAGzBzBZCIgoKCjpz5oxarQ4M\nDLR9Xa2ora2tqKgYNGiQKLduO4a16a0OhHV1dRkZGQMGDGDBnsVCBEKr6fX6s2fPhoSErF27\ndtq0abt37542bdr69etF/CnELjlaGkQCBBEJF6tKS0tPnjz56quvhoWFBQQEzJ0799q1a6zT\nhTn7VFVV9erVq8ct3t7eglUOAOCwzBxDSETBwcEk6rwy9rcqPcO6I3ZkotHU1NTGxkbDL6px\ncXESiQTDCK2Wm5tbXV0dExMjlUr/9a9/JSYm/vbbb/Pnzxe7LrviCGnwP/9pMP4ndjng0IT7\nNSs7O1sul4eEhLCLbm5ugYGB2dnZsbGx7e4zcODAhoaG5OTkjRs31tTUhIaGTp061d/f33Cg\nTqerra01XNTr9RzHCXK3uijD3Xfwx8E+TJgwISwsbNGiRWIXAp2je70rWZdRDw+PdstmE40W\nFBSIdQeLi4uJyM/PT4ACuFtsfUN0q4WwoqLC6ptjAwiHDRvGzqBSqcLCws6cOaPT6ZycnDqx\n1O7LomeTLa8yaNAgjuNcXFw2bdr0wAMPfPPNNz179nzrrbdsWSZ0e7YOfl3h70tXqAEsJVwg\nrKysdHd3N36VeHp6Nltst619amtrVSpVbW3trFmzJBLJDz/88NZbb61atcrV9b8/IB05cmTe\nvHmGo1atWpWQkGDjO9QNyOXyjow5ga6gpKRk3759KSkpK1euxIesfehe78rGxkYiCgwMbLfs\ngQMHElFJSYlYd7CqqoqIwsLCBCtAoVAIcCt9+vQhIp1OZ/X9OnXqFBGNGzfOcIYRI0asX7/+\n2rVrcXFxnVVnt8ZSt5kuXrxIRCNHjmSPp4+Pz++//z5ixIhPPvlk8ODBzz77rK2qdBhHj9aJ\nXUKnEbjpryv8fdHpdGKXABYTtL97s6+zPM+buY+np+c333xj2Dh//vzJkycfPXqULYVMRN7e\n3sYJUKlUarXaTqy8O3JycuJ5Hm/L7i4tLY2Ibt68mZmZGYH5pLs5mUzGcVz3+nQqKysjIjc3\nt3bLZkMHc3JyxLqDbNELPz8/AQqQSCQcxzU1Ndn6huhWl9HS0lLr7pdWq01OTg4PD/f29jac\nISEhYf369UePHrW/IZeWkkqlEonEosc2LS2N47jo6GjDUb6+vlu2bElMTNy+ffsTTzxhm0od\nxYkT9vC9RawuoF3h74ter8d42m5HuCdMpVJVVlbyPG+IfBUVFc1+kzNnHyJSKBQ9evS4ceOG\nYUtMTMyqVasMFysqKpq1PToajuN8fHy0Wm1lZaXYtUCHnDhxgv3n0KFD9jc4ytF4e3uz6SLF\nLsQCJSUlRCSVStst29PTUyKR5ObminUHr1y5Qq31PbEFZ2dnmUxWU1Nj6xsiIjZ9pVqttu5+\nnTp1qqamJiEhwfjwAQMGENHRo0efeeaZzqqzm/Lw8JDL5VVVVXq93pz9eZ4/ffp0YGBgszdF\n3759XVxcsrKyutcbvEvqrqMHu8I4wK7w8nNycnJ2dha7CrCMcJPK9OvXT6vV5uTksIsVFRWF\nhYXNWjza2ic/P3/FihWGnz3q6uqKi4vx5Rgcwblz59h/WFMhgMDMn1RGLpf36tVLxEll2Kr0\ndrnsBN2a7tUKhgGExhv79+/v4eGRkpLS8fIcTX5+/s2bN2NiYpptl0gkoaGhubm56JjTEd1u\nLhnMCgP2QbhA6OXlNWLEiC+++CInJ6ewsPDTTz8NCwtjP1Lu27dv586dJvbx9vZOTk5euXKl\nRqO5du3a8uXLPTw8hg8fLljxAGI5f/68s7OzXC7HlIAgisrKSo7jzFzqPTg4uLS01HiKLyFp\nNBqJRGJ/i62zQGj1D/+tBkKJRBIbG5ufn19aWtrxCh1KRkYGEbXa1bZfv36NjY0i/iYCgkEI\nBDsj6Gp+s2fPDg0Nfeedd9544w2FQvH222+zrqFnzpw5efKkiX3c3d3fe++9GzduzJ079803\n3ySijz76SJjR/AAiamxszM7OjoiIiI6OzsrKEqZ/GoCxyspKNzc3qVRqzs7BwcE8zxcWFtq6\nqlap1WofHx/7Wx+cjZuwbtkJnudPnjzp5+fH5oA1ZliNsMMFOha2FFbLFkIiCg8PJ6Ls7Gyh\na7IXXb95EDkQ7JWggz6VSuWcOXPmzJnTbLvxBKFt7YNp98EBZWdnNzY2RkdHu7q6pqWlZWRk\noGEcBFZZWWlOf1EmKCiIiPLz8/v372/LolrB83xRUZHwtysANjjTeNi8+S5dunTjxo2HHnqo\n5VWGQDh27NiOluhIzp49S0TR0dEtr+rXrx8RXbp06b777hO6rO6vK6dBJECwe4K2EAKARQyr\nXQ0dOpTwWz6I4ebNm2yWS3OwQMhm+xRYWVlZY2OjXY4tl8lk3t7eRUVFVhzban9RJi4ujuM4\nfKpYKj09PSAgoEePHi2vYi2EhnkQoLtDeyA4DkwLC9B1sRlloqOj/f396dZiYgCC0Wq1dXV1\n5gfC4OBgIsrPz7dlUa1Tq9VEZJeBkIj8/Pyys7ONp+A2EwuErfYs8PLyCg0NPX36tE6nwxzx\nZiosLCwrK2s1YBNRaGioVCpFl1ErdLXmQYRAcDRoIQToulggHDhwYEhISI8ePfBbPgiMrVtj\naSAUpYXQXqcYZfz8/BobG62YaPT48eMeHh5t9aSNj4+vra3NysrqcIGOgg0gbGvxRrlcHhQU\ndOnSpVaXWYauD02C4LAQCAG6rvPnz/v7+/v4+BDRkCFD2Cy7YhcFDsT8NSeYXr16OTs7o4Ww\n0/n5+RGRpb1Gr127dvXq1cTExLbmBGLDCLH4hPlMTDHKhIeHV1VVWde/12F1heZB5EBwcAiE\nAF1UUVFRaWlpVFQUuxgXF0foNQrCYi2E5gdCjuMCAwNFCYSshZAFJ/tjXSBMTk6mNgYQMiwQ\nYo1T87EZZUwEQsO8MsLVBB2DKAhACIQAXRbrL8rW6iSiIUOGEL66gbAsDYREFBQUVF1dXVZW\nZrOiWnf16lUi6tOnj8C3KwzrAqGJGWWYiIgINzc3tBCaLyMjw8/Pz8TvDiwQYhih+cRqHkTv\nUABjCIQAXVTLQCiRSDCMEIRkRSAUa14ZtvhhYGCgwLcrDDY20tJAmJKSIpfLBw8e3NYOUqk0\nNjY2Ly/PujUtHI1arS4uLjbRPEhEYWFhhEDYtSEHArSEQAjQRTULhB4eHuHh4RkZGVqtVtS6\nwIGwMYTmTypD4q08UVhY6OXl5ebmJvDtCsOKFsLq6uqLFy8OGjRILpeb2C0+Pp7neXQ9MEe7\nAwgJa9N3bYiCAG1BIAToos6dO6dQKEJDQw1bhgwZUldXhykBQTCWTipDRH379iXBWwj1ev31\n69fttXmQiHx9fcnCQHjmzJmmpiY29tiEmJgYujU0DkxjgZA9Ym1RqVS+vr4YQ2gmwfqLIgoC\nmIZACNAVNTY25uTkREZGGk8PyL7bodcoCMaKFkKWygRuIVSr1Y2Njaxx0i5Z0WWUjQxk08aY\nwPognD9/vgPVOQq25oTpQEhE4eHhGo2GdbcG0SEKApgDgRCgK8rKytLpdIb+ogz7boeJRkEw\nlq5DSCItRchmlAkICBDyRoXk7Ozs6elpUSBkvUDbbSEMDg52d3dHIDRH2LJOXwAAIABJREFU\nenq6t7e3v7+/6d3YvDI5OTmCFNWNCdA8iCgIYCYEQoCuqNkAQiYiIsLV1RWjfUAwVgRClUrl\n6ekpcJdRlj/tuMsoEfn5+VkUCE+dOuXn59fuY8JxXERERG5ubm1tbccKtHMlJSUajcbEDD0G\nbBgheo2KCw2DABZBIAToiloNhFKpdPDgwZcvXxZ+Tn9wTFaMISSiwMDAwsLCpqYm2xTVCtZC\naPeBsKampqamxpyd8/LySkpK2u0vykRFRen1+osXL3asQDtnZn9RujXRKFoIxYIoCGAFBEKA\nrujcuXMcx0VGRjbbHhcXx/P8mTNnRKkKHA0LhO7u7hYd1bdvX61Wy1aKF4Z9rznBWDTRKBtp\n3G5/UYZ9zrAfoaAtLBCanmKUwVKE5rBFf1FEQQCrIRACdEXnz58PCAhQqVTNtmN5ehBSZWWl\ni4uL6XULWmKTu7TsNVpRUTF8+PA1a9Z0Wn232P0YQrIwELKRxmYGwoEDBxLmlWkPm4jVnEDo\n7+/v5uaGLqMCQxQE6AgEQoAu59q1a+Xl5VFRUS2vYn3AMNEoCKOqqsrS/qLU9lKEP//8c05O\nzo4dOzqnOCMFBQUeHh4tf0CxJxYFwrS0NJlMZs6ANyKKjIzkOA6B0LSMjAwvLy9zWqE5jgsL\nC8vLy2tsbBSgsO6oc5sH0TAI0HEIhABdDvtm1mwAIePn5xcQEHD69Gme5wWvCxxORUWFRTPK\nMG0tRbh161YiysjIaGgw9e2toKDAoklKeZ6/evWqfTcPkiWBsKGhITMzMyIiQqlUmnNmDw+P\ngIAABEITysrKCgsLBw0axHGcOfv369dPp9NduXLF1oUBoiBAp0AgBOhy2GAe1o+rpSFDhpSX\nl+fm5gpbFDgcvV5fXV1tRSBstYWwsLDwxIkTRNTY2MgW+G7LxIkTH3roIfN/8iguLm5oaLDj\nRQgZ8wNhRkZGY2OjmTPKMFFRUeXl5devX7e+PrvGXrHm9Bdl2ESjGEZoU2gYBOhECIQAXU5m\nZiYRtdpllNBrFIRSVVWl1+ut6DIaGBjIcVxeXp7xxh9//JHn+aFDh5LJV29ubm5BQUFhYaH5\n622yGWXQQmhg0YwyDPu0QSNhW9hDGhsba+b+CIQmdEp/UURBgM6FQAggmqampg0bNrCvs8bO\nnz+vVCpDQkJaPYp9z8Py9GBrbBFCKwKhQqHw8/Nr1kK4bds2uVz+3nvvEVFKSkpbxyYnJ7P/\n/Prrr2beHHsHoYXQgKUXi1oIWQd1TDTaloMHD0okkqSkJDP3x1KENoU0CNDpEAgBRPP999/P\nmzdv3LhxxitW1dXV5ebmRkVFSSStvz0HDRrk5OSUnJys1+uFqhQcEVtzwoouo0QUFBRUVFRk\nGCt49uzZixcv3nXXXfHx8d7e3iamyf3zzz+JiOO4PXv2mHlbjrDmBBG5u7srlUpzAuGpU6e8\nvLxCQ0PNPzlrIczKyrK+vm5izZo1CxcutOiQysrKtLS06OhoHx8fMw8JCQlxcnJCC2GnQzdR\nABtBIAQQR319/dKlS2UymUajeeihhwy/JWdlZTU1NbXVX5SIFArFyJEjs7KyZs+erdPphKoX\nHE5HAmFwcDDP84ZGQjadzKOPPspxXFxc3PXr169du9bqgcnJyZ6ennfddVd2draZ36cdpMso\nEfn5+bUbCDUazdWrV4cMGWLm9CfMbbfdplAoHKHL6Ndff/3ll1+27JdhwtGjR3U63Z133mn+\nIU5OTn379s3JycHsX50IURDAdhAIAcSxZs0atVo9Y8aM999/v6ioaMKECeznedMzyhiOjYuL\n27p165QpUzCzOdgIC4RWdBmlWx042dduvV7/008/ubu7jxkzhm51ZWy1kbCwsLCwsDAxMXH8\n+PFEtHv3bnNuy0G6jBKRr6/vzZs3Tc/RakV/USKSSqURERHZ2dl2/3miVquJ6I8//jD/kAMH\nDhCRRYGQiMLDw2tqajBPTzNWDyBEGgSwKQRCABFUVFSsWLHC3d19zpw5L7300qJFi27cuDFx\n4sTz58+bWHPCQKVSbdmyZejQoXv37p0yZYrpL4gA1rF6DCERBQcHExGbV+bIkSNqtXr8+PEK\nhYJuZZVWhxEeO3aMiIYPHz527FipVGrmMMKrV6+6urp6e3tbUWf34ufnx/N8cXGxiX1Y0rZo\nRhkmKipKp9PZ97C3ysrK2tpaIvr999/NP+rgwYOurq6WZux+/fpRNxlGeODAga48Sxm6iUKn\nGzZsWEREhNhVdC0IhMLJy8s7e/as2FVAl/DFF1+Ul5fPnj2bfYt98cUXP/roo7KysokTJ+7f\nv5/juMjISNNn8PDw2Lp16+23375v376nn36afcsB6EQsEFrdZZRurTyxbds2Inr00UfZVUOG\nDJFKpa22ELIZZYYPH96jR4+hQ4eePn2ateeYVlhYaPcDCBk2r4xGozGxT2pqKsdxQ4YMsfTk\njjCvjOHldOTIETN/R8vLy8vLyxsxYoRcLrfotsLCwqg7TDT6n//858knn5w5c6bYhbQOURBs\n4cknn5w8ebLYVXQtCITCef755ydMmIDGHNBoNGvWrOnZs6fx3+Dp06cvWbKELTAYFBTk7u7e\n7nlcXV2///77e+655/Dhw4899hj7+g7QWTreZTQ/P7++vn7Xrl29e/ceOXIku8rNza1///7p\n6ekteyf++eefrq6uMTExRDRu3Die59ttJLxx40Ztba0jDCAkMyYa1Wq16enp4eHhVsR49iOU\nfQ8jZFlaJpPV1tay6YvatX//frK8vyjdaiHs4oHw4sWLL774ol6vLygouHLliq1vztL+okiD\n0OnY3525c+e+9dZbYtfStSAQCqSsrCwzM7Oqqur48eNi1wIiW7ZsWV1d3RtvvOHq+j9/HZ9/\n/vlly5ZJJBLzV7tSKBQbN24cP378yZMnH3/8ccw7Cp2oI11Ge/fuLZfL8/Pzf/vtt+rq6ocf\nfth41tz4+PiWy9Or1eq8vLyEhASZTEZE48aNIzMWn2CNkI4wgJDMCIRZWVl1dXVW9BelWy2E\n9h0IWQvh3XffTUT79u0z55CDBw8S0R133GHpbYWHh3McZ7suo01NTadPn+7IpDXl5eXPPvts\nVVUVW07j8OHDnVddJ0AahGbUavULL7wQHBysUCh69er1yCOPXLhwwXDtsWPHRo8e7eHh4eLi\nEhsb+/XXXxuuSkpKuuOOO/bs2RMYGDhixAhq0WXUxLGmb9SeIBAKJDk5mX1ws78u4LAuX778\n/fffBwcHP/fccy2vnTRp0h9//PF///d/5p9QLpevXbt26NChaWlppgcXAVikI7OMSqXSPn36\nFBQUsPlFH3vsMeNrW12enrXYGJZ6Cw4OjoqKOnbsGCujLVevXiXHmGKUbgVCE29z62aUYby9\nvXv16mXfXUZZC+Ejjzzi4uJizjBCrVZ79OjRwMBA1v/TIm5ubr1797ZdC+HXX3997733WjQY\n0phOp5s2bVpeXt7LL7+8ZMkSIjpy5EinFtghSIPQ0sMPP7xr166FCxfu2bNn2bJlly5d+stf\n/sLGyxw8ePDOO+/UarWbNm365Zdfhg0bNm3atGXLlrED5XJ5eXn53/72tzfeeKPlqjOmjzVx\no3ZGJnYBjsKw2vKBAwf+8Y9/iFsMiGjx4sVarfatt95qa0SK6flFWyWTyQYOHJiSklJUVNSr\nV68O1whARFRVVUXWthASUXBw8JUrV/bv3x8ZGdlskiTWhNUsEBoGEBq2jBs3btmyZfv27TOM\nP2zJoVoI2bvbRAuh1TPKMFFRUfv37y8pKenZs6d1Z+jiWCAMCQkZOXLkvn37Ll++bHq1xrS0\ntKqqqokTJ1p3c+Hh4YcOHSovL/fy8rLuDCZs2bKFiLKyskaPHm3F4e+8886RI0fuvvvuhQsX\nSiSSnj17Hj16VK/Xt7X+rZCQBqGlysrK48ePz58/f9q0aWzLiBEjNm/efPPmTaVS+de//jUg\nIGDv3r3Ozs5ENHr06OvXr3/wwQezZs1ycXGRyWQZGRnbt29v9b1s4litVmviRoW66wIR/53v\nIJKTk52cnAYNGnT+/PmSkhKxywFxpKen//LLLwMHDrT6G0ZbzJltAsAiHWkhpFshTafTPfLI\nI82uCgsL8/LyatlCqFAojPtLs16jpleod8AWQhOBMDU11dXV1erZ8+x+Xhn2CdmrV6977rmH\nzJhr1LoFJwzCw8OJKCcnx7rDTcjNzT1z5gz7jxWHb9y4cd26deHh4WvWrJFKpRzH3X777Tdu\n3LBph2EzBxAiDUKrlEpljx49Nm/e/Mcff7DRMSEhIW+99Za/v39paWlaWtrYsWN5nq+/Zdy4\ncRUVFYbZy2Qy2QMPPNDytKaPNXGjQt53YSAQCqGysvLcuXMxMTFsmgT0GnVYixYt4vn/x96Z\nxzdR5///PTkmzdErvU9Kaemx9KAc5Vag3MihiCK4CuoXFvcr7ldRF9djvWXXY1dWVnFlFVZk\nF1YELJdU5KaltOWGQk96t2mbXjlnfn98lvyyaZumySSZtO/ngz/ayczk09Am85r36/16s6+8\n8grnd2H7vFJEkP7S0tJC07RUKrXvcCIIKYq6//77LR4iMZhVVVWmKW2NjY23bt0aM2aMeeU8\nJSUlOjo6JyfHShbXoKoQ+vv70zTd25+5SqUqLS0lIa72nT85ORkGdBthdXW1SCQKCgoigrDP\naYTHjh0TCoWk6cgOnBc0+u9//5t8YUcSzLlz5zZs2ODn57d9+3ZT/X/KlCnAA9coqkGkN0Qi\nUXZ2NkVRWVlZQUFBDz300I4dO4xGI9wdRbt582apGWvWrAGAqqoqcnhQUBDpTrfA+rFWnnTg\ngYLQFeTm5hqNxvHjx5MbjSgIByd5eXk///zzhAkTpk2bxvnJURAinKNWq+32i8LdyRPjx4/v\ncSYEaSM03b49ffo0y7LmflHC7NmzOzo6fv75596epbKy0svLKzAw0O51ehAURQUHB/f2Z37h\nwgWWZe32i8LdCuG1a9fsPgPPqa2tDQoKEgqF0dHRCQkJp06dstILpFKpioqKMjIy7DZ8Om8U\n4ffff0/TtL+//+3bt/t1oFarfeyxxxiG2bJlS2xsrGk7EYTuzZVBNYhYZ8yYMbdu3crJyXny\nySevXbv2yCOPTJkyRavVUhQFACtXrjzTDZIgBQC9Nen0eWxvT+qqH9p1oCB0BSQsYfz48Wlp\naf7+/seOHXMkGQzxUIjD55FHHnHGyftsLkKQ/tLW1uaIIBw7dmxSUtLatWt7fNSijZA0EJoS\nZUz06Rq9c+dOZGQk+VAfDAQHBzc1NRkMhu4PkRfTEUE4bNgwmqYHqmXUaDQ2NDSEhYWRb7Oy\nsnQ6nRUJdOLECaPRaEe+qAliGbXP1WmFa9euXb9+/d57701OTq6vr+/o6LD92JKSkqampkWL\nFln8XFFRUUOGDDlz5oxer+d2tYQ+/aKoBhFbEAqFU6dOff/99y9evPjXv/719OnTO3fuJA4R\nhmHGdaPPe4W2HNvjkzr7J3U9KAhdwZkzZ4RC4dixY4VC4eTJk+vr6wfwLVikN4i3jZRNOAd7\nCBFuYVlWrVbb3UAIAOHh4cePH581a1aPj44aNUogEOTl5ZFvT506RdN0dzEzbtw4pVJ56NCh\nHl06zc3NbW1tg2QqPSEkJMRoNDY2NnZ/yMFEGQCgaTo+Pv7GjRs9Cs4+4fmNzoaGBoPBYIrd\n6rON0MEGQgBQKpUA0NLSYvcZeoT4RRcvXjx06FCWZfvlGi0vL4e7XlYLpkyZ0tHRceHCBa7W\naTuoBpE+OX/+/MMPP2yesUzilOrr65VK5dixY/fs2WP+t/b111//7ne/6/OtzPqxVp6Uq5+L\nP6AgdDqdnZ1FRUXJycnk0op8upBPGmRQQazqTmp2CggIEIlEWCFEuKKjo8NgMDgiCK3j7e2d\nkJBw8eJFnU6nUqlu3LiRkZHh5eVlsZtQKJw5c2ZjY6NJOppDEmUGmyCEnrwADMNcuHAhOjra\nwYDQ5ORknU5nSw5KcXHxzp07//jHPz7zzDP333//6NGjIyIili5d6sizOxVyv8xUIczMzPT2\n9rYiCI8dO+br62v7VNju0DRN03S/Knh9wrLsd999J5VK58yZQzyf/apAlpWVQS/3JXnSRogg\nPRIREXHw4MEZM2Z8+eWXR44c2bFjx4oVKyQSCYmK2bhxY2dn5+TJk7dt23b48OFXXnnlySef\nJD3DfZ7ZyrHWn3SAgYLQ6eTl5en1elNvzD333APYRjgoKS8vp2naSWMhhEJhYGAgCkKEK8hU\nem9vb+c9xejRo7Va7aVLl86ePcswTPcGQoIV1yipuqMgBICbN2+q1Wr7JhCaY2OuTFtbW1ZW\n1q9//ev3339/x44dJ06caGtrk8vlP/30E28dp2QqvekdWCwW33PPPVVVVZcvX+6+882bN6uq\nqiZPnmzLBaUVFApFe3u7I2ewoKCgoLy8fMaMGXK53A5BSCqEMTEx3R+aNGkSRVGubyPE8iBi\nC2FhYcePH4+Pj3/55Zfnz5//3HPPBQcHHz9+PCEhAQDuueeenJycsLCwp59+euHChbt3737j\njTe2bNliy5mtHGv9SQcYOIfQ6Vj0xpARt2fOnNFoNN1vhyMDmMrKyoiICOdNeQoNDb18+TJP\nBkkhno6DMydsYcyYMdu2bcvPzyfF8+4NhISpU6fKZLLs7Ow33njD4iGsEJogTj/HBSHJlbl6\n9Wr3bFhzcnNzOzs7Z8+evWLFiujo6KioKIVC8f333z/55JPbtm0jg875hmnmhGlLVlbW/v37\nDx48mJGRYbEzuWnrSAMhgXNB+N133wEAGVxkhyAk/tIeBWFgYGBSUlJ+fn5nZye3M9asNBCi\nGkRsJzU1ddeuXb09OmnSpMOHD/f4UHcjwNmzZ2081vqTDiTwwtHpnDlzhqIo85vf9957r1ar\nNY2qRwYDra2tra2tTmogJISEhBgMhqamJuc9BTJ4IBVCpwpC0u2Wl5d3+vRpsVhMcke74+Xl\nNW3atPLy8u7dTYNq5gShN0HoeKIMgVQI+6zykc+vFStWzJo1KykpSaFQAMCcOXMCAgJ27dql\n0WgcXIYzIBVCk2UUAKZPn05R1MGDB7vv7HgDIUEul3MoCBmG+f777729vUkj09ChQymK6q9l\nVKFQ9Ja0MWXKFJ1OZ3GtjCDIYAAFoXPRarX5+fkJCQmkuZyAwycGIS7wtmGuDMIhpELoSMpo\nn8THx/v5+Z06dYqMaZXLey0jkNH2u3fvttg+qKbSE8ifefdIg/Pnz0skkhEjRjh+/oCAgD4t\no6dPnxYIBJmZmeYbaZp+6KGHWltbv//+eweX4QwsLKPk6xEjRpw5c8Yi90Wn050+fTo2Ntbx\new0KhaKrq4uMtHacs2fP1tTUzJ07VyKRAICXl1d4eLjtoTJGo7GysrLH8iDBxW2EWB5EEP6A\ngtC5XLhwQavVWvTGTJw4kaZpzJUZVLiglIGjCBEOIRVCpwpCMp6+oaGBjGm1sueMGTN8fHz2\n7NljkTVaUVFB0zT5zR8k9Phn3t7efvPmzdTU1N5mbfWLX/ziF9XV1c3Nzb3toNFoioqKkpKS\n/Pz8LB5asWIFRVHbtm1zfBmcQ1408wohAGRlZRkMBgu32NmzZzs7Ox0vDwKAQqFgWZarXBlz\nvyhh6NCh9fX1NhYhq6urdTqdFUE4fvx4sVjs3mmECIK4BRSEzoX4aiyudeRy+ejRo69fv47X\n7oMHp0aMElAQIhzigh5CuDueHnpvICRIJJJ58+bV19db1C7u3Lnj1L5cHhIYGCgQCCz+zAsK\nCoxGo+N+UQJxjVqZjXT+/HmdTtejho+Pjx83bty5c+ecMY3dQWpqauRyucU9DuK9PHDgAOnj\n+MMf/rBw4cJly5YBF35RACBmWk5co3q9fu/evUqlktTxCKSN0MYioZVEGYJCoUhPT798+bJK\npXJ0uX2B5UEE4RWD6HPULfQoCAFg6tSpLMuia3TwQD6JnWoZxdn0CIe4oIcQ7va8kTGt1vck\nrlEygY3Q1tbW0tIyqBJlAEAkEnXPEyYTCB1PlCGQXJlLly71toNFUpoFK1asAIDt27dzshgO\nqa2t7R7ynJGRERAQ8O2338bGxi5YsGDjxo1nzpyJjY19+umnORGExAjNiSA8ceKESqW67777\nxGKxaWO/cmWszJwwMWXKFIZhTp8+7dBaEQTxNFAQOhG9Xp+XlxcbG9v9Q4hkl6EgHDxghRDx\nLFxgGQWAUaNGiUSilJSUPp9o0qRJISEhP/zwg1b7n8IC+ZsabIIQAIKDg+vr682nwJNEme5R\nmfYxbtw4sDqxnSSlkd26s2DBAj8/v507d+p0Ok7WwwldXV0tLS0WflEAEAqFCxcu1Gg0UVFR\njz/++BdffHH16tUTJ068/vrrnPhvSYWQE8tod78oAAwdOhT6KQitVAjhbhuhs12jWB5EEL6B\ngtCJXLx4saOjo0dfTWpqqlKp/Pnnn80/1JEBTEVFhZeXV3BwsPOeAkNlEA5xjWXUx8fnm2++\n+fOf/9znnkKhcNGiRWq1+siRI2TLoBWEISEhOp3OvMcvPz8/JCSEq5ciJiYmOTn51KlTPbYR\n6nS68+fPDxs2LCgoqMfDvby8lixZolKpehwd6S66z5ww8cknn9TX1589e5b4RXtL4LQPriyj\nWq02Ozs7NDTU4orCjgoh0ZC9MXr0aKlUim2ECDLYQEHoRIjpokdBKBAIpkyZ0tDQwNsZvgi3\nVFZWRkVFURTlvKcICgoSCoVYIUQ4wTWCEACmTp2alJRky55kMp4pa3QQTqUnWHgBSktLGxsb\nexvaYR/z58/X6/WHDh3q/lBRUVFXV5f1ns9f/vKXwDPXaHV1NQCEh4d3f0gkEvUmbh2HWEYd\nrxAeOXJErVYvWrTIomN26NChAoHARkFYWloqEol6fBFM0DSdmZl5+/btqqoqh1bcO1geRBAe\ngoLQiVhvtCD9CZg1OhhQqVTt7e3OvnIViUQBAQEoCBFOaGtrAwBvb293L+T/k5GRMXTo0CNH\njhCxOgin0hMsvABkPCNXflHC/PnzAWD//v3dHyKfa735RQlJSUmjRo06fvw4KUnxAfJyuT6Q\nlqsK4cmTJwFg3rx5FtslEkl4eLiNgrCioiIyMtK8BbFHXDx8AkEQPoCC0FkwDJObmxsREdHb\n9QppI/z5559duizEHZBEGadOpSeEhIRYNBchiH20tLQIhUJyOcsfHnjgAa1W+8MPPwBWCO/e\n+iENhFwlyhCSkpLi4uJ++ukncl/AnN6S0ixYsWIFy7L/+Mc/OFyVI5AhhNaLY86AK0FIBG2P\nHyJDhw5tbGwkTb9WaG5ubmlpse4XJUyePBmcJgixPIgg/AQFobO4cuVKa2vrxIkTe9shPDw8\nISHh7NmzpowEZKDisman7s1FCGIfarXax8fHqSZnOzCfUH/nzh2RSNQ9JmTAYyEI8/PzRSJR\nWloat88yb948nU539OhR841GozE3NzcqKioyMtL64YsXL1YoFDt27DAYDNwuzD48vULY0NBA\nUVRAQED3h4YNGwY2TJ6wJWKUkJqa6u/vv2/fvhdeeKGgoMCe5SII17Q5B3f/WDxC5O4FOAWZ\nTOb2yVSFhYUAMH36dH9//972GTVq1I0bN9ra2nrsdHccsVhs5dkRl9HQ0AAASUlJ9v13CAQC\nlmVlMlmfe5IU087OTnKJgPAN8r7kEX+V7e3t/v7+fFvqmDFjMjIyTp061dXVdefOncjISG4j\nQGyHoiiKojgJouwv8fHxAKBWq/39/TUazZUrV0aMGBEREcHtsyxbtuxPf/rT4cOHV65cadpY\nWFioVqsXLFjQ5y+Gv7//smXLtmzZcvr06YULF3K7Njsgg/USEhK6r5z8VTqpXZZ8uBuNRgf/\nlJqampRKZY+ClsyNrKurs/4UjY2NYPPH0Jtvvvn73/9+69atW7duTU5Ofvzxx5cvX+6AnP5P\n3iyWB10AH960GYZx9xKQfjMwBWFnZ6der3fvGnJycgAgLS3NSrmGJK2XlJRwfk1DbiXq9fo+\nbSSICyAzmgMCAuyr3cnlcoPBYEsl2c/PDwCKi4v7vH+PuAWlUgkAHlHCbW5uDg4O5uFSFy5c\neOHChc2bNzc2NiYkJLhrhRKJRCQScTJOoL+Qe0Pl5eXNzc15eXk6nW7kyJGcvw6xsbGRkZHZ\n2dk1NTVeXl5kI4mZGTVqlC1Pt3Tp0i1btmzevNl8kLq7KC8vFwgEXl5e3Vfu4+ND03Rra6sz\nrmKJgb+xsdHB/6Da2trIyMgeT0KK5JcuXZo5c6aVM5AEOxv/qB966KH777//yJEj33zzzdGj\nR1944YWXX355wYIFmzZtEonsuG6U9/8QxE748KYtFotdEEiGcAtaRp3FyJEjZ86cab1QQ3Qg\nuW+HDGBIs5NThxAScBQhwgkajUan0/HzE33x4sUCgeDzzz+HQdlACADBwcEURZE/c9JAOGrU\nKM6fhaKouXPndnR0mM/LtbGBkJCenp6YmHjs2DE+DCSsra1VKpWur+hyYhnt6Ojo6OjoLQqV\nTJ6w0TJqSw8hQSwWz507d/v27UVFRb///e+jo6N3797Nn6ZQBEG4BQWhs3jmmWf6fOtEQThI\nqKiokMlkPbZ/cAuxJ+EoQsRBWlpa4G7BmW+EhYVNmDChqakJBqsglEgkvr6+5M88Ly8PuE6U\nMUGyRkmEDwCwLHv27Nng4GDbHekpKSkGg4HcEXMjLMvW1ta6PlEGOBpMX19fD703QMbExAiF\nwj6DRolitCPbLDg4eO3atd99951UKn3vvffsbrtCvyiC8BkUhO4EBeFggGXZyspKF0SMAlYI\nEY4gVnPiaechJFoGXFJ15ychISHkzzw/P9/f35/UiDgnMzMzJCTkwIEDpMR38+bNxsZGG8uD\nBLKw27dvO2N5tqNSqXQ6nZN69a1D5hA6WCEkXei9VQhpmrZl8kSyn9wPAAAgAElEQVR5eXlg\nYKDducFhYWFr1qxpbGz8y1/+Yt8ZEAThMygI3QkKwsFAQ0NDV1eXa65cLQaUIYh9kEF/vBWE\n9913H/H+Ddpe2ZCQkK6uruLi4urq6lGjRjkpDFYgEMyePbu1tfXUqVNg2wRCC4ggtHFKnvMg\nMyfcEkjLiWWUVAh7E4QAEBsb29TURAr7PaLT6Wpqamz3i/bIunXrgoOD//KXv9gxsx7LgwjC\nc1AQuhMUhIMBV05LM28uQhC7Ia4w3gpCX1/fmTNnUhTlpMoY/yG3foiZ0xkNhCbIJHTyRGfP\nngWACRMm2H44MZe6vULorpkTAEDTNE3TnFQIg4ODe9uhzzbC8vJyhmEcNKrI5fLnn39eo9G8\n//77jpwHQRAegoLQnRBBSJphkIEKGULomgohTdNKpRIFIeIgPLeMAsAHH3ywd+9et3SF8QGi\nbbKzs8HJgnDSpEl+fn4HDhxgGObMmTN+fn6JiYm2H84TyygRhO4aWalQKDipEPYpCK1UYsvL\nywEgJibGkWUAwKOPPjp8+PCdO3eSzFIbwfIggvAfFITuRC6XS6VScvMPGaiQT2KXpV+YmosQ\nxG6IZZSfKaMEpVLZL+/iAIMIwsLCQoFAkJGR4bwnEovFs2bNqq+v/+c//1ldXZ2ZmdmvGb/e\n3t7BwcGD2TIKAHK53MFQGes9hGBDhdD2qfTWEYlEr776KsMwr7/+uoOnQhDEHIPBQFHUwYMH\n3bUAFIRuJjAwEC2jAxtXVggBICQkRKvV8mESEeK58LyHECGCkGXZuLg4Z+t24hp95513wOaB\nE+bExsbW1NR0dnZyvzKbIYLQLaEywEWFsE9BSJoDrQhvohUd7CEkzJo1a+LEiceOHSPDlhFk\nwFNfXy+RSKKiooxGY5875+TkkGlAHgcKQjcTGBioUqmcMQ8X4QkuG0JIwKBRxHGIZZTPFcJB\njqkdzkkDJ8yZNm2aQqEgmsoOQThs2DCWZfuckudU3FshVCgUnZ2djnzK19XVCQQC0mPSI0OG\nDBEKhX1WCB23jBLeeustgUDwyiuvGAwGTk6IIHzmiy++mDRpkk6n279/f587f/jhhwNZEH7y\nyScsy3bf3tLS8thjj3G9pMFFYGCg0Wi0Eg6GeDoVFRU+Pj4uG+lG7oKjIEQcgf+W0UGOSRA6\ntYGQIJFIpk+fDgByuTwlJaW/h/MhaLSmpkYikfj7+7vl2RUKBcuyjtRI6+vrlUqlSCTqbQea\npiMiIqy8yGVlZVKp1EoXYr8YMWLEAw88cPPmzW+//ZaTEyIIb2EY5vPPP1++fPnDDz/82Wef\nmT90586dhQsXKhSKoKCgNWvWdHV1TZs2LTs7+9lnnx01alR7eztFUceOHSM737p1i6KoW7du\nAcDVq1dnzpzp7+/v5+c3a9YsstGcv//970lJSVKpNDQ0dO3atRqNxgU/qU2C8Jlnnpk+fTpp\nhTJx8ODBESNG7NixwzkLGyyQYeXYRjhQYRjmzp07rhyfjRVCxHH4HyozyHGlIIS7E+rHjBkj\nFov7eywfgkbr6upCQkKcNJyjTxwfRdjQ0GDFL0oYNmyYSqXqsVmAZdmKioqYmBgOX4ENGzZI\nJJL33nuvq6uLq3MiiC0IWlSO/wObK/bZ2dmNjY1Lly5duXLloUOHSLGdsHz5cpqmb926dfr0\n6ZMnT65fvz4nJyc6Ovrjjz/Oz8+3cs4HH3wwNDS0oqKioqJCoVBYlNZKSkpWrVq1adOm9vb2\n3NzcvLy8jz76qP+vU7/p9YaTOd9+++1vfvOblJSUDz/88Mknn2xra3vuuee2bNkyYcKEQ4cO\nOXuJAxvyLo9BowOVuro6nU7nmqn0BKwQIo6DgpDnKBQKuVxOUVS/Mj/tZubMmffdd9/DDz9s\nx7FuDxrV6XRNTU1unFDi4CjCtrY2jUbTZ3EvNjb2p59+Ki0t7V4Ira2t1Wg03H4MRUZGPvro\no1988cWZM2emTZvG4ZkRxDqiTR84fhLDMy8ytn3Affrpp0uXLlUoFOnp6WlpaVu2bHn77bcB\n4PLly8ePHy8uLg4NDQ0NDd22bVt1dbWNz378+HEvLy9yq+iRRx5ZtmyZuQ2zvr6eZVl/f3+h\nUBgdHX327FmhUNj/H7Hf2CQIH3roodmzZ7/88surV6/euXNncXFxc3Pzpk2b1q5d665bbgMG\nHEU4sHHlEEICzqZHHKe1tZWiKG9vb3cvBOmVp59+2svLyzUXCjKZ7Msvv7Tv2NjYWIFA4EZB\nWFdXx7KsuxoIwWFB2OfMCYLJmts9dZbbBkITEyZM+OKLLwoLCz1LEFLARjCVNYIII7jibwfh\nHFYqp6geutj6dxLaJvlTWlp66NCh48ePk29XrVr11ltvvf7662KxmFhATUFNI0eOHDlypI3P\nXlBQ8N5775WUlDAM09XVpdfrzeNqMjMzn3766czMzLFjx2ZlZS1btsw1N/5sekUAwNfXd9Om\nTX5+fm+//TZFUfv27SPJY4iDoGV0YEMEoSsrhGgZRRyntbXV29vbNWIDsY/169e7ewk2IZFI\nrLe3ORuSKOPGkZVEENo9ecJGQUguTHvMlXGSIExPTweAwsJCbk/rbOKYm0v1/6ighuwSL+ui\nZO5eDtJv9M9tcNlzffbZZwzDmPSO0Whsb2/fs2fPgw8+SGp6DMPY+EFpipUqLy+fP3/+a6+9\nlp2dTdP03r17Fy5caL4nRVGbNm168cUXf/jhh/3797/77rvbt29funQppz9ZD9iaMlpRUbFg\nwYK33377qaeemjBhwqJFi1566SX0jjsOWkYHNq6vEIaGhlIUhYIQcYTW1lZMlEG4YtiwYU1N\nTe7KTiN2CXfNnIC7PYQOCsI+ewithPcQQcjJzAlzoqKiAgMDL1y4wO1pnY2cbQeAaLZ8pf7z\nQAbvxSO9otPpvvzyy9dee63wLpcuXVqyZAmJlomLi2NZ9vr162Tn3NzcTZs2mR8ukUgoitLp\ndORbU/NhXl6e0Wh86aWXaJoGgO6RpAaDoaGhISoqas2aNfv371+7du2nn37qzB/0P9gkCD/4\n4IPk5OTCwsLDhw9//vnnx48ff++99/70pz+lpqbiIBoHIRVCtIwOVFw8cwIAaJr29fVFQYg4\nglqtRr8owhXuDRp178wJcNgySgxEfVYIo6OjRSKRFUHIeYUQANLS0urq6jyrQ8ELNABQRUX6\ns6rH9FuGMZYBjwhC2LVrV2tr669//esYM/73f/83JyenuLg4JSVl/Pjxzz//fHl5+c2bN1ev\nXn3lyhUAkMlkt27dampqEovFcXFxZNB8e3u7SS5GRkYaDIYTJ04wDLNjxw4io8z7D7/66quM\njIz8/HyGYerq6i5fvkyiuZyNTYLw+eefX7JkyaVLl2bMmAEAAoHgueeeKywsDAwMJGnUiN2Q\nHkK0jA5UyFR6V1YIASA0NBQFIWIwGF544QU7cr/0en1XVxcmyiBc4d6gUbdXCDkRhFaGEBLE\nYnFkZGSPgrC8vFwoFEZGRtq3ACt4omuUBi0AHBdN2yN6UASGpfrtE4wn3L0ohI9s3rz5/vvv\nt/jTmzJlSkJCAikS7tixQywWJycnT5gwITMz84MPPgCA1atXb968eezYseQM2dnZQ4cOzcrK\n+t///V8AMBgM48aNW79+/aJFi4KDg3Nycvbt2zdy5MjRo0ebSoirVq166qmnlixZIpPJ0tLS\noqKiyJmdjU09hHv37r3vvvssNiYkJJw8efKPf/yjE1Y1iEDL6MCmoqJCqVS6uNgSEhJy/fp1\ntVqN1/SDmdLS0q1bt/7zn/88evRov+4v4lR6hFvIr5+7KoSeLgiJZdQ0aMQKsbGxOTk5KpVK\nqVSaby8tLQ0PDyf+NG4xCcLZs2dzfnInIWG1AKClvEoEcWrK50HDjqmGI75My2HxXIyZQcw5\ncaLnOwXXrl0jXwwZMqT7qPp169atW7eOfD19+nSTpxQATFGiGzdu3Lhxo2m7yXdt2uHVV199\n9dVXHf0B+olNFcLuapAgFApffPFFTtcz6KBp2tvbGy2jAxKj0VhdXe3i8iBgrgwCAAAqlQoA\nOjo6Vq5c2a+xtmQqvZ+fn7NWhgwySPeauwQh8WK50TLq4BxCG0Nl4K411yJXpq2tTaVSOcMv\nCgAk0dSzKoQS0AKAlpUAQKVgyJfi1Q1UcAaT94zugxmGAyGsJ9lfEYRDbA2VQZxHYGAgCsIB\nSXV1tV6vd70gxFGECNwVhN7e3teuXfv9739v+4GkQog9hAhXREdHi8Vid1lG6+rq/Pz8vLy8\n3PLswIVlVCgUdp8u2B0iCG/evGm+kfjQnJR0HRwcHBYW5lmCkL5bISTftlD+X4mfyhNmUqxx\nrPHMk7pPn9R/OtZ4RgZ2hgAhiIeCgtD9BAYGtrS06PV6dy8E4RjSQOjKmRMErBAiANDc3AwA\n69evj4uL+9vf/vbDDz/YeCCpEKLfGOEKkUg0ZMgQN4bKuLE8CA6PnWhoaAgICLAl2n7UqFEU\nRb311lvl5eWmjeRrJ1UIASA9Pb2pqYl82HkEpEKooySmLVpKclg078+S578TPXhLEB/E1M8w\nHHhG+8exxjPuWyaCuBoUhO4nKCiIZVlyOx8ZSLh+5gQBZ9MjcLczOSoq6ssvv5RIJOvWrbPx\noo0IQuwhRDgkNja2ra2NuB9dSWtra2dnpxsbCMGxCiHLsvX19bb4RQEgIyPj3Xffra+vX7Jk\niSmpjuhwzmdOmPC4XBkv0LBA6UBssd0A4qvClJ3iRz+RPJ8jmkkBO8JY5JYVIohbQEHofsjk\nCcyVcTbHjx8fO3bsrl27XPaMrp85QcAKIQIAZOybUqlMSkp6/fXXW1tbV69ebTAY+jywra0N\nsEKIcIqVXBmdTnfrlrOi/92eKAOO9RC2trbqdLo+hxCaeOKJJ9auXVtWVrZ8+XJSkyQVQucZ\nVUaOHAkeJQhpVqOlJCxQve3QDoozwkmNgqBgtk4IRleuDUHcCApC94OTJ5wNy7J//vOfly5d\nWlpaartxznFIQQYFIeIWyD0m0nr0xBNPzJ8/Py8v7/333+/zQKwQIpxD2tt6bCP8wx/+MGHC\nhMuXLzvjeckQQs+tENo4hNCc119/fcmSJQUFBStXrtTr9c62jKalpQFAQUGBk87POV6g1YGk\nz93qqDAhGHFyPTJ4QEHofoggxFwZJ9He3r5q1ao333wzICBAKpWaRwA7m4qKCoqiMFQGcQuk\nh9AUQP/RRx9FRUX9+c9/PnbsmPUDSagMVggRDultFCHLsrt372ZZ9vz58854XlIhdG8PIU3T\nNE3b10Noe8SoCYqi/vSnP02dOvWnn35at25dSUmJv7+/8+7vKJXK6OjoixcvmhLzeQ7NarVU\n34KwlgoDgBC2us89EWRggILQ/RBBiJZRZ3Dz5s2ZM2fu379/7NixR48eTU5OLi0t1Wq1rnn2\nioqKgIAAmUzmmqczIZVKfXx8UBAOckhbsimc0M/P77PPPqMoqs8iIYbKIJxDKoTdLaMXLlwg\nToqLFy8643n5IAgBQKFQOFIhtN0ySqBp+ssvv0xLS/vXv/5VWVnpvPIgIT09vbW11V2hQf1C\nAIwY9GTmhHVqBWEAEMrWOH9RCMILUBC6H7SMOol9+/bNmjWruLj4ySef3LNnT2hoaGJiotFo\ntEjldhJ6vb6mpsb1EaOEkJAQDJUZ5DQ3N3t7e5tPox4zZkxCQsLFixd1Op2VA3EwPcI54eHh\nUqm0u2bYu3cv+cKpgtC9llEAkMvl9glCOyqEBIVC8e2335IsGWd/DHlQrgzN6ihgTTMnrFAH\nYSxQoQwKQmSwgILQ/aBl1BmcOnXqiSeeMBqNn3766bvvvisWiwEgKSkJAFzjGq2urjYaja73\nixJCQkLa29vtDjpHBgAqlar77LL09HSdTnft2jUrB2IPIcI5FEUNHTq0pKSEYRjTRpZl9+3b\nJ5PJ4uLirl275ozZS6SHkA8VQvveje2rEBICAwP/+c9/pqen33fffXYcbjskV8Yj2ghp+K8h\nhFbQUpIWShnC1lLgGVZYBHEQFITuBy2jzuDf//43y7JffPHFgw8+aNqYmJgIrhKEpJXf9Yky\nBMyVGeSwLNvc3GxqIDRhy738hoYGgUCAg+kRbomNjdVqtVVVVaYtBQUFlZWVM2bMGDNmjE6n\nu3HjBudPWlNTIxKJyIesG1EoFJ2dneZi2EbIe7h9ghAAYmJijhw5smDBAvsOt5HU1FSBQOAR\nFUIv0ACALaEyAFBDhdGg82fx2gwZFKAgdD9KpVIgEGCFkENYlj106JCvr+/UqVPNtxNBaL08\nwhVEELqrQoi5MoMctVptMBh6rBCCVUGo0+kuX76ckJBg7jVFEMeJi4uD/86VIX7RhQsXpqam\nAsClS5e4fca6urrS0tLg4GBbpro7FYVCwTBMZ2dnfw8kFUJyg4+3+Pj4xMbGXrp0yWjk+5AG\nmtUCgMY2QVgnCAOAMBabL5BBAQpC9yMSifz8/LCHkEMKCgrq6uqmT59OnKImQkJClEqlCyqE\nbW1tn3zyCUVR5Prb9WCFcJBjETFq4he/+AVN01YEYVFRkU6nGzt2rHPXhww+LEYRsiy7d+9e\nmUyWlZVFBCG3bYQVFRXz589vaWm5//77OTytfdg9irChoUEsFvv5+TlhUVySnp7e2dnpmv58\nR5CAFmyuENZSoQAQgm2EyOAABSEvCAwMRMsohxw8eBAA5syZ0/2hxMTEO3fukNHbzuOFF14o\nLS1ds2aNewUh5soMWsj7SUBAgMV2mqaTkpKuX7+u0Wh6PPDcuXMAgIIQ4RwScGIShCRfdObM\nmVKpdMSIEQKBgENBWFxcfN9995WVlT355JOvvvoqV6e1GyII7WgjrKurCwoKEgj4fqnmKbky\nElYDALaMnQCAGioCMGgUGTTw/V1mkBAYGNjW1uaycQgDnkOHDonFYgu/KCEpKYllWacWCf/x\nj3/s2rUrPT39d7/7nfOexTrcVghPnz6N2tKzaGlpAbOZE+akp6cbDIbe5oCTcXBjxoxx6vKQ\nQYjFKMJ9+/YBAGlvk8lkw4YNu3z5sh1ddt0pKiqaP39+dXX1hg0b3n33XYqiHD+ng5CO3P5W\nCFmWbWpqcnsDpC2QXBkPEIQkVMa2CmEXJWujvEMZHEWIDApQEPICciMfXaOcUFlZefXq1fHj\nx/cYk0jaCJ2RXkC4cePGb3/7W29v7y1btrixC4tDQXj9+vXFixfz4S47YjukQtibIASAoqKi\nHg/My8sLDAwkxRwE4ZDAwEBfX18iCM39ouTR1NTUzs7OW7duOfgsZ86cWbx4cUtLy3vvvfeb\n3/zG0UVzhH2W0ebmZr1eb8fMCdczYsQIoVA4wAQhANRS4VLo9GFbnbko+zGwzB1dV5625Qd9\n7XaqYrPs9oeBxQymoiJ2IXL3AhCAuxliTU1NkZGR7l6Lx0P8orNnz+7xUacGjWq12tWrV3d1\ndW3evNnZs4Ctw2GozNdff80wjHk2IMJ/yFT67pZRsGruKisrq6+vnzdvnrOXhwxOSPSITqe7\ndOlSZWXlokWLpFIpeSglJWX37t2XLl0aPny43ef/8ccfV65cqdfrP/7442XLlnG0ag6wzzJK\n3sA9QhDKZLLhw4dfvnxZp9PxOY/q7tgJmwWhICyeuRHK1qgpd47h0bDMHX1XHatpEOpaJbo2\nmaHTx6BXGhklC93ykm436uODxD2dBkGsgYKQF5DrNgwa5YRDhw4BwKxZs3p81KlBoxs2bLhy\n5cqKFSuWLFnijPPbjkKhkMvljgtCrVa7a9cuwPK1p0FCZXrMokhISJBIJD1WCPPy8gBg1KhR\nzl4eMjgZNmxYQUFBRUWFuV+UYMqVeeCBB+w7eVtb2+OPP86y7NatW3tsIHcj9llGySWB3TMn\nXEx6evq1a9euXbuWlpbm7rX0ioQlFcK+5xAS6qgwAAhham4KEp24rLs0GLS1jLYetCqRtkWi\n71AYNL5GQwDD+vZQ9aNaKHGZUKoWyjtEvl10oIEOAa9wkVf8b9zvkUY8ERSEvIA0CeA1t+Oo\n1eozZ84kJSX1NgDQz88vLCzMGYLw+++///rrrxMTE9955x3OT24HISEhjjf+7d27l0gL/OX0\nLHpLGQUAsVickpJSUFDQ2dkpk8nMHyKCEBNlECcRGxsLALdv37bwiwJASkoKRVG9TZ5oaWl5\n7bXXnn76aSv1w4KCAq1Wu2bNGr6pQQBQKBTQf0FYX18PHlIhBICRI0fu2LGjsLCQz4LQi6SM\n2jCYnlBLhQHXuTJqo6HGoKmnNE0CvVqia5MZuhQGnR9jDGCge23VCAIVRd8QydQi706Rr5YO\nMtIhlFekWOpFmfV8CcGsVGjgcLWDnNGjR+fn51ts3Lp16+OPP+6O5fwXOTk5Pj4+o0eP5uqE\nKAh5gcky6u6FeDw5OTk6na43vyghMTHxp59+ampq6tFQZx/l5eX/93//J5VKt2zZYjJBuZeQ\nkJCSkhKNRuPlZeuHX3e+/vprAIiIiKiqqurq6uLJj4b0CbGM9igIASA9Pf38+fOXLl3KzMw0\n356bm0vTtLuicZEBD8mV2bVrV2Vl5cKFC83fT/z8/KKioi5dusSybPcYmG+++eabb76Ry+VW\nbreR6zZ+5iHZ10NIbsN5UIUQAAoLCx977DF3r6VXiGXUxjmEANBK+XVRsn4LQgrq9Np6g7ZJ\noGsR6tS0vk1q6JIbdb5GYwAL0p6a/NopUa1A0iKSd4i8u0T+OjqIlYQJJGFiicA87EOEl+2u\nZsWKFa+99pr5Fhvngur1eovJZ9zy4Ycfzp8/n0NBiKEyvAAto1xBGgh784sSkpKSgGvX6Mcf\nf6xWq9966y1iSeUDjrcR3rx589y5c+PGjSPXWFgk9CCsC0JyC9+ijbCtre369eupqakSia1X\nSwjSL0iFkPhFFy5caPFoampqS0tLZWVl9wO/++47AMjNzbVychKQm5GRwdVqOYRUCPvbQ+hZ\nFcI+Z5zyAWIZ1dncQwgAdVSoD9sqg//6v+tkjOW6zgva1hxtw3dM9deC8s2ykg8Dit+Puf52\n2tU3J1/5fOatPXMrT8yuuzSjufyedtVYTdcv9EYlI2yipFfEylyvIccUqYeVUw+GPnRgyG+O\nJL6Sm/zbW0n/1xi/umvoIxA1hw4ZLfGLEEsFeJXubnx9feP+G+IAr6urW7ZsWXh4eEBAwPTp\n08nUHL1eT1HU1q1bhw4dumrVKrLbQw895OfnFxAQMHPmzCtXrpDT3rlzZ+HChQqFIigoaM2a\nNV1dXQBw9erVmTNn+vv7+/n5zZo1yxSy9fe//z0pKUkqlYaGhq5du1aj0UybNi07O/vZZ58l\nLR7dd7DjJ8VbDbyAWEZREDqIwWA4evRocHAwicDuDSIIr1+/PmnSJK6eOjc3VyqV8irGYMiQ\nIQBQUlJCvrCD7du3syz76KOPks/4urq63oy4CN9QqVQSicTCEWqix1yZ/Px8o9HIzwILMjAg\nFUKj0WjhFyWkpqbu37//4sWLFu8zZWVl5Hf1ypUrHR0dpNrWnfz8/NDQUH4Gs9lnGfWsCiFN\n08nJyVeuXLHdlsIAc1vXVQztNfIuAFDohAqD2IcV+TF0oFASIBLRVLfIFAcXyWoYEOih17qN\n2mhQM3o1Y2gHfRtlbBcYbgQOC1f6ZKtvVYFMLzcafBjGl+21xMgA1UKJy4WSDqGsQyTXCv10\ntJ9RHASScJGXt/C/L7nxAtwu/lRb73iQ6prgQC/HxnsuXLgwICCgoKBALpe/9tpr99xzz61b\ntwICAiiK2rx583fffUfufy1fvjwgIKCkpEQqlb799ttZWVm3b9+WyWTLly8PDg6+detWW1vb\n4sWL169fv2nTpgcffHDUqFEVFRUsy65cufKxxx47depUSUnJqlWrjhw5cu+991ZVVT3wwAMf\nffRRTk5OTEzMSy+9tGbNmh53+O1vf9vfnwh/H3kBCkJOOHv2bEtLy4oVK6yP8bUeNHrw4EF/\nf38LK511mpubi4uLx40b51R7QH8xxef0OI+xT3Q63c6dO/38/BYsWFBdXQ1YIfQompubeysP\nAkB8fLxcLrcQhNhAiDgbb2/voKCghoaGrKys7v5zU67M/Pnzzbfv2bMHAMiB+fn5U6ZM6X7m\nsrKypqYmiwP5g32WUQ9KGSWkp6cXFhbeuHGjexuhAZhGvb6B0aooXbNAXyfXtARrdVEMeFm9\ntu+iBG0gaheIOgQSjZDWUWKDwMsooI0imhVIGErOinpMUNEAY6D+M9NST7F6itEJWKPAqBoS\nJqSDv60rNQhZg5jVSxgjzTA0MF4sK2dZOQvdTncRlADkvVQHLFBqStQgELUJvDqFXhqhTCvy\nNYh9jOJAoAMEdJBIIrA4A5o8ueaVKg6mIi9VKsNp+wVhQUHBuXPnLl++TOyjb7755ubNm/fu\n3bty5UqBQLBgwQJy1/XKlStHjx6tra0lH8dvvPHGX/7yl/379ycnJx8/fry4uDg0NDQ0NHTb\ntm3kKuv48eNeXl7k7eKRRx5ZtmwZy7L19fUsy/r7+wuFwujo6LNnzwqF/3WjpM8dbAR/T3mB\nn5+fSCRCQeggJF/UegMhACQkJAgEgh4toyqVatWqVUFBQYWFhbaPM87Pz2dZlm+lFQedsfv3\n71epVE899ZSXlxe5IkFB6EGoVCpSjekRoVCYkpKSm5urVqt9fHzIRiIIOWxIQJDuxMbGNjQ0\ndPeLAkBKSgoAEOeVOd99951YLF6/fv0LL7yQm5vboyDks18U7LWMNjQ00DTd40BdfvLcc89t\n2LDBYvzp//xQt2dUaw85mQwIawTetXRwi2SITi4EQTOlbRMZOkSGLgnTJTXopIxBzjDerC7Q\nqBMYO0Hv+ApvQSwAwLCu/9qqoSgtCNooYb1A2CUQawW0TiDRCaV6gdwgihZ0/cZ7f51myM/a\nOQFiUQ8eTpR8riVTLmO6C/d+4m2zGPz000//+te/mm85dzpRvFYAACAASURBVO5caWkpRVEJ\nCQlki0wmi4iIIENWASA+Pp58UVxcDHf7d0yUlJTQNE1RlGne78iRI4mvraCg4L333ispKWEY\npqurS6/XG43GzMzMp59+OjMzc+zYsVlZWcuWLbNoTepzBxvB32JeIBAIlEolCkIHOXjwoFQq\nveeee6zvJpVKo6Ojb9y40T29YM+ePXq9vrq6urCw0Lrv1Bx+XknHxcWJxWK7Jy5u27YNAB59\n9FG461lCQegpdHZ2ajQaKxVCAEhPTz979uzFixeJcZphmPz8/KioKIuPLgThlvvuu6+jo2PG\njBndHwoODg4NDbUQhDdv3rx69er06dPnzJlDBGGPpyWJMnx7EzZht2U0KCjI9luTbqfHdw+5\nSEBpQVwspDuFsk6RTCv01okjjdJEkbeC1DEo+C8HJgPQBfDfkk1l0DUzuk5g2li9BhidgNFQ\nRo2QYe+WAbVClqEAAIQsiBiBgP2P/qSNIiELQhBIGErECtYr/60xyr9tXSADgUwglgkEvsLe\nfT0UgBgoYEc3q9up8qs8nq84qDiSGOfKp3v44Yc3bNhgviUuLq60tBQAWPb/3+Ywv5409eGT\nLZ2dnRaGCNIUzTCMeSmvvLx8/vz5r732WnZ2Nk3Te/fuJTfOKIratGnTiy+++MMPP+zfv//d\nd9/dvn370qVLTQf2uYONoCDkC4GBgSUlJe5ehQdz7dq1srKyuXPn2tK9kJSUdODAgZqamvDw\ncPPtZOYeAGRnZ/dLEFIUxTevHU3TsbGxN27cYBjGuoe2O2VlZadOnRo7diwpM6Ig9CxIXrF1\nQWjKlSGC8Pr162q12noaE4I4zurVq1evXt3bo6mpqYcPH66trTVJC3LltGjRotDQ0Ojo6PPn\nzxuNxu6GqPPnz4tEIt4OPLDDMmo0GhsbG3n7E9nOR7OChv457L829b+kphTRyh5mMphh7GW7\n2W+KAJhZquoqQdQViY/tT80CVU+FRLB3JKDTWl8DMhBRKpUjRoyw2BgfH8+y7PXr14mvob29\nvaqqylQYNN8NAAoLC8ePH0+2lJSUxMbGxsXFmR+em5ubm5sbGhpqNBpfeuklIiOJ6wEADAZD\nc3NzVFTUmjVr1qxZ8+yzz3766afmeq/PHWwE84v4QmBgoEaj6e8dRMTE4cOHAWDmzJm27Nzj\nePqKiorz58+npaXRNJ2dnW3j8xqNxoKCgpiYGA6HWHBFUlJSV1dXWVlZfw/86quvSJwM+ZYI\nQhJ5h/CflpYWALAwbllgkSuDI+kRPtDdNfr999/TND137lwAyMzMbGtr626D12q1V69eTUpK\n6i1Fye1IJBKxWNyvz/fm5maj0UjyBRBOkICWAlZr88wJE7VUGAVsMMtB6xoyMEhLS5swYcJL\nL73U0NCgVqtffPFFHx+fRYsWWeyWnJw8bdq0559/vrKyUq/Xb968OSUlpba2NiUlZfz48c8/\n/3x5efnNmzdXr1595cqVyMhIg8Fw4sQJhmF27NiRk5MDANXV1V999VVGRkZ+fj7DMHV1dZcv\nXyb9IDKZ7NatW01NTb3t0F9QEPIF8r6Powjt5uDBgwKBoEcnUnd6zJXZtWsXy7KPPfbYlClT\nbt68aQr8tc7Vq1fb29v5Vh4k9Kh7+0Sn03377bc+Pj6mPh9iW8IKoadA3kas36EYNmyYr6+v\nSRASJ16/spQQhHMsBOHly5eLi4uzsrJIpyt5mz137pzFUYWFhTqdjm9d3BbI5fJ+9RCSRBkb\nJ54htkCz/RtCaKJWEAYAoQyX4+kRT+fbb78Vi8WxsbGxsbFlZWUnTpwwNeSb849//CMyMjIl\nJcXf33/btm0HDhwg9ocdO3aIxeLk5OQJEyZkZmZ+8MEH48aNW79+/aJFi4KDg3Nycvbt2zdy\n5MjRo0dPmzbtqaeeWrJkiUwmS0tLi4qK+uCDDwBg9erVmzdvHjt27KpVq3rcob+gZZQvEEHY\n0NBg95CAwUxjY+OFCxdGjRplYyCbafKE+cbvvvuOpul58+YBwI8//pidnf3MM8/0eSp+NhAS\nTD8m+aFsJDs7u7Gx8cknnzS53kmwAQpCT6G5uRn6soxSFJWamnry5EmVSqVUKnNzc+VyOX+m\naCKDExI0eunSJfItyRc13XcnNyxyc3OfeOIJ86N4nihDUCgU/aoQEkeGp8yc8AgkQIYQ2jQS\nw5w6QTgA9Hs8PeL5mHyb3YmKiiJvUBYYDAbzb0NDQ3fu3Nl9tyFDhuzfv99i48aNGzdu3Gj6\n9sKFC+SLV1999dVXX7XYed26devWrbOyQ3/BCiFfwMkTjvDjjz8yDGOjXxQAhg0bJhaLzUtn\nFy9evH79+vTp05VK5ezZswUCwYEDB2w5FQkz4OfN6eTkZOh/hXD79u0AsGLFCvONJPOdw7Uh\nzoNMpffz87O+W1paGsuyRUVFjY2NZWVlo0aNEonwFiHiTqKiopRKJakQsiy7Z88eqVRqemNP\nSEjw9fXtnitDLpt4bnjuryD0rCGEHgGpENphGW2ggg0gCmGqnbAoBOELLv34b29v//zzz/Py\n8gwGw4gRI371q191r+f0to8tx3o0aBl1hKtXr0J/RqjRND1s2LCbN2+a8gl2794NAEuWLAGA\noKCg0aNHnz9/vq6urk/HTm5urkKh4GdpJTo6WiaT9UsQVlZWHj9+fNSoUb/4xS/MtwcFBRUX\nF9s+cRhxI7ZUCOFuG2FRUZFGowG+3tRABhspKSk///yzSqUqKysrLy9fsGCBaRK9QCAYPXr0\n0aNHq6qqIiIiTIdcuHDB39/fvrYZl6FQKDo7O7tHW/cGEYQD7DrHvXj9p0LYb0FoBGEjFRTE\n1otAb+h9qD2CeDQurRB+/PHHFRUVb7755kcffSQUCt944w2GYWzcx5ZjPRqTZdTdC/FISG5K\nTEyM7YckJiZ2dXWVl5cDAMMw//73v729vU23oufOncswTJ9FQlJaycjIsG8MqLMRCAQJCQkl\nJSU6nc7GQy5dusSybPdaKwaNehCkQmg9VAbMcmWI7RkFIcIHTOPpiR1r8eLF5o+aXKOmLbW1\ntXfu3MnIyOD5eAaFQsEwTGdnp437Y4WQc4hl1I4KIQDUCcKEYAxi8RMQGbC4ThA2Njbm5uY+\n88wzcXFxkZGRzz77bFVVVVFRkS372HKsp4MVQkcoKyuTSCT9GqFmHrhy8uTJ2tra+fPnm8pf\npOmuz6xRcl3Cz0QZQmJiosFgINNRbaE3aY1Box4EEYR95hNGR0crlcrCwsJz585RFMVzxx0y\nSCC5MkVFRfv27VMoFFlZWeaPkjdbc0FImnz42cVtDqlz2p4rg6EynEOzGrArVAYAaqkwAAjB\nXBlk4OI6QVhcXEzT9NChQ8m3CoUiKirK4jq1t31sOdbTwR5Cu2FZtqysLCYmpl/T9sxzZcj4\nwQceeMD0aExMTFJS0qlTp9RqtZWT8HwaMtxtIySWWluoqKgAgO7JRuS6BAWhR0Aso332EFIU\nlZaWVlVVVVBQkJCQ0Of+COICSIXw66+/vnPnzpw5cyw86hkZGWKx2Dxo1CMaCOHubPq2tjYb\n9ycXAzh2gkP+EypjnyDEXBlkoOO6HkK1Wu3t7W1u6vD19W1tbbVlH19fX+vHFhUVffbZZ6Zv\n165dm5CQ4JQfw2nExsYCQEtLi6+vL1fnFIvFHJ6Nt9TU1HR1dcXFxfXrhyUGudu3b0skkgMH\nDoSFhc2bN8/c+bl48eJ33nnn9OnTDz30UG8nyc/Ppyjq3nvvderrLBQKaZq2r3mPXCeVlZXZ\nuMKqqioASElJsdg/OjoaANrb2wfDb5TzoCiKoihnv4YtLS1isTgqKqpPE924ceN++uknvV4/\nadIk/J/tFwKBgKIojOHhnJEjR/r4+JA7U8uXL7f4tfT19U1PT79w4QJFUSTkvaCggKKoe+65\nx+5fYPK27+3t7fDarUF6em3/829oaJBKpVFRUU5dlavox7wN5/GfUJn+9xACQD0VwgIV4gmj\nCPnwTj7AWroGCS79MLO4OmFZ1vZ9rB+rUqnMPSSPP/64WOxhjb8BAQFeXl4NDQ0crpyiKI97\nHeyA9AHGx8f364dNSEiQy+VXr149dOhQS0vLqlWrLBTX/fff/8477+zbt88ib9OEXq8vKChI\nSkpyjavHvjZF0id25coVG1+csrIyhUIRHh5usZ1saWxsHAy/Uc7G2a8hmSRB03Sfe5r6BidN\nmoT/s3bQL1cCYiNpaWknTpzw9/efM2dO91/LSZMm5eXlFRQUZGVlGQyGgoKCxMREx8NXnP37\nT+SrRqOx8Ynq6+tDQ0Pxr5JD7B47AQA6oDtB7s1acwzxBD78zliMXkA8AtcJQj8/P7VabR6x\n1draahF70Ns+fR47efLknJwc07dGo9ETm/ECAgLq6uo4WTlFUUqlUqfT2W5Q8VxIRnlISEh/\nX7q4uLirV6+S2vK8efMsDh8yZEhkZGR2dnZNTU2P19YFBQWdnZ0jR4509i+bXC43GAxardaO\nY2maDggIuHjxoi2LZBimtLR02LBh3Xcmarm8vNwT/7L4A3nXIpZO59HU1BQWFmbL/5QpmDEp\nKQn/Z/uFRCIRiUT9GjWO2EhycvKJEyfmzp3b4+cX8ZQeOXJk5MiRFy9e7OjoSE9Pd+S319vb\nm6bp5uZmp5Y1yB29qqoqW5ZqMBiampqGDBkyUP4qeRG6RlJGNWBnUHaHQK5kPOC/gw+/M2Kx\nuMcp7QifcZ0gHD58uF6vv3XrVnx8PAC0trZWVlZahPX3tk9ERIT1Y0UikfkvX2trq9FodNEP\nxh0BAQHXrl1jGIbDtLQey7ADjNLSUgCIiYnp7w+blJRUVFT0448/xsfHp6amdj989uzZX3zx\nxc8//2wRbEAwZTM6+0Vm72Lf4YmJiadPn25tbe3zDbq2tlar1Q4ZMqT7c5FWlvr6+sHwG+Vs\nnPoakttAycnJtjxLeHh4aGio0WgcOnQo/s/2Cwf/KhErTJ8+fdu2bcuXL+/x5SW5MufOnWNZ\nliTKjBo1yvH/CGf/b5p6CG15lsbGRoZhgoKC8BeMQ0iojH0powDQAYpgqJOwWvtMpy6DD78z\nzliDs03diOvsLv7+/hMnTvzkk09u3bpVWVn54YcfxsXFkVlnR44c2bdvn5V9rBw7kAgMDNTr\n9S0tLe5eiIdhx8wJgumeAhk/2J25c+dC71mjRBDyOVGGkJSUxLLsjRs3+tyTmG+7J8rA3XFY\nOHaC/5DyY0BAgI37f/XVV9u3b+d5ZD8yqJg6dWp5eXlvc1CCg4NjYmLy8/ONRiOJ9eJ/ogzc\nFYQ2lpRx5oQzcMQyCgAdIAcAGbRzuSYE4Q0u7X/49a9/PWzYsN/97nfPPfecl5fXyy+/TK5C\nCgsLTR2Ave3T2/aBBHn350O537MoLS0VCAQk9aRfmAThokWLetxhwoQJSqXy4MGDPRacc3Nz\nfX19SdWaz5gP2LAOkdY9CkKapn19fVEQ8h8yc6LPqfQmMjIyMjIynLkiBOGYzMzM9vb2q1ev\nnj9/XiaTWViN+Em/xk7gzAlnQLNaBgR6e51xHZQCAORg6yRJBPEsXBoqI5PJ1q1bt27dOovt\n69ev73Of3rYPJMhN/cbGxri4OHevxZMoKyuLiIiwJULDAlJkHjNmDIl47Y5QKJwxY8bOnTvz\n8/Mthg3W1NRUVVVNmzaN/6kSZPKELYKwt5kThKCgIBw7wX9IhbDPqfQI4rmMHTt2586dBw8e\nLCkpmTBhgkdkvfZr7AS59YYzJ7jFCzRakLBgZy2hi5IDgJxtt/cECMJr+H4tO6jAUYR2oFar\nVSqVHX5RAAgNDf38888//vhjK/vMmTMHenKNkt4VPo+kN5GQkEBRlC2C0IplFACCgoLUarVG\no+F4fQinkAohCkJkAEPeeLdu3cqyrEf4RaGfllFy683x6FTEHAmr0TnQ/tcOMgCQo2UUGaCg\nIOQRxDKKgrBfEA1jnyAEgMWLFw8fPtzKDtOmTfPy8tq9e/ft27fNtxOTM/8bCAHAx8cnMjLS\nRssoRVG9mW/J7ye6RnlOf3sIEcTjGD58uL+/P3kv8ixB2N5uk5wgPxoKQm6hQWt3ogwAdBLL\nKIvBwsjABAUhjzBZRt29EE/C7kQZG5FKpb/61a9qa2tnzpx56NAh0/bz588LhUJPab5KTExU\nqVSkL8UKFRUVISEhFvMYTWCujEdAmpCxQogMYAQCgelmnKcIQtJDaKMgxAoh5wiAEYPBMUEo\nBwAZCkJkgIKCkEcQyyiGyvQLMnNi6NChznuKDRs2fPzxxxqN5tFHH924cSPDMFqt9uLFiwkJ\nCZ6Sg5yUlAR9tRFqNJq6urre/KJw9+oE2wh5DqkQ2h4qgyCeCHGNRkVFeUrySr8so5cuXfLy\n8oqIiHDyogYREtBSwDoyMaIdFICCEBm4oCDkEUQQYgWmXzi7QkhYvnz5vn37wsLC/vCHPzz6\n6KMnTpzQ6XQe0UBIICl8169ft7JPRUUFy7JWBCFaRj0C7CFEBgPjxo0DDzHtE2y3jNbV1RUX\nF48ZM0YsFjt/XYMFmtWCA0MIAS2jyEDHA7K5Bg8YKmMHViYlcEtGRsbRo0efeOKJw4cPHzt2\nDDzqWsSWoFHriTKAgtBDwAohMhgYM2bMK6+8MmPGDHcvxFYkEolYLLZFEJ48eRIAJk2a5PxF\nDSIkrENDCAFADyIt0HIKQ2WQgQlWCHmEVCqVy+VoGe0XZWVlSqXSx8fHBc8VGBi4e/fu//mf\n/9HpdOAhEaOE+Ph4kUiEgnAwoFKpKIry8/Nz90IQxIkIhcJnnnmGmOE9BblcjoLQXUgoLQBo\nwH5BCACdlELOYIUQGZhghZBfBAYG4gW37eh0uurq6vT0dJc9o0gkevvttzMzM4uLi53auMgt\nNE3HxsbeuHGDYZjeBif2WWslghB7CHmOSqXy9fX1iMlsCDKoUCgUtvQQnjhxQi6Xjxw50gVL\nGjyQCqGe6ve8YnM6Kbkf2ywEoxGEHK0LQfgCXjTwi8DAwMrKSoPBgNdztlBRUWE0Gp3dQNid\nBQsWuPgZHScxMfHmzZsVFRW9vVxkKr2VFxNTRj0ClUqFflEE4SFyuby6utr6Pnfu3CkvL582\nbRo2EHKLhNWAYz2EANABcgpYKXSRgBkEGUigZZRfBAYGMgzT0tLi7oV4Bq5JlBkY9Bk0WlZW\nJpFIrASdSyQSHx8fFIR8xmg0tra2oiBEEB5CKoQsy1rZ58SJE4B+UScgoTTgsGW04z+5MthG\niAxAUBDyCwwa7RcoCG2nT0FYUVExZMiQ3gylhKCgILSM8pnW1laGYTBiFEF4iEKhYBimq6vL\nyj6kgXDy5MmuWtRg4W6ojGMVQkoOKAiRAQoKQn5B6jN9DhBHCEQQelAvnxuxLggbGxs7Ojqi\no6OtnyQoKEitVmu1Wu7Xh3ABRowiCG+xZfLEqVOnfH19U1JSXLWowQINjo6dAIBOMooQMFcG\nGYCgIOQXZBBtn20GCAErhLYTExMjlUp7G0Vo4ys5OINGKysrly9ffunSJXcvpG9wCCGC8JY+\nBWFJSUlVVdX48eOFQsws4RhuKoQgAxxFiAxQUBDyCyIIq6qq3L0Qz6CsrEwqlVppe0NMCASC\nhISE27dvk5kZFpCZE31WCAdnrszOnTsPHz782GOPEbnFZ8gKsUKIIDxELpeDVUGIAyechwQ4\nGDtBeghlKAiRgQgKQn4RHh4OWCG0DZZly8vLY2JiKIpy91o8g8TERL1ef/v27e4P9TmEkDA4\nK4SnTp0CgMrKyqeeespoNLp7OdZAQYggvIVUCK1MnsAGQudBs1oA0DowmB4AOik5ACjQMooM\nRFAQ8gsiCLFCaAs1NTUajQb9oraTmpoKAOfOnev+EBGEfb6YpEI4qHJldDrd+fPn4+Lipk6d\nevz48ffff9/dK7IG6SFEyyiC8BDrllGWZU+ePKlUKhMTE127rkGBF2gAQOdYDyGZNiHDUBlk\nIIKCkF/4+fnZMqoIAUyU6T/33HMPABw9erT7QzZaRgdhhTA/P1+j0UyePPmzzz4bMmTIxx9/\nvH//fncvqldIhTAgIMDdC0EQxBJiGe2tQnjjxo2GhoaJEydaj3pG7INmtQwI9I4N39ZQUgYE\naBlFBiT4vsM7IiIisEJoC0QQ9ulyREwMHz58yJAhx48f7x4TWlFRERAQQG5gW4EIQk+pEB44\ncGDv3r0OnuT06dMAMH78eH9//7/97W80Ta9bt66kpISLBXIPhsogCG8hb7BtbW09PooNhE5F\nAlotSFhwqMGEBaqLkikAK4TIAAQFIe8IDw9vb29Xq9XuXgjfKS0tBawQ9pMZM2Z0dnYSkWNC\np9NVV1fbYr71rFCZDRs2rF+/3sGTkNdqwoQJAJCWlrZx40a1Wv344493dnZysESuQcsogvAW\n6z2EpFcZBaGTkLAaByNGCR2UHCuEyIAEBSHvwDZCG0HLqB1kZWUBwJEjR8w33rlzx2g02lJr\n9SDLqNForK2tbW5u7jFV1UZ0Ol1eXl58fHxISAjZ8sgjj/zyl7+8du3aunXrOFoplzQ1NQFa\nRhGEl1hJGWUY5vTp0yEhIfHx8S5f16BAAlotJ4IQvEVgIEMsEGQggYKQd+AoQhspKysTiUTk\n5UJsZOLEiVKp1EIQ2thACABeXl7e3t4eIQjr6+sNBgPLso6s9sKFC11dXaQ8aOLdd9/NyMjY\ns2fPt99+6/AyOaalpUUmk9E07e6FIAhiiZVQmatXr6pUqkmTJg3I0OyZMzlQYo4gAEYMei3L\nSYVQBgAydI0iAw4UhLwDRxHaSHl5eUREhFgsdvdCPAkvL6/JkyeXlZXdunXLtNHGiFFCUFCQ\nRwjCmpoa8oUjqzX3i5qgaXrTpk0A4HiDIueoVCosDyIIP7FiGT1x4gSgX9RpSP4zc4KTCqEC\ncDY9MhBBQcg7cBShLbS2tjY3N6Nf1A6mT58OAD/++KNpi41DCAlBQUEtLS2O+DBdg+kvyBFB\nSLp6LAQhAMTHx0dFRZ07d45vYwmbm5txCCGC8BMrFcIBP4HQvUVCGjgYQkggowhRECIDDxSE\nvAN7CG2BJMpgxKgdzJgxAxwThOAJbYSOVwhJA+GwYcNCQ0O7Pzpx4kS1Wn3x4kX7l+gYph/Q\nRFtbm06nw0QZBOEnvfUQGgyGs2fPRkZG4ieak/hPhZDlQBB2gBwA5BRaRpGBBgpC3oE9hLZA\nEmVwKr0dREVFJSYmnjlzxnRdUl5eLhaLyZ2IPvGUoFGTXrJ7SEZBQUFXV9fEiRN7fJRsJyVE\n13Po0KHU1NR//etf5hsxYhRB+ExvFcKLFy+q1eoB7xd1Y5FQAhrgyDKKFUJkoIKCkHcoFAof\nHx+sEFoHBaEjZGVl6XS6n3/+mXxbUVEREREhFAptOdZTRhE6bhklDYT8FISkqPv555+bbyRD\nCNEyiiD8xMvLSyQSde8hxAmEzkYCWgDQASehMgoAwMkTyMADBSEfiYiIwAqhdXAIoSOQ4RPE\nNdrS0tLS0mK7tPa4CqHdS+2tgZAQFRVF2ggNBoN953eE1tZWACgsLLxw4YJpI6kQoiBEEN6i\nUCi6VwgHjyB0V5FQAjrgLFRGDgBy6FkQBrH1icYrjj8LgrgeFIR8JDw8vKuri9zvR3oEK4SO\nMHbsWB8fn6NHj7Is268GQvCcHsLq6mrSsWPfUq03EBImTpzY1tbmljbClpYW8sXWrVtNG8kQ\nQhSECMJb5HK5hSBsb28/derU8OHDcYSS85BAFwBouagQdlIkZbTnHsKZ+uz7Df+Usp2OPxGC\nuBgUhHwE2wj7pLy8PCgoiFzxI/1FLBbfe++9NTU1V65cqaioANuGEBI8wjLKsmxNTU1MTIxc\nLrdPEBYWFnZ2dvZWHiS40TWqVqsBQCaT7dmzx3TnCHsIEYTnKBQKC8vo0aNHdTrd3Llz3bUk\nF+OWIqGE1QCAjosKoR5EWqBlvQjCYLaOAjaI5fXnI4L0CApCPoKTJ6yj1WrJ5b67F+LBmFyj\nxHw7wCyjKpVKq9VGREQEBQXZp12JzOutgZBALF6k1dDFEO332GOPaTSaHTt2kI1YIUQQniOX\nyzs6OliWNW354YcfAGDwCEK3QIMOADTAQcooAHRSCnlPNUAp2ymDDgBAQYh4IigI+QjOprdO\nWVkZwzDYQOgIM2bMEAgER44cIRVC2y2jHiEIyc2U8PBwu6cm9jiS3oLIyMioqKizZ8+6vo2Q\n9BCuXbtWIpH8/e9/ZxgG7qpEHEyPILxFoVAYjUaNRkO+1ev1OTk5YWFh6enp7l2YK3F9kZCM\nneCkQggAHSD3gi4hWA6hDYY68kUgg4IQ8TxQEPIRrBBap79tb0h3AgMDU1NT8/PzCwsLoT+W\nUS8vL4VCwXNBSBJlQkNDQ0JCWJYlpTPb0ev1ubm5sbGxYWFh1vecNGlSe3t7UVGR/Wu1i9bW\nVplMFhoaumDBgrKysmPHjgFaRhGE95DJE21tbeTbkydPtra2zpkzh6Iot65rgONFxk5w0UMI\nAB2UggJWCl0W24PYBosvEMSDQEHIR7BCaB2MGOWErKwso9FYVFTk4+PTLxURFBTEc0FoXiGE\n/tczCwoKOjs7rftFCaSE6Po2wpaWFj8/PwBYuXIlAHz55ZeAllEE4T2k793URkj8ovPmzXPn\nmtyBi4uEYpakjHJlGZUDgJyxbCMkhUEWKLSMIp4ICkI+QiqEKAh7g1QIsYfQQUgbIfS/1mq3\nD9NlmCqE9kXg2OIXJZA2QtcLQrVa7evrCwBjxowZMWLEjz/+WFlZ2dzcTNM0Ji0hCG/x9vaG\nu7PpGYY5ePCgn5/f+PHj3b0uN+BKTchthbAdFAAgB0tBSHRgjSBCBh2yXuZSIAhvQUHIR6RS\nqVKpRMtob9y5cwf643JEemTkyJGBgYHQf0EYHBzMsmxjY6Nz1sUBRBDaUiHcv3//Qw89tGvX\nLnN9a7sgjIyMHDJkSG5urivbCPV6fUdHh4+PD/l25/uiEAAAIABJREFU1apVRqPx66+/bm5u\nRr8ogvAZcr+GCML8/Py6uroZM2aIxWJ3r2uAQ7NaBgR64OZ17qLkANBd8gUyDW2UTyUVTb7m\n5LkQxGWgIOQp4eHh1dXV5llkiInKykr6/7V35+FtVOf+wN/RvlleYlveE8eOHS9ZgRCaPWQh\nUJaSUrYuF0hLKf2ltJRCny7PU+gtvZQLXLil91IutJQSmoaQkBKSQICEQDay2AnZvMZr4l2y\nJdlaZn5/nEQotuR4kTQzmu/nr3g0kl47GltfnXPeo9Ox9/owZiqV6tprr6XRj7VKfytCFggz\nMzMvO0L41ltvffjhhw888MCsWbOeeuqp8+fPswWE+fn5bKD+subNm9fX18eWYsYG23OCTRkl\notWrVycmJr7++usdHR2YLwogZWwNIZsy+t5775Gy+4vGbJDQQAMR2ZWecZKJiCyX7jxhEvpM\n5GznbB1cGqHRKMgQAqFEZWdnezweKQ/CiKipqSk7O1ulwqt3vNh7kbKyslHdS/pbEba0tFgs\nFqvVetmeqE1NTVqtds2aNW63+w9/+MPs2bPvvPNOp9M5kuFBJva7EbIWo2zKKBGZTKZvfOMb\nHR0d/f39CIQAUsYCIRsh3Lp1q8FgWLp0qdhFiSk2mVBP/Z4IzRclIqfKQkSDdp9njWTaubR2\nLp3QaBRkCG+pJQrLCMPp7e3t6enJzc0Vu5B4cP311+/bt2/16tWjupf0d55obW1lV9BlBzMb\nGxszMjKefPLJioqKJ598Mjc3d9euXXS5HQiDxT4Q9vT0UFAgJKJ77rmHdSnElFEAKQsEwlOn\nTtXU1CxevNhkMoldlMhikAl1QkRHCAULEVkunTKaRhcCYQeXLhCHRqMgOwiEEoWdJ8JhCwhz\ncnLELiROFBQUjLbjucRHCHt7e3t7e9mOEcMHQrfb3dXVxT5cSEhIWLNmzd69e//xj3888sgj\nI+/7l52dPWnSpAMHDni93gh9B5cxaISQiKZMmcLa22CEEEDKAmsIMV80ZlTEa8k7EKFd6YnI\nydYQCr3BB1P954moQ2Ub4PR9XEJgT0IAuUAglCi28wQC4VCNjY1EhBFCEUl8DSG7alggNJvN\nJpMpXKlNTU2CIAR/uMBx3NKlS3/2s5+N6mP7efPmOZ3OmC0jZIEwsIaQuffee4koIyMjNjUA\nwBgE1hBu3bpVrVavXLlS7IpiYerUy7TcjOogIduVPlItRomonzP6SW0aPGW0TSCuk0slonbO\nZhRcaDQK8oJAKFHYijAcFggxQigiiU8ZDXSUYV+mpaWFG8yM1GhzjGeNDp0ySkQ33HDDG2+8\ncf/998emBgAYAxYIT58+XVFRcfXVV2NIPyB6mVDP9pyI3JRRgTg3GS2XbjuRRu29nLWfDETU\njr4yIEMIhBKFQBgO+5lghFBEEh8hDOw5wb5MT0/v6ekJOZ8zsoGQbVYRA0OnjBIRx3HLly8P\n7EUBABLEpoxu27ZNEAQF7kc/vChlQj0NENGAELEpo0Tk5Cwm4csBQJPQZxRcLAfSxUCInSdA\nXhAIJSozM5PjOEwZHQojhKIzmUzJyclnz54Vu5DQBgXCtLQ0nuc7OzuHnhmpQJiVlZWfn79/\n//7YLCMMOWUUAKSPjRC63W4iWrVqldjlxM5lZ40y0ciEOjZllItkIHRxFg352H739GWLURv7\nsoNLJ4wQgtwgEEqUTqdLTU1FIByqsbFRrVaPcI84iJLS0tKmpiY2d1Fq2BhycCCkMOOZEVyP\nOm/ePJfLFZtlhOzHjkAIIDssEBLR9OnTMc8lpIhnQjZC6CFdBB/TyZmIKDBIyLJfx8URQtZo\nFCOEIC8IhNKVnZ197tw5v98vdiHS0tjYaLPZtFqt2IUoWllZmSAIJ0+eFLuQEIaOEFKYQNjU\n1MRxHJuePU6xXEYYcg0hAEgfmzJK6C8aQ4ZIryEkIidZaEggZDsQsudCo1GQHQRC6crKyvJ6\nvZJt7i8Kj8fT0dGB+aKiKy8vJ6IvvvhC7EJCaG1t1ev1gR35htkko6mpacKECUajcfxPes01\n1xDRwYMHx/9Ql9Xb20tEWC4IIDtGo1Gj0ZDC5ouOVmQHCdmU0f7IbTtBRC7OTETmi4EwlW8T\niOtSpQZOQKNRkB0EQunCVoRDNTU18TyPmTaiKysrI6Ljx4+LXUgILS0tGRkZgc0Vw/VE9fv9\nra2tkfpwITs7OyUlJTYJuaenR6PRBIYaAEBGJkyYMHny5NLSUrELibURLiNkIpgJWZdRT+S2\nnSCiPjITkflio9HgFqMMGo2C7CAQShe2IhyKdQFBIBRdcXGxRqOR4AjhwMBAd3d38BLTcFNG\nW1tbfT5fBEeby8vLm5ubu7u7I/WA4djtdqvVGki8ACAj//znP998802xq4gRzu3SffKhtvLw\nGO4bqUyoIw9Fesqoi7PQxRFCM13SYpS5GAixjBBkQyN2AVFhMBgMhkhODxBFQUEBEXV0dCQk\nJIztETQazZjvK03sbX1hYWGcfV/D02g0Wq1Wp4vkmvhxSkhIKCoqOn36dGAGlES0tbUJgjBx\n4sTAKyQ/P5+Iuru7B71murq6iKigoCBSr6WZM2fu3r27vr4+Ly8v3DksxY3zGe12+4QJExR1\nCUiQ6iKxC4HxYr/BLBaLIAgxeLo5c+bE4FmkQq2mA59RRpZh3iIiIuJHde8VK/Q7dgyMswS9\n0E9EnggHQjMRmYQ++nIBoS34hA6VjYhS+bbYD7tI4U9DbC4liCwJvZOLIK/XGwe9WNhUt/r6\n+v7+/tHel+M4vV7P8/wY7itltbW1RJSRkRFn39fwDAaD3++PzZYGI1dWVnbixIkvvviiuLhY\n7Fq+VFdXR0Q2my3wCmHNV1pbWwe9ZmpqaogoMzMzUq+lkpISIjp8+PAwb/i0Wi3HceN5RkEQ\n7HZ7fn6+oi4BCdJqtWq1Gv8LcYAF+/7+fryLjTyVSpedq2pqGGhvExKs06bRsWOj+2Rz/JnQ\nQGwNYWSbypiJyMy5iCiNZ3tOXDJC2EFpAnGiTBmVwi8ltVotdgkwavEZCCX47nkMbDYbETU1\nNY3he2EDETzPx8HPIRjb+y4zMzPOvq/h6XQ6Cb6kWf6pqKiYPHmy2LV8ie0kYbPZAj8uvV5v\nNBrb2toG/QAj/lqaOnUqEVVUVAz/gIIgjOcZHQ6H3++3Wq1Sez0ojUql4jgO/wtxgOVAn8/H\n86Mbv4KR4AqK9I1nhdMnvTNmExGNfvuHcWZCHduYPqJNZZwXmsr0EVHqhT0n0oNPYI1GRQmE\n+KUEY4PpLtJls9nUajXWEAaL1E7iMH6sr8yJEyfELuQSbM+JzMzM4INpaWlDu4xG/LVUVFSk\n1WqHX1f50ksvvfjii+N5FofDQWgxCgAy4SsoIiJNzZnxPMh41hPq+QGK9JRRH2kHOH1gyqhA\nXOelI4SERqMgNwiE0qXVatPT09ku28A0NjampKSYTCaxCwGJNhoNGQjT09O7u7t9Pl/wQTaW\nGMFAqNPpCgsLT58+PeiJAnw+389+9rNf//rX43kWu91O2JUeAGSCT5nAJ09Qn63lvF4aZa/R\nYGPOhDoa4EnlpQjvXewii5mcRJQqtPdy1qFNa9BoFOQFgVDSsrKyhk51Uyy2TwBajEqEzWZL\nTU2VWqNRNqIe3GWUiNLS0nieZ11kApqamsxmc0pKSgSfvby8fGBgoLq6OuStJ06c6O3t7e7u\nHs8aD7YrfWCXRQAAifMVTOF8PvXZ2nE+zooV+jHEQgMNRLbFKOMkk0Hotwp2o+Bqv3S+KING\noyAvCISSlpWV5ff7z58/L3YhknD+/Hmv14tAKB1lZWWtra2Dgpa4Wlpa1Go1a8gUEHLniaam\npojPPWZ7i4ULyQcOHGD/GLoHxsixQIgpowAgF77CCMwaDRhtJtRTf2QXEDJOlYUjIU+oJ6KQ\ngfDLRqMAcoBAKGnYijAYFhBKDZs1KqlBwtbW1oyMjEEtzlggDF5G2NXV5XK5Iv5aGn5d5f79\n+9k/zp07N+anYFNGWetUAADp82fnkdGkqT5DEerjOqpMqBP6ByLaYpRxChYimsTX0ZAWo4yI\njUYBxgCBUNJYIMQyQibii75gnEQMhO+///7Q68Ln87W3t2dkZAw6PjQQRunDhfLycgq/rvLg\nwYPsH+MZ82dNZRAIAUA2VCrvpMmcy6k+30rjWEYYbISZUEW8lnyR7SjDsEajE/k6GtJilBng\n9L2cFYEQ5AKBUNIQCIMhEEoNyz+xD4QNDQ133XXXT37yk0HHz58/7/f7B3WUoYtbegZP1IzS\nayktLS0tLS3kD6Spqam5uZkNXY4nELIpowiEACAj/oIiIlJXR2bWKDOSJYV66ieiaIwQsr3p\nk4RugbhOVYhASEQdXDoajYJcIBBKGuuNgSmjDBvVycvLE7sQuGDKlCk6nS72jUYPHz5MRLt2\n7Rq0GI9dKexjlGBD1xCy11I01qOWl5efP3++o6Nj0HG2gHD+/Pk0vkCILqMAIDu+yYWkVmtq\nTrMvIzJIyAyfCfUC25U+8msIWSAkIgeXOBBmc0U0GgUZQSCUNATCYBghlBqtVjtlypQzZ854\nPJ5YPm9FRQUR+f3+zZs3Bx8PuecExTYQhptGywLh6tWr6dLJq6PFRggRCAFARgS9wZ+dq247\nz9l7Iv7gwwwV6inymxAyzouBMOQCwuCb0GgUZAGBUNLS09O1Wi2mjDLNzc1msxkN9yWlvLzc\n4/HU1NTE8kkrKyuJiOO4t956K/g4a9Yy8kA4dCxx/MI1Gj1w4IBWq73xxhspEmsI0WUUAOTl\nwg71tVXsywgOEjIhM+HFKaNR6DIqWNg/Qi4gvHATGo2CfCAQSpparbbZbAiETGNjI/ackJrY\nb08vCEJFRUVeXt7cuXM///zzurq6wE3sShm0CSERWa1Wg8EQPC7X2Nio1WqHtp8ZP7auclCj\n0b6+vhMnTkyfPj03N1en040nEHZ3d3Mch0AIAPLiKyymyG0+EdLQoUI2ZTQqI4SqwAhh+ECI\nRqMgHwiEUpeVldXR0RHjKXkSFKV9AmCcYt9otL6+3m63z5gx49ZbbyWiTZs2BW5iU0aHBkIi\nSktLGzRCOHR3iogIua7y888/9/v9c+bM4TjOZrONc4TQYrFoNJpxVwoAEDt8UjKfkqpuqOei\n/H4mOBOyKaPRaCrTT0Y/qYmoI0xHGUKjUZAVBEKpy87OFgSBvdNVMraAECOEUhP7RqNsAeGM\nGTNuvvlmnU63YcOGwE0tLS0cx4Uc90tLS+vq6vL7/UTkdru7urqi9FrSaDRFRUVVVVXBH+Kw\nBYRz5swhoszMzI6ODp/PN7bH7+npQYtRAJAjX2ER5/er62vZlxGfNRoQGCrUXWgqE/lAKBDn\nJqNAXGf4NYRE1M6lGQWXSeiLeAEAkYVAKHVK23miqakp5II0FgijsegLxiMlJSUjIyP2gXD6\n9OnJycmLFy8+c+ZMYDiutbU1JSVFpwvR8C0tLc3v93d1dRFRU1OTIAjRG21m6yqrq6sDR9gO\nhFdddRURZWRk8Dzf2dk5tgd3OByYLwoAcnRhGWE0Z40GW7FCP2Oym4j6OWM0Hr9eXVCrKgjX\nYpQ5p8oiolyhMRoFAEQQAqHUTZ48mYj2798vdiEx8s1vfvP6668fOkU2em0hYZzKysra29vH\n0zlzVAIjhHSxaefGjRuJSBCEc+fOhZwvSpf2lYnSrvQBg9ZV+v3+zz//fOLEiTabjS72vBnb\nrFGPx+N2u9FiFADkyJ+VIxiNmtoqEgR2JHqDhIy17bTAqQqXFkbjwTdrVr+p/fbw59RxBUSU\n768e/jQA0SEQSt1NN91kMpleeeUVr9crdi1R19fXd/Lkya6uro8//njQTZgyKlmxXEYoCEJl\nZWVeXl5KSgoRrVq1ymw2b9y4ked5ttQ23Bgy25uepdZov5YG/UC++OKLvr6+uXPnsi/ZjNax\nBULsOQEAMqZS+fOncC6nqjUWk540A30We5MzOc+vM7FJpJfdyD7imlR5A6QrEBAIQeoQCKUu\nMTHxtttuO3fu3Lvvvit2LVF39OhRnueJaMuWLYNuivaoDoxZLANhXV2d3W6fOXMm+9JoNF53\n3XXNzc379+9n23UO3XOCif0IYaDRaPACwkCFYxtQZYEQawgBQKZ8hUVEpKs4FDgSvUHCpLZT\nJAg96VODD8Y4FvpJ3aDKTxK6U4QxLhMAiA0EQhlYs2YNx3EvvfSS2IVE3dGjR9k/tm3bNmhE\ntKmpSafTsUl3ICmxDIRsB8Lp06cHjgRmjYbbhJBhI4QsELIVudELhCkpKZmZmYEpo8ELCGl8\nU0axCSEAyJqvYAqfmq49XqE9cjDaz5V4/hQR2W0lQ2+K5YBhrXoKEU3mMUgIkoZAKANTp05d\nuHDhwYMHjxw5InYt0XX48GEiWrhwYU9PzyeffBJ8U2NjY2ZmpkqFV6zkFBYWGgyG2ARC9pFB\nYISQiBYvXpySkrJ58+b6+noa2QhhQ0MDx3FRbVBUWlra0dHBhgH379+fmJhYXFzMbhr/lNHk\n5OTIVQoAEDuCRutefadgNBk+3K4+e2EX2WgMEnK839pe5TEmuazD7Tcbg2RYwxUQAiFIHt5e\ny8N3v/tdInr55ZfFLiS6jh49mpiYuHbtWrp01qjT6ezu7sYCQmlSq9XFxcXV1dUx2C2zsrKS\n47hp06YFjmi12ptvvrm7u3vdunV0uUDIElpzc/OECROMxqj0nWMCu3E0Nzc3NzdfeeWVgc8y\nxhMIMUIIAHLHWxPdX7udOM74zgZVd7QmUiZ01mp8/T2hhgdDil4y7OYmdHMpE/laDY1xtyGA\nGEAglIcVK1YUFBRs2rQpZr0cY6+zs7OxsXHmzJnz589PTU3dunVrYK821gUECwglq6yszOv1\nnj59OqrPMqijTMDXvvY1ujhn9bJdRv1+f2tra7Q/XAg0GmX9gQMdZYgoIyNDpVKNLRB2d3cT\nmsoAgMz5s3P7V9zA9buNG9/k+t0UhUHCpLZTRNSTPtJAGBBIhhEMh7WqQh15c4SGSD0gQMQh\nEMoDx3H33HOPx+P561//KnYt0cImxM6aNUutVq9ataqrq+uzzz5jN2HPCYmLzfb0rKMM23Ai\n2Ny5cwOvjXAjhImJiXq9vq2trbW11efzRXtDy8C6ykEdZYhIo9EkJyePLRDa7XZCUxkAkD9v\n+UzP7Dmqrk7jlo3E8xF//MTzp3i1tjc1fzwPEhwOx5MPa1WFRDTZH2KPZQCJ0IhdAIzU3Xff\n/R//8R+vvPLKj370o5Bbb8sdW0DIlofdeOONf/vb3/71r38tXLiQsOeE5A3aeS9KgncgDMZx\n3C233PLCCy8kJiZaLJZwd09LS2tvb4/NhwsFBQVsXaVGo9FqtbNmzQq+1WazVVdXC4LAcdyo\nHpYFQowQAkAcGFiyQtXTramt0n+0Y+Da66ZOdZ46ZY7IIxv62g3Ojh5bCa+O5JulkJlwx46B\ny96xXlXgI81kvupDWh69Si7CxFQYCwRC2bBYLLfffvvLL7+8efPm2267TexyIo+93WeBcP78\n+cnJye++++6TTz6pVqtZW8hoj+rAmJWWllL0RwiHthgNWL169QsvvBBueJBJS0s7duxYQ0MD\nRX/6sVqtnjp1KkvI06ZNG7Re0WaznThxoqenZ7TtYVggxBpCAIgHKlX/DV8z/f0V3eEDfLrN\nO21WpDLhxfmiUy975viNbORQ7/5soq2r9oZFHq8+Ieo1AYwepozKyX333cdx3J///GexC4mK\nI0eOpKens9Sn1WpXrlzZ1tbGZtxhhFDikpKSsrOzT506FdVnOXr0KMdxQ0cIiaisrOy+++77\nzne+M8zd09LSfD4fS5UxWI9aWlrq8/l8Pl/wfFGG7Z4yhlmjmDIKAPFEMBjct94h6A36ndtV\nDnukHjbx3CniOLstFoFwhOzpU0gQrG1nxC4EIDQEQjkpLCxcunTpkSNH2M5m8aSxsbG9vX32\n7NmBIzfeeCMRvfPOO+xWlUqFEUIpy8vL6+zsHBi4/OSZsREE4dixY3l5eeFG1X7/+9+vWbNm\nmEdgfWXYzOQYfLjA1lXSpR1lGNZodAwNorDtBADEGT45ZWDxMs7rMbz3DgnC+LvLqL39Cd11\nLmuGxyih2fWOtCIiSmyvErsQgNAQCGXme9/7HsXj/hPB80WZxYsXW63Wd999l+f5pqam9PT0\nuFw5GTeysrIEQWhtbY3S47OOMiHni44QC4THjh2jmEw/ZusqKWhL+oAxjxA6HA6dTmcwGMZf\nHgCARHinzfJPmqxuqNN8UTn+R0tsP8Px/h5b6fgfKoKc1iyvPiGx/TQJgti1AISAQCgzS5Ys\nKSws3LJlS/TeeYsi0GI0cESn061YsaK1tXXv3r3nz5/HfFGJY+v3WlpaovT4Qz8yGK309HQi\n6u/vN5vNgzauiIbS0lKO4yZOnMji39BKxhAIe3p6MF8UAOINx/Wv+Kqg1Ro+3sG5nOMcJEw6\nH7sFhKPAcY7UKRqPy2xvFrsUgBAQCGWG47j77rvP6/Vu2LBB7Foi6ciRIxzHDXq7z2aN/u//\n/i/P89iEUOLYBoDRDoQhFxCOEBshpFhtaJmUlPToo4/+8pe/HHrTeEYIEQgBIP7wiUmeeYs5\nt1v/wXvjeiBBSGw/7dOZXUmSe89gt00hosR2LCMEKUIglJ9Vq1YR0d69e8UuJGJ4nq+oqBi6\n4fjSpUvNZvP27dsJu9JLXgxGCDmOG/+UUYrha+nhhx++5ZZbhh5ngXC0awh5nnc4HNhzAgDi\nkueKq/0ZWdrTJzRnTo15kNDc3aAZ6LPbpgqc5N7f2tOKieMQCEGaJHfBwGVlZ2fn5OQcOHCA\nj8JerqKorq52OBzBHWUYg8GwfPly9m1iyqjEsRHCKM1kZh1lJk6cOJ5+KoFAKPpraWwjhA6H\ng+d5jBACQHxSqQZW3URqteGDrVy/e2yZMJYbToyWT2d2WrPMXWc1vn6xawEYDIFQlubOnWu3\n26Pd5T9mhi4gDGCzRkkCb+JheFENhLW1tXa7fTzzReniyj2SwIaWRqMxISFhtIEQu9IDQHzz\np6YPzPkK5+zT79o5tkdIajspqNSspacEOdKLOIFPaK8RuxCAwRAIZenqq68mon379oldSGQc\nPXqUwgTC5cuXm0wmwpRRyUtPT9dqtVGaMjr+BYRElJiYyBrVSuHDBZvNNrZAiBFCAIhj3msW\n8qnp2mNH1PW1ox0k1PY7TI5zvcn5Pq1EWzHbL2w+cVrsQgAGQyCUJbazWTwFQrVaPW3atKE3\nGY3GVatWWSyWiRMnxr4wGDmVSmWz2aIUCNlu8uNZQEhEHMelpqaSND5csNlsvb29Lpdr5Hdh\ngdBqtUatKAAAkQlqdf/KrxKR/rNdRDSqTJh0/hQJgt1WHK3ixq0veaJfo8f29CBBCISyVFxc\nnJKSsn//frELiQCv13vs2LEpU6aYzeaQJzz//POHDx82Go0xLgxGKzMzs7293ev1RvyRx99R\nhmHLCCUSCGmUfWUwQggASuDPyhESrCp7z2jvOKHlKBH1ZJREoajIEFRqx4QCvbs7oatW7FoA\nLoFAKEscx82ZM6elpaWhoUHsWsbr5MmTAwMDw+wvp9PpxtNKBGImMzOT5/lz585F9mEFQais\nrMzLyxv/y2DRokXTp09nDVHFNYa+MlhDCAAKwRtNnNvF9nAf4SCh3tWV0FnrTM7rN6dFubpx\n6c6ZSUTFe1/OqvqQE+KkNSDEAQRCuYqbZYTDdJQBeYlSX5mamhqHwzHOBYTMr371q507d6pU\n4v/eG8Pe9BghBACFEExm8vup382+HEkmTG08RILQnndVlEsbr86sGWfm3ufTmbNPbS/59EWD\ns13sigCIEAjliwXCOJg1ikAYN6K0N/2WLVuIaN68eZF9WHGNYYSwp6eHEAgBQAEEs5mIVCNf\nZS0IqY2f82ptd+Z4VxbEgD2t6Piih7ozy8zdjWW7/stWu4eNhQKICIFQrmbOnGk0GuMgEB4+\nfFin05WVlYldCIxXNAKhIAjr1q3T6XQhd3iXrzGvIcSUUQCIe4LJQkScqy9wZPhBQmt7lc7d\n0505XbL9RQfx6czVV367duY3BJU674stRQdeVXtG0WMMIOIQCOVKq9XOnj37zJkznZ2dYtcy\ndm63u6qqqry8nO0HALLG1uZFdsroZ599VldXd/3116ekpETwYUXHAuGo1luyEUIEQgCIeyFH\nCIfJhGlNnxNRe96V0S4ssjpzrzi+8KHeCQWJbaenfP46x/vFrgiUC4FQxq6++mpBEA4cOCB2\nIWNXWVnp8/kwXzQ+sEAY2RHCN954g4juuuuuCD6mFGDKKABAOLzJREScc3ACDJkJNR53UusX\nA+bU3pT8WBQXUR5T8qlrvttjK0norMn7YovY5YByIRDKGNuNUNazRtkCwmFajIKMZGRkqNXq\nCI4Q9vb2btmyJSsra+HChZF6TIlISkoyGAyjCoQOh0OlUiUkJESvKgAAKRBMZiKioCmjAUMz\n4YTmIyre15F7BXFcDGqLPI6rnX2nO8GWXr837ayMP+IHWUMglLE5c+ZoNBpZNxpFR5l4otVq\nU1NTIzhCuHHjRrfbfdddd6nV6kg9pnSkpaWNdoQwISFBCi1SAQCiy2whItWQEcKQJjQcJI7r\nyJkd5ZqiyK/RV1/1LZ/WMPH4JmxRCKLAewsZM5vNZWVllZWVrpF34pKYo0ePWiyWwsJCsQuB\nyMjKyjp//rzfH5mFEOvWreM47o477ojIo0lNRkZGd3e31+sd4fkOh8NqtUa1JAAAKeBNZiLi\nXKEDYfAgodnebHa02NOKPEZ5r6/uN6fVzL6bBKHw87/r+u1ilwOKg0Aob1dffbXX6z106JDY\nhYyF2+2ur68vLS2Ny/EfZcrKyvL5fKNqnhnOqVOnDh06NH/+/IkTJ47/0SQoPT2d5/n29pFu\nQtXT04MFhACgBILRRBynChMIKSgTpjZ+TkSJDcl1AAAgAElEQVQdkt9+cCQc6UXNU1dqBvoK\n9/9F5feIXQ4oCwKhvMl6GWF1dTXP80VFRWIXAhETwb4y8dpOJmBUO0+43W6Px5OcnBzlogAA\nJEClEgwGcoZYQxgwdaqT4/0pzUf9OlOPrSRmpUVVa8GizuyZZkfLpIq3xa4FlEUjdgEwLrIO\nhFVVVUSE+aLxJFI7T/h8vrfeestqtd5www2RqEuKRtVoFC1GAUBRBHMCZ+8e/pxy1SGNx3V+\n8nxeFS/vZjmufsZqQ2/bhObDie2n/BqDoFL71TpSa/wa/fmJ1/RklIpdIsSnmF5CfX19L730\n0sGDB30+X3l5+QMPPJCenj7Cc9auXVtfXx84zWAwrF+/PpbFS1NaWtrkyZPZj0ujkdkvxOrq\naiKaMmWK2IVAxERqb/pt27a1tbXdc889RqMxEnVJ0agCIduVHoEQABRCMJlUHW2c1ytoteHO\n0R4/SkQdufEwXzSAV+uq53yn8PAbmv5eld/Led06v1fF+4hIEAiBEKIkphHiueee6+joeOKJ\nJwwGw1/+8pfHH3/8+eefH9Q0L9w5fX193/ve99iAGBGh1V7A1VdfvW7duuPHj8tu8wY2QohA\nGE9YIBz/COG6deuI6M4774xATVI1hkCIXekBQCF4k1lNxLmcQmLo33ucw66ur/XbMvPmJJw6\nFePqostjTDox7weDDs5+79d6d48o9YASxC5WdXR0HDhwYO3atYWFhTk5OQ899FBzc3NFRcUI\nz+nt7c3IyEi9KCUlJWaVS5x8Z41WVVXpdLrc3FyxC4GIicgIYVtb24cfflhSUhLf+5FghBAA\nIJwLWxGGX0ao+6KCBME7bSaF2bA+zniMSToEQoia2AVC9u4/Pz+ffWmxWHJzc9kY0WXP8Xq9\nAwMDe/fu/X//7//de++9//7v/x7Bvc7kjgVC2e1GyPN8bW1tQUGB7Ga6wjCysrI4jhvn5blu\n3Tqfz3f33XdHqippYpPhsYYQACAEthVh+Eaj6oZ6IvJOLWNfxn0m9JiSVH6PxiPXbcZA4mL3\nXtzhcCQkJHAcFziSmJjIPva+7DkulyspKcnlcj344IMqlWrdunU///nPX3zxRbPZzE5raWkJ\nTkRXXnmlcoYQS0tLMzIy9u3bp9frAz869g+1Wm0wGEStLqyzZ8+63e7i4mLJVigdGo2G47jg\n60KyDAbDhAkTWltbx/Pfun79ep1Od/fdd8ffa4P9J7LvKycnR61Wt7e3j+TbdDqdRJSamhp/\nPxOZ0mg0Uv4FCyPHVqDo9XpBEMSuBb6kSkwiIp3XowlzlakcdjKZDMlfvtmbPVs4fFgGfyjH\nxmNIIiK9u9unMw1zmhR+Kcni7QoMEsVAuGfPnqeffpr9+8knn6QhL5GQv3xDnpOYmPjaa68F\nDj766KPf+c539uzZs3LlSnbk9OnTv/vd7wInvPjii3l5eZH5NuRg/vz5GzZsaGlpKS4uDj6u\nVqstFotYVQ2voaGBiMrLyyVboaRow6+ql5rc3NwTJ06Yzeax/Un49NNPz5w5s3r16kmTJkW6\nNKkIvObT09Pb2tpGcgn09/cTUUZGBq4XSZHRhQnDC3y+DBLBp6Z6ifQejzrkLz1BGOh1cLbM\nQb8S58+nPXvcMSoxtjzGJCLSuXucidnDnCaFvxE+n0/sEmDUohgIZ8+e/V//9V/s3xkZGQ6H\nw+FwCIIQeJtot9sHbauVlJR02XOIyGAwpKamdnZ2Bo6UlZX9/ve/D3yZnZ3d29sb8e9Isq66\n6qoNGzZ88MEHbAUXEXEcZ7FYfD6f2y3R34xsaeikSZMU9T81Nnq93u/3y+U3bEZGxpEjR+rq\n6tLS0sZw9zfffJOIvv71r8flC4Pl5L6+C6ti0tLSTp065XA4Lhue2XaFOp0uLn8scsRGCAcG\nBsQuBMbLaDRqNJq+vj6MEEoKx6m1RAPdnf6Qv/T6enV+v9+SEPwrUaVSGQyGGTN8FRVxuBRl\nwHQhEA5/mhT+RqhUKqwGkp0o/oeZTKaJEycGviwqKvJ6vdXV1ayrpN1ub2xsnDp1avBdwp1z\n9uzZLVu23H///ezjWLfb3dbWxnY8Y9LT05ctWxb40m63K+rv9JVXXklEu3fvvv3229kRFgh5\nnpfsz+HkyZNENGnSJMlWKB0ajcbn88nlB5WRkUFE9fX1Vqt1DHffunWrwWCYN2+eXL7fUTGb\nzYIgBL619PT0ysrK1tbWCRMmDH9H9vmXyWSKyx+LfOG/Iw7o9Xoi8ng8PM+LXQt8SaXTaYn4\n3t6QV5mqvV1H5LNYgm9Vq9U6nW5gYGDq1IFTp+JtyDcwQjj8aVL4pYSpE3IUu6YyycnJ8+bN\ne+GFF6qrqxsbG5955pnCwsKysjIiev/997ds2TLMOSkpKXv37v3jH/947ty55ubm5557zmq1\nXnPNNTErXuLKy8tTUlJ2794tow84q6qqOI7DrvTxh31SM7a+MmfOnKmtrV20aFEcbz8YjDUa\nZaN/w2NNZYZOlwAAiEusy6jKGbpVjLrPQURCQtg+W/HXY8ZjTKYRBEKAsYnpbn4//OEPCwoK\nfvnLXz788MMGg+EXv/gFmyh19OjRAwcODHNOQkLCb37zm87Ozoceeuixxx4jot/97ndSWDgr\nESqV6itf+cq5c+cGdW2VsqqqqqysLCzbiD/jCYTbt28nosDa4LjHAuG5c+cueya2nQAARRE0\nGkGr49yhcx3nsBORYB3uV+LUqc54ioUevVXgVHp3t9iFQHyK6Rxfk8n0ox/96Ec/+tGg4488\n8shlzyksLHziiSeiXqJsLVy48F//+tfu3buLiorEruXyuru7Ozo6Fi9eLHYhEHnj2Zt++/bt\nHMcFT/+ObyPfeaKnp8dgMOh0uugXBQAgCYLZHG6EkAVCfthAyEyd6oyP6aOCSu01WHUujBBC\nVMR0hBCiZ+HChUS0e/dusQsZkerqaiLCfNG4NOZA2NXV9fnnn8+cOTN4eXB8G/ne9A6HIykp\nKfoVAQBIhtlC/W7y+4fewvU6iIi3JIzkYeJmnNBjTNJ6+lS8PDrMgbwgEMaJgoKC3NzcTz75\nRBa9KNnUVgTCuMQC4RimjL7//vt+v18580VplGsIMV8UABSFN5lJELj+EM3SVQ47qVTCyAIh\nxcv00QFjEgmC1m2//KkAo4RAGD/mz5/f19d39OhRsQu5PDZCyHrJQpwxmUxJSUljCIRKW0BI\nFzuyXnaE0O/3O51OBEIAUJRh+sqoHHbBkkCq0b2JlXsmZI1G9f1YRgiRh0AYP2Q0a5SNECIQ\nxqvMzMzRBkKPx/PRRx9lZ2ezzsMKYbPZOI67bCC02+2CIGDKKAAoCm8yExHn6ht0nPP7ObeL\nTxjLzkayHiq8sPMElhFCFCAQxo9FixZxHCeLQHjmzJmEhAQ2PALxJysry+12d3eP4lPMTz/9\ntK+vb+XKlZfdoj2e6HS6xMTEkQRCQotRAFAYwWQiIhoyQsj1OkgQRtJRJhyZxsILI4TYeQKi\nAIEwfqSlpU2dOvXgwYMul0vsWobj8XgaGhqmTJmiqLf+ijKGvjI7duwghc0XZWw222UDIduE\nEIEQAJTFbCEilWtIIBzBnhMjIbtMyLYi1CIQQhQgEMaVhQsXejye/fv3i13IcOrq6nw+HzrK\nxLExbEW4fft2s9k8b968qBUlUZMmTXK5XKdOnRrmHIfDQURW61jmRwEAyNTFKaOhA+HYpowO\nIq+hwosjhGgqA5GHQBhXZLGMEAsI495oG42eOHGisbFxyZIler0+mnVJ0c0330xEb7755jDn\nsBHC5OTkGNUEACABgtlMoUYI1b0OisQIYYBcYqFPa/BrDTrsTQ9RgEAYV77yla9otVpZBEKM\nEMax0U4Z3bZtGylyvigR3XjjjYmJievXr/d6veHOwRpCAFAgwWgmInIOaSrTayciISHCvxJl\nEQs9xkSdu4cEQexCIN4gEMYVi8Uya9as48ePd3Z2il1LWNhzIu6Ndsro+++/r1Kpli1bFs2i\nJMpgMNx8883t7e0ffvhhuHNYIMSUUQBQFMFgILWaG9IWIYJTRodisVCyyXDAkKzyezVeSbeK\nADlCIIw3ixYt4nl+z549YhcSVlVVlUajyc/PF7sQiJZRjRC2t7cfPnz4iiuuSE1NjXJdEnXn\nnXcS0bp168Kd8O6773Ich0F1AFAWjhNMJtWQbSdUvb2CRisYjVF9cmnGQjQahShBIIw30l9G\nWF1dPXHiRJ1OJ3YhEC1Wq9VisYxwhHD79u08zytzvihz5ZVXFhUV7dixI+TA/ocffnjo0KHl\ny5cXFxfHvjYAABHxRjPncg2aIcn12oVYTaGX2oAhtiKEKEEgjDezZ882m827du0Su5DQWltb\ne3t7MV807mVmZjY3N4/kzO3btxPRddddF+WKJO3222/3er0bNmwYetMzzzxDRA8//HDMiwIA\nEJlgNpPfzw30B45w/f3cwEAEO8qMUCAZihsOB1ggRF8ZiDQEwnij0+muueaa+vr6uro6sWsJ\nAS1GFSIrK6uvr6+3t3f40/r7+3fv3j1x4kSFD3/dcccdGo3m73//+6DjH3300f79+5ctWzZ7\n9mxRCgMAEJPJQpfuPKHqdVDUFhCOkIjJ0GNKJiIdpoxCpCEQxiE2a3Tnzp1iFxICAqFCjLCv\nzCeffOJyuRQ+PEhE6enpixcvPnnyZGVlZfDx//zP/ySin/70pyLVBQAgJt5sJiLO+WX0ilKL\n0bEJHjaMTT68MGUUgRAiDYEwDi1atIiIPvjgAxFrcDgc3/jGN7Zu3TroOGsxivYYcW+EWxHu\n37+fiJYsWRKLmqTt7rvvpktby3z88cf79+9funTpFVdcIV5dAACiEUyDtyK80GJUkl2XB+XD\naKREr8EqcKpwgVA6ax1BdjRiFwCRV1JSkpqa+tFHHwmXrsPu7+/nOC42e3/v27fvo48+Onz4\n8KxZs9hgEYNAqBAsEJ47d27402pqaoioqKgoFjVJ24oVK1JSUt56663f/OY3rOXSH/7wByJ6\n5JFHxC4NAEAcvGnwVoQXp4xKYoRwJCIf0nYnmD1dyH4QWRghjEMcxy1YsKCtre3YsWNEdPbs\n2ZdeeunrX/96QUHBHXfcEZsa2Mw3u93+4x//ODiXVlVVpaamJicnx6YMEMsIRwhra2sNBkN2\ndnZMipI0nU63evXq7u7ubdu2EdHu3bsPHDiwZMmSK6+8UuzSAABEwqaMBm1FyEYIY99URjr4\nBCvndnE+n9iFQFxBIIxPbNboww8/PH/+/CuvvPIXv/jFrl27OI779NNPLztoExEsEJaWlu7c\nuTPQKsPpdLa0tGABoRKMZA0hz/N1dXX5+fkqFX4REV3ckPCNN94gDA8CABAJJgtdOmVU5bAT\nxwmiNpURF29NIkHgeh1iFwJxBe/D4lNgN8K6urolS5Y8+eSThw8ffuyxxwRBYF3+o62ysjIl\nJeVvf/ub2Wz+9a9/3djYSETV1dWCICAQKsFIRghbWlrcbvfkyZNjVZTUTZs2rby8/OOPP16/\nfv2+ffuWLFly1VVXiV0UAIBoeJOJLu0yyjnsgsEoaJS74ontwchGSgEiBYEwPuXl5a1bt+4f\n//jHmTNn1q9fv2bNmtzcXNbLMQaBsLOzs7m5efr06Xl5eb/5zW96e3vZxFG0GFWO5ORkg8Ew\nfCCsra0looKCglgVJQN33XWX3+//8Y9/TGguCgCKJ5jMxHFcYA2hIKicfbyC54vSxS03VL0I\nhBBJCIRx64477rjlllvMZnPgSGFhYUFBwa5du5zO6K5FrqioIKIZM2YQ0be//e2lS5fu2rXr\n1VdfRSBUDo7jMjMzW1tbhzmHdZRBIAy2evVqnU7n8XgWL148Z84cscsBABCVSkUGY2CEkOvr\nI7+fDZEpFls/qcIIIUQUAqGyrFy50uPx7Nq1K6rPwprZTJs2jYg4jnvmmWesVuvjjz/+8ccf\nEwKhYmRlZXV3dw/z6QMbIcSU0WApKSkrV67kOA7DgwAARMSbTF8Gwl47EfEW5S4gpIsdVjFl\nFCILgVBZYjNrlHWUYYGQiLKzs3/72986nc7Dhw8bDIacnJyoPjtIBNtM4tSpU+FOQCAM6emn\nn3777bevvvpqsQsBABCfYLJwHg/n8xKRutdBym4xSkRCYhJd3H4DIFIQCJXlqquuSklJef/9\n93mej96zVFZWWq3W/Pz8wJE777xz+fLlRFRQUICWkgpRUlJCRCdOnAh3Qk1NTUJCQnp6egyL\nkoGUlJR58+aJXQUAgCRc7CvjIiLWWlPJLUaJSNDpBIOBs4fYm157+gQ30B/7kiAO4K25smg0\nmmXLlrW3tx86dChKT2G328+ePVteXs5xXPDxZ555xmazLViwIErPC1JTVlZG4QOhz+draGjA\n8CAAAAxDYK0Q+vro4jxJhTeVIbYVocNBQZs8E5G6o83wzgbDu5vEqgpkDYFQcVauXElEO3bs\niNLjV1ZWCoLAOsoEy8jIOH78+BNPPBGl5wWpKSkp4TguXCBsaGjwer3oKAMAAMNhWxG6nXSx\ntSZbRKdkgjWJ8/s4tyv4oObYUSLylU4TqSiQNwRCxbn22mt1Ol30lhEOWkAIipWQkJCTk3Py\n5MmQt6LFKAAAXBZvNhMR53QSEWe3k1otBLVPV6YQjUZ5XnvyuKA3+AqLRSsL5AyBUHHMZvO8\nefNOnjxZV1cXjcdnLUanT58ejQcHeSktLe3u7g65GyE6ygAAwGUJJjMRqVxshNDBmy2k+E4E\nF7YiDAqEmtoqztnnKykXNBrx6gIZU/pFpUwrVqwgovfffz8aD15ZWWk0GgsLC6Px4CAvpaWl\nRBRykBCBEAAALos3mYmIXE42SVLhLUYZ9kMI3nlCe+woEXnLB6/WARghBEIluu666ziOi8as\nUafTWVNTU15erlarI/7gIDssEH7xxRdDb2JTRhEIAQBgOGYLEXHOPtZGBR1l6GJbnUAg5FxO\nTV01n5rmz8wWtS6QMQRCJcrJySkpKdm7d29PT4i2xeNx/PhxnueHdpQBZRp+hHDChAlJSUkx\nLwoAAGTj4pRRF8s/GCGkwJTRi1sRak8cI7/fW4a3XjB2CIQKdd1113m93o8++iiyD8s6ymAB\nITAFBQUGg2HoCOHAwEBzczM6ygAAwPAErVbQajmXk+UfXtmbEDKCJYHU6sAIoeZ4BalU3jK8\n9YKxQyBUKLb5xNhmjW7bti03N/fgwYNDb2IdZdBiFBi1Wl1UVFRTU+PxeIKP19bW8jyP+aIA\nAHBZgsnMOftYDxWF70p/gUrFmy3sB6I+36puP+/LLxTMFrHLAhlDIFSoWbNm2Wy2nTt3+ny+\n0d533759/f39zzzzzNCbKisrdTpdcTG6HsMFpaWlHo+nuro6+CDrKIMRQgAAuDyzhet3c/Zu\nIhKsWGhARCRYEzm3i/P5tMcriMiHdjIwPgiECsVx3IoVK3p6evbt2zfa+7J38zt37jx16lTw\n8YGBgTNnzpSVlWm12ogVCjJXUlJCRIO2p8cmhAAAMEK8yUyCoDrfSkR8QoLY5UiCYE0iQeC6\nuzQnj5HR5CsoErsikDcEQuUa86zR+vp6IhIE4X/+53+Cj588edLr9ZaXl0eoQIgHIfvKYM8J\nAAAYIdZXRt3ZIWh1gsEodjmS4LdaiUh35CDndntKygS0dofxQSBUrkWLFhmNxm3bto3qXoIg\n1NXVFRcX5+Xl/fOf/2xrawvchI4yMFTInSdqamo4jsvPzxepKAAAkA3eZCIi4nnBigWEF7Bu\nq9rjR4nIVz5T7HJA9hAIlctgMCxZsqS+vp4FuRFqbW3t7+8vLCy8//77PR7P//3f/wVuQiCE\nodLT01NTU4eOEGZmZprY33gAAIBhmC9ME8UmhAEXtt/w+/2p6X5bptjlgOwhECraLbfcQkSb\nN28e+V0Ck/2++c1vpqSkvPrqqy6Xi91UUVGh0WjKysqiUSrIV2lpaUtLS1dXF/uyr6+vra0N\nCwgBAGAkhIufHgoJCIQXBLbf8E2fJW4lEB8QCBXtuuuuM5lMGzduFARhhHepq6sjokmTJplM\npm9961vd3d3r1q0jIq/Xe/LkyeLiYr1eH8WKQYbYrNFACyJ0lAEAgJHjzWb2D+w5ESAkJhER\nqdXeUmz0BRGAQKhoRqNx2bJlTU1NR44cGeFdWCBk7UDWrFmj0+lefPFFv99/+vTpgYEBzBeF\noVggDDQaZYEQHWUAAGAkBOOFQIgpowGCVuebVOCZcYVgxOILiAAEQqX72te+RkSbNm0a4fks\nELJ2IBkZGbfeemtDQ8N7772HBYQQzqBAiBajAAAwcoERQgTCYO7b7h649jqxq4A4gUCodMuX\nL09ISNi8eTPP8yM5v7a2Vq/XZ2ZeWMH8gx/8gOO4F1544dixY4RACKEUFxer1epBgRBTRgEA\nYEQMRlKriQhdRgGiBIFQ6fR6/YoVK1paWj7//PPLniwIQn19/aRJk1SqC6+ckpKSxYsXHz58\n+O2331apVOgoA0MZDIbJkyefOnWKfehQW1ur0Wjy8vLErgsAAOSA4wSDkTgOawgBogSBEOjm\nm28morfffvuyZ54/f97lcg2a7PfAAw8QUWdnZ2FhofnivA6AYCUlJU6n8+zZs0RUU1OTk5Oj\n0+nELgoAAOTBb8v0p6YLao3YhQDEJwRCoGuvvdZqtb7zzjt+v3/4M4MXEAYsWbKkvLycMF8U\nwgssI+zs7Ozp6cF8UQAAGDn31253fWuN2FUAxC0EQiCdTrdq1aq2trZ9+/YNf2Z9fT0RTZo0\nadDxH/zgB0Q0e/bsqNQH8hcIhOgoAwAAo6ZSsWWEABAN8Tn4rtFoAovclInjOCJSqVQj3BXw\ntttu+8c//rFly5alS5cOcxqb8jd0s8G77767sLDwiiuu0Gq146gaQlOr1ew/VL5mzZpFRKdP\nn2ZRUMn7VXIcp9jvPZ5oNBq1Wo3/yjjA3i3odLqR78cL0qRSqUb+tgeiR+HvwGUqPgOhWq1W\nK/uTpEAgHGFCW7FiRUpKyqZNm5577jmNJuyrgk0ZLS4uHvqwCxYsGEe9MByVSiX3QFhQUGC1\nWr/44ovi4mIK8xJSAvb/qMzvPc6wj2nwXxkHAlclAqHccRyHqxJgbOIzEA4MDHi9XrGrEBMb\nhfD5fH19fSO8y6pVq/7+979v27Zt8eLF4c6pqqrS6XRJSUkjf1gYP7PZ7PP5BgYGxC5kXIqL\niw8dOnTo0CEiys7OVuZLiLXSUeb3Hmf0er1Go3E6nWIXAuNltVrVarXT6Rzh3ksgWWq12mKx\n4Bes6LRarcFgELsKGB2M6sIFt9xyCxFt3rx5mHPq6+vz8vIUPvoKY1NaWsrz/J49e3Q6XVZW\nltjlAAAAAAARAiEELFiwIDU19V//+pfH4wl5Qnt7e29vL9qBwNiUlJQQ0cDAwOTJk/GZAgAA\nAIBEIBDCBWq1+qtf/WpPT88nn3wS8oSQe04AjFBZWRn7Bz5TAAAAAJAOBEL4Eps1umnTppC3\nsg0Dhu45ATASpaWlrHkDNiEEAAAAkA4EQvjS3LlzbTbb1q1bQ84aZSOEGN6BsbFardnZ2YSX\nEAAAAICUIBDCl9Rq9fXXX+9wOPbu3Tv0VkwZhXFiywgRCAEAAACkA4EQLrFs2TIi+uCDD4be\nVFdXp9Vqc3NzY14UxInbb799wYIFM2bMELsQAAAAALgAgRAusXDhQoPBsHPnzqE31dfX5+bm\nDrNtPcDwbr755o0bN5rNZrELAQAAAIALEAjhEgaD4Zprrqmqqqqvrw8+3tXV1dPTg/miAAAA\nAADxBIEQBmOzRgcNErIWowiEAAAAAADxBIEQBgsZCNFiFAAAAAAg/iAQwmCTJ0/Oz8//5JNP\n3G534CBajAIAAAAAxB8EQghh2bJl/f39wZtPIBACAAAAAMQfBEIIYejmE3V1dWq1GntOAAAA\nAADEEwRCCGHevHlGo3HHjh2BI3V1dTk5OTqdTsSqAAAAAAAgshAIIQS9Xr9gwYKzZ8/W1NQQ\nkd1u7+rqQkcZAAAAAIA4g0AIoV177bV0cdYo9pwAAAAAAIhLCIQQWvDmE+goAwAAAAAQlxAI\nIbS8vLyioqJPP/3U6XRihBAAAAAAIC4hEEJYy5Yt83g8e/bsqa+vJwRCAAAAAIC4g0AIYbFl\nhDt37qytrVWpVBMnThS7IgAAAAAAiCSN2AWAdM2dO9disXzwwQdutzsrK0uv14tdEQAAAAAA\nRBJGCCEsnU63cOHCxsbGjo4O7DkBAAAAABB/EAhhOGzWKGEBIQAAAABAPEIghOEsW7aM4zhC\nIAQAAAAAiEcIhDCcrKyskpISQiAEAAAAAIhHCIRwGbfccotOp5s2bZrYhQAAAAAAQIQhEMJl\n/PjHP66qqsrNzRW7EAAAAAAAiDAEQrg8k8kkdgkAAAAAABB5CIQAAAAAAAAKhUAIAAAAAACg\nUAiEAAAAAAAACoVACAAAAAAAoFAIhAAAAAAAAAqFQAgAAAAAAKBQCIQAAAAAAAAKhUAIAAAA\nAACgUAiEAAAAAAAACoVACAAAAAAAoFAIhAAAAAAAAAqFQAgAAAAAAKBQCIQAAAAAAAAKhUAI\nAAAAAACgUAiEAAAAAAAACoVACAAAAAAAoFAIhAAAAAAAAAqFQAgAAAAAAKBQCIQAAAAAAAAK\nhUAIAAAAAACgUJwgCGLXAJHndrufffbZgoKC22+/XexaAOCCP/7xj36/f+3atWIXAgAXbNiw\n4cyZM2vXrrVYLGLXAgAgDowQxiev17tx48bPPvtM7EIA4Evbtm3bunWr2FUAwJf279+/cePG\n/v5+sQsBABANAiEAAAAAAIBCIRACAAAAAAAoFAIhAAAAAACAQqGpDAAAAAAAgEJhhBAAAAAA\nAEChEAgBAAAAAAAUCoEQAAAAAABAoTRiFwCj09XV9eqrrx49etTr9ebn599zzz1FRUXspubm\n5meffba6unrTpk2B89euXVtfXx/40iMEeRoAAAcESURBVGAwrF+/noj6+vpeeumlgwcP+ny+\n8vLyBx54ID09PbbfCkCcCHdVhjse7urDVQkQKaO9KvG3EgCUDE1lZOYnP/mJXq//7ne/azQa\nX3/99crKyj//+c8Gg+GTTz55+eWXZ82a9fHHHwcHwnvvvffWW2+dO3cu+1KlUqWkpBDRb3/7\n246Ojh/+8IcGg+Evf/nLuXPnnn/+eZUKI8YAoxbuqgx3PNzVh6sSIFJGe1XibyUAKBl+qclJ\nb2+vzWb74Q9/OHny5MzMzH/7t3+z2+0NDQ1E5PV6n3766cAfs+C7ZGRkpF7E/sJ1dHQcOHBg\n7dq1hYWFOTk5Dz30UHNzc0VFhQjfEoDMhbsqwx0Pd/XhqgSIlNFelYS/lQCgbJgyKicJCQmP\nPvpo4MvOzk6O49jfraVLlxJRTU1N8Pler3dgYGDv3r1//etfnU5nQUHBPffck5WVVVVVpdPp\n8vPz2WkWiyU3N7eqqmrWrFkx/G4A4kG4qzLc8XBXX39/P65KgIgY7VWJv5UAoHAYIZSr3t7e\nF1544cYbb0xNTQ13jsvlSkpKcrlcDz744GOPPebz+X7+8587nU6Hw5GQkMBxXODMxMREu90e\nk8IB4la4qzL4eLirD1clQDSM5KrE30oAUDiMEMpSU1PTE088MXPmzPvuu2+Y0xITE1977bXA\nl48++uh3vvOdPXv2EFHwXzgiwlJSgHEKd1UOPR7u6sNVCRBZI7wq8bcSABQOgVB+Kioqnnrq\nqbvuuuuGG24Y1R0NBkNqampnZ2dBQYHD4RAEIfCnzm63JycnR6FYAEUId1UOPZ6UlBTy6gt3\nPJbfBUA8GflVOQj+VgKA0mDKqMycOHHiqaeeevjhh0eSBs+ePfvf//3fXq+Xfel2u9va2jIz\nM4uKirxeb3V1NTtut9sbGxunTp0axboB4le4qzLk8XBXH65KgAga1VWJv5UAoHAYIZQTj8fz\n3HPP3XTTTXl5eR0dHeygxWIxGAzd3d1+v7+3t5eI2E0WiyUlJWXv3r0+n++OO+7w+/2vvfaa\n1Wq95pprDAbDvHnzXnjhhbVr1+r1+pdffrmwsLCsrEzM7w1AnsJdlSqVKuTx5OTkkFcfx3G4\nKgEiYrRXJf5WAoDCYR9COamoqPjVr3416OD9999/ww03rFmzpq2tLfj4mjVrbrrppurq6r/+\n9a9VVVVarba0tPTee++12WxE5HK5/vznP+/du5fn+VmzZn3/+9/HNBiAMQh3Vebk5IS7WsNd\nfbgqASJiDFcl/lYCgJIhEAIAAAAAACgU1hACAAAAAAAoFAIhAAAAAACAQiEQAgAAAAAAKBQC\nIQAAAAAAgEIhEAIAAAAAACgUAiEAAAAAAIBCIRACAAAAAAAoFAIhAABE3ve//30uvLlz5xLR\n3Llzp06dKnalAAAAiqYRuwAAAIhDd9xxR3l5Oft3VVXV888/v3r16sWLF7MjGRkZ7By32y1W\nhQAAAEBEnCAIYtcAAADx7OOPP16yZMmzzz770EMPiV0LAAAAXAJTRgEAQBzBU0YXLVq0YMGC\n/fv3X3XVVQaDITs7++mnn/b5fL/4xS+ysrISEhKuvfbampqawH0//fTT5cuXW61Wo9E4a9as\nV155RaRvAgAAQN4QCAEAQHwajaahoeHRRx999tlnjxw5MmPGjEceeWT16tU+n++jjz5av379\nwYMH77vvPnYyG3L0er2vv/76O++8M3fu3Pvuu+/pp58W91sAAACQI6whBAAA8XEc19DQsHHj\nxiuuuIKIHnvssffee+/8+fObN28mouLi4q9+9asbNmzw+/1qtfqnP/1pTk7O9u3b9Xo9ES1f\nvrylpeW3v/3tgw8+aDQaRf5OAAAAZAUjhAAAIAkWi4WlQSLKysoiogULFgRuzcrK8nq9Tqez\no6Pj0KFD1113nSAI/Rddf/31drv90KFD4pQOAAAgWxghBAAASZgwYULg3xqNJuQRnucbGxuJ\n6E9/+tOf/vSnQY/Q3Nwci0IBAADiCAIhAADICcdxRHTPPfd873vfG3RTYWGhGBUBAADIGAIh\nAADISV5eHhHxPM92twcAAIDxwBpCAACQk5SUlDlz5mzatKmnpydw8LXXXvvlL3/p8/lELAwA\nAECOEAgBAEBmnnrqKZfLtWDBgr/97W87duz41a9+tWbNmpaWFrbOEAAAAEYOfzsBAEBmFi1a\n9OGHHz7++OMPPvig1+vNz89//PHHH3nkEbHrAgAAkB9OEASxawAAAAAAAAARYMooAAAAAACA\nQiEQAgAAAAAAKBQCIQAAAAAAgEIhEAIAAAAAACgUAiEAAAAAAIBCIRACAAAAAAAoFAIhAAAA\nAACAQiEQAgAAAAAAKBQCIQAAAAAAgEIhEAIAAAAAACgUAiEAAAAAAIBC/X/G5ElYTObFVgAA\nAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 300,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fc <- arima.forecast(x.train, h)\n",
    "my.plot_forecast(fc, future=h, test=x.test, past=h*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "dc2dfd61-7098-462a-8833-cce95aa054f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-= Iteration 0 Sun Sep 25 22:37:25 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 100 Sun Sep 25 22:37:29 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 200 Sun Sep 25 22:37:33 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 300 Sun Sep 25 22:37:37 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 400 Sun Sep 25 22:37:41 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 500 Sun Sep 25 22:37:45 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 600 Sun Sep 25 22:37:49 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 700 Sun Sep 25 22:37:53 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 800 Sun Sep 25 22:37:57 2022 =-=-=-=-=\n",
      "=-=-=-=-= Iteration 900 Sun Sep 25 22:38:01 2022 =-=-=-=-=\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NULL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHQAAALQCAIAAAB+M7AjAAAACXBIWXMAABJ0AAASdAHeZh94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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 360,
       "width": 570
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bsts.lines <- function(fc, obs, ...) {\n",
    "    n1 <- ncol(fc$distribution)\n",
    "    time <- index(fc$original.series)\n",
    "    deltat <- tail(diff(tail(time, 2)), 1)\n",
    "    pred.time <- tail(time, 1) + (1:n1) * deltat\n",
    "    obs <- obs[1:length(pred.time)]\n",
    "    index(obs) <- pred.time\n",
    "    #l <- lines(obs)\n",
    "    l <- lines(pred.time, as.numeric(obs), ...)\n",
    "    return(l)\n",
    "}\n",
    "\n",
    "fc <- bsts.forecast(x.train, h)\n",
    "\n",
    "my.figsize(9.5,6)\n",
    "plot(fc, plot.original=h*6)\n",
    "bsts.lines(fc, x.test, col='red')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
